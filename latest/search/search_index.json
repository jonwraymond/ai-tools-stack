{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Tools Stack","text":"<p>Welcome to the unified documentation for the AI Tools Stack. This site brings all tool libraries together in one place and shows how they compose into a progressive-disclosure MCP surface.</p> <p>Simple and elegant at the core, extensible through modular, pluggable architecture.</p> <p></p>"},{"location":"#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes Index</li> <li>User Journeys Index</li> <li>Stack Changelog</li> </ul>"},{"location":"#what-this-stack-provides","title":"What this stack provides","text":"Layer Components Purpose Foundation toolfoundation (model, adapter, version) Canonical schemas + protocol adapters Discovery tooldiscovery (index, tooldoc, search, semantic) Registry, docs, search strategies Execution toolexec (run, code, runtime, backend) Execution, chaining, sandboxing Composition toolcompose (set, skill) Filtered collections, skill workflows Operations toolops (observe, cache, auth, resilience, health) Observability + production controls Protocol toolprotocol (transport, wire, content, stream, task, session, resource, prompt, elicit) Protocol primitives Surface metatools-mcp MCP server wiring"},{"location":"#high-level-flow","title":"High-level Flow","text":"<p>Diagram controls</p> <p>Click any diagram to open a zoomable, pannable view. Scroll/pinch to zoom and drag to pan.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0', 'primaryTextColor': '#fff', 'lineColor': '#4a5568'}}}%%\nflowchart TB\n    subgraph client[\"Client\"]\n        Agent[\"\ud83e\udd16 AI Agent\"]\n    end\n\n    subgraph surface[\"MCP Surface\"]\n        MCP[\"\ud83d\udd37 metatools-mcp&lt;br/&gt;&lt;small&gt;JSON-RPC / SSE&lt;/small&gt;\"]\n    end\n\n    subgraph operations[\"Operations\"]\n        Observe[\"\ud83d\udc41\ufe0f toolops/observe\"]\n        Cache[\"\ud83d\udcbe toolops/cache\"]\n        Auth[\"\ud83d\udd10 toolops/auth\"]\n        Resilience[\"\ud83e\uddef toolops/resilience\"]\n        Health[\"\ud83d\udc9a toolops/health\"]\n    end\n\n    subgraph composition[\"Composition\"]\n        Toolset[\"\ud83d\udce6 toolcompose/set\"]\n        Skill[\"\ud83c\udfaf toolcompose/skill\"]\n    end\n\n    subgraph protocol[\"Protocol\"]\n        Wire[\"\ud83d\udd04 toolprotocol/wire\"]\n        Transport[\"\ud83d\udce1 toolprotocol/transport\"]\n        Content[\"\ud83e\udde9 toolprotocol/content\"]\n    end\n\n    subgraph execution[\"Execution\"]\n        Run[\"\u25b6\ufe0f toolexec/run\"]\n        Code[\"\ud83d\udcbb toolexec/code\"]\n        Runtime[\"\ud83c\udfc3 toolexec/runtime\"]\n    end\n\n    subgraph discovery[\"Discovery\"]\n        Index[\"\ud83d\udcc7 tooldiscovery/index\"]\n        Docs[\"\ud83d\udcda tooldiscovery/tooldoc\"]\n        Search[\"\ud83d\udd0d tooldiscovery/search\"]\n        Semantic[\"\ud83e\udde0 tooldiscovery/semantic\"]\n    end\n\n    subgraph foundation[\"Foundation\"]\n        Model[\"\ud83e\uddf1 toolfoundation/model\"]\n        Adapter[\"\ud83e\udde9 toolfoundation/adapter\"]\n        Version[\"\ud83c\udff7\ufe0f toolfoundation/version\"]\n    end\n\n    subgraph backends[\"Backends\"]\n        Local[\"\ud83c\udfe0 Local\"]\n        Provider[\"\ud83d\udd0c Provider\"]\n        MCPBackend[\"\ud83d\udce1 MCP Server\"]\n        Docker[\"\ud83d\udc33 Docker\"]\n    end\n\n    Agent &lt;--&gt;|\"MCP Protocol\"| MCP\n\n    MCP --&gt; Observe\n    MCP --&gt; Cache\n    MCP --&gt; Auth\n    MCP --&gt; Resilience\n    MCP --&gt; Health\n\n    MCP --&gt; Toolset\n    MCP --&gt; Skill\n\n    MCP --&gt; Wire\n    MCP --&gt; Transport\n    MCP --&gt; Content\n\n    MCP --&gt; Index\n    MCP --&gt; Docs\n    Index --&gt; Search\n    Index --&gt; Semantic\n\n    MCP --&gt; Run\n    Run --&gt; Code\n    Code --&gt; Runtime\n\n    Toolset --&gt; Index\n    Toolset --&gt; Model\n    Skill --&gt; Run\n\n    Index --&gt; Model\n    Docs --&gt; Model\n    Adapter --&gt; Model\n    Version --&gt; Model\n\n    Run --&gt; Local\n    Run --&gt; Provider\n    Run --&gt; MCPBackend\n    Runtime --&gt; Docker\n\n    style client fill:#4a5568,stroke:#2d3748,stroke-width:2px\n    style surface fill:#2b6cb0,stroke:#2c5282,stroke-width:3px\n    style operations fill:#e53e3e,stroke:#c53030\n    style composition fill:#6b46c1,stroke:#553c9a\n    style protocol fill:#d69e2e,stroke:#b7791f\n    style execution fill:#38a169,stroke:#276749\n    style discovery fill:#3182ce,stroke:#2c5282\n    style foundation fill:#718096,stroke:#4a5568\n    style backends fill:#2d3748,stroke:#1a202c</code></pre>"},{"location":"#progressive-disclosure","title":"Progressive Disclosure","text":"<p>The core usability pattern: discover \u2192 describe \u2192 execute</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'actorBkg': '#2b6cb0', 'actorTextColor': '#fff'}}}%%\nsequenceDiagram\n    autonumber\n    participant Agent as \ud83e\udd16 Agent\n    participant MCP as \ud83d\udd37 metatools-mcp\n\n    rect rgb(43, 108, 176, 0.1)\n        Note over Agent,MCP: 1. Discovery (Token-Cheap)\n        Agent-&gt;&gt;MCP: search_tools(\"create issue\")\n        MCP--&gt;&gt;Agent: Summary[] (no schemas)\n    end\n\n    rect rgb(214, 158, 46, 0.1)\n        Note over Agent,MCP: 2. Description (On-Demand)\n        Agent-&gt;&gt;MCP: describe_tool(id, \"schema\")\n        MCP--&gt;&gt;Agent: Full tool schema\n    end\n\n    rect rgb(56, 161, 105, 0.1)\n        Note over Agent,MCP: 3. Execution (Validated)\n        Agent-&gt;&gt;MCP: run_tool(id, args)\n        MCP--&gt;&gt;Agent: Execution result\n    end</code></pre>"},{"location":"#quickstart","title":"Quickstart","text":"<ol> <li>Start with <code>toolfoundation/model</code> for your canonical schemas</li> <li>Register tools in <code>tooldiscovery/index</code> for discovery</li> <li>Add docs/examples in <code>tooldiscovery/tooldoc</code></li> <li>Execute tools via <code>toolexec/run</code></li> <li>Expose the MCP surface using <code>metatools-mcp</code></li> </ol> <p>See the Components section for per-library examples and diagrams.</p>"},{"location":"#design-notes-and-user-journeys","title":"Design Notes and User Journeys","text":"<p>For deeper context, see the aggregated indexes:</p> <ul> <li>Design Notes Index \u2014 per\u2011repo tradeoffs and error semantics</li> <li>User Journeys Index \u2014 end\u2011to\u2011end agent workflows</li> </ul>"},{"location":"#docs-from-each-repo","title":"Docs from each repo","text":"<p>Under Library Docs (from repos) you will find the docs imported directly from each repository at build time.</p>"},{"location":"architecture/design-notes/","title":"Design Notes Index","text":"<p>This page aggregates the per\u2011repo Design Notes pages that document tradeoffs and error semantics for each component. Use these when you want to understand why a design decision was made or how to handle specific failure modes.</p>"},{"location":"architecture/design-notes/#perrepo-design-notes","title":"Per\u2011repo Design Notes","text":"<ul> <li>toolfoundation \u2014 design-notes</li> <li>tooldiscovery \u2014 design-notes</li> <li>toolexec \u2014 design-notes</li> <li>toolcompose \u2014 design-notes</li> <li>toolops \u2014 design-notes</li> <li>toolprotocol \u2014 design-notes</li> <li>metatools-mcp \u2014 design-notes</li> <li>metatools\u2011mcp \u2014 design-notes</li> </ul>"},{"location":"architecture/design-notes/#when-to-read-these","title":"When to read these","text":"<ul> <li>You\u2019re debugging failure modes or error propagation.</li> <li>You want to compare tradeoffs (latency vs safety, flexibility vs simplicity).</li> <li>You\u2019re deciding where to plug in a custom implementation.</li> </ul>"},{"location":"architecture/overview/","title":"Stack Architecture","text":"<p>This stack is built around progressive disclosure and a clean separation of schema, discovery, docs, execution, and transport.</p>"},{"location":"architecture/overview/#system-context-c4-level-1","title":"System Context (C4 Level 1)","text":"<p>High-level view showing the ApertureStack and its external actors.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#1a365d', 'primaryTextColor': '#fff', 'primaryBorderColor': '#2c5282', 'lineColor': '#4a5568', 'secondaryColor': '#2d3748', 'tertiaryColor': '#e2e8f0'}}}%%\nflowchart TB\n    subgraph external[\"External Systems\"]\n        Agent[\"\ud83e\udd16 AI Agent&lt;br/&gt;&lt;small&gt;Claude, GPT, etc.&lt;/small&gt;\"]\n        ExtMCP[\"\ud83d\udce1 External MCP Servers&lt;br/&gt;&lt;small&gt;GitHub, Filesystem, etc.&lt;/small&gt;\"]\n        Backends[\"\u2699\ufe0f Execution Backends&lt;br/&gt;&lt;small&gt;Docker, K8s, WASM&lt;/small&gt;\"]\n    end\n\n    subgraph aperture[\"ApertureStack\"]\n        direction TB\n        MCP[\"\ud83d\udd37 metatools-mcp&lt;br/&gt;&lt;small&gt;MCP Server Surface&lt;/small&gt;\"]\n    end\n\n    subgraph observability[\"Observability\"]\n        OTLP[\"\ud83d\udcca OTLP Collector\"]\n        Prometheus[\"\ud83d\udcc8 Prometheus\"]\n        Jaeger[\"\ud83d\udd0d Jaeger\"]\n    end\n\n    Agent --&gt;|\"MCP Protocol&lt;br/&gt;JSON-RPC\"| MCP\n    MCP --&gt;|\"Tool Calls\"| ExtMCP\n    MCP --&gt;|\"Code Execution\"| Backends\n    MCP -.-&gt;|\"Traces\"| OTLP\n    MCP -.-&gt;|\"Metrics\"| Prometheus\n    OTLP --&gt; Jaeger\n\n    style aperture fill:#1a365d,stroke:#2c5282,stroke-width:3px\n    style external fill:#2d3748,stroke:#4a5568,stroke-width:2px\n    style observability fill:#2f855a,stroke:#276749,stroke-width:2px</code></pre>"},{"location":"architecture/overview/#layering-model-consolidated-stack","title":"Layering Model (Consolidated Stack)","text":"<p>Complete view of the consolidated repositories organized by layer.</p> <p></p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0', 'primaryTextColor': '#fff', 'lineColor': '#4a5568'}}}%%\nflowchart TB\n    subgraph surface[\"MCP Surface Layer\"]\n        direction LR\n        metatools[\"\ud83d\udd37 metatools-mcp&lt;br/&gt;&lt;small&gt;v0.5.0 \u2022 MCP Server&lt;/small&gt;\"]\n    end\n\n    subgraph protocol[\"Protocol Layer\"]\n        direction LR\n        toolprotocol[\"\ud83d\udce1 toolprotocol&lt;br/&gt;&lt;small&gt;v0.1.0 \u2022 Transports + Wire&lt;/small&gt;\"]\n    end\n\n    subgraph operations[\"Operations Layer\"]\n        direction LR\n        toolops[\"\ud83d\udc41\ufe0f toolops&lt;br/&gt;&lt;small&gt;v0.1.0 \u2022 Observe/Cache/Auth&lt;/small&gt;\"]\n    end\n\n    subgraph composition[\"Composition Layer\"]\n        direction LR\n        toolcompose[\"\ud83d\udce6 toolcompose&lt;br/&gt;&lt;small&gt;v0.1.0 \u2022 Set + Skill&lt;/small&gt;\"]\n    end\n\n    subgraph execution[\"Execution Layer\"]\n        direction LR\n        toolexec[\"\u25b6\ufe0f toolexec&lt;br/&gt;&lt;small&gt;v0.1.0 \u2022 Run/Code/Runtime&lt;/small&gt;\"]\n    end\n\n    subgraph discovery[\"Discovery Layer\"]\n        direction LR\n        tooldiscovery[\"\ud83d\udcc7 tooldiscovery&lt;br/&gt;&lt;small&gt;v0.1.0 \u2022 Index/Search/Docs&lt;/small&gt;\"]\n    end\n\n    subgraph foundation[\"Foundation Layer\"]\n        direction LR\n        toolfoundation[\"\ud83e\uddf1 toolfoundation&lt;br/&gt;&lt;small&gt;v0.1.0 \u2022 Model/Adapter/Version&lt;/small&gt;\"]\n    end\n\n    toolfoundation --&gt; tooldiscovery\n    toolfoundation --&gt; toolexec\n    toolfoundation --&gt; toolprotocol\n    toolfoundation --&gt; toolops\n    toolfoundation --&gt; toolcompose\n\n    tooldiscovery --&gt; toolcompose\n    toolexec --&gt; toolcompose\n\n    toolprotocol --&gt; metatools\n    toolops --&gt; metatools\n    toolcompose --&gt; metatools\n    toolexec --&gt; metatools\n    tooldiscovery --&gt; metatools\n    toolfoundation --&gt; metatools\n\n    style surface fill:#2b6cb0,stroke:#2c5282,stroke-width:2px\n    style protocol fill:#d69e2e,stroke:#b7791f,stroke-width:2px\n    style operations fill:#e53e3e,stroke:#c53030,stroke-width:2px\n    style composition fill:#6b46c1,stroke:#553c9a,stroke-width:2px\n    style execution fill:#38a169,stroke:#276749,stroke-width:2px\n    style discovery fill:#3182ce,stroke:#2c5282,stroke-width:2px\n    style foundation fill:#718096,stroke:#4a5568,stroke-width:2px</code></pre>"},{"location":"architecture/overview/#progressive-disclosure-pipeline","title":"Progressive Disclosure Pipeline","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'actorBkg': '#2b6cb0', 'actorTextColor': '#fff', 'actorBorder': '#2c5282'}}}%%\nsequenceDiagram\n    autonumber\n\n    participant Agent as \ud83e\udd16 AI Agent\n    participant MCP as \ud83d\udd37 metatools-mcp\n    participant Index as \ud83d\udcc7 tooldiscovery/index\n    participant Search as \ud83d\udd0d tooldiscovery/search\n    participant Docs as \ud83d\udcda tooldiscovery/tooldoc\n    participant Run as \u25b6\ufe0f toolexec/run\n\n    rect rgb(43, 108, 176, 0.1)\n        Note over Agent,Search: Phase 1: Discovery (Token-Cheap)\n        Agent-&gt;&gt;+MCP: search_tools(\"create issue\", limit=5)\n        MCP-&gt;&gt;+Index: Search(query, limit)\n        Index-&gt;&gt;+Search: Search(docs, query, limit)\n        Search--&gt;&gt;-Index: scored results\n        Index--&gt;&gt;-MCP: Summary[] (no schemas)\n        MCP--&gt;&gt;-Agent: summaries\n    end\n\n    rect rgb(214, 158, 46, 0.1)\n        Note over Agent,Docs: Phase 2: Description (On-Demand)\n        Agent-&gt;&gt;+MCP: describe_tool(\"github:create_issue\", \"schema\")\n        MCP-&gt;&gt;+Docs: DescribeTool(id, DetailSchema)\n        Docs-&gt;&gt;Index: GetTool(id)\n        Index--&gt;&gt;Docs: Tool definition\n        Docs--&gt;&gt;-MCP: ToolDoc with schema\n        MCP--&gt;&gt;-Agent: full tool schema\n    end\n\n    rect rgb(56, 161, 105, 0.1)\n        Note over Agent,Run: Phase 3: Execution (Validated)\n        Agent-&gt;&gt;+MCP: run_tool(\"github:create_issue\", args)\n        MCP-&gt;&gt;+Run: Run(ctx, id, args)\n        Run-&gt;&gt;Run: ValidateInput(args)\n        Run-&gt;&gt;Run: ResolveBackend()\n        Run-&gt;&gt;Run: Execute via backend\n        Run-&gt;&gt;Run: ValidateOutput(result)\n        Run--&gt;&gt;-MCP: RunResult\n        MCP--&gt;&gt;-Agent: execution result\n    end</code></pre>"},{"location":"architecture/overview/#tool-execution-and-runtime-isolation","title":"Tool Execution and Runtime Isolation","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#38a169'}}}%%\nflowchart LR\n    subgraph input[\"Input Phase\"]\n        A[\"\ud83d\udce5 Receive&lt;br/&gt;ToolID + Args\"]\n    end\n\n    subgraph validation1[\"Validation Phase 1\"]\n        B[\"\u2705 Validate&lt;br/&gt;Tool ID Format\"]\n        C[\"\u2705 Validate&lt;br/&gt;Input Schema\"]\n    end\n\n    subgraph resolution[\"Resolution Phase\"]\n        D[\"\ud83d\udd0d Resolve&lt;br/&gt;Tool Definition\"]\n        E[\"\ud83c\udfaf Select&lt;br/&gt;Backend\"]\n    end\n\n    subgraph execution[\"Execution Phase\"]\n        F{\"Backend&lt;br/&gt;Type?\"}\n        G[\"\ud83c\udfe0 Local&lt;br/&gt;Handler\"]\n        H[\"\ud83d\udd0c Provider&lt;br/&gt;Executor\"]\n        I[\"\ud83d\udce1 MCP&lt;br/&gt;Server Call\"]\n    end\n\n    subgraph normalization[\"Normalization Phase\"]\n        J[\"\ud83d\udce4 Normalize&lt;br/&gt;Result\"]\n    end\n\n    subgraph validation2[\"Validation Phase 2\"]\n        K[\"\u2705 Validate&lt;br/&gt;Output Schema\"]\n    end\n\n    subgraph output[\"Output Phase\"]\n        L[\"\ud83d\udce6 Return&lt;br/&gt;RunResult\"]\n    end\n\n    A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F\n    F --&gt;|local| G\n    F --&gt;|provider| H\n    F --&gt;|mcp| I\n    G --&gt; J\n    H --&gt; J\n    I --&gt; J\n    J --&gt; K --&gt; L\n\n    style input fill:#3182ce,stroke:#2c5282\n    style validation1 fill:#38a169,stroke:#276749\n    style resolution fill:#d69e2e,stroke:#b7791f\n    style execution fill:#6b46c1,stroke:#553c9a\n    style normalization fill:#e53e3e,stroke:#c53030\n    style validation2 fill:#38a169,stroke:#276749\n    style output fill:#3182ce,stroke:#2c5282</code></pre>"},{"location":"architecture/overview/#search-strategy-layering","title":"Search Strategy Layering","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#3182ce'}}}%%\nflowchart TB\n    subgraph query[\"Search Query\"]\n        Input[\"\ud83d\udd0d 'create github issue'\"]\n    end\n\n    subgraph index[\"tooldiscovery/index\"]\n        Search[\"Index.Search(query, limit)\"]\n        Docs[\"SearchDoc[]&lt;br/&gt;&lt;small&gt;ID, Name, Namespace,&lt;br/&gt;Description, Tags&lt;/small&gt;\"]\n    end\n\n    subgraph strategies[\"Search Strategies\"]\n        direction TB\n\n        subgraph lexical[\"Lexical (Default)\"]\n            Simple[\"Simple substring&lt;br/&gt;matching\"]\n        end\n\n        subgraph bm25[\"BM25 (tooldiscovery/search)\"]\n            BM[\"BM25Searcher\"]\n            Boosts[\"Field Boosts:&lt;br/&gt;&lt;small&gt;name: 4x&lt;br/&gt;namespace: 2x&lt;br/&gt;tags: 1x&lt;/small&gt;\"]\n            Bleve[\"Bleve Index\"]\n        end\n\n        subgraph semantic[\"Semantic (tooldiscovery/semantic)\"]\n            Embed[\"Embedder\"]\n            Vector[\"Vector Store\"]\n            Similarity[\"Cosine Similarity\"]\n        end\n    end\n\n    subgraph ranking[\"Ranking\"]\n        Score[\"\ud83d\udcca Score + Rank\"]\n        Dedup[\"\ud83d\udd04 Deduplicate\"]\n        Limit[\"\u2702\ufe0f Apply Limit\"]\n    end\n\n    subgraph output[\"Results\"]\n        Results[\"Summary[]&lt;br/&gt;&lt;small&gt;No schemas (token-cheap)&lt;/small&gt;\"]\n    end\n\n    Input --&gt; Search\n    Search --&gt; Docs\n\n    Docs --&gt; Simple\n    Docs --&gt; BM --&gt; Boosts --&gt; Bleve\n    Docs --&gt; Embed --&gt; Vector --&gt; Similarity\n\n    Simple --&gt; Score\n    Bleve --&gt; Score\n    Similarity --&gt; Score\n\n    Score --&gt; Dedup --&gt; Limit --&gt; Results\n\n    style strategies fill:#3182ce,stroke:#2c5282,stroke-width:2px\n    style bm25 fill:#38a169,stroke:#276749\n    style semantic fill:#6b46c1,stroke:#553c9a\n    style ranking fill:#d69e2e,stroke:#b7791f</code></pre>"},{"location":"architecture/overview/#component-dependency-graph","title":"Component Dependency Graph","text":"<p>Directed acyclic graph showing module dependencies and bump order.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#4a5568'}}}%%\nflowchart TD\n    subgraph order1[\"Bump Order 1\"]\n        toolfoundation[\"\ud83e\uddf1 toolfoundation\"]\n    end\n\n    subgraph order2[\"Bump Order 2\"]\n        tooldiscovery[\"\ud83d\udcc7 tooldiscovery\"]\n        toolexec[\"\u25b6\ufe0f toolexec\"]\n        toolprotocol[\"\ud83d\udce1 toolprotocol\"]\n        toolops[\"\ud83d\udc41\ufe0f toolops\"]\n    end\n\n    subgraph order3[\"Bump Order 3\"]\n        toolcompose[\"\ud83d\udce6 toolcompose\"]\n    end\n\n    subgraph order4[\"Bump Order 4\"]\n        metatools[\"\ud83d\udd37 metatools-mcp\"]\n    end\n\n    toolfoundation --&gt; tooldiscovery\n    toolfoundation --&gt; toolexec\n    toolfoundation --&gt; toolprotocol\n    toolfoundation --&gt; toolops\n    toolfoundation --&gt; toolcompose\n\n    tooldiscovery --&gt; toolcompose\n    toolexec --&gt; toolcompose\n\n    toolprotocol --&gt; metatools\n    toolops --&gt; metatools\n    toolcompose --&gt; metatools\n    toolexec --&gt; metatools\n    tooldiscovery --&gt; metatools\n    toolfoundation --&gt; metatools\n\n    style order1 fill:#718096,stroke:#4a5568\n    style order2 fill:#3182ce,stroke:#2c5282\n    style order3 fill:#38a169,stroke:#276749\n    style order4 fill:#6b46c1,stroke:#553c9a</code></pre>"},{"location":"architecture/overview/#observability-integration","title":"Observability Integration","text":"<p>How toolops/observe wraps around tool execution with traces, metrics, and logs.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e53e3e'}}}%%\nflowchart TB\n    subgraph client[\"Client Layer\"]\n        Request[\"\ud83d\udce5 Tool Request\"]\n    end\n\n    subgraph middleware[\"toolops/observe Middleware\"]\n        direction TB\n        MW[\"\ud83d\udd00 Middleware.Wrap()\"]\n\n        subgraph tracing[\"Tracing\"]\n            SpanStart[\"StartSpan&lt;br/&gt;&lt;small&gt;tool.exec.{namespace}.{name}&lt;/small&gt;\"]\n            SpanEnd[\"EndSpan\"]\n            SpanAttrs[\"Span Attributes&lt;br/&gt;&lt;small&gt;tool.id, tool.namespace, tool.name&lt;br/&gt;tool.version, tool.category, tool.tags&lt;/small&gt;\"]\n        end\n\n        subgraph metrics[\"Metrics\"]\n            Counter[\"tool.exec.total&lt;br/&gt;&lt;small&gt;{call} counter&lt;/small&gt;\"]\n            Histogram[\"tool.exec.duration&lt;br/&gt;&lt;small&gt;ms histogram&lt;/small&gt;\"]\n        end\n\n        subgraph logging[\"Structured Logging\"]\n            LogFields[\"Fields: tool.id, args (redacted)&lt;br/&gt;duration, error\"]\n        end\n    end\n\n    subgraph execution[\"Actual Execution\"]\n        Runner[\"\u25b6\ufe0f toolexec/run.Runner\"]\n    end\n\n    subgraph exporters[\"Exporters\"]\n        direction LR\n        OTLP[\"\ud83d\udce1 OTLP\"]\n        Jaeger[\"\ud83d\udd0d Jaeger\"]\n        Prometheus[\"\ud83d\udcca Prometheus\"]\n        Stdout[\"\ud83d\udda5\ufe0f Stdout\"]\n    end\n\n    Request --&gt; MW\n    MW --&gt; SpanStart --&gt; SpanAttrs\n    MW --&gt; Counter\n    SpanAttrs --&gt; Runner\n    Runner --&gt; SpanEnd\n    Runner --&gt; Histogram\n\n    SpanEnd --&gt; OTLP\n    SpanEnd --&gt; Jaeger\n    Histogram --&gt; Prometheus\n    Histogram --&gt; OTLP\n\n    style middleware fill:#e53e3e,stroke:#c53030,stroke-width:2px\n    style tracing fill:#6b46c1,stroke:#553c9a\n    style metrics fill:#38a169,stroke:#276749\n    style logging fill:#3182ce,stroke:#2c5282\n    style exporters fill:#d69e2e,stroke:#b7791f</code></pre>"},{"location":"architecture/pluggable-architecture/","title":"Pluggable Architecture","text":"<p>The stack is designed so each layer is replaceable without changing the others. This keeps the core stable while allowing experimentation and integration.</p>"},{"location":"architecture/pluggable-architecture/#extension-points","title":"Extension points","text":""},{"location":"architecture/pluggable-architecture/#what-you-can-plug-in","title":"What you can plug in","text":"<ul> <li>Search: swap lexical for BM25 or semantic ranking</li> <li>Execution: add MCP servers, local handlers, or provider adapters</li> <li>Code execution: change engines or language runtimes</li> <li>Runtime isolation: choose the sandbox backend per environment</li> </ul>"},{"location":"architecture/pluggable-architecture/#design-goal","title":"Design goal","text":"<p>The default implementations are intentionally simple and safe. Advanced capabilities are injected rather than baked into the core.</p>"},{"location":"architecture/progressive-disclosure/","title":"Progressive Disclosure","text":"<p>Progressive disclosure is the core usability strategy of this stack. It lets agents discover just enough information to choose the right tool, then retrieve deeper details only when needed.</p>"},{"location":"architecture/progressive-disclosure/#why-it-matters","title":"Why it matters","text":"<ul> <li>Lower token cost: most tools are never fully expanded</li> <li>Faster decisions: summary-level signals are enough to pick candidates</li> <li>Safer execution: schema and examples are fetched only after a tool is chosen</li> </ul>"},{"location":"architecture/progressive-disclosure/#flow","title":"Flow","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'actorBkg': '#2b6cb0', 'actorTextColor': '#fff', 'actorBorder': '#2c5282'}}}%%\nsequenceDiagram\n    autonumber\n\n    participant Agent as \ud83e\udd16 AI Agent\n    participant MCP as \ud83d\udd37 metatools-mcp\n    participant Index as \ud83d\udcc7 tooldiscovery/index\n    participant Search as \ud83d\udd0d tooldiscovery/search\n    participant Docs as \ud83d\udcda tooldiscovery/tooldoc\n    participant Run as \u25b6\ufe0f toolexec/run\n    participant Cache as \ud83d\udcbe toolops/cache\n    participant Observe as \ud83d\udc41\ufe0f toolops/observe\n\n    rect rgb(43, 108, 176, 0.1)\n        Note over Agent,Search: Phase 1: Discovery (Token-Cheap)\n        Agent-&gt;&gt;+MCP: search_tools(\"create issue\", limit=5)\n        MCP-&gt;&gt;+Index: Search(query, limit)\n        Index-&gt;&gt;+Search: Search(docs, query, limit)\n        Search--&gt;&gt;-Index: scored results\n        Index--&gt;&gt;-MCP: Summary[] (no schemas)\n        MCP--&gt;&gt;-Agent: summaries\n    end\n\n    rect rgb(214, 158, 46, 0.1)\n        Note over Agent,Docs: Phase 2: Description (On-Demand)\n        Agent-&gt;&gt;+MCP: describe_tool(\"github:create_issue\", \"schema\")\n        MCP-&gt;&gt;+Docs: DescribeTool(id, DetailSchema)\n        Docs-&gt;&gt;Index: GetTool(id)\n        Index--&gt;&gt;Docs: Tool definition\n        Docs--&gt;&gt;-MCP: ToolDoc with schema\n        MCP--&gt;&gt;-Agent: full tool schema\n    end\n\n    rect rgb(56, 161, 105, 0.1)\n        Note over Agent,Observe: Phase 3: Execution (Validated)\n        Agent-&gt;&gt;+MCP: run_tool(\"github:create_issue\", args)\n        MCP-&gt;&gt;Observe: StartSpan(\"tool.exec.github.create_issue\")\n        MCP-&gt;&gt;+Cache: Get(toolID, argsHash)\n        alt Cache Hit\n            Cache--&gt;&gt;MCP: cached result\n        else Cache Miss\n            MCP-&gt;&gt;+Run: Run(ctx, id, args)\n            Run-&gt;&gt;Run: ValidateInput(args)\n            Run-&gt;&gt;Run: ResolveBackend()\n            Run-&gt;&gt;Run: Execute via backend\n            Run-&gt;&gt;Run: ValidateOutput(result)\n            Run--&gt;&gt;-MCP: RunResult\n            MCP-&gt;&gt;Cache: Set(toolID, argsHash, result)\n        end\n        Cache--&gt;&gt;-MCP: result\n        MCP-&gt;&gt;Observe: EndSpan(result)\n        MCP--&gt;&gt;-Agent: execution result\n    end</code></pre>"},{"location":"architecture/progressive-disclosure/#detail-levels","title":"Detail Levels","text":"<p>The three progressive detail levels minimize token consumption:</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#3182ce'}}}%%\nflowchart LR\n    subgraph level1[\"DetailSummary\"]\n        S1[\"\ud83d\udccb 1-2 line description\"]\n        S2[\"\ud83c\udff7\ufe0f Tags\"]\n        S3[\"\ud83d\udcc1 Namespace\"]\n    end\n\n    subgraph level2[\"DetailSchema\"]\n        SS1[\"\ud83d\udccb Full description\"]\n        SS2[\"\ud83d\udcd0 Input schema\"]\n        SS3[\"\ud83d\udce4 Output schema\"]\n    end\n\n    subgraph level3[\"DetailFull\"]\n        F1[\"\ud83d\udccb Everything from Schema\"]\n        F2[\"\ud83d\udcdd Human-authored notes\"]\n        F3[\"\ud83d\udca1 1-3 examples\"]\n        F4[\"\ud83d\udd17 External references\"]\n    end\n\n    level1 --&gt;|\"Agent selects tool\"| level2\n    level2 --&gt;|\"Needs examples\"| level3\n\n    style level1 fill:#38a169,stroke:#276749\n    style level2 fill:#d69e2e,stroke:#b7791f\n    style level3 fill:#6b46c1,stroke:#553c9a</code></pre>"},{"location":"architecture/progressive-disclosure/#component-roles","title":"Component Roles","text":"Component Role in Progressive Disclosure <code>tooldiscovery/index</code> Fast, summary-only discovery <code>tooldiscovery/search</code> Pluggable ranking strategy (BM25, semantic) <code>tooldiscovery/semantic</code> Vector-based intent matching <code>tooldiscovery/tooldoc</code> Structured detail (summary/schema/full/examples) <code>toolexec/run</code> Execution with validation + consistent errors <code>toolexec/code</code> Optional code-mode orchestration <code>toolops/cache</code> Cache results to avoid re-execution <code>toolops/observe</code> Trace execution for debugging"},{"location":"architecture/progressive-disclosure/#token-economics","title":"Token Economics","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#38a169'}}}%%\npie showData\n    title Token Distribution by Phase\n    \"Discovery (Summary)\" : 15\n    \"Description (Schema)\" : 35\n    \"Execution (Args/Result)\" : 50</code></pre> <p>Most tools are never fully expanded \u2014 progressive disclosure means you only pay for the detail level you actually need.</p>"},{"location":"architecture/user-journeys/","title":"User Journeys Index","text":"<p>This page aggregates the per\u2011repo User Journey pages that describe full end\u2011to\u2011end workflows. These are ideal for onboarding and for validating that the progressive\u2011disclosure flow is coherent across layers.</p>"},{"location":"architecture/user-journeys/#perrepo-user-journeys","title":"Per\u2011repo User Journeys","text":"<ul> <li>toolfoundation \u2014 user-journey</li> <li>tooldiscovery \u2014 user-journey</li> <li>toolexec \u2014 user-journey</li> <li>toolcompose \u2014 user-journey</li> <li>toolops \u2014 user-journey</li> <li>toolprotocol \u2014 user-journey</li> <li>metatools-mcp \u2014 user-journey</li> <li>metatools\u2011mcp \u2014 user-journey</li> </ul>"},{"location":"architecture/user-journeys/#when-to-read-these","title":"When to read these","text":"<ul> <li>You want to understand how an agent discovers, inspects, and runs tools.</li> <li>You\u2019re validating the progressive disclosure path across components.</li> <li>You want examples that show how the pieces fit together end\u2011to\u2011end.</li> </ul>"},{"location":"architecture/why-go/","title":"Why Go","text":"<p>Go is a strong fit for this stack because it pairs high performance with a simple concurrency model and a clean interface story.</p>"},{"location":"architecture/why-go/#advantages-for-this-stack","title":"Advantages for this stack","text":""},{"location":"architecture/why-go/#compiled-fast-startup","title":"Compiled + fast startup","text":"<ul> <li>Small binaries and quick startup times are ideal for MCP servers</li> <li>Predictable performance for low-latency tool calls</li> </ul>"},{"location":"architecture/why-go/#concurrency-without-complexity","title":"Concurrency without complexity","text":"<ul> <li>Goroutines and channels make async tool execution straightforward</li> <li><code>context.Context</code> enables timeouts and cancellation across the stack</li> </ul>"},{"location":"architecture/why-go/#interface-first-extensibility","title":"Interface-first extensibility","text":"<ul> <li>Each layer (<code>Searcher</code>, <code>Runner</code>, <code>Engine</code>, <code>Backend</code>) is interface-driven</li> <li>You can plug in new languages, providers, or runtimes without redesigning</li> </ul>"},{"location":"architecture/why-go/#operational-simplicity","title":"Operational simplicity","text":"<ul> <li>Static binaries simplify deployment</li> <li>Works equally well in containers, VMs, or bare metal</li> </ul>"},{"location":"architecture/why-go/#summary","title":"Summary","text":"<p>Go lets you build a composable system that is fast, concurrent, and easy to extend. That is exactly what this stack needs.</p>"},{"location":"components/metatools-mcp/","title":"metatools-mcp","text":"<p>MCP server that exposes the tool stack via standardized MCP tools with a progressive-disclosure flow.</p>"},{"location":"components/metatools-mcp/#motivation","title":"Motivation","text":"<ul> <li>Provide a minimal, consistent MCP surface</li> <li>Keep discovery cheap and execution safe</li> <li>Enable pluggable search and optional code execution</li> </ul>"},{"location":"components/metatools-mcp/#core-responsibilities","title":"Core responsibilities","text":"<ul> <li>Expose <code>search_tools</code>, <code>list_namespaces</code></li> <li>Expose <code>describe_tool</code>, <code>list_tool_examples</code></li> <li>Expose <code>run_tool</code>, <code>run_chain</code></li> <li>Optionally expose <code>execute_code</code></li> <li>Use the official MCP Go SDK</li> </ul>"},{"location":"components/metatools-mcp/#transport-surface","title":"Transport surface","text":"<ul> <li><code>stdio</code> (default): local clients/Claude Desktop.</li> <li><code>streamable</code> (recommended HTTP): MCP spec 2025-03-26 with session management.</li> <li><code>sse</code> (deprecated): legacy web clients.</li> </ul> <p>See <code>metatools-mcp/docs/usage.md</code> for the full config/env matrix.</p>"},{"location":"components/metatools-mcp/#optional-runtime-integration","title":"Optional runtime integration","text":"<p><code>execute_code</code> is enabled with the <code>toolruntime</code> build tag and selects a runtime profile at startup:</p> <ul> <li><code>dev</code> profile (default): unsafe subprocess backend.</li> <li><code>standard</code> profile: Docker sandbox (set <code>METATOOLS_RUNTIME_PROFILE=standard</code>).</li> <li><code>METATOOLS_DOCKER_IMAGE</code> overrides the sandbox image name.</li> <li><code>METATOOLS_WASM_ENABLED=true</code> enables the WASM backend (wazero).</li> <li><code>METATOOLS_RUNTIME_BACKEND=wasm</code> selects WASM for the standard profile.</li> </ul>"},{"location":"components/metatools-mcp/#example","title":"Example","text":"<pre><code>srv, _ := server.New(cfg)\n_ = srv.Run(context.Background(), &amp;mcp.StdioTransport{})\n</code></pre>"},{"location":"components/metatools-mcp/#diagram","title":"Diagram","text":""},{"location":"components/metatools-mcp/#usability-notes","title":"Usability notes","text":"<ul> <li>Small tool surface reduces prompt complexity</li> <li>Schemas and examples are fetched on demand</li> </ul>"},{"location":"components/toolcompose/","title":"toolcompose","text":"<p>Composition layer providing filtered tool collections and skill-based workflows. This repository enables building higher-level abstractions over tools.</p>"},{"location":"components/toolcompose/#packages","title":"Packages","text":"Package Purpose <code>set</code> Filtered tool collections with predicates <code>skill</code> Skill-based workflow composition"},{"location":"components/toolcompose/#motivation","title":"Motivation","text":"<ul> <li>Group related tools into logical collections</li> <li>Enable skill-based workflows for common tasks</li> <li>Provide filtered views without duplicating tools</li> <li>Support composition patterns for complex operations</li> </ul>"},{"location":"components/toolcompose/#set-package","title":"set Package","text":"<p>The <code>set</code> package provides filtered tool collections using predicates.</p>"},{"location":"components/toolcompose/#core-responsibilities","title":"Core Responsibilities","text":"<ul> <li>Create filtered views of tool registries</li> <li>Apply namespace, tag, and custom predicates</li> <li>Chain filters for complex selections</li> <li>Export filtered sets in multiple formats</li> </ul>"},{"location":"components/toolcompose/#example","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolcompose/set\"\n  \"github.com/jonwraymond/toolfoundation/adapter\"\n)\n\ntools := []*adapter.CanonicalTool{\n  {Namespace: \"github\", Name: \"create_issue\", Tags: []string{\"issues\"}, InputSchema: &amp;adapter.JSONSchema{Type: \"object\"}},\n  {Namespace: \"github\", Name: \"add_labels\", Tags: []string{\"issues\"}, InputSchema: &amp;adapter.JSONSchema{Type: \"object\"}},\n}\n\nts, _ := set.NewBuilder(\"github-issues\").\n  FromTools(tools).\n  WithNamespace(\"github\").\n  WithTags([]string{\"issues\"}).\n  WithPolicy(set.DenyTags(\"danger\")).\n  Build()\n\nids := ts.IDs()\n</code></pre>"},{"location":"components/toolcompose/#built-in-predicates","title":"Built-in Predicates","text":"Predicate Description <code>NamespaceFilter(ns...)</code> Match any namespace <code>TagsAny(tags...)</code> Match tools with any tag <code>TagsAll(tags...)</code> Match tools with all tags <code>TagsNone(tags...)</code> Match tools with none of the tags <code>CategoryFilter(cats...)</code> Match any category <code>AllowIDs(ids...)</code> Allow only listed IDs <code>DenyIDs(ids...)</code> Exclude listed IDs"},{"location":"components/toolcompose/#skill-package","title":"skill Package","text":"<p>The <code>skill</code> package provides skill-based workflow composition.</p>"},{"location":"components/toolcompose/#features","title":"Features","text":"<ul> <li>Define declarative skills from tool steps</li> <li>Deterministic planning (sorted by step ID)</li> <li>Guardrails for max steps and allowed tool IDs</li> <li>Execution via a pluggable runner</li> </ul>"},{"location":"components/toolcompose/#example_1","title":"Example","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolcompose/skill\"\n  \"github.com/jonwraymond/toolexec/run\"\n)\n\nsk := skill.Skill{\n  Name: \"create-issue\",\n  Steps: []skill.Step{\n    {ID: \"create\", ToolID: \"github:create_issue\", Inputs: map[string]any{\"title\": \"Bug report\"}},\n    {ID: \"label\", ToolID: \"github:add_labels\", Inputs: map[string]any{\"labels\": []string{\"bug\"}}},\n  },\n}\n\nplan, _ := skill.NewPlanner().Plan(sk)\n\ntype runAdapter struct{ exec run.Runner }\nfunc (r runAdapter) Run(ctx context.Context, step skill.Step) (any, error) {\n  res, err := r.exec.Run(ctx, step.ToolID, step.Inputs)\n  if err != nil {\n    return nil, err\n  }\n  return res.Output, nil\n}\n\nrunner := run.NewRunner()\n_, err := skill.Execute(context.Background(), plan, runAdapter{exec: runner})\n</code></pre>"},{"location":"components/toolcompose/#skill-composition","title":"Skill Composition","text":"<pre><code>flowchart TB\n    Input[\"Skill Inputs\"] --&gt; Step1[\"Step 1: create_issue\"]\n    Step1 --&gt; Cond{\"Has labels?\"}\n    Cond --&gt;|Yes| Step2[\"Step 2: add_labels\"]\n    Cond --&gt;|No| Output\n    Step2 --&gt; Output[\"Skill Output\"]</code></pre>"},{"location":"components/toolcompose/#diagram","title":"Diagram","text":""},{"location":"components/toolcompose/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Deterministic sets: Toolset listing is sorted and repeatable</li> <li>Filter + policy: Filters reduce candidates, policies enforce access</li> <li>Declarative skills: Skills are pure definitions, not executors</li> <li>Pluggable runners: Execution integrates with any tool runner</li> </ol>"},{"location":"components/toolcompose/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Design notes</li> <li>User journey</li> </ul>"},{"location":"components/tooldiscovery/","title":"tooldiscovery","text":"<p>Discovery layer providing tool registry, search strategies, and progressive documentation. This repository enables efficient tool discovery through multiple search approaches.</p>"},{"location":"components/tooldiscovery/#packages","title":"Packages","text":"Package Purpose <code>index</code> Global registry and lookup by tool ID <code>search</code> BM25-based full-text search strategy <code>semantic</code> Embedding-based semantic search (optional) <code>tooldoc</code> Progressive documentation with detail levels <code>discovery</code> Unified facade combining index + search + semantic + tooldoc <code>registry</code> MCP server helper with local + backend execution"},{"location":"components/tooldiscovery/#motivation","title":"Motivation","text":"<ul> <li>Keep discovery fast and cheap (token-efficient)</li> <li>Decouple search quality from core registry</li> <li>Support multiple search strategies (lexical, BM25, semantic)</li> <li>Provide progressive disclosure of tool documentation</li> <li>Offer a unified facade for most consumers (<code>discovery</code>)</li> </ul>"},{"location":"components/tooldiscovery/#discovery-package","title":"discovery Package","text":"<p>The <code>discovery</code> package provides a simple API that composes index, search, semantic search, and documentation into one facade.</p>"},{"location":"components/tooldiscovery/#example","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/discovery\"\n\ndisc, _ := discovery.New(discovery.Options{})\n_ = disc.RegisterTool(tool, backend)\n\nresults, _ := disc.Search(context.Background(), \"create issue\", 5)\nfor _, r := range results {\n  fmt.Println(r.ScoreType, r.Summary.ID)\n}\n</code></pre>"},{"location":"components/tooldiscovery/#registry-package","title":"registry Package","text":"<p>The <code>registry</code> package is a high-level helper for building MCP servers that combines index, search, local handlers, and MCP backend aggregation.</p>"},{"location":"components/tooldiscovery/#example_1","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/registry\"\n\nreg := registry.New(registry.Config{\n  ServerInfo: registry.ServerInfo{Name: \"my-mcp\", Version: \"1.0.0\"},\n})\n\n_ = reg.RegisterLocalFunc(\n  \"echo\",\n  \"Echo input\",\n  map[string]any{\"type\": \"object\"},\n  func(ctx context.Context, args map[string]any) (any, error) { return args, nil },\n)\n\n_ = reg.Start(context.Background())\ndefer reg.Stop()\n</code></pre>"},{"location":"components/tooldiscovery/#index-package","title":"index Package","text":"<p>The <code>index</code> package provides the global registry and search layer for tools.</p>"},{"location":"components/tooldiscovery/#core-responsibilities","title":"Core Responsibilities","text":"<ul> <li>Register tools + backends</li> <li>Search by name/namespace/description/tags</li> <li>List namespaces</li> <li>Resolve tools by canonical ID</li> </ul>"},{"location":"components/tooldiscovery/#example_2","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/index\"\n\nidx := index.NewInMemoryIndex()\n\n_ = idx.RegisterTool(tool, backend)\n\nsummaries, _ := idx.Search(\"repo\", 5)\nfor _, s := range summaries {\n  fmt.Println(s.ID, s.ShortDescription)\n}\n</code></pre>"},{"location":"components/tooldiscovery/#search-package","title":"search Package","text":"<p>The <code>search</code> package provides BM25-based full-text search using Bleve.</p>"},{"location":"components/tooldiscovery/#features","title":"Features","text":"<ul> <li>BM25 ranking algorithm</li> <li>Field boosts (name: 4x, namespace: 2x, tags: 1x)</li> <li>Fuzzy matching support</li> <li>Pluggable into index via <code>SearchStrategy</code> interface</li> </ul>"},{"location":"components/tooldiscovery/#example_3","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/search\"\n\nsearcher, _ := search.NewBM25Searcher(search.DefaultConfig())\ndefer searcher.Close()\n\n// Index documents\nsearcher.Index(docs)\n\n// Search\nresults, _ := searcher.Search(\"create issue\", 10)\n</code></pre>"},{"location":"components/tooldiscovery/#semantic-package","title":"semantic Package","text":"<p>The <code>semantic</code> package provides embedding-based semantic search (optional).</p>"},{"location":"components/tooldiscovery/#features_1","title":"Features","text":"<ul> <li>Vector similarity search</li> <li>Configurable embedder interface</li> <li>Cosine similarity ranking</li> <li>Hybrid search support (combine with BM25)</li> </ul>"},{"location":"components/tooldiscovery/#tooldoc-package","title":"tooldoc Package","text":"<p>The <code>tooldoc</code> package provides progressive documentation with multiple detail levels.</p>"},{"location":"components/tooldiscovery/#detail-levels","title":"Detail Levels","text":"Level Contents Use Case <code>Summary</code> Name, namespace, short description Listing, filtering <code>Schema</code> Input/output JSON schemas Execution <code>Full</code> Everything including metadata Documentation"},{"location":"components/tooldiscovery/#example_4","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n\nstore := tooldoc.NewInMemoryStore()\n\n// Get progressive documentation\ndoc, _ := store.GetDoc(toolID, tooldoc.DetailSchema)\nfmt.Println(doc.Tool.InputSchema)\n</code></pre>"},{"location":"components/tooldiscovery/#schemas-and-contracts","title":"Schemas and Contracts","text":"<p>tooldiscovery defines data contracts for discovery payloads (summaries, documentation records, and results) and relies on toolfoundation for JSON Schema validation. See:</p> <ul> <li>schemas and contracts</li> </ul>"},{"location":"components/tooldiscovery/#diagram","title":"Diagram","text":""},{"location":"components/tooldiscovery/#search-strategy-layering","title":"Search Strategy Layering","text":"<pre><code>flowchart TB\n    Query[\"Search Query\"] --&gt; Index[\"index.Search()\"]\n    Index --&gt; Lexical[\"Lexical (default)\"]\n    Index --&gt; BM25[\"search.BM25Searcher\"]\n    Index --&gt; Semantic[\"semantic.Searcher\"]\n\n    Lexical --&gt; Results\n    BM25 --&gt; Results\n    Semantic --&gt; Results\n\n    Results[\"Ranked Results\"]</code></pre>"},{"location":"components/tooldiscovery/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Pluggable strategies: Search implementations are swappable</li> <li>Token efficiency: Summaries exclude schemas to reduce tokens</li> <li>Progressive disclosure: Request only the detail level needed</li> <li>Optional semantic: Vector search is opt-in (requires embeddings)</li> </ol>"},{"location":"components/tooldiscovery/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Design notes</li> <li>User journey</li> <li>Schemas and contracts</li> <li>Architecture</li> <li>Concurrency</li> <li>Registry</li> </ul>"},{"location":"components/toolexec/","title":"toolexec","text":"<p>Execution layer providing tool running, code orchestration, and runtime isolation. This repository handles the actual execution of tools across different backend types.</p>"},{"location":"components/toolexec/#packages","title":"Packages","text":"Package Purpose <code>exec</code> Unified facade combining discovery + execution <code>run</code> Core tool execution and chaining <code>code</code> Code-based tool orchestration <code>runtime</code> Sandbox and runtime isolation <code>backend</code> Backend registry and resolution"},{"location":"components/toolexec/#motivation","title":"Motivation","text":"<ul> <li>Execute tools with proper validation and error handling</li> <li>Support multiple backend types (local, provider, MCP server)</li> <li>Enable tool chaining and orchestration</li> <li>Provide secure runtime isolation</li> </ul>"},{"location":"components/toolexec/#run-package","title":"run Package","text":"<p>The <code>run</code> package provides the core tool execution engine.</p>"},{"location":"components/toolexec/#core-responsibilities","title":"Core Responsibilities","text":"<ul> <li>Validate input against tool schema</li> <li>Resolve backend and execute</li> <li>Normalize results</li> <li>Validate output against schema</li> </ul>"},{"location":"components/toolexec/#example","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/toolexec/run\"\n\nrunner := run.NewRunner(run.Config{\n  Index:    idx,\n  Backends: backends,\n})\n\nresult, err := runner.Run(ctx, \"github:create_issue\", map[string]any{\n  \"owner\": \"jonwraymond\",\n  \"repo\":  \"toolexec\",\n  \"title\": \"New issue\",\n})\n</code></pre>"},{"location":"components/toolexec/#execution-pipeline","title":"Execution Pipeline","text":"<pre><code>flowchart LR\n    Input[\"Tool ID + Args\"] --&gt; Validate1[\"Validate Input\"]\n    Validate1 --&gt; Resolve[\"Resolve Backend\"]\n    Resolve --&gt; Execute[\"Execute\"]\n    Execute --&gt; Normalize[\"Normalize Result\"]\n    Normalize --&gt; Validate2[\"Validate Output\"]\n    Validate2 --&gt; Result[\"RunResult\"]</code></pre>"},{"location":"components/toolexec/#exec-package","title":"exec Package","text":"<p>The <code>exec</code> facade composes discovery, documentation, and execution behind a single API for most callers.</p>"},{"location":"components/toolexec/#example_1","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolexec/exec\"\n  \"github.com/jonwraymond/tooldiscovery/index\"\n  \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n)\n\nidx := index.NewInMemoryIndex()\ndocs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\nexecutor, err := exec.New(exec.Options{Index: idx, Docs: docs})\nresult, err := executor.RunTool(ctx, \"math:add\", map[string]any{\"a\": 5, \"b\": 3})\n</code></pre>"},{"location":"components/toolexec/#code-package","title":"code Package","text":"<p>The <code>code</code> package provides code-based tool orchestration for complex workflows.</p>"},{"location":"components/toolexec/#features","title":"Features","text":"<ul> <li>Multi-tool orchestration</li> <li>Conditional execution</li> <li>Result aggregation</li> <li>Error handling with retries</li> </ul>"},{"location":"components/toolexec/#example_2","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/toolexec/code\"\n\nexecutor := code.NewExecutor(runner)\n\n// Execute a workflow\nresult, err := executor.Execute(ctx, `\n  issue := run(\"github:create_issue\", {title: \"Bug fix\"})\n  run(\"github:add_labels\", {issue: issue.number, labels: [\"bug\"]})\n`)\n</code></pre>"},{"location":"components/toolexec/#runtime-package","title":"runtime Package","text":"<p>The <code>runtime</code> package provides sandbox and runtime isolation for tool execution.</p>"},{"location":"components/toolexec/#supported-runtimes","title":"Supported Runtimes","text":"Runtime Isolation Use Case <code>local</code> Process Trusted tools <code>docker</code> Container Untrusted code <code>wasm</code> Sandbox Browser/edge"},{"location":"components/toolexec/#example_3","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n  \"github.com/jonwraymond/toolexec/runtime\"\n  \"github.com/jonwraymond/toolexec/runtime/backend/unsafe\"\n  \"github.com/jonwraymond/toolexec/runtime/gateway/direct\"\n)\n\ndocs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\ngateway := direct.New(direct.Config{Index: idx, Docs: docs, Runner: runner})\n\nrt := runtime.NewDefaultRuntime(runtime.RuntimeConfig{\n  Backends: map[runtime.SecurityProfile]runtime.Backend{\n    runtime.ProfileDev: unsafe.New(unsafe.Config{RequireOptIn: true}),\n  },\n  DefaultProfile: runtime.ProfileDev,\n})\n\nresult, err := rt.Execute(ctx, runtime.ExecuteRequest{\n  Language: \"go\",\n  Code:     `__out = \"ok\"`,\n  Profile:  runtime.ProfileDev,\n  Gateway:  gateway,\n  Metadata: map[string]any{\"unsafeOptIn\": true},\n})\n</code></pre>"},{"location":"components/toolexec/#backend-package","title":"backend Package","text":"<p>The <code>backend</code> package provides backend registry and resolution.</p>"},{"location":"components/toolexec/#backend-types","title":"Backend Types","text":"Type Description <code>local</code> In-process handler function <code>provider</code> External tool provider <code>mcp</code> Remote MCP server"},{"location":"components/toolexec/#example_4","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/toolexec/backend\"\n\nregistry := backend.NewRegistry()\n\n// Register a local backend\nregistry.Register(\"calculator\", backend.Local(func(ctx context.Context, args any) (any, error) {\n  // Implementation\n}))\n\n// Resolve backend for tool\nb, err := registry.Resolve(tool.Backend)\n</code></pre>"},{"location":"components/toolexec/#schemas-and-contracts","title":"Schemas and Contracts","text":"<p>toolexec enforces the canonical tool schema from toolfoundation. It does not define new input/output schemas; instead it validates against each <code>model.Tool</code> schema at execution time.</p> <p>Key guarantees:</p> <ul> <li>InputSchema is required for all tools.</li> <li>OutputSchema is optional; output validation runs only when present.</li> <li>Execution results are normalized into <code>run.RunResult</code> and <code>exec.Result</code>.</li> <li>Streaming uses <code>run.StreamEvent</code> with <code>progress</code>, <code>chunk</code>, <code>done</code>, <code>error</code>.</li> </ul> <p>See the full schema and contract details in: - toolexec schemas - toolfoundation schemas</p>"},{"location":"components/toolexec/#examples","title":"Examples","text":"<p>Runnable examples cover execution, chaining, discovery, and runtimes:</p> <pre><code>go run ./examples/basic\ngo run ./examples/chain\ngo run ./examples/discovery\ngo run ./examples/streaming\ngo run ./examples/runtime\ngo run ./examples/full\n</code></pre>"},{"location":"components/toolexec/#diagram","title":"Diagram","text":""},{"location":"components/toolexec/#architecture-plan-summary","title":"Architecture Plan Summary","text":"<p>The <code>toolexec</code> architecture plan focused on delivering a unified execution surface while keeping each layer isolated and testable:</p> <ul> <li>Facade-first API: <code>exec.Exec</code> provides the primary entry point, composing   discovery, documentation, and execution behind a single interface.</li> <li>Deterministic execution: <code>run.DefaultRunner</code> enforces a strict pipeline   (resolve \u2192 validate \u2192 execute \u2192 normalize \u2192 validate) with structured results.</li> <li>Runtime isolation: the <code>runtime</code> package allows sandboxed execution for   code workflows without coupling to tool execution paths.</li> <li>Schema contracts: execution never invents schemas; it validates against   <code>toolfoundation</code> and surfaces structured results for downstream chaining.</li> </ul> <p>See the full plan for rationale and milestones: Architecture plan.</p>"},{"location":"components/toolexec/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Schema validation: Both input and output are validated</li> <li>Backend abstraction: Execution is decoupled from backend type</li> <li>Unified facade: Most callers use exec instead of wiring packages</li> <li>Pluggable runtimes: Security profiles are configurable</li> <li>Chaining support: Tools can call other tools</li> </ol>"},{"location":"components/toolexec/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Schemas and contracts</li> <li>Architecture</li> <li>Design notes</li> <li>User journey</li> <li>Examples</li> <li>Architecture plan</li> </ul>"},{"location":"components/toolfoundation/","title":"toolfoundation","text":"<p>Foundational layer providing canonical schema definitions and protocol-agnostic format conversion. This repository contains the core data types that all other ApertureStack components depend on.</p>"},{"location":"components/toolfoundation/#packages","title":"Packages","text":"Package Purpose <code>model</code> Canonical MCP tool schema definitions, validation, backend bindings <code>adapter</code> Protocol-agnostic tool format conversion (MCP, OpenAI, Anthropic) <code>version</code> Semantic version parsing, constraints, compatibility matrices"},{"location":"components/toolfoundation/#motivation","title":"Motivation","text":"<ul> <li>Standardize tool definitions across the stack</li> <li>Align directly with MCP via the official Go SDK</li> <li>Enable multi-provider support without changing the MCP surface</li> <li>Keep schemas portable and validation deterministic</li> </ul>"},{"location":"components/toolfoundation/#model-package","title":"model Package","text":"<p>The <code>model</code> package provides the canonical schema definitions for all tools.</p>"},{"location":"components/toolfoundation/#core-types","title":"Core Types","text":"<ul> <li><code>Tool</code> (embeds MCP <code>mcp.Tool</code>, adds <code>Namespace</code>, <code>Version</code>, <code>Tags</code>)</li> <li><code>ToolBackend</code> (execution binding: mcp, provider, local)</li> <li><code>SchemaValidator</code> (input/output validation)</li> </ul>"},{"location":"components/toolfoundation/#example","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolfoundation/model\"\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\ntool := model.Tool{\n  Namespace: \"github\",\n  Tool: mcp.Tool{\n    Name:        \"get_repo\",\n    Description: \"Fetch repository metadata\",\n    InputSchema: map[string]any{\n      \"type\": \"object\",\n      \"properties\": map[string]any{\n        \"owner\": {\"type\": \"string\"},\n        \"repo\":  {\"type\": \"string\"},\n      },\n      \"required\": []string{\"owner\", \"repo\"},\n    },\n  },\n  Tags: model.NormalizeTags([]string{\"GitHub\", \"repos\"}),\n}\n\n_ = tool.Validate()\n</code></pre>"},{"location":"components/toolfoundation/#schema-contracts","title":"Schema contracts","text":"<p>Canonical schema rules and JSON Schema requirements are documented here:</p> <ul> <li>tool schemas</li> </ul>"},{"location":"components/toolfoundation/#adapter-package","title":"adapter Package","text":"<p>The <code>adapter</code> package enables bidirectional transformation between MCP, OpenAI, and Anthropic tool definitions through a canonical intermediate representation.</p>"},{"location":"components/toolfoundation/#core-types_1","title":"Core Types","text":"Type Purpose <code>CanonicalTool</code> Protocol-agnostic intermediate representation <code>JSONSchema</code> Superset of all supported schema features <code>Adapter</code> Interface for format-specific converters <code>AdapterRegistry</code> Thread-safe adapter management and conversion <code>FeatureLossWarning</code> Indicates unsupported features in target format"},{"location":"components/toolfoundation/#example_1","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolfoundation/adapter\"\n)\n\n// Set up registry with all adapters\nregistry := adapter.NewRegistry()\nregistry.Register(adapter.NewMCPAdapter())\nregistry.Register(adapter.NewOpenAIAdapter())\nregistry.Register(adapter.NewAnthropicAdapter())\n\n// Convert MCP tool to OpenAI format\nresult, err := registry.Convert(mcpTool, \"mcp\", \"openai\")\nif err != nil {\n  log.Fatal(err)\n}\n\n// Check for feature loss warnings\nfor _, w := range result.Warnings {\n  log.Printf(\"Warning: %s\", w)\n}\n</code></pre>"},{"location":"components/toolfoundation/#feature-support-matrix","title":"Feature Support Matrix","text":"Feature MCP OpenAI Anthropic <code>$ref/$defs</code> Yes No No <code>anyOf/oneOf/allOf</code> Yes No Yes <code>pattern</code> Yes Yes* Yes <code>enum/const</code> Yes Yes Yes"},{"location":"components/toolfoundation/#diagram","title":"Diagram","text":""},{"location":"components/toolfoundation/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>MCP alignment: Tool embeds official MCP SDK types</li> <li>Pure transforms: Adapter conversions have no I/O or side effects</li> <li>Loss visibility: Feature loss is tracked as warnings, not errors</li> <li>Minimal deps: Foundation has minimal external dependencies</li> <li>Explicit versioning: Compatibility rules are defined via <code>version.Matrix</code></li> </ol>"},{"location":"components/toolfoundation/#version-package","title":"version Package","text":"<p>The <code>version</code> package provides SemVer parsing, constraints, and compatibility negotiation across stack components.</p> <pre><code>import \"github.com/jonwraymond/toolfoundation/version\"\n\nbase := version.MustParse(\"v1.0.0\")\ncurrent := version.MustParse(\"v1.2.3\")\n\nif current.Compatible(base) {\n  fmt.Println(\"compatible\")\n}\n</code></pre>"},{"location":"components/toolfoundation/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Tool schemas</li> <li>Design notes</li> <li>User journey</li> </ul>"},{"location":"components/toolops/","title":"toolops","text":"<p>Operations layer providing observability, caching, authentication, health checks, and resilience patterns. This repository contains cross-cutting concerns for production deployments.</p>"},{"location":"components/toolops/#packages","title":"Packages","text":"Package Purpose <code>observe</code> OpenTelemetry-based tracing, metrics, and logging <code>cache</code> Deterministic caching with pluggable backends <code>auth</code> Authentication and authorization middleware <code>health</code> Health check endpoints and probes <code>resilience</code> Circuit breakers, retries, and rate limiting"},{"location":"components/toolops/#motivation","title":"Motivation","text":"<ul> <li>Provide production-ready observability out of the box</li> <li>Enable caching to reduce execution latency and costs</li> <li>Support authentication across different providers</li> <li>Expose health checks for orchestration platforms</li> <li>Handle transient failures gracefully</li> </ul>"},{"location":"components/toolops/#observe-package","title":"observe Package","text":"<p>The <code>observe</code> package provides OpenTelemetry-based observability middleware.</p>"},{"location":"components/toolops/#features","title":"Features","text":"<ul> <li>Distributed tracing with span attributes</li> <li>Prometheus-compatible metrics</li> <li>Structured logging with tool context</li> <li>OTLP export support</li> </ul>"},{"location":"components/toolops/#example","title":"Example","text":"<pre><code>import (\n  \"context\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolops/observe\"\n)\n\nobs, err := observe.NewObserver(ctx, observe.Config{\n  ServiceName: \"metatools-mcp\",\n  Tracing:     observe.TracingConfig{Enabled: true, Exporter: \"otlp\"},\n  Metrics:     observe.MetricsConfig{Enabled: true, Exporter: \"prometheus\"},\n  Logging:     observe.LoggingConfig{Enabled: true, Level: \"info\"},\n})\nif err != nil {\n  log.Fatal(err)\n}\ndefer obs.Shutdown(ctx)\n\nmw, _ := observe.MiddlewareFromObserver(obs)\nwrapped := mw.Wrap(func(ctx context.Context, tool observe.ToolMeta, input any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n\n_, _ = wrapped(ctx, observe.ToolMeta{Name: toolID}, args)\n</code></pre>"},{"location":"components/toolops/#metrics-emitted","title":"Metrics Emitted","text":"Metric Type Description <code>tool.exec.total</code> Counter Total tool executions <code>tool.exec.duration</code> Histogram Execution duration (ms) <code>tool.exec.errors</code> Counter Failed executions"},{"location":"components/toolops/#cache-package","title":"cache Package","text":"<p>The <code>cache</code> package provides deterministic caching with pluggable backends.</p>"},{"location":"components/toolops/#features_1","title":"Features","text":"<ul> <li>Content-addressable caching (hash of tool + args)</li> <li>TTL and size-based eviction</li> <li>Pluggable backends (memory, Redis, file)</li> <li>Cache invalidation patterns</li> </ul>"},{"location":"components/toolops/#example_1","title":"Example","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/cache\"\n)\n\npolicy := cache.DefaultPolicy()\nc := cache.NewMemoryCache(policy)\nkeyer := cache.NewDefaultKeyer()\nmw := cache.NewCacheMiddleware(c, keyer, policy, nil)\n\nresult, err := mw.Execute(ctx, toolID, args, []string{\"cacheable\"}, func(ctx context.Context, toolID string, input any) ([]byte, error) {\n  return []byte(\"{\\\"ok\\\":true}\"), nil\n})\n</code></pre>"},{"location":"components/toolops/#auth-package","title":"auth Package","text":"<p>The <code>auth</code> package provides authentication and authorization middleware.</p>"},{"location":"components/toolops/#features_2","title":"Features","text":"<ul> <li>Multiple auth providers (API keys, JWT, OAuth)</li> <li>Per-namespace authorization rules</li> <li>Rate limiting per identity</li> <li>Audit logging</li> </ul>"},{"location":"components/toolops/#example_2","title":"Example","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/auth\"\n)\n\nauthenticator := auth.NewJWTAuthenticator(auth.JWTConfig{Issuer: \"issuer\"})\nauthorizer := auth.NewSimpleRBACAuthorizer(auth.RBACConfig{\n  DefaultRole: \"reader\",\n  Roles: map[string]auth.RoleConfig{\n    \"reader\": {AllowedTools: []string{\"github:*\"}, AllowedActions: []string{\"list\"}},\n  },\n})\n\nreq := &amp;auth.AuthRequest{Headers: map[string][]string{\"Authorization\": {\"Bearer token\"}}}\nresult, _ := authenticator.Authenticate(ctx, req)\nif result != nil &amp;&amp; result.Identity != nil {\n  _ = authorizer.Authorize(ctx, &amp;auth.AuthzRequest{\n    Subject:  result.Identity,\n    Resource: \"tool:github:list_issues\",\n    Action:   \"list\",\n  })\n}\n</code></pre>"},{"location":"components/toolops/#health-package","title":"health Package","text":"<p>The <code>health</code> package provides health check endpoints and probes.</p>"},{"location":"components/toolops/#features_3","title":"Features","text":"<ul> <li>Kubernetes-compatible probes (liveness, readiness)</li> <li>Dependency health checks</li> <li>Graceful degradation reporting</li> </ul>"},{"location":"components/toolops/#example_3","title":"Example","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/health\"\n)\n\nagg := health.NewAggregator()\nagg.Register(\"memory\", health.NewMemoryChecker(health.MemoryCheckerConfig{\n  WarningThreshold:  0.80,\n  CriticalThreshold: 0.95,\n}))\n\nresults := agg.CheckAll(ctx)\noverall := agg.OverallStatus(results)\n_ = overall\n</code></pre>"},{"location":"components/toolops/#resilience-package","title":"resilience Package","text":"<p>The <code>resilience</code> package provides circuit breakers, retries, and rate limiting.</p>"},{"location":"components/toolops/#features_4","title":"Features","text":"<ul> <li>Circuit breaker with configurable thresholds</li> <li>Exponential backoff retries</li> <li>Token bucket rate limiting</li> <li>Bulkhead isolation</li> </ul>"},{"location":"components/toolops/#example_4","title":"Example","text":"<pre><code>import (\n  \"context\"\n  \"time\"\n\n  \"github.com/jonwraymond/toolops/resilience\"\n)\n\nexecutor := resilience.NewExecutor(\n  resilience.WithCircuitBreaker(resilience.NewCircuitBreaker(resilience.CircuitBreakerConfig{\n    MaxFailures:  5,\n    ResetTimeout: 30 * time.Second,\n  })),\n  resilience.WithRetry(resilience.NewRetry(resilience.RetryConfig{\n    MaxAttempts: 3,\n  })),\n  resilience.WithTimeout(5*time.Second),\n)\n\n_ = executor.Execute(ctx, func(ctx context.Context) error {\n  return nil\n})\n</code></pre>"},{"location":"components/toolops/#diagram","title":"Diagram","text":""},{"location":"components/toolops/#middleware-chain","title":"Middleware Chain","text":"<pre><code>flowchart LR\n    Request --&gt; Auth[\"auth\"]\n    Auth --&gt; RateLimit[\"resilience\"]\n    RateLimit --&gt; Cache[\"cache\"]\n    Cache --&gt; Observe[\"observe\"]\n    Observe --&gt; Runner[\"toolexec/run\"]\n    Runner --&gt; Response</code></pre>"},{"location":"components/toolops/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Middleware pattern: Observe/cache wrap execution functions</li> <li>Composable: Patterns stack in a deterministic order</li> <li>Explicit wiring: No implicit instrumentation or caching</li> <li>Standards-based: OpenTelemetry, Prometheus, K8s probes</li> </ol>"},{"location":"components/toolops/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Design notes</li> <li>User journey</li> </ul>"},{"location":"components/toolprotocol/","title":"toolprotocol","text":"<p>Protocol layer providing transport, wire format, and protocol primitives for MCP, A2A, and ACP integrations.</p>"},{"location":"components/toolprotocol/#packages","title":"Packages","text":"Package Purpose <code>content</code> Unified content parts (text, image, audio, file, resource) <code>discover</code> Service discovery + capability negotiation <code>transport</code> Transport interfaces (stdio, SSE, streamable HTTP) <code>wire</code> Protocol wire encoding (MCP, A2A, ACP) <code>stream</code> Streaming events for progress/partial/complete <code>session</code> Client session store + context helpers <code>task</code> Long-running task lifecycle + subscriptions <code>resource</code> MCP resources registry + subscriptions <code>prompt</code> Prompt templates + registry <code>elicit</code> User input elicitation (text/confirm/choice/form)"},{"location":"components/toolprotocol/#contracts-highlights","title":"Contracts (Highlights)","text":"<ul> <li>Transport: concurrent-safe; <code>Serve</code> honors context; <code>Close</code> is idempotent.</li> <li>Wire: deterministic encode/decode; capabilities reflect real support.</li> <li>Content: immutable content parts; MIME type always matches payload.</li> <li>Stream: event order preserved; <code>Done</code> closes on <code>Close</code>.</li> </ul>"},{"location":"components/toolprotocol/#example-wire-transport","title":"Example: Wire + Transport","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/transport\"\n  \"github.com/jonwraymond/toolprotocol/wire\"\n)\n\ntype server struct{}\n\nfunc (s *server) ServeTransport(ctx context.Context, t transport.Transport) error {\n  return nil\n}\n\nctx := context.Background()\ncodec := wire.NewMCP()\npayload, _ := codec.EncodeRequest(ctx, &amp;wire.Request{\n  ID:     \"1\",\n  Method: \"tools/list\",\n})\n\ntp, _ := transport.New(\"stdio\", nil)\n_ = payload\n_ = tp.Serve(ctx, &amp;server{})\n</code></pre>"},{"location":"components/toolprotocol/#diagram","title":"Diagram","text":""},{"location":"components/toolprotocol/#protocol-flow","title":"Protocol Flow","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Transport\n    participant Wire\n    participant Handler\n\n    Client-&gt;&gt;Transport: Connect\n    Transport-&gt;&gt;Wire: Decode request\n    Wire-&gt;&gt;Handler: Route to handler\n\n    Handler--&gt;&gt;Wire: Response\n    Wire--&gt;&gt;Transport: Encode response\n    Transport--&gt;&gt;Client: Send</code></pre>"},{"location":"components/toolprotocol/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Architecture</li> <li>Schemas and contracts</li> <li>Examples</li> <li>Design notes</li> <li>User journey</li> </ul>"},{"location":"operations/ci-and-versioning/","title":"CI and Versioning","text":""},{"location":"operations/ci-and-versioning/#ci-checks","title":"CI checks","text":"<p>Each repo runs CI for:</p> <ul> <li>go vet</li> <li>go test</li> <li>lint + security (golangci-lint + gosec)</li> </ul>"},{"location":"operations/ci-and-versioning/#go-module-privacy-fast-tag-uptake","title":"Go module privacy (fast tag uptake)","text":"<p>CI sets:</p> <ul> <li><code>GOPRIVATE=github.com/jonwraymond/*</code></li> <li><code>GONOSUMDB=github.com/jonwraymond/*</code></li> </ul> <p>This bypasses the public proxy/sumdb for the org\u2019s modules so newly\u2011pushed tags are immediately usable in CI and local workflows.</p>"},{"location":"operations/ci-and-versioning/#version-alignment","title":"Version alignment","text":"<ul> <li><code>ai-tools-stack/go.mod</code> is the source of truth.</li> <li><code>VERSIONS.md</code> is generated in each repo and updated via:</li> </ul> <pre><code>scripts/update-version-matrix.sh --apply\n</code></pre>"},{"location":"operations/ci-and-versioning/#new-modules-example-toolprotocol","title":"New modules (example: toolprotocol)","text":"<p>When a new module is added to the stack (for example <code>toolprotocol</code>), the propagation steps are:</p> <p>1) Tag the new module (<code>vX.Y.Z</code>). 2) Add it to <code>ai-tools-stack/go.mod</code> at the tagged version. 3) Run <code>scripts/update-version-matrix.sh --apply</code> to sync <code>VERSIONS.md</code> across repos. 4) Update <code>mkdocs.yml</code> to include the new module in Components and Library Docs.</p>"},{"location":"operations/ci-and-versioning/#dependency-bumping","title":"Dependency bumping","text":"<p>Use the DAG-aware bump tool:</p> <pre><code>scripts/bump-dep.sh --dep toolexec --latest --apply\n</code></pre> <p>This updates all downstream repos and ai-tools-stack in order.</p>"},{"location":"operations/ci-and-versioning/#docs-automation","title":"Docs automation","text":"<p>The unified docs site is built from this repo using MkDocs + the multirepo plugin. GitHub Actions runs on push to main and nightly (scheduled) to pull fresh docs from the tool repos.</p> <p>Versioned docs are published with <code>mike</code>:</p> <ul> <li><code>latest</code> alias is deployed from <code>main</code></li> <li>tag builds deploy versioned docs (for example, <code>v0.1.8</code>) and set <code>stable</code></li> <li>the version selector appears in the site header once at least one tag build exists</li> </ul> <p>Local preview:</p> <pre><code>pip install -r requirements.txt\n./scripts/prepare-mkdocs-multirepo.sh\nmkdocs serve\n</code></pre> <p>Versioned preview:</p> <pre><code>pip install -r requirements.txt\n./scripts/prepare-mkdocs-multirepo.sh\nmike serve\n</code></pre>"},{"location":"operations/consolidation-validation-report/","title":"Consolidation Validation Report","text":"<p>Date: 2026-02-01 PRDs: PRD-190, PRD-191, PRD-192 Validator: Codex (local)</p>"},{"location":"operations/consolidation-validation-report/#executive-summary","title":"Executive Summary","text":"<p>The ApertureStack consolidation is complete. All 13 standalone repositories are archived with migration guidance. The stack is consolidated into 6 libraries + 2 application repos with updated documentation and diagrams.</p>"},{"location":"operations/consolidation-validation-report/#repository-status-local-validation","title":"Repository Status (Local Validation)","text":""},{"location":"operations/consolidation-validation-report/#consolidated-libraries","title":"Consolidated Libraries","text":"Repository Build Tests Status toolfoundation \u2713 \u2713 OK tooldiscovery \u2713 \u2713 OK toolexec \u2713 \u2713 OK toolcompose \u2713 \u2713 OK toolops \u2713 \u2713 OK toolprotocol \u2713 \u2713 OK <p>Notes: Tests run with <code>GOWORK=off</code> to avoid the global <code>go.work</code> at <code>/Users/jraymond/Documents/Projects/go.work</code>.</p>"},{"location":"operations/consolidation-validation-report/#application-layer","title":"Application Layer","text":"Repository Build Tests CLI Status metatools-mcp \u2713 \u2713 \u2713 (<code>./metatools version</code>) OK ai-tools-stack \u2713 \u2713 N/A OK"},{"location":"operations/consolidation-validation-report/#ci-status-latest-known","title":"CI Status (Latest Known)","text":"Repository CI Notes toolprotocol \u2713 success Last run 2026-02-01 metatools-mcp \u2713 success Last run 2026-02-01 ai-tools-stack \u2713 success Docs workflow green (2026-02-01)"},{"location":"operations/consolidation-validation-report/#archive-status","title":"Archive Status","text":"<p>All 13 standalone repositories are archived and verified:</p> Repository Migrated To Archived README Deprecated MIGRATION.md toolmodel toolfoundation/model \u2713 \u2713 \u2713 tooladapter toolfoundation/adapter \u2713 \u2713 \u2713 toolindex tooldiscovery/index \u2713 \u2713 \u2713 toolsearch tooldiscovery/search \u2713 \u2713 \u2713 toolsemantic tooldiscovery/semantic \u2713 \u2713 \u2713 tooldocs tooldiscovery/tooldoc \u2713 \u2713 \u2713 toolrun toolexec/run \u2713 \u2713 \u2713 toolruntime toolexec/runtime \u2713 \u2713 \u2713 toolcode toolexec/code \u2713 \u2713 \u2713 toolset toolcompose/set \u2713 \u2713 \u2713 toolskill toolcompose/skill \u2713 \u2713 \u2713 toolobserve toolops/observe \u2713 \u2713 \u2713 toolcache toolops/cache \u2713 \u2713 \u2713"},{"location":"operations/consolidation-validation-report/#submodule-status","title":"Submodule Status","text":"<p>Root repo uses consolidated submodules:</p> <pre><code>ai-tools-stack\nmetatools-mcp\ntoolcompose\ntooldiscovery\ntoolexec\ntoolfoundation\ntoolops\ntoolprotocol\n</code></pre>"},{"location":"operations/consolidation-validation-report/#documentation-status","title":"Documentation Status","text":"<ul> <li>D2 diagrams rendered to SVG for ai-tools-stack and metatools-mcp.</li> <li>MkDocs build validated in CI (Docs workflow).</li> <li>Documentation structure and navigation aligned to consolidated repos.</li> </ul>"},{"location":"operations/consolidation-validation-report/#conclusion","title":"Conclusion","text":"<p>Gate G7: PASSED</p>"},{"location":"operations/migration-guide/","title":"Migration Guide: Consolidated Repositories (v0.3.0)","text":"<p>This guide helps you migrate from the previous 14 standalone repositories to the new 6 consolidated repositories introduced in v0.3.0.</p>"},{"location":"operations/migration-guide/#overview-of-changes","title":"Overview of Changes","text":"<p>The ApertureStack tool framework has been reorganized to group related packages by architectural concern:</p> Old Repository New Location Import Path Change <code>toolmodel</code> <code>toolfoundation/model</code> <code>github.com/jonwraymond/toolfoundation/model</code> <code>tooladapter</code> <code>toolfoundation/adapter</code> <code>github.com/jonwraymond/toolfoundation/adapter</code> <code>toolindex</code> <code>tooldiscovery/index</code> <code>github.com/jonwraymond/tooldiscovery/index</code> <code>tooldocs</code> <code>tooldiscovery/tooldoc</code> <code>github.com/jonwraymond/tooldiscovery/tooldoc</code> <code>toolsearch</code> <code>tooldiscovery/search</code> <code>github.com/jonwraymond/tooldiscovery/search</code> <code>toolsemantic</code> <code>tooldiscovery/semantic</code> <code>github.com/jonwraymond/tooldiscovery/semantic</code> <code>toolrun</code> <code>toolexec/run</code> <code>github.com/jonwraymond/toolexec/run</code> <code>toolcode</code> <code>toolexec/code</code> <code>github.com/jonwraymond/toolexec/code</code> <code>toolruntime</code> <code>toolexec/runtime</code> <code>github.com/jonwraymond/toolexec/runtime</code> <code>toolset</code> <code>toolcompose/set</code> <code>github.com/jonwraymond/toolcompose/set</code> <code>toolskill</code> <code>toolcompose/skill</code> <code>github.com/jonwraymond/toolcompose/skill</code> <code>toolobserve</code> <code>toolops/observe</code> <code>github.com/jonwraymond/toolops/observe</code> <code>toolcache</code> <code>toolops/cache</code> <code>github.com/jonwraymond/toolops/cache</code>"},{"location":"operations/migration-guide/#migration-steps","title":"Migration Steps","text":""},{"location":"operations/migration-guide/#1-update-gomod-dependencies","title":"1. Update go.mod Dependencies","text":"<p>Replace old standalone dependencies with consolidated ones:</p> <pre><code># Remove old dependencies\ngo mod edit -droprequire github.com/jonwraymond/toolmodel\ngo mod edit -droprequire github.com/jonwraymond/tooladapter\ngo mod edit -droprequire github.com/jonwraymond/toolindex\n# ... repeat for all old repos\n\n# Add consolidated dependencies\ngo get github.com/jonwraymond/toolfoundation@latest\ngo get github.com/jonwraymond/tooldiscovery@latest\ngo get github.com/jonwraymond/toolexec@latest\ngo get github.com/jonwraymond/toolcompose@latest\ngo get github.com/jonwraymond/toolops@latest\ngo get github.com/jonwraymond/toolprotocol@latest\n</code></pre>"},{"location":"operations/migration-guide/#2-update-import-statements","title":"2. Update Import Statements","text":"<p>Use your editor's find-and-replace or a tool like <code>gofmt</code> to update imports:</p> <pre><code>// Before\nimport (\n    \"github.com/jonwraymond/toolmodel\"\n    \"github.com/jonwraymond/toolindex\"\n    \"github.com/jonwraymond/toolrun\"\n)\n\n// After\nimport (\n    \"github.com/jonwraymond/toolfoundation/model\"\n    \"github.com/jonwraymond/tooldiscovery/index\"\n    \"github.com/jonwraymond/toolexec/run\"\n)\n</code></pre>"},{"location":"operations/migration-guide/#3-update-package-aliases-if-needed","title":"3. Update Package Aliases (if needed)","text":"<p>If you used short aliases, update them:</p> <pre><code>// Before\nimport toolmodel \"github.com/jonwraymond/toolmodel\"\n\n// After (same alias, new path)\nimport toolmodel \"github.com/jonwraymond/toolfoundation/model\"\n</code></pre>"},{"location":"operations/migration-guide/#4-run-tests","title":"4. Run Tests","text":"<p>After updating imports, run your test suite to verify everything works:</p> <pre><code>go mod tidy\ngo test ./...\n</code></pre>"},{"location":"operations/migration-guide/#api-compatibility","title":"API Compatibility","text":"<p>All public APIs remain unchanged. The consolidation only affects import paths, not function signatures or types. Your existing code should work after updating the import statements.</p>"},{"location":"operations/migration-guide/#benefits-of-consolidation","title":"Benefits of Consolidation","text":"<ol> <li>Simpler dependency management - 6 repos instead of 14</li> <li>Clearer architecture - Packages grouped by concern</li> <li>Easier versioning - Related packages released together</li> <li>Better discoverability - Find related functionality in one place</li> </ol>"},{"location":"operations/migration-guide/#questions","title":"Questions?","text":"<p>If you encounter issues during migration, please open an issue on the ai-tools-stack repository.</p>"},{"location":"operations/stack-changelog/","title":"Stack Changelog","text":"<p>Aggregated highlights from each repo\u2019s latest release. For full history, use each repo\u2019s CHANGELOG.</p>"},{"location":"operations/stack-changelog/#version-matrix-current-tags","title":"Version matrix (current tags)","text":""},{"location":"operations/stack-changelog/#version-compatibility-current-tags","title":"Version compatibility (current tags)","text":"<ul> <li><code>toolfoundation</code>: <code>v0.2.0</code></li> <li><code>tooldiscovery</code>: <code>v0.2.2</code></li> <li><code>toolexec</code>: <code>v0.1.4</code></li> <li><code>toolops</code>: <code>v0.1.4</code></li> <li><code>toolprotocol</code>: <code>v0.1.5</code></li> <li><code>metatools-mcp</code>: <code>v0.5.2</code></li> </ul> <p>Generated from <code>ai-tools-stack/go.mod</code>.</p>"},{"location":"operations/stack-changelog/#repo-changelogs","title":"Repo changelogs","text":"<ul> <li>ai-tools-stack</li> <li>toolfoundation</li> <li>tooldiscovery</li> <li>toolexec</li> <li>toolcompose</li> <li>toolops</li> <li>toolprotocol</li> <li>metatools-mcp</li> </ul>"},{"location":"operations/stack-changelog/#notes","title":"Notes","text":"<ul> <li>The stack was consolidated from 13 standalone repos into 6 library repos.</li> <li>Legacy repo changelogs remain available in their archived repositories.</li> </ul> <p>Generated by scripts/generate-combined-changelog.sh</p>"},{"location":"library-docs-from-repos/toolfoundation/","title":"toolfoundation","text":"<p>Foundation layer providing canonical schema definitions and protocol-agnostic format conversion for the ApertureStack tool framework.</p>"},{"location":"library-docs-from-repos/toolfoundation/#packages","title":"Packages","text":"Package Purpose <code>model</code> Canonical MCP tool schema definitions, validation, backend bindings <code>adapter</code> Protocol-agnostic tool format conversion (MCP, OpenAI, Anthropic) <code>version</code> Semantic version parsing, constraints, compatibility matrices"},{"location":"library-docs-from-repos/toolfoundation/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolfoundation@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/#quick-start","title":"Quick Start","text":""},{"location":"library-docs-from-repos/toolfoundation/#defining-a-tool-model-package","title":"Defining a Tool (model package)","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolfoundation/model\"\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\ntool := model.Tool{\n  Namespace: \"github\",\n  Tool: mcp.Tool{\n    Name:        \"get_repo\",\n    Description: \"Fetch repository metadata\",\n    InputSchema: map[string]any{\n      \"type\": \"object\",\n      \"properties\": map[string]any{\n        \"owner\": map[string]any{\"type\": \"string\"},\n        \"repo\":  map[string]any{\"type\": \"string\"},\n      },\n      \"required\": []string{\"owner\", \"repo\"},\n    },\n  },\n  Tags: model.NormalizeTags([]string{\"GitHub\", \"repos\"}),\n}\n\nif err := tool.Validate(); err != nil {\n  log.Fatal(err)\n}\n\nfmt.Println(tool.ToolID()) // \"github:get_repo\"\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/#converting-between-formats-adapter-package","title":"Converting Between Formats (adapter package)","text":"<pre><code>import \"github.com/jonwraymond/toolfoundation/adapter\"\n\n// Use the default registry with all built-in adapters\nregistry := adapter.DefaultRegistry()\n\nresult, err := registry.Convert(mcpTool, \"mcp\", \"openai\")\nif err != nil {\n  log.Fatal(err)\n}\n\n// Check for feature loss warnings\nfor _, w := range result.Warnings {\n  log.Printf(\"Feature loss: %s\", w)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/#versioning-utilities-version-package","title":"Versioning Utilities (version package)","text":"<pre><code>import \"github.com/jonwraymond/toolfoundation/version\"\n\nv1 := version.MustParse(\"v1.2.0\")\nv2 := version.MustParse(\"v1.3.1\")\n\nif v2.GreaterThan(v1) {\n  fmt.Println(\"upgrade available\")\n}\n\nmatrix := version.NewMatrix()\nmatrix.Add(version.Compatibility{\n  Component:  \"toolexec\",\n  MinVersion: version.MustParse(\"v1.0.0\"),\n})\n\nok, msg := matrix.Check(\"toolexec\", v1)\nif !ok {\n  log.Fatal(msg)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/#key-features","title":"Key Features","text":"<ul> <li>MCP-aligned: Tool type embeds official MCP SDK types</li> <li>Protocol-agnostic: Convert between MCP, OpenAI, and Anthropic formats</li> <li>Loss visibility: Feature loss during conversion is tracked as warnings</li> <li>Minimal dependencies: Foundation has minimal external dependencies</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/#schema-contracts","title":"Schema contracts","text":"<p>See the dedicated schema reference for field constraints, JSON Schema rules, and recommended patterns:</p> <ul> <li>tool schemas</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/#schema-validation-policy","title":"Schema Validation Policy","text":"<p>Schema validation follows JSON Schema 2020-12 by default with draft-07 support. External <code>$ref</code> resolution is disabled to prevent network access. See design notes for details and limitations.</p>"},{"location":"library-docs-from-repos/toolfoundation/#links","title":"Links","text":"<ul> <li>model design notes</li> <li>user journey</li> <li>tool schemas</li> <li>ai-tools-stack documentation</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/architecture/","title":"Architecture","text":"<p>This document describes the architecture of the toolfoundation package.</p>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#package-structure","title":"Package Structure","text":"<pre><code>toolfoundation/\n\u251c\u2500\u2500 model/      # Canonical tool definitions\n\u251c\u2500\u2500 adapter/    # Format conversion\n\u251c\u2500\u2500 version/    # Semantic versioning\n\u2514\u2500\u2500 examples/   # Usage examples\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#dependency-graph","title":"Dependency Graph","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     External                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  github.com/modelcontextprotocol/go-sdk/mcp     \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                          \u25b2                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   toolfoundation                        \u2502\n\u2502                          \u2502                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502                              \u2502\n\u2502  \u2502  version  \u2502 (standalone - no internal deps)          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502                              \u2502\n\u2502       \u25b2                  \u2502                              \u2502\n\u2502       \u2502                  \u2502                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502  \u2502           model             \u2502                        \u2502\n\u2502  \u2502  - Tool type (embeds mcp)   \u2502                        \u2502\n\u2502  \u2502  - Schema validation        \u2502                        \u2502\n\u2502  \u2502  - Backend bindings         \u2502                        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\n\u2502                \u25b2                                        \u2502\n\u2502                \u2502                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502  \u2502          adapter            \u2502                        \u2502\n\u2502  \u2502  - CanonicalTool            \u2502                        \u2502\n\u2502  \u2502  - MCPAdapter               \u2502                        \u2502\n\u2502  \u2502  - OpenAIAdapter            \u2502                        \u2502\n\u2502  \u2502  - AnthropicAdapter         \u2502                        \u2502\n\u2502  \u2502  - AdapterRegistry          \u2502                        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\n\u2502                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#package-responsibilities","title":"Package Responsibilities","text":""},{"location":"library-docs-from-repos/toolfoundation/architecture/#version","title":"version","text":"<p>Standalone package with no internal dependencies.</p> <ul> <li>Semantic version parsing (<code>Parse</code>, <code>MustParse</code>)</li> <li>Version comparison (<code>Compare</code>, <code>LessThan</code>, <code>GreaterThan</code>, <code>Equal</code>)</li> <li>Version constraints (<code>ParseConstraint</code>, <code>Check</code>)</li> <li>Compatibility matrices (<code>Matrix</code>, <code>Negotiate</code>)</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#model","title":"model","text":"<p>Depends on: version, mcp-go SDK</p> <ul> <li>Canonical <code>Tool</code> type (embeds <code>mcp.Tool</code>)</li> <li>Tool extensions: <code>Namespace</code>, <code>Version</code>, <code>Tags</code>, <code>Backend</code></li> <li>Schema validation (<code>SchemaValidator</code>, <code>DefaultValidator</code>)</li> <li>Tag normalization (<code>NormalizeTags</code>)</li> <li>Backend factory functions (<code>NewMCPBackend</code>, <code>NewLocalBackend</code>, <code>NewProviderBackend</code>)</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#adapter","title":"adapter","text":"<p>Depends on: model</p> <ul> <li><code>CanonicalTool</code> - intermediate representation</li> <li><code>Adapter</code> interface for format converters</li> <li>Built-in adapters: MCP, OpenAI, Anthropic</li> <li><code>AdapterRegistry</code> for managing converters</li> <li>Feature loss detection and warnings</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#data-flow","title":"Data Flow","text":""},{"location":"library-docs-from-repos/toolfoundation/architecture/#tool-conversion","title":"Tool Conversion","text":"<pre><code>Source Format    Canonical        Target Format\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500        \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   MCP   \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502Canonical\u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 OpenAI  \u2502\n\u2502  Tool   \u2502      \u2502  Tool   \u2502      \u2502  Tool   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u25b2                                \u2502\n      \u2502          ToCanonical()         \u2502\n      \u2502          FromCanonical()       \u2502\n      \u2502                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Anthropic\u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 OpenAI  \u2502\n\u2502  Tool   \u2502                      \u2502  Tool   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>All conversions pass through <code>CanonicalTool</code>, enabling N adapters to support N\u00b2 conversions with only 2N implementations.</p>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#feature-loss-detection","title":"Feature Loss Detection","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Source Schema  \u2502\n\u2502  (full features)\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Target Adapter  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502FeatureLossWarning\u2502\n\u2502SupportsFeature()\u2502     \u2502 - Feature       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502 - Path          \u2502\n                        \u2502 - Message       \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#design-principles","title":"Design Principles","text":"<ol> <li>Pure Transformations: Conversions have no I/O or side effects</li> <li>Minimal Dependencies: Only essential external packages</li> <li>MCP Alignment: Tool type embeds official MCP SDK types</li> <li>Explicit Loss: Feature degradation is warnings, not errors</li> <li>Thread Safety: Registry is safe for concurrent reads after setup</li> </ol>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#extension-points","title":"Extension Points","text":""},{"location":"library-docs-from-repos/toolfoundation/architecture/#custom-adapters","title":"Custom Adapters","text":"<p>Implement the <code>Adapter</code> interface:</p> <pre><code>type Adapter interface {\n    Name() string\n    ToCanonical(raw any) (*CanonicalTool, error)\n    FromCanonical(ct *CanonicalTool) (any, error)\n    SupportsFeature(feature SchemaFeature) bool\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#custom-validators","title":"Custom Validators","text":"<p>Implement the <code>SchemaValidator</code> interface:</p> <pre><code>type SchemaValidator interface {\n    Validate(schema any, data any) error\n    ValidateInput(tool *Tool, input any) error\n    ValidateOutput(tool *Tool, output any) error\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/","title":"toolfoundation Design Notes","text":""},{"location":"library-docs-from-repos/toolfoundation/design-notes/#overview","title":"Overview","text":"<p>toolfoundation provides the canonical data types that all other ApertureStack components depend on. It contains two packages: <code>model</code> for tool definitions and <code>adapter</code> for format conversion.</p>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#model-package","title":"model Package","text":""},{"location":"library-docs-from-repos/toolfoundation/design-notes/#design-decisions","title":"Design Decisions","text":"<ol> <li> <p>MCP SDK Embedding: The <code>Tool</code> type embeds <code>mcp.Tool</code> from the official    MCP Go SDK rather than reimplementing the fields. This ensures 1:1 spec    compatibility while allowing extension.</p> </li> <li> <p>Namespace + Name = ID: Tool IDs are <code>namespace:name</code> format, providing    stable identifiers across registry operations.</p> </li> <li> <p>Backend Abstraction: <code>ToolBackend</code> supports three kinds:</p> </li> <li><code>local</code>: In-process handler function</li> <li><code>provider</code>: External tool provider</li> <li> <p><code>mcp</code>: Remote MCP server</p> </li> <li> <p>Tag Normalization: Tags are normalized (lowercase, trimmed, deduped)    to ensure consistent search behavior.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#error-handling","title":"Error Handling","text":"<ul> <li><code>Validate()</code> returns descriptive errors for invalid tools</li> <li>Schema validation uses JSON Schema draft 2020-12</li> <li>Empty names, invalid characters, and missing schemas are rejected</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#schema-validation-policy","title":"Schema Validation Policy","text":"<p>The default validator supports the following dialects:</p> <ul> <li>JSON Schema 2020-12 (default)</li> <li>JSON Schema draft-07</li> </ul> <p>External <code>$ref</code> resolution is disabled to prevent network access during validation. Validation behavior is deterministic and does not perform I/O.</p> <p>Limitations (from the underlying jsonschema-go implementation):</p> <ul> <li><code>format</code> is treated as annotation (not validated)</li> <li><code>contentEncoding</code> and <code>contentMediaType</code> are not validated</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#adapter-package","title":"adapter Package","text":""},{"location":"library-docs-from-repos/toolfoundation/design-notes/#design-decisions_1","title":"Design Decisions","text":"<ol> <li> <p>Canonical Intermediate: All conversions go through <code>CanonicalTool</code>,    a protocol-agnostic intermediate representation.</p> </li> <li> <p>Pure Transforms: Conversions have no I/O or side effects. Same input    always produces same output.</p> </li> <li> <p>Feature Loss Warnings: When the target format doesn't support a feature    (e.g., <code>$ref</code> in OpenAI), warnings are returned instead of errors.</p> </li> <li> <p>Minimal Dependencies: The MCP adapter depends on the MCP SDK. OpenAI    and Anthropic adapters use self-contained types.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#supported-formats","title":"Supported Formats","text":"Format Adapter Notes MCP MCPAdapter Full spec support OpenAI OpenAIAdapter Strict mode support Anthropic AnthropicAdapter Full spec support"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#feature-compatibility","title":"Feature Compatibility","text":"Feature MCP OpenAI Anthropic <code>$ref/$defs</code> Yes No No <code>anyOf/oneOf</code> Yes No Yes <code>pattern</code> Yes Yes* Yes <code>enum/const</code> Yes Yes Yes <p>*OpenAI supports pattern only in strict mode.</p>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#feature-loss-warnings","title":"Feature Loss Warnings","text":"<p>Adapters emit <code>FeatureLossWarning</code> entries when the target format does not support a schema feature used by the source. Conversions still succeed, but consumers should review warnings before exposing the converted tool to users.</p>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#dependencies","title":"Dependencies","text":"<ul> <li><code>github.com/modelcontextprotocol/go-sdk/mcp</code> - MCP type definitions</li> <li><code>github.com/santhosh-tekuri/jsonschema</code> - Schema validation (optional)</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#links","title":"Links","text":"<ul> <li>index</li> <li>tool schemas</li> <li>user journey</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/schemas/","title":"Tool Schemas","text":"<p>toolfoundation defines the canonical tool schema (the <code>Tool</code> record) and the JSON Schemas used for tool input/output validation. This page documents the fields, constraints, and JSON Schema rules that all downstream components rely on.</p>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#tool-schema-fields-and-constraints","title":"Tool schema fields and constraints","text":"<p>The canonical tool record is <code>model.Tool</code>, which embeds the MCP SDK <code>mcp.Tool</code> fields and adds stack-specific extensions.</p>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#core-mcp-tool-fields","title":"Core MCP tool fields","text":"Field Required Constraints / Notes <code>name</code> Yes 1-128 chars, allowed: <code>[A-Za-z0-9_.-]</code> only. <code>description</code> No Human-readable description. <code>inputSchema</code> Yes JSON Schema object defining tool parameters. <code>outputSchema</code> No JSON Schema object for structured output (optional). <code>title</code> No Display name (preferred over <code>name</code>). <code>annotations</code> No Hints for clients (readOnly, idempotent, destructive, openWorld). <code>_meta</code> No Arbitrary metadata. <code>icons</code> No List of icon assets for UI."},{"location":"library-docs-from-repos/toolfoundation/schemas/#toolfoundation-extensions","title":"toolfoundation extensions","text":"Field Required Constraints / Notes <code>namespace</code> No Optional namespace for stable IDs. If present, tool ID is <code>namespace:name</code>. Namespace and name must both be non-empty when used. <code>version</code> No Optional semantic version string (accepts <code>v1.2.3</code> or <code>1.2.3</code>). <code>tags</code> No Normalized tags for discovery; see rules below."},{"location":"library-docs-from-repos/toolfoundation/schemas/#tool-id-rules","title":"Tool ID rules","text":"<ul> <li>Tool IDs are <code>namespace:name</code> when <code>namespace</code> is set, otherwise just <code>name</code>.</li> <li>Only one <code>:</code> is permitted in an ID.</li> <li><code>namespace</code> and <code>name</code> must both be non-empty when a <code>:</code> is used.</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#tag-normalization-rules","title":"Tag normalization rules","text":"<p>Tags are normalized for stable search behavior:</p> <ul> <li>Lowercased and trimmed.</li> <li>Whitespace collapsed to <code>-</code>.</li> <li>Allowed characters: <code>[a-z0-9-_.]</code> (others are removed).</li> <li>Max tag length: 64 chars.</li> <li>Max tag count: 20.</li> <li>Duplicates removed while preserving order.</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#inputschema-outputschema-requirements","title":"InputSchema / OutputSchema requirements","text":"<ul> <li>InputSchema is required. A tool without <code>inputSchema</code> is invalid.</li> <li>OutputSchema is optional. If omitted, output validation is skipped.</li> <li>Schemas must be valid JSON Schema objects. Accepted representations:</li> <li><code>map[string]any</code></li> <li><code>json.RawMessage</code></li> <li><code>[]byte</code></li> <li><code>*jsonschema.Schema</code></li> <li>Validation is performed by <code>model.SchemaValidator</code>:</li> <li><code>ValidateInput</code> must use <code>tool.InputSchema</code> and returns <code>ErrInvalidSchema</code>     if <code>tool</code> or <code>InputSchema</code> is nil.</li> <li><code>ValidateOutput</code> returns nil when <code>OutputSchema</code> is nil.</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#supported-dialects-and-limitations","title":"Supported dialects and limitations","text":"<ul> <li>Default dialect: JSON Schema 2020-12 (assumed when <code>$schema</code> is absent).</li> <li>Supported: 2020-12 and draft-07.</li> <li>External <code>$ref</code> resolution is disabled (no network access).</li> <li>Known limitations from the underlying validator:</li> <li><code>format</code> is treated as annotation (not enforced).</li> <li><code>contentEncoding</code> and <code>contentMediaType</code> are not validated.</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#recommended-no-parameters-schema","title":"Recommended \"no parameters\" schema","text":"<p>The MCP-recommended schema for tools that take no parameters:</p> <pre><code>{\n  \"type\": \"object\",\n  \"additionalProperties\": false\n}\n</code></pre> <p>The MCP-allowed (but less strict) variant:</p> <pre><code>{\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#example-schema-patterns","title":"Example schema patterns","text":""},{"location":"library-docs-from-repos/toolfoundation/schemas/#required-string-property","title":"Required string property","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"path\": {\"type\": \"string\", \"description\": \"File path\"}\n  },\n  \"required\": [\"path\"],\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#optional-enum-with-default","title":"Optional enum with default","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"encoding\": {\"type\": \"string\", \"enum\": [\"utf8\", \"ascii\"], \"default\": \"utf8\"}\n  },\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#array-of-objects","title":"Array of objects","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"items\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"id\": {\"type\": \"string\"},\n          \"value\": {\"type\": \"number\"}\n        },\n        \"required\": [\"id\"],\n        \"additionalProperties\": false\n      }\n    }\n  },\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#one-of-variants","title":"One-of variants","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"mode\": {\n      \"oneOf\": [\n        {\"type\": \"string\", \"enum\": [\"fast\", \"safe\"]},\n        {\"type\": \"number\", \"minimum\": 1, \"maximum\": 10}\n      ]\n    }\n  }\n}\n</code></pre> <p>Note: some adapters (e.g., OpenAI) do not support all schema features. See the adapter feature matrix in the toolfoundation component docs for details.</p>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#authoring-approaches-recommended","title":"Authoring approaches (recommended)","text":"<ol> <li>Go structs + schema generation (recommended default)</li> <li>Define input/output types in Go and generate JSON Schema.</li> <li>Example generator: <code>github.com/invopop/jsonschema</code>.</li> <li>Schema builder helpers</li> <li>Useful for advanced constructs not easily expressed in tags.</li> <li>Raw map/JSON schema</li> <li>Fully supported, but most error-prone.</li> <li>Schema validation libraries (implementation detail)</li> <li><code>github.com/santhosh-tekuri/jsonschema</code> is commonly used for      fast validation and supports 2020-12 and draft-07.</li> </ol>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#links","title":"Links","text":"<ul> <li>Design notes</li> <li>User journey</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/","title":"toolfoundation User Journey","text":""},{"location":"library-docs-from-repos/toolfoundation/user-journey/#overview","title":"Overview","text":"<p>This guide walks through the typical usage patterns for toolfoundation, from defining your first tool to converting between LLM provider formats.</p>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#1-installation","title":"1. Installation","text":"<pre><code>go get github.com/jonwraymond/toolfoundation@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#2-define-your-first-tool","title":"2. Define Your First Tool","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolfoundation/model\"\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// Create a tool definition\ntool := model.Tool{\n  Namespace: \"calculator\",\n  Tool: mcp.Tool{\n    Name:        \"add\",\n    Description: \"Add two numbers together\",\n    InputSchema: map[string]any{\n      \"type\": \"object\",\n      \"properties\": map[string]any{\n        \"a\": map[string]any{\"type\": \"number\"},\n        \"b\": map[string]any{\"type\": \"number\"},\n      },\n      \"required\": []string{\"a\", \"b\"},\n    },\n  },\n  Tags: model.NormalizeTags([]string{\"math\", \"arithmetic\"}),\n}\n\n// Validate the tool\nif err := tool.Validate(); err != nil {\n  log.Fatalf(\"Invalid tool: %v\", err)\n}\n\n// Get the canonical ID\nfmt.Println(tool.ToolID()) // \"calculator:add\"\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#3-assign-a-backend","title":"3. Assign a Backend","text":"<pre><code>// Local handler backend\ntool.Backend = model.NewLocalBackend(\"add_handler\")\n\n// Or MCP server backend\ntool.Backend = model.NewMCPBackend(\"math-server\")\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#4-convert-to-openai-format","title":"4. Convert to OpenAI Format","text":"<pre><code>import \"github.com/jonwraymond/toolfoundation/adapter\"\n\n// Use the default registry with all built-in adapters\nregistry := adapter.DefaultRegistry()\n\n// Convert MCP tool to OpenAI format\nresult, err := registry.Convert(&amp;tool, \"mcp\", \"openai\")\nif err != nil {\n  log.Fatalf(\"Conversion failed: %v\", err)\n}\n\n// Check for feature loss\nfor _, warning := range result.Warnings {\n  log.Printf(\"Warning: %s\", warning)\n}\n\nopenaiTool := result.Tool.(*adapter.OpenAITool)\nfmt.Printf(\"OpenAI function: %s\\n\", openaiTool.Function.Name)\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#5-round-trip-conversion","title":"5. Round-Trip Conversion","text":"<pre><code>// Convert OpenAI \u2192 MCP\nresult2, err := registry.Convert(openaiTool, \"openai\", \"mcp\")\nif err != nil {\n  log.Fatal(err)\n}\n\nmcpTool := result2.Tool.(mcp.Tool)\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#common-patterns","title":"Common Patterns","text":""},{"location":"library-docs-from-repos/toolfoundation/user-journey/#batch-tool-registration","title":"Batch Tool Registration","text":"<pre><code>tools := []model.Tool{\n  {Namespace: \"math\", Tool: mcp.Tool{Name: \"add\", ...}},\n  {Namespace: \"math\", Tool: mcp.Tool{Name: \"subtract\", ...}},\n  {Namespace: \"math\", Tool: mcp.Tool{Name: \"multiply\", ...}},\n}\n\nfor _, t := range tools {\n  if err := t.Validate(); err != nil {\n    log.Printf(\"Skipping invalid tool %s: %v\", t.ToolID(), err)\n    continue\n  }\n  // Register with index...\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#schema-validation","title":"Schema Validation","text":"<pre><code>validator := model.NewDefaultValidator()\n\n// Validate input against tool schema\ninput := map[string]any{\"a\": 5, \"b\": 10}\nif err := validator.ValidateInput(&amp;tool, input); err != nil {\n  log.Fatalf(\"Invalid input: %v\", err)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#version-compatibility","title":"Version Compatibility","text":"<pre><code>import \"github.com/jonwraymond/toolfoundation/version\"\n\ncurrent := version.MustParse(\"v1.2.0\")\nrequired := version.MustParse(\"v1.0.0\")\n\nif !current.Compatible(required) {\n  log.Fatalf(\"version %s is not compatible with %s\", current, required)\n}\n\nmatrix := version.NewMatrix()\nmatrix.Add(version.Compatibility{\n  Component:  \"toolfoundation\",\n  MinVersion: required,\n})\n\nok, msg := matrix.Check(\"toolfoundation\", current)\nif !ok {\n  log.Fatal(msg)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Register tools with tooldiscovery/index</li> <li>Execute tools with toolexec/run</li> <li>Expose via MCP with metatools-mcp</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/","title":"tooldiscovery","text":"<p>Discovery layer providing tool registry, search strategies, and progressive documentation for the ApertureStack tool framework.</p>"},{"location":"library-docs-from-repos/tooldiscovery/#packages","title":"Packages","text":"Package Purpose <code>discovery</code> Unified facade combining index, search, semantic, and tooldoc <code>index</code> Global registry, tool lookup, and search interface <code>search</code> BM25-based full-text search strategy <code>semantic</code> Embedding-based semantic search (optional) <code>tooldoc</code> Progressive documentation with detail levels <code>registry</code> MCP server helper with local + backend execution"},{"location":"library-docs-from-repos/tooldiscovery/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/tooldiscovery@latest\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#quick-start","title":"Quick Start","text":""},{"location":"library-docs-from-repos/tooldiscovery/#use-the-discovery-facade-recommended","title":"Use the Discovery Facade (Recommended)","text":"<pre><code>import (\n  \"context\"\n  \"github.com/jonwraymond/tooldiscovery/discovery\"\n)\n\ndisc, _ := discovery.New(discovery.Options{})\n\n// Register tools through the facade\n_ = disc.RegisterTool(tool, backend)\n\n// Search (hybrid-ready)\nresults, _ := disc.Search(context.Background(), \"create issue\", 5)\nfor _, r := range results {\n  fmt.Printf(\"[%s] %s\\n\", r.ScoreType, r.Summary.ID)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#build-an-mcp-server-registry","title":"Build an MCP Server (registry)","text":"<pre><code>import (\n  \"context\"\n  \"github.com/jonwraymond/tooldiscovery/registry\"\n)\n\nreg := registry.New(registry.Config{\n  ServerInfo: registry.ServerInfo{Name: \"my-mcp\", Version: \"1.0.0\"},\n})\n\n_ = reg.RegisterLocalFunc(\n  \"echo\",\n  \"Echo input\",\n  map[string]any{\"type\": \"object\"},\n  func(ctx context.Context, args map[string]any) (any, error) { return args, nil },\n)\n\n_ = reg.Start(context.Background())\ndefer reg.Stop()\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#register-and-search-tools","title":"Register and Search Tools","text":"<pre><code>import (\n  \"github.com/jonwraymond/tooldiscovery/index\"\n  \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Create an index\nidx := index.NewInMemoryIndex()\n\n// Register a tool\nerr := idx.RegisterTool(tool, backend)\nif err != nil {\n  log.Fatal(err)\n}\n\n// Search for tools\nsummaries, err := idx.Search(\"create issue\", 5)\nfor _, s := range summaries {\n  fmt.Printf(\"%s: %s\\n\", s.ID, s.ShortDescription)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#enable-bm25-search","title":"Enable BM25 Search","text":"<pre><code>import (\n  \"github.com/jonwraymond/tooldiscovery/index\"\n  \"github.com/jonwraymond/tooldiscovery/search\"\n)\n\n// Create BM25 searcher\nsearcher, err := search.NewBM25Searcher(search.DefaultConfig())\nif err != nil {\n  log.Fatal(err)\n}\ndefer searcher.Close()\n\n// Create index with BM25\nidx := index.NewInMemoryIndex(index.WithSearchStrategy(searcher))\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#search-strategy-guidance","title":"Search Strategy Guidance","text":"<ul> <li>Lexical (default): simple substring matching; best for small registries.</li> <li>BM25 (<code>search</code>): higher quality ranking for larger registries.</li> <li>Semantic (<code>semantic</code>): intent-based matching when embeddings are available.</li> <li>Hybrid (<code>discovery</code>): combines BM25 + semantic with weighted scoring.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/#progressive-documentation","title":"Progressive Documentation","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n\nstore := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n// Get summary only (token-cheap)\ndoc, _ := store.GetDoc(toolID, tooldoc.DetailSummary)\n\n// Get full schema (on-demand)\ndoc, _ = store.GetDoc(toolID, tooldoc.DetailSchema)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#semantic-search-optional","title":"Semantic Search (Optional)","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/semantic\"\n\n// Provide an Embedder + VectorStore implementation\nsearcher := semantic.NewSemanticSearcher(embedder, vectorStore)\nidx := index.NewInMemoryIndex(index.WithSearchStrategy(searcher))\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#key-features","title":"Key Features","text":"<ul> <li>Token-efficient: Summaries exclude schemas to reduce context usage</li> <li>Pluggable search: Swap between lexical, BM25, or semantic search</li> <li>Progressive disclosure: Request only the detail level needed</li> <li>Namespace support: List and filter tools by namespace</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/#links","title":"Links","text":"<ul> <li>design notes</li> <li>user journey</li> <li>schemas and contracts</li> <li>architecture</li> <li>registry</li> <li>concurrency</li> <li>error handling</li> <li>performance</li> <li>migration</li> <li>ai-tools-stack documentation</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/","title":"Architecture Overview","text":"<p>This document describes the component architecture of tooldiscovery and how the packages interact.</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#package-hierarchy","title":"Package Hierarchy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         discovery                                \u2502\n\u2502              (Unified Facade - Recommended Entry Point)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                 \u2502                 \u2502\n         v                 v                 v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    index    \u2502\u25c4\u2500\u2500\u2500\u2502   semantic   \u2502   \u2502  tooldoc \u2502\n\u2502  (Registry) \u2502    \u2502  (Scoring)   \u2502   \u2502  (Docs)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                    \u2502\n       v                                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n\u2502    search    \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502   (BM25)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  toolfoundation  \u2502\n\u2502     (model)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#package-responsibilities","title":"Package Responsibilities","text":""},{"location":"library-docs-from-repos/tooldiscovery/architecture/#discovery-unified-facade","title":"<code>discovery</code> - Unified Facade","text":"<p>The recommended entry point for most use cases. Combines all packages into a simple API.</p> <p>Provides: - Single <code>Discovery</code> type with unified operations - Built-in hybrid search (BM25 + semantic) - Integrated documentation management - Result filtering helpers</p> <p>Key Types: - <code>Discovery</code> - Main facade - <code>Options</code> - Configuration - <code>Result</code> / <code>Results</code> - Search results with scores - <code>HybridSearcher</code> - Composite searcher</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#registry-mcp-server-helper","title":"<code>registry</code> - MCP Server Helper","text":"<p>High-level helper for building MCP servers. It composes <code>index</code> + <code>search</code> with local execution handlers and MCP backend aggregation.</p> <p>Provides: - Local tool registration with handlers - MCP backend connections and tool aggregation - MCP protocol handlers (<code>initialize</code>, <code>tools/list</code>, <code>tools/call</code>) - Transports (<code>ServeStdio</code>, <code>ServeHTTP</code>, <code>ServeSSE</code>)</p> <p>Key Types: - <code>Registry</code> - Core registry + lifecycle - <code>ToolHandler</code> - Local execution handler - <code>BackendConfig</code> - MCP backend connection config</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#index-tool-registry","title":"<code>index</code> - Tool Registry","text":"<p>Core registry for tool storage, lookup, and search orchestration.</p> <p>Provides: - Tool registration with backends - Canonical ID generation (<code>namespace:name</code>) - Pluggable search via <code>Searcher</code> interface - Change notifications - Pagination support</p> <p>Key Types: - <code>Index</code> - Registry interface - <code>InMemoryIndex</code> - Default implementation - <code>Searcher</code> - Search strategy interface - <code>Summary</code> / <code>SearchDoc</code> - Lightweight search results</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#search-bm25-implementation","title":"<code>search</code> - BM25 Implementation","text":"<p>Production-ready BM25 search using Bleve.</p> <p>Provides: - Full-text search with field boosting - Configurable term weighting - Deterministic ordering for pagination - Efficient index caching</p> <p>Key Types: - <code>BM25Searcher</code> - Main searcher (implements <code>index.Searcher</code>) - <code>BM25Config</code> - Boost configuration</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#semantic-embedding-search","title":"<code>semantic</code> - Embedding Search","text":"<p>Pluggable semantic search with no external dependencies.</p> <p>Provides: - Strategy pattern for scoring (BM25, embedding, hybrid) - Document indexing for semantic operations - Bring-your-own-embedder support - Namespace/tag filtering</p> <p>Key Types: - <code>Strategy</code> - Scoring interface - <code>Embedder</code> - User-provided embedding generator - <code>Indexer</code> - Document storage interface - <code>Document</code> - Semantic document model</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#tooldoc-documentation-store","title":"<code>tooldoc</code> - Documentation Store","text":"<p>Progressive disclosure documentation system.</p> <p>Provides: - Three detail levels (summary, schema, full) - Example storage and validation - Schema information extraction - Integration with index for tool lookup</p> <p>Key Types: - <code>Store</code> - Documentation interface - <code>InMemoryStore</code> - Default implementation - <code>DetailLevel</code> - Disclosure granularity - <code>ToolDoc</code> / <code>DocEntry</code> - Documentation types</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#data-flow","title":"Data Flow","text":""},{"location":"library-docs-from-repos/tooldiscovery/architecture/#tool-registration","title":"Tool Registration","text":"<pre><code>model.Tool + ToolBackend\n        \u2502\n        v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 index.Index   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Stores tool + backend\n\u2502 RegisterTool  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Normalizes tags\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Builds SearchDoc\n        \u2502               \u2500\u2500\u2500\u2500\u2500\u2500\u25ba Notifies listeners\n        v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 tooldoc.Store \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Stores documentation\n\u2502 RegisterDoc   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Validates examples\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#search-flow","title":"Search Flow","text":"<pre><code>Query String\n     \u2502\n     v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 index.Search   \u2502\u25c4\u2500\u2500\u2500 Gets SearchDoc snapshot\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502\n        v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Searcher.Search\u2502\u25c4\u2500\u2500\u2500 BM25Searcher or HybridSearcher\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502\n        v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Strategy.Score \u2502\u25c4\u2500\u2500\u2500 BM25, Embedding, or Hybrid\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502\n        v\n   []Summary (sorted by score, then ID)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#progressive-disclosure","title":"Progressive Disclosure","text":"<pre><code>Tool ID\n   \u2502\n   \u251c\u2500\u2500\u25ba DetailSummary \u2500\u2500\u25ba Summary only (cheap)\n   \u2502\n   \u251c\u2500\u2500\u25ba DetailSchema  \u2500\u2500\u25ba Summary + Tool + SchemaInfo\n   \u2502\n   \u2514\u2500\u2500\u25ba DetailFull    \u2500\u2500\u25ba Everything + Notes + Examples\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#interface-contracts","title":"Interface Contracts","text":""},{"location":"library-docs-from-repos/tooldiscovery/architecture/#indexsearcher","title":"index.Searcher","text":"<pre><code>type Searcher interface {\n    Search(query string, limit int, docs []SearchDoc) ([]Summary, error)\n}\n</code></pre> <p>Contract: - Must be safe for concurrent use - Must return deterministic ordering (score desc, ID asc) - Must handle empty query (return first N docs) - Must respect limit parameter</p> <p>Implementations: - <code>search.BM25Searcher</code> - Bleve-based full-text search - <code>discovery.HybridSearcher</code> - BM25 + semantic combination - <code>discovery.BM25OnlySearcher</code> - Semantic BM25 with scores</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#indexdeterministicsearcher","title":"index.DeterministicSearcher","text":"<pre><code>type DeterministicSearcher interface {\n    Searcher\n    Deterministic() bool\n}\n</code></pre> <p>Required for pagination support. Implementations that return <code>true</code> guarantee stable ordering across calls with identical inputs.</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#semanticstrategy","title":"semantic.Strategy","text":"<pre><code>type Strategy interface {\n    Score(ctx context.Context, query string, doc Document) (float64, error)\n}\n</code></pre> <p>Contract: - Must honor context cancellation - Must return deterministic scores - Must be safe for concurrent use</p> <p>Implementations: - <code>bm25Strategy</code> - Token overlap scoring - <code>embeddingStrategy</code> - Cosine similarity of embeddings - <code>hybridStrategy</code> - Weighted combination</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#semanticembedder","title":"semantic.Embedder","text":"<pre><code>type Embedder interface {\n    Embed(ctx context.Context, text string) ([]float32, error)\n}\n</code></pre> <p>Contract: - Must honor context cancellation - Must return consistent-length vectors - Must be safe for concurrent use</p> <p>User-provided implementations connect to embedding services (OpenAI, Ollama, etc.).</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#type-mapping","title":"Type Mapping","text":""},{"location":"library-docs-from-repos/tooldiscovery/architecture/#indexsearchdoc-semanticdocument","title":"index.SearchDoc \u2194 semantic.Document","text":"<p>The <code>semantic/adapter.go</code> provides conversion between package types:</p> index.SearchDoc semantic.Document ID ID DocText Text Summary.Name Name Summary.Namespace Namespace Summary.ShortDescription Description Summary.Tags Tags (not present) Category"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#configuration-patterns","title":"Configuration Patterns","text":""},{"location":"library-docs-from-repos/tooldiscovery/architecture/#minimal-setup-bm25-only","title":"Minimal Setup (BM25 only)","text":"<pre><code>idx := index.NewInMemoryIndex()  // Uses built-in lexical searcher\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#bm25-with-custom-config","title":"BM25 with Custom Config","text":"<pre><code>searcher := search.NewBM25Searcher(search.BM25Config{\n    NameBoost: 3,\n    TagsBoost: 2,\n})\nidx := index.NewInMemoryIndex(index.IndexOptions{\n    Searcher: searcher,\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#hybrid-search-via-discovery","title":"Hybrid Search via Discovery","text":"<pre><code>disc, _ := discovery.New(discovery.Options{\n    Embedder:    myEmbedder,\n    HybridAlpha: 0.7,  // 70% BM25, 30% semantic\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#extension-points","title":"Extension Points","text":"<ol> <li>Custom Searcher: Implement <code>index.Searcher</code> for alternative search backends</li> <li>Custom Embedder: Implement <code>semantic.Embedder</code> for any embedding provider</li> <li>Custom Strategy: Implement <code>semantic.Strategy</code> for custom scoring logic</li> <li>Custom Backend Selector: Provide <code>BackendSelector</code> function to <code>IndexOptions</code></li> <li>Change Listeners: Subscribe via <code>OnChange</code> for reactive integrations</li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/","title":"Concurrency Guide","text":"<p>All tooldiscovery types are safe for concurrent use. This document explains the concurrency model and provides examples of safe concurrent patterns.</p>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#thread-safety-guarantees","title":"Thread Safety Guarantees","text":""},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#index-package","title":"index Package","text":"Type Thread Safety Implementation <code>InMemoryIndex</code> Safe <code>sync.RWMutex</code> <code>Summary</code> Immutable Value type <code>SearchDoc</code> Immutable Value type <code>ChangeEvent</code> Immutable Value type <p>Operations: - <code>RegisterTool</code>: Write lock (exclusive) - <code>GetTool</code>: Read lock (shared) - <code>Search</code>: Read lock (shared) - <code>OnChange</code>: Write lock for subscription, callbacks run outside lock</p>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#search-package","title":"search Package","text":"Type Thread Safety Implementation <code>BM25Searcher</code> Safe <code>sync.RWMutex</code> + fingerprint caching <p>Operations: - <code>Search</code>: Read lock for cache check, write lock only on cache miss - <code>Close</code>: Write lock (exclusive)</p>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#semantic-package","title":"semantic Package","text":"Type Thread Safety Implementation <code>InMemoryIndex</code> Safe <code>sync.RWMutex</code>, point-in-time snapshots <code>InMemorySearcher</code> Safe Stateless All strategies Safe Stateless <p>Note: <code>InMemoryIndex.List()</code> holds the read lock for the entire operation to ensure point-in-time snapshot consistency.</p>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#tooldoc-package","title":"tooldoc Package","text":"Type Thread Safety Implementation <code>InMemoryStore</code> Safe <code>sync.RWMutex</code> <code>ToolDoc</code> Immutable Value type (deep copied) <code>DocEntry</code> Immutable Value type"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#discovery-package","title":"discovery Package","text":"Type Thread Safety Implementation <code>Discovery</code> Safe Delegates to thread-safe components <code>HybridSearcher</code> Safe Stateless <code>Results</code> Immutable Value type"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#concurrent-usage-patterns","title":"Concurrent Usage Patterns","text":""},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#concurrent-search","title":"Concurrent Search","text":"<p>Multiple goroutines can search simultaneously:</p> <pre><code>idx := index.NewInMemoryIndex()\n// ... register tools ...\n\nvar wg sync.WaitGroup\nqueries := []string{\"git\", \"docker\", \"kubernetes\", \"python\", \"javascript\"}\n\nfor _, query := range queries {\n    wg.Add(1)\n    go func(q string) {\n        defer wg.Done()\n\n        results, err := idx.Search(q, 10)\n        if err != nil {\n            log.Printf(\"Search failed for %q: %v\", q, err)\n            return\n        }\n        log.Printf(\"Found %d results for %q\", len(results), q)\n    }(query)\n}\n\nwg.Wait()\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#concurrent-registration-and-search","title":"Concurrent Registration and Search","text":"<p>Searches can run while registrations happen:</p> <pre><code>idx := index.NewInMemoryIndex()\nctx, cancel := context.WithCancel(context.Background())\ndefer cancel()\n\n// Background registration\ngo func() {\n    for i := 0; i &lt; 1000; i++ {\n        tool := createTool(i)\n        if err := idx.RegisterTool(tool, backend); err != nil {\n            log.Printf(\"Registration failed: %v\", err)\n        }\n        time.Sleep(10 * time.Millisecond)\n    }\n}()\n\n// Concurrent searches\nfor i := 0; i &lt; 10; i++ {\n    go func() {\n        for {\n            select {\n            case &lt;-ctx.Done():\n                return\n            default:\n                results, _ := idx.Search(\"tool\", 10)\n                log.Printf(\"Found %d tools\", len(results))\n                time.Sleep(50 * time.Millisecond)\n            }\n        }\n    }()\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#concurrent-documentation-access","title":"Concurrent Documentation Access","text":"<pre><code>store := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\nvar wg sync.WaitGroup\ntoolIDs := []string{\"git:status\", \"docker:ps\", \"kubectl:get\"}\n\nfor _, id := range toolIDs {\n    wg.Add(1)\n    go func(toolID string) {\n        defer wg.Done()\n\n        // These can all run concurrently\n        summary, _ := store.DescribeTool(toolID, tooldoc.DetailSummary)\n        schema, _ := store.DescribeTool(toolID, tooldoc.DetailSchema)\n        full, _ := store.DescribeTool(toolID, tooldoc.DetailFull)\n\n        log.Printf(\"%s: summary=%q, hasSchema=%v, notes=%q\",\n            toolID, summary.Summary, schema.SchemaInfo != nil, full.Notes)\n    }(id)\n}\n\nwg.Wait()\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#using-discovery-facade-concurrently","title":"Using Discovery Facade Concurrently","text":"<pre><code>disc, _ := discovery.New(discovery.Options{})\n// ... register tools ...\n\n// Concurrent hybrid search\nresults := make(chan discovery.Results, 10)\nqueries := []string{\"create issue\", \"list containers\", \"deploy app\"}\n\nfor _, q := range queries {\n    go func(query string) {\n        ctx := context.Background()\n        r, err := disc.Search(ctx, query, 10)\n        if err != nil {\n            log.Printf(\"Search error: %v\", err)\n            results &lt;- nil\n            return\n        }\n        results &lt;- r\n    }(q)\n}\n\nfor range queries {\n    r := &lt;-results\n    if r != nil {\n        log.Printf(\"Got %d results\", len(r))\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#change-notification-safety","title":"Change Notification Safety","text":"<p>Change listeners are called outside the index lock to prevent deadlocks:</p> <pre><code>idx := index.NewInMemoryIndex()\n\n// Safe: listener doesn't hold locks\nunsubscribe := idx.OnChange(func(event index.ChangeEvent) {\n    // This runs outside the index lock\n    log.Printf(\"Tool %s: %s\", event.ToolID, event.Type)\n\n    // Safe to call index methods (they acquire their own locks)\n    if event.Type == index.ChangeRegistered {\n        tool, _, _ := idx.GetTool(event.ToolID)\n        log.Printf(\"Registered: %s\", tool.Description)\n    }\n})\ndefer unsubscribe()\n\n// Registrations trigger callbacks\nidx.RegisterTool(tool, backend)\n</code></pre> <p>Warning: Don't hold your own locks when calling index methods from listeners, as this can cause deadlocks.</p>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#embedder-concurrency","title":"Embedder Concurrency","text":"<p>Custom embedders must be thread-safe:</p> <pre><code>type CachedEmbedder struct {\n    client *openai.Client\n    cache  sync.Map // Thread-safe cache\n}\n\nfunc (e *CachedEmbedder) Embed(ctx context.Context, text string) ([]float32, error) {\n    // Check cache (thread-safe)\n    if cached, ok := e.cache.Load(text); ok {\n        return cached.([]float32), nil\n    }\n\n    // Make API call\n    resp, err := e.client.CreateEmbedding(ctx, openai.EmbeddingRequest{\n        Model: \"text-embedding-3-small\",\n        Input: []string{text},\n    })\n    if err != nil {\n        return nil, err\n    }\n\n    vec := resp.Data[0].Embedding\n\n    // Store in cache (thread-safe)\n    e.cache.Store(text, vec)\n\n    return vec, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#avoiding-common-pitfalls","title":"Avoiding Common Pitfalls","text":""},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#dont-hold-locks-across-calls","title":"Don't Hold Locks Across Calls","text":"<pre><code>// BAD: Holding your own lock while calling index methods\nfunc (s *MyService) badPattern() {\n    s.mu.Lock()\n    defer s.mu.Unlock()\n\n    // This acquires the index lock while holding s.mu\n    // If another goroutine holds index lock and tries to acquire s.mu,\n    // you have a deadlock\n    results, _ := s.idx.Search(\"query\", 10)\n    s.cache = results\n}\n\n// GOOD: Release your lock before calling index methods\nfunc (s *MyService) goodPattern() {\n    results, _ := s.idx.Search(\"query\", 10)\n\n    s.mu.Lock()\n    s.cache = results\n    s.mu.Unlock()\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#dont-modify-returned-slices","title":"Don't Modify Returned Slices","text":"<pre><code>// BAD: Modifying returned slice\nresults, _ := idx.Search(\"query\", 10)\nresults[0].Name = \"modified\" // Don't do this!\n\n// GOOD: Copy if you need to modify\nresults, _ := idx.Search(\"query\", 10)\nmyResults := make([]index.Summary, len(results))\ncopy(myResults, results)\nmyResults[0].Name = \"modified\" // Safe\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#use-context-for-timeouts","title":"Use Context for Timeouts","text":"<pre><code>// GOOD: Use context to prevent hanging on slow embedders\nfunc (s *MyService) SearchWithTimeout(query string) ([]Result, error) {\n    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n    defer cancel()\n\n    return s.searcher.Search(ctx, query)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#benchmarking-concurrent-performance","title":"Benchmarking Concurrent Performance","text":"<p>Use the provided benchmarks to measure concurrent performance:</p> <pre><code># Run concurrent benchmarks\ngo test ./index -bench=Concurrent -benchtime=5s\n\n# Example output:\n# BenchmarkIndex_Concurrent_Search-8     50000    25000 ns/op\n# BenchmarkIndex_Concurrent_Mixed-8      30000    40000 ns/op\n</code></pre> <p>The benchmarks use <code>b.RunParallel</code> to test concurrent access patterns.</p>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/","title":"tooldiscovery Design Notes","text":""},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#overview","title":"Overview","text":"<p>tooldiscovery provides the discovery layer for the ApertureStack tool framework. It handles tool registration, search, and progressive documentation.</p>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#index-package","title":"index Package","text":""},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#design-decisions","title":"Design Decisions","text":"<ol> <li> <p>Single Source of Truth: The index is the authoritative registry for all    registered tools. Tool IDs are derived from <code>toolfoundation/model.Tool.ToolID()</code>.</p> </li> <li> <p>Search Strategy Interface: Search is pluggable via the <code>SearchStrategy</code>    interface. Default is lexical substring matching.</p> </li> <li> <p>Token-Efficient Summaries: <code>Search()</code> returns <code>Summary</code> objects that    exclude schemas, keeping discovery cheap in terms of LLM context tokens.</p> </li> <li> <p>Namespace Isolation: Tools are grouped by namespace, enabling filtered    views and multi-tenant scenarios.</p> </li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#error-handling","title":"Error Handling","text":"<ul> <li>Duplicate tool registration returns an error</li> <li>Invalid tool IDs return descriptive errors</li> <li>Search errors are logged but don't fail the request</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#search-package","title":"search Package","text":""},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#design-decisions_1","title":"Design Decisions","text":"<ol> <li> <p>BM25 Algorithm: Uses Okapi BM25 for relevance ranking, implemented via    the Bleve search library.</p> </li> <li> <p>Field Boosting: Configurable boosts for name (4x), namespace (2x), and    tags (1x) fields.</p> </li> <li> <p>Optional Dependency: BM25 support depends on Bleve and is only used when    the <code>search</code> package is imported. Consumers can omit BM25 entirely by    sticking with the default lexical strategy.</p> </li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#search-strategy-policy","title":"Search Strategy Policy","text":"<ul> <li>Lexical (default): Lightweight substring matching; best for small indexes.</li> <li>BM25 (search package): Preferred for larger registries; tunable boosts.</li> <li>Semantic (semantic package): Best for fuzzy intent matching; requires embeddings.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#configuration","title":"Configuration","text":"Config Default Description NameBoost 4.0 Boost for tool name matches NamespaceBoost 2.0 Boost for namespace matches TagBoost 1.0 Boost for tag matches MaxDocs 0 Max docs to index (0=unlimited)"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#semantic-package","title":"semantic Package","text":""},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#design-decisions_2","title":"Design Decisions","text":"<ol> <li> <p>Embedder Interface: Abstracts the embedding model, allowing different    providers (OpenAI, local models, etc.).</p> </li> <li> <p>Vector Store Interface: Abstracts the vector storage, supporting    in-memory, file-based, or external stores.</p> </li> <li> <p>Optional Dependency: Semantic search is opt-in and requires additional    setup (embeddings, vector store).</p> </li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#contract-expectations","title":"Contract Expectations","text":"<ul> <li>Embedder: Must be deterministic for the same input and return fixed-size   vectors. Errors should be propagated rather than swallowed.</li> <li>VectorStore: Must return results ordered by similarity and include IDs   that map back to registered tools.</li> <li>Hybrid: The hybrid searcher uses Reciprocal Rank Fusion (RRF) to combine   BM25 and semantic results.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#tooldoc-package","title":"tooldoc Package","text":""},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#design-decisions_3","title":"Design Decisions","text":"<ol> <li>Detail Levels: Three progressive levels:</li> <li><code>Summary</code>: Name, namespace, short description</li> <li><code>Schema</code>: Input/output JSON schemas</li> <li> <p><code>Full</code>: Everything including examples</p> </li> <li> <p>On-Demand Loading: Schemas are only loaded when requested at    <code>DetailSchema</code> or <code>DetailFull</code> level.</p> </li> <li> <p>Index Integration: DocStore can use an Index to derive documentation    from registered tools.</p> </li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#detail-level-field-matrix","title":"Detail-Level Field Matrix","text":"Level Fields Summary ID, Name, Namespace, ShortDescription Schema Summary + InputSchema, OutputSchema Full Schema + Examples, Metadata"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#dependencies","title":"Dependencies","text":"<ul> <li><code>github.com/jonwraymond/toolfoundation/model</code> - Tool definitions</li> <li><code>github.com/blevesearch/bleve/v2</code> - BM25 search (optional)</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#links","title":"Links","text":"<ul> <li>index</li> <li>user journey</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/","title":"Error Handling Guide","text":"<p>This document describes the error types and error handling patterns used throughout tooldiscovery.</p>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#error-types-by-package","title":"Error Types by Package","text":""},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#index-package","title":"index Package","text":"Error When Returned Example Cause <code>ErrNotFound</code> Tool/backend lookup fails <code>GetTool(\"nonexistent:tool\")</code> <code>ErrInvalidTool</code> Tool validation fails Empty name, invalid schema <code>ErrInvalidBackend</code> Backend validation fails MCP backend missing ServerName <code>ErrInvalidCursor</code> Pagination cursor invalid Malformed or expired cursor <code>ErrNonDeterministicSearcher</code> SearchPage with non-deterministic searcher Custom searcher without stable ordering"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#search-package","title":"search Package","text":"<p>The search package returns errors from the underlying Bleve index but doesn't define custom error types. Errors are typically related to index operations.</p>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#semantic-package","title":"semantic Package","text":"Error When Returned Example Cause <code>ErrInvalidSearcher</code> Searcher missing components <code>NewSearcher(nil, nil)</code> <code>ErrInvalidDocumentID</code> Document ID is empty <code>idx.Add(ctx, Document{})</code> <code>ErrInvalidEmbedder</code> Embedder is nil <code>NewEmbeddingStrategy(nil)</code> <code>ErrInvalidHybridConfig</code> Invalid hybrid config Alpha outside [0,1] range"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#tooldoc-package","title":"tooldoc Package","text":"Error When Returned Example Cause <code>ErrNotFound</code> Tool not in index/resolver Unknown tool ID <code>ErrInvalidDetail</code> Invalid detail level Unrecognized DetailLevel value <code>ErrNoTool</code> No tool source configured Store without Index or ToolResolver <code>ErrArgsTooLarge</code> Example args exceed limits Nesting &gt; 5 or keys &gt; 50"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#discovery-package","title":"discovery Package","text":"Error When Returned Example Cause <code>ErrNotFound</code> Tool lookup fails Forwarded from index package"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#error-checking-patterns","title":"Error Checking Patterns","text":""},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#using-errorsis","title":"Using errors.Is","text":"<p>Always use <code>errors.Is</code> for error checking, as errors may be wrapped:</p> <pre><code>tool, backend, err := idx.GetTool(\"github:create-issue\")\nif errors.Is(err, index.ErrNotFound) {\n    // Tool doesn't exist\n    log.Printf(\"Tool not found: %s\", toolID)\n    return\n}\nif err != nil {\n    // Other error\n    return fmt.Errorf(\"failed to get tool: %w\", err)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#handling-validation-errors","title":"Handling Validation Errors","text":"<p>Validation errors often wrap the sentinel error with additional context:</p> <pre><code>err := idx.RegisterTool(tool, backend)\nif errors.Is(err, index.ErrInvalidTool) {\n    // Tool validation failed - check the error message for details\n    log.Printf(\"Invalid tool: %v\", err)\n    return\n}\nif errors.Is(err, index.ErrInvalidBackend) {\n    // Backend validation failed\n    log.Printf(\"Invalid backend: %v\", err)\n    return\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#handling-search-errors","title":"Handling Search Errors","text":"<pre><code>results, err := searcher.Search(ctx, query)\nif errors.Is(err, semantic.ErrInvalidSearcher) {\n    // Searcher not properly configured\n    log.Fatal(\"Searcher missing index or strategy\")\n}\nif errors.Is(err, semantic.ErrInvalidEmbedder) {\n    // Embedder is nil (for embedding/hybrid strategies)\n    log.Fatal(\"Embedder required for semantic search\")\n}\nif err != nil {\n    // May be context cancellation or embedder error\n    return fmt.Errorf(\"search failed: %w\", err)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#handling-documentation-errors","title":"Handling Documentation Errors","text":"<pre><code>doc, err := store.DescribeTool(toolID, tooldoc.DetailFull)\nif errors.Is(err, tooldoc.ErrNotFound) {\n    // Tool not found in index\n    return nil, fmt.Errorf(\"unknown tool: %s\", toolID)\n}\nif errors.Is(err, tooldoc.ErrNoTool) {\n    // Store has no way to look up tools\n    log.Fatal(\"Store not configured with Index or ToolResolver\")\n}\nif errors.Is(err, tooldoc.ErrInvalidDetail) {\n    // Invalid detail level (shouldn't happen with constants)\n    return nil, fmt.Errorf(\"invalid detail level\")\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#context-errors","title":"Context Errors","text":"<p>Many operations accept a context and honor cancellation:</p> <pre><code>ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\ndefer cancel()\n\nresults, err := searcher.Search(ctx, query)\nif errors.Is(err, context.DeadlineExceeded) {\n    log.Printf(\"Search timed out\")\n    return nil, err\n}\nif errors.Is(err, context.Canceled) {\n    log.Printf(\"Search was canceled\")\n    return nil, err\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#wrapping-errors","title":"Wrapping Errors","text":"<p>When propagating errors, wrap them with context:</p> <pre><code>func (s *MyService) FindTools(query string) ([]Tool, error) {\n    results, err := s.discovery.Search(ctx, query, 10)\n    if err != nil {\n        return nil, fmt.Errorf(\"tool search failed: %w\", err)\n    }\n\n    var tools []Tool\n    for _, r := range results {\n        tool, _, err := s.discovery.GetTool(r.Summary.ID)\n        if err != nil {\n            // Log but continue - tool may have been removed\n            log.Printf(\"Failed to get tool %s: %v\", r.Summary.ID, err)\n            continue\n        }\n        tools = append(tools, tool)\n    }\n    return tools, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#validation-before-operations","title":"Validation Before Operations","text":"<p>Validate inputs before expensive operations:</p> <pre><code>// Validate tool before registration\nif tool.Name == \"\" {\n    return fmt.Errorf(\"tool name is required\")\n}\nif tool.InputSchema == nil {\n    return fmt.Errorf(\"tool InputSchema is required\")\n}\n\n// Now safe to register\nif err := idx.RegisterTool(tool, backend); err != nil {\n    return fmt.Errorf(\"registration failed: %w\", err)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#error-recovery-patterns","title":"Error Recovery Patterns","text":""},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>func (s *MyService) Search(query string) ([]Result, error) {\n    // Try hybrid search first\n    if s.embedder != nil {\n        results, err := s.hybridSearch(query)\n        if err == nil {\n            return results, nil\n        }\n        // Log and fall back to BM25\n        log.Printf(\"Hybrid search failed, falling back to BM25: %v\", err)\n    }\n\n    // Fall back to BM25-only search\n    return s.bm25Search(query)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#retry-with-backoff","title":"Retry with Backoff","text":"<pre><code>func (e *MyEmbedder) EmbedWithRetry(ctx context.Context, text string) ([]float32, error) {\n    var lastErr error\n    for i := 0; i &lt; 3; i++ {\n        vec, err := e.Embed(ctx, text)\n        if err == nil {\n            return vec, nil\n        }\n        lastErr = err\n\n        // Don't retry on context errors\n        if errors.Is(err, context.Canceled) || errors.Is(err, context.DeadlineExceeded) {\n            return nil, err\n        }\n\n        // Exponential backoff\n        time.Sleep(time.Duration(1&lt;&lt;i) * 100 * time.Millisecond)\n    }\n    return nil, fmt.Errorf(\"embedding failed after 3 retries: %w\", lastErr)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#testing-error-conditions","title":"Testing Error Conditions","text":"<pre><code>func TestGetTool_NotFound(t *testing.T) {\n    idx := index.NewInMemoryIndex()\n\n    _, _, err := idx.GetTool(\"nonexistent:tool\")\n\n    if !errors.Is(err, index.ErrNotFound) {\n        t.Errorf(\"expected ErrNotFound, got %v\", err)\n    }\n}\n\nfunc TestRegisterTool_InvalidTool(t *testing.T) {\n    idx := index.NewInMemoryIndex()\n\n    // Tool with empty name\n    tool := model.Tool{\n        Tool: mcp.Tool{\n            Name: \"\", // Invalid\n            InputSchema: map[string]any{\"type\": \"object\"},\n        },\n    }\n\n    err := idx.RegisterTool(tool, model.NewMCPBackend(\"server\"))\n\n    if !errors.Is(err, index.ErrInvalidTool) {\n        t.Errorf(\"expected ErrInvalidTool, got %v\", err)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/examples/","title":"Examples","text":"<p>tooldiscovery ships with runnable examples that demonstrate each search mode and documentation level.</p>"},{"location":"library-docs-from-repos/tooldiscovery/examples/#basic-discovery-bm25-progressive-docs","title":"Basic discovery (BM25 + progressive docs)","text":"<pre><code>go run ./examples/basic\n</code></pre> <p>Shows: - Registering tools in the index - BM25 search results - Summary vs schema disclosure</p>"},{"location":"library-docs-from-repos/tooldiscovery/examples/#semantic-search","title":"Semantic search","text":"<pre><code>go run ./examples/semantic\n</code></pre> <p>Shows: - Custom embedder stub - Semantic index + searcher - Score ordering</p>"},{"location":"library-docs-from-repos/tooldiscovery/examples/#hybrid-search","title":"Hybrid search","text":"<pre><code>go run ./examples/hybrid\n</code></pre> <p>Shows: - BM25 + semantic weighted scoring - Score type tracking</p>"},{"location":"library-docs-from-repos/tooldiscovery/examples/#full-discovery-facade","title":"Full discovery facade","text":"<pre><code>go run ./examples/full\n</code></pre> <p>Shows: - <code>discovery.Discovery</code> unified API - Registration + search + describe flow</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/","title":"Migration Guide","text":"<p>This guide helps you migrate to tooldiscovery from other tool discovery systems.</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#migrating-from-toolindex","title":"Migrating from toolindex","text":"<p>The <code>tooldiscovery/index</code> package is the successor to <code>github.com/jonwraymond/toolindex</code>. The migration is straightforward as the API is largely compatible.</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#import-changes","title":"Import Changes","text":"<pre><code>// Before\nimport \"github.com/jonwraymond/toolindex\"\n\n// After\nimport \"github.com/jonwraymond/tooldiscovery/index\"\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#type-mapping","title":"Type Mapping","text":"toolindex tooldiscovery/index Notes <code>Index</code> <code>Index</code> Same interface <code>InMemoryIndex</code> <code>InMemoryIndex</code> Same implementation <code>Summary</code> <code>Summary</code> Same fields <code>SearchDoc</code> <code>SearchDoc</code> Same fields <code>Searcher</code> <code>Searcher</code> Same interface <code>ToolRegistration</code> <code>ToolRegistration</code> Same struct"},{"location":"library-docs-from-repos/tooldiscovery/migration/#new-features","title":"New Features","text":"<p>tooldiscovery adds: - <code>discovery</code> package for unified facade - <code>semantic</code> package for embedding-based search - <code>tooldoc</code> package for progressive documentation - <code>search</code> package with production BM25</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#code-changes","title":"Code Changes","text":"<p>Most code works unchanged:</p> <pre><code>// Before\nidx := toolindex.NewInMemoryIndex()\nidx.RegisterTool(tool, backend)\nresults, _ := idx.Search(\"query\", 10)\n\n// After (identical)\nidx := index.NewInMemoryIndex()\nidx.RegisterTool(tool, backend)\nresults, _ := idx.Search(\"query\", 10)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#using-discovery-facade-recommended","title":"Using Discovery Facade (Recommended)","text":"<p>For new code, use the <code>discovery</code> package:</p> <pre><code>// New recommended approach\ndisc, _ := discovery.New(discovery.Options{})\ndisc.RegisterTool(tool, backend, &amp;tooldoc.DocEntry{\n    Summary: \"Tool description\",\n})\nresults, _ := disc.Search(ctx, \"query\", 10)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#migrating-from-custom-tool-registries","title":"Migrating from Custom Tool Registries","text":"<p>If you have a custom tool registry, here's how to migrate:</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#step-1-map-your-tool-type","title":"Step 1: Map Your Tool Type","text":"<p>Create a function to convert your tools to <code>model.Tool</code>:</p> <pre><code>func convertTool(myTool MyTool) model.Tool {\n    return model.Tool{\n        Tool: mcp.Tool{\n            Name:        myTool.Name,\n            Description: myTool.Description,\n            InputSchema: myTool.Schema,\n        },\n        Namespace: myTool.Category, // Map to namespace\n        Tags:      myTool.Keywords, // Map to tags\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#step-2-map-your-backend-type","title":"Step 2: Map Your Backend Type","text":"<pre><code>func convertBackend(myBackend MyBackend) model.ToolBackend {\n    switch myBackend.Type {\n    case \"mcp\":\n        return model.NewMCPBackend(myBackend.ServerName)\n    case \"local\":\n        return model.NewLocalBackend(myBackend.HandlerName)\n    case \"external\":\n        return model.NewProviderBackend(myBackend.Provider, myBackend.ID)\n    default:\n        return model.NewMCPBackend(\"default\")\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#step-3-migrate-registration","title":"Step 3: Migrate Registration","text":"<pre><code>// Create index\nidx := index.NewInMemoryIndex()\n\n// Migrate existing tools\nfor _, myTool := range myRegistry.GetAllTools() {\n    tool := convertTool(myTool)\n    backend := convertBackend(myTool.Backend)\n\n    if err := idx.RegisterTool(tool, backend); err != nil {\n        log.Printf(\"Failed to migrate %s: %v\", myTool.Name, err)\n        continue\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#step-4-migrate-search","title":"Step 4: Migrate Search","text":"<pre><code>// Before (custom registry)\nresults := myRegistry.Search(query)\n\n// After\nsummaries, _ := idx.Search(query, 100)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#step-5-add-documentation-optional","title":"Step 5: Add Documentation (Optional)","text":"<pre><code>store := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\nfor _, myTool := range myRegistry.GetAllTools() {\n    toolID := fmt.Sprintf(\"%s:%s\", myTool.Category, myTool.Name)\n\n    store.RegisterDoc(toolID, tooldoc.DocEntry{\n        Summary:  myTool.ShortHelp,\n        Notes:    myTool.LongHelp,\n        Examples: convertExamples(myTool.Examples),\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#integrating-with-existing-mcp-servers","title":"Integrating with Existing MCP Servers","text":""},{"location":"library-docs-from-repos/tooldiscovery/migration/#receiving-tools-from-mcp-server","title":"Receiving Tools from MCP Server","text":"<pre><code>// When you receive tools from an MCP server\nfunc onToolsReceived(serverName string, mcpTools []mcp.Tool) {\n    // Convert to model.Tool (which embeds mcp.Tool)\n    tools := make([]model.Tool, len(mcpTools))\n    for i, t := range mcpTools {\n        tools[i] = model.Tool{Tool: t}\n    }\n\n    // Register all tools from this server\n    if err := idx.RegisterToolsFromMCP(serverName, tools); err != nil {\n        log.Printf(\"Failed to register tools from %s: %v\", serverName, err)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#handling-server-disconnect","title":"Handling Server Disconnect","text":"<pre><code>// When an MCP server disconnects, remove its tools\nfunc onServerDisconnect(serverName string) {\n    // Get all tools and find ones from this server\n    // (You'd need to track this mapping separately)\n    for _, toolID := range toolsFromServer[serverName] {\n        idx.UnregisterBackend(toolID, model.BackendKindMCP, serverName)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#using-with-toolfoundation-v020","title":"Using with toolfoundation v0.2.0","text":"<p>tooldiscovery requires toolfoundation v0.2.0+:</p> <pre><code>go get github.com/jonwraymond/toolfoundation@v0.2.0\n</code></pre> <p>Key features from toolfoundation used by tooldiscovery: - <code>model.Tool</code> with embedded <code>mcp.Tool</code> - <code>model.ToolBackend</code> with MCP/Provider/Local variants - <code>model.NormalizeTags</code> for consistent tag handling - Backend factory functions (<code>NewMCPBackend</code>, etc.)</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#gradual-migration-strategy","title":"Gradual Migration Strategy","text":"<p>For large codebases, migrate gradually:</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#phase-1-add-tooldiscovery-alongside-existing","title":"Phase 1: Add tooldiscovery Alongside Existing","text":"<pre><code>// Keep existing registry\noldRegistry := myRegistry.New()\n\n// Add tooldiscovery\nidx := index.NewInMemoryIndex()\n\n// Sync tools to both\nfunc registerTool(tool MyTool) {\n    oldRegistry.Register(tool)\n    idx.RegisterTool(convertTool(tool), convertBackend(tool.Backend))\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#phase-2-shadow-read","title":"Phase 2: Shadow Read","text":"<pre><code>// Search both, compare results\nfunc search(query string) []MyTool {\n    oldResults := oldRegistry.Search(query)\n\n    // Shadow: also search new index\n    newResults, _ := idx.Search(query, 100)\n    logComparison(oldResults, newResults)\n\n    return oldResults // Still use old results\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#phase-3-switch-read-path","title":"Phase 3: Switch Read Path","text":"<pre><code>func search(query string) []MyTool {\n    summaries, _ := idx.Search(query, 100)\n    return convertToMyTools(summaries)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#phase-4-remove-old-registry","title":"Phase 4: Remove Old Registry","text":"<pre><code>// Only use tooldiscovery\nidx := index.NewInMemoryIndex()\n// ... registration and search ...\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#common-migration-issues","title":"Common Migration Issues","text":""},{"location":"library-docs-from-repos/tooldiscovery/migration/#tool-id-format","title":"Tool ID Format","text":"<p>tooldiscovery uses <code>namespace:name</code> format for tool IDs:</p> <pre><code>// Tool with namespace \"git\" and name \"status\"\ntoolID := \"git:status\"\n\n// Tool without namespace\ntoolID := \"simple_tool\"\n</code></pre> <p>Ensure your code handles both formats.</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#search-result-differences","title":"Search Result Differences","text":"<p>tooldiscovery's BM25 search may return different results than simple substring matching. Tune the <code>BM25Config</code> to match your expected behavior:</p> <pre><code>// For behavior closer to substring matching\nsearcher := search.NewBM25Searcher(search.BM25Config{\n    NameBoost:      5,  // Strongly prefer name matches\n    NamespaceBoost: 1,\n    TagsBoost:      1,\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#backend-selection","title":"Backend Selection","text":"<p>If you have multiple backends per tool, customize the selector:</p> <pre><code>idx := index.NewInMemoryIndex(index.IndexOptions{\n    BackendSelector: func(backends []model.ToolBackend) model.ToolBackend {\n        // Your custom logic\n        for _, b := range backends {\n            if b.Kind == model.BackendKindLocal {\n                return b // Prefer local backends\n            }\n        }\n        return backends[0]\n    },\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/","title":"Performance Tuning Guide","text":"<p>This guide covers performance characteristics and tuning options for tooldiscovery.</p>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#search-strategy-selection","title":"Search Strategy Selection","text":"<p>Choose the right search strategy based on your needs:</p> Strategy Speed Quality Dependencies Use When Lexical (built-in) Fastest Basic None Simple substring matching BM25 Fast Good Bleve Production text search Embedding Slow Best Embedder Semantic similarity needed Hybrid Medium Best Embedder Balance of speed and quality"},{"location":"library-docs-from-repos/tooldiscovery/performance/#recommendation-by-corpus-size","title":"Recommendation by Corpus Size","text":"Corpus Size Recommended Strategy Rationale &lt; 100 tools Lexical or BM25 Low overhead, fast enough 100-1000 tools BM25 Good balance of speed and quality 1000+ tools BM25 or Hybrid May benefit from semantic ranking"},{"location":"library-docs-from-repos/tooldiscovery/performance/#bm25-configuration","title":"BM25 Configuration","text":""},{"location":"library-docs-from-repos/tooldiscovery/performance/#field-boost-values","title":"Field Boost Values","text":"<p>The <code>BM25Config</code> controls how different fields affect ranking:</p> <pre><code>searcher := search.NewBM25Searcher(search.BM25Config{\n    NameBoost:      3,  // Name matches are 3x more important\n    NamespaceBoost: 2,  // Namespace matches are 2x\n    TagsBoost:      2,  // Tag matches are 2x\n})\n</code></pre> <p>Guidelines: - Higher <code>NameBoost</code> (3-5): Prefer exact tool name matches - Higher <code>TagsBoost</code> (2-3): Prefer keyword/category matches - Higher <code>NamespaceBoost</code> (2-3): Group related tools together</p>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#corpus-size-limits","title":"Corpus Size Limits","text":"<p>For very large corpora, use limits to control memory:</p> <pre><code>searcher := search.NewBM25Searcher(search.BM25Config{\n    MaxDocs:       5000,  // Limit indexed documents\n    MaxDocTextLen: 1000,  // Truncate long descriptions\n})\n</code></pre> <p>Trade-offs: - <code>MaxDocs</code>: Older documents may be excluded from search - <code>MaxDocTextLen</code>: Long descriptions truncated (may miss relevant terms)</p>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#benchmark-results","title":"Benchmark Results","text":"<p>Representative benchmarks on Apple M4 Max (run with <code>go test -bench=.</code>):</p>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#index-operations","title":"Index Operations","text":"Operation Corpus Size Time/Op Notes RegisterTool N/A ~900ns Single tool registration RegisterTool (sequential) Growing ~1.5\u03bcs With index growth GetTool 1000 ~110ns Hash map lookup ListNamespaces 1000 ~210ns Set iteration"},{"location":"library-docs-from-repos/tooldiscovery/performance/#search-operations","title":"Search Operations","text":"Operation Corpus Size Time/Op Notes Search (lexical) 1000 ~80\u03bcs Built-in searcher Search (BM25 cold) 1000 ~52ms First search, builds index Search (BM25 warm) 1000 ~580\u03bcs Cached index Search (BM25) 100 ~7\u03bcs Small corpus Search (BM25) 500 ~49\u03bcs Medium corpus Search (BM25) 2000 ~1.2ms Large corpus"},{"location":"library-docs-from-repos/tooldiscovery/performance/#semantic-operations","title":"Semantic Operations","text":"Operation Corpus Size Time/Op Notes BM25 Strategy Score 1 ~700ns Per document Embedding Strategy Score 1 ~1\u03bcs Per document (mock embedder) Hybrid Search 1000 ~1.9ms With mock embedder"},{"location":"library-docs-from-repos/tooldiscovery/performance/#documentation-operations","title":"Documentation Operations","text":"Operation Detail Level Time/Op Notes DescribeTool Summary ~250ns Minimal data DescribeTool Schema ~260ns With schema info DescribeTool Full ~250ns All details ListExamples N/A ~215ns Example retrieval"},{"location":"library-docs-from-repos/tooldiscovery/performance/#optimization-strategies","title":"Optimization Strategies","text":""},{"location":"library-docs-from-repos/tooldiscovery/performance/#1-warm-up-bm25-index","title":"1. Warm Up BM25 Index","text":"<p>The BM25 searcher builds its Bleve index on first search. Warm it up at startup:</p> <pre><code>func warmupSearcher(idx *index.InMemoryIndex) {\n    // Trigger index build with empty query\n    _, _ = idx.Search(\"\", 1)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#2-batch-tool-registration","title":"2. Batch Tool Registration","text":"<p>Use <code>RegisterTools</code> for batch registration instead of individual calls:</p> <pre><code>// Slower: individual registrations\nfor _, tool := range tools {\n    idx.RegisterTool(tool, backend)\n}\n\n// Faster: batch registration\nregs := make([]index.ToolRegistration, len(tools))\nfor i, tool := range tools {\n    regs[i] = index.ToolRegistration{Tool: tool, Backend: backend}\n}\nidx.RegisterTools(regs)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#3-cache-embeddings","title":"3. Cache Embeddings","text":"<p>For hybrid search, cache embeddings to avoid repeated API calls:</p> <pre><code>type CachedEmbedder struct {\n    embedder semantic.Embedder\n    cache    sync.Map\n}\n\nfunc (e *CachedEmbedder) Embed(ctx context.Context, text string) ([]float32, error) {\n    if vec, ok := e.cache.Load(text); ok {\n        return vec.([]float32), nil\n    }\n    vec, err := e.embedder.Embed(ctx, text)\n    if err != nil {\n        return nil, err\n    }\n    e.cache.Store(text, vec)\n    return vec, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#4-use-progressive-disclosure","title":"4. Use Progressive Disclosure","text":"<p>Fetch only the detail level you need:</p> <pre><code>// For search result display - use Summary (cheapest)\nfor _, r := range results {\n    summary, _ := store.DescribeTool(r.ID, tooldoc.DetailSummary)\n    displayResult(summary.Summary)\n}\n\n// Only fetch Full when user selects a tool\nfull, _ := store.DescribeTool(selectedID, tooldoc.DetailFull)\ndisplayFullDoc(full)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#5-limit-search-results","title":"5. Limit Search Results","text":"<p>Always specify a reasonable limit:</p> <pre><code>// Good: limited results\nresults, _ := idx.Search(query, 10)\n\n// Bad: potentially returns entire corpus\nresults, _ := idx.Search(query, 1000000)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#6-use-pagination-for-large-result-sets","title":"6. Use Pagination for Large Result Sets","text":"<pre><code>var allResults []index.Summary\ncursor := \"\"\n\nfor {\n    page, nextCursor, err := idx.SearchPage(query, 50, cursor)\n    if err != nil {\n        break\n    }\n    allResults = append(allResults, page...)\n    if nextCursor == \"\" {\n        break\n    }\n    cursor = nextCursor\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#memory-considerations","title":"Memory Considerations","text":""},{"location":"library-docs-from-repos/tooldiscovery/performance/#index-memory-usage","title":"Index Memory Usage","text":"<p>Approximate memory per tool: - <code>InMemoryIndex</code>: ~500 bytes (tool metadata + search doc) - <code>BM25Searcher</code>: +200-500 bytes (Bleve index entry) - <code>tooldoc.InMemoryStore</code>: +100-500 bytes (documentation)</p> <p>Estimate: ~1KB per tool with full documentation</p>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#search-doc-caching","title":"Search Doc Caching","text":"<p>The index caches search documents. This is rebuilt when: - New tools are registered - Tools are updated - Backends are removed - <code>Refresh()</code> is called</p> <p>Force a refresh if you need immediate consistency:</p> <pre><code>idx.Refresh() // Rebuilds search doc cache\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#profiling","title":"Profiling","text":"<p>Use Go's built-in profiling to identify bottlenecks:</p> <pre><code>import _ \"net/http/pprof\"\n\nfunc main() {\n    go func() {\n        log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n    }()\n    // ... your code ...\n}\n</code></pre> <p>Then profile with:</p> <pre><code># CPU profile\ngo tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n\n# Memory profile\ngo tool pprof http://localhost:6060/debug/pprof/heap\n\n# Goroutine profile\ngo tool pprof http://localhost:6060/debug/pprof/goroutine\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#running-benchmarks","title":"Running Benchmarks","text":"<pre><code># Run all benchmarks\ngo test ./... -bench=. -benchmem\n\n# Run specific package benchmarks\ngo test ./index -bench=. -benchmem\ngo test ./search -bench=. -benchmem\ngo test ./semantic -bench=. -benchmem\n\n# Run with longer duration for stable results\ngo test ./... -bench=. -benchtime=5s\n\n# Save baseline for comparison\ngo test ./... -bench=. &gt; benchmark_baseline.txt\n\n# Compare after changes\ngo test ./... -bench=. &gt; benchmark_new.txt\nbenchstat benchmark_baseline.txt benchmark_new.txt\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/","title":"registry","text":"<p>High-level helpers for building MCP servers with tool discovery, registration, local execution, and MCP backend aggregation. The registry composes:</p> <ul> <li><code>toolfoundation/model</code> (tool schema + validation)</li> <li><code>tooldiscovery/index</code> (registry + lookup)</li> <li><code>tooldiscovery/search</code> (BM25 search)</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#goals","title":"Goals","text":"<ul> <li>Provide a fast path to a working MCP server.</li> <li>Keep tool discovery and tool execution in a single, minimal API.</li> <li>Support local tools and federated MCP backends.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#package-overview","title":"Package Overview","text":"<pre><code>registry/\n\u251c\u2500\u2500 registry.go   # Core Registry type and lifecycle\n\u251c\u2500\u2500 handler.go    # Local tool handler and registration helpers\n\u251c\u2500\u2500 backend.go    # MCP backend connections\n\u251c\u2500\u2500 mcp.go        # MCP JSON-RPC request/response handling\n\u251c\u2500\u2500 server.go     # ServeStdio, ServeHTTP, ServeSSE\n\u2514\u2500\u2500 errors.go     # Sentinel errors + MCP error codes\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#core-types","title":"Core Types","text":"<pre><code>// Config configures a Registry.\ntype Config struct {\n    SearchConfig    *search.BM25Config\n    ServerInfo      ServerInfo\n    BackendSelector index.BackendSelector\n}\n\n// ServerInfo describes this MCP server for initialize response.\ntype ServerInfo struct {\n    Name    string\n    Version string\n}\n\n// Registry is a high-level MCP tool registry.\ntype Registry struct { /* ... */ }\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#local-tools","title":"Local Tools","text":"<pre><code>reg := registry.New(registry.Config{\n    ServerInfo: registry.ServerInfo{\n        Name:    \"my-mcp\",\n        Version: \"1.0.0\",\n    },\n})\n\nreg.RegisterLocalFunc(\n    \"echo\",\n    \"Echoes back input\",\n    map[string]any{\n        \"type\": \"object\",\n        \"properties\": map[string]any{\n            \"message\": map[string]any{\"type\": \"string\"},\n        },\n        \"required\": []string{\"message\"},\n    },\n    func(ctx context.Context, args map[string]any) (any, error) {\n        return map[string]any{\"echo\": args[\"message\"]}, nil\n    },\n    registry.WithNamespace(\"utility\"),\n    registry.WithTags(\"echo\", \"debug\"),\n)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#mcp-backends","title":"MCP Backends","text":"<p>Backends allow the registry to aggregate tools from other MCP servers.</p> <pre><code>err := reg.RegisterMCP(registry.BackendConfig{\n    Name: \"remote-tools\",\n    URL:  \"https://example.com/mcp\",\n    Headers: map[string]string{\n        \"Authorization\": \"Bearer ...\",\n    },\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#backendconfig","title":"BackendConfig","text":"<pre><code>type BackendConfig struct {\n    Name          string\n    URL           string\n    Headers       map[string]string\n    MaxRetries    int\n    RetryInterval time.Duration\n    Transport     mcp.Transport // optional override\n}\n</code></pre> <ul> <li><code>URL</code> supports <code>http(s)://</code> (streamable HTTP), <code>sse://</code> (legacy SSE), and   <code>stdio://</code> (stdio transport bound to the current process).</li> <li><code>Headers</code> are injected into HTTP requests.</li> <li><code>Transport</code> is useful for tests or custom transports (e.g. in-memory).</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#execution","title":"Execution","text":"<pre><code>result, err := reg.Execute(ctx, \"utility:echo\", map[string]any{\"message\": \"hi\"})\n</code></pre> <p>Execution routing:</p> <ol> <li>Tool lookup in <code>index</code></li> <li>Backend selection via <code>BackendSelector</code></li> <li>Local handler or MCP backend call</li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#result-mapping","title":"Result Mapping","text":"<p>When calling an MCP backend:</p> <ul> <li><code>StructuredContent</code> is returned when available</li> <li>single <code>TextContent</code> returns a string</li> <li>otherwise, the full <code>[]mcp.Content</code> is returned</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#mcp-protocol-handling","title":"MCP Protocol Handling","text":"<p>The registry handles MCP JSON-RPC methods:</p> <ul> <li><code>initialize</code></li> <li><code>tools/list</code></li> <li><code>tools/call</code></li> </ul> <p>These are exposed via <code>ServeStdio</code>, <code>ServeHTTP</code>, or <code>ServeSSE</code>.</p>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#transports","title":"Transports","text":"<pre><code>// Stdio\n_ = registry.ServeStdio(ctx, reg)\n\n// HTTP (streamable)\nhttp.Handle(\"/mcp\", registry.ServeHTTP(reg))\n\n// SSE (legacy)\nhttp.Handle(\"/mcp-sse\", registry.ServeSSE(reg))\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#lifecycle","title":"Lifecycle","text":"<pre><code>if err := reg.Start(ctx); err != nil {\n    log.Fatal(err)\n}\ndefer reg.Stop()\n</code></pre> <ul> <li><code>Start</code> connects registered MCP backends and registers their tools</li> <li><code>Stop</code> closes backend sessions</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#errors","title":"Errors","text":"<p>Registry returns sentinel errors from <code>errors.go</code>:</p> <ul> <li><code>ErrNotStarted</code></li> <li><code>ErrAlreadyStarted</code></li> <li><code>ErrToolNotFound</code></li> <li><code>ErrBackendNotFound</code></li> <li><code>ErrHandlerNotFound</code></li> <li><code>ErrExecutionFailed</code></li> <li><code>ErrInvalidRequest</code></li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#diagram","title":"Diagram","text":"<pre><code>flowchart LR\n    Local[\"Local handlers\"] --&gt; Registry\n    MCP[\"MCP backends\"] --&gt; Registry\n    Registry --&gt; Index\n    Index --&gt; Search\n    Registry --&gt;|ServeStdio / ServeHTTP / ServeSSE| Transports</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/","title":"Schemas and Data Contracts","text":"<p>tooldiscovery does not define new JSON Schemas for tool input/output. Those come from toolfoundation/model.Tool and are treated as opaque, validated payloads. What tooldiscovery does define are the data contracts that shape discovery, documentation, and search outputs.</p> <p>This page documents those contracts, their constraints, and how they relate to the underlying tool schemas.</p>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#canonical-tool-schema-dependency","title":"Canonical tool schema dependency","text":"<ul> <li><code>model.Tool</code> is the canonical tool record (from toolfoundation).</li> <li><code>InputSchema</code> is required; <code>OutputSchema</code> is optional.</li> <li>tooldiscovery never mutates schemas \u2014 it passes them through for   describe or execution flows.</li> </ul> <p>If you need the JSON Schema contracts, see the toolfoundation schema docs.</p>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#summary-schema-indexsummary","title":"Summary schema (index.Summary)","text":"<p><code>Summary</code> is the minimal discovery payload returned from search and list calls.</p> <p>Fields:</p> Field Type Notes <code>id</code> string Canonical tool ID (<code>namespace:name</code> or <code>name</code>) <code>name</code> string Tool name <code>namespace</code> string Optional namespace <code>shortDescription</code> string Truncated to 120 chars <code>tags</code> []string Normalized tags <p>Constraints:</p> <ul> <li><code>shortDescription</code> is capped by <code>index.MaxShortDescriptionLen</code> (120).</li> <li><code>tags</code> are normalized and deduplicated by the index.</li> <li><code>Summary</code> never includes schemas.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#searchdoc-schema-indexsearchdoc","title":"SearchDoc schema (index.SearchDoc)","text":"<p><code>SearchDoc</code> is the internal/searcher payload used to score results.</p> <p>Fields:</p> Field Type Notes <code>ID</code> string Canonical tool ID <code>DocText</code> string Lowercased concatenation of name, namespace, description, tags <code>Summary</code> Summary Prebuilt summary returned to callers <p>Contracts:</p> <ul> <li><code>DocText</code> must be deterministic for the same tool.</li> <li><code>SearchDoc</code> is read-only for searchers; mutating it is forbidden.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#documentation-schema-tooldoctooldoc","title":"Documentation schema (tooldoc.ToolDoc)","text":"<p><code>ToolDoc</code> is the progressive documentation payload returned by <code>tooldoc.Store</code>.</p> <p>Fields:</p> Field Type Notes <code>tool</code> *model.Tool Present for <code>schema</code>/<code>full</code> levels <code>summary</code> string Capped at 200 chars <code>schemaInfo</code> *SchemaInfo Derived from input schema <code>notes</code> string Capped at 2000 chars <code>examples</code> []ToolExample Optional usage examples <code>externalRefs</code> []string URLs or resource IDs"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#schemainfo","title":"SchemaInfo","text":"<p>Derived from a tool\u2019s InputSchema (best effort):</p> Field Type Notes <code>required</code> []string Required parameter names <code>defaults</code> map[string]any Default values <code>types</code> map[string][]string Allowed types by param"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#toolexample","title":"ToolExample","text":"<p>Usage examples are bounded to prevent context bloat:</p> <ul> <li><code>Description</code> max 300 chars</li> <li><code>ResultHint</code> max 200 chars</li> <li><code>Args</code> capped at depth 5 and size 50 (keys + items)</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#detail-levels-tooldocdetaillevel","title":"Detail levels (tooldoc.DetailLevel)","text":"Level Contents <code>summary</code> Summary only <code>schema</code> Summary + tool + schema info <code>full</code> Schema + notes + examples + external refs"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#discovery-results-discoveryresult","title":"Discovery results (discovery.Result)","text":"<p>The discovery facade wraps summaries with scoring metadata:</p> Field Type Notes <code>summary</code> Summary Tool metadata <code>score</code> float64 Relevance score <code>scoreType</code> string <code>bm25</code>, <code>embedding</code>, or <code>hybrid</code>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#semantic-document-contract-semanticdocument","title":"Semantic document contract (semantic.Document)","text":"<p>Semantic search operates on normalized <code>Document</code> payloads:</p> Field Type Notes <code>id</code> string Canonical tool ID <code>namespace</code> string Optional <code>name</code> string Tool name <code>description</code> string Short description <code>tags</code> []string Lowercased + sorted <code>category</code> string Optional category <code>text</code> string Normalized search text <p><code>Document.Normalized()</code> lowercases and sorts tags and builds <code>text</code>.</p>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#json-schema-guidance","title":"JSON Schema guidance","text":"<p>For JSON Schema input/output contract details, reference:</p> <ul> <li>toolfoundation schema docs</li> <li><code>model.Tool</code> in toolfoundation/model</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/","title":"tooldiscovery User Journey","text":""},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#overview","title":"Overview","text":"<p>This guide walks through the progressive disclosure pattern that tooldiscovery enables: discover cheaply, inspect on-demand, then execute.</p>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#1-installation","title":"1. Installation","text":"<pre><code>go get github.com/jonwraymond/tooldiscovery@latest\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#2-set-up-the-index","title":"2. Set Up the Index","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/index\"\n\n// Create an in-memory index\nidx := index.NewInMemoryIndex()\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#3-register-tools","title":"3. Register Tools","text":"<pre><code>import \"github.com/jonwraymond/toolfoundation/model\"\n\n// Create and validate a tool\ntool := model.Tool{\n  Namespace: \"github\",\n  Tool: mcp.Tool{\n    Name:        \"create_issue\",\n    Description: \"Create a new GitHub issue\",\n    InputSchema: map[string]any{...},\n  },\n}\n\n// Define the backend\nbackend := model.ToolBackend{\n  Kind:       model.BackendKindMCP,\n  ServerName: \"github-mcp\",\n}\n\n// Register\nerr := idx.RegisterTool(tool, backend)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#4-search-for-tools-token-cheap","title":"4. Search for Tools (Token-Cheap)","text":"<pre><code>// Search returns summaries without schemas\nsummaries, err := idx.Search(\"create issue\", 5)\nif err != nil {\n  log.Fatal(err)\n}\n\nfor _, s := range summaries {\n  fmt.Printf(\"Found: %s - %s\\n\", s.ID, s.ShortDescription)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#5-get-full-documentation-on-demand","title":"5. Get Full Documentation (On-Demand)","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n\nstore := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n// Progressive detail levels\ndoc, _ := store.GetDoc(\"github:create_issue\", tooldoc.DetailSummary)\nfmt.Println(doc.Summary)\n\ndoc, _ = store.GetDoc(\"github:create_issue\", tooldoc.DetailSchema)\nfmt.Printf(\"Input Schema: %v\\n\", doc.Tool.InputSchema)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#detail-level-guidance","title":"Detail Level Guidance","text":"<ul> <li>Summary: listing/search results (token-cheap)</li> <li>Schema: just-in-time execution</li> <li>Full: documentation view or export</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#6-enable-bm25-search-optional","title":"6. Enable BM25 Search (Optional)","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/search\"\n\n// Create BM25 searcher with custom config\nconfig := search.Config{\n  NameBoost:      4.0,\n  NamespaceBoost: 2.0,\n  TagBoost:       1.0,\n}\n\nsearcher, err := search.NewBM25Searcher(config)\nif err != nil {\n  log.Fatal(err)\n}\ndefer searcher.Close()\n\n// Create index with BM25 strategy\nidx := index.NewInMemoryIndex(index.WithSearchStrategy(searcher))\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#7-list-namespaces","title":"7. List Namespaces","text":"<pre><code>namespaces := idx.ListNamespaces()\n// [\"github\", \"slack\", \"jira\", ...]\n\n// Filter tools by namespace\ntools := idx.ListToolsInNamespace(\"github\")\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#progressive-disclosure-flow","title":"Progressive Disclosure Flow","text":"<pre><code>Agent                    MCP Server              tooldiscovery\n  |                          |                        |\n  |-- search_tools(\"issue\") -|                        |\n  |                          |-- idx.Search() --------|\n  |                          |&lt;-- []Summary ----------|\n  |&lt;- summaries (no schema) -|                        |\n  |                          |                        |\n  |-- describe_tool(id) -----|                        |\n  |                          |-- store.GetDoc() -----|\n  |                          |&lt;-- ToolDoc w/schema ---|\n  |&lt;-- full schema ----------|                        |\n  |                          |                        |\n  |-- run_tool(id, args) ----|                        |\n  |                          |      (to toolexec)     |\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Execute tools with toolexec/run</li> <li>Expose via MCP with metatools-mcp</li> </ul>"},{"location":"library-docs-from-repos/toolexec/","title":"toolexec","text":"<p>Execution layer providing tool running, code orchestration, and runtime isolation for the ApertureStack tool framework.</p>"},{"location":"library-docs-from-repos/toolexec/#packages","title":"Packages","text":"Package Purpose <code>exec</code> Unified facade - combines discovery + execution into single API <code>run</code> Core tool execution engine with validation <code>code</code> Code-based tool orchestration for sandboxed execution <code>runtime</code> Sandbox and runtime isolation with security profiles <code>backend</code> Backend registry and resolution"},{"location":"library-docs-from-repos/toolexec/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolexec@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/#quick-start","title":"Quick Start","text":""},{"location":"library-docs-from-repos/toolexec/#using-the-unified-facade-recommended","title":"Using the Unified Facade (Recommended)","text":"<pre><code>import (\n    \"github.com/jonwraymond/toolexec/exec\"\n    \"github.com/jonwraymond/tooldiscovery/index\"\n    \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n)\n\n// Setup discovery infrastructure\nidx := index.NewInMemoryIndex()\ndocs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n// Create executor with local handlers\nexecutor, err := exec.New(exec.Options{\n    Index: idx,\n    Docs:  docs,\n    LocalHandlers: map[string]exec.Handler{\n        \"math-add\": func(ctx context.Context, args map[string]any) (any, error) {\n            a, b := args[\"a\"].(float64), args[\"b\"].(float64)\n            return a + b, nil\n        },\n    },\n})\n\n// Execute a tool\nresult, err := executor.RunTool(ctx, \"math:add\", map[string]any{\"a\": 5, \"b\": 3})\nfmt.Println(result.Value) // 8\n\n// Search for tools\nresults, _ := executor.SearchTools(ctx, \"calculator\", 10)\n\n// Chain tools together\nchainResult, steps, _ := executor.RunChain(ctx, []exec.Step{\n    {ToolID: \"text:format\", Args: map[string]any{\"text\": \"hello\", \"style\": \"upper\"}},\n    {ToolID: \"text:analyze\", Args: map[string]any{}, UsePrevious: true},\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/#using-the-run-package-directly","title":"Using the Run Package Directly","text":"<pre><code>import \"github.com/jonwraymond/toolexec/run\"\n\n// Create runner with index\nrunner := run.NewRunner(run.WithIndex(idx))\n\n// Execute a tool\nresult, err := runner.Run(ctx, \"github:create_issue\", map[string]any{\n    \"owner\": \"jonwraymond\",\n    \"repo\":  \"toolexec\",\n    \"title\": \"New issue\",\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/#register-a-local-backend","title":"Register a Local Backend","text":"<pre><code>import \"github.com/jonwraymond/toolexec/backend/local\"\n\nbackend := local.New(\"math\")\nbackend.RegisterHandler(\"add\", local.ToolDef{\n    Name:        \"add\",\n    Description: \"Adds two numbers\",\n    Handler: func(ctx context.Context, args map[string]any) (any, error) {\n        a, b := args[\"a\"].(float64), args[\"b\"].(float64)\n        return a + b, nil\n    },\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/#key-features","title":"Key Features","text":"<ul> <li>Unified Facade: Single API for discovery, execution, and documentation</li> <li>Schema Validation: Input and output validated against tool schemas</li> <li>Backend Abstraction: Execute local, provider, or MCP server backends</li> <li>Tool Chaining: Chain multiple tool calls with <code>UsePrevious</code> result passing</li> <li>Security Profiles: Dev, Standard, and Hardened isolation levels</li> <li>Runtime Isolation: Sandbox untrusted code with Docker, gVisor, or WASM</li> </ul>"},{"location":"library-docs-from-repos/toolexec/#examples","title":"Examples","text":"<p>See examples for runnable walkthroughs.</p>"},{"location":"library-docs-from-repos/toolexec/#links","title":"Links","text":"<ul> <li>Architecture</li> <li>Schemas and contracts</li> <li>Design notes</li> <li>User journey</li> <li>ai-tools-stack documentation</li> </ul>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/","title":"toolexec Architecture Improvement Plan","text":"<p>\u2705 COMPLETED: This plan was fully implemented on 2026-02-01. All phases completed: exec/ facade, examples, example tests, coverage improvements, documentation. See CHANGELOG.md for details.</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#executive-summary","title":"Executive Summary","text":"<p>Architectural review and improvement plan for the toolexec submodule, focusing on better integration with toolfoundation and tooldiscovery, comprehensive examples, and coverage improvements.</p> <p>Current State: 18 packages, 62-94% coverage Dependencies: toolfoundation v0.2.0, tooldiscovery v0.2.1</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#1-current-architecture-overview","title":"1. Current Architecture Overview","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#package-dependency-graph","title":"Package Dependency Graph","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         EXTERNAL DEPENDENCIES                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  toolfoundation                    tooldiscovery                     \u2502\n\u2502  \u251c\u2500\u2500 model.Tool                    \u251c\u2500\u2500 index.Index                   \u2502\n\u2502  \u251c\u2500\u2500 model.ToolBackend             \u251c\u2500\u2500 search.BM25Searcher           \u2502\n\u2502  \u2514\u2500\u2500 model.SchemaValidator         \u2514\u2500\u2500 tooldoc.Store                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           toolexec                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502   \u2502   backend/   \u2502      \u2502     run/     \u2502      \u2502    code/     \u2502      \u2502\n\u2502   \u2502              \u2502      \u2502              \u2502      \u2502              \u2502      \u2502\n\u2502   \u2502 \u2022 Backend    \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2502 \u2022 Runner     \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2502 \u2022 Executor   \u2502      \u2502\n\u2502   \u2502 \u2022 Registry   \u2502      \u2502 \u2022 dispatch   \u2502      \u2502 \u2022 Engine     \u2502      \u2502\n\u2502   \u2502 \u2022 Aggregator \u2502      \u2502 \u2022 resolve    \u2502      \u2502 \u2022 Tools      \u2502      \u2502\n\u2502   \u2502 \u2022 local/     \u2502      \u2502 \u2022 normalize  \u2502      \u2502 \u2022 Config     \u2502      \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502          \u2502                     \u2502                     \u2502               \u2502\n\u2502          \u2502                     \u2502                     \u25bc               \u2502\n\u2502          \u2502                     \u2502            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502          \u2502                     \u2502            \u2502   runtime/   \u2502         \u2502\n\u2502          \u2502                     \u2502            \u2502              \u2502         \u2502\n\u2502          \u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 \u2022 Runtime    \u2502         \u2502\n\u2502          \u2502                                  \u2502 \u2022 Backend    \u2502         \u2502\n\u2502          \u2502                                  \u2502 \u2022 Gateway    \u2502         \u2502\n\u2502          \u2502                                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502          \u2502                                         \u2502                 \u2502\n\u2502          \u2502                                         \u25bc                 \u2502\n\u2502          \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502          \u2502              \u2502         runtime/backend/               \u2502   \u2502\n\u2502          \u2502              \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2502          \u2502              \u2502 unsafe \u2502 docker \u2502 wasm \u2502 gvisor \u2502 ...  \u2502   \u2502\n\u2502          \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502          \u2502                                         \u2502                 \u2502\n\u2502          \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502          \u2502              \u2502         runtime/gateway/               \u2502   \u2502\n\u2502          \u2502              \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2502          \u2502              \u2502         direct    \u2502    proxy           \u2502   \u2502\n\u2502          \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502          \u2502                                                           \u2502\n\u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\n\u2502                                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#execution-flow","title":"Execution Flow","text":"<pre><code>User Code Request\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 code.Executor   \u2502 \u2500\u2500 Orchestrates execution with limits\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 code.Engine     \u2502 \u2500\u2500 Pluggable language runtime (Go, Python, etc.)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 runtime/toolcodeengine      \u2502 \u2500\u2500 Adapter: code.Engine \u2192 runtime.Backend\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 runtime.Runtime \u2502 \u2500\u2500 Routes by security profile\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510\n    \u25bc         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502unsafe \u2502 \u2502docker \u2502 ... (10 backend implementations)\n\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n    \u2502         \u2502\n    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 runtime.Gateway \u2502 \u2500\u2500 Tool access from sandbox\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 run.Runner      \u2502 \u2500\u2500 Tool execution pipeline\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u25bc         \u25bc        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  MCP  \u2502 \u2502Provider\u2502 \u2502 Local \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#2-identified-gaps","title":"2. Identified Gaps","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#21-coverage-gaps","title":"2.1 Coverage Gaps","text":"Package Current Target Gap Analysis <code>backend/</code> 67.0% 90%+ Registry lifecycle, concurrent access <code>backend/local/</code> 62.9% 90%+ Handler edge cases, error paths <code>code/</code> 72.6% 90%+ Limit enforcement, timeout handling <code>runtime/gateway/proxy/</code> 68.4% 85%+ Connection failures, codec errors <code>run/</code> ~75% 90%+ Chain execution, streaming"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#22-documentation-gaps","title":"2.2 Documentation Gaps","text":"Gap Severity Description Empty examples/ High No runnable examples showing integration Missing architecture doc High No high-level overview of package relationships Interface contracts Medium Some contracts lack error semantics Migration guide Low No guide from direct usage to facades"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#23-integration-gaps","title":"2.3 Integration Gaps","text":"Gap Description No unified facade Users must understand 4+ packages to use toolexec Bridge patterns unclear How tooldiscovery \u2192 toolexec \u2192 runtime flows Backend selection logic No documented strategy for profile \u2192 backend mapping"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#3-improvement-plan","title":"3. Improvement Plan","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#phase-1-unified-facade-package-new","title":"Phase 1: Unified Facade Package (NEW)","text":"<p>Create a <code>toolexec/exec</code> package that provides a simplified entry point.</p> <pre><code>// exec/exec.go - Unified facade for tool execution\n\npackage exec\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/tooldiscovery/index\"\n    \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n    \"github.com/jonwraymond/toolexec/run\"\n    \"github.com/jonwraymond/toolexec/code\"\n    \"github.com/jonwraymond/toolexec/runtime\"\n)\n\n// Exec is the unified facade for tool execution.\n// It combines discovery, execution, and runtime management.\ntype Exec struct {\n    index   index.Index\n    docs    tooldoc.Store\n    runner  run.Runner\n    runtime runtime.Runtime\n    code    code.Executor\n}\n\n// Options configures an Exec instance.\ntype Options struct {\n    // Index provides tool discovery. Required.\n    Index index.Index\n\n    // Docs provides tool documentation. Required.\n    Docs tooldoc.Store\n\n    // SecurityProfile determines the runtime backend.\n    // Default: ProfileDev\n    SecurityProfile runtime.SecurityProfile\n\n    // EnableCodeExecution enables the code execution subsystem.\n    // Default: false (tool execution only)\n    EnableCodeExecution bool\n\n    // MaxToolCalls limits tool calls in code execution.\n    // Default: 100\n    MaxToolCalls int\n\n    // DefaultLanguage for code execution.\n    // Default: \"go\"\n    DefaultLanguage string\n}\n\n// New creates a new Exec instance.\nfunc New(opts Options) (*Exec, error)\n\n// RunTool executes a single tool by ID.\nfunc (e *Exec) RunTool(ctx context.Context, toolID string, args map[string]any) (Result, error)\n\n// RunChain executes a sequence of tools.\nfunc (e *Exec) RunChain(ctx context.Context, steps []Step) (Result, []StepResult, error)\n\n// ExecuteCode runs code with tool access.\nfunc (e *Exec) ExecuteCode(ctx context.Context, params CodeParams) (CodeResult, error)\n\n// SearchTools finds tools matching a query.\nfunc (e *Exec) SearchTools(ctx context.Context, query string, limit int) ([]ToolSummary, error)\n\n// GetToolDoc retrieves tool documentation.\nfunc (e *Exec) GetToolDoc(ctx context.Context, toolID string, level tooldoc.DetailLevel) (tooldoc.ToolDoc, error)\n</code></pre> <p>Files to create: - <code>exec/exec.go</code> - Main facade - <code>exec/result.go</code> - Unified result types - <code>exec/options.go</code> - Configuration and validation - <code>exec/exec_test.go</code> - Comprehensive tests - <code>exec/example_test.go</code> - pkg.go.dev examples - <code>exec/doc.go</code> - Package documentation</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#phase-2-comprehensive-examples","title":"Phase 2: Comprehensive Examples","text":"<p>Create runnable examples showing the full integration:</p> <pre><code>examples/\n\u251c\u2500\u2500 basic/\n\u2502   \u2514\u2500\u2500 main.go           # Simple tool execution\n\u251c\u2500\u2500 chain/\n\u2502   \u2514\u2500\u2500 main.go           # Sequential tool chaining\n\u251c\u2500\u2500 code/\n\u2502   \u2514\u2500\u2500 main.go           # Code execution with tool access\n\u251c\u2500\u2500 discovery/\n\u2502   \u2514\u2500\u2500 main.go           # Search \u2192 Execute workflow\n\u251c\u2500\u2500 streaming/\n\u2502   \u2514\u2500\u2500 main.go           # Streaming tool execution\n\u251c\u2500\u2500 runtime/\n\u2502   \u2514\u2500\u2500 main.go           # Custom runtime configuration\n\u2514\u2500\u2500 full/\n    \u2514\u2500\u2500 main.go           # Complete integration example\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#examplesbasicmaingo","title":"examples/basic/main.go","text":"<pre><code>// Demonstrates basic tool execution with toolexec.\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"github.com/jonwraymond/tooldiscovery/index\"\n    \"github.com/jonwraymond/tooldiscovery/search\"\n    \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n    \"github.com/jonwraymond/toolexec/exec\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    // 1. Setup tool discovery (from tooldiscovery)\n    idx := index.NewInMemoryIndex(index.IndexOptions{\n        Searcher: search.NewBM25Searcher(search.BM25Config{\n            NameBoost: 3,\n            TagsBoost: 2,\n        }),\n    })\n    docs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n    // 2. Register a sample tool\n    tool := model.Tool{\n        Tool: mcp.Tool{\n            Name:        \"greet\",\n            Description: \"Greets a user by name\",\n            InputSchema: map[string]any{\n                \"type\": \"object\",\n                \"properties\": map[string]any{\n                    \"name\": map[string]any{\"type\": \"string\"},\n                },\n                \"required\": []any{\"name\"},\n            },\n        },\n        Namespace: \"demo\",\n    }\n\n    // Register with local handler\n    if err := idx.RegisterTool(tool, model.NewLocalBackend(\"greet-handler\")); err != nil {\n        log.Fatal(err)\n    }\n\n    // Add documentation\n    docs.RegisterDoc(\"demo:greet\", tooldoc.DocEntry{\n        Summary: \"Greets a user with a friendly message\",\n        Notes:   \"Returns a greeting string\",\n        Examples: []tooldoc.ToolExample{\n            {Title: \"Basic greeting\", Args: map[string]any{\"name\": \"World\"}},\n        },\n    })\n\n    // 3. Create executor with unified facade\n    executor, err := exec.New(exec.Options{\n        Index: idx,\n        Docs:  docs,\n        LocalHandlers: map[string]exec.Handler{\n            \"greet-handler\": func(ctx context.Context, args map[string]any) (any, error) {\n                name := args[\"name\"].(string)\n                return fmt.Sprintf(\"Hello, %s!\", name), nil\n            },\n        },\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // 4. Execute the tool\n    result, err := executor.RunTool(ctx, \"demo:greet\", map[string]any{\"name\": \"World\"})\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    fmt.Printf(\"Result: %v\\n\", result.Value)\n    // Output: Result: Hello, World!\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#examplesdiscoverymaingo","title":"examples/discovery/main.go","text":"<pre><code>// Demonstrates search \u2192 execute workflow combining tooldiscovery and toolexec.\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"github.com/jonwraymond/tooldiscovery/discovery\"\n    \"github.com/jonwraymond/toolexec/exec\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    // 1. Create discovery facade (from tooldiscovery)\n    disc, err := discovery.New(discovery.Options{})\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // 2. Register tools (simplified)\n    registerDemoTools(disc)\n\n    // 3. Create executor using discovery's index\n    executor, err := exec.New(exec.Options{\n        Index: disc.Index(),\n        Docs:  disc.DocStore(),\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // 4. Search for tools\n    results, err := disc.Search(ctx, \"file operations\", 5)\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    fmt.Printf(\"Found %d tools:\\n\", len(results))\n    for _, r := range results {\n        fmt.Printf(\"  - %s (score: %.2f)\\n\", r.Summary.ID, r.Score)\n    }\n\n    // 5. Execute the top result\n    if len(results) &gt; 0 {\n        topTool := results[0].Summary.ID\n        result, err := executor.RunTool(ctx, topTool, map[string]any{\n            \"path\": \"/tmp/example.txt\",\n        })\n        if err != nil {\n            log.Printf(\"Execution failed: %v\", err)\n            return\n        }\n        fmt.Printf(\"Executed %s: %v\\n\", topTool, result.Value)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#examplesfullmaingo","title":"examples/full/main.go","text":"<pre><code>// Complete integration example showing all layers working together.\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"time\"\n\n    // Foundation layer\n    \"github.com/jonwraymond/toolfoundation/model\"\n\n    // Discovery layer\n    \"github.com/jonwraymond/tooldiscovery/discovery\"\n    \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n\n    // Execution layer\n    \"github.com/jonwraymond/toolexec/exec\"\n    \"github.com/jonwraymond/toolexec/runtime\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // LAYER 1: Foundation (toolfoundation)\n    // Define tool types and schemas\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    tools := []struct {\n        tool    model.Tool\n        backend model.ToolBackend\n        doc     tooldoc.DocEntry\n        handler exec.Handler\n    }{\n        {\n            tool: model.Tool{\n                Tool: mcp.Tool{\n                    Name:        \"calculate\",\n                    Description: \"Performs basic arithmetic\",\n                    InputSchema: calculateSchema(),\n                },\n                Namespace: \"math\",\n                Tags:      []string{\"math\", \"calculator\"},\n            },\n            backend: model.NewLocalBackend(\"calc-handler\"),\n            doc: tooldoc.DocEntry{\n                Summary: \"Basic arithmetic operations\",\n                Notes:   \"Supports add, subtract, multiply, divide\",\n            },\n            handler: calculateHandler,\n        },\n        // ... more tools\n    }\n\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // LAYER 2: Discovery (tooldiscovery)\n    // Register and search for tools\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    disc, _ := discovery.New(discovery.Options{})\n\n    for _, t := range tools {\n        disc.RegisterTool(t.tool, t.backend, &amp;t.doc)\n    }\n\n    // Search demonstration\n    results, _ := disc.Search(ctx, \"arithmetic\", 10)\n    fmt.Printf(\"Discovery found %d tools for 'arithmetic'\\n\", len(results))\n\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // LAYER 3: Execution (toolexec)\n    // Execute tools with proper runtime management\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    handlers := make(map[string]exec.Handler)\n    for _, t := range tools {\n        handlers[t.backend.Local.Name] = t.handler\n    }\n\n    executor, _ := exec.New(exec.Options{\n        Index:           disc.Index(),\n        Docs:            disc.DocStore(),\n        LocalHandlers:   handlers,\n        SecurityProfile: runtime.ProfileDev,\n\n        // Code execution settings\n        EnableCodeExecution: true,\n        MaxToolCalls:        50,\n        DefaultLanguage:     \"go\",\n        DefaultTimeout:      30 * time.Second,\n    })\n\n    // Single tool execution\n    result, _ := executor.RunTool(ctx, \"math:calculate\", map[string]any{\n        \"operation\": \"add\",\n        \"a\":         10,\n        \"b\":         20,\n    })\n    fmt.Printf(\"10 + 20 = %v\\n\", result.Value)\n\n    // Chain execution\n    chainResult, steps, _ := executor.RunChain(ctx, []exec.Step{\n        {ToolID: \"math:calculate\", Args: map[string]any{\"operation\": \"add\", \"a\": 5, \"b\": 3}},\n        {ToolID: \"math:calculate\", Args: map[string]any{\"operation\": \"multiply\", \"a\": 0, \"b\": 2}, UsePrevious: true},\n    })\n    fmt.Printf(\"Chain result: %v (steps: %d)\\n\", chainResult.Value, len(steps))\n\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // LAYER 4: Code Execution (with tool access)\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    codeResult, _ := executor.ExecuteCode(ctx, exec.CodeParams{\n        Language: \"go\",\n        Code: `\n            // This code runs in a sandbox with tool access\n            result, _ := tools.Run(\"math:calculate\", map[string]any{\n                \"operation\": \"add\",\n                \"a\": 100,\n                \"b\": 200,\n            })\n            return result\n        `,\n        Timeout: 10 * time.Second,\n    })\n    fmt.Printf(\"Code execution result: %v\\n\", codeResult.Value)\n    fmt.Printf(\"Tool calls made: %d\\n\", len(codeResult.ToolCalls))\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#phase-3-example-tests-pkggodev","title":"Phase 3: Example Tests (pkg.go.dev)","text":"<p>Create example tests for each core package:</p> <p>Files to create: - <code>run/example_test.go</code> - Runner examples - <code>code/example_test.go</code> - Executor examples - <code>backend/example_test.go</code> - Backend/registry examples - <code>runtime/example_test.go</code> - Runtime examples - <code>exec/example_test.go</code> - Unified facade examples</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#phase-4-coverage-improvements","title":"Phase 4: Coverage Improvements","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#backend-67-90","title":"backend/ (67% \u2192 90%+)","text":"<p>Add tests for: - Registry concurrent access - Backend lifecycle (Start/Stop) - Aggregator with multiple backends - Error paths (backend unavailable, tool not found)</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#backendlocal-629-90","title":"backend/local/ (62.9% \u2192 90%+)","text":"<p>Add tests for: - Handler registration/unregistration - Concurrent handler execution - Panic recovery in handlers - Context cancellation</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#code-726-90","title":"code/ (72.6% \u2192 90%+)","text":"<p>Add tests for: - MaxToolCalls enforcement - MaxChainSteps enforcement - Timeout handling - Engine error propagation</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#runtimegatewayproxy-684-85","title":"runtime/gateway/proxy/ (68.4% \u2192 85%+)","text":"<p>Add tests for: - Connection failures - Codec errors - Timeout scenarios - Large payload handling</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#phase-5-documentation","title":"Phase 5: Documentation","text":"<p>Files to create: - <code>docs/architecture.md</code> - Package hierarchy and data flow - <code>docs/integration.md</code> - How to integrate with tooldiscovery - <code>docs/security-profiles.md</code> - Runtime security configuration - <code>docs/error-handling.md</code> - Error types and handling patterns - <code>docs/migration.md</code> - Upgrading from direct package usage</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#4-integration-patterns","title":"4. Integration Patterns","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#pattern-1-discovery-execution","title":"Pattern 1: Discovery \u2192 Execution","text":"<pre><code>// Search for tools, then execute\ndisc, _ := discovery.New(discovery.Options{})\nexec, _ := exec.New(exec.Options{Index: disc.Index(), Docs: disc.DocStore()})\n\nresults, _ := disc.Search(ctx, \"query\", 10)\nfor _, r := range results {\n    result, _ := exec.RunTool(ctx, r.Summary.ID, args)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#pattern-2-code-with-tool-access","title":"Pattern 2: Code with Tool Access","text":"<pre><code>// Execute code that can call tools\nexec, _ := exec.New(exec.Options{\n    Index: idx,\n    Docs:  docs,\n    EnableCodeExecution: true,\n})\n\nresult, _ := exec.ExecuteCode(ctx, exec.CodeParams{\n    Code: `tools.Run(\"ns:tool\", args)`,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#pattern-3-chain-execution","title":"Pattern 3: Chain Execution","text":"<pre><code>// Execute tools in sequence\nresult, steps, _ := exec.RunChain(ctx, []exec.Step{\n    {ToolID: \"ns:tool1\", Args: args1},\n    {ToolID: \"ns:tool2\", UsePrevious: true}, // Uses tool1's result\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#pattern-4-custom-runtime","title":"Pattern 4: Custom Runtime","text":"<pre><code>// Configure specific backend for security\nexec, _ := exec.New(exec.Options{\n    Index:           idx,\n    Docs:            docs,\n    SecurityProfile: runtime.ProfileHardened,\n    RuntimeBackends: map[runtime.SecurityProfile]runtime.Backend{\n        runtime.ProfileHardened: gvisor.NewBackend(gvisor.Config{}),\n    },\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#5-file-summary","title":"5. File Summary","text":"Phase File Action Est. Lines 1 <code>exec/exec.go</code> Create ~200 1 <code>exec/result.go</code> Create ~80 1 <code>exec/options.go</code> Create ~100 1 <code>exec/exec_test.go</code> Create ~400 1 <code>exec/example_test.go</code> Create ~150 1 <code>exec/doc.go</code> Create ~50 2 <code>examples/basic/main.go</code> Create ~80 2 <code>examples/chain/main.go</code> Create ~100 2 <code>examples/code/main.go</code> Create ~120 2 <code>examples/discovery/main.go</code> Create ~100 2 <code>examples/streaming/main.go</code> Create ~100 2 <code>examples/runtime/main.go</code> Create ~120 2 <code>examples/full/main.go</code> Create ~200 3 <code>run/example_test.go</code> Create ~100 3 <code>code/example_test.go</code> Create ~100 3 <code>backend/example_test.go</code> Create ~80 3 <code>runtime/example_test.go</code> Create ~100 4 <code>backend/backend_test.go</code> Expand ~150 4 <code>backend/local/local_test.go</code> Expand ~150 4 <code>code/executor_test.go</code> Expand ~200 4 <code>runtime/gateway/proxy/*_test.go</code> Expand ~150 5 <code>docs/architecture.md</code> Create ~200 5 <code>docs/integration.md</code> Create ~150 5 <code>docs/security-profiles.md</code> Create ~100 5 <code>docs/error-handling.md</code> Create ~150"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#6-verification","title":"6. Verification","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#unit-tests","title":"Unit Tests","text":"<pre><code>go test ./... -v -race -cover\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#coverage-target","title":"Coverage Target","text":"<pre><code>go test ./... -coverprofile=cover.out\ngo tool cover -func=cover.out | grep total\n# Target: 85%+ overall\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#example-execution","title":"Example Execution","text":"<pre><code>go run examples/basic/main.go\ngo run examples/full/main.go\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#7-implementation-order","title":"7. Implementation Order","text":"<ol> <li>Phase 1: exec/ facade - Unified entry point (enables Phase 2)</li> <li>Phase 2: examples/ - Runnable integration examples</li> <li>Phase 3: example_test.go - pkg.go.dev documentation</li> <li>Phase 4: coverage - Test gap closure</li> <li>Phase 5: docs/ - Written documentation</li> </ol> <p>Each phase can be committed independently and provides incremental value.</p>"},{"location":"library-docs-from-repos/toolexec/architecture/","title":"Architecture Overview","text":"<p>toolexec is the execution layer for MCP-style tools. It focuses on running validated tools across different backends and isolating untrusted code with configurable runtimes.</p>"},{"location":"library-docs-from-repos/toolexec/architecture/#core-packages","title":"Core Packages","text":"Package Responsibility <code>exec</code> Unified facade that composes discovery + execution + docs <code>run</code> Execution pipeline with validation + chaining <code>backend</code> Backend registry and resolution <code>runtime</code> Sandbox runtimes and security profiles <code>code</code> Orchestration of code with tool access"},{"location":"library-docs-from-repos/toolexec/architecture/#execution-flow","title":"Execution Flow","text":"<ol> <li>Resolve tool definition and backend binding</li> <li>Validate input against JSON Schema</li> <li>Execute tool on backend (local, provider, MCP)</li> <li>Normalize results into structured output</li> <li>Validate output (if OutputSchema present)</li> </ol>"},{"location":"library-docs-from-repos/toolexec/architecture/#chaining","title":"Chaining","text":"<p>Chains execute sequentially. If <code>UsePrevious</code> is true, the prior step\u2019s structured result is injected into <code>args[\"previous\"]</code> for the next step.</p>"},{"location":"library-docs-from-repos/toolexec/architecture/#runtime-isolation","title":"Runtime Isolation","text":"<p>The <code>runtime</code> package provides isolation levels via security profiles:</p> <ul> <li>Dev: local / unsafe execution with explicit opt\u2011in</li> <li>Standard: container or sandbox runtime</li> <li>Hardened: strongest isolation (Docker/gVisor/WASM)</li> </ul>"},{"location":"library-docs-from-repos/toolexec/architecture/#observability","title":"Observability","text":"<p>Execution surfaces timing and tool call metadata in <code>exec.Result</code> and <code>run.RunResult</code>, enabling tracing and audits in higher layers.</p>"},{"location":"library-docs-from-repos/toolexec/architecture/#related-docs","title":"Related Docs","text":"<ul> <li>Schemas and Contracts</li> <li>Design Notes</li> <li>User Journey</li> </ul>"},{"location":"library-docs-from-repos/toolexec/design-notes/","title":"toolexec Design Notes","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#overview","title":"Overview","text":"<p>toolexec provides the execution layer for the ApertureStack tool framework. It handles tool execution, code orchestration, and runtime isolation.</p>"},{"location":"library-docs-from-repos/toolexec/design-notes/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          exec                                \u2502\n\u2502              (Unified Facade - Single Entry Point)          \u2502\n\u2502  SearchTools, RunTool, RunChain, GetToolDoc                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          v               v               v\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  index   \u2502   \u2502     run      \u2502  \u2502 tooldoc  \u2502\n    \u2502(discover)\u2502   \u2502  (execute)   \u2502  \u2502  (docs)  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          v\n                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                   \u2502   backend    \u2502\n                   \u2502  (registry)  \u2502\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          v               v               v\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  local   \u2502   \u2502     mcp      \u2502  \u2502 provider \u2502\n    \u2502 handlers \u2502   \u2502   servers    \u2502  \u2502   APIs   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/design-notes/#exec-package-unified-facade","title":"exec Package (Unified Facade)","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#design-decisions","title":"Design Decisions","text":"<ol> <li> <p>Single Entry Point: The <code>exec.Exec</code> type provides a unified API combining    discovery (search, describe) with execution (run, chain). Users don't need    to understand multiple packages for basic operations.</p> </li> <li> <p>Options Pattern: Configuration via <code>exec.Options</code> allows:</p> </li> <li>Custom index and doc store</li> <li>Local handler registration via map</li> <li>MCP and provider executors</li> <li>Input/output validation toggles</li> <li> <p>Security profile selection</p> </li> <li> <p>Result Types: Consistent <code>Result</code> and <code>StepResult</code> types wrap lower-level    <code>run.RunResult</code> with additional context (toolID, duration, error).</p> </li> <li> <p>Handler Function: Simple <code>func(ctx, args) (any, error)</code> signature for    local tool handlers, avoiding the need to understand backend interfaces.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolexec/design-notes/#run-package","title":"run Package","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#design-decisions_1","title":"Design Decisions","text":"<ol> <li>Execution Pipeline: Every tool call follows a strict pipeline:</li> <li>Validate tool ID format</li> <li>Validate input against schema</li> <li>Resolve tool definition from index</li> <li>Select and invoke backend</li> <li>Normalize result</li> <li> <p>Validate output against schema</p> </li> <li> <p>Backend Abstraction: The runner doesn't care how tools are executed.    It delegates to the backend registry which supports local, provider, and    MCP server backends.</p> </li> <li> <p>Result Normalization: All backends return results in a consistent    <code>RunResult</code> format with output, error, duration, and metadata.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolexec/design-notes/#error-handling","title":"Error Handling","text":"<ul> <li>Input validation errors include the failing field and constraint</li> <li>Backend errors are wrapped with context</li> <li>Output validation errors are warnings (logged but not fatal)</li> </ul>"},{"location":"library-docs-from-repos/toolexec/design-notes/#code-package","title":"code Package","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#design-decisions_2","title":"Design Decisions","text":"<ol> <li> <p>DSL for Orchestration: Provides a simple DSL for chaining tool calls    with variable binding and conditional logic.</p> </li> <li> <p>Runner Integration: Delegates actual tool execution to the <code>run</code>    package, ensuring consistent validation and error handling.</p> </li> <li> <p>Runtime Integration: Code execution can be isolated by wiring a    <code>runtime.Runtime</code> via the <code>runtime/toolcodeengine</code> adapter.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolexec/design-notes/#runtime-package","title":"runtime Package","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#design-decisions_3","title":"Design Decisions","text":"<ol> <li> <p>Runtime Interface: Abstracts sandbox implementations behind a common    interface supporting Execute and Cleanup operations.</p> </li> <li> <p>Security Profiles:</p> </li> <li><code>ProfileDev</code>: Unsafe host execution (development only)</li> <li><code>ProfileStandard</code>: Container-based isolation</li> <li> <p><code>ProfileHardened</code>: Maximum isolation (seccomp + VM/VM-like backends)</p> </li> <li> <p>Resource Limits: Configurable CPU, memory, and timeout limits for    sandboxed execution.</p> </li> <li>Gateway Requirement: Every execution request must include a    <code>ToolGateway</code> to broker tool discovery/execution for sandboxed code.</li> </ol>"},{"location":"library-docs-from-repos/toolexec/design-notes/#supported-runtimes","title":"Supported Runtimes","text":"Runtime Isolation Performance Use Case Unsafe host None Fast Trusted/dev Docker Container Medium Production WASM Sandbox Varies Edge/browser"},{"location":"library-docs-from-repos/toolexec/design-notes/#runtime-backend-matrix","title":"Runtime Backend Matrix","text":"BackendKind Isolation Requirements Notes <code>BackendUnsafeHost</code> None Go toolchain (subprocess mode) Dev-only, explicit opt-in supported <code>BackendDocker</code> Container Docker daemon + ContainerRunner Standard isolation <code>BackendContainerd</code> Container containerd client Infrastructure-native <code>BackendKubernetes</code> Pod/Job kubeconfig/client Cluster execution <code>BackendGVisor</code> Sandbox gVisor/runsc Stronger isolation <code>BackendKata</code> VM Kata runtime VM-level isolation <code>BackendFirecracker</code> MicroVM Firecracker runtime Strongest isolation <code>BackendWASM</code> Sandbox wazero In-process WASM <code>BackendTemporal</code> Workflow Temporal client Orchestrated execution <code>BackendRemote</code> Remote HTTP/gRPC service External runtime"},{"location":"library-docs-from-repos/toolexec/design-notes/#toolcode-runtime-contract","title":"Toolcode \u2194 Runtime Contract","text":"<p>The <code>code</code> package uses the <code>runtime/toolcodeengine</code> adapter to bridge code execution with runtime backends. The adapter maps <code>code.ExecuteParams</code> to <code>runtime.ExecuteRequest</code>, preserving:</p> <ul> <li>Security profile selection</li> <li>Resource limits (timeouts, tool-call/chain limits)</li> <li>ToolGateway injection for tool discovery/execution</li> </ul>"},{"location":"library-docs-from-repos/toolexec/design-notes/#backend-package","title":"backend Package","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#design-decisions_4","title":"Design Decisions","text":"<ol> <li> <p>Backend Registry: Central registry for all backend implementations,    enabling runtime backend selection.</p> </li> <li> <p>Backend Kinds:</p> </li> <li><code>local</code>: In-process Go function</li> <li><code>provider</code>: External tool provider via HTTP/gRPC</li> <li> <p><code>mcp</code>: Remote MCP server via JSON-RPC</p> </li> <li> <p>Lazy Resolution: Backends are resolved at execution time, allowing    dynamic registration and configuration.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolexec/design-notes/#dependencies","title":"Dependencies","text":"<ul> <li><code>github.com/jonwraymond/toolfoundation/model</code> - Tool definitions</li> <li><code>github.com/jonwraymond/tooldiscovery/index</code> - Tool resolution</li> <li><code>github.com/tetratelabs/wazero</code> - WASM runtime (optional)</li> </ul>"},{"location":"library-docs-from-repos/toolexec/design-notes/#links","title":"Links","text":"<ul> <li>index</li> <li>user journey</li> </ul>"},{"location":"library-docs-from-repos/toolexec/examples/","title":"Examples","text":"<p>toolexec ships with runnable examples that cover execution, chaining, streaming, discovery integration, and runtime isolation.</p>"},{"location":"library-docs-from-repos/toolexec/examples/#basic-execution","title":"Basic execution","text":"<pre><code>go run ./examples/basic\n</code></pre> <p>Shows: - Local backend registration - Input validation and execution - Structured results</p>"},{"location":"library-docs-from-repos/toolexec/examples/#tool-chaining","title":"Tool chaining","text":"<pre><code>go run ./examples/chain\n</code></pre> <p>Shows: - Sequential chains - <code>UsePrevious</code> argument injection - Step results and errors</p>"},{"location":"library-docs-from-repos/toolexec/examples/#discovery-execution","title":"Discovery + execution","text":"<pre><code>go run ./examples/discovery\n</code></pre> <p>Shows: - Index + docs store integration - Search + execute via <code>exec</code> facade</p>"},{"location":"library-docs-from-repos/toolexec/examples/#streaming","title":"Streaming","text":"<pre><code>go run ./examples/streaming\n</code></pre> <p>Shows: - Streaming events from execution - Progress + chunk envelopes</p>"},{"location":"library-docs-from-repos/toolexec/examples/#runtime-isolation","title":"Runtime isolation","text":"<pre><code>go run ./examples/runtime\n</code></pre> <p>Shows: - Security profiles - Runtime selection (unsafe / docker / wasm)</p>"},{"location":"library-docs-from-repos/toolexec/examples/#full-integration","title":"Full integration","text":"<pre><code>go run ./examples/full\n</code></pre> <p>Shows: - End-to-end setup with discovery + exec + runtime</p>"},{"location":"library-docs-from-repos/toolexec/schemas/","title":"Schemas and Contracts","text":"<p>toolexec relies on toolfoundation/model.Tool as the canonical tool schema. It does not introduce new input/output JSON Schema formats; instead it executes tools and validates against the schemas defined on each <code>model.Tool</code>.</p> <p>This page documents: - The canonical tool schema fields and constraints (summary) - Input/Output schema requirements as enforced by the runner - JSON Schema dialect support and limitations - Execution payload contracts (RunResult, StreamEvent, ChainStep) - Recommended schema patterns</p> <p>For full schema details, see toolfoundation\u2019s schema docs.</p>"},{"location":"library-docs-from-repos/toolexec/schemas/#tool-schema-fieldsconstraints-summary","title":"Tool schema fields/constraints (summary)","text":"<p><code>model.Tool</code> embeds the MCP SDK <code>mcp.Tool</code> and adds stack extensions.</p>"},{"location":"library-docs-from-repos/toolexec/schemas/#core-mcp-fields","title":"Core MCP fields","text":"Field Required Notes <code>name</code> Yes 1\u2013128 chars, <code>[A-Za-z0-9_.-]</code> only <code>description</code> No Human-readable description <code>inputSchema</code> Yes JSON Schema object for tool parameters <code>outputSchema</code> No JSON Schema object for structured output <code>title</code> No Display label <code>annotations</code> No Hints (readOnly, idempotent, destructive, openWorld) <code>_meta</code> No Arbitrary metadata <code>icons</code> No Optional icon assets"},{"location":"library-docs-from-repos/toolexec/schemas/#extensions","title":"Extensions","text":"Field Required Notes <code>namespace</code> No Tool ID is <code>namespace:name</code> when set <code>version</code> No SemVer (<code>v1.2.3</code> or <code>1.2.3</code>) <code>tags</code> No Normalized tags for discovery"},{"location":"library-docs-from-repos/toolexec/schemas/#inputschema-outputschema-requirements","title":"InputSchema / OutputSchema requirements","text":"<ul> <li>InputSchema is required. A tool without <code>inputSchema</code> is invalid.</li> <li>OutputSchema is optional. If omitted, output validation is skipped.</li> <li>Validation in <code>run</code> uses <code>model.SchemaValidator</code>:</li> <li>Input validation runs before execution.</li> <li>Output validation runs after execution when <code>OutputSchema</code> is present.</li> </ul>"},{"location":"library-docs-from-repos/toolexec/schemas/#supported-dialects-and-limitations","title":"Supported dialects and limitations","text":"<p>Inherited from toolfoundation:</p> <ul> <li>Default dialect: JSON Schema 2020-12 (when <code>$schema</code> is absent)</li> <li>Supported: 2020-12 and draft-07</li> <li>External <code>$ref</code> resolution is disabled (no network I/O)</li> <li><code>format</code> is treated as annotation (not enforced)</li> </ul>"},{"location":"library-docs-from-repos/toolexec/schemas/#execution-payload-contracts","title":"Execution payload contracts","text":""},{"location":"library-docs-from-repos/toolexec/schemas/#runresult-runrunresult","title":"RunResult (<code>run.RunResult</code>)","text":"<p>Normalized result of executing a tool:</p> Field Type Notes <code>tool</code> <code>model.Tool</code> Resolved tool definition <code>backend</code> <code>model.ToolBackend</code> Backend used for execution <code>structured</code> <code>any</code> Normalized result value <code>mcpResult</code> <code>*mcp.CallToolResult</code> Raw MCP result when backend is MCP"},{"location":"library-docs-from-repos/toolexec/schemas/#streamevent-runstreamevent","title":"StreamEvent (<code>run.StreamEvent</code>)","text":"<p>Transport-agnostic streaming envelope:</p> Field Type Notes <code>kind</code> string <code>progress</code>, <code>chunk</code>, <code>done</code>, <code>error</code> <code>toolId</code> string Canonical tool ID <code>data</code> any Event payload (progress/chunk details)"},{"location":"library-docs-from-repos/toolexec/schemas/#chainstep-runchainstep","title":"ChainStep (<code>run.ChainStep</code>)","text":"Field Type Notes <code>toolId</code> string Canonical tool ID <code>args</code> map Tool arguments <code>usePrevious</code> bool Inject prior result into <code>args[\"previous\"]</code>"},{"location":"library-docs-from-repos/toolexec/schemas/#recommended-no-parameters-schema","title":"Recommended \u201cno parameters\u201d schema","text":"<p>Strict MCP-recommended schema:</p> <pre><code>{\n  \"type\": \"object\",\n  \"additionalProperties\": false\n}\n</code></pre> <p>Less strict variant:</p> <pre><code>{\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/schemas/#example-schema-patterns","title":"Example schema patterns","text":""},{"location":"library-docs-from-repos/toolexec/schemas/#required-string-property","title":"Required string property","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"path\": {\"type\": \"string\", \"description\": \"File path\"}\n  },\n  \"required\": [\"path\"],\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/schemas/#optional-enum-with-default","title":"Optional enum with default","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"encoding\": {\"type\": \"string\", \"enum\": [\"utf8\", \"ascii\"], \"default\": \"utf8\"}\n  },\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/schemas/#array-of-objects","title":"Array of objects","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"items\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"id\": {\"type\": \"string\"},\n          \"value\": {\"type\": \"number\"}\n        },\n        \"required\": [\"id\"],\n        \"additionalProperties\": false\n      }\n    }\n  },\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/schemas/#one-of-variants","title":"One-of variants","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"mode\": {\n      \"oneOf\": [\n        {\"type\": \"string\", \"enum\": [\"fast\", \"safe\"]},\n        {\"type\": \"number\", \"minimum\": 1, \"maximum\": 10}\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/schemas/#links","title":"Links","text":"<ul> <li>Architecture</li> <li>Design notes</li> <li>User journey</li> <li>toolfoundation schemas</li> </ul>"},{"location":"library-docs-from-repos/toolexec/user-journey/","title":"toolexec User Journey","text":""},{"location":"library-docs-from-repos/toolexec/user-journey/#overview","title":"Overview","text":"<p>This guide walks through using toolexec to execute tools, from simple single-tool calls to complex orchestrated workflows.</p>"},{"location":"library-docs-from-repos/toolexec/user-journey/#1-installation","title":"1. Installation","text":"<pre><code>go get github.com/jonwraymond/toolexec@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#2-quick-start-with-the-unified-facade-recommended","title":"2. Quick Start with the Unified Facade (Recommended)","text":"<p>The <code>exec</code> package provides a unified facade combining discovery and execution:</p> <pre><code>import (\n    \"github.com/jonwraymond/toolexec/exec\"\n    \"github.com/jonwraymond/tooldiscovery/index\"\n    \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n)\n\n// Setup discovery infrastructure\nidx := index.NewInMemoryIndex()\ndocs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n// Create executor with local handlers\nexecutor, err := exec.New(exec.Options{\n    Index: idx,\n    Docs:  docs,\n    LocalHandlers: map[string]exec.Handler{\n        \"calculator-add\": func(ctx context.Context, args map[string]any) (any, error) {\n            a, b := args[\"a\"].(float64), args[\"b\"].(float64)\n            return a + b, nil\n        },\n    },\n})\n\n// Execute a tool\nresult, err := executor.RunTool(ctx, \"math:add\", map[string]any{\"a\": 5, \"b\": 3})\nfmt.Println(result.Value) // 8\n\n// Search for tools\nresults, _ := executor.SearchTools(ctx, \"calculator\", 10)\n\n// Get tool documentation\ndoc, _ := executor.GetToolDoc(ctx, \"math:add\", tooldoc.DetailFull)\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#3-execute-a-single-tool","title":"3. Execute a Single Tool","text":"<pre><code>result, err := executor.RunTool(ctx, \"github:create_issue\", map[string]any{\n    \"owner\": \"jonwraymond\",\n    \"repo\":  \"toolexec\",\n    \"title\": \"Bug report\",\n    \"body\":  \"Description here\",\n})\n\nif err != nil {\n    log.Fatalf(\"Execution failed: %v\", err)\n}\n\nfmt.Printf(\"Created issue: %v\\n\", result.Value)\nfmt.Printf(\"Duration: %v\\n\", result.Duration)\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#4-chain-tool-calls","title":"4. Chain Tool Calls","text":"<p>Use <code>UsePrevious</code> to pass results between steps:</p> <pre><code>result, steps, err := executor.RunChain(ctx, []exec.Step{\n    {ToolID: \"github:create_issue\", Args: map[string]any{\n        \"title\": \"Bug report\",\n    }},\n    {ToolID: \"github:add_labels\", Args: map[string]any{\n        \"labels\": []string{\"bug\"},\n    }, UsePrevious: true}, // Injects previous result as \"previous\" arg\n})\n\nfmt.Printf(\"Final result: %v\\n\", result.Value)\nfor i, step := range steps {\n    fmt.Printf(\"Step %d: %s \u2192 %v\\n\", i+1, step.ToolID, step.Value)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#5-register-local-tools","title":"5. Register Local Tools","text":"<p>Register tools using the backend/local package:</p> <pre><code>import \"github.com/jonwraymond/toolexec/backend/local\"\n\nbackend := local.New(\"calculator\")\nbackend.RegisterHandler(\"add\", local.ToolDef{\n    Name:        \"add\",\n    Description: \"Adds two numbers\",\n    InputSchema: map[string]any{\n        \"type\": \"object\",\n        \"properties\": map[string]any{\n            \"a\": map[string]any{\"type\": \"number\"},\n            \"b\": map[string]any{\"type\": \"number\"},\n        },\n    },\n    Handler: func(ctx context.Context, args map[string]any) (any, error) {\n        a, b := args[\"a\"].(float64), args[\"b\"].(float64)\n        return a + b, nil\n    },\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#6-using-the-run-package-directly-advanced","title":"6. Using the Run Package Directly (Advanced)","text":"<p>For more control, use the <code>run</code> package directly:</p> <pre><code>import \"github.com/jonwraymond/toolexec/run\"\n\nrunner := run.NewRunner(\n    run.WithIndex(idx),\n    run.WithLocalRegistry(localReg),\n    run.WithValidation(true, true),\n)\n\nresult, err := runner.Run(ctx, \"ns:tool\", args)\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#7-code-orchestration-sandboxed-execution","title":"7. Code Orchestration (Sandboxed Execution)","text":"<p>The <code>code</code> package enables executing user-provided code that can call tools:</p> <pre><code>import \"github.com/jonwraymond/toolexec/code\"\n\n// Create code executor with limits\ncodeExec := code.NewExecutor(code.Config{\n    Index:        idx,\n    Docs:         docs,\n    Run:          runner,\n    MaxToolCalls: 50,\n    Timeout:      30 * time.Second,\n})\n\nresult, err := codeExec.Execute(ctx, code.ExecuteParams{\n    Language: \"go\",\n    Code: `\n        // Access tools via the tools interface\n        result, _ := tools.RunTool(ctx, \"math:add\", map[string]any{\"a\": 1, \"b\": 2})\n        return result.Structured\n    `,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#8-runtime-isolation-security-profiles","title":"8. Runtime Isolation (Security Profiles)","text":"<p>toolexec supports three security profiles for different isolation levels:</p> Profile Isolation Use Case <code>ProfileDev</code> None Development/testing <code>ProfileStandard</code> Container Production <code>ProfileHardened</code> VM/gVisor Untrusted code <pre><code>import (\n    \"github.com/jonwraymond/toolexec/runtime\"\n    \"github.com/jonwraymond/toolexec/runtime/backend/unsafe\"\n    \"github.com/jonwraymond/toolexec/runtime/gateway/direct\"\n)\n\n// Gateway exposes tool discovery + execution to sandboxed code\ngateway := direct.New(direct.Config{\n    Index:  idx,\n    Docs:   docs,\n    Runner: runner,\n})\n\n// Runtime with security profile selection\nrt := runtime.NewDefaultRuntime(runtime.RuntimeConfig{\n    Backends: map[runtime.SecurityProfile]runtime.Backend{\n        runtime.ProfileDev: unsafe.New(unsafe.Config{RequireOptIn: true}),\n        // runtime.ProfileStandard: docker.New(dockerConfig),\n        // runtime.ProfileHardened: gvisor.New(gvisorConfig),\n    },\n    DefaultProfile: runtime.ProfileDev,\n})\n\n// Execute code in the runtime\nresult, err := rt.Execute(ctx, runtime.ExecuteRequest{\n    Language: \"go\",\n    Code:     `__out = 1 + 1`,\n    Profile:  runtime.ProfileDev,\n    Gateway:  gateway,\n    Limits: runtime.Limits{\n        MaxToolCalls:   100,\n        MemoryBytes:    512 * 1024 * 1024, // 512MB\n        CPUQuotaMillis: 60000,             // 60s\n    },\n})\n</code></pre> <p>For container isolation, use <code>runtime/backend/docker</code> with <code>ProfileStandard</code>. For maximum isolation, use <code>runtime/backend/gvisor</code> with <code>ProfileHardened</code>.</p>"},{"location":"library-docs-from-repos/toolexec/user-journey/#execution-flow","title":"Execution Flow","text":"<pre><code>Client              exec.Exec            run.Runner           Backend\n  |                     |                     |                    |\n  |-- RunTool(id) ------|                     |                    |\n  |                     |-- Run(id, args) ----|                    |\n  |                     |                     |-- Validate --------|\n  |                     |                     |-- Resolve ---------|\n  |                     |                     |-- Execute ---------|\n  |                     |                     |&lt;-- Result ---------|\n  |                     |&lt;-- RunResult -------|                    |\n  |&lt;-- Result ----------|                     |                    |\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#examples","title":"Examples","text":"<p>See the examples page for runnable examples (source lives in <code>toolexec/examples/</code>):</p> <ul> <li><code>basic/</code> - Simple tool execution</li> <li><code>chain/</code> - Sequential tool chaining</li> <li><code>discovery/</code> - Search and execute workflow</li> <li><code>streaming/</code> - Streaming execution events</li> <li><code>runtime/</code> - Security profile configuration</li> <li><code>full/</code> - Complete integration example</li> </ul>"},{"location":"library-docs-from-repos/toolexec/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Add observability with toolops/observe</li> <li>Expose via MCP with metatools-mcp</li> </ul>"},{"location":"library-docs-from-repos/toolcompose/","title":"toolcompose","text":"<p>Composition layer for building filtered tool collections and declarative skills.</p>"},{"location":"library-docs-from-repos/toolcompose/#packages","title":"Packages","text":"Package Purpose <code>set</code> Toolset composition, filtering, and exposure <code>skill</code> Declarative skill planning and execution"},{"location":"library-docs-from-repos/toolcompose/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolcompose@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/#quick-start-toolset","title":"Quick Start: Toolset","text":"<pre><code>import (\n  \"fmt\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolcompose/set\"\n  \"github.com/jonwraymond/toolfoundation/adapter\"\n)\n\ntools := []*adapter.CanonicalTool{\n  {\n    Namespace: \"github\",\n    Name:      \"create_issue\",\n    Tags:      []string{\"issues\"},\n    InputSchema: &amp;adapter.JSONSchema{Type: \"object\"},\n  },\n  {\n    Namespace: \"github\",\n    Name:      \"list_issues\",\n    Tags:      []string{\"issues\"},\n    InputSchema: &amp;adapter.JSONSchema{Type: \"object\"},\n  },\n}\n\nts, err := set.NewBuilder(\"github-issues\").\n  FromTools(tools).\n  WithNamespace(\"github\").\n  WithTags([]string{\"issues\"}).\n  WithPolicy(set.DenyTags(\"danger\")).\n  Build()\nif err != nil {\n  log.Fatal(err)\n}\n\nfmt.Println(ts.IDs())\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/#quick-start-skill","title":"Quick Start: Skill","text":"<pre><code>import (\n  \"context\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolcompose/skill\"\n  \"github.com/jonwraymond/toolexec/run\"\n)\n\n// Define a skill\nsk := skill.Skill{\n  Name: \"triage-issue\",\n  Steps: []skill.Step{\n    {ID: \"create\", ToolID: \"github:create_issue\", Inputs: map[string]any{\"title\": \"Bug\"}},\n    {ID: \"label\", ToolID: \"github:add_labels\", Inputs: map[string]any{\"labels\": []string{\"bug\"}}},\n  },\n}\n\nplan, err := skill.NewPlanner().Plan(sk)\nif err != nil {\n  log.Fatal(err)\n}\n\nrunner := run.NewRunner()\n\n// Adapt toolexec runner to skill.Runner\ntype runAdapter struct{ exec run.Runner }\nfunc (r runAdapter) Run(ctx context.Context, step skill.Step) (any, error) {\n  res, err := r.exec.Run(ctx, step.ToolID, step.Inputs)\n  if err != nil {\n    return nil, err\n  }\n  return res.Output, nil\n}\n\nctx := context.Background()\nresults, err := skill.Execute(ctx, plan, runAdapter{exec: runner})\nif err != nil {\n  log.Fatal(err)\n}\n_ = results\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/","title":"toolcompose Design Notes","text":""},{"location":"library-docs-from-repos/toolcompose/design-notes/#overview","title":"Overview","text":"<p>toolcompose provides composition primitives for the ApertureStack ecosystem:</p> <ul> <li>set: build filtered, access-controlled tool collections</li> <li>skill: declare tool-based workflows and execute them deterministically</li> </ul>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#ecosystem-position","title":"Ecosystem Position","text":"<pre><code>flowchart TB\n    subgraph Foundation[\"toolfoundation\"]\n        Model[model.Tool]\n        Adapter[adapter.CanonicalTool]\n        Backend[model.ToolBackend]\n    end\n\n    subgraph Discovery[\"tooldiscovery\"]\n        Index[index.Index]\n        Search[search.BM25Searcher]\n        Docs[tooldoc.Store]\n    end\n\n    subgraph Exec[\"toolexec\"]\n        Runner[run.Runner]\n        Code[code.Executor]\n        Runtime[runtime.Sandbox]\n    end\n\n    subgraph Compose[\"toolcompose\"]\n        Set[set.Toolset]\n        Skill[skill.Skill]\n        Exposure[set.Exposure]\n    end\n\n    Model --&gt; Adapter\n    Adapter --&gt; Set\n    Index --&gt; Set\n    Set --&gt; Exposure\n    Runner --&gt; Skill\n    Exposure --&gt; Code</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#dependency-flow","title":"Dependency Flow","text":"Package Depends On Provides To toolfoundation - All packages (core types) tooldiscovery toolfoundation toolcompose (registry source) toolexec toolfoundation, tooldiscovery toolcompose (Runner impl) toolcompose toolfoundation End users (composition API)"},{"location":"library-docs-from-repos/toolcompose/design-notes/#set-package","title":"set Package","text":""},{"location":"library-docs-from-repos/toolcompose/design-notes/#design-decisions","title":"Design Decisions","text":"<ol> <li>Thread-safe Toolset: Toolsets wrap a map with RW locks for safe concurrent access.</li> <li>Deterministic Ordering: <code>IDs()</code> and <code>Tools()</code> return lexicographically sorted results.</li> <li>Pure Composition: No I/O or execution; callers supply tools as input.</li> <li>Filter + Policy: Filters reduce candidates; policies enforce access rules.</li> <li>Export via Adapters: <code>Exposure</code> converts toolsets to protocol-specific shapes.</li> </ol>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#filter-policy-semantics","title":"Filter + Policy Semantics","text":"<ul> <li>Filters are AND-composed in builder order.</li> <li>Policies run after filters.</li> <li><code>nil</code> tools are always rejected.</li> </ul> <pre><code>flowchart LR\n    Source[Canonical Tools] --&gt; Filters\n    Filters --&gt; Policy\n    Policy --&gt; Toolset\n    Toolset --&gt; Exposure</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#thread-safety-model","title":"Thread Safety Model","text":"Type Safe For Notes <code>Toolset</code> Concurrent reads Uses <code>sync.RWMutex</code> <code>Builder</code> Single goroutine Configure, then call <code>Build()</code> once <code>Exposure</code> Concurrent reads After construction only <code>FilterFunc</code> Must be thread-safe If Toolset is shared"},{"location":"library-docs-from-repos/toolcompose/design-notes/#error-handling","title":"Error Handling","text":"<p>Sentinel errors enable programmatic handling:</p> <pre><code>ts, err := builder.Build()\nif errors.Is(err, set.ErrNoSource) {\n    // No tools provided - call FromTools or FromRegistry\n}\nif errors.Is(err, set.ErrNilAdapter) {\n    // Adapter is nil in Exposure\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#skill-package","title":"skill Package","text":""},{"location":"library-docs-from-repos/toolcompose/design-notes/#design-decisions_1","title":"Design Decisions","text":"<ol> <li>Declarative Skills: Skills are lightweight definitions of steps.</li> <li>Deterministic Planning: Planner sorts steps by ID to guarantee stable execution order.</li> <li>Runner Interface: Execution delegates to a <code>Runner</code> for tool integration.</li> <li>Guards: Optional validation hooks (max steps, allowed tool IDs).</li> <li>Fail-fast Execution: Execution stops on the first step error.</li> </ol> <pre><code>flowchart LR\n    Skill --&gt; Planner\n    Planner --&gt; Plan\n    Plan --&gt; Execute\n    Execute --&gt; Runner</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#execution-model","title":"Execution Model","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Planner\n    participant Execute\n    participant Guard\n    participant Runner\n\n    User-&gt;&gt;Planner: Plan(skill)\n    Planner-&gt;&gt;Planner: Validate skill\n    Planner-&gt;&gt;Planner: Apply guards\n    Planner--&gt;&gt;User: Plan\n\n    User-&gt;&gt;Execute: Execute(ctx, plan, runner)\n    loop Each Step\n        Execute-&gt;&gt;Runner: Run(ctx, toolID, inputs)\n        Runner--&gt;&gt;Execute: Result\n        alt Error\n            Execute--&gt;&gt;User: Partial results + error\n        end\n    end\n    Execute--&gt;&gt;User: All results</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#guard-contract","title":"Guard Contract","text":"<p>Guards must be: - Idempotent: Same skill \u2192 same result - Pure: No side effects during <code>Check()</code> - Thread-safe: If planner is shared</p>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#thread-safety-model_1","title":"Thread Safety Model","text":"Type Safe For Notes <code>Planner</code> Concurrent use Stateless after construction <code>Plan</code> Concurrent reads Immutable after creation <code>Runner</code> Implementation-dependent Check implementation docs <code>Guard</code> Must be thread-safe If Planner is shared"},{"location":"library-docs-from-repos/toolcompose/design-notes/#error-handling_1","title":"Error Handling","text":"<p>Sentinel errors for programmatic handling:</p> <pre><code>plan, err := planner.Plan(skill)\nif errors.Is(err, skill.ErrNoSteps) {\n    // Skill has no steps defined\n}\nif errors.Is(err, skill.ErrMaxStepsExceeded) {\n    // MaxStepsGuard rejected the skill\n}\nif errors.Is(err, skill.ErrToolNotAllowed) {\n    // AllowedToolIDsGuard rejected a tool\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#trade-offs","title":"Trade-offs","text":"Decision Benefit Cost No implicit parallelism Deterministic, easy to reason about Sequential execution only Explicit runner adapter No hard dependency on execution engine Requires integration work Binary policy Simple allow/deny semantics Rich policies need wrappers Fail-fast execution Errors surface immediately No partial recovery Deterministic ordering Reproducible results Sorting overhead"},{"location":"library-docs-from-repos/toolcompose/design-notes/#integration-patterns","title":"Integration Patterns","text":""},{"location":"library-docs-from-repos/toolcompose/design-notes/#with-tooldiscovery","title":"With tooldiscovery","text":"<pre><code>// Build toolset from registry\nts, err := set.NewBuilder(\"github-tools\").\n    FromRegistry(registry).\n    WithNamespace(\"github\").\n    Build()\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#with-toolexec","title":"With toolexec","text":"<pre><code>// Execute skill with toolexec runner\nrunner := exec.NewRunner(executor)\nplanner := skill.NewPlanner(skill.PlannerOptions{Runner: runner})\nplan, _ := planner.Plan(mySkill)\nresults, _ := skill.Execute(ctx, plan, runner)\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#protocol-export","title":"Protocol Export","text":"<pre><code>// Export for MCP server\nexposure := set.NewExposure(ts, adapter.NewMCPAdapter())\ntools, warnings, errs := exposure.ExportWithWarnings()\nfor _, w := range warnings {\n    log.Printf(\"Feature %s lost converting %s \u2192 %s\",\n        w.Feature, w.FromAdapter, w.ToAdapter)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/","title":"toolcompose User Journey","text":""},{"location":"library-docs-from-repos/toolcompose/user-journey/#1-installation","title":"1. Installation","text":"<pre><code>go get github.com/jonwraymond/toolcompose@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#2-build-a-toolset","title":"2. Build a Toolset","text":"<pre><code>import (\n  \"fmt\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolcompose/set\"\n  \"github.com/jonwraymond/toolfoundation/adapter\"\n)\n\ntools := []*adapter.CanonicalTool{\n  {Namespace: \"github\", Name: \"create_issue\", Tags: []string{\"issues\"}, InputSchema: &amp;adapter.JSONSchema{Type: \"object\"}},\n  {Namespace: \"github\", Name: \"add_labels\", Tags: []string{\"issues\"}, InputSchema: &amp;adapter.JSONSchema{Type: \"object\"}},\n  {Namespace: \"slack\", Name: \"post_message\", Tags: []string{\"chat\"}, InputSchema: &amp;adapter.JSONSchema{Type: \"object\"}},\n}\n\nts, err := set.NewBuilder(\"issue-workflow\").\n  FromTools(tools).\n  WithNamespace(\"github\").\n  WithTags([]string{\"issues\"}).\n  WithPolicy(set.DenyTags(\"danger\")).\n  Build()\nif err != nil {\n  log.Fatal(err)\n}\n\nfmt.Println(\"Toolset IDs:\", ts.IDs())\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#3-filter-an-existing-toolset","title":"3. Filter an Existing Toolset","text":"<pre><code>filtered := ts.Filter(set.TagsAny(\"issues\"))\nfmt.Println(filtered.IDs())\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#4-export-toolsets","title":"4. Export Toolsets","text":"<pre><code>import (\n  \"log\"\n\n  \"github.com/jonwraymond/toolfoundation/adapter/mcp\"\n)\n\nexposure := set.NewExposure(ts, mcp.NewAdapter())\ntools, warnings, errs := exposure.ExportWithWarnings()\n\nif len(errs) &gt; 0 {\n  log.Printf(\"conversion errors: %v\", errs)\n}\n_ = warnings\n_ = tools\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#5-define-a-skill","title":"5. Define a Skill","text":"<pre><code>import \"github.com/jonwraymond/toolcompose/skill\"\n\nsk := skill.Skill{\n  Name: \"triage-issue\",\n  Steps: []skill.Step{\n    {ID: \"create\", ToolID: \"github:create_issue\", Inputs: map[string]any{\"title\": \"Bug\"}},\n    {ID: \"label\", ToolID: \"github:add_labels\", Inputs: map[string]any{\"labels\": []string{\"bug\"}}},\n  },\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#6-plan-guard","title":"6. Plan + Guard","text":"<pre><code>planner := skill.NewPlanner()\nplan, err := planner.Plan(sk)\nif err != nil {\n  log.Fatal(err)\n}\n\nguard := skill.MaxStepsGuard(5)\nif err := guard.Validate(sk); err != nil {\n  log.Fatal(err)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#7-execute-via-toolexec","title":"7. Execute via toolexec","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolcompose/skill\"\n  \"github.com/jonwraymond/toolexec/run\"\n)\n\ntype runAdapter struct{ exec run.Runner }\nfunc (r runAdapter) Run(ctx context.Context, step skill.Step) (any, error) {\n  res, err := r.exec.Run(ctx, step.ToolID, step.Inputs)\n  if err != nil {\n    return nil, err\n  }\n  return res.Output, nil\n}\n\nrunner := run.NewRunner()\nresults, err := skill.Execute(context.Background(), plan, runAdapter{exec: runner})\nif err != nil {\n  log.Fatal(err)\n}\n_ = results\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Combine with <code>toolcompose/set</code> to scope which tools a skill can access.</li> <li>Use <code>toolcompose/set</code> exposures to export protocol-specific tool lists.</li> </ul>"},{"location":"library-docs-from-repos/toolops/","title":"toolops","text":"<p>Operations layer providing observability, caching, authentication, health checks, and resilience patterns for production deployments.</p>"},{"location":"library-docs-from-repos/toolops/#packages","title":"Packages","text":"Package Purpose <code>observe</code> OpenTelemetry-based tracing, metrics, and logging <code>cache</code> Deterministic caching with policies and middleware <code>auth</code> Authentication and authorization primitives <code>health</code> Health checks and HTTP probes <code>resilience</code> Circuit breakers, retries, rate limits, bulkheads"},{"location":"library-docs-from-repos/toolops/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolops@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolops/#documentation-map","title":"Documentation Map","text":"<ul> <li>Architecture</li> <li>Schemas and Contracts</li> <li>Examples</li> <li>Design Notes</li> </ul>"},{"location":"library-docs-from-repos/toolops/#quick-start-observability","title":"Quick Start: Observability","text":"<pre><code>import (\n  \"context\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolops/observe\"\n)\n\nobs, err := observe.NewObserver(context.Background(), observe.Config{\n  ServiceName: \"metatools-mcp\",\n  Tracing:     observe.TracingConfig{Enabled: true, Exporter: \"otlp\"},\n  Metrics:     observe.MetricsConfig{Enabled: true, Exporter: \"prometheus\"},\n  Logging:     observe.LoggingConfig{Enabled: true, Level: \"info\"},\n})\nif err != nil {\n  log.Fatal(err)\n}\ndefer obs.Shutdown(context.Background())\n\nmw, _ := observe.MiddlewareFromObserver(obs)\nwrapped := mw.Wrap(func(ctx context.Context, tool observe.ToolMeta, input any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n\n_, _ = wrapped(context.Background(), observe.ToolMeta{Name: \"echo\"}, map[string]any{\"msg\": \"hi\"})\n</code></pre>"},{"location":"library-docs-from-repos/toolops/#quick-start-cache","title":"Quick Start: Cache","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/cache\"\n)\n\nc := cache.NewMemoryCache(cache.DefaultPolicy())\nkeyer := cache.NewDefaultKeyer()\nmw := cache.NewCacheMiddleware(c, keyer, cache.DefaultPolicy(), nil)\n\nresult, err := mw.Execute(context.Background(), \"github:create_issue\", map[string]any{\"title\": \"Bug\"}, []string{\"issues\"},\n  func(ctx context.Context, toolID string, input any) ([]byte, error) {\n    return []byte(\"{\\\"ok\\\":true}\"), nil\n  })\n_ = result\n_ = err\n</code></pre>"},{"location":"library-docs-from-repos/toolops/architecture/","title":"toolops Architecture","text":"<p>The toolops layer provides operational capabilities around tool execution. It does not execute tools itself. Instead, it wraps execution with observability, caching, authentication, health checks, and resilience.</p>"},{"location":"library-docs-from-repos/toolops/architecture/#design-principles","title":"Design Principles","text":"<ul> <li>Pure operations layer: No tool execution, no transport. Wraps calls only.</li> <li>Composable middleware: Each capability exposes a middleware function that   can be stacked around tool execution.</li> <li>Deterministic behavior: Policies and configuration produce predictable   outcomes for retries, caching, and rate limits.</li> <li>Fail-safe defaults: Misconfiguration fails fast with explicit errors.</li> </ul>"},{"location":"library-docs-from-repos/toolops/architecture/#core-packages","title":"Core Packages","text":"Package Responsibility <code>observe</code> Tracing, metrics, structured logging <code>cache</code> Deterministic caching + policies <code>auth</code> Authentication + authorization utilities <code>health</code> Health checks, HTTP probes, readiness <code>resilience</code> Retries, circuit breakers, rate limits, bulkheads"},{"location":"library-docs-from-repos/toolops/architecture/#execution-boundary","title":"Execution Boundary","text":"<p>Tool execution lives in <code>toolexec</code>. toolops sits around it:</p> <pre><code>flowchart LR\n    Exec[\"toolexec/run\"] --&gt; Observe[\"toolops/observe\"]\n    Exec --&gt; Cache[\"toolops/cache\"]\n    Exec --&gt; Auth[\"toolops/auth\"]\n    Exec --&gt; Resilience[\"toolops/resilience\"]\n    Exec --&gt; Health[\"toolops/health\"]</code></pre>"},{"location":"library-docs-from-repos/toolops/architecture/#recommended-middleware-order","title":"Recommended Middleware Order","text":"<p>The order below is optimized for correctness and observability:</p> <ol> <li>Auth \u2014 reject unauthorized requests early.</li> <li>Rate limit / Resilience \u2014 prevent overload and retry safely.</li> <li>Cache \u2014 serve deterministic cached results when allowed.</li> <li>Observe \u2014 record spans/metrics/logs around the final execution.</li> </ol> <pre><code>flowchart LR\n    In[\"Request\"] --&gt; Auth\n    Auth --&gt; Resilience\n    Resilience --&gt; Cache\n    Cache --&gt; Observe\n    Observe --&gt; Exec[\"Execute Tool\"]\n    Exec --&gt; Out[\"Result\"]</code></pre>"},{"location":"library-docs-from-repos/toolops/architecture/#operational-contracts","title":"Operational Contracts","text":"<ul> <li>Concurrency: All middleware must be safe for concurrent use.</li> <li>Context: Context cancellations should abort operations quickly.</li> <li>Errors: All packages expose sentinel errors for configuration issues.</li> <li>No mutation: Middleware must not mutate tool inputs; use copies where needed.</li> </ul>"},{"location":"library-docs-from-repos/toolops/architecture/#consolidation-note","title":"Consolidation Note","text":"<p>The legacy <code>toolobserve</code> and <code>toolcache</code> repositories are consolidated into <code>toolops/observe</code> and <code>toolops/cache</code>. All behavior and contracts live here.</p>"},{"location":"library-docs-from-repos/toolops/design-notes/","title":"toolops Design Notes","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#overview","title":"Overview","text":"<p>toolops provides cross-cutting operational concerns for tool execution:</p> <ul> <li>observe: tracing, metrics, structured logging</li> <li>cache: deterministic caching with TTL policy</li> <li>auth: authentication + authorization primitives</li> <li>health: health checks and probe handlers</li> <li>resilience: retries, timeouts, circuit breakers, rate limits, bulkheads</li> </ul>"},{"location":"library-docs-from-repos/toolops/design-notes/#observe-package","title":"observe Package","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#design-decisions","title":"Design Decisions","text":"<ol> <li>Observer abstraction: Wraps OpenTelemetry tracer/meter/logger into one object.</li> <li>Middleware wrapping: <code>Middleware</code> decorates an <code>ExecuteFunc</code> for execution telemetry.</li> <li>No execution dependency: observe only instruments; it does not call tools.</li> </ol>"},{"location":"library-docs-from-repos/toolops/design-notes/#contracts","title":"Contracts","text":"<ul> <li>Observer must be shut down to flush exporters.</li> <li>Middleware wraps an <code>ExecuteFunc</code> and records telemetry per call.</li> <li>ToolMeta drives span naming (<code>tool.exec.&lt;namespace&gt;.&lt;name&gt;</code>).</li> </ul>"},{"location":"library-docs-from-repos/toolops/design-notes/#cache-package","title":"cache Package","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#design-decisions_1","title":"Design Decisions","text":"<ol> <li>Deterministic keys: Inputs are canonicalized and hashed (SHA\u2011256).</li> <li>Explicit policy: TTL and unsafe tag handling are policy\u2011driven.</li> <li>No caching on error: executor failures are never cached.</li> </ol>"},{"location":"library-docs-from-repos/toolops/design-notes/#policy-semantics","title":"Policy Semantics","text":"<ul> <li>DefaultTTL controls caching enablement (0 disables).</li> <li>MaxTTL clamps overrides.</li> <li>AllowUnsafe gates caching for unsafe-tagged tools.</li> </ul>"},{"location":"library-docs-from-repos/toolops/design-notes/#auth-package","title":"auth Package","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#design-decisions_2","title":"Design Decisions","text":"<ol> <li>Authenticator vs Authorizer: Authentication returns identities; authorization enforces permissions.</li> <li>RBAC support: Simple RBAC authorizer with role inheritance.</li> <li>Protocol-agnostic: Works with any transport layer.</li> </ol>"},{"location":"library-docs-from-repos/toolops/design-notes/#contracts_1","title":"Contracts","text":"<ul> <li>Authenticator returns <code>AuthResult</code> for success/failure; errors indicate internal failure.</li> <li>Authorizer returns an <code>AuthzError</code> when denied.</li> </ul>"},{"location":"library-docs-from-repos/toolops/design-notes/#health-package","title":"health Package","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#design-decisions_3","title":"Design Decisions","text":"<ol> <li>Checker interface: Components implement <code>Check(ctx)</code> returning <code>Result</code>.</li> <li>Aggregator: Multiple checkers can be composed into liveness/readiness endpoints.</li> <li>HTTP handlers: Built-in probe handlers for orchestration platforms.</li> </ol>"},{"location":"library-docs-from-repos/toolops/design-notes/#contracts_2","title":"Contracts","text":"<ul> <li>Checker returns a <code>Result</code> with status + details.</li> <li>Aggregator combines results and computes overall status.</li> </ul>"},{"location":"library-docs-from-repos/toolops/design-notes/#resilience-package","title":"resilience Package","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#design-decisions_4","title":"Design Decisions","text":"<ol> <li>Composable executor: Pattern chain order is deterministic and documented.</li> <li>Minimal state: Each pattern is isolated and configurable.</li> <li>Context-aware: All patterns honor cancellation and deadlines.</li> </ol>"},{"location":"library-docs-from-repos/toolops/design-notes/#execution-order","title":"Execution Order","text":"<p>The executor composes patterns in this order: 1. Rate limiter 2. Bulkhead 3. Circuit breaker 4. Retry 5. Timeout</p>"},{"location":"library-docs-from-repos/toolops/design-notes/#trade-offs","title":"Trade-offs","text":"<ul> <li>No built-in storage: cache is in-memory by default; external backends are explicit.</li> <li>No implicit telemetry: callers must wire observe middleware to execution functions.</li> <li>Fail-fast execution: resilience executor stops on first failure after pattern handling.</li> </ul>"},{"location":"library-docs-from-repos/toolops/examples/","title":"Examples","text":"<p>This page collects runnable examples for each toolops capability.</p>"},{"location":"library-docs-from-repos/toolops/examples/#observability","title":"Observability","text":"<pre><code>import (\n  \"context\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolops/observe\"\n)\n\nobs, err := observe.NewObserver(context.Background(), observe.Config{\n  ServiceName: \"metatools-mcp\",\n  Tracing:     observe.TracingConfig{Enabled: true, Exporter: \"otlp\", SamplePct: 1.0},\n  Metrics:     observe.MetricsConfig{Enabled: true, Exporter: \"prometheus\"},\n  Logging:     observe.LoggingConfig{Enabled: true, Level: \"info\"},\n})\nif err != nil {\n  log.Fatal(err)\n}\n\ndefer obs.Shutdown(context.Background())\n\nmw, _ := observe.MiddlewareFromObserver(obs)\nwrapped := mw.Wrap(func(ctx context.Context, tool observe.ToolMeta, input any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n\n_, _ = wrapped(context.Background(), observe.ToolMeta{Name: \"echo\"}, map[string]any{\"msg\": \"hi\"})\n</code></pre>"},{"location":"library-docs-from-repos/toolops/examples/#cache","title":"Cache","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/cache\"\n)\n\nc := cache.NewMemoryCache(cache.DefaultPolicy())\nkeyer := cache.NewDefaultKeyer()\npolicy := cache.DefaultPolicy()\n\nmw := cache.NewCacheMiddleware(c, keyer, policy, nil)\nresult, err := mw.Execute(context.Background(), \"github:create_issue\", map[string]any{\"title\": \"Bug\"}, []string{\"issues\"},\n  func(ctx context.Context, toolID string, input any) ([]byte, error) {\n    return []byte(\"{\\\"ok\\\":true}\"), nil\n  })\n_ = result\n_ = err\n</code></pre>"},{"location":"library-docs-from-repos/toolops/examples/#auth-jwt","title":"Auth (JWT)","text":"<pre><code>import \"github.com/jonwraymond/toolops/auth\"\n\nvalidator := auth.NewJWTValidator(auth.JWTConfig{\n  Issuer:   \"https://issuer.example.com\",\n  Audience: \"mcp\",\n})\n\nok, claims, err := validator.ValidateToken(\"&lt;token&gt;\")\n_ = ok\n_ = claims\n_ = err\n</code></pre>"},{"location":"library-docs-from-repos/toolops/examples/#health","title":"Health","text":"<pre><code>import \"github.com/jonwraymond/toolops/health\"\n\nagg := health.NewAggregator(health.AggregatorConfig{ServiceName: \"metatools-mcp\"})\nagg.Register(\"memory\", health.NewMemoryChecker(health.MemoryCheckerConfig{MaxRSSBytes: 512 * 1024 * 1024}))\n\nstatus := agg.Check(context.Background())\n_ = status\n</code></pre>"},{"location":"library-docs-from-repos/toolops/examples/#resilience","title":"Resilience","text":"<pre><code>import \"github.com/jonwraymond/toolops/resilience\"\n\nretry := resilience.NewRetry(resilience.RetryConfig{\n  MaxAttempts: 3,\n})\n\ncb := resilience.NewCircuitBreaker(resilience.CircuitBreakerConfig{\n  FailureThreshold: 5,\n})\n\n_ = retry\n_ = cb\n</code></pre>"},{"location":"library-docs-from-repos/toolops/schemas/","title":"Schemas and Contracts","text":"<p>This document describes the configuration schemas and behavioral contracts for <code>toolops</code>. These schemas are expressed as Go types with validation rules.</p>"},{"location":"library-docs-from-repos/toolops/schemas/#observe","title":"observe","text":""},{"location":"library-docs-from-repos/toolops/schemas/#config","title":"Config","text":"<p><code>observe.Config</code> is the root configuration for observability.</p> Field Type Required Notes <code>ServiceName</code> <code>string</code> Yes Required for tracing/metrics resource attribution. <code>Version</code> <code>string</code> No Optional service version label. <code>Tracing</code> <code>TracingConfig</code> No Enables and configures tracing. <code>Metrics</code> <code>MetricsConfig</code> No Enables and configures metrics. <code>Logging</code> <code>LoggingConfig</code> No Enables structured logs. <p>Validation errors (sentinels): - <code>ErrMissingServiceName</code> - <code>ErrInvalidTracingExporter</code> - <code>ErrInvalidSamplePct</code> - <code>ErrInvalidMetricsExporter</code> - <code>ErrInvalidLogLevel</code></p>"},{"location":"library-docs-from-repos/toolops/schemas/#tracingconfig","title":"TracingConfig","text":"Field Type Required Notes <code>Enabled</code> <code>bool</code> No Enable tracing. <code>Exporter</code> <code>string</code> No <code>otlp</code>, <code>jaeger</code>, <code>stdout</code>, <code>none</code>. <code>SamplePct</code> <code>float64</code> No Range <code>0.0</code>\u2013<code>1.0</code>."},{"location":"library-docs-from-repos/toolops/schemas/#metricsconfig","title":"MetricsConfig","text":"Field Type Required Notes <code>Enabled</code> <code>bool</code> No Enable metrics. <code>Exporter</code> <code>string</code> No <code>otlp</code>, <code>prometheus</code>, <code>stdout</code>, <code>none</code>."},{"location":"library-docs-from-repos/toolops/schemas/#loggingconfig","title":"LoggingConfig","text":"Field Type Required Notes <code>Enabled</code> <code>bool</code> No Enable logging. <code>Level</code> <code>string</code> No <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>. <p>Redaction: - Sensitive fields are automatically redacted using <code>observe.RedactedFields</code>.</p>"},{"location":"library-docs-from-repos/toolops/schemas/#cache","title":"cache","text":""},{"location":"library-docs-from-repos/toolops/schemas/#policy","title":"Policy","text":"<p><code>cache.Policy</code> defines caching behavior.</p> Field Type Required Notes <code>DefaultTTL</code> <code>time.Duration</code> No <code>0</code> disables caching by default. <code>MaxTTL</code> <code>time.Duration</code> No Clamp TTL overrides; <code>0</code> = no max. <code>AllowUnsafe</code> <code>bool</code> No Allow caching tools tagged as unsafe."},{"location":"library-docs-from-repos/toolops/schemas/#cache-contract","title":"Cache Contract","text":"<ul> <li><code>Get</code> returns <code>(nil, false)</code> on miss and must not error.</li> <li><code>Set</code> with <code>ttl=0</code> disables caching.</li> <li><code>Delete</code> is idempotent; no error on miss.</li> </ul>"},{"location":"library-docs-from-repos/toolops/schemas/#keyer-contract","title":"Keyer Contract","text":"<ul> <li><code>cache.Keyer</code> must return deterministic, stable keys.</li> <li>Keys must pass <code>cache.ValidateKey</code> (non-empty, &lt;=512 chars, no newlines).</li> </ul>"},{"location":"library-docs-from-repos/toolops/schemas/#auth","title":"auth","text":"<p>Auth uses specific config types per mechanism:</p> Type Purpose <code>JWTConfig</code> Validate JWT tokens and claims <code>JWKSConfig</code> JWKS URL + caching for JWT verification <code>APIKeyConfig</code> Static API key validation <code>OAuth2Config</code> Introspection settings <code>RBACConfig</code> Role-based access control <code>RoleConfig</code> Role definition + permissions <p>Contracts: - All auth checks are deterministic and side-effect free. - Errors are explicit; deny-by-default on failure.</p>"},{"location":"library-docs-from-repos/toolops/schemas/#health","title":"health","text":"Type Purpose <code>AggregatorConfig</code> Aggregates multiple checks and configures thresholds <code>MemoryCheckerConfig</code> Memory health thresholds <p>Contracts: - Health checks are fast and non-blocking. - Failures return structured errors with context.</p>"},{"location":"library-docs-from-repos/toolops/schemas/#resilience","title":"resilience","text":"Type Purpose <code>RetryConfig</code> Retry count, backoff, jitter <code>CircuitBreakerConfig</code> Failure thresholds, open/half-open timings <code>RateLimiterConfig</code> Rate, burst, time window <code>BulkheadConfig</code> Concurrency limits <code>TimeoutConfig</code> Max execution duration <p>Contracts: - All resilience middleware must be concurrency-safe. - Timeouts and cancellations honor <code>context.Context</code>. - Retry policies never retry on context cancellation.</p>"},{"location":"library-docs-from-repos/toolops/user-journey/","title":"toolops User Journey","text":""},{"location":"library-docs-from-repos/toolops/user-journey/#1-installation","title":"1. Installation","text":"<pre><code>go get github.com/jonwraymond/toolops@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#2-observability-middleware","title":"2. Observability Middleware","text":"<pre><code>import (\n  \"context\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolops/observe\"\n)\n\nobs, err := observe.NewObserver(context.Background(), observe.Config{\n  ServiceName: \"metatools-mcp\",\n  Tracing:     observe.TracingConfig{Enabled: true, Exporter: \"otlp\"},\n  Metrics:     observe.MetricsConfig{Enabled: true, Exporter: \"prometheus\"},\n  Logging:     observe.LoggingConfig{Enabled: true, Level: \"info\"},\n})\nif err != nil {\n  log.Fatal(err)\n}\ndefer obs.Shutdown(context.Background())\n\nmw, _ := observe.MiddlewareFromObserver(obs)\nwrapped := mw.Wrap(func(ctx context.Context, tool observe.ToolMeta, input any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n_, _ = wrapped(context.Background(), observe.ToolMeta{Name: \"echo\"}, map[string]any{\"msg\": \"hi\"})\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#3-caching-with-policies","title":"3. Caching with Policies","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/cache\"\n)\n\npolicy := cache.DefaultPolicy()\nc := cache.NewMemoryCache(policy)\nkeyer := cache.NewDefaultKeyer()\nmw := cache.NewCacheMiddleware(c, keyer, policy, nil)\n\n_, _ = mw.Execute(context.Background(), \"github:list_issues\", map[string]any{\"repo\": \"toolops\"}, []string{\"issues\"},\n  func(ctx context.Context, toolID string, input any) ([]byte, error) {\n    return []byte(\"{\\\"ok\\\":true}\"), nil\n  })\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#4-authentication-authorization","title":"4. Authentication + Authorization","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/auth\"\n)\n\nauthenticator := auth.NewAPIKeyAuthenticator(auth.APIKeyConfig{\n  Header: \"X-API-Key\",\n  Keys:   map[string]string{\"dev-key\": \"developer\"},\n})\n\nauthorizer := auth.NewSimpleRBACAuthorizer(auth.RBACConfig{\n  DefaultRole: \"reader\",\n  Roles: map[string]auth.RoleConfig{\n    \"reader\": {AllowedTools: []string{\"github:*\"}, AllowedActions: []string{\"list\"}},\n  },\n})\n\nreq := &amp;auth.AuthRequest{Headers: map[string][]string{\"X-API-Key\": {\"dev-key\"}}}\nresult, _ := authenticator.Authenticate(context.Background(), req)\nif result != nil &amp;&amp; result.Identity != nil {\n  _ = authorizer.Authorize(context.Background(), &amp;auth.AuthzRequest{\n    Subject: result.Identity,\n    Resource: \"tool:github:list_issues\",\n    Action: \"list\",\n  })\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#5-health-checks","title":"5. Health Checks","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/health\"\n)\n\nagg := health.NewAggregator()\nagg.Register(\"memory\", health.NewMemoryChecker(health.MemoryCheckerConfig{\n  WarningThreshold: 0.80,\n  CriticalThreshold: 0.95,\n}))\n\nresults := agg.CheckAll(context.Background())\noverall := agg.OverallStatus(results)\n_ = overall\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#6-resilience-patterns","title":"6. Resilience Patterns","text":"<pre><code>import (\n  \"context\"\n  \"time\"\n\n  \"github.com/jonwraymond/toolops/resilience\"\n)\n\nexecutor := resilience.NewExecutor(\n  resilience.WithRetry(resilience.NewRetry(resilience.RetryConfig{\n    MaxAttempts: 3,\n  })),\n  resilience.WithTimeout(2*time.Second),\n)\n\n_ = executor.Execute(context.Background(), func(ctx context.Context) error {\n  return nil\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Combine <code>observe</code> + <code>cache</code> + <code>resilience</code> in a middleware chain.</li> <li>Use <code>auth</code> + <code>health</code> to harden MCP endpoints.</li> <li>Review the Examples page for runnable snippets.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/","title":"toolprotocol","text":"<p>Protocol layer providing transport, wire format, and protocol primitives for MCP, A2A, and ACP integrations. The packages here are transport-agnostic and composable.</p>"},{"location":"library-docs-from-repos/toolprotocol/#packages","title":"Packages","text":"Package Purpose <code>content</code> Unified content parts (text, image, audio, file, resource) <code>discover</code> Service discovery + capability negotiation <code>transport</code> Transport interfaces (stdio, SSE, streamable HTTP) <code>wire</code> Protocol wire encoding (MCP, A2A, ACP) <code>stream</code> Streaming events for progress/partial/complete <code>session</code> Client session store + context helpers <code>task</code> Long-running task lifecycle + subscriptions <code>resource</code> MCP resources registry + subscriptions <code>prompt</code> Prompt templates + registry <code>elicit</code> User input elicitation (text/confirm/choice/form)"},{"location":"library-docs-from-repos/toolprotocol/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolprotocol@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/#documentation-map","title":"Documentation Map","text":"<ul> <li>Architecture</li> <li>Schemas and Contracts</li> <li>Examples</li> <li>Design Notes</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/#quick-start-wire-transport","title":"Quick Start: Wire + Transport","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/transport\"\n  \"github.com/jonwraymond/toolprotocol/wire\"\n)\n\ntype server struct{}\n\nfunc (s *server) ServeTransport(ctx context.Context, t transport.Transport) error {\n  // decode/route using wire codecs\n  return nil\n}\n\nctx := context.Background()\ncodec := wire.NewMCP()\npayload, _ := codec.EncodeRequest(ctx, &amp;wire.Request{\n  ID:        \"1\",\n  Method:    \"tools/list\",\n  ToolID:    \"\",\n  Arguments: nil,\n})\n\ntp, _ := transport.New(\"stdio\", nil)\n_ = payload\n_ = tp.Serve(ctx, &amp;server{})\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/#quick-start-tasks-streaming","title":"Quick Start: Tasks + Streaming","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/stream\"\n  \"github.com/jonwraymond/toolprotocol/task\"\n)\n\nctx := context.Background()\nmgr := task.NewManager()\n_ , _ = mgr.Create(ctx, \"task-1\")\n\nsource := stream.NewSource()\ns := source.NewBufferedStream(ctx, 50)\n_ = s.Send(ctx, stream.Event{Type: stream.EventProgress, Data: 0.5})\n_ = s.Send(ctx, stream.Event{Type: stream.EventComplete, Data: map[string]any{\"ok\": true}})\n_ = s.Close()\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/#contracts-summary","title":"Contracts (Summary)","text":"<ul> <li>Transport: concurrent-safe; <code>Serve</code> honors context; <code>Close</code> is idempotent.</li> <li>Wire: encode/decode deterministic; <code>Capabilities</code> must match actual behavior.</li> <li>Content: immutable content instances; <code>Bytes</code> must be safe to call multiple times.</li> <li>Stream: event ordering preserved; <code>Done</code> closes after <code>Close</code>.</li> <li>Task: state machine enforces valid transitions; terminal states are final.</li> <li>Session: store guarantees TTL cleanup and thread safety.</li> <li>Resource/Prompt/Elicit: registries are concurrency-safe; errors are explicit.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/architecture/","title":"toolprotocol Architecture","text":"<p>The toolprotocol layer defines protocol primitives for tool exchange. It does not implement execution or discovery; it standardizes how tools, results, and streams are transported between systems.</p>"},{"location":"library-docs-from-repos/toolprotocol/architecture/#design-principles","title":"Design Principles","text":"<ul> <li>Protocol-first: wire/transport types are independent of transport runtime.</li> <li>Composable: packages can be used individually (e.g., <code>wire</code> only).</li> <li>Deterministic: message schemas are stable and versioned.</li> <li>Streaming-safe: stream/session types are concurrency-safe by default.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/architecture/#core-packages","title":"Core Packages","text":"Package Responsibility <code>wire</code> Low-level protocol types and envelopes <code>transport</code> Transport-agnostic interfaces (SSE/stdio/etc.) <code>content</code> Content blocks and rendering helpers <code>stream</code> Streaming event types and default stream implementation <code>session</code> Session identifiers, lifecycles, and context <code>task</code> Task/event primitives for long-running work <code>resource</code> Resource references and metadata <code>prompt</code> Prompt templates and variables <code>discover</code> Discovery request/response types <code>elicit</code> Elicitation prompts and responses"},{"location":"library-docs-from-repos/toolprotocol/architecture/#layering","title":"Layering","text":"<pre><code>flowchart TB\n    subgraph Protocol\n        Wire[\"wire\"]\n        Transport[\"transport\"]\n        Stream[\"stream\"]\n        Session[\"session\"]\n    end\n\n    subgraph Content\n        ContentPkg[\"content\"]\n        Prompt[\"prompt\"]\n        Resource[\"resource\"]\n        Elicit[\"elicit\"]\n    end\n\n    subgraph Tasks\n        Task[\"task\"]\n        Discover[\"discover\"]\n    end\n\n    Wire --&gt; Transport\n    Wire --&gt; Stream\n    Stream --&gt; Session\n    ContentPkg --&gt; Wire\n    Prompt --&gt; ContentPkg\n    Resource --&gt; ContentPkg\n    Elicit --&gt; ContentPkg\n    Task --&gt; Wire\n    Discover --&gt; Wire</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/architecture/#protocol-boundary","title":"Protocol Boundary","text":"<p><code>toolprotocol</code> is consumed by higher layers (e.g., <code>metatools-mcp</code>). It does not own transport servers/clients itself. The intention is to keep protocol types portable across SSE, stdio, and HTTP.</p>"},{"location":"library-docs-from-repos/toolprotocol/architecture/#concurrency-contract","title":"Concurrency Contract","text":"<ul> <li>Streams must be safe for concurrent writers and readers.</li> <li>Close operations are idempotent.</li> <li>Sessions must not leak goroutines or block on close.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/architecture/#consolidation-note","title":"Consolidation Note","text":"<p>Legacy protocol primitives from the pre-consolidation stack are now unified here, with stable import paths under <code>github.com/jonwraymond/toolprotocol/...</code>.</p>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/","title":"Design Notes","text":""},{"location":"library-docs-from-repos/toolprotocol/design-notes/#architecture-decisions","title":"Architecture Decisions","text":"<ol> <li>Layered protocols, not monoliths. Transport, wire format, and content are    isolated so that new protocols can reuse the same primitives.</li> <li>Protocol-agnostic primitives. Packages like <code>task</code>, <code>stream</code>, <code>session</code>,    <code>resource</code>, and <code>prompt</code> are independent of MCP/A2A/ACP specifics.</li> <li>Deterministic encoding. <code>wire</code> implementations must encode/decode    deterministically to preserve caching and reproducibility.</li> <li>Minimal dependencies. The repo avoids heavy deps to keep transport    implementations portable across environments.</li> </ol>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#contract-semantics","title":"Contract Semantics","text":""},{"location":"library-docs-from-repos/toolprotocol/design-notes/#transport","title":"transport","text":"<ul> <li>Concurrency: implementations must be safe for concurrent use.</li> <li>Cancellation: <code>Serve</code> must respect context cancellation.</li> <li>Idempotency: <code>Close</code> is safe to call multiple times.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#wire","title":"wire","text":"<ul> <li>Lossless mapping: encode/decode preserves request/response shape.</li> <li>Capabilities: <code>Capabilities()</code> must reflect actual encoder support.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#content","title":"content","text":"<ul> <li>Immutability: content instances are safe to share across goroutines.</li> <li>MIME fidelity: <code>MIMEType</code> must always match the payload.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#stream","title":"stream","text":"<ul> <li>Ordering: events are delivered in send order.</li> <li>Termination: <code>Done()</code> closes after <code>Close()</code> completes.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#task","title":"task","text":"<ul> <li>State machine: only valid transitions are allowed.</li> <li>Subscriptions: updates are fan-out safe and non-blocking.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#sessionresourcepromptelicit","title":"session/resource/prompt/elicit","text":"<ul> <li>Thread safety: registries are concurrency-safe.</li> <li>Explicit errors: missing keys or invalid args return typed errors.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#trade-offs","title":"Trade-offs","text":"<ul> <li>Pure interfaces vs. convenience helpers. We keep core interfaces small and   provide optional helpers in each package to avoid bloated APIs.</li> <li>Broad scope vs. cohesion. This repo groups protocol primitives to simplify   versioning, but avoids pulling in execution or schema concerns.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/toolprotocol/examples/#wire-envelope","title":"Wire Envelope","text":"<pre><code>import \"github.com/jonwraymond/toolprotocol/wire\"\n\nmsg := wire.Envelope{\n  Version: \"1.0\",\n  Type:    \"discover.request\",\n  Payload: map[string]any{\n    \"query\": \"create issue\",\n  },\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/examples/#stream","title":"Stream","text":"<pre><code>import \"github.com/jonwraymond/toolprotocol/stream\"\n\ns := stream.NewDefaultStream()\n\ngo func() {\n  _ = s.Send(stream.Event{Type: \"progress\", Data: map[string]any{\"pct\": 50}})\n  _ = s.Close()\n}()\n\nfor ev := range s.Events() {\n  _ = ev\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/examples/#session","title":"Session","text":"<pre><code>import \"github.com/jonwraymond/toolprotocol/session\"\n\nsess := session.New(session.Config{ID: \"session-1\"})\nctx := sess.Context()\n_ = ctx\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/examples/#content-blocks","title":"Content Blocks","text":"<pre><code>import \"github.com/jonwraymond/toolprotocol/content\"\n\nblock := content.Block{\n  Type: \"text\",\n  Data: map[string]any{\"text\": \"hello\"},\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/schemas/","title":"Schemas and Contracts","text":"<p>This document defines the protocol schema contracts in <code>toolprotocol</code>. These are structural schemas (wire formats, streaming events, sessions), not execution schemas.</p>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#wire","title":"wire","text":"<p>The <code>wire</code> package defines protocol envelopes for requests and responses.</p> <p>Contract highlights:</p> <ul> <li>All envelopes carry a version and type.</li> <li>Payloads are JSON-serializable and stable across transports.</li> <li>Unknown fields must be ignored for forward compatibility.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#transport","title":"transport","text":"<p><code>transport</code> defines interfaces for moving <code>wire</code> payloads across channels.</p> <p>Contract highlights:</p> <ul> <li>Implementations must be concurrency-safe.</li> <li>Close operations are idempotent.</li> <li>Errors must wrap <code>context.Canceled</code> and <code>context.DeadlineExceeded</code> when applicable.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#stream","title":"stream","text":"<p>Streams represent ordered event sequences.</p> <p>Contract highlights:</p> <ul> <li>Events are delivered in-order.</li> <li>Close is idempotent; no panic on double-close.</li> <li>Readers must not block indefinitely after Close.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#session","title":"session","text":"<p>Sessions track ongoing interactions across transports.</p> <p>Contract highlights:</p> <ul> <li>Session IDs are unique and immutable.</li> <li>Context cancellation must terminate session-bound operations.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#content","title":"content","text":"<p><code>content</code> defines structured content blocks.</p> <p>Contract highlights:</p> <ul> <li>Content blocks are self-describing (<code>type</code> + <code>data</code>).</li> <li>Blocks must be valid JSON and stable for storage/transmission.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#task","title":"task","text":"<p><code>task</code> defines long-running work events.</p> <p>Contract highlights:</p> <ul> <li>Task state transitions are monotonic.</li> <li>Errors are represented using a stable error envelope.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#discover","title":"discover","text":"<p>Discovery request/response shapes.</p> <p>Contract highlights:</p> <ul> <li>Search requests are deterministic.</li> <li>Responses include stable identifiers; schemas are not required in discovery.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#prompt-elicit","title":"prompt + elicit","text":"<p>Prompt templates and elicitation flows.</p> <p>Contract highlights:</p> <ul> <li>Prompts are explicit about required variables.</li> <li>Elicitation responses map 1:1 to requested fields.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/user-journey/","title":"User Journey","text":""},{"location":"library-docs-from-repos/toolprotocol/user-journey/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolprotocol@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/user-journey/#basic-usage-minimal-protocol-server","title":"Basic Usage: Minimal Protocol Server","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/transport\"\n  \"github.com/jonwraymond/toolprotocol/wire\"\n)\n\ntype server struct{\n  codec wire.Wire\n}\n\nfunc (s *server) ServeTransport(ctx context.Context, t transport.Transport) error {\n  // Read bytes from transport, decode with s.codec, route to handlers.\n  return nil\n}\n\nctx := context.Background()\nsrv := &amp;server{codec: wire.NewMCP()}\ntp, _ := transport.New(\"stdio\", nil)\n_ = tp.Serve(ctx, srv)\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/user-journey/#intermediate-sessions-resources","title":"Intermediate: Sessions + Resources","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/resource\"\n  \"github.com/jonwraymond/toolprotocol/session\"\n)\n\nctx := context.Background()\n\nstore := session.NewMemoryStore()\nsess, _ := store.Create(ctx, \"client-1\")\nctx = session.WithSession(ctx, sess)\n\nregistry := resource.NewRegistry()\nstatic := resource.NewStaticProvider()\nstatic.Add(\n  resource.Resource{URI: \"file:///readme.md\", Name: \"README\", MIMEType: \"text/markdown\"},\n  resource.Contents{URI: \"file:///readme.md\", MIMEType: \"text/markdown\", Text: \"# README\"},\n)\nregistry.Register(\"file\", static)\n\n_, _ = registry.Read(ctx, \"file:///readme.md\")\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/user-journey/#advanced-task-streaming","title":"Advanced: Task + Streaming","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/stream\"\n  \"github.com/jonwraymond/toolprotocol/task\"\n)\n\nctx := context.Background()\nmgr := task.NewManager()\n_ , _ = mgr.Create(ctx, \"job-123\")\n\nsource := stream.NewSource()\ns := source.NewBufferedStream(ctx, 100)\n_ = s.Send(ctx, stream.Event{Type: stream.EventProgress, Data: 0.3})\n_ = s.Send(ctx, stream.Event{Type: stream.EventComplete, Data: map[string]any{\"ok\": true}})\n_ = s.Close()\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Review the Examples page for runnable snippets.</li> <li>Use <code>toolprotocol/wire</code> + <code>toolprotocol/transport</code> inside <code>metatools-mcp</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/","title":"metatools-mcp","text":"<p><code>metatools-mcp</code> is the MCP server that exposes the tool stack via a small, progressive-disclosure tool surface. It composes <code>toolfoundation</code>, <code>tooldiscovery</code>, <code>toolexec</code>, and optionally <code>toolexec/runtime</code> for sandboxed execution.</p> <p></p>"},{"location":"library-docs-from-repos/metatools-mcp/#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: design-notes.md</li> <li>User Journey: user-journey.md</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#motivation","title":"Motivation","text":"<ul> <li>One MCP surface for discovery, docs, and execution</li> <li>Progressive disclosure to keep tool context small</li> <li>Pluggable design for search, runtimes, and engines</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#mcp-tools-exposed","title":"MCP tools exposed","text":"<ul> <li><code>search_tools</code></li> <li><code>list_namespaces</code></li> <li><code>describe_tool</code></li> <li><code>list_tool_examples</code></li> <li><code>run_tool</code></li> <li><code>run_chain</code></li> <li><code>execute_code</code> (optional)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#quickstart","title":"Quickstart","text":"<pre><code>idx := index.NewInMemoryIndex()\ndocs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\nrunner := run.NewRunner(run.WithIndex(idx))\n\ncfg := adapters.NewConfig(idx, docs, runner, nil)\nserver, _ := server.New(cfg)\n\n_ = server.Run(context.Background(), &amp;mcp.StdioTransport{})\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/#usability-notes","title":"Usability notes","text":"<ul> <li>Fewer MCP tools means simpler agent prompts</li> <li>Outputs are structured and aligned to MCP schemas</li> <li>Search and execution behaviors are deterministic by default</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#runtime-notes-execute_code","title":"Runtime notes (execute_code)","text":"<p><code>execute_code</code> is optional and wired behind the <code>toolruntime</code> build tag. By default, the runtime uses the unsafe dev profile; when Docker is available, set <code>METATOOLS_RUNTIME_PROFILE=standard</code> to enable the hardened Docker backend. WASM can be enabled with <code>METATOOLS_WASM_ENABLED=true</code> and selected with <code>METATOOLS_RUNTIME_BACKEND=wasm</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/#interface-contracts","title":"Interface Contracts","text":"<ul> <li>Transport: thread-safe; <code>Serve</code> honors context; <code>Close</code> is idempotent.</li> <li>Backend: thread-safe; <code>ListTools</code>/<code>Execute</code> honor context; streaming backends return non-nil channel when err is nil.</li> <li>ToolProvider: thread-safe; <code>Handle</code> honors context; streaming providers return non-nil channel when err is nil.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#next","title":"Next","text":"<ul> <li>Server architecture: <code>architecture.md</code></li> <li>Ordered execution plan: <code>plan-of-record.md</code></li> <li>Configuration and env vars: <code>usage.md</code></li> <li>Examples: <code>examples.md</code></li> <li>Design Notes: design-notes.md</li> <li>User Journey: user-journey.md</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#proposals","title":"Proposals","text":"<p>Master Plan: - ROADMAP - Master roadmap with all work streams, phases, and milestones</p> <p>Architecture: - Pluggable Architecture - Extensible, modular design - Architecture Evaluation - Championship-level comparison - Component Library Analysis - Tool* library ecosystem - Architecture Review - Comprehensive proposal analysis and consistency check - MCP Spec Alignment - Targeted spec compliance improvements</p> <p>Features: - Protocol-Agnostic Tools - Composable toolsets and protocol adapters - Multi-Tenancy Extension - Tenant isolation patterns - Agent Skills - Higher-level capability composition (see ROADMAP)</p> <p>Implementation: - Implementation Phases - Phased rollout plan</p>"},{"location":"library-docs-from-repos/metatools-mcp/api/","title":"API Reference","text":""},{"location":"library-docs-from-repos/metatools-mcp/api/#server","title":"Server","text":"<pre><code>func New(cfg config.Config) (*Server, error)\nfunc (s *Server) Run(ctx context.Context, transport mcp.Transport) error\nfunc (s *Server) MCPServer() *mcp.Server\nfunc (s *Server) ListTools() []*mcp.Tool\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/api/#config","title":"Config","text":"<pre><code>type Config struct {\n  Index    index.Index\n  Docs     tooldoc.Store\n  Runner   run.Runner\n  Executor code.Executor // optional\n\n  NotifyToolListChanged           bool\n  NotifyToolListChangedDebounceMs int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/api/#interface-contracts","title":"Interface Contracts","text":"<ul> <li>Transport: thread-safe; <code>Serve</code> honors context; <code>Close</code> is idempotent.</li> <li>Backend: thread-safe; <code>ListTools</code>/<code>Execute</code> honor context; streaming backends must return non-nil channel when err is nil.</li> <li>ToolProvider: thread-safe; <code>Handle</code> honors context; streaming providers must return non-nil channel when err is nil.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/api/#transport","title":"Transport","text":"<p>The transport layer is in <code>internal/transport</code>:</p> <pre><code>// Transport interface for MCP protocol transports\ntype Transport interface {\n  Name() string\n  Info() Info\n  Serve(ctx context.Context, server Server) error\n  Close() error\n}\n\n// Info describes a transport instance\ntype Info struct {\n  Name string\n  Addr string\n  Path string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/api/#available-transports","title":"Available transports","text":"Type Struct Use Case stdio <code>StdioTransport</code> Claude Desktop, local CLI streamable <code>StreamableHTTPTransport</code> Web apps, HTTP clients (MCP 2025-03-26) sse <code>SSETransport</code> Legacy HTTP clients (deprecated)"},{"location":"library-docs-from-repos/metatools-mcp/api/#streamablehttpconfig","title":"StreamableHTTPConfig","text":"<pre><code>type StreamableHTTPConfig struct {\n  Host              string        // Network interface (default: \"0.0.0.0\")\n  Port              int           // TCP port (required)\n  Path              string        // Endpoint path (default: \"/mcp\")\n  ReadHeaderTimeout time.Duration // Header read timeout (default: 10s)\n  TLS               TLSConfig     // HTTPS configuration\n  Stateless         bool          // Disable session management\n  JSONResponse      bool          // Prefer JSON over SSE streaming\n  SessionTimeout    time.Duration // Idle session cleanup\n}\n\ntype TLSConfig struct {\n  Enabled  bool\n  CertFile string\n  KeyFile  string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/api/#toolruntime-integration","title":"Toolruntime integration","text":"<p>When built with <code>-tags toolruntime</code>, <code>execute_code</code> is backed by a <code>toolexec/runtime</code> runtime. The runtime selects a profile at startup:</p> <ul> <li><code>dev</code> profile: unsafe subprocess backend (default).</li> <li><code>standard</code> profile: Docker sandbox by default or WASM when selected.</li> <li><code>METATOOLS_DOCKER_IMAGE</code> overrides the sandbox image name.</li> <li><code>METATOOLS_WASM_ENABLED=true</code> enables the WASM backend (wazero).</li> <li><code>METATOOLS_RUNTIME_BACKEND=wasm</code> selects WASM for the standard profile.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/api/#mcp-tool-io-types","title":"MCP tool I/O types","text":"<p>These are exported in <code>pkg/metatools</code>:</p> <ul> <li><code>SearchToolsInput</code> / <code>SearchToolsOutput</code></li> <li><code>ListNamespacesInput</code> / <code>ListNamespacesOutput</code></li> <li><code>DescribeToolInput</code> / <code>DescribeToolOutput</code></li> <li><code>ListToolExamplesInput</code> / <code>ListToolExamplesOutput</code></li> <li><code>RunToolInput</code> / <code>RunToolOutput</code></li> <li><code>RunChainInput</code> / <code>RunChainOutput</code></li> <li><code>ExecuteCodeInput</code> / <code>ExecuteCodeOutput</code></li> </ul> <p>Notes: - <code>SearchToolsInput</code>/<code>ListNamespacesInput</code> accept <code>limit</code> + <code>cursor</code>. - <code>SearchToolsOutput</code>/<code>ListNamespacesOutput</code> return <code>nextCursor</code> when more data exists.</p>"},{"location":"library-docs-from-repos/metatools-mcp/api/#error-codes","title":"Error codes","text":"<p>Metatools surfaces standardized error codes (strings), including:</p> <ul> <li><code>tool_not_found</code></li> <li><code>no_backends</code></li> <li><code>validation_input</code></li> <li><code>validation_output</code></li> <li><code>execution_failed</code></li> <li><code>stream_not_supported</code></li> <li><code>chain_step_failed</code></li> <li><code>cancelled</code></li> <li><code>timeout</code></li> <li><code>internal</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/architecture/","title":"Architecture","text":"<p><code>metatools-mcp</code> composes the core libraries and exposes a small MCP tool surface.</p>"},{"location":"library-docs-from-repos/metatools-mcp/architecture/#transport-layer","title":"Transport layer","text":"<p>The transport layer abstracts how clients connect to the MCP server. All transports implement the <code>Transport</code> interface, enabling protocol flexibility without changing server logic.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#805ad5'}}}%%\nclassDiagram\n    class Transport {\n        &lt;&lt;interface&gt;&gt;\n        +Name() string\n        +Info() Info\n        +Serve(ctx, server) error\n        +Close() error\n    }\n\n    class StdioTransport {\n        +Name() \"stdio\"\n        +Serve() stdin/stdout\n    }\n\n    class StreamableHTTPTransport {\n        +Config StreamableHTTPConfig\n        +Name() \"streamable\"\n        +Serve() HTTP POST/GET/DELETE\n    }\n\n    class SSETransport {\n        +Config SSEConfig\n        +Name() \"sse\"\n        +Serve() HTTP + SSE\n    }\n\n    Transport &lt;|.. StdioTransport\n    Transport &lt;|.. StreamableHTTPTransport\n    Transport &lt;|.. SSETransport\n\n    note for StreamableHTTPTransport \"MCP spec 2025-03-26\\nRecommended for HTTP\"\n    note for SSETransport \"Deprecated\"</code></pre> Transport Protocol Session Best For <code>stdio</code> stdin/stdout JSON-RPC Implicit Claude Desktop, local CLI <code>streamable</code> HTTP POST/GET/DELETE Mcp-Session-Id header Web apps, remote clients <code>sse</code> HTTP + Server-Sent Events Cookie-based Legacy (deprecated)"},{"location":"library-docs-from-repos/metatools-mcp/architecture/#component-wiring","title":"Component wiring","text":""},{"location":"library-docs-from-repos/metatools-mcp/architecture/#runtime-layer-execute_code","title":"Runtime layer (execute_code)","text":"<p>When built with the <code>toolruntime</code> tag, <code>execute_code</code> is backed by a runtime that selects between an unsafe dev backend and a Docker-backed standard backend. Docker is opt-in via <code>METATOOLS_RUNTIME_PROFILE=standard</code>.</p> <p>Standard isolation can also be provided by the WASM backend when enabled (<code>METATOOLS_WASM_ENABLED=true</code>, <code>METATOOLS_RUNTIME_BACKEND=wasm</code>). If Docker is unavailable and WASM is enabled, the server falls back to WASM for the standard profile.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0'}}}%%\nflowchart LR\n    Agent[\"AI Agent\"] --&gt; MCP[\"metatools-mcp\"]\n    MCP --&gt; Toolcode[\"toolexec/code Executor\"]\n    Toolcode --&gt; Runtime[\"toolexec/runtime\"]\n\n    Runtime --&gt; Dev[\"dev profile&lt;br/&gt;unsafe subprocess\"]\n    Runtime --&gt; Standard[\"standard profile&lt;br/&gt;Docker sandbox\"]\n\n    style MCP fill:#2b6cb0,stroke:#2c5282\n    style Toolcode fill:#6b46c1,stroke:#553c9a\n    style Runtime fill:#4a5568,stroke:#2d3748\n    style Dev fill:#dd6b20,stroke:#c05621\n    style Standard fill:#2f855a,stroke:#276749</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/architecture/#progressive-disclosure-flow","title":"Progressive disclosure flow","text":""},{"location":"library-docs-from-repos/metatools-mcp/architecture/#mcp-tool-mapping","title":"MCP tool mapping","text":""},{"location":"library-docs-from-repos/metatools-mcp/changelog/","title":"Changelog","text":""},{"location":"library-docs-from-repos/metatools-mcp/changelog/#unreleased","title":"Unreleased","text":""},{"location":"library-docs-from-repos/metatools-mcp/changelog/#added","title":"Added","text":"<ul> <li>Cursor-based pagination for <code>search_tools</code> and <code>list_namespaces</code> with opaque cursors.</li> <li><code>notifications/tools/list_changed</code> support with debounce and env toggle.</li> <li>Tests for list-changed notifications and cancellation propagation.</li> <li>Progress notifications for <code>run_tool</code>, <code>run_chain</code>, and <code>execute_code</code> when a progress token is provided.</li> <li>Cancellation and timeout error codes (<code>cancelled</code>, <code>timeout</code>) for tool failures.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/changelog/#changed","title":"Changed","text":"<ul> <li><code>list_namespaces</code> input/output schemas now include <code>limit</code>, <code>cursor</code>, and <code>nextCursor</code>.</li> <li>Cursor helpers marked deprecated in favor of toolindex tokens.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/","title":"Design Notes","text":"<p>This page documents the tradeoffs and error semantics behind <code>metatools-mcp</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#design-tradeoffs","title":"Design tradeoffs","text":"<ul> <li>MCP-native surface. All metatools (search, describe, run, chain, execute_code) are exposed via the official MCP Go SDK types to keep wire compatibility.</li> <li>Adapters, not re-implementation. The server delegates to tooldiscovery/index, tooldiscovery/tooldoc, toolexec/run, and toolexec/code via thin adapters so the libraries remain the source of truth.</li> <li>Structured error objects. Tool-level errors are returned in a consistent <code>ErrorObject</code> shape rather than raw Go errors, preserving the MCP tool contract.</li> <li>Explicit limits. Inputs such as <code>limit</code> and <code>max</code> are capped for safe defaults (e.g., search limit cap 100, examples cap 5).</li> <li>Opaque pagination. Cursor tokens are opaque and validated against index mutations to prevent stale paging.</li> <li>Pluggable search. BM25 is optional via build tags (<code>toolsearch</code>) and runtime config via env vars.</li> <li>Change notifications. Tool list updates emit <code>notifications/tools/list_changed</code> with a debounce window; notifications can be disabled and are emitted as a single list change per debounce window.</li> <li>Transport abstraction. The <code>Transport</code> interface decouples protocol handling from server logic, enabling stdio, SSE, and Streamable HTTP without code changes.</li> <li>Runtime isolation. <code>execute_code</code> is optional; the <code>toolruntime</code> build tag enables sandboxed execution via toolexec/runtime with runtime profile selection.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#transport-layer","title":"Transport layer","text":"<p>The transport layer abstracts how clients connect to the MCP server. All transports implement the same <code>Transport</code> interface, ensuring identical behavior regardless of protocol:</p> <pre><code>type Transport interface {\n    Name() string\n    Info() Info\n    Serve(ctx context.Context, server Server) error\n    Close() error\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#transport-selection-rationale","title":"Transport selection rationale","text":"Transport Status Use Case Rationale <code>stdio</code> Recommended (local) Claude Desktop, local CLIs Zero config, implicit session, lowest latency <code>streamable</code> Recommended (HTTP) Web apps, remote clients MCP spec 2025-03-26 compliant, session management, bidirectional <code>sse</code> Deprecated Legacy web clients Superseded by streamable per MCP spec"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#streamable-http-design-decisions","title":"Streamable HTTP design decisions","text":"<ol> <li> <p>Single endpoint (<code>/mcp</code>): Follows MCP spec 2025-03-26 with POST/GET/DELETE methods    on one path, simplifying routing and CORS configuration.</p> </li> <li> <p>Session management via header: Uses <code>Mcp-Session-Id</code> header (not cookies) for    stateless load balancing compatibility and explicit session lifecycle.</p> </li> <li> <p>Stateless mode option: Enables serverless/FaaS deployments where session    persistence is impractical. Trade-off: no server-initiated requests.</p> </li> <li> <p>JSON vs SSE response modes: Default SSE streaming supports long-running tools;    <code>JSONResponse=true</code> option for simpler request/response patterns.</p> </li> <li> <p>TLS built-in: Direct TLS support avoids reverse proxy requirements for simple    deployments while allowing proxy termination for complex setups.</p> </li> <li> <p>Graceful shutdown: 5-second timeout allows in-flight requests to complete,    balancing responsiveness with reliability.</p> </li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#error-semantics","title":"Error semantics","text":"<p><code>metatools-mcp</code> distinguishes protocol errors from tool errors:</p> <ul> <li>Protocol errors (invalid input) return a non-nil error from handlers.</li> <li>Tool errors are wrapped into <code>ErrorObject</code> and returned with <code>isError = true</code> so MCP clients treat them as tool failures.</li> </ul> <p>Key error behaviors:</p> <ul> <li><code>run_tool</code> rejects <code>stream=true</code> and <code>backend_override</code> in the default handler (not supported yet).</li> <li><code>run_chain</code> stops on first error and returns partial results with an <code>ErrorObject</code>.</li> <li><code>describe_tool</code>/<code>list_tool_examples</code> return validation errors when required fields are missing.</li> <li>Invalid cursors return JSON-RPC invalid params.</li> <li>Cancellation and timeouts map to <code>cancelled</code> and <code>timeout</code> error codes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#extension-points","title":"Extension points","text":"<ul> <li>Transport: implement <code>Transport</code> interface to add new protocols (e.g., WebSocket, gRPC).</li> <li>Search strategy: enable BM25 via the <code>toolsearch</code> build tag and env vars.</li> <li>Tool execution: swap <code>toolexec/run</code> runner implementation or configure different backends.</li> <li>Code execution: plug in a different <code>toolexec/code</code> engine (e.g., toolexec/runtime-backed).</li> <li>Progress: when a progress token is provided, <code>run_tool</code>, <code>run_chain</code>, and <code>execute_code</code> emit progress notifications. If the runner supports progress callbacks, step-level updates are forwarded; otherwise a coarse start/end signal is sent.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#runtime-profile-selection","title":"Runtime profile selection","text":"<p>When built with <code>-tags toolruntime</code>, metatools-mcp wires <code>toolexec/runtime</code> into <code>toolexec/code</code>:</p> <ul> <li>Dev profile (<code>dev</code>) uses the unsafe subprocess backend for fast iteration.</li> <li>Standard profile (<code>standard</code>) uses Docker by default or WASM when selected.</li> <li>Set <code>METATOOLS_RUNTIME_PROFILE=standard</code> to opt into standard isolation.</li> <li>Use <code>METATOOLS_RUNTIME_BACKEND=wasm</code> with <code>METATOOLS_WASM_ENABLED=true</code> to   prefer the WASM backend (wazero) for standard profile.</li> <li>If Docker is unavailable and WASM is enabled, the server falls back to WASM   for the standard profile.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#operational-guidance","title":"Operational guidance","text":""},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#transport-configuration","title":"Transport configuration","text":"<ul> <li>Use <code>--transport=stdio</code> (default) for Claude Desktop and local CLI integration.</li> <li>Use <code>--transport=streamable --port=8080</code> for HTTP-based clients and web applications.</li> <li>Configure TLS for production HTTP deployments: <code>--tls --tls-cert=cert.pem --tls-key=key.pem</code></li> <li>Use <code>--stateless</code> for serverless/FaaS where session persistence is unavailable.</li> <li>Set <code>METATOOLS_TRANSPORT_STREAMABLE_SESSION_TIMEOUT</code> to control idle session cleanup.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#search-configuration","title":"Search configuration","text":"<ul> <li>Use environment variables to configure search strategy:</li> <li><code>METATOOLS_SEARCH_STRATEGY=lexical|bm25</code></li> <li><code>METATOOLS_SEARCH_BM25_*</code> for weighting and caps</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#general-guidance","title":"General guidance","text":"<ul> <li>Keep tool schemas in <code>toolfoundation/model</code> to preserve MCP compatibility end-to-end.</li> <li>Treat metatools as the stable surface; update libraries behind it as needed.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/metatools-mcp/examples/#register-a-local-tool-expose-mcp-server","title":"Register a local tool + expose MCP server","text":"<pre><code>type localRegistry struct {\n  handlers map[string]run.LocalHandler\n}\n\nfunc newLocalRegistry() *localRegistry {\n  return &amp;localRegistry{handlers: make(map[string]run.LocalHandler)}\n}\n\nfunc (r *localRegistry) Get(name string) (run.LocalHandler, bool) {\n  h, ok := r.handlers[name]\n  return h, ok\n}\n\nfunc (r *localRegistry) Register(name string, h run.LocalHandler) {\n  r.handlers[name] = h\n}\n\nidx := index.NewInMemoryIndex()\n\nlocal := newLocalRegistry()\nlocal.Register(\"ping\", func(ctx context.Context, args map[string]any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n\n_ = idx.RegisterTool(model.Tool{\n  Namespace: \"local\",\n  Tool: mcp.Tool{\n    Name:        \"ping\",\n    Description: \"Simple health check\",\n    InputSchema: map[string]any{\"type\": \"object\"},\n  },\n}, model.ToolBackend{\n  Kind:  model.BackendKindLocal,\n  Local: &amp;model.LocalBackend{Name: \"ping\"},\n})\n\nrunner := run.NewRunner(run.WithIndex(idx), run.WithLocalRegistry(local))\n\ncfg := adapters.NewConfig(idx, tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx}), runner, nil)\nserver, _ := server.New(cfg)\n_ = server.Run(context.Background(), &amp;mcp.StdioTransport{})\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/examples/#tool-search-and-execution","title":"Tool search and execution","text":"<pre><code>summaries, _ := idx.Search(\"ping\", 3)\n\nres, _ := runner.Run(ctx, summaries[0].ID, map[string]any{})\nfmt.Println(res.Structured)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/","title":"Plan of Record (Ordered Execution)","text":"<p>This page consolidates all proposals and PRDs into a single, ordered execution sequence. It is intentionally Go\u2011architecture focused: concurrency safety, context propagation, and production operational boundaries are explicit in each phase.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#principles-go-architect-evaluation","title":"Principles (Go Architect Evaluation)","text":"<ul> <li>Context propagation is a contract: every long\u2011running or remote execution path must honor <code>context.Context</code> for cancellation and timeouts.</li> <li>Concurrency safety by default: all registries and caches must be thread\u2011safe under concurrent reads/writes.</li> <li>Errors are data: tool errors should be structured and preserved end\u2011to\u2011end rather than surfaced as raw panics.</li> <li>Stable seams first: prioritize interfaces, wiring, and deterministic behaviors before adding new feature surface.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#current-baseline-already-in-place","title":"Current Baseline (already in place)","text":"<p>These libraries and contracts are the foundation and must remain stable:</p> <ul> <li><code>toolfoundation</code> \u2013 core types + adapters + versioning</li> <li><code>tooldiscovery</code> \u2013 registry, docs, search strategies</li> <li><code>toolexec</code> \u2013 execution, orchestration, runtime isolation</li> <li><code>toolcompose</code> \u2013 toolsets + skills</li> <li><code>toolops</code> \u2013 observability, cache, auth, resilience, health</li> <li><code>toolprotocol</code> \u2013 transport, wire, content, session, task primitives</li> </ul> <p>See the master roadmap for the current version matrix: ROADMAP</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-0-spec-alignment-server-correctness-p1","title":"Phase 0 \u2014 Spec Alignment &amp; Server Correctness (P1)","text":"<p>Goal: Ensure the MCP server edge is protocol\u2011correct before expanding capability.</p> <ol> <li>MCP spec alignment</li> <li><code>notifications/tools/list_changed</code></li> <li>pagination/cursor consistency</li> <li>cancellation propagation</li> <li>optional progress forwarding</li> </ol> <p>Docs: - Proposal: MCP Spec Alignment - PRD: PRD\u2011180</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-1-core-exposure-mvp-foundation","title":"Phase 1 \u2014 Core Exposure (MVP Foundation)","text":"<p>Goal: Provide CLI, configuration, transport, and provider/backends for production use.</p> <ol> <li>Repo scaffolding + CLI surface</li> <li>Configuration layer</li> <li>Transport layer</li> <li>Tool provider registry</li> <li>Backend registry</li> <li>Middleware chain</li> </ol> <p>Docs: - PRDs: PRD\u2011110, PRD\u2011111,   PRD\u2011112, PRD\u2011113</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-2-protocol-layer","title":"Phase 2 \u2014 Protocol Layer","text":"<p>Goal: Normalize tools into composable, protocol\u2011agnostic sets without changing core semantics.</p> <ol> <li>tooladapter \u2192 now <code>toolfoundation/adapter</code></li> <li>toolset \u2192 now <code>toolcompose/set</code></li> </ol> <p>Docs: - PRD\u2011121 - PRD\u2011150</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-3-crosscutting-observability-caching","title":"Phase 3 \u2014 Cross\u2011Cutting Observability &amp; Caching","text":"<p>Goal: Make the system operationally measurable and resilient.</p> <ol> <li>toolobserve \u2192 now <code>toolops/observe</code></li> <li>toolcache \u2192 now <code>toolops/cache</code></li> </ol> <p>Docs: - PRD\u2011160 - PRD\u2011161</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-4-enterprise-extensions","title":"Phase 4 \u2014 Enterprise Extensions","text":"<p>Goal: Enable scale, isolation, and advanced discovery without destabilizing core APIs.</p> <ol> <li>Multi\u2011tenancy core</li> <li>toolsemantic \u2192 now <code>tooldiscovery/semantic</code></li> </ol> <p>Docs: - Proposal: Multi\u2011Tenancy - PRD\u2011132</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-5-agent-skills","title":"Phase 5 \u2014 Agent Skills","text":"<p>Goal: Higher\u2011level capability composition for reusable workflows.</p> <ol> <li>toolskill \u2192 now <code>toolcompose/skill</code></li> </ol> <p>Docs: - PRD\u2011151</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-6-runtime-expansion","title":"Phase 6 \u2014 Runtime Expansion","text":"<p>Goal: Expand sandbox options and isolation strategies.</p> <ol> <li>toolruntime Docker backend \u2192 now <code>toolexec/runtime</code></li> </ol> <p>Docs: - PRD\u2011141</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#go-architecture-review-summary","title":"Go Architecture Review (Summary)","text":"<ul> <li>Context propagation: enforce in all public execution APIs; cancellation must be honored by toolexec/run and toolexec/runtime to avoid leaked goroutines.</li> <li>Concurrency safety: all registries must be RW\u2011safe; avoid maps without guards under write paths.</li> <li>Pagination correctness: use stable cursors and cap limits across list endpoints.</li> <li>Error semantics: preserve tool errors as structured data; avoid panics in runtime paths.</li> <li>Observability: add tracing hooks before multi\u2011tenant and semantic layers to avoid blind spots.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#reference-docs","title":"Reference Docs","text":"<ul> <li>ROADMAP</li> <li>Pluggable Architecture</li> <li>Implementation Phases</li> <li>Architecture Evaluation</li> <li>Protocol\u2011Agnostic Tools</li> <li>Multi\u2011Tenancy</li> <li>Architecture Review</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/metatools-mcp/usage/#build-and-run-stdio","title":"Build and run (stdio)","text":"<pre><code>go run ./cmd/metatools serve\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#cli-overview","title":"CLI overview","text":"<pre><code>metatools serve --transport=stdio                        # Local/Claude Desktop (default)\nmetatools serve --transport=streamable --port=8080       # HTTP clients (recommended)\nmetatools serve --transport=sse --port=8080              # Legacy HTTP clients (deprecated)\nmetatools version\nmetatools config validate --config examples/metatools.yaml\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#transport-selection","title":"Transport selection","text":"Transport Use Case Protocol <code>stdio</code> Claude Desktop, local CLI clients stdin/stdout JSON-RPC <code>streamable</code> Web apps, REST APIs, remote clients HTTP POST/GET/DELETE (MCP 2025-03-26) <code>sse</code> Legacy web clients HTTP + Server-Sent Events (deprecated)"},{"location":"library-docs-from-repos/metatools-mcp/usage/#streamable-http-recommended-for-http","title":"Streamable HTTP (recommended for HTTP)","text":"<p>Streamable HTTP is the MCP spec (2025-03-26) transport replacing SSE:</p> <pre><code># Basic HTTP server\nmetatools serve --transport=streamable --port=8080\n\n# With TLS\nmetatools serve --transport=streamable --port=443 \\\n  --tls --tls-cert=cert.pem --tls-key=key.pem\n\n# Stateless mode (no session tracking)\nmetatools serve --transport=streamable --port=8080 --stateless\n</code></pre> <p>Protocol flow: 1. Client POSTs JSON-RPC to <code>/mcp</code> with <code>initialize</code> request 2. Server responds with <code>Mcp-Session-Id</code> header 3. Client includes session ID in subsequent requests 4. Client may GET <code>/mcp</code> for server notification stream 5. Client DELETEs <code>/mcp</code> to terminate session</p> <p>YAML configuration: <pre><code>transport:\n  type: streamable\n  http:\n    host: 0.0.0.0\n    port: 8080\n    tls:\n      enabled: true\n      cert: /path/to/cert.pem\n      key: /path/to/key.pem\n  streamable:\n    stateless: false        # Enable session management\n    json_response: false    # Use SSE streaming (default)\n    session_timeout: 30m    # Clean up idle sessions\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#configuration-files-koanf","title":"Configuration files (Koanf)","text":"<p>Config precedence: 1. Defaults 2. Config file (<code>--config</code>) 3. Environment variables (<code>METATOOLS_</code> prefix) 4. CLI flags</p> <p>Example file: <code>examples/metatools.yaml</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#provider-toggles","title":"Provider toggles","text":"<p>Built-in metatools can be enabled/disabled via <code>providers.*.enabled</code> in the config file (see the <code>providers</code> block in <code>examples/metatools.yaml</code>). This controls which MCP tools are registered at startup.</p>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#middleware-chain","title":"Middleware chain","text":"<p>Configure optional middleware in <code>middleware.chain</code> (ordered) with per-middleware settings under <code>middleware.configs</code>. Built-in middleware: <code>logging</code>, <code>metrics</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#enable-bm25-search-build-tag-env","title":"Enable BM25 search (build tag + env)","text":"<pre><code>go build -tags toolsearch ./cmd/metatools\nMETATOOLS_SEARCH_STRATEGY=bm25 ./metatools\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#environment-variables","title":"Environment variables","text":""},{"location":"library-docs-from-repos/metatools-mcp/usage/#cli-defaults-serve-command","title":"CLI defaults (serve command)","text":"<p>These map directly to <code>metatools serve</code> flags when the flags are not set:</p> Variable Default Description <code>METATOOLS_TRANSPORT</code> <code>stdio</code> Transport type: <code>stdio</code>, <code>streamable</code>, <code>sse</code> <code>METATOOLS_PORT</code> <code>8080</code> Port for HTTP transports <code>METATOOLS_HOST</code> <code>0.0.0.0</code> Host/interface for HTTP transports <code>METATOOLS_CONFIG</code> \"\" Path to config file"},{"location":"library-docs-from-repos/metatools-mcp/usage/#transport-configuration-koanf-config","title":"Transport configuration (Koanf config)","text":"<p>These map to the config schema loaded by <code>config.Load</code>:</p> Variable Default Description <code>METATOOLS_TRANSPORT_TYPE</code> <code>stdio</code> Transport type: <code>stdio</code>, <code>streamable</code>, <code>sse</code> <code>METATOOLS_TRANSPORT_HTTP_HOST</code> <code>0.0.0.0</code> Host/interface for HTTP transports <code>METATOOLS_TRANSPORT_HTTP_PORT</code> <code>8080</code> Port for HTTP transports <code>METATOOLS_TRANSPORT_HTTP_TLS_ENABLED</code> <code>false</code> Enable TLS for HTTP transports <code>METATOOLS_TRANSPORT_HTTP_TLS_CERT</code> \"\" TLS certificate path <code>METATOOLS_TRANSPORT_HTTP_TLS_KEY</code> \"\" TLS key path <code>METATOOLS_TRANSPORT_STREAMABLE_STATELESS</code> <code>false</code> Disable session management <code>METATOOLS_TRANSPORT_STREAMABLE_JSON_RESPONSE</code> <code>false</code> Prefer JSON over SSE streaming <code>METATOOLS_TRANSPORT_STREAMABLE_SESSION_TIMEOUT</code> <code>30m</code> Idle session cleanup duration"},{"location":"library-docs-from-repos/metatools-mcp/usage/#runtime-configuration-toolruntime-build-tag","title":"Runtime configuration (toolruntime build tag)","text":"Variable Default Description <code>METATOOLS_RUNTIME_PROFILE</code> <code>dev</code> <code>dev</code> (unsafe) or <code>standard</code> (Docker) <code>METATOOLS_DOCKER_IMAGE</code> <code>toolruntime-sandbox:latest</code> Docker image for standard profile <code>METATOOLS_WASM_ENABLED</code> <code>false</code> Enable WASM backend (wazero) <code>METATOOLS_RUNTIME_BACKEND</code> <code>docker</code> Preferred standard backend: <code>docker</code> or <code>wasm</code>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#search-configuration","title":"Search configuration","text":"Variable Default Description <code>METATOOLS_SEARCH_STRATEGY</code> <code>lexical</code> <code>lexical</code> or <code>bm25</code> <code>METATOOLS_SEARCH_BM25_NAME_BOOST</code> <code>3</code> BM25 name field boost <code>METATOOLS_SEARCH_BM25_NAMESPACE_BOOST</code> <code>2</code> BM25 namespace field boost <code>METATOOLS_SEARCH_BM25_TAGS_BOOST</code> <code>2</code> BM25 tags field boost <code>METATOOLS_SEARCH_BM25_MAX_DOCS</code> <code>0</code> Max docs to index (0=unlimited) <code>METATOOLS_SEARCH_BM25_MAX_DOCTEXT_LEN</code> <code>0</code> Max doc text length (0=unlimited) <code>METATOOLS_NOTIFY_TOOL_LIST_CHANGED</code> <code>true</code> Emit <code>notifications/tools/list_changed</code> on index updates <code>METATOOLS_NOTIFY_TOOL_LIST_CHANGED_DEBOUNCE_MS</code> <code>150</code> Debounce window for list change notifications"},{"location":"library-docs-from-repos/metatools-mcp/usage/#pagination-and-cursors","title":"Pagination and cursors","text":"<ul> <li><code>search_tools</code> and <code>list_namespaces</code> accept <code>limit</code> (default 20, max 100) and <code>cursor</code>.</li> <li>Responses include <code>nextCursor</code> when more results are available.</li> <li>Cursor tokens are opaque and invalid cursors return JSON-RPC invalid params.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#tool-list-change-notifications","title":"Tool list change notifications","text":"<ul> <li><code>notifications/tools/list_changed</code> is emitted when the underlying tooldiscovery/index changes.</li> <li>Notifications are debounced to avoid client spam and can be disabled with <code>METATOOLS_NOTIFY_TOOL_LIST_CHANGED=false</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#progress-notifications","title":"Progress notifications","text":"<p>When callers supply a progress token, <code>run_tool</code>, <code>run_chain</code>, and <code>execute_code</code> emit progress notifications. If the runner exposes progress callbacks, step-level updates are forwarded; otherwise a coarse start/end signal is emitted.</p>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#optional-toolruntime-support","title":"Optional toolruntime support","text":"<pre><code>go run -tags toolruntime ./cmd/metatools\n</code></pre> <p>This enables <code>execute_code</code> backed by a <code>toolexec/runtime</code> engine. By default it uses the <code>dev</code> (unsafe) profile; set <code>METATOOLS_RUNTIME_PROFILE=standard</code> to enable the Docker backend when available. To use WASM instead, set <code>METATOOLS_WASM_ENABLED=true</code> and <code>METATOOLS_RUNTIME_BACKEND=wasm</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/","title":"User Journey","text":"<p>This journey shows the full end-to-end agent workflow via MCP metatools.</p>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#transport-selection","title":"Transport selection","text":"<p>Before tool discovery begins, clients establish a connection via one of the supported transports. The transport choice depends on the client environment:</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0'}}}%%\nflowchart LR\n    subgraph clients[\"Clients\"]\n        Claude[\"\ud83d\udda5\ufe0f Claude Desktop\"]\n        WebApp[\"\ud83c\udf10 Web Application\"]\n        CLI[\"\u2328\ufe0f CLI Tool\"]\n    end\n\n    subgraph transports[\"Transport Layer\"]\n        Stdio[\"\ud83d\udcdf stdio&lt;br/&gt;&lt;small&gt;stdin/stdout&lt;/small&gt;\"]\n        Streamable[\"\ud83d\udd04 streamable&lt;br/&gt;&lt;small&gt;HTTP POST/GET/DELETE&lt;/small&gt;\"]\n        SSE[\"\ud83d\udce1 sse&lt;br/&gt;&lt;small&gt;deprecated&lt;/small&gt;\"]\n    end\n\n    subgraph server[\"metatools-mcp\"]\n        MCP[\"\ud83d\udd37 MCP Server\"]\n    end\n\n    Claude --&gt; Stdio --&gt; MCP\n    WebApp --&gt; Streamable --&gt; MCP\n    CLI --&gt; Stdio --&gt; MCP\n    WebApp -.-&gt; SSE -.-&gt; MCP\n\n    style clients fill:#4a5568,stroke:#2d3748\n    style transports fill:#805ad5,stroke:#6b46c1\n    style server fill:#2b6cb0,stroke:#2c5282\n    style SSE fill:#718096,stroke:#4a5568,stroke-dasharray: 5 5</code></pre> Transport Client Type Session Protocol <code>stdio</code> Local CLI, Claude Desktop Implicit stdin/stdout JSON-RPC <code>streamable</code> Web apps, remote clients Mcp-Session-Id header HTTP (MCP 2025-03-26) <code>sse</code> Legacy web clients Cookie-based HTTP + SSE (deprecated) <p>Streamable HTTP session flow: 1. Client POSTs <code>initialize</code> request to <code>/mcp</code> 2. Server returns <code>Mcp-Session-Id</code> header 3. Client includes session ID in all subsequent requests 4. Client may open GET stream for server notifications 5. Client sends DELETE to terminate session</p>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#end-to-end-flow-agent-view","title":"End-to-end flow (agent view)","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0', 'primaryTextColor': '#fff'}}}%%\nsequenceDiagram\n    autonumber\n\n    participant Agent as \ud83e\udd16 AI Agent\n    participant Transport as \ud83d\udd04 Transport\n    participant MCP as \ud83d\udd37 metatools-mcp\n    participant Index as \ud83d\udcc7 tooldiscovery/index\n    participant Docs as \ud83d\udcda tooldiscovery/tooldoc\n    participant Run as \u25b6\ufe0f toolexec/run\n    participant Code as \ud83d\udcbb toolexec/code\n\n    rect rgb(128, 90, 213, 0.1)\n        Note over Agent,MCP: Phase 0: Connection\n        Agent-&gt;&gt;+Transport: Connect (stdio/streamable/sse)\n        Transport-&gt;&gt;+MCP: initialize\n        MCP--&gt;&gt;-Transport: capabilities + session\n        Transport--&gt;&gt;-Agent: Ready\n    end\n\n    rect rgb(43, 108, 176, 0.1)\n        Note over Agent,Index: Phase 1: Discovery\n        Agent-&gt;&gt;+MCP: search_tools(\"create issue\", 5)\n        MCP-&gt;&gt;+Index: Search(query, limit)\n        Index--&gt;&gt;-MCP: Summary[]\n        MCP--&gt;&gt;-Agent: summaries (no schemas)\n    end\n\n    rect rgb(214, 158, 46, 0.1)\n        Note over Agent,Docs: Phase 2: Documentation\n        Agent-&gt;&gt;+MCP: describe_tool(id, \"schema\")\n        MCP-&gt;&gt;+Docs: DescribeTool(id, DetailSchema)\n        Docs--&gt;&gt;-MCP: ToolDoc\n        MCP--&gt;&gt;-Agent: tool schema + description\n    end\n\n    rect rgb(56, 161, 105, 0.1)\n        Note over Agent,Run: Phase 3: Execution\n        Agent-&gt;&gt;+MCP: run_tool(id, args)\n        MCP-&gt;&gt;+Run: Run(ctx, id, args)\n        Run--&gt;&gt;-MCP: RunResult\n        MCP--&gt;&gt;-Agent: result\n    end\n\n    rect rgb(107, 70, 193, 0.1)\n        Note over Agent,Code: Phase 4: Orchestration (optional)\n        Agent-&gt;&gt;+MCP: execute_code(snippet)\n        MCP-&gt;&gt;+Code: ExecuteCode(ctx, params)\n        Code--&gt;&gt;-MCP: ExecuteResult\n        MCP--&gt;&gt;-Agent: value + tool calls\n    end</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#mcp-tool-surface","title":"MCP Tool Surface","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0'}}}%%\nflowchart TB\n    subgraph agent[\"AI Agent\"]\n        Request[\"\ud83d\udce5 MCP Request&lt;br/&gt;&lt;small&gt;JSON-RPC&lt;/small&gt;\"]\n    end\n\n    subgraph transport[\"Transport Layer\"]\n        Stdio[\"\ud83d\udcdf stdio\"]\n        Streamable[\"\ud83d\udd04 streamable\"]\n    end\n\n    subgraph metatools[\"metatools-mcp\"]\n        Server[\"\ud83d\udd37 MCP Server\"]\n\n        subgraph discovery[\"Discovery Tools\"]\n            SearchTools[\"\ud83d\udd0d search_tools\"]\n            ListNS[\"\ud83d\udcc1 list_namespaces\"]\n        end\n\n        subgraph docs[\"Documentation Tools\"]\n            DescribeTool[\"\ud83d\udcda describe_tool\"]\n            ListExamples[\"\ud83d\udca1 list_tool_examples\"]\n        end\n\n        subgraph execution[\"Execution Tools\"]\n            RunTool[\"\u25b6\ufe0f run_tool\"]\n            RunChain[\"\ud83d\udd17 run_chain\"]\n        end\n\n        subgraph orchestration[\"Orchestration (optional)\"]\n            ExecCode[\"\ud83d\udcbb execute_code\"]\n        end\n    end\n\n    subgraph stack[\"Stack Libraries\"]\n        Index[\"\ud83d\udcc7 tooldiscovery/index\"]\n        Docs2[\"\ud83d\udcda tooldiscovery/tooldoc\"]\n        Run[\"\u25b6\ufe0f toolexec/run\"]\n        Code[\"\ud83d\udcbb toolexec/code\"]\n    end\n\n    Request --&gt; Stdio &amp; Streamable --&gt; Server\n    Server --&gt; SearchTools --&gt; Index\n    Server --&gt; ListNS --&gt; Index\n    Server --&gt; DescribeTool --&gt; Docs2\n    Server --&gt; ListExamples --&gt; Docs2\n    Server --&gt; RunTool --&gt; Run\n    Server --&gt; RunChain --&gt; Run\n    Server --&gt; ExecCode --&gt; Code\n\n    style agent fill:#4a5568,stroke:#2d3748\n    style transport fill:#805ad5,stroke:#6b46c1\n    style metatools fill:#2b6cb0,stroke:#2c5282,stroke-width:2px\n    style discovery fill:#3182ce,stroke:#2c5282\n    style docs fill:#d69e2e,stroke:#b7791f\n    style execution fill:#38a169,stroke:#276749\n    style orchestration fill:#6b46c1,stroke:#553c9a\n    style stack fill:#718096,stroke:#4a5568</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#step-by-step","title":"Step-by-step","text":"<ol> <li>Connect via transport (stdio for local, streamable HTTP for remote).</li> <li>Discover tools with <code>search_tools</code> (summary-only results).</li> <li>Inspect schema using <code>describe_tool</code> (schema or full detail).</li> <li>Execute a single tool with <code>run_tool</code> or a sequence with <code>run_chain</code>.</li> <li>Orchestrate complex flows using <code>execute_code</code> (optional).</li> </ol> <p>When built with <code>-tags toolruntime</code>, <code>execute_code</code> runs in a sandboxed toolexec/runtime. Default profile is <code>dev</code> (unsafe); set <code>METATOOLS_RUNTIME_PROFILE=standard</code> to enable Docker when available. Set <code>METATOOLS_WASM_ENABLED=true</code> and <code>METATOOLS_RUNTIME_BACKEND=wasm</code> to use the WASM backend instead.</p>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#example-full-agent-workflow","title":"Example: full agent workflow","text":"<pre><code>1) search_tools(\"create issue\", limit=5)\n2) describe_tool(\"github:create_issue\", detail_level=\"schema\")\n3) run_tool(\"github:create_issue\", args={...})\n4) run_chain([{tool_id:\"github:get_issue\"}, {tool_id:\"github:add_label\", use_previous:true}])\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#expected-outcomes","title":"Expected outcomes","text":"<ul> <li>Stable MCP-compatible APIs for discovery, documentation, and execution.</li> <li>Consistent error objects for tool failures.</li> <li>Progressive disclosure to minimize token costs.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#common-failure-modes","title":"Common failure modes","text":"<ul> <li>Invalid input payloads (handler validation errors).</li> <li>Tool-level errors returned in <code>ErrorObject</code> with <code>code</code> and <code>op</code> fields.</li> <li>Unsupported options (e.g., <code>stream=true</code> for <code>run_tool</code>).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/data-flow/","title":"Data Flow","text":""},{"location":"library-docs-from-repos/metatools-mcp/diagrams/data-flow/#overview","title":"Overview","text":"<p>End-to-end flow for discovery and execution requests across the stack.</p>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/data-flow/#diagram","title":"Diagram","text":"<pre><code>sequenceDiagram\n    autonumber\n    actor Agent\n    participant MCP as metatools-mcp\n    participant Discovery as tooldiscovery\n    participant Compose as toolcompose\n    participant Exec as toolexec\n    participant Ops as toolops\n    participant Proto as toolprotocol\n    participant Provider as External Tool Provider\n\n    Agent-&gt;&gt;MCP: tools/search\n    MCP-&gt;&gt;Discovery: search(query)\n    Discovery--&gt;&gt;MCP: results\n    MCP--&gt;&gt;Agent: tool list\n\n    Agent-&gt;&gt;MCP: tools/call\n    MCP-&gt;&gt;Compose: select toolset/policy\n    Compose--&gt;&gt;MCP: allowed tool(s)\n    MCP-&gt;&gt;Exec: run(tool, input)\n    Exec-&gt;&gt;Ops: observe/cache/resilience/auth\n    Ops--&gt;&gt;Exec: policy + telemetry\n    Exec-&gt;&gt;Proto: encode + transport\n    Proto-&gt;&gt;Provider: request\n    Provider--&gt;&gt;Proto: response\n    Proto--&gt;&gt;Exec: decoded result\n    Exec--&gt;&gt;MCP: result\n    MCP--&gt;&gt;Agent: output</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/dependency-graph/","title":"Dependency Graph","text":""},{"location":"library-docs-from-repos/metatools-mcp/diagrams/dependency-graph/#overview","title":"Overview","text":"<p>Inter-repo dependencies (conceptual view). Higher layers depend on lower layers only.</p>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/dependency-graph/#diagram","title":"Diagram","text":"<pre><code>graph LR\n    mcp[\"MCP Go SDK\"]\n\n    toolfoundation[\"toolfoundation\"]\n    tooldiscovery[\"tooldiscovery\"]\n    toolexec[\"toolexec\"]\n    toolcompose[\"toolcompose\"]\n    toolops[\"toolops\"]\n    toolprotocol[\"toolprotocol\"]\n    metatools[\"metatools-mcp\"]\n\n    tooldiscovery --&gt; toolfoundation\n    toolexec --&gt; toolfoundation\n    toolexec --&gt; tooldiscovery\n    toolcompose --&gt; toolfoundation\n    toolops --&gt; toolfoundation\n    toolprotocol --&gt; toolfoundation\n\n    toolprotocol --&gt; mcp\n\n    metatools --&gt; toolprotocol\n    metatools --&gt; toolops\n    metatools --&gt; toolcompose\n    metatools --&gt; toolexec\n    metatools --&gt; tooldiscovery\n    metatools --&gt; toolfoundation</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/layer-architecture/","title":"Layer Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/diagrams/layer-architecture/#overview","title":"Overview","text":"<p>The ApertureStack ecosystem is organized into layered tiers. Each higher tier depends on lower tiers only.</p>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/layer-architecture/#diagram","title":"Diagram","text":"<pre><code>graph TB\n    subgraph \"Tier 8: Application\"\n        metatools[\"metatools-mcp\\n(MCP Server)\"]\n    end\n\n    subgraph \"Tier 7: Protocol\"\n        toolprotocol[\"toolprotocol\"]\n        subgraph \"toolprotocol packages\"\n            transport[\"transport\"]\n            wire[\"wire\"]\n            discover[\"discover\"]\n            content[\"content\"]\n            task[\"task\"]\n            stream[\"stream\"]\n            session[\"session\"]\n            elicit[\"elicit\"]\n            resource[\"resource\"]\n            prompt[\"prompt\"]\n        end\n    end\n\n    subgraph \"Tier 6: Operations\"\n        toolops[\"toolops\"]\n        subgraph \"toolops packages\"\n            observe[\"observe\"]\n            cache[\"cache\"]\n            resilience[\"resilience\"]\n            health[\"health\"]\n            auth[\"auth\"]\n        end\n    end\n\n    subgraph \"Tier 5: Composition\"\n        toolcompose[\"toolcompose\"]\n        subgraph \"toolcompose packages\"\n            set[\"set\"]\n            skill[\"skill\"]\n        end\n    end\n\n    subgraph \"Tier 4: Execution\"\n        toolexec[\"toolexec\"]\n        subgraph \"toolexec packages\"\n            run[\"run\"]\n            runtime[\"runtime\"]\n            code[\"code\"]\n            backend[\"backend\"]\n        end\n    end\n\n    subgraph \"Tier 3: Discovery\"\n        tooldiscovery[\"tooldiscovery\"]\n        subgraph \"tooldiscovery packages\"\n            index[\"index\"]\n            search[\"search\"]\n            semantic[\"semantic\"]\n            docs[\"tooldoc\"]\n        end\n    end\n\n    subgraph \"Tier 2: Foundation\"\n        toolfoundation[\"toolfoundation\"]\n        subgraph \"toolfoundation packages\"\n            model[\"model\"]\n            adapter[\"adapter\"]\n            version[\"version\"]\n        end\n    end\n\n    subgraph \"Tier 1: External\"\n        mcp[\"MCP Go SDK\"]\n    end\n\n    metatools --&gt; toolprotocol\n    metatools --&gt; toolops\n    metatools --&gt; toolcompose\n    metatools --&gt; toolexec\n    metatools --&gt; tooldiscovery\n    metatools --&gt; toolfoundation\n\n    toolprotocol --&gt; toolfoundation\n    toolops --&gt; toolfoundation\n    toolcompose --&gt; toolfoundation\n    toolexec --&gt; toolfoundation\n    tooldiscovery --&gt; toolfoundation\n\n    toolprotocol --&gt; mcp</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/protocol-adapters/","title":"Protocol Adapters","text":""},{"location":"library-docs-from-repos/metatools-mcp/diagrams/protocol-adapters/#overview","title":"Overview","text":"<p><code>toolprotocol</code> provides transport and wire adapters to support multiple client/server protocols.</p>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/protocol-adapters/#diagram","title":"Diagram","text":"<pre><code>graph LR\n    model[\"toolfoundation/model\"] --&gt; wire[\"toolprotocol/wire\"]\n    wire --&gt; transport[\"toolprotocol/transport\"]\n\n    transport --&gt; mcp[\"MCP (JSON-RPC)\"]\n    transport --&gt; sse[\"SSE\"]\n    transport --&gt; stdio[\"stdio\"]\n    transport --&gt; http[\"HTTP/JSON\"]\n    transport --&gt; grpc[\"gRPC\"]\n\n    wire --&gt; adapters[\"Protocol Adapters\"]\n    adapters --&gt; openai[\"OpenAI tools\"]\n    adapters --&gt; anthropic[\"Anthropic tools\"]\n    adapters --&gt; custom[\"Custom adapters\"]</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/repository-map/","title":"Repository Map","text":""},{"location":"library-docs-from-repos/metatools-mcp/diagrams/repository-map/#overview","title":"Overview","text":"<p>This map shows the six consolidated repositories and the packages they contain.</p>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/repository-map/#diagram","title":"Diagram","text":"<pre><code>graph TB\n    subgraph toolfoundation\n        tf_model[\"model\"]\n        tf_adapter[\"adapter\"]\n        tf_version[\"version\"]\n    end\n\n    subgraph tooldiscovery\n        td_index[\"index\"]\n        td_search[\"search\"]\n        td_semantic[\"semantic\"]\n        td_doc[\"tooldoc\"]\n    end\n\n    subgraph toolexec\n        te_run[\"run\"]\n        te_runtime[\"runtime\"]\n        te_code[\"code\"]\n        te_backend[\"backend\"]\n    end\n\n    subgraph toolcompose\n        tc_set[\"set\"]\n        tc_skill[\"skill\"]\n    end\n\n    subgraph toolops\n        to_observe[\"observe\"]\n        to_cache[\"cache\"]\n        to_auth[\"auth\"]\n        to_resilience[\"resilience\"]\n        to_health[\"health\"]\n    end\n\n    subgraph toolprotocol\n        tp_transport[\"transport\"]\n        tp_wire[\"wire\"]\n        tp_discover[\"discover\"]\n        tp_content[\"content\"]\n        tp_task[\"task\"]\n        tp_stream[\"stream\"]\n        tp_session[\"session\"]\n        tp_elicit[\"elicit\"]\n        tp_resource[\"resource\"]\n        tp_prompt[\"prompt\"]\n    end</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/","title":"ApertureStack Consolidation PRDs","text":"<p>This directory contains all Product Requirement Documents for the ApertureStack ecosystem consolidation from 15 standalone repositories into 6 consolidated repositories.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/#quick-links","title":"Quick Links","text":"<ul> <li>Master Plan - Executive overview</li> <li>Order of Operations - Execution sequence</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/#prd-summary","title":"PRD Summary","text":"<p>Total PRDs: 41 Total Effort: 236 hours (~29.5 days) Timeline: 6-8 weeks with parallelization</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/#phase-0-planning-documentation-12h","title":"Phase 0: Planning &amp; Documentation (12h)","text":"PRD Title Effort Status PRD-100 Master Consolidation Plan 4h Done PRD-101 Architecture Diagrams 4h Done PRD-102 Schema Definitions 4h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/#phase-1-infrastructure-setup-16h","title":"Phase 1: Infrastructure Setup (16h)","text":"PRD Title Effort Status PRD-110 Repository Creation 8h Done PRD-111 CI/CD Templates 4h Done PRD-112 GitHub Org Config 2h Done PRD-113 Release Automation 2h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/#phase-2-foundation-layer-toolfoundation-16h","title":"Phase 2: Foundation Layer - toolfoundation (16h)","text":"PRD Title Effort Status PRD-120 Migrate toolmodel 4h Done PRD-121 Migrate tooladapter 4h Done PRD-122 Create toolversion 8h Done PRD-123 Docs + README alignment 3h Done PRD-124 Schema validation policy docs 2h Done PRD-125 Adapter feature matrix docs 2h Done PRD-126 Version package usage docs 2h Done PRD-127 Contract verification 1h Done PRD-128 Release + propagation 1h Done PRD-129 Gate G2 validation 1h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/#phase-3-discovery-layer-tooldiscovery-18h","title":"Phase 3: Discovery Layer - tooldiscovery (18h)","text":"PRD Title Effort Status PRD-130 Migrate toolindex 4h Done PRD-131 Migrate toolsearch 4h Done PRD-132 Migrate toolsemantic 6h Done PRD-133 Migrate tooldocs 4h Done PRD-134 Docs + README alignment 2h Done PRD-135 Search strategy policy docs 2h Done PRD-136 Semantic contracts docs 2h Done PRD-137 Progressive docs details 2h Done PRD-138 Release + propagation 1h Done PRD-139 Discovery validation 1h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/#phase-4-execution-layer-toolexec-18h","title":"Phase 4: Execution Layer - toolexec (18h)","text":"PRD Title Effort Status PRD-140 Migrate toolrun 4h Done PRD-141 Migrate toolruntime 4h Done PRD-142 Migrate toolcode 4h Done PRD-143 Extract toolbackend 6h Done PRD-144 toolexec docs alignment 2h Done PRD-145 Runtime security profile docs 2h Done PRD-146 Backend matrix docs 2h Done PRD-147 Toolcode/runtime contract docs 2h Done PRD-148 Release + propagation 1h Done PRD-149 toolexec validation 1h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/#phase-5-composition-layer-toolcompose-12h","title":"Phase 5: Composition Layer - toolcompose (12h)","text":"PRD Title Effort Status PRD-150 Migrate toolset 4h Done PRD-151 Complete toolskill 8h Done PRD-152 toolcompose docs alignment 2h Done PRD-153 set filter/policy docs 2h Done PRD-154 skill contract docs 2h Done PRD-155 user journey + examples 2h Done PRD-156 docs site integration 1h Done PRD-157 Release + propagation 1h Done PRD-158 toolcompose validation 1h Done PRD-159 docs publish readiness 1h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/#phase-6-operations-layer-toolops-30h","title":"Phase 6: Operations Layer - toolops (30h)","text":"PRD Title Effort Status PRD-160 Migrate toolobserve 4h Done PRD-161 Migrate toolcache 4h Done PRD-162 Extract toolauth 8h Done PRD-163 Create toolresilience 8h Done PRD-164 Create toolhealth 6h Done PRD-165 toolops docs alignment 2h Done PRD-166 observe contracts docs 2h Done PRD-167 cache policy docs 2h Done PRD-168 auth/health/resilience docs 2h Done PRD-169 release + validation 2h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/#phase-7-protocol-layer-toolprotocol-84h","title":"Phase 7: Protocol Layer - toolprotocol (84h)","text":"PRD Title Effort Status PRD-170 Create tooltransport 8h Done PRD-171 Create toolwire 12h Done PRD-172 Create tooldiscover 8h Done PRD-173 Create toolcontent 8h Done PRD-174 Create tooltask 10h Done PRD-175 Create toolstream 8h Done PRD-176 Create toolsession 6h Done PRD-177 Create toolelicit 6h Done PRD-178 Create toolresource 10h Done PRD-179 Create toolprompt 8h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/#phase-8-integration-22h","title":"Phase 8: Integration (22h)","text":"PRD Title Effort Status PRD-180 Update metatools-mcp 12h Done PRD-181 Update ai-tools-stack 4h Done PRD-182 Documentation Site 6h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/#phase-9-cleanup-8h","title":"Phase 9: Cleanup (8h)","text":"PRD Title Effort Status PRD-190 Archive Old Repos 2h Done PRD-191 Update Submodules 2h Done PRD-192 Validation 4h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/#checkpoint-gates","title":"Checkpoint Gates","text":"Gate After PRD Validation G1 PRD-113 All repos created, CI working G2 PRD-122 Foundation layer complete G3 PRD-143 Discovery + Execution layers complete G4 PRD-164 Composition + Operations layers complete G5 PRD-179 Protocol layer complete G6 PRD-182 Integration complete G7 PRD-192 Full validation complete"},{"location":"library-docs-from-repos/metatools-mcp/plans/#consolidated-repositories","title":"Consolidated Repositories","text":"Repository Packages toolfoundation model, adapter, version tooldiscovery index, search, semantic, docs toolexec run, runtime, code, backend toolcompose set, skill toolops observe, cache, resilience, health, auth toolprotocol transport, wire, discover, content, task, stream, session, elicit, resource, prompt"},{"location":"library-docs-from-repos/metatools-mcp/plans/#previous-plans","title":"Previous Plans","text":"Item File Status PRD-016 <code>2026-01-30-prd-016-interface-contracts.md</code> Done PRD-017 <code>2026-01-30-prd-017-auth-middleware.md</code> Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/","title":"PRD-016 Execution Plan \u2014 metatools-mcp (TDD)","text":"<p>Status: Done Date: 2026-01-30 PRD: <code>2026-01-30-prd-016-interface-contracts.md</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#tdd-workflow-required","title":"TDD Workflow (required)","text":"<ol> <li>Red \u2014 write failing contract tests</li> <li>Red verification \u2014 run tests</li> <li>Green \u2014 minimal code/doc changes</li> <li>Green verification \u2014 run tests</li> <li>Commit \u2014 one commit per task</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#task-0-inventory-contract-outline","title":"Task 0 \u2014 Inventory + contract outline","text":"<ul> <li>Confirm interface list and method signatures.</li> <li>Draft explicit contract bullets for each interface.</li> <li>Update docs/plans/README.md with this PRD + plan.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#task-1-contract-tests-redgreen","title":"Task 1 \u2014 Contract tests (Red/Green)","text":"<ul> <li>Add <code>*_contract_test.go</code> with tests for each interface listed below.</li> <li>Use stub implementations where needed.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#task-2-godoc-contracts","title":"Task 2 \u2014 GoDoc contracts","text":"<ul> <li>Add/expand GoDoc on each interface with explicit contract clauses (thread-safety, errors, context, ownership).</li> <li>Update README/design-notes if user-facing.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#task-3-verification","title":"Task 3 \u2014 Verification","text":"<ul> <li>Run <code>go test ./...</code></li> <li>Run linters if configured (golangci-lint / gosec).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#test-skeletons-contract_testgo","title":"Test Skeletons (contract_test.go)","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#metricscollector","title":"MetricsCollector","text":"<pre><code>func TestMetricsCollector_Contract(t *testing.T) {\n    // Methods:\n    // - Start(tool string)\n    // - Finish(tool string, err error, duration time.Duration)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#server","title":"Server","text":"<pre><code>func TestServer_Contract(t *testing.T) {\n    // Methods:\n    // - Run(ctx context.Context, transport mcp.Transport) error\n    // - MCPServer() *mcp.Server\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#transport","title":"Transport","text":"<pre><code>func TestTransport_Contract(t *testing.T) {\n    // Methods:\n    // - Name() string\n    // - Info() Info\n    // - Serve(ctx context.Context, server Server) error\n    // - Close() error\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#toolprovider","title":"ToolProvider","text":"<pre><code>func TestToolProvider_Contract(t *testing.T) {\n    // Methods:\n    // - Name() string\n    // - Enabled() bool\n    // - Tool() mcp.Tool\n    // - Handle(ctx context.Context, req *mcp.CallToolRequest, args map[string]any) (*mcp.CallToolResult, any, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#configurableprovider","title":"ConfigurableProvider","text":"<pre><code>func TestConfigurableProvider_Contract(t *testing.T) {\n    // Methods:\n    // - ToolProvider\n    // - Configure(cfg map[string]any) error\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#streamingprovider","title":"StreamingProvider","text":"<pre><code>func TestStreamingProvider_Contract(t *testing.T) {\n    // Methods:\n    // - ToolProvider\n    // - HandleStream(ctx context.Context, req *mcp.CallToolRequest, args map[string]any) (&lt;-chan any, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#backend","title":"Backend","text":"<pre><code>func TestBackend_Contract(t *testing.T) {\n    // Methods:\n    // - Kind() string\n    // - Name() string\n    // - Enabled() bool\n    // - ListTools(ctx context.Context) ([]toolmodel.Tool, error)\n    // - Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n    // - Start(ctx context.Context) error\n    // - Stop() error\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#configurablebackend","title":"ConfigurableBackend","text":"<pre><code>func TestConfigurableBackend_Contract(t *testing.T) {\n    // Methods:\n    // - Backend\n    // - Configure(raw []byte) error\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#streamingbackend","title":"StreamingBackend","text":"<pre><code>func TestStreamingBackend_Contract(t *testing.T) {\n    // Methods:\n    // - Backend\n    // - ExecuteStream(ctx context.Context, tool string, args map[string]any) (&lt;-chan any, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#index","title":"Index","text":"<pre><code>func TestIndex_Contract(t *testing.T) {\n    // Methods:\n    // - SearchPage(ctx context.Context, query string, limit int, cursor string) ([]metatools.ToolSummary, string, error)\n    // - ListNamespacesPage(ctx context.Context, limit int, cursor string) ([]string, string, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#store","title":"Store","text":"<pre><code>func TestStore_Contract(t *testing.T) {\n    // Methods:\n    // - DescribeTool(ctx context.Context, id string, level string) (ToolDoc, error)\n    // - ListExamples(ctx context.Context, id string, maxExamples int) ([]metatools.ToolExample, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#runner","title":"Runner","text":"<pre><code>func TestRunner_Contract(t *testing.T) {\n    // Methods:\n    // - Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)\n    // - RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#progressrunner","title":"ProgressRunner","text":"<pre><code>func TestProgressRunner_Contract(t *testing.T) {\n    // Methods:\n    // - RunWithProgress(ctx context.Context, toolID string, args map[string]any, onProgress func(ProgressEvent)) (RunResult, error)\n    // - RunChainWithProgress(ctx context.Context, steps []ChainStep, onProgress func(ProgressEvent)) (RunResult, []StepResult, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-execution-plan/#executor","title":"Executor","text":"<pre><code>func TestExecutor_Contract(t *testing.T) {\n    // Methods:\n    // - ExecuteCode(ctx context.Context, params ExecuteParams) (ExecuteResult, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-interface-contracts/","title":"PRD-016 Interface Contracts \u2014 metatools-mcp","text":"<p>Status: Done Date: 2026-01-30</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-interface-contracts/#overview","title":"Overview","text":"<p>Define explicit interface contracts (GoDoc + documented semantics) for all interfaces in this repo. Contracts must state concurrency guarantees, error semantics, ownership of inputs/outputs, and context handling.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-interface-contracts/#goals","title":"Goals","text":"<ul> <li>Every interface has explicit GoDoc describing behavioral contract.</li> <li>Contract behavior is codified in tests (contract tests).</li> <li>Docs/README updated where behavior is user-facing.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-interface-contracts/#non-goals","title":"Non-Goals","text":"<ul> <li>No API shape changes unless required to satisfy the contract tests.</li> <li>No new features beyond contract clarity and tests.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-interface-contracts/#interface-inventory","title":"Interface Inventory","text":"Interface File Methods <code>MetricsCollector</code> <code>metatools-mcp/internal/middleware/metrics.go:22</code> Start(tool string)Finish(tool string, err error, duration time.Duration) <code>Server</code> <code>metatools-mcp/internal/transport/transport.go:10</code> Run(ctx context.Context, transport mcp.Transport) errorMCPServer() *mcp.Server <code>Transport</code> <code>metatools-mcp/internal/transport/transport.go:23</code> Name() stringInfo() InfoServe(ctx context.Context, server Server) errorClose() error <code>ToolProvider</code> <code>metatools-mcp/internal/provider/provider.go:11</code> Name() stringEnabled() boolTool() mcp.ToolHandle(ctx context.Context, req mcp.CallToolRequest, args map[string]any) (mcp.CallToolResult, any, error) <code>ConfigurableProvider</code> <code>metatools-mcp/internal/provider/provider.go:27</code> ToolProviderConfigure(cfg map[string]any) error <code>StreamingProvider</code> <code>metatools-mcp/internal/provider/provider.go:35</code> ToolProviderHandleStream(ctx context.Context, req *mcp.CallToolRequest, args map[string]any) (&lt;-chan any, error) <code>Backend</code> <code>metatools-mcp/internal/backend/backend.go:20</code> Kind() stringName() stringEnabled() boolListTools(ctx context.Context) ([]toolmodel.Tool, error)Execute(ctx context.Context, tool string, args map[string]any) (any, error)Start(ctx context.Context) errorStop() error <code>ConfigurableBackend</code> <code>metatools-mcp/internal/backend/backend.go:44</code> BackendConfigure(raw []byte) error <code>StreamingBackend</code> <code>metatools-mcp/internal/backend/backend.go:51</code> BackendExecuteStream(ctx context.Context, tool string, args map[string]any) (&lt;-chan any, error) <code>Index</code> <code>metatools-mcp/internal/handlers/interfaces.go:10</code> SearchPage(ctx context.Context, query string, limit int, cursor string) ([]metatools.ToolSummary, string, error)ListNamespacesPage(ctx context.Context, limit int, cursor string) ([]string, string, error) <code>Store</code> <code>metatools-mcp/internal/handlers/interfaces.go:26</code> DescribeTool(ctx context.Context, id string, level string) (ToolDoc, error)ListExamples(ctx context.Context, id string, maxExamples int) ([]metatools.ToolExample, error) <code>Runner</code> <code>metatools-mcp/internal/handlers/interfaces.go:64</code> Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error) <code>ProgressRunner</code> <code>metatools-mcp/internal/handlers/interfaces.go:70</code> RunWithProgress(ctx context.Context, toolID string, args map[string]any, onProgress func(ProgressEvent)) (RunResult, error)RunChainWithProgress(ctx context.Context, steps []ChainStep, onProgress func(ProgressEvent)) (RunResult, []StepResult, error) <code>Executor</code> <code>metatools-mcp/internal/handlers/interfaces.go:92</code> ExecuteCode(ctx context.Context, params ExecuteParams) (ExecuteResult, error)"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-interface-contracts/#contract-template-apply-per-interface","title":"Contract Template (apply per interface)","text":"<ul> <li>Thread-safety: explicitly state if safe for concurrent use.</li> <li>Context: cancellation/deadline handling (if context is a parameter).</li> <li>Errors: classification, retryability, and wrapping expectations.</li> <li>Ownership: who owns/allocates inputs/outputs; mutation expectations.</li> <li>Determinism/order: ordering guarantees for returned slices/maps/streams.</li> <li>Nil/zero handling: behavior for nil inputs or empty values.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-016-interface-contracts/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>All interfaces have GoDoc with explicit behavioral contract.</li> <li>Contract tests exist and pass.</li> <li>No interface contract contradictions across repos.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/","title":"PRD-017: Pluggable Authentication &amp; Authorization Middleware","text":"<p>Status: Ready for Implementation Date: 2026-01-30 Priority: P1 (High) Depends On: PRD-016 (Interface Contracts) Proposal: auth-middleware.md Architecture: persistence-boundary.md</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#overview","title":"Overview","text":"<p>Implement a 100% pluggable authentication and authorization middleware following the persistence boundary architecture. Core interfaces live in <code>internal/auth</code>, implementations are pluggable via factory registration.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#scope","title":"Scope","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#in-scope","title":"In Scope","text":"<ul> <li>Core auth interfaces (<code>Authenticator</code>, <code>Authorizer</code>, <code>Identity</code>)</li> <li>JWT authenticator with JWKS support</li> <li>API Key authenticator with pluggable store interface</li> <li>Simple RBAC authorizer (no external dependencies)</li> <li>Casbin authorizer (optional, build-tagged)</li> <li>Auth middleware integration with existing middleware chain</li> <li>Context propagation helpers</li> <li>YAML configuration support</li> <li>CLI flags for basic auth configuration</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#out-of-scope-future-prds","title":"Out of Scope (Future PRDs)","text":"<ul> <li>OAuth2 token introspection (PRD-018)</li> <li>mTLS authenticator (PRD-019)</li> <li>OPA authorizer (PRD-020)</li> <li>Persistence implementations (toolpersist library)</li> <li>Multi-tenancy integration (after auth foundation)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#implementation-tasks","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#task-1-core-identity-types","title":"Task 1: Core Identity Types","text":"<p>Files: - <code>internal/auth/identity.go</code> - <code>internal/auth/identity_test.go</code></p> <pre><code>// internal/auth/identity.go\npackage auth\n\nimport (\n    \"context\"\n    \"time\"\n)\n\n// Identity represents an authenticated principal.\ntype Identity struct {\n    Principal   string            `json:\"principal\"`\n    TenantID    string            `json:\"tenant_id,omitempty\"`\n    Roles       []string          `json:\"roles,omitempty\"`\n    Permissions []string          `json:\"permissions,omitempty\"`\n    Claims      map[string]any    `json:\"claims,omitempty\"`\n    Method      AuthMethod        `json:\"method\"`\n    Metadata    map[string]string `json:\"metadata,omitempty\"`\n    ExpiresAt   time.Time         `json:\"expires_at,omitempty\"`\n    IssuedAt    time.Time         `json:\"issued_at\"`\n}\n\n// AuthMethod identifies how the identity was authenticated.\ntype AuthMethod string\n\nconst (\n    AuthMethodJWT       AuthMethod = \"jwt\"\n    AuthMethodOAuth2    AuthMethod = \"oauth2\"\n    AuthMethodAPIKey    AuthMethod = \"api_key\"\n    AuthMethodMTLS      AuthMethod = \"mtls\"\n    AuthMethodBasic     AuthMethod = \"basic\"\n    AuthMethodAnonymous AuthMethod = \"anonymous\"\n)\n\n// HasRole checks if the identity has a specific role.\nfunc (id *Identity) HasRole(role string) bool {\n    for _, r := range id.Roles {\n        if r == role {\n            return true\n        }\n    }\n    return false\n}\n\n// HasPermission checks if the identity has a specific permission.\nfunc (id *Identity) HasPermission(perm string) bool {\n    for _, p := range id.Permissions {\n        if p == perm {\n            return true\n        }\n    }\n    return false\n}\n\n// HasAnyRole checks if the identity has any of the specified roles.\nfunc (id *Identity) HasAnyRole(roles ...string) bool {\n    for _, role := range roles {\n        if id.HasRole(role) {\n            return true\n        }\n    }\n    return false\n}\n\n// IsExpired checks if the identity has expired.\nfunc (id *Identity) IsExpired() bool {\n    if id.ExpiresAt.IsZero() {\n        return false\n    }\n    return time.Now().After(id.ExpiresAt)\n}\n\n// Context key for identity storage.\ntype identityKey struct{}\n\n// WithIdentity adds an identity to the context.\nfunc WithIdentity(ctx context.Context, id *Identity) context.Context {\n    return context.WithValue(ctx, identityKey{}, id)\n}\n\n// IdentityFromContext retrieves the identity from context.\nfunc IdentityFromContext(ctx context.Context) *Identity {\n    if v := ctx.Value(identityKey{}); v != nil {\n        return v.(*Identity)\n    }\n    return nil\n}\n\n// PrincipalFromContext retrieves the principal from context.\nfunc PrincipalFromContext(ctx context.Context) string {\n    if id := IdentityFromContext(ctx); id != nil {\n        return id.Principal\n    }\n    return \"\"\n}\n\n// TenantIDFromContext retrieves the tenant ID from context.\nfunc TenantIDFromContext(ctx context.Context) string {\n    if id := IdentityFromContext(ctx); id != nil {\n        return id.TenantID\n    }\n    return \"\"\n}\n</code></pre> <p>Tests:</p> <pre><code>// internal/auth/identity_test.go\npackage auth\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc TestIdentity_HasRole(t *testing.T) {\n    id := &amp;Identity{Roles: []string{\"admin\", \"user\"}}\n\n    assert.True(t, id.HasRole(\"admin\"))\n    assert.True(t, id.HasRole(\"user\"))\n    assert.False(t, id.HasRole(\"superuser\"))\n}\n\nfunc TestIdentity_HasPermission(t *testing.T) {\n    id := &amp;Identity{Permissions: []string{\"read:tools\", \"write:tools\"}}\n\n    assert.True(t, id.HasPermission(\"read:tools\"))\n    assert.False(t, id.HasPermission(\"delete:tools\"))\n}\n\nfunc TestIdentity_HasAnyRole(t *testing.T) {\n    id := &amp;Identity{Roles: []string{\"user\"}}\n\n    assert.True(t, id.HasAnyRole(\"admin\", \"user\"))\n    assert.False(t, id.HasAnyRole(\"admin\", \"superuser\"))\n}\n\nfunc TestIdentity_IsExpired(t *testing.T) {\n    t.Run(\"not expired\", func(t *testing.T) {\n        id := &amp;Identity{ExpiresAt: time.Now().Add(time.Hour)}\n        assert.False(t, id.IsExpired())\n    })\n\n    t.Run(\"expired\", func(t *testing.T) {\n        id := &amp;Identity{ExpiresAt: time.Now().Add(-time.Hour)}\n        assert.True(t, id.IsExpired())\n    })\n\n    t.Run(\"no expiry\", func(t *testing.T) {\n        id := &amp;Identity{}\n        assert.False(t, id.IsExpired())\n    })\n}\n\nfunc TestIdentityContext(t *testing.T) {\n    ctx := context.Background()\n\n    // No identity in context\n    assert.Nil(t, IdentityFromContext(ctx))\n    assert.Empty(t, PrincipalFromContext(ctx))\n    assert.Empty(t, TenantIDFromContext(ctx))\n\n    // Add identity\n    id := &amp;Identity{\n        Principal: \"alice\",\n        TenantID:  \"acme-corp\",\n    }\n    ctx = WithIdentity(ctx, id)\n\n    // Retrieve identity\n    retrieved := IdentityFromContext(ctx)\n    require.NotNil(t, retrieved)\n    assert.Equal(t, \"alice\", retrieved.Principal)\n    assert.Equal(t, \"acme-corp\", retrieved.TenantID)\n\n    // Convenience helpers\n    assert.Equal(t, \"alice\", PrincipalFromContext(ctx))\n    assert.Equal(t, \"acme-corp\", TenantIDFromContext(ctx))\n}\n</code></pre> <p>Verification:</p> <pre><code>go test ./internal/auth/... -run TestIdentity -v\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#task-2-authenticator-interface-types","title":"Task 2: Authenticator Interface &amp; Types","text":"<p>Files: - <code>internal/auth/authenticator.go</code> - <code>internal/auth/authenticator_test.go</code></p> <pre><code>// internal/auth/authenticator.go\npackage auth\n\nimport (\n    \"context\"\n    \"crypto/x509\"\n    \"errors\"\n)\n\n// Common authentication errors.\nvar (\n    ErrUnauthorized       = errors.New(\"unauthorized\")\n    ErrInvalidCredentials = errors.New(\"invalid credentials\")\n    ErrInvalidToken       = errors.New(\"invalid token\")\n    ErrTokenExpired       = errors.New(\"token expired\")\n    ErrMissingCredentials = errors.New(\"missing credentials\")\n    ErrUnsupportedMethod  = errors.New(\"unsupported authentication method\")\n)\n\n// AuthRequest contains request data for authentication.\ntype AuthRequest struct {\n    Headers    map[string][]string\n    Method     string\n    Resource   string\n    RemoteAddr string\n    TLSInfo    *TLSInfo\n    Raw        any\n}\n\n// TLSInfo contains client certificate information.\ntype TLSInfo struct {\n    PeerCertificates []*x509.Certificate\n    Verified         bool\n    CommonName       string\n    DNSNames         []string\n}\n\n// GetHeader retrieves a header value.\nfunc (r *AuthRequest) GetHeader(name string) string {\n    if values, ok := r.Headers[name]; ok &amp;&amp; len(values) &gt; 0 {\n        return values[0]\n    }\n    return \"\"\n}\n\n// AuthResult encapsulates authentication outcome.\ntype AuthResult struct {\n    Authenticated bool\n    Identity      *Identity\n    Error         error\n    Challenge     string\n}\n\n// Authenticator validates credentials and returns an identity.\ntype Authenticator interface {\n    Authenticate(ctx context.Context, req *AuthRequest) (*AuthResult, error)\n    Name() string\n    Supports(ctx context.Context, req *AuthRequest) bool\n}\n\n// AuthenticatorFunc is a function adapter for Authenticator.\ntype AuthenticatorFunc func(ctx context.Context, req *AuthRequest) (*AuthResult, error)\n\n// Authenticate implements Authenticator.\nfunc (f AuthenticatorFunc) Authenticate(ctx context.Context, req *AuthRequest) (*AuthResult, error) {\n    return f(ctx, req)\n}\n\n// Name implements Authenticator.\nfunc (f AuthenticatorFunc) Name() string { return \"func\" }\n\n// Supports implements Authenticator.\nfunc (f AuthenticatorFunc) Supports(ctx context.Context, req *AuthRequest) bool { return true }\n</code></pre> <p>Tests:</p> <pre><code>// internal/auth/authenticator_test.go\npackage auth\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n)\n\nfunc TestAuthRequest_GetHeader(t *testing.T) {\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{\n            \"Authorization\": {\"Bearer token123\"},\n            \"X-API-Key\":     {\"key456\"},\n        },\n    }\n\n    assert.Equal(t, \"Bearer token123\", req.GetHeader(\"Authorization\"))\n    assert.Equal(t, \"key456\", req.GetHeader(\"X-API-Key\"))\n    assert.Empty(t, req.GetHeader(\"Missing\"))\n}\n\nfunc TestAuthenticatorFunc(t *testing.T) {\n    called := false\n    auth := AuthenticatorFunc(func(ctx context.Context, req *AuthRequest) (*AuthResult, error) {\n        called = true\n        return &amp;AuthResult{Authenticated: true}, nil\n    })\n\n    result, err := auth.Authenticate(context.Background(), &amp;AuthRequest{})\n    assert.NoError(t, err)\n    assert.True(t, result.Authenticated)\n    assert.True(t, called)\n    assert.Equal(t, \"func\", auth.Name())\n    assert.True(t, auth.Supports(context.Background(), &amp;AuthRequest{}))\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#task-3-composite-authenticator","title":"Task 3: Composite Authenticator","text":"<p>Files: - <code>internal/auth/composite.go</code> - <code>internal/auth/composite_test.go</code></p> <pre><code>// internal/auth/composite.go\npackage auth\n\nimport (\n    \"context\"\n    \"errors\"\n)\n\n// CompositeAuthenticator tries multiple authenticators in order.\ntype CompositeAuthenticator struct {\n    Authenticators []Authenticator\n    StopOnFirst    bool\n}\n\n// NewCompositeAuthenticator creates a composite authenticator.\nfunc NewCompositeAuthenticator(authenticators ...Authenticator) *CompositeAuthenticator {\n    return &amp;CompositeAuthenticator{\n        Authenticators: authenticators,\n        StopOnFirst:    true,\n    }\n}\n\n// Authenticate implements Authenticator.\nfunc (c *CompositeAuthenticator) Authenticate(ctx context.Context, req *AuthRequest) (*AuthResult, error) {\n    var lastResult *AuthResult\n    var errs []error\n\n    for _, auth := range c.Authenticators {\n        if !auth.Supports(ctx, req) {\n            continue\n        }\n\n        result, err := auth.Authenticate(ctx, req)\n        if err != nil {\n            errs = append(errs, err)\n            continue\n        }\n\n        if result.Authenticated {\n            if c.StopOnFirst {\n                return result, nil\n            }\n            lastResult = result\n        } else {\n            lastResult = result\n        }\n    }\n\n    if lastResult != nil &amp;&amp; lastResult.Authenticated {\n        return lastResult, nil\n    }\n\n    if lastResult != nil {\n        return lastResult, nil\n    }\n\n    // No authenticator succeeded\n    return &amp;AuthResult{\n        Authenticated: false,\n        Challenge:     \"Bearer\",\n        Error:         errors.Join(append([]error{ErrUnauthorized}, errs...)...),\n    }, nil\n}\n\n// Name implements Authenticator.\nfunc (c *CompositeAuthenticator) Name() string {\n    return \"composite\"\n}\n\n// Supports implements Authenticator.\nfunc (c *CompositeAuthenticator) Supports(ctx context.Context, req *AuthRequest) bool {\n    for _, auth := range c.Authenticators {\n        if auth.Supports(ctx, req) {\n            return true\n        }\n    }\n    return false\n}\n</code></pre> <p>Tests:</p> <pre><code>// internal/auth/composite_test.go\npackage auth\n\nimport (\n    \"context\"\n    \"errors\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc TestCompositeAuthenticator_FirstSucceeds(t *testing.T) {\n    auth1 := &amp;mockAuthenticator{\n        name:     \"auth1\",\n        supports: true,\n        result:   &amp;AuthResult{Authenticated: true, Identity: &amp;Identity{Principal: \"user1\"}},\n    }\n    auth2 := &amp;mockAuthenticator{\n        name:     \"auth2\",\n        supports: true,\n        result:   &amp;AuthResult{Authenticated: true, Identity: &amp;Identity{Principal: \"user2\"}},\n    }\n\n    composite := NewCompositeAuthenticator(auth1, auth2)\n    result, err := composite.Authenticate(context.Background(), &amp;AuthRequest{})\n\n    require.NoError(t, err)\n    assert.True(t, result.Authenticated)\n    assert.Equal(t, \"user1\", result.Identity.Principal)\n    assert.True(t, auth1.called)\n    assert.False(t, auth2.called) // StopOnFirst\n}\n\nfunc TestCompositeAuthenticator_FallbackToSecond(t *testing.T) {\n    auth1 := &amp;mockAuthenticator{\n        name:     \"auth1\",\n        supports: true,\n        result:   &amp;AuthResult{Authenticated: false},\n    }\n    auth2 := &amp;mockAuthenticator{\n        name:     \"auth2\",\n        supports: true,\n        result:   &amp;AuthResult{Authenticated: true, Identity: &amp;Identity{Principal: \"user2\"}},\n    }\n\n    composite := NewCompositeAuthenticator(auth1, auth2)\n    result, err := composite.Authenticate(context.Background(), &amp;AuthRequest{})\n\n    require.NoError(t, err)\n    assert.True(t, result.Authenticated)\n    assert.Equal(t, \"user2\", result.Identity.Principal)\n}\n\nfunc TestCompositeAuthenticator_AllFail(t *testing.T) {\n    auth1 := &amp;mockAuthenticator{\n        name:     \"auth1\",\n        supports: true,\n        result:   &amp;AuthResult{Authenticated: false},\n    }\n    auth2 := &amp;mockAuthenticator{\n        name:     \"auth2\",\n        supports: true,\n        result:   &amp;AuthResult{Authenticated: false},\n    }\n\n    composite := NewCompositeAuthenticator(auth1, auth2)\n    result, err := composite.Authenticate(context.Background(), &amp;AuthRequest{})\n\n    require.NoError(t, err)\n    assert.False(t, result.Authenticated)\n    assert.ErrorIs(t, result.Error, ErrUnauthorized)\n}\n\nfunc TestCompositeAuthenticator_SkipsUnsupported(t *testing.T) {\n    auth1 := &amp;mockAuthenticator{\n        name:     \"auth1\",\n        supports: false, // Does not support\n        result:   &amp;AuthResult{Authenticated: true},\n    }\n    auth2 := &amp;mockAuthenticator{\n        name:     \"auth2\",\n        supports: true,\n        result:   &amp;AuthResult{Authenticated: true, Identity: &amp;Identity{Principal: \"user2\"}},\n    }\n\n    composite := NewCompositeAuthenticator(auth1, auth2)\n    result, err := composite.Authenticate(context.Background(), &amp;AuthRequest{})\n\n    require.NoError(t, err)\n    assert.True(t, result.Authenticated)\n    assert.Equal(t, \"user2\", result.Identity.Principal)\n    assert.False(t, auth1.called)\n    assert.True(t, auth2.called)\n}\n\nfunc TestCompositeAuthenticator_HandlesErrors(t *testing.T) {\n    auth1 := &amp;mockAuthenticator{\n        name:     \"auth1\",\n        supports: true,\n        err:      errors.New(\"network error\"),\n    }\n    auth2 := &amp;mockAuthenticator{\n        name:     \"auth2\",\n        supports: true,\n        result:   &amp;AuthResult{Authenticated: true, Identity: &amp;Identity{Principal: \"user2\"}},\n    }\n\n    composite := NewCompositeAuthenticator(auth1, auth2)\n    result, err := composite.Authenticate(context.Background(), &amp;AuthRequest{})\n\n    require.NoError(t, err)\n    assert.True(t, result.Authenticated)\n    assert.Equal(t, \"user2\", result.Identity.Principal)\n}\n\n// mockAuthenticator for testing\ntype mockAuthenticator struct {\n    name     string\n    supports bool\n    result   *AuthResult\n    err      error\n    called   bool\n}\n\nfunc (m *mockAuthenticator) Authenticate(ctx context.Context, req *AuthRequest) (*AuthResult, error) {\n    m.called = true\n    return m.result, m.err\n}\n\nfunc (m *mockAuthenticator) Name() string { return m.name }\n\nfunc (m *mockAuthenticator) Supports(ctx context.Context, req *AuthRequest) bool {\n    return m.supports\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#task-4-jwt-authenticator","title":"Task 4: JWT Authenticator","text":"<p>Files: - <code>internal/auth/jwt.go</code> - <code>internal/auth/jwt_test.go</code></p> <pre><code>// internal/auth/jwt.go\npackage auth\n\nimport (\n    \"context\"\n    \"crypto/rsa\"\n    \"errors\"\n    \"fmt\"\n    \"strings\"\n    \"time\"\n\n    \"github.com/golang-jwt/jwt/v5\"\n)\n\n// JWTConfig configures JWT validation.\ntype JWTConfig struct {\n    Issuer           string        `yaml:\"issuer\"`\n    Audience         string        `yaml:\"audience\"`\n    HeaderName       string        `yaml:\"header_name\"`\n    TokenPrefix      string        `yaml:\"token_prefix\"`\n    ClockSkew        time.Duration `yaml:\"clock_skew\"`\n    RequiredClaims   []string      `yaml:\"required_claims\"`\n    PrincipalClaim   string        `yaml:\"principal_claim\"`\n    TenantClaim      string        `yaml:\"tenant_claim\"`\n    RolesClaim       string        `yaml:\"roles_claim\"`\n    PermissionsClaim string        `yaml:\"permissions_claim\"`\n}\n\n// DefaultJWTConfig returns sensible defaults.\nfunc DefaultJWTConfig() JWTConfig {\n    return JWTConfig{\n        HeaderName:     \"Authorization\",\n        TokenPrefix:    \"Bearer \",\n        ClockSkew:      5 * time.Minute,\n        PrincipalClaim: \"sub\",\n    }\n}\n\n// KeyProvider fetches signing keys for JWT validation.\ntype KeyProvider interface {\n    GetKey(ctx context.Context, keyID string) (any, error)\n    GetKeys(ctx context.Context) ([]any, error)\n}\n\n// StaticKeyProvider uses a single static key.\ntype StaticKeyProvider struct {\n    Key any\n}\n\n// GetKey implements KeyProvider.\nfunc (p *StaticKeyProvider) GetKey(ctx context.Context, keyID string) (any, error) {\n    return p.Key, nil\n}\n\n// GetKeys implements KeyProvider.\nfunc (p *StaticKeyProvider) GetKeys(ctx context.Context) ([]any, error) {\n    return []any{p.Key}, nil\n}\n\n// JWTAuthenticator validates JWT tokens.\ntype JWTAuthenticator struct {\n    Config      JWTConfig\n    KeyProvider KeyProvider\n}\n\n// NewJWTAuthenticator creates a JWT authenticator.\nfunc NewJWTAuthenticator(cfg JWTConfig, keyProvider KeyProvider) *JWTAuthenticator {\n    if cfg.HeaderName == \"\" {\n        cfg.HeaderName = \"Authorization\"\n    }\n    if cfg.TokenPrefix == \"\" {\n        cfg.TokenPrefix = \"Bearer \"\n    }\n    if cfg.PrincipalClaim == \"\" {\n        cfg.PrincipalClaim = \"sub\"\n    }\n    return &amp;JWTAuthenticator{\n        Config:      cfg,\n        KeyProvider: keyProvider,\n    }\n}\n\n// Authenticate implements Authenticator.\nfunc (a *JWTAuthenticator) Authenticate(ctx context.Context, req *AuthRequest) (*AuthResult, error) {\n    // Extract token from header\n    header := req.GetHeader(a.Config.HeaderName)\n    if header == \"\" {\n        return &amp;AuthResult{\n            Authenticated: false,\n            Challenge:     \"Bearer\",\n            Error:         ErrMissingCredentials,\n        }, nil\n    }\n\n    // Remove prefix\n    if !strings.HasPrefix(header, a.Config.TokenPrefix) {\n        return &amp;AuthResult{\n            Authenticated: false,\n            Challenge:     \"Bearer\",\n            Error:         ErrInvalidToken,\n        }, nil\n    }\n    tokenString := strings.TrimPrefix(header, a.Config.TokenPrefix)\n\n    // Parse and validate token\n    token, err := jwt.Parse(tokenString, func(token *jwt.Token) (any, error) {\n        // Get key ID from header\n        kid, _ := token.Header[\"kid\"].(string)\n        return a.KeyProvider.GetKey(ctx, kid)\n    }, jwt.WithLeeway(a.Config.ClockSkew))\n\n    if err != nil {\n        if errors.Is(err, jwt.ErrTokenExpired) {\n            return &amp;AuthResult{\n                Authenticated: false,\n                Challenge:     \"Bearer error=\\\"invalid_token\\\", error_description=\\\"token expired\\\"\",\n                Error:         ErrTokenExpired,\n            }, nil\n        }\n        return &amp;AuthResult{\n            Authenticated: false,\n            Challenge:     \"Bearer error=\\\"invalid_token\\\"\",\n            Error:         fmt.Errorf(\"%w: %v\", ErrInvalidToken, err),\n        }, nil\n    }\n\n    if !token.Valid {\n        return &amp;AuthResult{\n            Authenticated: false,\n            Challenge:     \"Bearer error=\\\"invalid_token\\\"\",\n            Error:         ErrInvalidToken,\n        }, nil\n    }\n\n    // Extract claims\n    claims, ok := token.Claims.(jwt.MapClaims)\n    if !ok {\n        return &amp;AuthResult{\n            Authenticated: false,\n            Error:         errors.New(\"invalid claims format\"),\n        }, nil\n    }\n\n    // Validate issuer\n    if a.Config.Issuer != \"\" {\n        if iss, _ := claims[\"iss\"].(string); iss != a.Config.Issuer {\n            return &amp;AuthResult{\n                Authenticated: false,\n                Error:         errors.New(\"invalid issuer\"),\n            }, nil\n        }\n    }\n\n    // Validate audience\n    if a.Config.Audience != \"\" {\n        audClaim := claims[\"aud\"]\n        valid := false\n        switch aud := audClaim.(type) {\n        case string:\n            valid = aud == a.Config.Audience\n        case []any:\n            for _, a := range aud {\n                if s, ok := a.(string); ok &amp;&amp; s == a.Config.Audience {\n                    valid = true\n                    break\n                }\n            }\n        }\n        if !valid {\n            return &amp;AuthResult{\n                Authenticated: false,\n                Error:         errors.New(\"invalid audience\"),\n            }, nil\n        }\n    }\n\n    // Check required claims\n    for _, claim := range a.Config.RequiredClaims {\n        if _, ok := claims[claim]; !ok {\n            return &amp;AuthResult{\n                Authenticated: false,\n                Error:         fmt.Errorf(\"missing required claim: %s\", claim),\n            }, nil\n        }\n    }\n\n    // Build identity\n    identity := a.buildIdentity(claims)\n\n    return &amp;AuthResult{\n        Authenticated: true,\n        Identity:      identity,\n    }, nil\n}\n\nfunc (a *JWTAuthenticator) buildIdentity(claims jwt.MapClaims) *Identity {\n    id := &amp;Identity{\n        Method:   AuthMethodJWT,\n        Claims:   make(map[string]any),\n        IssuedAt: time.Now(),\n    }\n\n    // Principal\n    if principal, ok := claims[a.Config.PrincipalClaim].(string); ok {\n        id.Principal = principal\n    }\n\n    // Tenant\n    if a.Config.TenantClaim != \"\" {\n        if tenant, ok := claims[a.Config.TenantClaim].(string); ok {\n            id.TenantID = tenant\n        }\n    }\n\n    // Roles\n    if a.Config.RolesClaim != \"\" {\n        if roles, ok := claims[a.Config.RolesClaim].([]any); ok {\n            for _, r := range roles {\n                if s, ok := r.(string); ok {\n                    id.Roles = append(id.Roles, s)\n                }\n            }\n        }\n    }\n\n    // Permissions\n    if a.Config.PermissionsClaim != \"\" {\n        if perms, ok := claims[a.Config.PermissionsClaim].([]any); ok {\n            for _, p := range perms {\n                if s, ok := p.(string); ok {\n                    id.Permissions = append(id.Permissions, s)\n                }\n            }\n        }\n    }\n\n    // Expiration\n    if exp, ok := claims[\"exp\"].(float64); ok {\n        id.ExpiresAt = time.Unix(int64(exp), 0)\n    }\n\n    // Copy all claims\n    for k, v := range claims {\n        id.Claims[k] = v\n    }\n\n    return id\n}\n\n// Name implements Authenticator.\nfunc (a *JWTAuthenticator) Name() string {\n    return \"jwt\"\n}\n\n// Supports implements Authenticator.\nfunc (a *JWTAuthenticator) Supports(ctx context.Context, req *AuthRequest) bool {\n    header := req.GetHeader(a.Config.HeaderName)\n    return strings.HasPrefix(header, a.Config.TokenPrefix)\n}\n\n// NewStaticKeyProvider creates a key provider with a static key.\nfunc NewStaticKeyProvider(key any) *StaticKeyProvider {\n    return &amp;StaticKeyProvider{Key: key}\n}\n\n// NewRSAKeyProvider creates a key provider with an RSA public key.\nfunc NewRSAKeyProvider(key *rsa.PublicKey) *StaticKeyProvider {\n    return &amp;StaticKeyProvider{Key: key}\n}\n\n// NewHMACKeyProvider creates a key provider with an HMAC secret.\nfunc NewHMACKeyProvider(secret []byte) *StaticKeyProvider {\n    return &amp;StaticKeyProvider{Key: secret}\n}\n</code></pre> <p>Tests:</p> <pre><code>// internal/auth/jwt_test.go\npackage auth\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/golang-jwt/jwt/v5\"\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nvar testSecret = []byte(\"test-secret-key-for-jwt-testing\")\n\nfunc createTestToken(claims jwt.MapClaims) string {\n    token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)\n    tokenString, _ := token.SignedString(testSecret)\n    return tokenString\n}\n\nfunc TestJWTAuthenticator_ValidToken(t *testing.T) {\n    auth := NewJWTAuthenticator(\n        JWTConfig{\n            Issuer:         \"test-issuer\",\n            Audience:       \"test-audience\",\n            PrincipalClaim: \"sub\",\n            RolesClaim:     \"roles\",\n        },\n        NewHMACKeyProvider(testSecret),\n    )\n\n    token := createTestToken(jwt.MapClaims{\n        \"sub\":   \"alice\",\n        \"iss\":   \"test-issuer\",\n        \"aud\":   \"test-audience\",\n        \"exp\":   time.Now().Add(time.Hour).Unix(),\n        \"roles\": []any{\"admin\", \"user\"},\n    })\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{\n            \"Authorization\": {\"Bearer \" + token},\n        },\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.True(t, result.Authenticated)\n    require.NotNil(t, result.Identity)\n    assert.Equal(t, \"alice\", result.Identity.Principal)\n    assert.Equal(t, AuthMethodJWT, result.Identity.Method)\n    assert.Contains(t, result.Identity.Roles, \"admin\")\n    assert.Contains(t, result.Identity.Roles, \"user\")\n}\n\nfunc TestJWTAuthenticator_ExpiredToken(t *testing.T) {\n    auth := NewJWTAuthenticator(\n        DefaultJWTConfig(),\n        NewHMACKeyProvider(testSecret),\n    )\n\n    token := createTestToken(jwt.MapClaims{\n        \"sub\": \"alice\",\n        \"exp\": time.Now().Add(-time.Hour).Unix(), // Expired\n    })\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{\n            \"Authorization\": {\"Bearer \" + token},\n        },\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.False(t, result.Authenticated)\n    assert.ErrorIs(t, result.Error, ErrTokenExpired)\n}\n\nfunc TestJWTAuthenticator_InvalidSignature(t *testing.T) {\n    auth := NewJWTAuthenticator(\n        DefaultJWTConfig(),\n        NewHMACKeyProvider([]byte(\"wrong-secret\")),\n    )\n\n    token := createTestToken(jwt.MapClaims{\n        \"sub\": \"alice\",\n        \"exp\": time.Now().Add(time.Hour).Unix(),\n    })\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{\n            \"Authorization\": {\"Bearer \" + token},\n        },\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.False(t, result.Authenticated)\n    assert.ErrorIs(t, result.Error, ErrInvalidToken)\n}\n\nfunc TestJWTAuthenticator_MissingToken(t *testing.T) {\n    auth := NewJWTAuthenticator(\n        DefaultJWTConfig(),\n        NewHMACKeyProvider(testSecret),\n    )\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{},\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.False(t, result.Authenticated)\n    assert.ErrorIs(t, result.Error, ErrMissingCredentials)\n}\n\nfunc TestJWTAuthenticator_InvalidIssuer(t *testing.T) {\n    auth := NewJWTAuthenticator(\n        JWTConfig{\n            Issuer: \"expected-issuer\",\n        },\n        NewHMACKeyProvider(testSecret),\n    )\n\n    token := createTestToken(jwt.MapClaims{\n        \"sub\": \"alice\",\n        \"iss\": \"wrong-issuer\",\n        \"exp\": time.Now().Add(time.Hour).Unix(),\n    })\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{\n            \"Authorization\": {\"Bearer \" + token},\n        },\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.False(t, result.Authenticated)\n}\n\nfunc TestJWTAuthenticator_TenantClaim(t *testing.T) {\n    auth := NewJWTAuthenticator(\n        JWTConfig{\n            PrincipalClaim: \"sub\",\n            TenantClaim:    \"org_id\",\n        },\n        NewHMACKeyProvider(testSecret),\n    )\n\n    token := createTestToken(jwt.MapClaims{\n        \"sub\":    \"alice\",\n        \"org_id\": \"acme-corp\",\n        \"exp\":    time.Now().Add(time.Hour).Unix(),\n    })\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{\n            \"Authorization\": {\"Bearer \" + token},\n        },\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.True(t, result.Authenticated)\n    assert.Equal(t, \"acme-corp\", result.Identity.TenantID)\n}\n\nfunc TestJWTAuthenticator_Supports(t *testing.T) {\n    auth := NewJWTAuthenticator(DefaultJWTConfig(), NewHMACKeyProvider(testSecret))\n\n    t.Run(\"supports bearer token\", func(t *testing.T) {\n        req := &amp;AuthRequest{\n            Headers: map[string][]string{\n                \"Authorization\": {\"Bearer token\"},\n            },\n        }\n        assert.True(t, auth.Supports(context.Background(), req))\n    })\n\n    t.Run(\"does not support api key\", func(t *testing.T) {\n        req := &amp;AuthRequest{\n            Headers: map[string][]string{\n                \"X-API-Key\": {\"key123\"},\n            },\n        }\n        assert.False(t, auth.Supports(context.Background(), req))\n    })\n\n    t.Run(\"does not support basic auth\", func(t *testing.T) {\n        req := &amp;AuthRequest{\n            Headers: map[string][]string{\n                \"Authorization\": {\"Basic dXNlcjpwYXNz\"},\n            },\n        }\n        assert.False(t, auth.Supports(context.Background(), req))\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#task-5-api-key-authenticator","title":"Task 5: API Key Authenticator","text":"<p>Files: - <code>internal/auth/apikey.go</code> - <code>internal/auth/apikey_test.go</code></p> <pre><code>// internal/auth/apikey.go\npackage auth\n\nimport (\n    \"context\"\n    \"crypto/sha256\"\n    \"crypto/subtle\"\n    \"encoding/hex\"\n    \"strings\"\n    \"time\"\n)\n\n// APIKeyConfig configures API key validation.\ntype APIKeyConfig struct {\n    HeaderName    string `yaml:\"header_name\"`\n    QueryParam    string `yaml:\"query_param\"`\n    Prefix        string `yaml:\"prefix\"`\n    HashAlgorithm string `yaml:\"hash_algorithm\"` // none, sha256\n}\n\n// DefaultAPIKeyConfig returns sensible defaults.\nfunc DefaultAPIKeyConfig() APIKeyConfig {\n    return APIKeyConfig{\n        HeaderName:    \"X-API-Key\",\n        HashAlgorithm: \"none\",\n    }\n}\n\n// APIKeyInfo contains API key metadata.\ntype APIKeyInfo struct {\n    ID          string\n    Name        string\n    KeyHash     string // Hashed key for storage\n    Principal   string\n    TenantID    string\n    Roles       []string\n    Permissions []string\n    Scopes      []string\n    Metadata    map[string]string\n    CreatedAt   time.Time\n    ExpiresAt   *time.Time\n    LastUsedAt  *time.Time\n}\n\n// IsExpired checks if the API key has expired.\nfunc (k *APIKeyInfo) IsExpired() bool {\n    if k.ExpiresAt == nil {\n        return false\n    }\n    return time.Now().After(*k.ExpiresAt)\n}\n\n// APIKeyStore retrieves API key information.\n// This is the pluggable interface - implementations live in toolpersist.\ntype APIKeyStore interface {\n    Lookup(ctx context.Context, keyHash string) (*APIKeyInfo, error)\n}\n\n// APIKeyAuthenticator validates API keys.\ntype APIKeyAuthenticator struct {\n    Config APIKeyConfig\n    Store  APIKeyStore\n}\n\n// NewAPIKeyAuthenticator creates an API key authenticator.\nfunc NewAPIKeyAuthenticator(cfg APIKeyConfig, store APIKeyStore) *APIKeyAuthenticator {\n    if cfg.HeaderName == \"\" {\n        cfg.HeaderName = \"X-API-Key\"\n    }\n    return &amp;APIKeyAuthenticator{\n        Config: cfg,\n        Store:  store,\n    }\n}\n\n// Authenticate implements Authenticator.\nfunc (a *APIKeyAuthenticator) Authenticate(ctx context.Context, req *AuthRequest) (*AuthResult, error) {\n    // Extract API key\n    key := a.extractKey(req)\n    if key == \"\" {\n        return &amp;AuthResult{\n            Authenticated: false,\n            Error:         ErrMissingCredentials,\n        }, nil\n    }\n\n    // Hash the key for lookup\n    keyHash := a.hashKey(key)\n\n    // Lookup key info\n    info, err := a.Store.Lookup(ctx, keyHash)\n    if err != nil {\n        return nil, err // System error\n    }\n    if info == nil {\n        return &amp;AuthResult{\n            Authenticated: false,\n            Error:         ErrInvalidCredentials,\n        }, nil\n    }\n\n    // Check expiration\n    if info.IsExpired() {\n        return &amp;AuthResult{\n            Authenticated: false,\n            Error:         ErrTokenExpired,\n        }, nil\n    }\n\n    // Build identity\n    identity := &amp;Identity{\n        Principal:   info.Principal,\n        TenantID:    info.TenantID,\n        Roles:       info.Roles,\n        Permissions: info.Permissions,\n        Method:      AuthMethodAPIKey,\n        Metadata:    info.Metadata,\n        IssuedAt:    info.CreatedAt,\n    }\n    if info.ExpiresAt != nil {\n        identity.ExpiresAt = *info.ExpiresAt\n    }\n\n    return &amp;AuthResult{\n        Authenticated: true,\n        Identity:      identity,\n    }, nil\n}\n\nfunc (a *APIKeyAuthenticator) extractKey(req *AuthRequest) string {\n    // Try header first\n    key := req.GetHeader(a.Config.HeaderName)\n    if key != \"\" {\n        if a.Config.Prefix != \"\" {\n            key = strings.TrimPrefix(key, a.Config.Prefix)\n        }\n        return key\n    }\n    return \"\"\n}\n\nfunc (a *APIKeyAuthenticator) hashKey(key string) string {\n    switch a.Config.HashAlgorithm {\n    case \"sha256\":\n        hash := sha256.Sum256([]byte(key))\n        return hex.EncodeToString(hash[:])\n    default:\n        return key\n    }\n}\n\n// Name implements Authenticator.\nfunc (a *APIKeyAuthenticator) Name() string {\n    return \"api_key\"\n}\n\n// Supports implements Authenticator.\nfunc (a *APIKeyAuthenticator) Supports(ctx context.Context, req *AuthRequest) bool {\n    return req.GetHeader(a.Config.HeaderName) != \"\"\n}\n\n// HashAPIKey hashes an API key for storage.\nfunc HashAPIKey(key string, algorithm string) string {\n    switch algorithm {\n    case \"sha256\":\n        hash := sha256.Sum256([]byte(key))\n        return hex.EncodeToString(hash[:])\n    default:\n        return key\n    }\n}\n\n// ValidateAPIKey compares a key against a stored hash.\nfunc ValidateAPIKey(key, storedHash, algorithm string) bool {\n    keyHash := HashAPIKey(key, algorithm)\n    return subtle.ConstantTimeCompare([]byte(keyHash), []byte(storedHash)) == 1\n}\n\n// MemoryAPIKeyStore is an in-memory implementation for testing.\ntype MemoryAPIKeyStore struct {\n    keys map[string]*APIKeyInfo\n}\n\n// NewMemoryAPIKeyStore creates an in-memory API key store.\nfunc NewMemoryAPIKeyStore() *MemoryAPIKeyStore {\n    return &amp;MemoryAPIKeyStore{\n        keys: make(map[string]*APIKeyInfo),\n    }\n}\n\n// Add stores an API key.\nfunc (s *MemoryAPIKeyStore) Add(info *APIKeyInfo) {\n    s.keys[info.KeyHash] = info\n}\n\n// Lookup implements APIKeyStore.\nfunc (s *MemoryAPIKeyStore) Lookup(ctx context.Context, keyHash string) (*APIKeyInfo, error) {\n    return s.keys[keyHash], nil\n}\n</code></pre> <p>Tests:</p> <pre><code>// internal/auth/apikey_test.go\npackage auth\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc TestAPIKeyAuthenticator_ValidKey(t *testing.T) {\n    store := NewMemoryAPIKeyStore()\n    store.Add(&amp;APIKeyInfo{\n        ID:        \"key1\",\n        KeyHash:   \"test-api-key\",\n        Principal: \"alice\",\n        TenantID:  \"acme-corp\",\n        Roles:     []string{\"user\"},\n    })\n\n    auth := NewAPIKeyAuthenticator(DefaultAPIKeyConfig(), store)\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{\n            \"X-API-Key\": {\"test-api-key\"},\n        },\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.True(t, result.Authenticated)\n    require.NotNil(t, result.Identity)\n    assert.Equal(t, \"alice\", result.Identity.Principal)\n    assert.Equal(t, \"acme-corp\", result.Identity.TenantID)\n    assert.Equal(t, AuthMethodAPIKey, result.Identity.Method)\n}\n\nfunc TestAPIKeyAuthenticator_HashedKey(t *testing.T) {\n    store := NewMemoryAPIKeyStore()\n    keyHash := HashAPIKey(\"my-secret-key\", \"sha256\")\n    store.Add(&amp;APIKeyInfo{\n        ID:        \"key1\",\n        KeyHash:   keyHash,\n        Principal: \"bob\",\n    })\n\n    auth := NewAPIKeyAuthenticator(\n        APIKeyConfig{\n            HeaderName:    \"X-API-Key\",\n            HashAlgorithm: \"sha256\",\n        },\n        store,\n    )\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{\n            \"X-API-Key\": {\"my-secret-key\"},\n        },\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.True(t, result.Authenticated)\n    assert.Equal(t, \"bob\", result.Identity.Principal)\n}\n\nfunc TestAPIKeyAuthenticator_InvalidKey(t *testing.T) {\n    store := NewMemoryAPIKeyStore()\n    auth := NewAPIKeyAuthenticator(DefaultAPIKeyConfig(), store)\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{\n            \"X-API-Key\": {\"invalid-key\"},\n        },\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.False(t, result.Authenticated)\n    assert.ErrorIs(t, result.Error, ErrInvalidCredentials)\n}\n\nfunc TestAPIKeyAuthenticator_ExpiredKey(t *testing.T) {\n    expiredTime := time.Now().Add(-time.Hour)\n    store := NewMemoryAPIKeyStore()\n    store.Add(&amp;APIKeyInfo{\n        ID:        \"key1\",\n        KeyHash:   \"expired-key\",\n        Principal: \"alice\",\n        ExpiresAt: &amp;expiredTime,\n    })\n\n    auth := NewAPIKeyAuthenticator(DefaultAPIKeyConfig(), store)\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{\n            \"X-API-Key\": {\"expired-key\"},\n        },\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.False(t, result.Authenticated)\n    assert.ErrorIs(t, result.Error, ErrTokenExpired)\n}\n\nfunc TestAPIKeyAuthenticator_MissingKey(t *testing.T) {\n    store := NewMemoryAPIKeyStore()\n    auth := NewAPIKeyAuthenticator(DefaultAPIKeyConfig(), store)\n\n    req := &amp;AuthRequest{\n        Headers: map[string][]string{},\n    }\n\n    result, err := auth.Authenticate(context.Background(), req)\n\n    require.NoError(t, err)\n    assert.False(t, result.Authenticated)\n    assert.ErrorIs(t, result.Error, ErrMissingCredentials)\n}\n\nfunc TestAPIKeyAuthenticator_Supports(t *testing.T) {\n    auth := NewAPIKeyAuthenticator(DefaultAPIKeyConfig(), NewMemoryAPIKeyStore())\n\n    t.Run(\"supports X-API-Key header\", func(t *testing.T) {\n        req := &amp;AuthRequest{\n            Headers: map[string][]string{\n                \"X-API-Key\": {\"key123\"},\n            },\n        }\n        assert.True(t, auth.Supports(context.Background(), req))\n    })\n\n    t.Run(\"does not support bearer token\", func(t *testing.T) {\n        req := &amp;AuthRequest{\n            Headers: map[string][]string{\n                \"Authorization\": {\"Bearer token\"},\n            },\n        }\n        assert.False(t, auth.Supports(context.Background(), req))\n    })\n}\n\nfunc TestHashAPIKey(t *testing.T) {\n    key := \"my-secret-key\"\n\n    t.Run(\"sha256\", func(t *testing.T) {\n        hash := HashAPIKey(key, \"sha256\")\n        assert.Len(t, hash, 64) // SHA256 hex = 64 chars\n        assert.NotEqual(t, key, hash)\n    })\n\n    t.Run(\"none\", func(t *testing.T) {\n        hash := HashAPIKey(key, \"none\")\n        assert.Equal(t, key, hash)\n    })\n}\n\nfunc TestValidateAPIKey(t *testing.T) {\n    key := \"my-secret-key\"\n    hash := HashAPIKey(key, \"sha256\")\n\n    assert.True(t, ValidateAPIKey(key, hash, \"sha256\"))\n    assert.False(t, ValidateAPIKey(\"wrong-key\", hash, \"sha256\"))\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#task-6-authorizer-interface-simple-rbac","title":"Task 6: Authorizer Interface &amp; Simple RBAC","text":"<p>Files: - <code>internal/auth/authorizer.go</code> - <code>internal/auth/rbac.go</code> - <code>internal/auth/authorizer_test.go</code> - <code>internal/auth/rbac_test.go</code></p> <pre><code>// internal/auth/authorizer.go\npackage auth\n\nimport (\n    \"context\"\n    \"errors\"\n    \"fmt\"\n)\n\n// Common authorization errors.\nvar (\n    ErrForbidden        = errors.New(\"forbidden\")\n    ErrInsufficientRole = errors.New(\"insufficient role\")\n)\n\n// AuthzRequest contains the authorization request parameters.\ntype AuthzRequest struct {\n    Subject      *Identity\n    Resource     string\n    Action       string\n    ResourceType string\n    Context      map[string]any\n}\n\n// AuthzError provides detailed authorization failure information.\ntype AuthzError struct {\n    Subject  string\n    Resource string\n    Action   string\n    Reason   string\n}\n\nfunc (e *AuthzError) Error() string {\n    return fmt.Sprintf(\"authorization denied: %s cannot %s on %s: %s\",\n        e.Subject, e.Action, e.Resource, e.Reason)\n}\n\nfunc (e *AuthzError) Unwrap() error {\n    return ErrForbidden\n}\n\n// Authorizer makes access control decisions.\ntype Authorizer interface {\n    Authorize(ctx context.Context, req *AuthzRequest) error\n    Name() string\n}\n\n// AuthorizerFunc is a function adapter for Authorizer.\ntype AuthorizerFunc func(ctx context.Context, req *AuthzRequest) error\n\n// Authorize implements Authorizer.\nfunc (f AuthorizerFunc) Authorize(ctx context.Context, req *AuthzRequest) error {\n    return f(ctx, req)\n}\n\n// Name implements Authorizer.\nfunc (f AuthorizerFunc) Name() string { return \"func\" }\n\n// AllowAllAuthorizer permits all requests.\nvar AllowAllAuthorizer = AuthorizerFunc(func(ctx context.Context, req *AuthzRequest) error {\n    return nil\n})\n\n// DenyAllAuthorizer denies all requests.\nvar DenyAllAuthorizer = AuthorizerFunc(func(ctx context.Context, req *AuthzRequest) error {\n    return &amp;AuthzError{\n        Subject:  req.Subject.Principal,\n        Resource: req.Resource,\n        Action:   req.Action,\n        Reason:   \"all access denied\",\n    }\n})\n</code></pre> <pre><code>// internal/auth/rbac.go\npackage auth\n\nimport (\n    \"context\"\n    \"slices\"\n    \"strings\"\n)\n\n// RBACConfig defines roles and permissions.\ntype RBACConfig struct {\n    Roles       map[string]RoleConfig `yaml:\"roles\"`\n    DefaultRole string                `yaml:\"default_role\"`\n}\n\n// RoleConfig defines a role's permissions.\ntype RoleConfig struct {\n    Permissions    []string `yaml:\"permissions\"`\n    Inherits       []string `yaml:\"inherits\"`\n    AllowedTools   []string `yaml:\"allowed_tools\"`\n    DeniedTools    []string `yaml:\"denied_tools\"`\n    AllowedActions []string `yaml:\"allowed_actions\"`\n}\n\n// SimpleRBACAuthorizer provides basic RBAC without external dependencies.\ntype SimpleRBACAuthorizer struct {\n    Config RBACConfig\n}\n\n// NewSimpleRBACAuthorizer creates a simple RBAC authorizer.\nfunc NewSimpleRBACAuthorizer(cfg RBACConfig) *SimpleRBACAuthorizer {\n    return &amp;SimpleRBACAuthorizer{Config: cfg}\n}\n\n// Authorize implements Authorizer.\nfunc (a *SimpleRBACAuthorizer) Authorize(ctx context.Context, req *AuthzRequest) error {\n    if req.Subject == nil {\n        return &amp;AuthzError{\n            Subject:  \"anonymous\",\n            Resource: req.Resource,\n            Action:   req.Action,\n            Reason:   \"no identity\",\n        }\n    }\n\n    // Get effective permissions\n    permissions := a.resolvePermissions(req.Subject)\n    allowedTools := a.resolveAllowedTools(req.Subject)\n    deniedTools := a.resolveDeniedTools(req.Subject)\n    allowedActions := a.resolveAllowedActions(req.Subject)\n\n    // Check for wildcard permission\n    if slices.Contains(permissions, \"*\") {\n        return nil\n    }\n\n    // Check denied tools first (takes precedence)\n    for _, pattern := range deniedTools {\n        if matchPattern(req.Resource, pattern) {\n            return &amp;AuthzError{\n                Subject:  req.Subject.Principal,\n                Resource: req.Resource,\n                Action:   req.Action,\n                Reason:   \"tool explicitly denied\",\n            }\n        }\n    }\n\n    // Check action allowed\n    if len(allowedActions) &gt; 0 &amp;&amp; !slices.Contains(allowedActions, req.Action) &amp;&amp; !slices.Contains(allowedActions, \"*\") {\n        return &amp;AuthzError{\n            Subject:  req.Subject.Principal,\n            Resource: req.Resource,\n            Action:   req.Action,\n            Reason:   \"action not allowed\",\n        }\n    }\n\n    // Check tool allowed\n    if len(allowedTools) &gt; 0 {\n        allowed := false\n        for _, pattern := range allowedTools {\n            if matchPattern(req.Resource, pattern) {\n                allowed = true\n                break\n            }\n        }\n        if !allowed &amp;&amp; !slices.Contains(allowedTools, \"*\") {\n            return &amp;AuthzError{\n                Subject:  req.Subject.Principal,\n                Resource: req.Resource,\n                Action:   req.Action,\n                Reason:   \"tool not allowed\",\n            }\n        }\n    }\n\n    // Check explicit permission\n    permKey := req.ResourceType + \":\" + req.Action\n    toolKey := \"tool:\" + req.Resource\n\n    if slices.Contains(permissions, permKey) || slices.Contains(permissions, toolKey) {\n        return nil\n    }\n\n    // If we have allowed tools/actions and passed those checks, allow\n    if len(allowedTools) &gt; 0 || len(allowedActions) &gt; 0 {\n        return nil\n    }\n\n    return &amp;AuthzError{\n        Subject:  req.Subject.Principal,\n        Resource: req.Resource,\n        Action:   req.Action,\n        Reason:   \"insufficient permissions\",\n    }\n}\n\nfunc (a *SimpleRBACAuthorizer) resolvePermissions(id *Identity) []string {\n    var perms []string\n    seen := make(map[string]bool)\n\n    var resolve func(roles []string)\n    resolve = func(roles []string) {\n        for _, role := range roles {\n            if seen[role] {\n                continue\n            }\n            seen[role] = true\n\n            if cfg, ok := a.Config.Roles[role]; ok {\n                perms = append(perms, cfg.Permissions...)\n                resolve(cfg.Inherits)\n            }\n        }\n    }\n\n    // Start with identity's roles\n    resolve(id.Roles)\n\n    // Add default role if no roles\n    if len(id.Roles) == 0 &amp;&amp; a.Config.DefaultRole != \"\" {\n        resolve([]string{a.Config.DefaultRole})\n    }\n\n    // Add identity's direct permissions\n    perms = append(perms, id.Permissions...)\n\n    return perms\n}\n\nfunc (a *SimpleRBACAuthorizer) resolveAllowedTools(id *Identity) []string {\n    var tools []string\n    seen := make(map[string]bool)\n\n    var resolve func(roles []string)\n    resolve = func(roles []string) {\n        for _, role := range roles {\n            if seen[role] {\n                continue\n            }\n            seen[role] = true\n\n            if cfg, ok := a.Config.Roles[role]; ok {\n                tools = append(tools, cfg.AllowedTools...)\n                resolve(cfg.Inherits)\n            }\n        }\n    }\n\n    resolve(id.Roles)\n    if len(id.Roles) == 0 &amp;&amp; a.Config.DefaultRole != \"\" {\n        resolve([]string{a.Config.DefaultRole})\n    }\n\n    return tools\n}\n\nfunc (a *SimpleRBACAuthorizer) resolveDeniedTools(id *Identity) []string {\n    var tools []string\n    seen := make(map[string]bool)\n\n    var resolve func(roles []string)\n    resolve = func(roles []string) {\n        for _, role := range roles {\n            if seen[role] {\n                continue\n            }\n            seen[role] = true\n\n            if cfg, ok := a.Config.Roles[role]; ok {\n                tools = append(tools, cfg.DeniedTools...)\n                resolve(cfg.Inherits)\n            }\n        }\n    }\n\n    resolve(id.Roles)\n    return tools\n}\n\nfunc (a *SimpleRBACAuthorizer) resolveAllowedActions(id *Identity) []string {\n    var actions []string\n    seen := make(map[string]bool)\n\n    var resolve func(roles []string)\n    resolve = func(roles []string) {\n        for _, role := range roles {\n            if seen[role] {\n                continue\n            }\n            seen[role] = true\n\n            if cfg, ok := a.Config.Roles[role]; ok {\n                actions = append(actions, cfg.AllowedActions...)\n                resolve(cfg.Inherits)\n            }\n        }\n    }\n\n    resolve(id.Roles)\n    if len(id.Roles) == 0 &amp;&amp; a.Config.DefaultRole != \"\" {\n        resolve([]string{a.Config.DefaultRole})\n    }\n\n    return actions\n}\n\n// Name implements Authorizer.\nfunc (a *SimpleRBACAuthorizer) Name() string {\n    return \"simple_rbac\"\n}\n\n// matchPattern matches a resource against a glob-like pattern.\n// Supports * as wildcard prefix/suffix (e.g., \"search_*\", \"*_tool\", \"*\")\nfunc matchPattern(resource, pattern string) bool {\n    if pattern == \"*\" {\n        return true\n    }\n    if strings.HasPrefix(pattern, \"*\") &amp;&amp; strings.HasSuffix(pattern, \"*\") {\n        return strings.Contains(resource, pattern[1:len(pattern)-1])\n    }\n    if strings.HasPrefix(pattern, \"*\") {\n        return strings.HasSuffix(resource, pattern[1:])\n    }\n    if strings.HasSuffix(pattern, \"*\") {\n        return strings.HasPrefix(resource, pattern[:len(pattern)-1])\n    }\n    return resource == pattern\n}\n</code></pre> <p>Tests:</p> <pre><code>// internal/auth/rbac_test.go\npackage auth\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc TestSimpleRBACAuthorizer_AdminRole(t *testing.T) {\n    authz := NewSimpleRBACAuthorizer(RBACConfig{\n        Roles: map[string]RoleConfig{\n            \"admin\": {Permissions: []string{\"*\"}},\n        },\n    })\n\n    req := &amp;AuthzRequest{\n        Subject:      &amp;Identity{Principal: \"alice\", Roles: []string{\"admin\"}},\n        Resource:     \"execute_code\",\n        Action:       \"call\",\n        ResourceType: \"tool\",\n    }\n\n    err := authz.Authorize(context.Background(), req)\n    assert.NoError(t, err)\n}\n\nfunc TestSimpleRBACAuthorizer_UserRole(t *testing.T) {\n    authz := NewSimpleRBACAuthorizer(RBACConfig{\n        Roles: map[string]RoleConfig{\n            \"user\": {\n                AllowedActions: []string{\"call\", \"list\"},\n                AllowedTools:   []string{\"search_*\", \"describe_*\"},\n            },\n        },\n    })\n\n    t.Run(\"allowed tool\", func(t *testing.T) {\n        req := &amp;AuthzRequest{\n            Subject:      &amp;Identity{Principal: \"bob\", Roles: []string{\"user\"}},\n            Resource:     \"search_tools\",\n            Action:       \"call\",\n            ResourceType: \"tool\",\n        }\n        err := authz.Authorize(context.Background(), req)\n        assert.NoError(t, err)\n    })\n\n    t.Run(\"denied tool\", func(t *testing.T) {\n        req := &amp;AuthzRequest{\n            Subject:      &amp;Identity{Principal: \"bob\", Roles: []string{\"user\"}},\n            Resource:     \"execute_code\",\n            Action:       \"call\",\n            ResourceType: \"tool\",\n        }\n        err := authz.Authorize(context.Background(), req)\n        require.Error(t, err)\n        assert.ErrorIs(t, err, ErrForbidden)\n    })\n\n    t.Run(\"denied action\", func(t *testing.T) {\n        req := &amp;AuthzRequest{\n            Subject:      &amp;Identity{Principal: \"bob\", Roles: []string{\"user\"}},\n            Resource:     \"search_tools\",\n            Action:       \"delete\",\n            ResourceType: \"tool\",\n        }\n        err := authz.Authorize(context.Background(), req)\n        require.Error(t, err)\n    })\n}\n\nfunc TestSimpleRBACAuthorizer_DeniedToolsTakePrecedence(t *testing.T) {\n    authz := NewSimpleRBACAuthorizer(RBACConfig{\n        Roles: map[string]RoleConfig{\n            \"user\": {\n                AllowedTools: []string{\"*\"},\n                DeniedTools:  []string{\"execute_code\", \"dangerous_*\"},\n            },\n        },\n    })\n\n    t.Run(\"explicitly denied\", func(t *testing.T) {\n        req := &amp;AuthzRequest{\n            Subject:      &amp;Identity{Principal: \"bob\", Roles: []string{\"user\"}},\n            Resource:     \"execute_code\",\n            Action:       \"call\",\n            ResourceType: \"tool\",\n        }\n        err := authz.Authorize(context.Background(), req)\n        require.Error(t, err)\n        var authzErr *AuthzError\n        require.ErrorAs(t, err, &amp;authzErr)\n        assert.Contains(t, authzErr.Reason, \"denied\")\n    })\n\n    t.Run(\"pattern denied\", func(t *testing.T) {\n        req := &amp;AuthzRequest{\n            Subject:      &amp;Identity{Principal: \"bob\", Roles: []string{\"user\"}},\n            Resource:     \"dangerous_operation\",\n            Action:       \"call\",\n            ResourceType: \"tool\",\n        }\n        err := authz.Authorize(context.Background(), req)\n        require.Error(t, err)\n    })\n}\n\nfunc TestSimpleRBACAuthorizer_RoleInheritance(t *testing.T) {\n    authz := NewSimpleRBACAuthorizer(RBACConfig{\n        Roles: map[string]RoleConfig{\n            \"admin\": {\n                Permissions: []string{\"*\"},\n            },\n            \"power_user\": {\n                Inherits:     []string{\"user\"},\n                AllowedTools: []string{\"execute_code\"},\n            },\n            \"user\": {\n                AllowedActions: []string{\"call\", \"list\"},\n                AllowedTools:   []string{\"search_*\"},\n            },\n        },\n    })\n\n    t.Run(\"inherits from user\", func(t *testing.T) {\n        req := &amp;AuthzRequest{\n            Subject:      &amp;Identity{Principal: \"carol\", Roles: []string{\"power_user\"}},\n            Resource:     \"search_tools\",\n            Action:       \"call\",\n            ResourceType: \"tool\",\n        }\n        err := authz.Authorize(context.Background(), req)\n        assert.NoError(t, err)\n    })\n\n    t.Run(\"has own permissions\", func(t *testing.T) {\n        req := &amp;AuthzRequest{\n            Subject:      &amp;Identity{Principal: \"carol\", Roles: []string{\"power_user\"}},\n            Resource:     \"execute_code\",\n            Action:       \"call\",\n            ResourceType: \"tool\",\n        }\n        err := authz.Authorize(context.Background(), req)\n        assert.NoError(t, err)\n    })\n}\n\nfunc TestSimpleRBACAuthorizer_DefaultRole(t *testing.T) {\n    authz := NewSimpleRBACAuthorizer(RBACConfig{\n        DefaultRole: \"anonymous\",\n        Roles: map[string]RoleConfig{\n            \"anonymous\": {\n                AllowedActions: []string{\"list\"},\n            },\n        },\n    })\n\n    t.Run(\"uses default role\", func(t *testing.T) {\n        req := &amp;AuthzRequest{\n            Subject:      &amp;Identity{Principal: \"unknown\"}, // No roles\n            Resource:     \"any_tool\",\n            Action:       \"list\",\n            ResourceType: \"tool\",\n        }\n        err := authz.Authorize(context.Background(), req)\n        assert.NoError(t, err)\n    })\n\n    t.Run(\"denied without role\", func(t *testing.T) {\n        req := &amp;AuthzRequest{\n            Subject:      &amp;Identity{Principal: \"unknown\"},\n            Resource:     \"any_tool\",\n            Action:       \"call\",\n            ResourceType: \"tool\",\n        }\n        err := authz.Authorize(context.Background(), req)\n        require.Error(t, err)\n    })\n}\n\nfunc TestSimpleRBACAuthorizer_NoIdentity(t *testing.T) {\n    authz := NewSimpleRBACAuthorizer(RBACConfig{})\n\n    req := &amp;AuthzRequest{\n        Subject:  nil,\n        Resource: \"any_tool\",\n        Action:   \"call\",\n    }\n\n    err := authz.Authorize(context.Background(), req)\n    require.Error(t, err)\n}\n\nfunc TestMatchPattern(t *testing.T) {\n    tests := []struct {\n        resource string\n        pattern  string\n        expected bool\n    }{\n        {\"search_tools\", \"search_*\", true},\n        {\"search_tools\", \"*_tools\", true},\n        {\"search_tools\", \"*\", true},\n        {\"search_tools\", \"search_tools\", true},\n        {\"search_tools\", \"other_*\", false},\n        {\"search_tools\", \"*_other\", false},\n        {\"search_tools\", \"exact_match\", false},\n        {\"long_search_tools\", \"*search*\", true},\n    }\n\n    for _, tc := range tests {\n        t.Run(tc.resource+\"/\"+tc.pattern, func(t *testing.T) {\n            assert.Equal(t, tc.expected, matchPattern(tc.resource, tc.pattern))\n        })\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#task-7-auth-middleware-integration","title":"Task 7: Auth Middleware Integration","text":"<p>Files: - <code>internal/auth/middleware.go</code> - <code>internal/auth/middleware_test.go</code></p> <pre><code>// internal/auth/middleware.go\npackage auth\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/jonwraymond/metatools-mcp/internal/mcp\"\n    \"github.com/jonwraymond/metatools-mcp/internal/middleware\"\n    \"github.com/jonwraymond/metatools-mcp/internal/provider\"\n)\n\n// AuthMiddlewareConfig configures the authentication middleware.\ntype AuthMiddlewareConfig struct {\n    AllowAnonymous    bool\n    AnonymousIdentity *Identity\n    SkipMethods       []string\n    OnAuthFailure     func(ctx context.Context, err error) error\n}\n\n// DefaultAuthMiddlewareConfig returns sensible defaults.\nfunc DefaultAuthMiddlewareConfig() AuthMiddlewareConfig {\n    return AuthMiddlewareConfig{\n        AllowAnonymous: false,\n        AnonymousIdentity: &amp;Identity{\n            Principal: \"anonymous\",\n            Method:    AuthMethodAnonymous,\n        },\n    }\n}\n\n// AuthMiddleware creates authentication middleware.\nfunc AuthMiddleware(auth Authenticator, cfg AuthMiddlewareConfig) middleware.Middleware {\n    return func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;authMiddleware{\n            auth:   auth,\n            next:   next,\n            config: cfg,\n        }\n    }\n}\n\ntype authMiddleware struct {\n    auth   Authenticator\n    next   provider.ToolProvider\n    config AuthMiddlewareConfig\n}\n\nfunc (m *authMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    // Build auth request from context\n    req := buildAuthRequestFromContext(ctx)\n\n    // Authenticate\n    result, err := m.auth.Authenticate(ctx, req)\n    if err != nil {\n        return nil, fmt.Errorf(\"authentication error: %w\", err)\n    }\n\n    if !result.Authenticated {\n        if m.config.AllowAnonymous {\n            ctx = WithIdentity(ctx, m.config.AnonymousIdentity)\n        } else {\n            if m.config.OnAuthFailure != nil {\n                return nil, m.config.OnAuthFailure(ctx, result.Error)\n            }\n            return nil, &amp;AuthError{\n                Code:      \"UNAUTHENTICATED\",\n                Message:   \"authentication required\",\n                Challenge: result.Challenge,\n            }\n        }\n    } else {\n        ctx = WithIdentity(ctx, result.Identity)\n    }\n\n    return m.next.Handle(ctx, input)\n}\n\nfunc (m *authMiddleware) Name() string        { return m.next.Name() }\nfunc (m *authMiddleware) Description() string { return m.next.Description() }\nfunc (m *authMiddleware) InputSchema() map[string]any { return m.next.InputSchema() }\n\n// AuthzMiddlewareConfig configures the authorization middleware.\ntype AuthzMiddlewareConfig struct {\n    ResourceResolver func(ctx context.Context, input map[string]any) string\n    ActionResolver   func(ctx context.Context, input map[string]any) string\n    ContextBuilder   func(ctx context.Context, input map[string]any) map[string]any\n    OnDenied         func(ctx context.Context, err error) error\n}\n\n// DefaultAuthzMiddlewareConfig returns sensible defaults.\nfunc DefaultAuthzMiddlewareConfig() AuthzMiddlewareConfig {\n    return AuthzMiddlewareConfig{\n        ResourceResolver: func(ctx context.Context, input map[string]any) string {\n            if name, ok := input[\"name\"].(string); ok {\n                return name\n            }\n            return \"\"\n        },\n        ActionResolver: func(ctx context.Context, input map[string]any) string {\n            return \"call\"\n        },\n        ContextBuilder: func(ctx context.Context, input map[string]any) map[string]any {\n            return nil\n        },\n    }\n}\n\n// AuthzMiddleware creates authorization middleware.\nfunc AuthzMiddleware(authz Authorizer, cfg AuthzMiddlewareConfig) middleware.Middleware {\n    return func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;authzMiddleware{\n            authz:  authz,\n            next:   next,\n            config: cfg,\n        }\n    }\n}\n\ntype authzMiddleware struct {\n    authz  Authorizer\n    next   provider.ToolProvider\n    config AuthzMiddlewareConfig\n}\n\nfunc (m *authzMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    identity := IdentityFromContext(ctx)\n    if identity == nil {\n        return nil, &amp;AuthError{Code: \"UNAUTHENTICATED\", Message: \"no identity in context\"}\n    }\n\n    req := &amp;AuthzRequest{\n        Subject:      identity,\n        Resource:     m.config.ResourceResolver(ctx, input),\n        Action:       m.config.ActionResolver(ctx, input),\n        ResourceType: \"tool\",\n        Context:      m.config.ContextBuilder(ctx, input),\n    }\n\n    if err := m.authz.Authorize(ctx, req); err != nil {\n        if m.config.OnDenied != nil {\n            return nil, m.config.OnDenied(ctx, err)\n        }\n        return nil, &amp;AuthError{\n            Code:    \"FORBIDDEN\",\n            Message: err.Error(),\n        }\n    }\n\n    return m.next.Handle(ctx, input)\n}\n\nfunc (m *authzMiddleware) Name() string        { return m.next.Name() }\nfunc (m *authzMiddleware) Description() string { return m.next.Description() }\nfunc (m *authzMiddleware) InputSchema() map[string]any { return m.next.InputSchema() }\n\n// AuthError represents an authentication/authorization error.\ntype AuthError struct {\n    Code      string\n    Message   string\n    Challenge string\n}\n\nfunc (e *AuthError) Error() string {\n    return fmt.Sprintf(\"%s: %s\", e.Code, e.Message)\n}\n\n// buildAuthRequestFromContext creates an AuthRequest from context.\n// In real usage, this would extract headers from the transport layer.\nfunc buildAuthRequestFromContext(ctx context.Context) *AuthRequest {\n    req := &amp;AuthRequest{\n        Headers: make(map[string][]string),\n    }\n\n    // Extract headers from context if available\n    if headers, ok := ctx.Value(headersKey{}).(map[string][]string); ok {\n        req.Headers = headers\n    }\n\n    return req\n}\n\n// Context key for headers.\ntype headersKey struct{}\n\n// WithHeaders adds request headers to context.\nfunc WithHeaders(ctx context.Context, headers map[string][]string) context.Context {\n    return context.WithValue(ctx, headersKey{}, headers)\n}\n\n// HeadersFromContext retrieves headers from context.\nfunc HeadersFromContext(ctx context.Context) map[string][]string {\n    if headers, ok := ctx.Value(headersKey{}).(map[string][]string); ok {\n        return headers\n    }\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#task-8-factory-registration","title":"Task 8: Factory Registration","text":"<p>Files: - <code>internal/auth/factory.go</code> - <code>internal/auth/factory_test.go</code></p> <pre><code>// internal/auth/factory.go\npackage auth\n\nimport (\n    \"fmt\"\n    \"sync\"\n\n    \"github.com/jonwraymond/metatools-mcp/internal/middleware\"\n)\n\n// AuthenticatorFactory creates an Authenticator from configuration.\ntype AuthenticatorFactory func(cfg map[string]any) (Authenticator, error)\n\n// AuthorizerFactory creates an Authorizer from configuration.\ntype AuthorizerFactory func(cfg map[string]any) (Authorizer, error)\n\n// Registry holds auth component factories.\ntype Registry struct {\n    mu             sync.RWMutex\n    authenticators map[string]AuthenticatorFactory\n    authorizers    map[string]AuthorizerFactory\n}\n\n// NewRegistry creates a new auth registry.\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        authenticators: make(map[string]AuthenticatorFactory),\n        authorizers:    make(map[string]AuthorizerFactory),\n    }\n}\n\n// RegisterAuthenticator registers an authenticator factory.\nfunc (r *Registry) RegisterAuthenticator(name string, factory AuthenticatorFactory) {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    r.authenticators[name] = factory\n}\n\n// RegisterAuthorizer registers an authorizer factory.\nfunc (r *Registry) RegisterAuthorizer(name string, factory AuthorizerFactory) {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    r.authorizers[name] = factory\n}\n\n// GetAuthenticator retrieves an authenticator factory.\nfunc (r *Registry) GetAuthenticator(name string) (AuthenticatorFactory, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    f, ok := r.authenticators[name]\n    return f, ok\n}\n\n// GetAuthorizer retrieves an authorizer factory.\nfunc (r *Registry) GetAuthorizer(name string) (AuthorizerFactory, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    f, ok := r.authorizers[name]\n    return f, ok\n}\n\n// DefaultRegistry is the global auth registry.\nvar DefaultRegistry = NewRegistry()\n\nfunc init() {\n    // Register built-in authenticators\n    DefaultRegistry.RegisterAuthenticator(\"jwt\", func(cfg map[string]any) (Authenticator, error) {\n        jwtCfg := DefaultJWTConfig()\n        if err := mapToStruct(cfg, &amp;jwtCfg); err != nil {\n            return nil, fmt.Errorf(\"jwt config: %w\", err)\n        }\n\n        // Get key provider based on config\n        keyProvider, err := buildKeyProvider(cfg)\n        if err != nil {\n            return nil, fmt.Errorf(\"jwt key provider: %w\", err)\n        }\n\n        return NewJWTAuthenticator(jwtCfg, keyProvider), nil\n    })\n\n    DefaultRegistry.RegisterAuthenticator(\"api_key\", func(cfg map[string]any) (Authenticator, error) {\n        apiKeyCfg := DefaultAPIKeyConfig()\n        if err := mapToStruct(cfg, &amp;apiKeyCfg); err != nil {\n            return nil, fmt.Errorf(\"api_key config: %w\", err)\n        }\n\n        // Get key store based on config\n        store, err := buildAPIKeyStore(cfg)\n        if err != nil {\n            return nil, fmt.Errorf(\"api_key store: %w\", err)\n        }\n\n        return NewAPIKeyAuthenticator(apiKeyCfg, store), nil\n    })\n\n    // Register built-in authorizers\n    DefaultRegistry.RegisterAuthorizer(\"simple_rbac\", func(cfg map[string]any) (Authorizer, error) {\n        rbacCfg := RBACConfig{}\n        if err := mapToStruct(cfg, &amp;rbacCfg); err != nil {\n            return nil, fmt.Errorf(\"rbac config: %w\", err)\n        }\n        return NewSimpleRBACAuthorizer(rbacCfg), nil\n    })\n\n    DefaultRegistry.RegisterAuthorizer(\"allow_all\", func(cfg map[string]any) (Authorizer, error) {\n        return AllowAllAuthorizer, nil\n    })\n\n    DefaultRegistry.RegisterAuthorizer(\"deny_all\", func(cfg map[string]any) (Authorizer, error) {\n        return DenyAllAuthorizer, nil\n    })\n\n    // Register middleware factories with global middleware registry\n    middleware.DefaultRegistry.Register(\"auth\", func(cfg map[string]any) (middleware.Middleware, error) {\n        authType, _ := cfg[\"type\"].(string)\n        if authType == \"\" {\n            authType = \"jwt\"\n        }\n\n        factory, ok := DefaultRegistry.GetAuthenticator(authType)\n        if !ok {\n            return nil, fmt.Errorf(\"unknown authenticator type: %s\", authType)\n        }\n\n        auth, err := factory(cfg)\n        if err != nil {\n            return nil, err\n        }\n\n        mwCfg := DefaultAuthMiddlewareConfig()\n        if allowAnon, ok := cfg[\"allow_anonymous\"].(bool); ok {\n            mwCfg.AllowAnonymous = allowAnon\n        }\n\n        return AuthMiddleware(auth, mwCfg), nil\n    })\n\n    middleware.DefaultRegistry.Register(\"authz\", func(cfg map[string]any) (middleware.Middleware, error) {\n        authzType, _ := cfg[\"type\"].(string)\n        if authzType == \"\" {\n            authzType = \"simple_rbac\"\n        }\n\n        factory, ok := DefaultRegistry.GetAuthorizer(authzType)\n        if !ok {\n            return nil, fmt.Errorf(\"unknown authorizer type: %s\", authzType)\n        }\n\n        authz, err := factory(cfg)\n        if err != nil {\n            return nil, err\n        }\n\n        return AuthzMiddleware(authz, DefaultAuthzMiddlewareConfig()), nil\n    })\n}\n\n// buildKeyProvider creates a KeyProvider from configuration.\nfunc buildKeyProvider(cfg map[string]any) (KeyProvider, error) {\n    // Check for static secret\n    if secret, ok := cfg[\"secret\"].(string); ok {\n        return NewHMACKeyProvider([]byte(secret)), nil\n    }\n\n    // Check for JWKS URL (future: implement JWKSKeyProvider)\n    if jwksURL, ok := cfg[\"jwks_url\"].(string); ok {\n        _ = jwksURL // TODO: Implement JWKSKeyProvider\n        return nil, fmt.Errorf(\"JWKS not yet implemented\")\n    }\n\n    return nil, fmt.Errorf(\"no key provider configured\")\n}\n\n// buildAPIKeyStore creates an APIKeyStore from configuration.\nfunc buildAPIKeyStore(cfg map[string]any) (APIKeyStore, error) {\n    storeCfg, _ := cfg[\"store\"].(map[string]any)\n    storeType, _ := storeCfg[\"type\"].(string)\n\n    switch storeType {\n    case \"memory\", \"\":\n        return NewMemoryAPIKeyStore(), nil\n    // Future: case \"redis\", \"postgres\"\n    default:\n        return nil, fmt.Errorf(\"unknown api_key store type: %s\", storeType)\n    }\n}\n\n// mapToStruct converts a map to a struct using reflection.\n// This is a simplified version - real implementation would use mapstructure.\nfunc mapToStruct(m map[string]any, target any) error {\n    // TODO: Use github.com/mitchellh/mapstructure\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#verification","title":"Verification","text":"<pre><code># Run all auth tests\ngo test ./internal/auth/... -v\n\n# Run with coverage\ngo test ./internal/auth/... -cover\n\n# Run specific test\ngo test ./internal/auth/... -run TestJWTAuthenticator -v\n\n# Lint\ngolangci-lint run ./internal/auth/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#definition-of-done","title":"Definition of Done","text":"<ul> <li>[ ] All tests pass with &gt;80% coverage</li> <li>[ ] No golangci-lint errors</li> <li>[ ] Interfaces documented with godoc comments</li> <li>[ ] Factory registration working</li> <li>[ ] Middleware chain integration verified</li> <li>[ ] YAML configuration parsing works</li> <li>[ ] Context propagation verified</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#dependencies","title":"Dependencies","text":"<pre><code>go get github.com/golang-jwt/jwt/v5\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#changelog","title":"Changelog","text":"Date Change 2026-01-30 Initial auth middleware PRD"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/","title":"ApertureStack Consolidation Master Plan","text":"<p>Date: 2026-01-30 Version: 1.0 Status: Planning</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#executive-summary","title":"Executive Summary","text":"<p>This document outlines the complete consolidation of the ApertureStack ecosystem from 15 standalone repositories into 6 consolidated repositories plus metatools-mcp. This is a breaking change with no backward compatibility requirements.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#current-state","title":"Current State","text":"<pre><code>ApertureStack/\n\u251c\u2500\u2500 toolmodel/          # Standalone\n\u251c\u2500\u2500 tooladapter/        # Standalone\n\u251c\u2500\u2500 toolindex/          # Standalone\n\u251c\u2500\u2500 toolsearch/         # Standalone\n\u251c\u2500\u2500 toolsemantic/       # Standalone (partial)\n\u251c\u2500\u2500 tooldocs/           # Standalone\n\u251c\u2500\u2500 toolrun/            # Standalone\n\u251c\u2500\u2500 toolruntime/        # Standalone\n\u251c\u2500\u2500 toolcode/           # Standalone\n\u251c\u2500\u2500 toolset/            # Standalone\n\u251c\u2500\u2500 toolskill/          # Standalone (partial)\n\u251c\u2500\u2500 toolobserve/        # Standalone\n\u251c\u2500\u2500 toolcache/          # Standalone\n\u251c\u2500\u2500 ai-tools-stack/     # Coordination repo\n\u2514\u2500\u2500 metatools-mcp/      # MCP server\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#target-state","title":"Target State","text":"<pre><code>ApertureStack/\n\u251c\u2500\u2500 toolfoundation/     # model + adapter + version\n\u251c\u2500\u2500 tooldiscovery/      # index + search + semantic + docs\n\u251c\u2500\u2500 toolexec/           # run + runtime + code + backend\n\u251c\u2500\u2500 toolcompose/        # set + skill\n\u251c\u2500\u2500 toolops/            # observe + cache + resilience + health + auth\n\u251c\u2500\u2500 toolprotocol/       # transport + wire + discover + content + task + stream + session + elicit + resource + prompt\n\u251c\u2500\u2500 ai-tools-stack/     # Coordination repo (updated)\n\u2514\u2500\u2500 metatools-mcp/      # MCP server (updated)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-overview","title":"Phase Overview","text":"Phase Name PRDs Effort Dependencies 0 Planning &amp; Documentation 100-102 2 days None 1 Infrastructure Setup 110-113 3 days Phase 0 2 Foundation Layer 120-122 3 days Phase 1 3 Discovery Layer 130-133 4 days Phase 2 4 Execution Layer 140-143 4 days Phase 2 5 Composition Layer 150-151 2 days Phase 3, 4 6 Operations Layer 160-164 5 days Phase 2 7 Protocol Layer 170-179 10 days Phase 2, 4, 6 8 Integration 180-182 3 days Phase 2-7 9 Cleanup 190-192 2 days Phase 8 <p>Total Estimated: 38 days (~8 weeks)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#prd-index","title":"PRD Index","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-0-planning-documentation","title":"Phase 0: Planning &amp; Documentation","text":"PRD Title Description PRD-100 Master Consolidation Plan This document PRD-101 Architecture Diagrams D2/Mermaid diagrams for all layers PRD-102 Schema Definitions JSON Schema for all data types"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-1-infrastructure-setup","title":"Phase 1: Infrastructure Setup","text":"PRD Title Description PRD-110 Repository Creation Create 6 new repos with structure PRD-111 CI/CD Templates Reusable workflow templates PRD-112 GitHub Org Config Secrets, branch protection, teams PRD-113 Release Automation Release-please config for monorepos"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-2-foundation-layer-toolfoundation","title":"Phase 2: Foundation Layer (toolfoundation)","text":"PRD Title Description PRD-120 Migrate toolmodel Move to toolfoundation/model PRD-121 Migrate tooladapter Move to toolfoundation/adapter PRD-122 Create toolversion New: toolfoundation/version"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-3-discovery-layer-tooldiscovery","title":"Phase 3: Discovery Layer (tooldiscovery)","text":"PRD Title Description PRD-130 Migrate toolindex Move to tooldiscovery/index PRD-131 Migrate toolsearch Move to tooldiscovery/search PRD-132 Migrate toolsemantic Move to tooldiscovery/semantic PRD-133 Migrate tooldocs Move to tooldiscovery/docs"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-4-execution-layer-toolexec","title":"Phase 4: Execution Layer (toolexec)","text":"PRD Title Description PRD-140 Migrate toolrun Move to toolexec/run PRD-141 Migrate toolruntime Move to toolexec/runtime PRD-142 Migrate toolcode Move to toolexec/code PRD-143 Extract toolbackend Extract from metatools-mcp"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-5-composition-layer-toolcompose","title":"Phase 5: Composition Layer (toolcompose)","text":"PRD Title Description PRD-150 Migrate toolset Move to toolcompose/set PRD-151 Complete toolskill Move + implement toolcompose/skill"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-6-operations-layer-toolops","title":"Phase 6: Operations Layer (toolops)","text":"PRD Title Description PRD-160 Migrate toolobserve Move to toolops/observe PRD-161 Migrate toolcache Move to toolops/cache PRD-162 Extract toolauth Extract from metatools-mcp PRD-163 Create toolresilience New: toolops/resilience PRD-164 Create toolhealth New: toolops/health"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-7-protocol-layer-toolprotocol","title":"Phase 7: Protocol Layer (toolprotocol)","text":"PRD Title Description PRD-170 Create tooltransport Wire layer (HTTP, gRPC, WS, Stdio) PRD-171 Create toolwire Protocol adapters (MCP, A2A, ACP) PRD-172 Create tooldiscover Capability discovery PRD-173 Create toolcontent Content/Part abstraction PRD-174 Create tooltask Task lifecycle PRD-175 Create toolstream Streaming/updates PRD-176 Create toolsession Session management PRD-177 Create toolelicit User input elicitation PRD-178 Create toolresource MCP Resources PRD-179 Create toolprompt MCP Prompts"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-8-integration","title":"Phase 8: Integration","text":"PRD Title Description PRD-180 Update metatools-mcp Use consolidated repos PRD-181 Update ai-tools-stack Version matrix, docs PRD-182 Documentation Site MkDocs update"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#phase-9-cleanup","title":"Phase 9: Cleanup","text":"PRD Title Description PRD-190 Archive Old Repos Archive 13 standalone repos PRD-191 Update Submodules New submodule structure PRD-192 Validation Smoke tests, final checks"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#execution-order","title":"Execution Order","text":"<pre><code>gantt\n    title ApertureStack Consolidation Timeline\n    dateFormat  YYYY-MM-DD\n\n    section Phase 0\n    Planning &amp; Docs       :p0, 2026-02-01, 2d\n\n    section Phase 1\n    Infrastructure        :p1, after p0, 3d\n\n    section Phase 2\n    Foundation Layer      :p2, after p1, 3d\n\n    section Phase 3-4\n    Discovery Layer       :p3, after p2, 4d\n    Execution Layer       :p4, after p2, 4d\n\n    section Phase 5-6\n    Composition Layer     :p5, after p3 p4, 2d\n    Operations Layer      :p6, after p2, 5d\n\n    section Phase 7\n    Protocol Layer        :p7, after p2 p4 p6, 10d\n\n    section Phase 8\n    Integration           :p8, after p5 p6 p7, 3d\n\n    section Phase 9\n    Cleanup               :p9, after p8, 2d</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#repository-structure","title":"Repository Structure","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#standard-layout-all-consolidated-repos","title":"Standard Layout (All Consolidated Repos)","text":"<pre><code>repo-name/\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u251c\u2500\u2500 ci.yml              # Test all subpackages\n\u2502       \u251c\u2500\u2500 lint-security.yml   # Lint + security scan\n\u2502       \u251c\u2500\u2500 commitlint.yml      # Conventional commits\n\u2502       \u2514\u2500\u2500 release-please.yml  # Multi-package releases\n\u251c\u2500\u2500 subpkg1/\n\u2502   \u251c\u2500\u2500 doc.go\n\u2502   \u251c\u2500\u2500 types.go\n\u2502   \u251c\u2500\u2500 implementation.go\n\u2502   \u2514\u2500\u2500 implementation_test.go\n\u251c\u2500\u2500 subpkg2/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 design-notes.md\n\u2502   \u2514\u2500\u2500 user-journey.md\n\u251c\u2500\u2500 examples/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 go.sum\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 LICENSE\n\u2514\u2500\u2500 release-please-config.json\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#go-module-structure","title":"Go Module Structure","text":"<p>Each consolidated repo uses a single go.mod with subpackages:</p> <pre><code>// go.mod for toolfoundation\nmodule github.com/ApertureStack/toolfoundation\n\ngo 1.24\n\nrequire (\n    github.com/modelcontextprotocol/go-sdk v1.2.0\n)\n</code></pre> <p>Import paths: <pre><code>import (\n    \"github.com/ApertureStack/toolfoundation/model\"\n    \"github.com/ApertureStack/toolfoundation/adapter\"\n    \"github.com/ApertureStack/toolfoundation/version\"\n)\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#cicd-strategy","title":"CI/CD Strategy","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#workflow-templates","title":"Workflow Templates","text":"<p>Create reusable workflows in <code>.github/workflows/</code>:</p> <p>ci.yml: <pre><code>name: CI\n\non:\n  push:\n    branches: [\"main\"]\n    paths-ignore: [\"**.md\", \"docs/**\"]\n  pull_request:\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        go: [\"1.24\"]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version: ${{ matrix.go }}\n      - name: Test all packages\n        run: go test -race -coverprofile=coverage.out ./...\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n</code></pre></p> <p>lint-security.yml: <pre><code>name: Lint &amp; Security\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n      - uses: golangci/golangci-lint-action@v6\n        with:\n          version: latest\n\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: securego/gosec@master\n        with:\n          args: ./...\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#release-strategy","title":"Release Strategy","text":"<p>Use release-please with multi-package support:</p> <p>release-please-config.json: <pre><code>{\n  \"$schema\": \"https://raw.githubusercontent.com/googleapis/release-please/main/schemas/config.json\",\n  \"release-type\": \"go\",\n  \"packages\": {\n    \".\": {}\n  },\n  \"changelog-sections\": [\n    {\"type\": \"feat\", \"section\": \"Features\"},\n    {\"type\": \"fix\", \"section\": \"Bug Fixes\"},\n    {\"type\": \"perf\", \"section\": \"Performance\"},\n    {\"type\": \"refactor\", \"section\": \"Refactoring\"}\n  ]\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#github-secrets-required","title":"GitHub Secrets Required","text":"Secret Purpose Scope <code>CODECOV_TOKEN</code> Coverage upload Org-level <code>RELEASE_PLEASE_TOKEN</code> Release automation Org-level <code>GOPRIVATE</code> Private module access Org-level"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#migration-checklist-template","title":"Migration Checklist Template","text":"<p>For each migration PRD:</p> <ul> <li>[ ] Create target directory structure</li> <li>[ ] Copy source files preserving git history (<code>git filter-repo</code>)</li> <li>[ ] Update import paths</li> <li>[ ] Update go.mod dependencies</li> <li>[ ] Update tests</li> <li>[ ] Run full test suite</li> <li>[ ] Update documentation</li> <li>[ ] Create PR</li> <li>[ ] Merge and tag</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#risk-mitigation","title":"Risk Mitigation","text":"Risk Mitigation Breaking imports No backward compat (per requirements) Lost git history Use <code>git subtree</code> or <code>git filter-repo</code> CI failures Test templates before bulk migration Dependency cycles Strict layer boundaries Scope creep Stick to migration, defer improvements"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#success-criteria","title":"Success Criteria","text":"<ul> <li>[ ] All 6 consolidated repos created and tested</li> <li>[ ] All existing functionality preserved</li> <li>[ ] CI/CD working for all repos</li> <li>[ ] Documentation updated</li> <li>[ ] metatools-mcp using consolidated repos</li> <li>[ ] Old repos archived</li> <li>[ ] ApertureStack submodules updated</li> <li>[ ] Smoke tests passing</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/CONSOLIDATION-MASTER-PLAN/#references","title":"References","text":"<ul> <li>LIBRARY-CATEGORIZATION.md - Full library inventory</li> <li>MULTI-PROTOCOL-TRANSPORT.md - Protocol layer design</li> <li>EXTRACTION-ANALYSIS.md - metatools-mcp extraction</li> <li>MCP-FEATURES-ANALYSIS.md - MCP protocol features</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-109-remediation/","title":"PRD-100\u2013109 Remediation Plan","text":"<p>Date: 2026-01-31 Owner: Jon W. Raymond Scope: PRD-100, PRD-101, PRD-102</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-109-remediation/#objective","title":"Objective","text":"<p>Close the remaining planning/documentation gaps in Phase 0 by: 1. Delivering the missing architecture diagrams (Mermaid). 2. Publishing the JSON schema definitions specified in PRD-102. 3. Updating plan status to reflect completion.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-109-remediation/#deliverables","title":"Deliverables","text":"Item Location Status Layer architecture diagram <code>docs/diagrams/layer-architecture.md</code> Planned Repository map diagram <code>docs/diagrams/repository-map.md</code> Planned Dependency graph <code>docs/diagrams/dependency-graph.md</code> Planned Data flow diagram <code>docs/diagrams/data-flow.md</code> Planned Protocol adapters diagram <code>docs/diagrams/protocol-adapters.md</code> Planned Tool schema <code>schemas/tool.schema.json</code> Planned Toolset schema <code>schemas/toolset.schema.json</code> Planned Execution schema <code>schemas/execution.schema.json</code> Planned Discovery schema <code>schemas/discovery.schema.json</code> Planned Config schema <code>schemas/config.schema.json</code> Planned Schema index <code>schemas/README.md</code> Planned Plan status update <code>docs/plans/README.md</code> Planned"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-109-remediation/#plan-of-record","title":"Plan of Record","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-109-remediation/#task-1-prd-101-diagrams","title":"Task 1 \u2014 PRD-101 Diagrams","text":"<ul> <li>Create the five Mermaid diagram markdown files under <code>docs/diagrams/</code>.</li> <li>Ensure diagrams reflect the consolidated repos and package layout.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-109-remediation/#task-2-prd-102-schemas","title":"Task 2 \u2014 PRD-102 Schemas","text":"<ul> <li>Create <code>schemas/</code> directory with JSON Schema files from PRD-102.</li> <li>Add <code>schemas/README.md</code> indexing the schema set.</li> <li>Validate JSON syntax locally (<code>python3 -m json.tool</code>).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-109-remediation/#task-3-update-plan-status","title":"Task 3 \u2014 Update Plan Status","text":"<ul> <li>Update <code>docs/plans/README.md</code> to mark PRD-100/101/102 as Done.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-109-remediation/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All diagram files exist and render in Mermaid.</li> <li>[ ] All schema files exist and are valid JSON.</li> <li>[ ] <code>schemas/README.md</code> references all schema files.</li> <li>[ ] <code>docs/plans/README.md</code> updated to reflect completion.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-109-remediation/#execution-notes","title":"Execution Notes","text":"<ul> <li>No code paths changed; documentation-only changes.</li> <li>Follows existing PRD definitions verbatim unless noted.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/","title":"PRD-100: Master Consolidation Plan","text":"<p>Phase: 0 - Planning &amp; Documentation Priority: Critical Effort: 4 hours Dependencies: None</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#objective","title":"Objective","text":"<p>Document the complete consolidation strategy, serving as the authoritative reference for all subsequent PRDs.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#deliverables","title":"Deliverables","text":"Deliverable Location Description Master Plan <code>docs/plans/CONSOLIDATION-MASTER-PLAN.md</code> Executive summary, phase overview, success criteria Order of Operations <code>docs/plans/PRD-ORDER-OF-OPERATIONS.md</code> Sequential execution order for all 41 PRDs This PRD <code>docs/plans/PRD-100-master-plan.md</code> Self-referential documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#task-1-create-master-plan-document","title":"Task 1: Create Master Plan Document","text":"<p>File: <code>docs/plans/CONSOLIDATION-MASTER-PLAN.md</code></p> <p>Content Requirements: - Executive summary with current/target state diagrams - Phase overview table (9 phases, effort estimates) - PRD index by phase - Execution order Mermaid gantt chart - Repository structure standards - Go module structure with import path examples - CI/CD strategy overview - GitHub secrets requirements - Migration checklist template - Risk mitigation table - Success criteria checklist - References to supporting documents</p> <p>Verification: <pre><code># Confirm document exists and has required sections\ngrep -c \"## Executive Summary\\|## Phase Overview\\|## PRD Index\\|## Execution Order\\|## Repository Structure\\|## CI/CD Strategy\\|## Success Criteria\" docs/plans/CONSOLIDATION-MASTER-PLAN.md\n# Should return 7 (all sections present)\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#task-2-create-order-of-operations-document","title":"Task 2: Create Order of Operations Document","text":"<p>File: <code>docs/plans/PRD-ORDER-OF-OPERATIONS.md</code></p> <p>Content Requirements: - Critical path diagram (ASCII or Mermaid) - Execution order table by week (9 weeks) - Parallel execution opportunities - Checkpoint gates table - PRD file naming convention - Quick reference: What each PRD delivers - Total effort summary</p> <p>Verification: <pre><code># Confirm all 41 PRDs are listed\ngrep -c \"PRD-1[0-9][0-9]\" docs/plans/PRD-ORDER-OF-OPERATIONS.md\n# Should return count &gt;= 41\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#task-3-create-prd-template","title":"Task 3: Create PRD Template","text":"<p>File: <code>docs/plans/PRD-TEMPLATE.md</code></p> <p>Content: <pre><code># PRD-XXX: [Title]\n\n**Phase:** X - [Phase Name]\n**Priority:** [Critical/High/Medium/Low]\n**Effort:** Xh\n**Dependencies:** PRD-XXX, PRD-YYY\n\n---\n\n## Objective\n\n[One paragraph describing what this PRD accomplishes]\n\n---\n\n## Deliverables\n\n| Deliverable | Location | Description |\n|-------------|----------|-------------|\n\n---\n\n## Tasks\n\n### Task 1: [Task Title]\n\n**Description:**\n\n**Commands/Code:**\n\n**Verification:**\n\n---\n\n## Verification Checklist\n\n- [ ] Item 1\n- [ ] Item 2\n\n---\n\n## Acceptance Criteria\n\n1. Criterion 1\n2. Criterion 2\n\n---\n\n## Rollback Plan\n\n[Commands to undo changes if needed]\n\n---\n\n## Next Steps\n\n- PRD-XXX: [Next PRD title]\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#task-4-cross-reference-validation","title":"Task 4: Cross-Reference Validation","text":"<p>Ensure all documents reference each other correctly:</p> <pre><code># Check CONSOLIDATION-MASTER-PLAN.md references\ngrep -l \"PRD-ORDER-OF-OPERATIONS\\|LIBRARY-CATEGORIZATION\\|MULTI-PROTOCOL-TRANSPORT\" docs/plans/CONSOLIDATION-MASTER-PLAN.md\n\n# Check PRD-ORDER-OF-OPERATIONS.md format\nhead -50 docs/plans/PRD-ORDER-OF-OPERATIONS.md\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] CONSOLIDATION-MASTER-PLAN.md created with all sections</li> <li>[ ] PRD-ORDER-OF-OPERATIONS.md created with all 41 PRDs</li> <li>[ ] PRD-TEMPLATE.md created for consistency</li> <li>[ ] All documents use consistent formatting</li> <li>[ ] Cross-references validated</li> <li>[ ] Mermaid diagrams render correctly</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>Master plan provides complete overview of consolidation effort</li> <li>Order of operations enables sequential execution</li> <li>Template ensures PRD consistency</li> <li>All effort estimates sum to 236 hours</li> <li>Parallel execution opportunities documented</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#rollback-plan","title":"Rollback Plan","text":"<pre><code># Revert to previous state\ngit checkout HEAD~1 -- docs/plans/CONSOLIDATION-MASTER-PLAN.md\ngit checkout HEAD~1 -- docs/plans/PRD-ORDER-OF-OPERATIONS.md\ngit checkout HEAD~1 -- docs/plans/PRD-TEMPLATE.md\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-100-master-plan/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-101: Architecture Diagrams</li> <li>PRD-102: Schema Definitions</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/","title":"PRD-101: Architecture Diagrams","text":"<p>Phase: 0 - Planning &amp; Documentation Priority: High Effort: 4 hours Dependencies: PRD-100</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#objective","title":"Objective","text":"<p>Create comprehensive architecture diagrams using Mermaid syntax to visualize the consolidated ecosystem structure, layer dependencies, and data flows.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#deliverables","title":"Deliverables","text":"Deliverable Location Description Layer Architecture <code>docs/diagrams/layer-architecture.md</code> 8-tier layer diagram Repository Map <code>docs/diagrams/repository-map.md</code> 6 repos with packages Dependency Graph <code>docs/diagrams/dependency-graph.md</code> Inter-repo dependencies Data Flow <code>docs/diagrams/data-flow.md</code> Request/response flows Protocol Adapters <code>docs/diagrams/protocol-adapters.md</code> Multi-protocol support"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#task-1-create-layer-architecture-diagram","title":"Task 1: Create Layer Architecture Diagram","text":"<p>File: <code>docs/diagrams/layer-architecture.md</code></p> <pre><code># Layer Architecture\n\n## Overview\n\nThe ApertureStack ecosystem is organized into 8 distinct tiers, each with clear responsibilities and dependencies.\n\n## Diagram\n\n\\`\\`\\`mermaid\ngraph TB\n    subgraph \"Tier 8: Application\"\n        metatools-mcp[\"metatools-mcp&lt;br/&gt;(MCP Server)\"]\n    end\n\n    subgraph \"Tier 7: Protocol\"\n        toolprotocol[\"toolprotocol\"]\n        subgraph \"toolprotocol packages\"\n            transport[\"transport\"]\n            wire[\"wire\"]\n            discover[\"discover\"]\n            content[\"content\"]\n            task[\"task\"]\n            stream[\"stream\"]\n            session[\"session\"]\n            elicit[\"elicit\"]\n            resource[\"resource\"]\n            prompt[\"prompt\"]\n        end\n    end\n\n    subgraph \"Tier 6: Operations\"\n        toolops[\"toolops\"]\n        subgraph \"toolops packages\"\n            observe[\"observe\"]\n            cache[\"cache\"]\n            resilience[\"resilience\"]\n            health[\"health\"]\n            auth[\"auth\"]\n        end\n    end\n\n    subgraph \"Tier 5: Composition\"\n        toolcompose[\"toolcompose\"]\n        subgraph \"toolcompose packages\"\n            set[\"set\"]\n            skill[\"skill\"]\n        end\n    end\n\n    subgraph \"Tier 4: Execution\"\n        toolexec[\"toolexec\"]\n        subgraph \"toolexec packages\"\n            run[\"run\"]\n            runtime[\"runtime\"]\n            code[\"code\"]\n            backend[\"backend\"]\n        end\n    end\n\n    subgraph \"Tier 3: Discovery\"\n        tooldiscovery[\"tooldiscovery\"]\n        subgraph \"tooldiscovery packages\"\n            index[\"index\"]\n            search[\"search\"]\n            semantic[\"semantic\"]\n            docs[\"docs\"]\n        end\n    end\n\n    subgraph \"Tier 2: Foundation\"\n        toolfoundation[\"toolfoundation\"]\n        subgraph \"toolfoundation packages\"\n            model[\"model\"]\n            adapter[\"adapter\"]\n            version[\"version\"]\n        end\n    end\n\n    subgraph \"Tier 1: External\"\n        mcp-sdk[\"MCP Go SDK\"]\n    end\n\n    metatools-mcp --&gt; toolprotocol\n    metatools-mcp --&gt; toolops\n    metatools-mcp --&gt; toolcompose\n    metatools-mcp --&gt; toolexec\n    metatools-mcp --&gt; tooldiscovery\n\n    toolprotocol --&gt; toolfoundation\n    toolops --&gt; toolfoundation\n    toolcompose --&gt; toolexec\n    toolcompose --&gt; tooldiscovery\n    toolexec --&gt; toolfoundation\n    tooldiscovery --&gt; toolfoundation\n    toolfoundation --&gt; mcp-sdk\n\\`\\`\\`\n\n## Layer Descriptions\n\n| Tier | Repository | Purpose |\n|------|------------|---------|\n| 8 | metatools-mcp | MCP server exposing metatools |\n| 7 | toolprotocol | Multi-protocol transport and wire adapters |\n| 6 | toolops | Cross-cutting operational concerns |\n| 5 | toolcompose | Tool composition and agent skills |\n| 4 | toolexec | Tool execution and runtime |\n| 3 | tooldiscovery | Tool registry and search |\n| 2 | toolfoundation | Core schemas and adapters |\n| 1 | (external) | MCP Go SDK |\n\\`\\`\\`\n\n### Task 2: Create Repository Map\n\n**File:** `docs/diagrams/repository-map.md`\n\n```markdown\n# Repository Map\n\n## Consolidated Structure\n\n\\`\\`\\`mermaid\ngraph LR\n    subgraph \"toolfoundation\"\n        tf-model[\"model/\"]\n        tf-adapter[\"adapter/\"]\n        tf-version[\"version/\"]\n    end\n\n    subgraph \"tooldiscovery\"\n        td-index[\"index/\"]\n        td-search[\"search/\"]\n        td-semantic[\"semantic/\"]\n        td-docs[\"docs/\"]\n    end\n\n    subgraph \"toolexec\"\n        te-run[\"run/\"]\n        te-runtime[\"runtime/\"]\n        te-code[\"code/\"]\n        te-backend[\"backend/\"]\n    end\n\n    subgraph \"toolcompose\"\n        tc-set[\"set/\"]\n        tc-skill[\"skill/\"]\n    end\n\n    subgraph \"toolops\"\n        to-observe[\"observe/\"]\n        to-cache[\"cache/\"]\n        to-resilience[\"resilience/\"]\n        to-health[\"health/\"]\n        to-auth[\"auth/\"]\n    end\n\n    subgraph \"toolprotocol\"\n        tp-transport[\"transport/\"]\n        tp-wire[\"wire/\"]\n        tp-discover[\"discover/\"]\n        tp-content[\"content/\"]\n        tp-task[\"task/\"]\n        tp-stream[\"stream/\"]\n        tp-session[\"session/\"]\n        tp-elicit[\"elicit/\"]\n        tp-resource[\"resource/\"]\n        tp-prompt[\"prompt/\"]\n    end\n\\`\\`\\`\n\n## Package Counts\n\n| Repository | Packages | Lines (est.) |\n|------------|----------|--------------|\n| toolfoundation | 3 | ~8,000 |\n| tooldiscovery | 4 | ~10,000 |\n| toolexec | 4 | ~15,000 |\n| toolcompose | 2 | ~5,000 |\n| toolops | 5 | ~12,000 |\n| toolprotocol | 10 | ~20,000 |\n| **Total** | **28** | **~70,000** |\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#task-3-create-dependency-graph","title":"Task 3: Create Dependency Graph","text":"<p>File: <code>docs/diagrams/dependency-graph.md</code></p> <pre><code># Dependency Graph\n\n## Inter-Repository Dependencies\n\n\\`\\`\\`mermaid\ngraph TD\n    metatools-mcp --&gt; toolprotocol\n    metatools-mcp --&gt; toolops\n    metatools-mcp --&gt; toolcompose\n    metatools-mcp --&gt; toolexec\n    metatools-mcp --&gt; tooldiscovery\n    metatools-mcp --&gt; toolfoundation\n\n    toolprotocol --&gt; toolfoundation\n    toolprotocol --&gt; toolops\n\n    toolops --&gt; toolfoundation\n\n    toolcompose --&gt; toolexec\n    toolcompose --&gt; tooldiscovery\n    toolcompose --&gt; toolfoundation\n\n    toolexec --&gt; toolfoundation\n\n    tooldiscovery --&gt; toolfoundation\n\n    toolfoundation --&gt; mcp-sdk[\"MCP Go SDK\"]\n\\`\\`\\`\n\n## Dependency Matrix\n\n|  | foundation | discovery | exec | compose | ops | protocol |\n|--|------------|-----------|------|---------|-----|----------|\n| **foundation** | - | | | | | |\n| **discovery** | \u2713 | - | | | | |\n| **exec** | \u2713 | | - | | | |\n| **compose** | \u2713 | \u2713 | \u2713 | - | | |\n| **ops** | \u2713 | | | | - | |\n| **protocol** | \u2713 | | | | \u2713 | - |\n| **metatools-mcp** | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 |\n\n## Build Order\n\nBased on dependencies, build order is:\n1. toolfoundation (no internal deps)\n2. tooldiscovery, toolexec, toolops (parallel, depend on foundation)\n3. toolcompose (depends on discovery + exec)\n4. toolprotocol (depends on foundation + ops)\n5. metatools-mcp (depends on all)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#task-4-create-data-flow-diagram","title":"Task 4: Create Data Flow Diagram","text":"<p>File: <code>docs/diagrams/data-flow.md</code></p> <pre><code># Data Flow\n\n## Tool Execution Flow\n\n\\`\\`\\`mermaid\nsequenceDiagram\n    participant Client\n    participant Transport as toolprotocol/transport\n    participant Wire as toolprotocol/wire\n    participant Auth as toolops/auth\n    participant Cache as toolops/cache\n    participant Exec as toolexec/run\n    participant Runtime as toolexec/runtime\n\n    Client-&gt;&gt;Transport: HTTP/gRPC/WebSocket Request\n    Transport-&gt;&gt;Wire: Decode Protocol (MCP/A2A/ACP)\n    Wire-&gt;&gt;Auth: Authenticate Request\n    Auth-&gt;&gt;Cache: Check Cache\n\n    alt Cache Hit\n        Cache--&gt;&gt;Wire: Cached Result\n    else Cache Miss\n        Cache-&gt;&gt;Exec: Execute Tool\n        Exec-&gt;&gt;Runtime: Sandbox Execution\n        Runtime--&gt;&gt;Exec: Result\n        Exec-&gt;&gt;Cache: Store Result\n        Cache--&gt;&gt;Wire: Fresh Result\n    end\n\n    Wire-&gt;&gt;Transport: Encode Response\n    Transport--&gt;&gt;Client: Response\n\\`\\`\\`\n\n## Tool Discovery Flow\n\n\\`\\`\\`mermaid\nsequenceDiagram\n    participant Client\n    participant Index as tooldiscovery/index\n    participant Search as tooldiscovery/search\n    participant Semantic as tooldiscovery/semantic\n    participant Docs as tooldiscovery/docs\n\n    Client-&gt;&gt;Index: List/Search Tools\n    Index-&gt;&gt;Search: BM25 Search\n\n    opt Semantic Search Enabled\n        Search-&gt;&gt;Semantic: Vector Search\n        Semantic--&gt;&gt;Search: Semantic Results\n    end\n\n    Search--&gt;&gt;Index: Ranked Results\n    Index-&gt;&gt;Docs: Get Documentation\n    Docs--&gt;&gt;Index: Tool Docs\n    Index--&gt;&gt;Client: Tools with Docs\n\\`\\`\\`\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#task-5-create-protocol-adapters-diagram","title":"Task 5: Create Protocol Adapters Diagram","text":"<p>File: <code>docs/diagrams/protocol-adapters.md</code></p> <pre><code># Protocol Adapters\n\n## Multi-Protocol Architecture\n\n\\`\\`\\`mermaid\ngraph TB\n    subgraph \"Clients\"\n        mcp-client[\"MCP Client\"]\n        a2a-client[\"A2A Agent\"]\n        acp-client[\"ACP Client\"]\n        http-client[\"HTTP Client\"]\n    end\n\n    subgraph \"Transport Layer\"\n        stdio[\"Stdio\"]\n        sse[\"SSE\"]\n        ws[\"WebSocket\"]\n        grpc[\"gRPC\"]\n        http[\"HTTP\"]\n    end\n\n    subgraph \"Wire Adapters\"\n        mcp-wire[\"MCP Wire\"]\n        a2a-wire[\"A2A Wire\"]\n        acp-wire[\"ACP Wire\"]\n    end\n\n    subgraph \"Canonical Layer\"\n        canonical[\"Canonical Tool Interface\"]\n    end\n\n    mcp-client --&gt; stdio\n    mcp-client --&gt; sse\n    a2a-client --&gt; grpc\n    acp-client --&gt; http\n    http-client --&gt; http\n\n    stdio --&gt; mcp-wire\n    sse --&gt; mcp-wire\n    grpc --&gt; a2a-wire\n    http --&gt; acp-wire\n\n    mcp-wire --&gt; canonical\n    a2a-wire --&gt; canonical\n    acp-wire --&gt; canonical\n\\`\\`\\`\n\n## Protocol Feature Matrix\n\n| Feature | MCP | A2A | ACP |\n|---------|-----|-----|-----|\n| Tool Discovery | \u2713 | \u2713 | \u2713 |\n| Tool Execution | \u2713 | \u2713 | \u2713 |\n| Streaming | \u2713 | \u2713 | \u2713 |\n| Resources | \u2713 | - | - |\n| Prompts | \u2713 | - | - |\n| Sessions | - | \u2713 | \u2713 |\n| Tasks | - | \u2713 | \u2713 |\n| Elicitation | \u2713 | - | - |\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All 5 diagram files created</li> <li>[ ] Mermaid syntax validates (no errors)</li> <li>[ ] Diagrams render in GitHub markdown preview</li> <li>[ ] All 6 repositories represented</li> <li>[ ] All 28 packages shown</li> <li>[ ] Dependency arrows are accurate</li> <li>[ ] Protocol adapters show all 3 protocols</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>Diagrams provide clear visual understanding of architecture</li> <li>All relationships between components are accurate</li> <li>Diagrams can be embedded in documentation</li> <li>Mermaid syntax is valid and renders correctly</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#rollback-plan","title":"Rollback Plan","text":"<pre><code># Remove diagram files\nrm -rf docs/diagrams/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-101-architecture-diagrams/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-102: Schema Definitions</li> <li>PRD-110: Repository Creation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/","title":"PRD-102: Schema Definitions","text":"<p>Phase: 0 - Planning &amp; Documentation Priority: High Effort: 4 hours Dependencies: PRD-100</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#objective","title":"Objective","text":"<p>Define JSON Schema specifications for all core data types used across the consolidated ecosystem, ensuring type safety and validation consistency.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#deliverables","title":"Deliverables","text":"Deliverable Location Description Tool Schema <code>schemas/tool.schema.json</code> Canonical tool definition Toolset Schema <code>schemas/toolset.schema.json</code> Tool collection schema Execution Schema <code>schemas/execution.schema.json</code> Tool execution request/result Discovery Schema <code>schemas/discovery.schema.json</code> Tool discovery structures Config Schema <code>schemas/config.schema.json</code> Configuration file schema"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#task-1-create-tool-schema","title":"Task 1: Create Tool Schema","text":"<p>File: <code>schemas/tool.schema.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://aperturestack.dev/schemas/tool.schema.json\",\n  \"title\": \"Tool\",\n  \"description\": \"Canonical tool definition for ApertureStack\",\n  \"type\": \"object\",\n  \"required\": [\"id\", \"name\", \"description\"],\n  \"properties\": {\n    \"id\": {\n      \"type\": \"string\",\n      \"pattern\": \"^[a-z][a-z0-9_-]*$\",\n      \"description\": \"Unique tool identifier\"\n    },\n    \"name\": {\n      \"type\": \"string\",\n      \"minLength\": 1,\n      \"maxLength\": 100,\n      \"description\": \"Human-readable tool name\"\n    },\n    \"description\": {\n      \"type\": \"string\",\n      \"minLength\": 1,\n      \"maxLength\": 1000,\n      \"description\": \"Tool description for discovery\"\n    },\n    \"version\": {\n      \"type\": \"string\",\n      \"pattern\": \"^v?\\\\d+\\\\.\\\\d+\\\\.\\\\d+(-[a-zA-Z0-9.]+)?$\",\n      \"description\": \"Semantic version\"\n    },\n    \"namespace\": {\n      \"type\": \"string\",\n      \"pattern\": \"^[a-z][a-z0-9_-]*$\",\n      \"description\": \"Tool namespace for grouping\"\n    },\n    \"inputSchema\": {\n      \"$ref\": \"https://json-schema.org/draft/2020-12/schema\",\n      \"description\": \"JSON Schema for tool input\"\n    },\n    \"outputSchema\": {\n      \"$ref\": \"https://json-schema.org/draft/2020-12/schema\",\n      \"description\": \"JSON Schema for tool output\"\n    },\n    \"metadata\": {\n      \"type\": \"object\",\n      \"additionalProperties\": true,\n      \"description\": \"Arbitrary metadata\"\n    },\n    \"tags\": {\n      \"type\": \"array\",\n      \"items\": {\"type\": \"string\"},\n      \"description\": \"Searchable tags\"\n    },\n    \"capabilities\": {\n      \"$ref\": \"#/$defs/Capabilities\"\n    }\n  },\n  \"$defs\": {\n    \"Capabilities\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"streaming\": {\"type\": \"boolean\", \"default\": false},\n        \"batch\": {\"type\": \"boolean\", \"default\": false},\n        \"async\": {\"type\": \"boolean\", \"default\": false},\n        \"cacheable\": {\"type\": \"boolean\", \"default\": true},\n        \"idempotent\": {\"type\": \"boolean\", \"default\": false}\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#task-2-create-toolset-schema","title":"Task 2: Create Toolset Schema","text":"<p>File: <code>schemas/toolset.schema.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://aperturestack.dev/schemas/toolset.schema.json\",\n  \"title\": \"Toolset\",\n  \"description\": \"Collection of tools with shared configuration\",\n  \"type\": \"object\",\n  \"required\": [\"id\", \"name\", \"tools\"],\n  \"properties\": {\n    \"id\": {\n      \"type\": \"string\",\n      \"pattern\": \"^[a-z][a-z0-9_-]*$\"\n    },\n    \"name\": {\n      \"type\": \"string\",\n      \"minLength\": 1,\n      \"maxLength\": 100\n    },\n    \"description\": {\n      \"type\": \"string\",\n      \"maxLength\": 1000\n    },\n    \"version\": {\n      \"type\": \"string\",\n      \"pattern\": \"^v?\\\\d+\\\\.\\\\d+\\\\.\\\\d+(-[a-zA-Z0-9.]+)?$\"\n    },\n    \"tools\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"oneOf\": [\n          {\"type\": \"string\", \"description\": \"Tool ID reference\"},\n          {\"$ref\": \"tool.schema.json\"}\n        ]\n      },\n      \"minItems\": 1\n    },\n    \"config\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"timeout\": {\n          \"type\": \"string\",\n          \"pattern\": \"^\\\\d+[smh]$\",\n          \"description\": \"Execution timeout (e.g., '30s', '5m')\"\n        },\n        \"retries\": {\n          \"type\": \"integer\",\n          \"minimum\": 0,\n          \"maximum\": 10\n        },\n        \"cachePolicy\": {\n          \"type\": \"string\",\n          \"enum\": [\"none\", \"default\", \"aggressive\"]\n        }\n      }\n    },\n    \"permissions\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\",\n        \"enum\": [\"read\", \"write\", \"execute\", \"admin\"]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#task-3-create-execution-schema","title":"Task 3: Create Execution Schema","text":"<p>File: <code>schemas/execution.schema.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://aperturestack.dev/schemas/execution.schema.json\",\n  \"title\": \"Execution\",\n  \"description\": \"Tool execution request and result schemas\",\n  \"$defs\": {\n    \"ExecutionRequest\": {\n      \"type\": \"object\",\n      \"required\": [\"toolId\", \"input\"],\n      \"properties\": {\n        \"toolId\": {\n          \"type\": \"string\",\n          \"description\": \"Tool to execute\"\n        },\n        \"input\": {\n          \"type\": \"object\",\n          \"description\": \"Tool input arguments\"\n        },\n        \"context\": {\n          \"$ref\": \"#/$defs/ExecutionContext\"\n        },\n        \"options\": {\n          \"$ref\": \"#/$defs/ExecutionOptions\"\n        }\n      }\n    },\n    \"ExecutionContext\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"requestId\": {\"type\": \"string\", \"format\": \"uuid\"},\n        \"traceId\": {\"type\": \"string\"},\n        \"spanId\": {\"type\": \"string\"},\n        \"userId\": {\"type\": \"string\"},\n        \"tenantId\": {\"type\": \"string\"},\n        \"metadata\": {\"type\": \"object\"}\n      }\n    },\n    \"ExecutionOptions\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"timeout\": {\"type\": \"string\", \"pattern\": \"^\\\\d+[smh]$\"},\n        \"backend\": {\"type\": \"string\", \"enum\": [\"local\", \"docker\", \"wasm\", \"remote\"]},\n        \"sandbox\": {\"type\": \"string\", \"enum\": [\"none\", \"basic\", \"strict\"]},\n        \"stream\": {\"type\": \"boolean\", \"default\": false},\n        \"cache\": {\"type\": \"boolean\", \"default\": true}\n      }\n    },\n    \"ExecutionResult\": {\n      \"type\": \"object\",\n      \"required\": [\"status\"],\n      \"properties\": {\n        \"status\": {\n          \"type\": \"string\",\n          \"enum\": [\"success\", \"error\", \"timeout\", \"cancelled\"]\n        },\n        \"output\": {\n          \"description\": \"Tool output on success\"\n        },\n        \"error\": {\n          \"$ref\": \"#/$defs/ExecutionError\"\n        },\n        \"metrics\": {\n          \"$ref\": \"#/$defs/ExecutionMetrics\"\n        }\n      }\n    },\n    \"ExecutionError\": {\n      \"type\": \"object\",\n      \"required\": [\"code\", \"message\"],\n      \"properties\": {\n        \"code\": {\"type\": \"string\"},\n        \"message\": {\"type\": \"string\"},\n        \"details\": {\"type\": \"object\"},\n        \"retryable\": {\"type\": \"boolean\", \"default\": false}\n      }\n    },\n    \"ExecutionMetrics\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"startTime\": {\"type\": \"string\", \"format\": \"date-time\"},\n        \"endTime\": {\"type\": \"string\", \"format\": \"date-time\"},\n        \"durationMs\": {\"type\": \"integer\", \"minimum\": 0},\n        \"backend\": {\"type\": \"string\"},\n        \"cached\": {\"type\": \"boolean\"}\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#task-4-create-discovery-schema","title":"Task 4: Create Discovery Schema","text":"<p>File: <code>schemas/discovery.schema.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://aperturestack.dev/schemas/discovery.schema.json\",\n  \"title\": \"Discovery\",\n  \"description\": \"Tool discovery and search schemas\",\n  \"$defs\": {\n    \"SearchQuery\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"query\": {\n          \"type\": \"string\",\n          \"description\": \"Search query text\"\n        },\n        \"filters\": {\n          \"$ref\": \"#/$defs/SearchFilters\"\n        },\n        \"options\": {\n          \"$ref\": \"#/$defs/SearchOptions\"\n        }\n      }\n    },\n    \"SearchFilters\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"namespace\": {\"type\": \"string\"},\n        \"tags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n        \"capabilities\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n        \"minVersion\": {\"type\": \"string\"},\n        \"maxVersion\": {\"type\": \"string\"}\n      }\n    },\n    \"SearchOptions\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"limit\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 100, \"default\": 10},\n        \"offset\": {\"type\": \"integer\", \"minimum\": 0, \"default\": 0},\n        \"sortBy\": {\"type\": \"string\", \"enum\": [\"relevance\", \"name\", \"updated\"]},\n        \"sortOrder\": {\"type\": \"string\", \"enum\": [\"asc\", \"desc\"]},\n        \"includeDeprecated\": {\"type\": \"boolean\", \"default\": false},\n        \"searchMode\": {\"type\": \"string\", \"enum\": [\"bm25\", \"semantic\", \"hybrid\"]}\n      }\n    },\n    \"SearchResult\": {\n      \"type\": \"object\",\n      \"required\": [\"tools\", \"total\"],\n      \"properties\": {\n        \"tools\": {\n          \"type\": \"array\",\n          \"items\": {\"$ref\": \"#/$defs/SearchHit\"}\n        },\n        \"total\": {\"type\": \"integer\", \"minimum\": 0},\n        \"hasMore\": {\"type\": \"boolean\"},\n        \"searchTime\": {\"type\": \"integer\", \"description\": \"Search time in milliseconds\"}\n      }\n    },\n    \"SearchHit\": {\n      \"type\": \"object\",\n      \"required\": [\"tool\", \"score\"],\n      \"properties\": {\n        \"tool\": {\"$ref\": \"tool.schema.json\"},\n        \"score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1},\n        \"highlights\": {\n          \"type\": \"object\",\n          \"additionalProperties\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#task-5-create-config-schema","title":"Task 5: Create Config Schema","text":"<p>File: <code>schemas/config.schema.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://aperturestack.dev/schemas/config.schema.json\",\n  \"title\": \"Config\",\n  \"description\": \"metatools-mcp configuration schema\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"server\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"transport\": {\n          \"type\": \"string\",\n          \"enum\": [\"stdio\", \"sse\", \"websocket\", \"grpc\"],\n          \"default\": \"stdio\"\n        },\n        \"host\": {\"type\": \"string\", \"default\": \"localhost\"},\n        \"port\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 65535, \"default\": 8080},\n        \"tls\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"enabled\": {\"type\": \"boolean\", \"default\": false},\n            \"certFile\": {\"type\": \"string\"},\n            \"keyFile\": {\"type\": \"string\"}\n          }\n        }\n      }\n    },\n    \"tools\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"directories\": {\n          \"type\": \"array\",\n          \"items\": {\"type\": \"string\"},\n          \"default\": [\"./tools\"]\n        },\n        \"providers\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"object\",\n            \"required\": [\"type\", \"url\"],\n            \"properties\": {\n              \"type\": {\"type\": \"string\", \"enum\": [\"http\", \"grpc\", \"mcp\"]},\n              \"url\": {\"type\": \"string\", \"format\": \"uri\"},\n              \"timeout\": {\"type\": \"string\", \"pattern\": \"^\\\\d+[smh]$\"}\n            }\n          }\n        }\n      }\n    },\n    \"execution\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"defaultBackend\": {\n          \"type\": \"string\",\n          \"enum\": [\"local\", \"docker\", \"wasm\", \"kubernetes\"],\n          \"default\": \"local\"\n        },\n        \"timeout\": {\"type\": \"string\", \"default\": \"30s\"},\n        \"maxConcurrent\": {\"type\": \"integer\", \"minimum\": 1, \"default\": 10}\n      }\n    },\n    \"cache\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"enabled\": {\"type\": \"boolean\", \"default\": true},\n        \"backend\": {\"type\": \"string\", \"enum\": [\"memory\", \"redis\", \"file\"]},\n        \"ttl\": {\"type\": \"string\", \"default\": \"5m\"},\n        \"maxSize\": {\"type\": \"string\", \"default\": \"100MB\"}\n      }\n    },\n    \"observability\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"tracing\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"enabled\": {\"type\": \"boolean\", \"default\": false},\n            \"exporter\": {\"type\": \"string\", \"enum\": [\"otlp\", \"jaeger\", \"zipkin\"]},\n            \"endpoint\": {\"type\": \"string\", \"format\": \"uri\"}\n          }\n        },\n        \"metrics\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"enabled\": {\"type\": \"boolean\", \"default\": true},\n            \"port\": {\"type\": \"integer\", \"default\": 9090}\n          }\n        },\n        \"logging\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"level\": {\"type\": \"string\", \"enum\": [\"debug\", \"info\", \"warn\", \"error\"]},\n            \"format\": {\"type\": \"string\", \"enum\": [\"json\", \"text\"]}\n          }\n        }\n      }\n    },\n    \"auth\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"enabled\": {\"type\": \"boolean\", \"default\": false},\n        \"provider\": {\"type\": \"string\", \"enum\": [\"jwt\", \"apikey\", \"oauth2\"]},\n        \"config\": {\"type\": \"object\"}\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#task-6-create-schema-index","title":"Task 6: Create Schema Index","text":"<p>File: <code>schemas/README.md</code></p> <pre><code># ApertureStack JSON Schemas\n\nThis directory contains JSON Schema definitions for all core data types in the ApertureStack ecosystem.\n\n## Schemas\n\n| Schema | Description | Go Package |\n|--------|-------------|------------|\n| [tool.schema.json](./tool.schema.json) | Canonical tool definition | `toolfoundation/model` |\n| [toolset.schema.json](./toolset.schema.json) | Tool collection | `toolcompose/set` |\n| [execution.schema.json](./execution.schema.json) | Execution request/result | `toolexec/run` |\n| [discovery.schema.json](./discovery.schema.json) | Search query/result | `tooldiscovery/search` |\n| [config.schema.json](./config.schema.json) | Configuration file | `metatools-mcp` |\n\n## Usage\n\n### Validation in Go\n\n```go\nimport \"github.com/xeipuuv/gojsonschema\"\n\nschemaLoader := gojsonschema.NewReferenceLoader(\"file:///path/to/tool.schema.json\")\ndocumentLoader := gojsonschema.NewGoLoader(myTool)\n\nresult, err := gojsonschema.Validate(schemaLoader, documentLoader)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#validation-in-typescript","title":"Validation in TypeScript","text":"<pre><code>import Ajv from \"ajv\";\nimport toolSchema from \"./tool.schema.json\";\n\nconst ajv = new Ajv();\nconst validate = ajv.compile(toolSchema);\nconst valid = validate(myTool);\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#schema-uris","title":"Schema URIs","text":"<p>All schemas are published at: - <code>https://aperturestack.dev/schemas/{name}.schema.json</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#versioning","title":"Versioning","text":"<p>Schemas follow semantic versioning. Breaking changes increment the major version and are published as new files (e.g., <code>tool.v2.schema.json</code>). <pre><code>---\n\n## Verification Checklist\n\n- [ ] All 5 schema files created\n- [ ] JSON syntax is valid\n- [ ] Schema `$id` URIs are consistent\n- [ ] Cross-references use correct paths\n- [ ] README documents all schemas\n- [ ] Go package mappings are accurate\n\n**Validation Commands:**\n```bash\n# Validate JSON syntax\nfor f in schemas/*.json; do\n  python3 -m json.tool \"$f\" &gt; /dev/null &amp;&amp; echo \"\u2713 $f\" || echo \"\u2717 $f\"\ndone\n\n# Validate schema structure (requires ajv-cli)\nnpx ajv validate -s schemas/tool.schema.json -d /dev/null --strict=false\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>All schemas are valid JSON Schema draft 2020-12</li> <li>Schemas accurately represent Go types</li> <li>Cross-references resolve correctly</li> <li>Documentation is complete</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#rollback-plan","title":"Rollback Plan","text":"<pre><code>rm -rf schemas/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-102-schema-definitions/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-110: Repository Creation</li> <li>PRD-120: Migrate toolmodel (implement schema validation)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-119-remediation/","title":"PRD-110\u2013119 Remediation Plan","text":"<p>Date: 2026-01-31 Owner: Jon W. Raymond Scope: PRD-110, PRD-111, PRD-112, PRD-113</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-119-remediation/#objective","title":"Objective","text":"<p>Close the Phase 1 infrastructure gaps by stabilizing repository setup, CI/CD workflows, org/repo settings, and release automation.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-119-remediation/#deliverables","title":"Deliverables","text":"Item Location Status Workflow templates <code>.github/workflow-templates/*</code> Done Dependency review workflow <code>.github/workflows/dependency-review.yml</code> (each repo) Done Release-please config updated <code>release-please-config.json</code> (each repo) Done Release-please manifest normalized <code>.release-please-manifest.json</code> Done Workflow permissions set Repo settings (GITHUB_TOKEN write) Done Branch protection applied main branch Done Repo settings standardized allow-squash/rebase, delete-branch Done Topics + descriptions set per-repo Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-119-remediation/#plan-of-record","title":"Plan of Record","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-119-remediation/#task-1-repo-baseline-prd-110","title":"Task 1 \u2014 Repo Baseline (PRD-110)","text":"<ul> <li>Verify all six repos exist and are public.</li> <li>Verify standard structure and workflows exist.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-119-remediation/#task-2-cicd-templates-prd-111","title":"Task 2 \u2014 CI/CD Templates (PRD-111)","text":"<ul> <li>Add <code>.github/workflow-templates/</code> in root with CI, lint, commitlint, release-please, dependency-review templates.</li> <li>Add dependency-review workflow to each consolidated repo.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-119-remediation/#task-3-github-orgrepo-config-prd-112","title":"Task 3 \u2014 GitHub Org/Repo Config (PRD-112)","text":"<ul> <li>Enable workflow permissions (GITHUB_TOKEN write).</li> <li>Apply branch protection (status checks + code owner review).</li> <li>Standardize repo settings (merge strategy, delete branch on merge).</li> <li>Set topics + descriptions.</li> <li>Enable security features (vulnerability alerts + automated fixes).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-119-remediation/#task-4-release-automation-prd-113","title":"Task 4 \u2014 Release Automation (PRD-113)","text":"<ul> <li>Update <code>release-please-config.json</code> to include component naming per repo.</li> <li>Normalize <code>.release-please-manifest.json</code> to <code>{\".\": \"0.0.0\"}</code>.</li> <li>Verify release-please workflow permissions enable PR creation.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-119-remediation/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All six repos exist and are public</li> <li>[x] Workflow templates created</li> <li>[x] Dependency review workflow present in each repo</li> <li>[x] Release-please config/manifest updated per repo</li> <li>[x] Workflow permissions set to write</li> <li>[x] Branch protection enabled</li> <li>[x] Repo settings + topics applied</li> <li>[x] Security alerts enabled</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-119-remediation/#notes","title":"Notes","text":"<ul> <li>Org name in examples is <code>ApertureStack</code>, but active repos are under <code>jonwraymond</code>. Commands will target <code>jonwraymond/*</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/","title":"PRD-110: Repository Creation","text":"<p>Phase: 1 - Infrastructure Setup Priority: Critical Effort: 8 hours Dependencies: PRD-100</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#objective","title":"Objective","text":"<p>Create 6 new consolidated repositories with standardized structure, ready for code migration.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#repositories-to-create","title":"Repositories to Create","text":"Repository GitHub URL Description toolfoundation github.com/ApertureStack/toolfoundation Canonical schema, protocol adapters, versioning tooldiscovery github.com/ApertureStack/tooldiscovery Registry, search, semantic, documentation toolexec github.com/ApertureStack/toolexec Execution pipeline, runtime, code orchestration toolcompose github.com/ApertureStack/toolcompose Toolsets, agent skills toolops github.com/ApertureStack/toolops Observability, caching, resilience, health, auth toolprotocol github.com/ApertureStack/toolprotocol Transport, wire adapters, protocol features"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#standard-repository-structure","title":"Standard Repository Structure","text":"<p>Each repository follows this exact structure:</p> <pre><code>{repo-name}/\n\u251c\u2500\u2500 .github/\n\u2502   \u251c\u2500\u2500 CODEOWNERS\n\u2502   \u251c\u2500\u2500 PULL_REQUEST_TEMPLATE.md\n\u2502   \u251c\u2500\u2500 ISSUE_TEMPLATE/\n\u2502   \u2502   \u251c\u2500\u2500 bug_report.md\n\u2502   \u2502   \u2514\u2500\u2500 feature_request.md\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u251c\u2500\u2500 ci.yml\n\u2502       \u251c\u2500\u2500 lint-security.yml\n\u2502       \u251c\u2500\u2500 commitlint.yml\n\u2502       \u2514\u2500\u2500 release-please.yml\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 design-notes.md\n\u2502   \u2514\u2500\u2500 user-journey.md\n\u251c\u2500\u2500 examples/\n\u2502   \u2514\u2500\u2500 .gitkeep\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .golangci.yml\n\u251c\u2500\u2500 commitlint.config.cjs\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 go.sum\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 release-please-config.json\n\u2514\u2500\u2500 .release-please-manifest.json\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#task-1-create-github-repositories","title":"Task 1: Create GitHub Repositories","text":"<p>Commands: <pre><code># Using GitHub CLI\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  gh repo create ApertureStack/$repo \\\n    --public \\\n    --description \"ApertureStack $repo - AI tool ecosystem\" \\\n    --license MIT \\\n    --clone\ndone\n</code></pre></p> <p>Verification: <pre><code>gh repo list ApertureStack --limit 20\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#task-2-initialize-repository-structure","title":"Task 2: Initialize Repository Structure","text":"<p>For each repository, create the standard structure:</p> <p>Script: <code>scripts/init-repo.sh</code> <pre><code>#!/bin/bash\nset -euo pipefail\n\nREPO_NAME=$1\nMODULE_PATH=\"github.com/ApertureStack/$REPO_NAME\"\n\ncd \"$REPO_NAME\"\n\n# Create directories\nmkdir -p .github/workflows .github/ISSUE_TEMPLATE docs examples\n\n# Create .gitignore\ncat &gt; .gitignore &lt;&lt; 'EOF'\n# Binaries\n*.exe\n*.exe~\n*.dll\n*.so\n*.dylib\n*.test\n*.out\n\n# Go\nvendor/\ngo.work\ngo.work.sum\n\n# IDE\n.idea/\n.vscode/\n*.swp\n*.swo\n\n# OS\n.DS_Store\nThumbs.db\n\n# Coverage\ncoverage.out\ncoverage.html\n\n# Build\ndist/\nbin/\nEOF\n\n# Create go.mod\ncat &gt; go.mod &lt;&lt; EOF\nmodule $MODULE_PATH\n\ngo 1.24\nEOF\n\n# Create LICENSE (MIT)\ncat &gt; LICENSE &lt;&lt; 'EOF'\nMIT License\n\nCopyright (c) 2026 ApertureStack\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\nEOF\n\n# Create README.md\ncat &gt; README.md &lt;&lt; EOF\n# $REPO_NAME\n\nPart of the [ApertureStack](https://github.com/ApertureStack) AI tool ecosystem.\n\n## Installation\n\n\\`\\`\\`bash\ngo get $MODULE_PATH\n\\`\\`\\`\n\n## Packages\n\n| Package | Description | Documentation |\n|---------|-------------|---------------|\n| TBD | TBD | [docs](./docs/) |\n\n## License\n\nMIT License - see [LICENSE](./LICENSE)\nEOF\n\n# Create CHANGELOG.md\ncat &gt; CHANGELOG.md &lt;&lt; 'EOF'\n# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [Unreleased]\n\n### Added\n- Initial repository structure\nEOF\n\n# Create .golangci.yml\ncat &gt; .golangci.yml &lt;&lt; 'EOF'\nrun:\n  timeout: 5m\n  modules-download-mode: readonly\n\nlinters:\n  enable:\n    - errcheck\n    - gosimple\n    - govet\n    - ineffassign\n    - staticcheck\n    - unused\n    - gofmt\n    - goimports\n    - misspell\n    - unconvert\n    - unparam\n\nlinters-settings:\n  goimports:\n    local-prefixes: github.com/ApertureStack\n\nissues:\n  exclude-use-default: false\n  max-issues-per-linter: 0\n  max-same-issues: 0\nEOF\n\n# Create commitlint.config.cjs\ncat &gt; commitlint.config.cjs &lt;&lt; 'EOF'\nmodule.exports = { extends: ['@commitlint/config-conventional'] };\nEOF\n\n# Create release-please-config.json\ncat &gt; release-please-config.json &lt;&lt; 'EOF'\n{\n  \"$schema\": \"https://raw.githubusercontent.com/googleapis/release-please/main/schemas/config.json\",\n  \"release-type\": \"go\",\n  \"packages\": {\n    \".\": {}\n  },\n  \"changelog-sections\": [\n    {\"type\": \"feat\", \"section\": \"Features\"},\n    {\"type\": \"fix\", \"section\": \"Bug Fixes\"},\n    {\"type\": \"perf\", \"section\": \"Performance Improvements\"},\n    {\"type\": \"refactor\", \"section\": \"Code Refactoring\"},\n    {\"type\": \"docs\", \"section\": \"Documentation\"},\n    {\"type\": \"chore\", \"section\": \"Miscellaneous\"}\n  ]\n}\nEOF\n\n# Create .release-please-manifest.json\necho '{\".\":\" 0.0.0\"}' &gt; .release-please-manifest.json\n\n# Create GitHub templates\ncat &gt; .github/CODEOWNERS &lt;&lt; 'EOF'\n* @jonwraymond\nEOF\n\ncat &gt; .github/PULL_REQUEST_TEMPLATE.md &lt;&lt; 'EOF'\n## Description\n\n&lt;!-- Describe your changes --&gt;\n\n## Type of Change\n\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update\n\n## Checklist\n\n- [ ] Tests pass (`go test ./...`)\n- [ ] Linter passes (`golangci-lint run`)\n- [ ] Documentation updated\n- [ ] CHANGELOG.md updated (if applicable)\nEOF\n\ncat &gt; .github/ISSUE_TEMPLATE/bug_report.md &lt;&lt; 'EOF'\n---\nname: Bug Report\nabout: Report a bug\ntitle: '[BUG] '\nlabels: bug\n---\n\n## Description\n\n## Steps to Reproduce\n\n1.\n2.\n3.\n\n## Expected Behavior\n\n## Actual Behavior\n\n## Environment\n\n- Go version:\n- OS:\nEOF\n\ncat &gt; .github/ISSUE_TEMPLATE/feature_request.md &lt;&lt; 'EOF'\n---\nname: Feature Request\nabout: Suggest a feature\ntitle: '[FEATURE] '\nlabels: enhancement\n---\n\n## Description\n\n## Use Case\n\n## Proposed Solution\n\n## Alternatives Considered\nEOF\n\n# Create docs\ncat &gt; docs/index.md &lt;&lt; EOF\n# $REPO_NAME\n\nOverview documentation for $REPO_NAME.\n\n## Packages\n\nTBD\n\n## Getting Started\n\nTBD\nEOF\n\ncat &gt; docs/design-notes.md &lt;&lt; 'EOF'\n# Design Notes\n\n## Architecture Decisions\n\nTBD\n\n## Trade-offs\n\nTBD\nEOF\n\ncat &gt; docs/user-journey.md &lt;&lt; 'EOF'\n# User Journey\n\n## Installation\n\nTBD\n\n## Basic Usage\n\nTBD\n\n## Advanced Usage\n\nTBD\nEOF\n\n# Create examples placeholder\ntouch examples/.gitkeep\n\necho \"\u2705 Initialized $REPO_NAME\"\n</code></pre></p> <p>Execute: <pre><code>chmod +x scripts/init-repo.sh\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  ./scripts/init-repo.sh $repo\ndone\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#task-3-create-ci-workflows","title":"Task 3: Create CI Workflows","text":"<p>File: <code>.github/workflows/ci.yml</code> <pre><code>name: CI\n\non:\n  push:\n    branches: [\"main\"]\n    paths-ignore:\n      - \"**.md\"\n      - \"docs/**\"\n  pull_request:\n    paths-ignore:\n      - \"**.md\"\n      - \"docs/**\"\n\npermissions:\n  contents: read\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        go: [\"1.24\"]\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: ${{ matrix.go }}\n          cache: true\n\n      - name: Download dependencies\n        run: go mod download\n\n      - name: Verify dependencies\n        run: go mod verify\n\n      - name: Build\n        run: go build ./...\n\n      - name: Test\n        run: go test -race -coverprofile=coverage.out -covermode=atomic ./...\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          token: ${{ secrets.CODECOV_TOKEN }}\n          files: coverage.out\n          fail_ci_if_error: false\n</code></pre></p> <p>File: <code>.github/workflows/lint-security.yml</code> <pre><code>name: Lint &amp; Security\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n\npermissions:\n  contents: read\n  security-events: write\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n          cache: true\n\n      - name: golangci-lint\n        uses: golangci/golangci-lint-action@v6\n        with:\n          version: latest\n          args: --timeout=5m\n\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n\n      - name: Run gosec\n        uses: securego/gosec@master\n        with:\n          args: -fmt sarif -out gosec.sarif ./...\n\n      - name: Upload SARIF\n        uses: github/codeql-action/upload-sarif@v3\n        with:\n          sarif_file: gosec.sarif\n</code></pre></p> <p>File: <code>.github/workflows/commitlint.yml</code> <pre><code>name: Commitlint\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n\njobs:\n  commitlint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup Node\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"20\"\n\n      - name: Install commitlint\n        run: npm install -g @commitlint/cli @commitlint/config-conventional\n\n      - name: Lint commits\n        run: npx commitlint --from HEAD~1 --to HEAD --verbose\n</code></pre></p> <p>File: <code>.github/workflows/release-please.yml</code> <pre><code>name: Release Please\n\non:\n  push:\n    branches: [\"main\"]\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  release-please:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Release Please\n        uses: google-github-actions/release-please-action@v4\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          config-file: release-please-config.json\n          manifest-file: .release-please-manifest.json\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#task-4-push-initial-structure","title":"Task 4: Push Initial Structure","text":"<pre><code>for repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  cd $repo\n  git add -A\n  git commit -m \"feat: initial repository structure\n\n- Add standard directory layout\n- Add CI/CD workflows\n- Add documentation templates\n- Add release automation\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n  git push origin main\n  cd ..\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#task-5-add-as-submodules-to-aperturestack","title":"Task 5: Add as Submodules to ApertureStack","text":"<pre><code>cd /Users/jraymond/Documents/Projects/ApertureStack\n\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  git submodule add git@github.com:ApertureStack/$repo.git $repo\ndone\n\ngit add .gitmodules\ngit commit -m \"feat: add consolidated repository submodules\n\n- toolfoundation (model, adapter, version)\n- tooldiscovery (index, search, semantic, docs)\n- toolexec (run, runtime, code, backend)\n- toolcompose (set, skill)\n- toolops (observe, cache, resilience, health, auth)\n- toolprotocol (transport, wire, discover, content, task, stream, session, elicit, resource, prompt)\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All 6 repositories created on GitHub</li> <li>[ ] Each repo has correct structure</li> <li>[ ] Each repo has all 4 workflow files</li> <li>[ ] All workflows pass initial run</li> <li>[ ] Repos added as submodules to ApertureStack</li> <li>[ ] Git push succeeds for all repos</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>gh repo view ApertureStack/{toolfoundation,tooldiscovery,toolexec,toolcompose,toolops,toolprotocol}</code> succeeds</li> <li>Each repo has passing CI badge</li> <li>Release-please PR created on first push</li> <li>Submodules appear in ApertureStack root</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#rollback-plan","title":"Rollback Plan","text":"<pre><code># Delete repos if needed\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  gh repo delete ApertureStack/$repo --yes\ndone\n\n# Remove submodules\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  git submodule deinit -f $repo\n  git rm -f $repo\n  rm -rf .git/modules/$repo\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-110-repo-creation/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-111: CI/CD Templates (reusable workflows)</li> <li>PRD-112: GitHub Org Config (secrets)</li> <li>PRD-113: Release Automation (multi-package)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/","title":"PRD-111: CI/CD Templates","text":"<p>Phase: 1 - Infrastructure Setup Priority: High Effort: 4 hours Dependencies: PRD-110</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#objective","title":"Objective","text":"<p>Create reusable GitHub Actions workflow templates that will be used across all 6 consolidated repositories, ensuring consistent CI/CD practices.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#deliverables","title":"Deliverables","text":"Deliverable Location Description CI Template <code>.github/workflow-templates/ci.yml</code> Test, build, coverage Lint/Security <code>.github/workflow-templates/lint-security.yml</code> Linting + security scan Commitlint <code>.github/workflow-templates/commitlint.yml</code> Conventional commits Release Please <code>.github/workflow-templates/release-please.yml</code> Automated releases Dependency Review <code>.github/workflow-templates/dependency-review.yml</code> Dependency checks"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#task-1-create-workflow-templates-directory","title":"Task 1: Create Workflow Templates Directory","text":"<pre><code>mkdir -p .github/workflow-templates\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#task-2-ci-workflow-template","title":"Task 2: CI Workflow Template","text":"<p>File: <code>.github/workflow-templates/ci.yml</code></p> <pre><code># Template for ci.yml in all consolidated repos\n# Copy to .github/workflows/ci.yml\n\nname: CI\n\non:\n  push:\n    branches: [\"main\"]\n    paths-ignore:\n      - \"**.md\"\n      - \"docs/**\"\n      - \"examples/**\"\n  pull_request:\n    paths-ignore:\n      - \"**.md\"\n      - \"docs/**\"\n      - \"examples/**\"\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  GO_VERSION: \"1.24\"\n  GOPRIVATE: \"github.com/ApertureStack/*\"\n\njobs:\n  test:\n    name: Test\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        go: [\"1.23\", \"1.24\"]\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: ${{ matrix.go }}\n          cache: true\n\n      - name: Configure Git for private repos\n        run: |\n          git config --global url.\"https://${{ secrets.GH_TOKEN }}@github.com/\".insteadOf \"https://github.com/\"\n\n      - name: Download dependencies\n        run: go mod download\n\n      - name: Verify dependencies\n        run: go mod verify\n\n      - name: Build\n        run: go build -v ./...\n\n      - name: Test with coverage\n        run: go test -race -coverprofile=coverage.out -covermode=atomic -v ./...\n\n      - name: Upload coverage\n        if: matrix.go == '1.24'\n        uses: codecov/codecov-action@v4\n        with:\n          token: ${{ secrets.CODECOV_TOKEN }}\n          files: coverage.out\n          fail_ci_if_error: false\n          verbose: true\n\n  integration:\n    name: Integration Tests\n    runs-on: ubuntu-latest\n    needs: test\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: ${{ env.GO_VERSION }}\n          cache: true\n\n      - name: Run integration tests\n        run: go test -tags=integration -v ./...\n        env:\n          INTEGRATION_TEST: \"true\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#task-3-lint-security-workflow-template","title":"Task 3: Lint &amp; Security Workflow Template","text":"<p>File: <code>.github/workflow-templates/lint-security.yml</code></p> <pre><code># Template for lint-security.yml in all consolidated repos\n# Copy to .github/workflows/lint-security.yml\n\nname: Lint &amp; Security\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n\npermissions:\n  contents: read\n  security-events: write\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  lint:\n    name: Lint\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n          cache: true\n\n      - name: golangci-lint\n        uses: golangci/golangci-lint-action@v6\n        with:\n          version: latest\n          args: --timeout=5m --config=.golangci.yml\n\n  security:\n    name: Security Scan\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n\n      - name: Run gosec\n        uses: securego/gosec@master\n        with:\n          args: -fmt sarif -out gosec.sarif -exclude-dir=examples ./...\n\n      - name: Upload SARIF\n        uses: github/codeql-action/upload-sarif@v3\n        if: always()\n        with:\n          sarif_file: gosec.sarif\n\n  govulncheck:\n    name: Vulnerability Check\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n\n      - name: Install govulncheck\n        run: go install golang.org/x/vuln/cmd/govulncheck@latest\n\n      - name: Run govulncheck\n        run: govulncheck ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#task-4-commitlint-workflow-template","title":"Task 4: Commitlint Workflow Template","text":"<p>File: <code>.github/workflow-templates/commitlint.yml</code></p> <pre><code># Template for commitlint.yml in all consolidated repos\n# Copy to .github/workflows/commitlint.yml\n\nname: Commitlint\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n\npermissions:\n  contents: read\n\njobs:\n  commitlint:\n    name: Lint Commits\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup Node\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"20\"\n\n      - name: Install commitlint\n        run: npm install -g @commitlint/cli @commitlint/config-conventional\n\n      - name: Validate current commit (push)\n        if: github.event_name == 'push'\n        run: npx commitlint --from HEAD~1 --to HEAD --verbose\n\n      - name: Validate PR commits\n        if: github.event_name == 'pull_request'\n        run: npx commitlint --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }} --verbose\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#task-5-release-please-workflow-template","title":"Task 5: Release Please Workflow Template","text":"<p>File: <code>.github/workflow-templates/release-please.yml</code></p> <pre><code># Template for release-please.yml in all consolidated repos\n# Copy to .github/workflows/release-please.yml\n\nname: Release Please\n\non:\n  push:\n    branches: [\"main\"]\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  release-please:\n    name: Release\n    runs-on: ubuntu-latest\n    outputs:\n      release_created: ${{ steps.release.outputs.release_created }}\n      tag_name: ${{ steps.release.outputs.tag_name }}\n      version: ${{ steps.release.outputs.version }}\n    steps:\n      - name: Release Please\n        id: release\n        uses: google-github-actions/release-please-action@v4\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          config-file: release-please-config.json\n          manifest-file: .release-please-manifest.json\n\n      - name: Checkout (on release)\n        if: steps.release.outputs.release_created\n        uses: actions/checkout@v4\n\n      - name: Set up Go (on release)\n        if: steps.release.outputs.release_created\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n\n      - name: Verify module (on release)\n        if: steps.release.outputs.release_created\n        run: |\n          go mod verify\n          go build ./...\n          go test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#task-6-dependency-review-workflow-template","title":"Task 6: Dependency Review Workflow Template","text":"<p>File: <code>.github/workflow-templates/dependency-review.yml</code></p> <pre><code># Template for dependency-review.yml in all consolidated repos\n# Copy to .github/workflows/dependency-review.yml\n\nname: Dependency Review\n\non:\n  pull_request:\n    paths:\n      - \"go.mod\"\n      - \"go.sum\"\n\npermissions:\n  contents: read\n  pull-requests: write\n\njobs:\n  dependency-review:\n    name: Review Dependencies\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Dependency Review\n        uses: actions/dependency-review-action@v4\n        with:\n          fail-on-severity: high\n          deny-licenses: GPL-3.0, AGPL-3.0\n          allow-licenses: MIT, Apache-2.0, BSD-2-Clause, BSD-3-Clause, ISC\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#task-7-create-template-readme","title":"Task 7: Create Template README","text":"<p>File: <code>.github/workflow-templates/README.md</code></p> <pre><code># Workflow Templates\n\nReusable GitHub Actions workflows for ApertureStack consolidated repositories.\n\n## Usage\n\nCopy the needed workflow files to `.github/workflows/` in each repository:\n\n```bash\n# From repository root\ncp /path/to/workflow-templates/*.yml .github/workflows/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#workflows","title":"Workflows","text":"Workflow Triggers Purpose <code>ci.yml</code> push, PR Build, test, coverage <code>lint-security.yml</code> push, PR golangci-lint, gosec, govulncheck <code>commitlint.yml</code> push, PR Conventional commits <code>release-please.yml</code> push to main Automated releases <code>dependency-review.yml</code> PR (go.mod) License + vulnerability check"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#required-secrets","title":"Required Secrets","text":"Secret Scope Purpose <code>CODECOV_TOKEN</code> Org Coverage upload <code>GH_TOKEN</code> Org Private repo access"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#customization","title":"Customization","text":"<p>Each workflow includes comments for customization points: - Go version matrix - Test tags - Lint configuration - Security exclusions <pre><code>---\n\n## Verification Checklist\n\n- [ ] All 5 workflow templates created\n- [ ] YAML syntax valid\n- [ ] Consistent naming conventions\n- [ ] Required secrets documented\n- [ ] README explains usage\n- [ ] Templates tested locally with `act` (optional)\n\n**Validation:**\n```bash\n# Validate YAML syntax\nfor f in .github/workflow-templates/*.yml; do\n  python3 -c \"import yaml; yaml.safe_load(open('$f'))\" &amp;&amp; echo \"\u2713 $f\" || echo \"\u2717 $f\"\ndone\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>All templates are valid GitHub Actions syntax</li> <li>Workflows can be copied directly to repos</li> <li>Documentation is complete</li> <li>Secrets requirements are documented</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#rollback-plan","title":"Rollback Plan","text":"<pre><code>rm -rf .github/workflow-templates/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-111-cicd-templates/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-112: GitHub Org Config (configure secrets)</li> <li>PRD-113: Release Automation (release-please config)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/","title":"PRD-112: GitHub Organization Configuration","text":"<p>Phase: 1 - Infrastructure Setup Priority: High Effort: 2 hours Dependencies: PRD-110</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#objective","title":"Objective","text":"<p>Configure GitHub organization settings, secrets, and branch protection rules for all ApertureStack repositories.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#deliverables","title":"Deliverables","text":"Deliverable Description Org Secrets CODECOV_TOKEN, GH_TOKEN configured Branch Protection Main branch protection on all repos Repository Settings Consistent settings across repos Teams CODEOWNERS team configuration"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#task-1-configure-organization-secrets","title":"Task 1: Configure Organization Secrets","text":"<p>Commands: <pre><code># Set organization-level secrets (requires admin access)\n# These secrets are inherited by all repos in the org\n\n# Codecov token for coverage uploads\ngh secret set CODECOV_TOKEN --org ApertureStack --visibility all\n\n# GitHub token for cross-repo access (PAT with repo scope)\ngh secret set GH_TOKEN --org ApertureStack --visibility all\n\n# Verify secrets are set\ngh secret list --org ApertureStack\n</code></pre></p> <p>Required Secrets:</p> Secret Purpose Scope <code>CODECOV_TOKEN</code> Upload test coverage to Codecov All repos <code>GH_TOKEN</code> Access private repos in go mod download All repos"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#task-2-configure-branch-protection","title":"Task 2: Configure Branch Protection","text":"<p>Script: <code>scripts/configure-branch-protection.sh</code></p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nREPOS=(\n  toolfoundation\n  tooldiscovery\n  toolexec\n  toolcompose\n  toolops\n  toolprotocol\n)\n\nfor repo in \"${REPOS[@]}\"; do\n  echo \"Configuring branch protection for ApertureStack/$repo...\"\n\n  gh api \\\n    --method PUT \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"/repos/ApertureStack/$repo/branches/main/protection\" \\\n    -f required_status_checks='{\"strict\":true,\"contexts\":[\"test\",\"lint\"]}' \\\n    -f enforce_admins=false \\\n    -f required_pull_request_reviews='{\"dismiss_stale_reviews\":true,\"require_code_owner_reviews\":true,\"required_approving_review_count\":1}' \\\n    -f restrictions=null \\\n    -f allow_force_pushes=false \\\n    -f allow_deletions=false \\\n    -f block_creations=false \\\n    -f required_conversation_resolution=true\n\n  echo \"\u2713 $repo configured\"\ndone\n\necho \"All repositories configured!\"\n</code></pre> <p>Execute: <pre><code>chmod +x scripts/configure-branch-protection.sh\n./scripts/configure-branch-protection.sh\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#task-3-configure-repository-settings","title":"Task 3: Configure Repository Settings","text":"<p>Script: <code>scripts/configure-repo-settings.sh</code></p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nREPOS=(\n  toolfoundation\n  tooldiscovery\n  toolexec\n  toolcompose\n  toolops\n  toolprotocol\n)\n\nfor repo in \"${REPOS[@]}\"; do\n  echo \"Configuring settings for ApertureStack/$repo...\"\n\n  # Update repository settings\n  gh api \\\n    --method PATCH \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"/repos/ApertureStack/$repo\" \\\n    -f has_issues=true \\\n    -f has_projects=false \\\n    -f has_wiki=false \\\n    -f has_discussions=false \\\n    -f allow_squash_merge=true \\\n    -f allow_merge_commit=false \\\n    -f allow_rebase_merge=true \\\n    -f allow_auto_merge=true \\\n    -f delete_branch_on_merge=true \\\n    -f allow_update_branch=true\n\n  echo \"\u2713 $repo settings updated\"\ndone\n\necho \"All repository settings configured!\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#task-4-configure-topics-and-description","title":"Task 4: Configure Topics and Description","text":"<p>Script: <code>scripts/configure-repo-topics.sh</code></p> <pre><code>#!/bin/bash\nset -euo pipefail\n\ndeclare -A DESCRIPTIONS=(\n  [\"toolfoundation\"]=\"Core schemas, protocol adapters, and versioning for ApertureStack AI tool ecosystem\"\n  [\"tooldiscovery\"]=\"Tool registry, search, semantic indexing, and documentation\"\n  [\"toolexec\"]=\"Tool execution pipeline, runtime sandboxing, and code orchestration\"\n  [\"toolcompose\"]=\"Tool composition, toolsets, and agent skills\"\n  [\"toolops\"]=\"Observability, caching, resilience, health checks, and authentication\"\n  [\"toolprotocol\"]=\"Multi-protocol transport layer: MCP, A2A, ACP adapters\"\n)\n\nCOMMON_TOPICS=\"golang,ai-tools,mcp,llm-tools,agent-tools\"\n\ndeclare -A SPECIFIC_TOPICS=(\n  [\"toolfoundation\"]=\"json-schema,protocol-adapters\"\n  [\"tooldiscovery\"]=\"search,bm25,semantic-search\"\n  [\"toolexec\"]=\"execution,sandbox,docker,wasm\"\n  [\"toolcompose\"]=\"composition,skills,toolsets\"\n  [\"toolops\"]=\"observability,caching,circuit-breaker,authentication\"\n  [\"toolprotocol\"]=\"mcp-protocol,a2a-protocol,grpc,websocket\"\n)\n\nfor repo in \"${!DESCRIPTIONS[@]}\"; do\n  echo \"Configuring ApertureStack/$repo...\"\n\n  # Update description\n  gh repo edit \"ApertureStack/$repo\" --description \"${DESCRIPTIONS[$repo]}\"\n\n  # Set topics\n  TOPICS=\"$COMMON_TOPICS,${SPECIFIC_TOPICS[$repo]}\"\n  gh api \\\n    --method PUT \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"/repos/ApertureStack/$repo/topics\" \\\n    -f names=\"[$(echo $TOPICS | sed 's/,/\",\"/g' | sed 's/^/\"/' | sed 's/$/\"/')\"]\"\n\n  echo \"\u2713 $repo configured\"\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#task-5-configure-codeowners","title":"Task 5: Configure CODEOWNERS","text":"<p>Each repository already has <code>.github/CODEOWNERS</code> from PRD-110. Verify:</p> <pre><code>for repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  echo \"Checking CODEOWNERS in $repo...\"\n  gh api \"/repos/ApertureStack/$repo/contents/.github/CODEOWNERS\" -q '.content' | base64 -d\ndone\n</code></pre> <p>Expected content: <pre><code>* @jonwraymond\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#task-6-configure-security-settings","title":"Task 6: Configure Security Settings","text":"<pre><code>#!/bin/bash\nset -euo pipefail\n\nREPOS=(\n  toolfoundation\n  tooldiscovery\n  toolexec\n  toolcompose\n  toolops\n  toolprotocol\n)\n\nfor repo in \"${REPOS[@]}\"; do\n  echo \"Enabling security features for ApertureStack/$repo...\"\n\n  # Enable Dependabot alerts\n  gh api \\\n    --method PUT \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"/repos/ApertureStack/$repo/vulnerability-alerts\"\n\n  # Enable Dependabot security updates\n  gh api \\\n    --method PUT \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"/repos/ApertureStack/$repo/automated-security-fixes\"\n\n  echo \"\u2713 $repo security enabled\"\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#task-7-verification","title":"Task 7: Verification","text":"<pre><code># Verify all configurations\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  echo \"=== ApertureStack/$repo ===\"\n\n  # Check branch protection\n  gh api \"/repos/ApertureStack/$repo/branches/main/protection\" -q '.required_status_checks.contexts[]' 2&gt;/dev/null || echo \"No branch protection\"\n\n  # Check secrets (just confirms they exist)\n  gh secret list -R \"ApertureStack/$repo\" 2&gt;/dev/null || echo \"Using org secrets\"\n\n  # Check settings\n  gh repo view \"ApertureStack/$repo\" --json allowSquashMerge,deleteBranchOnMerge\n\n  echo \"\"\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] CODECOV_TOKEN org secret configured</li> <li>[ ] GH_TOKEN org secret configured</li> <li>[ ] Branch protection enabled on all repos</li> <li>[ ] Require status checks (test, lint)</li> <li>[ ] Require code review</li> <li>[ ] Squash merge enabled</li> <li>[ ] Delete branch on merge enabled</li> <li>[ ] Dependabot alerts enabled</li> <li>[ ] Repository topics set</li> <li>[ ] CODEOWNERS verified</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>All org secrets are accessible to workflows</li> <li>PRs require passing CI and code review</li> <li>Force push to main is blocked</li> <li>Consistent settings across all repos</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#rollback-plan","title":"Rollback Plan","text":"<pre><code># Disable branch protection (allows force push to fix issues)\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  gh api --method DELETE \"/repos/ApertureStack/$repo/branches/main/protection\"\ndone\n\n# Remove org secrets\ngh secret delete CODECOV_TOKEN --org ApertureStack\ngh secret delete GH_TOKEN --org ApertureStack\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-112-github-org-config/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-113: Release Automation</li> <li>PRD-120: Migrate toolmodel</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/","title":"PRD-113: Release Automation","text":"<p>Phase: 1 - Infrastructure Setup Priority: High Effort: 2 hours Dependencies: PRD-110, PRD-111</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#objective","title":"Objective","text":"<p>Configure release-please for automated semantic versioning and changelog generation across all consolidated repositories.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Release Config <code>release-please-config.json</code> Per-repo release configuration Manifest <code>.release-please-manifest.json</code> Version tracking Changelog Sections Configured Categorized changelog entries"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#task-1-create-release-configuration-template","title":"Task 1: Create Release Configuration Template","text":"<p>File: <code>release-please-config.json</code> (template for all repos)</p> <pre><code>{\n  \"$schema\": \"https://raw.githubusercontent.com/googleapis/release-please/main/schemas/config.json\",\n  \"release-type\": \"go\",\n  \"packages\": {\n    \".\": {\n      \"component\": \"REPO_NAME\",\n      \"changelog-path\": \"CHANGELOG.md\"\n    }\n  },\n  \"changelog-sections\": [\n    {\"type\": \"feat\", \"section\": \"Features\", \"hidden\": false},\n    {\"type\": \"fix\", \"section\": \"Bug Fixes\", \"hidden\": false},\n    {\"type\": \"perf\", \"section\": \"Performance Improvements\", \"hidden\": false},\n    {\"type\": \"refactor\", \"section\": \"Code Refactoring\", \"hidden\": false},\n    {\"type\": \"docs\", \"section\": \"Documentation\", \"hidden\": false},\n    {\"type\": \"test\", \"section\": \"Tests\", \"hidden\": true},\n    {\"type\": \"chore\", \"section\": \"Miscellaneous\", \"hidden\": true},\n    {\"type\": \"ci\", \"section\": \"Continuous Integration\", \"hidden\": true},\n    {\"type\": \"build\", \"section\": \"Build System\", \"hidden\": true}\n  ],\n  \"bump-minor-pre-major\": true,\n  \"bump-patch-for-minor-pre-major\": true,\n  \"draft\": false,\n  \"prerelease\": false,\n  \"include-component-in-tag\": false,\n  \"include-v-in-tag\": true,\n  \"pull-request-title-pattern\": \"chore(release): ${version}\",\n  \"pull-request-header\": \"## Release PR\\n\\nThis PR was generated by release-please.\",\n  \"separate-pull-requests\": false,\n  \"sequential-calls\": false,\n  \"group-pull-request-title-pattern\": \"chore(release): ${version}\",\n  \"release-search-depth\": 500,\n  \"commit-search-depth\": 500\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#task-2-create-manifest-template","title":"Task 2: Create Manifest Template","text":"<p>File: <code>.release-please-manifest.json</code> (template)</p> <pre><code>{\n  \".\": \"0.0.0\"\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#task-3-deploy-to-all-repositories","title":"Task 3: Deploy to All Repositories","text":"<p>Script: <code>scripts/deploy-release-config.sh</code></p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nREPOS=(\n  toolfoundation\n  tooldiscovery\n  toolexec\n  toolcompose\n  toolops\n  toolprotocol\n)\n\nBASE_DIR=$(pwd)\n\nfor repo in \"${REPOS[@]}\"; do\n  REPO_DIR=\"../$repo\"\n\n  if [ ! -d \"$REPO_DIR\" ]; then\n    echo \"\u26a0 $repo directory not found, skipping...\"\n    continue\n  fi\n\n  echo \"Configuring release-please for $repo...\"\n\n  cd \"$REPO_DIR\"\n\n  # Create release-please-config.json with repo-specific component name\n  cat &gt; release-please-config.json &lt;&lt; EOF\n{\n  \"\\$schema\": \"https://raw.githubusercontent.com/googleapis/release-please/main/schemas/config.json\",\n  \"release-type\": \"go\",\n  \"packages\": {\n    \".\": {\n      \"component\": \"$repo\",\n      \"changelog-path\": \"CHANGELOG.md\"\n    }\n  },\n  \"changelog-sections\": [\n    {\"type\": \"feat\", \"section\": \"Features\", \"hidden\": false},\n    {\"type\": \"fix\", \"section\": \"Bug Fixes\", \"hidden\": false},\n    {\"type\": \"perf\", \"section\": \"Performance Improvements\", \"hidden\": false},\n    {\"type\": \"refactor\", \"section\": \"Code Refactoring\", \"hidden\": false},\n    {\"type\": \"docs\", \"section\": \"Documentation\", \"hidden\": false},\n    {\"type\": \"test\", \"section\": \"Tests\", \"hidden\": true},\n    {\"type\": \"chore\", \"section\": \"Miscellaneous\", \"hidden\": true},\n    {\"type\": \"ci\", \"section\": \"Continuous Integration\", \"hidden\": true},\n    {\"type\": \"build\", \"section\": \"Build System\", \"hidden\": true}\n  ],\n  \"bump-minor-pre-major\": true,\n  \"bump-patch-for-minor-pre-major\": true,\n  \"draft\": false,\n  \"prerelease\": false,\n  \"include-component-in-tag\": false,\n  \"include-v-in-tag\": true,\n  \"pull-request-title-pattern\": \"chore(release): \\${version}\",\n  \"separate-pull-requests\": false\n}\nEOF\n\n  # Create manifest\n  echo '{\".\":\" 0.0.0\"}' &gt; .release-please-manifest.json\n\n  # Commit if there are changes\n  if [ -n \"$(git status --porcelain)\" ]; then\n    git add release-please-config.json .release-please-manifest.json\n    git commit -m \"chore: configure release-please\n\n- Add release-please-config.json\n- Add .release-please-manifest.json\n- Configure changelog sections\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n    git push origin main\n    echo \"\u2713 $repo configured and pushed\"\n  else\n    echo \"\u2713 $repo already configured\"\n  fi\n\n  cd \"$BASE_DIR\"\ndone\n\necho \"\"\necho \"All repositories configured!\"\necho \"\"\necho \"Release-please will create PRs on next push to main with conventional commits.\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#task-4-verify-release-workflow","title":"Task 4: Verify Release Workflow","text":"<p>After pushing changes, verify the release-please workflow runs:</p> <pre><code>for repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  echo \"=== ApertureStack/$repo ===\"\n  gh run list -R \"ApertureStack/$repo\" --workflow=\"Release Please\" --limit 1\n  echo \"\"\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#task-5-test-release-flow","title":"Task 5: Test Release Flow","text":"<p>Create a test commit to verify the release process:</p> <pre><code>cd ../toolfoundation\n\n# Create a feature commit (this will trigger a minor version bump)\necho \"// test\" &gt;&gt; model/doc.go\ngit add model/doc.go\ngit commit -m \"feat: add initial model package\n\nThis commit sets up the foundation model package structure.\n\n- Add doc.go with package documentation\n- Prepare for tool schema types\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n\n# Check for release PR\nsleep 30  # Wait for workflow to run\ngh pr list -R \"ApertureStack/toolfoundation\" --label \"autorelease: pending\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#task-6-document-release-process","title":"Task 6: Document Release Process","text":"<p>File: <code>docs/RELEASE-PROCESS.md</code></p> <pre><code># Release Process\n\n## Overview\n\nAll ApertureStack repositories use [Release Please](https://github.com/googleapis/release-please) for automated releases.\n\n## How It Works\n\n1. **Commit with Conventional Commits**\n   ```bash\n   git commit -m \"feat: add new feature\"\n   git commit -m \"fix: resolve bug\"\n   git commit -m \"docs: update readme\"\n   ```\n\n2. **Push to Main**\n   ```bash\n   git push origin main\n   ```\n\n3. **Release PR Created**\n   - Release Please analyzes commits\n   - Creates/updates a release PR\n   - Generates CHANGELOG.md entries\n\n4. **Merge Release PR**\n   - Review the generated changelog\n   - Merge the PR\n   - Tag is created automatically\n   - GitHub Release is published\n\n## Version Bumping\n\n| Commit Type | Version Bump |\n|-------------|--------------|\n| `feat:` | Minor (0.1.0 \u2192 0.2.0) |\n| `fix:` | Patch (0.1.0 \u2192 0.1.1) |\n| `feat!:` or `BREAKING CHANGE:` | Major (0.1.0 \u2192 1.0.0) |\n| `docs:`, `chore:`, `ci:` | No bump |\n\n## Breaking Changes\n\nInclude `BREAKING CHANGE:` in the commit body:\n\n```bash\ngit commit -m \"feat: change API\n\nBREAKING CHANGE: This changes the public API signature\"\n</code></pre> <p>Or use <code>!</code> after the type:</p> <pre><code>git commit -m \"feat!: change API signature\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#manual-release","title":"Manual Release","text":"<p>If needed, you can create a release manually:</p> <pre><code># Create tag\ngit tag v1.0.0\ngit push origin v1.0.0\n\n# Create GitHub release\ngh release create v1.0.0 --generate-notes\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#release-pr-not-created","title":"Release PR not created","text":"<ol> <li>Check workflow ran: <code>gh run list --workflow=\"Release Please\"</code></li> <li>Verify conventional commits: <code>git log --oneline -5</code></li> <li>Check manifest: <code>cat .release-please-manifest.json</code></li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#wrong-version","title":"Wrong version","text":"<p>Edit <code>.release-please-manifest.json</code> to set the correct version. <pre><code>---\n\n## Verification Checklist\n\n- [ ] `release-please-config.json` in all repos\n- [ ] `.release-please-manifest.json` in all repos\n- [ ] Release Please workflow exists in all repos\n- [ ] Changelog sections configured correctly\n- [ ] Test commit triggers release PR\n- [ ] Documentation created\n\n---\n\n## Acceptance Criteria\n\n1. Conventional commits trigger release PRs\n2. Changelog is generated with correct sections\n3. Version bumping follows semver\n4. Tags include `v` prefix (e.g., `v1.0.0`)\n5. Go module versioning works correctly\n\n---\n\n## Rollback Plan\n\n```bash\n# Remove release-please config\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  cd ../$repo\n  rm -f release-please-config.json .release-please-manifest.json\n  git add -A\n  git commit -m \"chore: remove release-please config\"\n  git push origin main\n  cd -\ndone\n\n# Delete release workflow\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  rm ../$repo/.github/workflows/release-please.yml\ndone\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-113-release-automation/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-120: Migrate toolmodel (first actual code migration)</li> <li>Gate G1: Verify all infrastructure is working</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/","title":"PRD-120: Migrate toolmodel","text":"<p>Phase: 2 - Foundation Layer Priority: Critical Effort: 4 hours Dependencies: PRD-110 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolmodel</code> repository into <code>toolfoundation/model/</code> as the first package in the consolidated foundation layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolmodel</code> Target Location: <code>github.com/jonwraymond/toolfoundation/model</code></p> <p>Package Contents: - Core tool schema types (<code>Tool</code>, <code>ToolInput</code>, <code>ToolOutput</code>) - JSON Schema validation - Serialization helpers - ~2,500 lines of code - 89.6% test coverage</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#deliverables","title":"Deliverables","text":"Deliverable Location Description Model Package <code>toolfoundation/model/</code> Migrated tool schema types Tests <code>toolfoundation/model/*_test.go</code> All existing tests Documentation <code>toolfoundation/model/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#task-1-clone-source-repository","title":"Task 1: Clone Source Repository","text":"<pre><code># Create working directory\nmkdir -p /tmp/migration\ncd /tmp/migration\n\n# Clone source with full history\ngit clone git@github.com:jonwraymond/toolmodel.git\ncd toolmodel\n\n# Verify contents\nls -la\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#task-2-prepare-target-repository","title":"Task 2: Prepare Target Repository","text":"<pre><code># Clone target\ncd /tmp/migration\ngit clone git@github.com:jonwraymond/toolfoundation.git\ncd toolfoundation\n\n# Create model directory\nmkdir -p model\n\n# Verify go.mod exists\ncat go.mod\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#task-3-copy-source-files","title":"Task 3: Copy Source Files","text":"<pre><code>cd /tmp/migration\n\n# Copy Go source files (exclude go.mod, go.sum, .git)\ncp toolmodel/*.go toolfoundation/model/\n\n# List copied files\nls -la toolfoundation/model/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#task-4-update-import-paths","title":"Task 4: Update Import Paths","text":"<p>Script: <code>scripts/update-imports.sh</code></p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nOLD_IMPORT=\"github.com/jonwraymond/toolmodel\"\nNEW_IMPORT=\"github.com/jonwraymond/toolfoundation/model\"\n\ncd toolfoundation/model\n\n# Update all Go files\nfor file in *.go; do\n  if [ -f \"$file\" ]; then\n    sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\n    echo \"Updated: $file\"\n  fi\ndone\n\n# Verify no old imports remain\ngrep -r \"jonwraymond/toolmodel\" . &amp;&amp; echo \"\u26a0 Old imports still exist!\" || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#task-5-update-package-documentation","title":"Task 5: Update Package Documentation","text":"<p>File: <code>toolfoundation/model/doc.go</code></p> <pre><code>// Package model provides the canonical tool schema types for the ApertureStack ecosystem.\n//\n// This package defines the core data structures used to represent tools across\n// all layers of the stack, including:\n//\n//   - Tool: The primary tool definition with name, description, and schema\n//   - ToolInput: JSON Schema-based input parameter definitions\n//   - ToolOutput: Output type definitions and validation\n//   - Metadata: Extensible tool metadata\n//\n// # Usage\n//\n// Create a new tool definition:\n//\n//  tool := model.Tool{\n//      ID:          \"calculator\",\n//      Name:        \"Calculator\",\n//      Description: \"Performs arithmetic operations\",\n//      InputSchema: model.InputSchema{\n//          Type: \"object\",\n//          Properties: map[string]model.Property{\n//              \"operation\": {Type: \"string\", Enum: []string{\"add\", \"subtract\"}},\n//              \"a\":         {Type: \"number\"},\n//              \"b\":         {Type: \"number\"},\n//          },\n//          Required: []string{\"operation\", \"a\", \"b\"},\n//      },\n//  }\n//\n// Validate tool input:\n//\n//  if err := tool.ValidateInput(input); err != nil {\n//      return fmt.Errorf(\"invalid input: %w\", err)\n//  }\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolmodel as part of\n// the ApertureStack consolidation. The API remains unchanged.\npackage model\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#task-6-update-gomod-dependencies","title":"Task 6: Update go.mod Dependencies","text":"<pre><code>cd toolfoundation\n\n# Tidy dependencies\ngo mod tidy\n\n# Verify build\ngo build ./...\n\n# Run tests\ngo test -v ./model/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#task-7-verify-test-coverage","title":"Task 7: Verify Test Coverage","text":"<pre><code>cd toolfoundation\n\n# Run tests with coverage\ngo test -coverprofile=coverage.out ./model/...\n\n# Check coverage percentage (should be &gt;= 89%)\ngo tool cover -func=coverage.out | grep total\n\n# Generate HTML coverage report\ngo tool cover -html=coverage.out -o coverage.html\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd toolfoundation\n\ngit add -A\ngit commit -m \"feat(model): migrate toolmodel package\n\nMigrate the canonical tool schema types from standalone toolmodel repository.\n\nPackage contents:\n- Tool, ToolInput, ToolOutput types\n- JSON Schema validation\n- Serialization helpers\n- Full test coverage (89.6%)\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolmodel \u2192 toolfoundation/model\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#task-9-update-dependent-repositories","title":"Task 9: Update Dependent Repositories","text":"<p>Create a tracking issue for updating imports in dependent repos:</p> <pre><code>gh issue create -R jonwraymond/toolfoundation \\\n  --title \"Update dependent repos to use toolfoundation/model\" \\\n  --body \"## Dependent Repositories\n\nThe following repositories need import updates:\n\n- [ ] toolindex\n- [ ] toolsearch\n- [ ] toolrun\n- [ ] toolcode\n- [ ] metatools-mcp\n\n## Old Import\n\\`\\`\\`go\nimport \\\"github.com/jonwraymond/toolmodel\\\"\n\\`\\`\\`\n\n## New Import\n\\`\\`\\`go\nimport \\\"github.com/jonwraymond/toolfoundation/model\\\"\n\\`\\`\\`\n\n## Timeline\nWill be updated as part of each repo's migration PRD.\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#file-mapping","title":"File Mapping","text":"Source Target <code>toolmodel/tool.go</code> <code>toolfoundation/model/tool.go</code> <code>toolmodel/tool_test.go</code> <code>toolfoundation/model/tool_test.go</code> <code>toolmodel/schema.go</code> <code>toolfoundation/model/schema.go</code> <code>toolmodel/schema_test.go</code> <code>toolfoundation/model/schema_test.go</code> <code>toolmodel/validate.go</code> <code>toolfoundation/model/validate.go</code> <code>toolmodel/validate_test.go</code> <code>toolfoundation/model/validate_test.go</code> <code>toolmodel/doc.go</code> <code>toolfoundation/model/doc.go</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Coverage &gt;= 89%</li> <li>[ ] Package documentation updated</li> <li>[ ] Committed with proper message</li> <li>[ ] Pushed to main</li> <li>[ ] Dependent repos tracked</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolfoundation/model</code> package builds successfully</li> <li>All tests pass with &gt;= 89% coverage</li> <li>No references to old import path</li> <li>Package can be imported by other repos</li> <li>API is unchanged from original toolmodel</li> </ol> <p>Verification: <pre><code>// This should work in any dependent package\nimport \"github.com/jonwraymond/toolfoundation/model\"\n\nfunc example() {\n    tool := model.Tool{\n        ID:   \"test\",\n        Name: \"Test Tool\",\n    }\n    _ = tool\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolfoundation/model/</code> contains migrated sources and tests.</li> <li><code>toolfoundation/model/doc.go</code> documents the package contract.</li> <li><code>go test ./model/...</code> passes in <code>toolfoundation</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd toolfoundation\n\n# Remove model package\nrm -rf model/\n\n# Reset to previous state\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-120-migrate-toolmodel/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-121: Migrate tooladapter</li> <li>PRD-122: Create toolversion</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/","title":"PRD-121: Migrate tooladapter","text":"<p>Phase: 2 - Foundation Layer Priority: Critical Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#objective","title":"Objective","text":"<p>Migrate the existing <code>tooladapter</code> repository into <code>toolfoundation/adapter/</code> as the second package in the consolidated foundation layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/tooladapter</code> Target Location: <code>github.com/jonwraymond/toolfoundation/adapter</code></p> <p>Package Contents: - Schema adapters for converting between tool formats - MCP \u2194 OpenAI \u2194 Anthropic format conversion - LangChain tool format support - ~1,500 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#deliverables","title":"Deliverables","text":"Deliverable Location Description Adapter Package <code>toolfoundation/adapter/</code> Schema format adapters Tests <code>toolfoundation/adapter/*_test.go</code> All existing tests Documentation <code>toolfoundation/adapter/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#task-1-clone-source-repository","title":"Task 1: Clone Source Repository","text":"<pre><code>cd /tmp/migration\n\n# Clone source with full history\ngit clone git@github.com:jonwraymond/tooladapter.git\ncd tooladapter\n\n# Verify contents\nls -la\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#task-2-copy-source-files","title":"Task 2: Copy Source Files","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Create adapter directory\nmkdir -p adapter\n\n# Copy Go source files\ncp ../tooladapter/*.go adapter/\n\n# List copied files\nls -la adapter/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#task-3-update-import-paths","title":"Task 3: Update Import Paths","text":"<pre><code>cd /tmp/migration/toolfoundation/adapter\n\nOLD_IMPORT=\"github.com/jonwraymond/tooladapter\"\nNEW_IMPORT=\"github.com/jonwraymond/toolfoundation/adapter\"\n\n# Update all Go files\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\n  echo \"Updated: $file\"\ndone\n\n# Also update toolmodel import to toolfoundation/model\nOLD_MODEL=\"github.com/jonwraymond/toolmodel\"\nNEW_MODEL=\"github.com/jonwraymond/toolfoundation/model\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_MODEL|$NEW_MODEL|g\" \"$file\"\ndone\n\n# Verify\ngrep -r \"jonwraymond/tooladapter\\|jonwraymond/toolmodel\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#task-4-update-package-documentation","title":"Task 4: Update Package Documentation","text":"<p>File: <code>toolfoundation/adapter/doc.go</code></p> <pre><code>// Package adapter provides schema format conversion between different AI tool specifications.\n//\n// This package enables interoperability between various AI tool formats:\n//\n//   - MCP (Model Context Protocol) - Anthropic's standard\n//   - OpenAI Function Calling format\n//   - Anthropic Tool Use format\n//   - LangChain Tool format\n//\n// # Adapters\n//\n// Each adapter implements bidirectional conversion:\n//\n//  // Convert MCP tool to OpenAI format\n//  openaiTool := adapter.ToOpenAI(mcpTool)\n//\n//  // Convert OpenAI tool to MCP format\n//  mcpTool := adapter.FromOpenAI(openaiTool)\n//\n// # Supported Formats\n//\n//  | Format     | To MCP | From MCP |\n//  |------------|--------|----------|\n//  | OpenAI     | \u2713      | \u2713        |\n//  | Anthropic  | \u2713      | \u2713        |\n//  | LangChain  | \u2713      | \u2713        |\n//\n// # Schema Compatibility\n//\n// Not all schema features are supported across formats. The adapter handles:\n//\n//   - Parameter type mapping\n//   - Required field conversion\n//   - Description propagation\n//   - Enum value handling\n//\n// Features not supported in target format are gracefully degraded.\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/tooladapter as part of\n// the ApertureStack consolidation.\npackage adapter\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#task-5-verify-internal-dependencies","title":"Task 5: Verify Internal Dependencies","text":"<p>The adapter package depends on the model package. Verify the import works:</p> <pre><code>cd /tmp/migration/toolfoundation\n\n# Check imports in adapter files\ngrep -h \"import\" adapter/*.go | sort -u\n\n# Should include:\n# \"github.com/jonwraymond/toolfoundation/model\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#task-6-update-gomod-and-build","title":"Task 6: Update go.mod and Build","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Tidy dependencies\ngo mod tidy\n\n# Verify build\ngo build ./...\n\n# Run all tests\ngo test -v ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#task-7-verify-test-coverage","title":"Task 7: Verify Test Coverage","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Run adapter tests with coverage\ngo test -coverprofile=adapter_coverage.out ./adapter/...\n\n# Check coverage\ngo tool cover -func=adapter_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd /tmp/migration/toolfoundation\n\ngit add -A\ngit commit -m \"feat(adapter): migrate tooladapter package\n\nMigrate schema format adapters from standalone tooladapter repository.\n\nPackage contents:\n- MCP \u2194 OpenAI format conversion\n- MCP \u2194 Anthropic format conversion\n- MCP \u2194 LangChain format conversion\n- Bidirectional adapters with graceful degradation\n\nInternal dependency:\n- Uses toolfoundation/model for canonical types\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/tooladapter \u2192 toolfoundation/adapter\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#adapter-interface-design","title":"Adapter Interface Design","text":"<p>The migrated adapter package should follow this interface pattern:</p> <pre><code>package adapter\n\nimport \"github.com/jonwraymond/toolfoundation/model\"\n\n// Adapter converts between MCP tool format and external formats.\ntype Adapter interface {\n    // ToExternal converts an MCP tool to the external format.\n    ToExternal(tool model.Tool) (any, error)\n\n    // FromExternal converts an external format tool to MCP.\n    FromExternal(external any) (model.Tool, error)\n\n    // Name returns the adapter name (e.g., \"openai\", \"anthropic\").\n    Name() string\n}\n\n// OpenAIAdapter converts between MCP and OpenAI function calling format.\ntype OpenAIAdapter struct{}\n\nfunc (a *OpenAIAdapter) ToExternal(tool model.Tool) (any, error) { ... }\nfunc (a *OpenAIAdapter) FromExternal(external any) (model.Tool, error) { ... }\nfunc (a *OpenAIAdapter) Name() string { return \"openai\" }\n\n// AnthropicAdapter converts between MCP and Anthropic tool use format.\ntype AnthropicAdapter struct{}\n\n// LangChainAdapter converts between MCP and LangChain tool format.\ntype LangChainAdapter struct{}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#file-mapping","title":"File Mapping","text":"Source Target <code>tooladapter/adapter.go</code> <code>toolfoundation/adapter/adapter.go</code> <code>tooladapter/adapter_test.go</code> <code>toolfoundation/adapter/adapter_test.go</code> <code>tooladapter/openai.go</code> <code>toolfoundation/adapter/openai.go</code> <code>tooladapter/openai_test.go</code> <code>toolfoundation/adapter/openai_test.go</code> <code>tooladapter/anthropic.go</code> <code>toolfoundation/adapter/anthropic.go</code> <code>tooladapter/langchain.go</code> <code>toolfoundation/adapter/langchain.go</code> <code>tooladapter/doc.go</code> <code>toolfoundation/adapter/doc.go</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated (both adapter and model)</li> <li>[ ] Internal dependency on model/ works</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Package documentation updated</li> <li>[ ] Committed with proper message</li> <li>[ ] Pushed to main</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolfoundation/adapter</code> package builds successfully</li> <li>All tests pass</li> <li>Can import both <code>model</code> and <code>adapter</code> from same repo</li> <li>Adapter interface is well-defined</li> <li>No references to old import paths</li> </ol> <p>Verification: <pre><code>import (\n    \"github.com/jonwraymond/toolfoundation/model\"\n    \"github.com/jonwraymond/toolfoundation/adapter\"\n)\n\nfunc example() {\n    tool := model.Tool{ID: \"test\", Name: \"Test\"}\n    openaiAdapter := &amp;adapter.OpenAIAdapter{}\n    external, _ := openaiAdapter.ToExternal(tool)\n    _ = external\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolfoundation/adapter/</code> contains migrated sources and tests.</li> <li><code>toolfoundation/adapter/doc.go</code> documents the adapter contract.</li> <li><code>go test ./adapter/...</code> passes in <code>toolfoundation</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Remove adapter package\nrm -rf adapter/\n\n# Reset to previous state\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-121-migrate-tooladapter/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-122: Create toolversion</li> <li>Gate G2: Foundation layer complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/","title":"PRD-122: Create toolversion","text":"<p>Phase: 2 - Foundation Layer Priority: High Effort: 8 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#objective","title":"Objective","text":"<p>Create a new <code>toolfoundation/version</code> package for semantic versioning, compatibility checking, and version negotiation across the ApertureStack ecosystem.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#package-design","title":"Package Design","text":"<p>Location: <code>github.com/jonwraymond/toolfoundation/version</code></p> <p>Purpose: - Semantic version parsing and comparison - Version compatibility matrices - Protocol version negotiation - Deprecation tracking</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#deliverables","title":"Deliverables","text":"Deliverable Location Description Version Package <code>toolfoundation/version/</code> Version management utilities Tests <code>toolfoundation/version/*_test.go</code> Comprehensive tests Documentation <code>toolfoundation/version/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#task-1-create-package-structure","title":"Task 1: Create Package Structure","text":"<pre><code>cd /tmp/migration/toolfoundation\n\nmkdir -p version\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#task-2-create-core-types","title":"Task 2: Create Core Types","text":"<p>File: <code>toolfoundation/version/version.go</code></p> <pre><code>package version\n\nimport (\n    \"fmt\"\n    \"regexp\"\n    \"strconv\"\n    \"strings\"\n)\n\n// Version represents a semantic version (major.minor.patch-prerelease+build).\ntype Version struct {\n    Major      int\n    Minor      int\n    Patch      int\n    Prerelease string\n    Build      string\n}\n\nvar semverRegex = regexp.MustCompile(`^v?(\\d+)\\.(\\d+)\\.(\\d+)(?:-([0-9A-Za-z-.]+))?(?:\\+([0-9A-Za-z-.]+))?$`)\n\n// Parse parses a semantic version string.\nfunc Parse(s string) (Version, error) {\n    matches := semverRegex.FindStringSubmatch(s)\n    if matches == nil {\n        return Version{}, fmt.Errorf(\"invalid semantic version: %s\", s)\n    }\n\n    major, _ := strconv.Atoi(matches[1])\n    minor, _ := strconv.Atoi(matches[2])\n    patch, _ := strconv.Atoi(matches[3])\n\n    return Version{\n        Major:      major,\n        Minor:      minor,\n        Patch:      patch,\n        Prerelease: matches[4],\n        Build:      matches[5],\n    }, nil\n}\n\n// MustParse parses a version string and panics on error.\nfunc MustParse(s string) Version {\n    v, err := Parse(s)\n    if err != nil {\n        panic(err)\n    }\n    return v\n}\n\n// String returns the version as a string (with v prefix).\nfunc (v Version) String() string {\n    s := fmt.Sprintf(\"v%d.%d.%d\", v.Major, v.Minor, v.Patch)\n    if v.Prerelease != \"\" {\n        s += \"-\" + v.Prerelease\n    }\n    if v.Build != \"\" {\n        s += \"+\" + v.Build\n    }\n    return s\n}\n\n// Compare returns -1, 0, or 1 if v &lt; other, v == other, or v &gt; other.\nfunc (v Version) Compare(other Version) int {\n    if v.Major != other.Major {\n        return compareInt(v.Major, other.Major)\n    }\n    if v.Minor != other.Minor {\n        return compareInt(v.Minor, other.Minor)\n    }\n    if v.Patch != other.Patch {\n        return compareInt(v.Patch, other.Patch)\n    }\n    return comparePrerelease(v.Prerelease, other.Prerelease)\n}\n\n// LessThan returns true if v &lt; other.\nfunc (v Version) LessThan(other Version) bool {\n    return v.Compare(other) &lt; 0\n}\n\n// GreaterThan returns true if v &gt; other.\nfunc (v Version) GreaterThan(other Version) bool {\n    return v.Compare(other) &gt; 0\n}\n\n// Equal returns true if v == other (ignoring build metadata).\nfunc (v Version) Equal(other Version) bool {\n    return v.Compare(other) == 0\n}\n\n// Compatible returns true if v is compatible with other (same major, v &gt;= other).\nfunc (v Version) Compatible(other Version) bool {\n    if v.Major != other.Major {\n        return false\n    }\n    return v.Compare(other) &gt;= 0\n}\n\nfunc compareInt(a, b int) int {\n    if a &lt; b {\n        return -1\n    }\n    if a &gt; b {\n        return 1\n    }\n    return 0\n}\n\nfunc comparePrerelease(a, b string) int {\n    if a == \"\" &amp;&amp; b == \"\" {\n        return 0\n    }\n    if a == \"\" {\n        return 1 // no prerelease &gt; prerelease\n    }\n    if b == \"\" {\n        return -1\n    }\n    return strings.Compare(a, b)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#task-3-create-constraint-types","title":"Task 3: Create Constraint Types","text":"<p>File: <code>toolfoundation/version/constraint.go</code></p> <pre><code>package version\n\nimport (\n    \"fmt\"\n    \"strings\"\n)\n\n// Constraint represents a version constraint (e.g., \"&gt;=1.0.0\", \"^2.0.0\").\ntype Constraint struct {\n    Op      string  // \"\", \"=\", \"&gt;\", \"&gt;=\", \"&lt;\", \"&lt;=\", \"^\", \"~\"\n    Version Version\n}\n\n// ParseConstraint parses a version constraint string.\nfunc ParseConstraint(s string) (Constraint, error) {\n    s = strings.TrimSpace(s)\n\n    var op string\n    var versionStr string\n\n    switch {\n    case strings.HasPrefix(s, \"&gt;=\"):\n        op = \"&gt;=\"\n        versionStr = strings.TrimPrefix(s, \"&gt;=\")\n    case strings.HasPrefix(s, \"&lt;=\"):\n        op = \"&lt;=\"\n        versionStr = strings.TrimPrefix(s, \"&lt;=\")\n    case strings.HasPrefix(s, \"&gt;\"):\n        op = \"&gt;\"\n        versionStr = strings.TrimPrefix(s, \"&gt;\")\n    case strings.HasPrefix(s, \"&lt;\"):\n        op = \"&lt;\"\n        versionStr = strings.TrimPrefix(s, \"&lt;\")\n    case strings.HasPrefix(s, \"^\"):\n        op = \"^\"\n        versionStr = strings.TrimPrefix(s, \"^\")\n    case strings.HasPrefix(s, \"~\"):\n        op = \"~\"\n        versionStr = strings.TrimPrefix(s, \"~\")\n    case strings.HasPrefix(s, \"=\"):\n        op = \"=\"\n        versionStr = strings.TrimPrefix(s, \"=\")\n    default:\n        op = \"=\"\n        versionStr = s\n    }\n\n    v, err := Parse(strings.TrimSpace(versionStr))\n    if err != nil {\n        return Constraint{}, err\n    }\n\n    return Constraint{Op: op, Version: v}, nil\n}\n\n// Check returns true if the given version satisfies the constraint.\nfunc (c Constraint) Check(v Version) bool {\n    switch c.Op {\n    case \"\", \"=\":\n        return v.Equal(c.Version)\n    case \"&gt;\":\n        return v.GreaterThan(c.Version)\n    case \"&gt;=\":\n        return v.GreaterThan(c.Version) || v.Equal(c.Version)\n    case \"&lt;\":\n        return v.LessThan(c.Version)\n    case \"&lt;=\":\n        return v.LessThan(c.Version) || v.Equal(c.Version)\n    case \"^\":\n        // Caret: compatible with (same major, &gt;= version)\n        return v.Major == c.Version.Major &amp;&amp; (v.GreaterThan(c.Version) || v.Equal(c.Version))\n    case \"~\":\n        // Tilde: same major.minor, &gt;= version\n        return v.Major == c.Version.Major &amp;&amp; v.Minor == c.Version.Minor &amp;&amp;\n            (v.GreaterThan(c.Version) || v.Equal(c.Version))\n    default:\n        return false\n    }\n}\n\n// String returns the constraint as a string.\nfunc (c Constraint) String() string {\n    if c.Op == \"\" || c.Op == \"=\" {\n        return c.Version.String()\n    }\n    return c.Op + c.Version.String()\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#task-4-create-compatibility-matrix","title":"Task 4: Create Compatibility Matrix","text":"<p>File: <code>toolfoundation/version/compatibility.go</code></p> <pre><code>package version\n\nimport (\n    \"fmt\"\n)\n\n// Compatibility represents version compatibility between components.\ntype Compatibility struct {\n    Component  string\n    MinVersion Version\n    MaxVersion *Version // nil means no upper bound\n    Deprecated bool\n    Message    string\n}\n\n// Matrix holds compatibility information for multiple components.\ntype Matrix struct {\n    entries map[string][]Compatibility\n}\n\n// NewMatrix creates a new compatibility matrix.\nfunc NewMatrix() *Matrix {\n    return &amp;Matrix{\n        entries: make(map[string][]Compatibility),\n    }\n}\n\n// Add adds a compatibility entry for a component.\nfunc (m *Matrix) Add(comp Compatibility) {\n    m.entries[comp.Component] = append(m.entries[comp.Component], comp)\n}\n\n// Check checks if a version is compatible for a component.\nfunc (m *Matrix) Check(component string, v Version) (bool, string) {\n    entries, ok := m.entries[component]\n    if !ok {\n        return true, \"\" // unknown component, assume compatible\n    }\n\n    for _, entry := range entries {\n        if v.Compare(entry.MinVersion) &lt; 0 {\n            return false, fmt.Sprintf(\"version %s is below minimum %s\", v, entry.MinVersion)\n        }\n        if entry.MaxVersion != nil &amp;&amp; v.Compare(*entry.MaxVersion) &gt; 0 {\n            return false, fmt.Sprintf(\"version %s exceeds maximum %s\", v, entry.MaxVersion)\n        }\n        if entry.Deprecated {\n            return true, entry.Message // compatible but deprecated\n        }\n    }\n\n    return true, \"\"\n}\n\n// Negotiate finds the best compatible version from a list.\nfunc (m *Matrix) Negotiate(component string, available []Version) (Version, error) {\n    var best *Version\n\n    for _, v := range available {\n        compatible, _ := m.Check(component, v)\n        if compatible {\n            if best == nil || v.GreaterThan(*best) {\n                vCopy := v\n                best = &amp;vCopy\n            }\n        }\n    }\n\n    if best == nil {\n        return Version{}, fmt.Errorf(\"no compatible version found for %s\", component)\n    }\n\n    return *best, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#task-5-create-package-documentation","title":"Task 5: Create Package Documentation","text":"<p>File: <code>toolfoundation/version/doc.go</code></p> <pre><code>// Package version provides semantic versioning utilities for the ApertureStack ecosystem.\n//\n// This package handles version parsing, comparison, compatibility checking, and\n// version negotiation for tool and protocol versions.\n//\n// # Parsing Versions\n//\n// Parse semantic version strings:\n//\n//  v, err := version.Parse(\"1.2.3\")\n//  v, err := version.Parse(\"v2.0.0-beta.1+build.123\")\n//\n// # Comparing Versions\n//\n//  v1 := version.MustParse(\"1.0.0\")\n//  v2 := version.MustParse(\"2.0.0\")\n//\n//  v1.LessThan(v2)    // true\n//  v1.GreaterThan(v2) // false\n//  v1.Equal(v2)       // false\n//  v1.Compatible(v2)  // false (different major)\n//\n// # Version Constraints\n//\n// Parse and check version constraints:\n//\n//  c, _ := version.ParseConstraint(\"&gt;=1.0.0\")\n//  c.Check(version.MustParse(\"1.5.0\")) // true\n//  c.Check(version.MustParse(\"0.9.0\")) // false\n//\n// Supported constraint operators:\n//   - \"=\" or \"\" - exact match\n//   - \"&gt;\" - greater than\n//   - \"&gt;=\" - greater than or equal\n//   - \"&lt;\" - less than\n//   - \"&lt;=\" - less than or equal\n//   - \"^\" - compatible (same major)\n//   - \"~\" - approximately (same major.minor)\n//\n// # Compatibility Matrix\n//\n// Track version compatibility across components:\n//\n//  matrix := version.NewMatrix()\n//  matrix.Add(version.Compatibility{\n//      Component:  \"toolfoundation\",\n//      MinVersion: version.MustParse(\"0.1.0\"),\n//  })\n//\n//  ok, msg := matrix.Check(\"toolfoundation\", version.MustParse(\"0.2.0\"))\n//\n// # Version Negotiation\n//\n// Find the best compatible version from available options:\n//\n//  available := []version.Version{\n//      version.MustParse(\"1.0.0\"),\n//      version.MustParse(\"1.1.0\"),\n//      version.MustParse(\"2.0.0\"),\n//  }\n//  best, err := matrix.Negotiate(\"component\", available)\npackage version\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#task-6-create-tests","title":"Task 6: Create Tests","text":"<p>File: <code>toolfoundation/version/version_test.go</code></p> <pre><code>package version\n\nimport (\n    \"testing\"\n)\n\nfunc TestParse(t *testing.T) {\n    tests := []struct {\n        input   string\n        want    Version\n        wantErr bool\n    }{\n        {\"1.0.0\", Version{1, 0, 0, \"\", \"\"}, false},\n        {\"v1.0.0\", Version{1, 0, 0, \"\", \"\"}, false},\n        {\"1.2.3\", Version{1, 2, 3, \"\", \"\"}, false},\n        {\"1.0.0-alpha\", Version{1, 0, 0, \"alpha\", \"\"}, false},\n        {\"1.0.0-alpha.1\", Version{1, 0, 0, \"alpha.1\", \"\"}, false},\n        {\"1.0.0+build\", Version{1, 0, 0, \"\", \"build\"}, false},\n        {\"1.0.0-beta+build.123\", Version{1, 0, 0, \"beta\", \"build.123\"}, false},\n        {\"invalid\", Version{}, true},\n        {\"1.0\", Version{}, true},\n        {\"1\", Version{}, true},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.input, func(t *testing.T) {\n            got, err := Parse(tt.input)\n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Parse(%q) error = %v, wantErr %v\", tt.input, err, tt.wantErr)\n                return\n            }\n            if !tt.wantErr &amp;&amp; got != tt.want {\n                t.Errorf(\"Parse(%q) = %v, want %v\", tt.input, got, tt.want)\n            }\n        })\n    }\n}\n\nfunc TestVersion_Compare(t *testing.T) {\n    tests := []struct {\n        a, b string\n        want int\n    }{\n        {\"1.0.0\", \"1.0.0\", 0},\n        {\"1.0.0\", \"2.0.0\", -1},\n        {\"2.0.0\", \"1.0.0\", 1},\n        {\"1.0.0\", \"1.1.0\", -1},\n        {\"1.1.0\", \"1.0.0\", 1},\n        {\"1.0.0\", \"1.0.1\", -1},\n        {\"1.0.0-alpha\", \"1.0.0\", -1},\n        {\"1.0.0\", \"1.0.0-alpha\", 1},\n        {\"1.0.0-alpha\", \"1.0.0-beta\", -1},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.a+\"_vs_\"+tt.b, func(t *testing.T) {\n            a := MustParse(tt.a)\n            b := MustParse(tt.b)\n            if got := a.Compare(b); got != tt.want {\n                t.Errorf(\"%s.Compare(%s) = %d, want %d\", tt.a, tt.b, got, tt.want)\n            }\n        })\n    }\n}\n\nfunc TestVersion_Compatible(t *testing.T) {\n    tests := []struct {\n        a, b string\n        want bool\n    }{\n        {\"1.0.0\", \"1.0.0\", true},\n        {\"1.1.0\", \"1.0.0\", true},\n        {\"1.0.0\", \"1.1.0\", false}, // v &lt; other\n        {\"2.0.0\", \"1.0.0\", false}, // different major\n        {\"1.0.0\", \"2.0.0\", false}, // different major\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.a+\"_compat_\"+tt.b, func(t *testing.T) {\n            a := MustParse(tt.a)\n            b := MustParse(tt.b)\n            if got := a.Compatible(b); got != tt.want {\n                t.Errorf(\"%s.Compatible(%s) = %v, want %v\", tt.a, tt.b, got, tt.want)\n            }\n        })\n    }\n}\n\nfunc TestConstraint_Check(t *testing.T) {\n    tests := []struct {\n        constraint string\n        version    string\n        want       bool\n    }{\n        {\"1.0.0\", \"1.0.0\", true},\n        {\"=1.0.0\", \"1.0.0\", true},\n        {\"=1.0.0\", \"1.0.1\", false},\n        {\"&gt;1.0.0\", \"1.0.1\", true},\n        {\"&gt;1.0.0\", \"1.0.0\", false},\n        {\"&gt;=1.0.0\", \"1.0.0\", true},\n        {\"&gt;=1.0.0\", \"0.9.0\", false},\n        {\"&lt;2.0.0\", \"1.9.9\", true},\n        {\"&lt;2.0.0\", \"2.0.0\", false},\n        {\"&lt;=2.0.0\", \"2.0.0\", true},\n        {\"^1.0.0\", \"1.5.0\", true},\n        {\"^1.0.0\", \"2.0.0\", false},\n        {\"~1.0.0\", \"1.0.5\", true},\n        {\"~1.0.0\", \"1.1.0\", false},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.constraint+\"_\"+tt.version, func(t *testing.T) {\n            c, err := ParseConstraint(tt.constraint)\n            if err != nil {\n                t.Fatalf(\"ParseConstraint(%q) error: %v\", tt.constraint, err)\n            }\n            v := MustParse(tt.version)\n            if got := c.Check(v); got != tt.want {\n                t.Errorf(\"Constraint(%q).Check(%s) = %v, want %v\", tt.constraint, tt.version, got, tt.want)\n            }\n        })\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#task-7-build-and-test","title":"Task 7: Build and Test","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Tidy dependencies\ngo mod tidy\n\n# Build\ngo build ./...\n\n# Test with coverage\ngo test -v -coverprofile=version_coverage.out ./version/...\n\n# Check coverage (target: &gt;90%)\ngo tool cover -func=version_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd /tmp/migration/toolfoundation\n\ngit add -A\ngit commit -m \"feat(version): add semantic versioning package\n\nAdd new version package for semantic versioning and compatibility management.\n\nPackage contents:\n- Version parsing and comparison\n- Version constraint checking (&gt;=, &lt;=, ^, ~, etc.)\n- Compatibility matrix for component version tracking\n- Version negotiation for finding best compatible version\n\nFeatures:\n- Full semver 2.0 support (major.minor.patch-prerelease+build)\n- Constraint operators: =, &gt;, &gt;=, &lt;, &lt;=, ^, ~\n- Matrix-based compatibility checking\n- Deprecation tracking\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All source files created</li> <li>[x] <code>go build ./...</code> succeeds</li> <li>[x] <code>go test ./...</code> passes</li> <li>[x] Coverage &gt;= 90%</li> <li>[x] Package documentation complete</li> <li>[x] Committed with proper message</li> <li>[x] Pushed to main</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolfoundation/version</code> package builds successfully</li> <li>All tests pass with &gt;= 90% coverage</li> <li>Semver 2.0 parsing works correctly</li> <li>Constraint checking is accurate</li> <li>Compatibility matrix tracks versions correctly</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolfoundation/version/</code> contains version, constraint, compatibility types and tests.</li> <li><code>toolfoundation/version/doc.go</code> documents the package and usage.</li> <li><code>go test ./version/...</code> passes in <code>toolfoundation</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Remove version package\nrm -rf version/\n\n# Reset to previous state\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-122-create-toolversion/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G2: Foundation layer complete (all 3 packages)</li> <li>PRD-130: Migrate toolindex</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/","title":"PRD-123: toolfoundation Docs + README Alignment","text":"<p>Phase: 2 - Foundation Layer Priority: High Effort: 3 hours Dependencies: PRD-120, PRD-121, PRD-122 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#objective","title":"Objective","text":"<p>Align public-facing documentation with the consolidated <code>toolfoundation</code> API:</p> <ul> <li>Remove placeholders (README <code>TBD</code> entries).</li> <li>Ensure docs reflect the actual API (validator constructors, signatures).</li> <li>Add <code>version</code> package coverage in docs and user journey.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#scope","title":"Scope","text":"<p>In scope - <code>toolfoundation/README.md</code> - <code>toolfoundation/docs/index.md</code> - <code>toolfoundation/docs/user-journey.md</code></p> <p>Out of scope - API changes or behavior changes in code - New functionality beyond documentation</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#deliverables","title":"Deliverables","text":"Deliverable Location Description Updated README <code>toolfoundation/README.md</code> Package table + quick usage Updated index docs <code>toolfoundation/docs/index.md</code> Include <code>version</code> package + accurate API snippets Updated user journey <code>toolfoundation/docs/user-journey.md</code> Correct validator usage + version walkthrough"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#task-1-readme-package-table","title":"Task 1: README package table","text":"<ul> <li>Replace <code>TBD</code> with concrete package list:</li> <li><code>model</code></li> <li><code>adapter</code></li> <li><code>version</code></li> <li>Add short descriptions + link to <code>docs/</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#task-2-docsindexmd","title":"Task 2: docs/index.md","text":"<ul> <li>Add <code>version</code> package to Packages table.</li> <li>Add a short version example (Parse / Compare / Compatible).</li> <li>Ensure schema validation example uses <code>NewDefaultValidator</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#task-3-docsuser-journeymd","title":"Task 3: docs/user-journey.md","text":"<ul> <li>Fix schema validation snippet to use <code>NewDefaultValidator</code> and <code>ValidateInput(&amp;tool, input)</code>.</li> <li>Add a section showing version negotiation (compatibility matrix and constraints).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#task-4-verification","title":"Task 4: Verification","text":"<pre><code>cd toolfoundation\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>README has concrete package table (no <code>TBD</code>).</li> <li>Docs show <code>version</code> package in index + user journey.</li> <li>All snippets compile against current API.</li> <li><code>go test ./...</code> passes.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolfoundation/README.md</code> package table updated.</li> <li><code>toolfoundation/docs/index.md</code> includes <code>version</code> package + examples.</li> <li><code>toolfoundation/docs/user-journey.md</code> uses correct validator API.</li> <li><code>go test ./...</code> passes in <code>toolfoundation</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-123-toolfoundation-docs-alignment/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-124: Schema validation policy documentation</li> <li>PRD-125: Adapter feature matrix documentation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-124-toolfoundation-schema-policy/","title":"PRD-124: toolfoundation Schema Validation Policy","text":"<p>Phase: 2 - Foundation Layer Priority: Medium Effort: 2 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-124-toolfoundation-schema-policy/#objective","title":"Objective","text":"<p>Document the JSON Schema validation contract for <code>toolfoundation/model</code>:</p> <ul> <li>Supported dialects (2020-12, draft-07)</li> <li>External <code>$ref</code> handling policy (blocked)</li> <li>Validation limitations (format/content keywords)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-124-toolfoundation-schema-policy/#scope","title":"Scope","text":"<p>In scope - <code>toolfoundation/docs/design-notes.md</code> - <code>toolfoundation/docs/index.md</code></p> <p>Out of scope - Changing validation behavior - Adding new validation libraries</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-124-toolfoundation-schema-policy/#deliverables","title":"Deliverables","text":"Deliverable Location Description Schema policy notes <code>docs/design-notes.md</code> Dialects + external ref policy + limitations Public summary <code>docs/index.md</code> Short section linking to design notes"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-124-toolfoundation-schema-policy/#tasks","title":"Tasks","text":"<ol> <li>Add a \u201cSchema Validation Policy\u201d section to <code>docs/design-notes.md</code>.</li> <li>Add a short summary in <code>docs/index.md</code> with a link to the policy section.</li> <li>Verify examples remain accurate.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-124-toolfoundation-schema-policy/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Supported dialects and limitations are explicitly documented.</li> <li>External <code>$ref</code> policy is stated.</li> <li>Docs are consistent with <code>model/validator.go</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-124-toolfoundation-schema-policy/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Schema policy documented in <code>toolfoundation/docs/design-notes.md</code>.</li> <li>Summary added to <code>toolfoundation/docs/index.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-124-toolfoundation-schema-policy/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-125: Adapter feature matrix documentation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-125-toolfoundation-adapter-matrix/","title":"PRD-125: toolfoundation Adapter Feature Matrix Docs","text":"<p>Phase: 2 - Foundation Layer Priority: Medium Effort: 2 hours Dependencies: PRD-121 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-125-toolfoundation-adapter-matrix/#objective","title":"Objective","text":"<p>Document adapter feature support and loss semantics for <code>toolfoundation/adapter</code>:</p> <ul> <li>Supported schema features by target format</li> <li>How <code>FeatureLossWarning</code> is generated</li> <li>Guidance for consumers on safe conversions</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-125-toolfoundation-adapter-matrix/#scope","title":"Scope","text":"<p>In scope - <code>toolfoundation/docs/design-notes.md</code> - <code>toolfoundation/docs/index.md</code></p> <p>Out of scope - Changing adapter behavior - Adding new adapters</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-125-toolfoundation-adapter-matrix/#deliverables","title":"Deliverables","text":"Deliverable Location Description Feature matrix <code>docs/design-notes.md</code> Table of features by adapter Warnings guidance <code>docs/design-notes.md</code> How to interpret <code>FeatureLossWarning</code> Public summary <code>docs/index.md</code> Short summary with link"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-125-toolfoundation-adapter-matrix/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Feature matrix is present and aligns with adapter implementation.</li> <li>Warning semantics are documented with an example.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-125-toolfoundation-adapter-matrix/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Feature matrix + warning semantics documented in <code>toolfoundation/docs/design-notes.md</code>.</li> <li>Summary link added in <code>toolfoundation/docs/index.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-125-toolfoundation-adapter-matrix/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-126: Version package usage docs</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-126-toolfoundation-version-usage/","title":"PRD-126: toolfoundation Version Package Usage Docs","text":"<p>Phase: 2 - Foundation Layer Priority: Medium Effort: 2 hours Dependencies: PRD-122 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-126-toolfoundation-version-usage/#objective","title":"Objective","text":"<p>Publish usage guidance for <code>toolfoundation/version</code>:</p> <ul> <li>Semantic version parsing and comparison</li> <li>Constraints (<code>&gt;=</code>, <code>^</code>, <code>~</code>)</li> <li>Compatibility matrix + negotiation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-126-toolfoundation-version-usage/#scope","title":"Scope","text":"<p>In scope - <code>toolfoundation/docs/index.md</code> - <code>toolfoundation/docs/user-journey.md</code></p> <p>Out of scope - Changing version semantics</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-126-toolfoundation-version-usage/#deliverables","title":"Deliverables","text":"Deliverable Location Description Version example <code>docs/index.md</code> Parse/Compare/Compatible usage Compatibility example <code>docs/user-journey.md</code> Matrix + negotiate example"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-126-toolfoundation-version-usage/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Version package is documented in both index and user journey.</li> <li>Examples compile against current API.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-126-toolfoundation-version-usage/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>version</code> examples added to <code>toolfoundation/docs/index.md</code>.</li> <li>Compatibility example added to <code>toolfoundation/docs/user-journey.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-126-toolfoundation-version-usage/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-127: Contract verification</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-127-toolfoundation-contracts/","title":"PRD-127: toolfoundation Contract Verification","text":"<p>Phase: 2 - Foundation Layer Priority: Medium Effort: 1 hour Dependencies: PRD-120, PRD-121 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-127-toolfoundation-contracts/#objective","title":"Objective","text":"<p>Verify interface contracts in <code>toolfoundation</code> are explicitly documented and enforced with tests.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-127-toolfoundation-contracts/#deliverables","title":"Deliverables","text":"Deliverable Location Description SchemaValidator contract test <code>model/schema_validator_contract_test.go</code> Ensures validator behavior contract Adapter contract test <code>adapter/adapter_contract_test.go</code> Ensures adapter interface contract GoDoc contracts <code>model/validator.go</code>, <code>adapter/adapter.go</code> Contract comments present"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-127-toolfoundation-contracts/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>model/SchemaValidator</code> has explicit contract in GoDoc and contract tests.</li> <li><code>adapter/Adapter</code> has explicit contract in GoDoc and contract tests.</li> <li><code>go test ./...</code> passes in <code>toolfoundation</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-128-toolfoundation-release-propagation/","title":"PRD-128: toolfoundation Release + Version Propagation","text":"<p>Phase: 2 - Foundation Layer Priority: Medium Effort: 1 hour Dependencies: PRD-122 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-128-toolfoundation-release-propagation/#objective","title":"Objective","text":"<p>Ensure <code>toolfoundation</code> is tagged and propagated into the stack version matrix.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-128-toolfoundation-release-propagation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Module tag <code>toolfoundation</code> <code>v0.1.0</code> tag exists Version matrix entry <code>ai-tools-stack/VERSIONS.md</code> toolfoundation row present go.mod alignment <code>ai-tools-stack/go.mod</code> toolfoundation dependency pinned"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-128-toolfoundation-release-propagation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>ai-tools-stack/VERSIONS.md</code> lists <code>toolfoundation v0.1.0</code>.</li> <li><code>ai-tools-stack/go.mod</code> includes <code>github.com/jonwraymond/toolfoundation v0.1.0</code>.</li> <li>toolfoundation tag <code>v0.1.0</code> present.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-129-toolfoundation-g2-validation/","title":"PRD-129: toolfoundation G2 Validation","text":"<p>Phase: 2 - Foundation Layer Priority: High Effort: 1 hour Dependencies: PRD-120, PRD-121, PRD-122 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-129-toolfoundation-g2-validation/#objective","title":"Objective","text":"<p>Confirm the Foundation layer meets Gate G2 requirements:</p> <ul> <li>All three packages (<code>model</code>, <code>adapter</code>, <code>version</code>) compile and pass tests</li> <li>Linting passes</li> <li>Documentation exists for each package</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-129-toolfoundation-g2-validation/#verification-steps","title":"Verification Steps","text":"<pre><code>cd toolfoundation\n\ngo test ./...\n\ngolangci-lint run\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-129-toolfoundation-g2-validation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>go test ./...</code> passes in <code>toolfoundation</code>.</li> <li><code>golangci-lint run</code> passes in <code>toolfoundation</code>.</li> <li>Package docs exist: <code>model/doc.go</code>, <code>adapter/doc.go</code>, <code>version/doc.go</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/","title":"PRD-130: Migrate toolindex","text":"<p>Phase: 3 - Discovery Layer Priority: Critical Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolindex</code> repository into <code>tooldiscovery/index/</code> as the first package in the consolidated discovery layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolindex</code> Target Location: <code>github.com/jonwraymond/tooldiscovery/index</code></p> <p>Package Contents: - Tool registry with CRUD operations - In-memory and file-based index implementations - Searcher interface for pluggable search backends - Progressive disclosure support - ~3,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#deliverables","title":"Deliverables","text":"Deliverable Location Description Index Package <code>tooldiscovery/index/</code> Tool registry implementation Tests <code>tooldiscovery/index/*_test.go</code> All existing tests Documentation <code>tooldiscovery/index/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#task-1-prepare-target-repository","title":"Task 1: Prepare Target Repository","text":"<pre><code># Clone/create target\ncd /tmp/migration\ngit clone git@github.com:jonwraymond/tooldiscovery.git\ncd tooldiscovery\n\n# Create index directory\nmkdir -p index\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#task-2-clone-and-analyze-source","title":"Task 2: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolindex.git\ncd toolindex\n\n# Analyze contents\nls -la\nwc -l *.go\ngo test ./... -v\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#task-3-copy-source-files","title":"Task 3: Copy Source Files","text":"<pre><code>cd /tmp/migration\n\n# Copy Go source files\ncp toolindex/*.go tooldiscovery/index/\n\n# Verify\nls -la tooldiscovery/index/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#task-4-update-import-paths","title":"Task 4: Update Import Paths","text":"<pre><code>cd /tmp/migration/tooldiscovery/index\n\n# Update toolindex import\nOLD_IMPORT=\"github.com/jonwraymond/toolindex\"\nNEW_IMPORT=\"github.com/jonwraymond/tooldiscovery/index\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\ndone\n\n# Update toolmodel to toolfoundation/model\nOLD_MODEL=\"github.com/jonwraymond/toolmodel\"\nNEW_MODEL=\"github.com/jonwraymond/toolfoundation/model\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_MODEL|$NEW_MODEL|g\" \"$file\"\ndone\n\n# Verify\ngrep -r \"jonwraymond/toolindex\\|jonwraymond/toolmodel\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#task-5-update-gomod","title":"Task 5: Update go.mod","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\n# Add dependency on toolfoundation\ncat &gt;&gt; go.mod &lt;&lt; EOF\nrequire github.com/jonwraymond/toolfoundation v0.1.0\nEOF\n\ngo mod tidy\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#task-6-update-package-documentation","title":"Task 6: Update Package Documentation","text":"<p>File: <code>tooldiscovery/index/doc.go</code></p> <pre><code>// Package index provides the core tool registry for the ApertureStack ecosystem.\n//\n// This package implements tool registration, storage, retrieval, and search\n// capabilities. It supports multiple index backends and pluggable search strategies.\n//\n// # Index Types\n//\n// The package provides two built-in index implementations:\n//\n//   - InMemoryIndex: Fast, ephemeral storage for development and testing\n//   - FileIndex: Persistent JSON-based storage for single-node deployments\n//\n// # Usage\n//\n// Create and populate an index:\n//\n//  idx := index.NewInMemoryIndex(index.Options{})\n//\n//  tool := model.Tool{\n//      ID:          \"calculator\",\n//      Name:        \"Calculator\",\n//      Description: \"Performs arithmetic\",\n//  }\n//  err := idx.Add(ctx, tool)\n//\n// Search for tools:\n//\n//  results, err := idx.Search(ctx, \"arithmetic\")\n//\n// # Pluggable Search\n//\n// The index accepts a custom Searcher for advanced search capabilities:\n//\n//  searcher := search.NewBM25Searcher(config)\n//  idx := index.NewInMemoryIndex(index.Options{\n//      Searcher: searcher,\n//  })\n//\n// # Progressive Disclosure\n//\n// Tools support three disclosure levels:\n//\n//   - Summary: ID, name, description only\n//   - Schema: Includes input/output schemas\n//   - Full: Complete tool definition with examples\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolindex as part of\n// the ApertureStack consolidation.\npackage index\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#task-7-build-and-test","title":"Task 7: Build and Test","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=coverage.out ./index/...\n\n# Check coverage\ngo tool cover -func=coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngit add -A\ngit commit -m \"feat(index): migrate toolindex package\n\nMigrate the tool registry from standalone toolindex repository.\n\nPackage contents:\n- Index interface with CRUD operations\n- InMemoryIndex for ephemeral storage\n- FileIndex for persistent storage\n- Pluggable Searcher interface\n- Progressive disclosure support\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolindex \u2192 tooldiscovery/index\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#key-interfaces","title":"Key Interfaces","text":"<p>The migrated package should expose these key interfaces:</p> <pre><code>package index\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Index provides tool storage and retrieval.\ntype Index interface {\n    // Add registers a tool in the index.\n    Add(ctx context.Context, tool model.Tool) error\n\n    // Get retrieves a tool by ID.\n    Get(ctx context.Context, id string) (model.Tool, error)\n\n    // Remove deletes a tool from the index.\n    Remove(ctx context.Context, id string) error\n\n    // List returns all tools.\n    List(ctx context.Context) ([]model.Tool, error)\n\n    // Search finds tools matching the query.\n    Search(ctx context.Context, query string) ([]model.Tool, error)\n\n    // Count returns the number of tools.\n    Count(ctx context.Context) (int, error)\n}\n\n// Searcher defines the search strategy interface.\ntype Searcher interface {\n    // Search searches for tools matching the query.\n    Search(ctx context.Context, tools []model.Tool, query string) ([]model.Tool, error)\n}\n\n// Options configures index behavior.\ntype Options struct {\n    Searcher Searcher\n    MaxTools int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All source files copied</li> <li>[x] Import paths updated</li> <li>[x] Dependency on toolfoundation works</li> <li>[x] <code>go build ./...</code> succeeds</li> <li>[x] <code>go test ./...</code> passes</li> <li>[x] Package documentation updated</li> <li>[x] Committed with proper message</li> <li>[x] Pushed to main</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>tooldiscovery/index</code> package builds successfully</li> <li>All tests pass</li> <li>Can import from <code>toolfoundation/model</code></li> <li>Index and Searcher interfaces preserved</li> <li>Progressive disclosure works</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>tooldiscovery/index/</code> contains migrated sources and tests.</li> <li><code>tooldiscovery/index/doc.go</code> documents the package.</li> <li><code>go test ./index/...</code> passes in <code>tooldiscovery</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/tooldiscovery\nrm -rf index/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-130-migrate-toolindex/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-131: Migrate toolsearch</li> <li>PRD-132: Migrate toolsemantic</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/","title":"PRD-131: Migrate toolsearch","text":"<p>Phase: 3 - Discovery Layer Priority: High Effort: 4 hours Dependencies: PRD-130 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolsearch</code> repository into <code>tooldiscovery/search/</code> as the second package in the consolidated discovery layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolsearch</code> Target Location: <code>github.com/jonwraymond/tooldiscovery/search</code></p> <p>Package Contents: - BM25 search implementation using Bleve - Fingerprint-based index caching - Configurable field boosting - ~1,500 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#deliverables","title":"Deliverables","text":"Deliverable Location Description Search Package <code>tooldiscovery/search/</code> BM25 search implementation Tests <code>tooldiscovery/search/*_test.go</code> All existing tests Documentation <code>tooldiscovery/search/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#task-1-clone-and-analyze-source","title":"Task 1: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolsearch.git\ncd toolsearch\n\n# Analyze\nls -la\nwc -l *.go\ngo test ./... -v\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#task-2-copy-source-files","title":"Task 2: Copy Source Files","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\nmkdir -p search\ncp ../toolsearch/*.go search/\n\nls -la search/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#task-3-update-import-paths","title":"Task 3: Update Import Paths","text":"<pre><code>cd /tmp/migration/tooldiscovery/search\n\n# Update self-reference\nOLD_IMPORT=\"github.com/jonwraymond/toolsearch\"\nNEW_IMPORT=\"github.com/jonwraymond/tooldiscovery/search\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\ndone\n\n# Update toolindex to tooldiscovery/index\nOLD_INDEX=\"github.com/jonwraymond/toolindex\"\nNEW_INDEX=\"github.com/jonwraymond/tooldiscovery/index\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_INDEX|$NEW_INDEX|g\" \"$file\"\ndone\n\n# Update toolmodel to toolfoundation/model\nOLD_MODEL=\"github.com/jonwraymond/toolmodel\"\nNEW_MODEL=\"github.com/jonwraymond/toolfoundation/model\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_MODEL|$NEW_MODEL|g\" \"$file\"\ndone\n\n# Verify\ngrep -r \"jonwraymond/toolsearch\\|jonwraymond/toolindex\\|jonwraymond/toolmodel\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#task-4-update-package-documentation","title":"Task 4: Update Package Documentation","text":"<p>File: <code>tooldiscovery/search/doc.go</code></p> <pre><code>// Package search provides BM25-based full-text search for tool discovery.\n//\n// This package implements a high-quality search strategy using the BM25 algorithm\n// via the Bleve search library. It integrates with tooldiscovery/index via the\n// Searcher interface.\n//\n// # Features\n//\n//   - BM25 ranking algorithm for relevance scoring\n//   - Fingerprint-based index caching for efficiency\n//   - Configurable field boosting\n//   - MaxDocs limiting for resource bounds\n//   - Text length truncation\n//\n// # Usage\n//\n// Create a BM25 searcher and inject into index:\n//\n//  searcher := search.NewBM25Searcher(search.Config{\n//      NameBoost:        2.0,\n//      DescriptionBoost: 1.0,\n//      MaxDocs:          1000,\n//      MaxDocTextLen:    10000,\n//  })\n//\n//  idx := index.NewInMemoryIndex(index.Options{\n//      Searcher: searcher,\n//  })\n//\n// # BM25 Behavior\n//\n// The searcher provides three guarantees:\n//\n//   - Deterministic: Sorted by ID before indexing, consistent tie-breaking\n//   - Efficient: Fingerprint-based caching, rebuild only when tools change\n//   - Bounded: MaxDocs and MaxDocTextLen prevent resource exhaustion\n//\n// # Configuration\n//\n//  type Config struct {\n//      NameBoost        float64 // Boost for name field (default: 2.0)\n//      DescriptionBoost float64 // Boost for description (default: 1.0)\n//      TagBoost         float64 // Boost for tags (default: 1.5)\n//      MaxDocs          int     // Maximum indexed documents\n//      MaxDocTextLen    int     // Maximum text length per field\n//  }\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolsearch as part of\n// the ApertureStack consolidation.\npackage search\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#task-5-verify-bleve-dependency","title":"Task 5: Verify Bleve Dependency","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\n# Check for Bleve import\ngrep -r \"blevesearch/bleve\" search/*.go\n\n# Add to go.mod if needed\ngo get github.com/blevesearch/bleve/v2\ngo mod tidy\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngo build ./...\ngo test -v -coverprofile=search_coverage.out ./search/...\n\n# Check coverage\ngo tool cover -func=search_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngit add -A\ngit commit -m \"feat(search): migrate toolsearch package\n\nMigrate BM25 search implementation from standalone toolsearch repository.\n\nPackage contents:\n- BM25Searcher implementing index.Searcher interface\n- Fingerprint-based index caching\n- Configurable field boosting\n- MaxDocs and MaxDocTextLen bounds\n\nDependencies:\n- github.com/blevesearch/bleve/v2\n- github.com/jonwraymond/toolfoundation/model\n- github.com/jonwraymond/tooldiscovery/index (interface only)\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolsearch \u2192 tooldiscovery/search\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#key-types","title":"Key Types","text":"<pre><code>package search\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Config configures the BM25 searcher.\ntype Config struct {\n    NameBoost        float64\n    DescriptionBoost float64\n    TagBoost         float64\n    MaxDocs          int\n    MaxDocTextLen    int\n    CacheDir         string\n}\n\n// BM25Searcher implements index.Searcher using BM25 algorithm.\ntype BM25Searcher struct {\n    config      Config\n    fingerprint string\n    index       bleve.Index\n    mu          sync.RWMutex\n}\n\n// NewBM25Searcher creates a new BM25 searcher.\nfunc NewBM25Searcher(config Config) *BM25Searcher\n\n// Search implements index.Searcher.\nfunc (s *BM25Searcher) Search(ctx context.Context, tools []model.Tool, query string) ([]model.Tool, error)\n\n// Fingerprint returns the current document fingerprint.\nfunc (s *BM25Searcher) Fingerprint() string\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All source files copied</li> <li>[x] Import paths updated (search, index, model)</li> <li>[x] Bleve dependency resolved</li> <li>[x] <code>go build ./...</code> succeeds</li> <li>[x] <code>go test ./...</code> passes</li> <li>[x] Fingerprint caching works</li> <li>[x] Package documentation updated</li> <li>[x] Committed with proper message</li> <li>[x] Pushed to main</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>tooldiscovery/search</code> package builds successfully</li> <li>All tests pass</li> <li>BM25 search returns relevant results</li> <li>Fingerprint caching is efficient</li> <li>Implements <code>index.Searcher</code> interface</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>tooldiscovery/search/</code> contains migrated sources and tests.</li> <li><code>tooldiscovery/search/doc.go</code> documents the package.</li> <li><code>go test ./search/...</code> passes in <code>tooldiscovery</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/tooldiscovery\nrm -rf search/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-131-migrate-toolsearch/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-132: Migrate toolsemantic</li> <li>PRD-133: Migrate tooldocs</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/","title":"PRD-132: Migrate toolsemantic","text":"<p>Phase: 3 - Discovery Layer Priority: High Effort: 6 hours Dependencies: PRD-131 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#objective","title":"Objective","text":"<p>Migrate and complete the partial <code>toolsemantic</code> implementation into <code>tooldiscovery/semantic/</code> for vector-based semantic search capabilities.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolsemantic</code> (partial implementation) Target Location: <code>github.com/jonwraymond/tooldiscovery/semantic</code></p> <p>Current State: - Partial implementation with interfaces defined - Embedder interface for text-to-vector conversion - Vector index interface for similarity search - Needs completion: actual implementations</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#deliverables","title":"Deliverables","text":"Deliverable Location Description Semantic Package <code>tooldiscovery/semantic/</code> Vector search implementation Embedder Interface <code>semantic/embedder.go</code> Text embedding abstraction Vector Index <code>semantic/index.go</code> Vector similarity search Hybrid Searcher <code>semantic/hybrid.go</code> Combined BM25 + vector search Tests <code>semantic/*_test.go</code> Comprehensive tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#task-1-create-package-structure","title":"Task 1: Create Package Structure","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\nmkdir -p semantic\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#task-2-copy-existing-code","title":"Task 2: Copy Existing Code","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolsemantic.git\ncd toolsemantic\n\n# Copy existing files\ncp *.go ../tooldiscovery/semantic/\n\n# Update imports\ncd ../tooldiscovery/semantic\nsed -i '' 's|github.com/jonwraymond/toolsemantic|github.com/jonwraymond/tooldiscovery/semantic|g' *.go\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#task-3-define-core-interfaces","title":"Task 3: Define Core Interfaces","text":"<p>File: <code>tooldiscovery/semantic/embedder.go</code></p> <pre><code>package semantic\n\nimport \"context\"\n\n// Embedder converts text to vector embeddings.\ntype Embedder interface {\n    // Embed converts text to a vector embedding.\n    Embed(ctx context.Context, text string) ([]float32, error)\n\n    // EmbedBatch converts multiple texts to embeddings.\n    EmbedBatch(ctx context.Context, texts []string) ([][]float32, error)\n\n    // Dimension returns the embedding dimension.\n    Dimension() int\n\n    // Name returns the embedder name (e.g., \"openai\", \"cohere\").\n    Name() string\n}\n\n// EmbedderConfig is the base configuration for embedders.\ntype EmbedderConfig struct {\n    Model     string\n    Dimension int\n    BatchSize int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#task-4-define-vector-index-interface","title":"Task 4: Define Vector Index Interface","text":"<p>File: <code>tooldiscovery/semantic/index.go</code></p> <pre><code>package semantic\n\nimport (\n    \"context\"\n)\n\n// VectorIndex stores and searches vector embeddings.\ntype VectorIndex interface {\n    // Add adds a vector with its ID.\n    Add(ctx context.Context, id string, vector []float32) error\n\n    // AddBatch adds multiple vectors.\n    AddBatch(ctx context.Context, ids []string, vectors [][]float32) error\n\n    // Search finds the k most similar vectors to the query.\n    Search(ctx context.Context, query []float32, k int) ([]SearchResult, error)\n\n    // Remove deletes a vector by ID.\n    Remove(ctx context.Context, id string) error\n\n    // Count returns the number of vectors.\n    Count(ctx context.Context) (int, error)\n}\n\n// SearchResult represents a similarity search result.\ntype SearchResult struct {\n    ID       string\n    Score    float32\n    Distance float32\n}\n\n// VectorIndexConfig configures the vector index.\ntype VectorIndexConfig struct {\n    Dimension    int\n    Metric       string // \"cosine\", \"euclidean\", \"dot\"\n    MaxElements  int\n    EfSearch     int // HNSW search parameter\n    EfConstruct  int // HNSW construction parameter\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#task-5-implement-in-memory-vector-index","title":"Task 5: Implement In-Memory Vector Index","text":"<p>File: <code>tooldiscovery/semantic/memory_index.go</code></p> <pre><code>package semantic\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"math\"\n    \"sort\"\n    \"sync\"\n)\n\n// MemoryVectorIndex is an in-memory vector index using brute-force search.\n// Suitable for small to medium datasets (&lt;10k vectors).\ntype MemoryVectorIndex struct {\n    vectors   map[string][]float32\n    dimension int\n    metric    string\n    mu        sync.RWMutex\n}\n\n// NewMemoryVectorIndex creates a new in-memory vector index.\nfunc NewMemoryVectorIndex(config VectorIndexConfig) *MemoryVectorIndex {\n    return &amp;MemoryVectorIndex{\n        vectors:   make(map[string][]float32),\n        dimension: config.Dimension,\n        metric:    config.Metric,\n    }\n}\n\nfunc (m *MemoryVectorIndex) Add(ctx context.Context, id string, vector []float32) error {\n    if len(vector) != m.dimension {\n        return fmt.Errorf(\"expected dimension %d, got %d\", m.dimension, len(vector))\n    }\n    m.mu.Lock()\n    defer m.mu.Unlock()\n    m.vectors[id] = vector\n    return nil\n}\n\nfunc (m *MemoryVectorIndex) AddBatch(ctx context.Context, ids []string, vectors [][]float32) error {\n    if len(ids) != len(vectors) {\n        return fmt.Errorf(\"ids and vectors length mismatch\")\n    }\n    for i, id := range ids {\n        if err := m.Add(ctx, id, vectors[i]); err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\nfunc (m *MemoryVectorIndex) Search(ctx context.Context, query []float32, k int) ([]SearchResult, error) {\n    m.mu.RLock()\n    defer m.mu.RUnlock()\n\n    results := make([]SearchResult, 0, len(m.vectors))\n    for id, vector := range m.vectors {\n        score := m.similarity(query, vector)\n        results = append(results, SearchResult{\n            ID:    id,\n            Score: score,\n        })\n    }\n\n    sort.Slice(results, func(i, j int) bool {\n        return results[i].Score &gt; results[j].Score\n    })\n\n    if k &lt; len(results) {\n        results = results[:k]\n    }\n    return results, nil\n}\n\nfunc (m *MemoryVectorIndex) Remove(ctx context.Context, id string) error {\n    m.mu.Lock()\n    defer m.mu.Unlock()\n    delete(m.vectors, id)\n    return nil\n}\n\nfunc (m *MemoryVectorIndex) Count(ctx context.Context) (int, error) {\n    m.mu.RLock()\n    defer m.mu.RUnlock()\n    return len(m.vectors), nil\n}\n\nfunc (m *MemoryVectorIndex) similarity(a, b []float32) float32 {\n    switch m.metric {\n    case \"cosine\":\n        return cosineSimilarity(a, b)\n    case \"dot\":\n        return dotProduct(a, b)\n    default:\n        return cosineSimilarity(a, b)\n    }\n}\n\nfunc cosineSimilarity(a, b []float32) float32 {\n    var dot, normA, normB float32\n    for i := range a {\n        dot += a[i] * b[i]\n        normA += a[i] * a[i]\n        normB += b[i] * b[i]\n    }\n    if normA == 0 || normB == 0 {\n        return 0\n    }\n    return dot / (float32(math.Sqrt(float64(normA))) * float32(math.Sqrt(float64(normB))))\n}\n\nfunc dotProduct(a, b []float32) float32 {\n    var dot float32\n    for i := range a {\n        dot += a[i] * b[i]\n    }\n    return dot\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#task-6-implement-hybrid-searcher","title":"Task 6: Implement Hybrid Searcher","text":"<p>File: <code>tooldiscovery/semantic/hybrid.go</code></p> <pre><code>package semantic\n\nimport (\n    \"context\"\n    \"sort\"\n\n    \"github.com/jonwraymond/toolfoundation/model\"\n    \"github.com/jonwraymond/tooldiscovery/index\"\n)\n\n// HybridSearcher combines BM25 and semantic search.\ntype HybridSearcher struct {\n    bm25Searcher   index.Searcher\n    embedder       Embedder\n    vectorIndex    VectorIndex\n    bm25Weight     float32\n    semanticWeight float32\n}\n\n// HybridConfig configures the hybrid searcher.\ntype HybridConfig struct {\n    BM25Searcher   index.Searcher\n    Embedder       Embedder\n    VectorIndex    VectorIndex\n    BM25Weight     float32 // default: 0.5\n    SemanticWeight float32 // default: 0.5\n}\n\n// NewHybridSearcher creates a hybrid BM25 + semantic searcher.\nfunc NewHybridSearcher(config HybridConfig) *HybridSearcher {\n    bm25Weight := config.BM25Weight\n    semanticWeight := config.SemanticWeight\n    if bm25Weight == 0 &amp;&amp; semanticWeight == 0 {\n        bm25Weight = 0.5\n        semanticWeight = 0.5\n    }\n\n    return &amp;HybridSearcher{\n        bm25Searcher:   config.BM25Searcher,\n        embedder:       config.Embedder,\n        vectorIndex:    config.VectorIndex,\n        bm25Weight:     bm25Weight,\n        semanticWeight: semanticWeight,\n    }\n}\n\n// Search performs hybrid search combining BM25 and semantic results.\nfunc (h *HybridSearcher) Search(ctx context.Context, tools []model.Tool, query string) ([]model.Tool, error) {\n    // Index tools if needed\n    if err := h.indexTools(ctx, tools); err != nil {\n        return nil, err\n    }\n\n    // Get BM25 results\n    bm25Results, err := h.bm25Searcher.Search(ctx, tools, query)\n    if err != nil {\n        return nil, err\n    }\n\n    // Get semantic results\n    queryVec, err := h.embedder.Embed(ctx, query)\n    if err != nil {\n        return nil, err\n    }\n\n    semanticResults, err := h.vectorIndex.Search(ctx, queryVec, len(tools))\n    if err != nil {\n        return nil, err\n    }\n\n    // Combine results using reciprocal rank fusion\n    return h.fuseResults(tools, bm25Results, semanticResults), nil\n}\n\nfunc (h *HybridSearcher) indexTools(ctx context.Context, tools []model.Tool) error {\n    count, _ := h.vectorIndex.Count(ctx)\n    if count &gt;= len(tools) {\n        return nil // Already indexed\n    }\n\n    texts := make([]string, len(tools))\n    ids := make([]string, len(tools))\n    for i, tool := range tools {\n        texts[i] = tool.Name + \" \" + tool.Description\n        ids[i] = tool.ID\n    }\n\n    vectors, err := h.embedder.EmbedBatch(ctx, texts)\n    if err != nil {\n        return err\n    }\n\n    return h.vectorIndex.AddBatch(ctx, ids, vectors)\n}\n\nfunc (h *HybridSearcher) fuseResults(tools []model.Tool, bm25Results []model.Tool, semanticResults []SearchResult) []model.Tool {\n    // Reciprocal Rank Fusion\n    const k = 60.0 // RRF constant\n\n    scores := make(map[string]float32)\n\n    // BM25 scores\n    for i, tool := range bm25Results {\n        rank := float32(i + 1)\n        scores[tool.ID] += h.bm25Weight * (1.0 / (k + rank))\n    }\n\n    // Semantic scores\n    for i, result := range semanticResults {\n        rank := float32(i + 1)\n        scores[result.ID] += h.semanticWeight * (1.0 / (k + rank))\n    }\n\n    // Sort by combined score\n    type scored struct {\n        tool  model.Tool\n        score float32\n    }\n    toolMap := make(map[string]model.Tool)\n    for _, t := range tools {\n        toolMap[t.ID] = t\n    }\n\n    results := make([]scored, 0, len(scores))\n    for id, score := range scores {\n        if tool, ok := toolMap[id]; ok {\n            results = append(results, scored{tool, score})\n        }\n    }\n\n    sort.Slice(results, func(i, j int) bool {\n        return results[i].score &gt; results[j].score\n    })\n\n    output := make([]model.Tool, len(results))\n    for i, r := range results {\n        output[i] = r.tool\n    }\n    return output\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#task-7-create-package-documentation","title":"Task 7: Create Package Documentation","text":"<p>File: <code>tooldiscovery/semantic/doc.go</code></p> <pre><code>// Package semantic provides vector-based semantic search for tool discovery.\n//\n// This package enables semantic similarity search using vector embeddings,\n// complementing the BM25 keyword search in tooldiscovery/search.\n//\n// # Components\n//\n//   - Embedder: Converts text to vector embeddings\n//   - VectorIndex: Stores and searches vector embeddings\n//   - HybridSearcher: Combines BM25 and semantic search\n//\n// # Usage\n//\n// Create a hybrid searcher:\n//\n//  embedder := openai.NewEmbedder(apiKey)\n//  vectorIndex := semantic.NewMemoryVectorIndex(semantic.VectorIndexConfig{\n//      Dimension: 1536,\n//      Metric:    \"cosine\",\n//  })\n//  bm25 := search.NewBM25Searcher(search.Config{})\n//\n//  hybrid := semantic.NewHybridSearcher(semantic.HybridConfig{\n//      BM25Searcher:   bm25,\n//      Embedder:       embedder,\n//      VectorIndex:    vectorIndex,\n//      BM25Weight:     0.5,\n//      SemanticWeight: 0.5,\n//  })\n//\n// # Fusion Strategy\n//\n// The hybrid searcher uses Reciprocal Rank Fusion (RRF) to combine results:\n//\n//  score(d) = \u03a3(weight_i / (k + rank_i(d)))\n//\n// This produces robust rankings without score normalization.\n//\n// # Embedder Implementations\n//\n// The package defines the Embedder interface. Implementations are provided\n// separately to avoid API key dependencies:\n//\n//   - OpenAI: text-embedding-3-small/large\n//   - Cohere: embed-english-v3\n//   - Local: sentence-transformers via gRPC\n//\n// # Migration Note\n//\n// This package consolidates and completes the partial toolsemantic\n// implementation as part of the ApertureStack consolidation.\npackage semantic\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#task-8-create-tests","title":"Task 8: Create Tests","text":"<p>File: <code>tooldiscovery/semantic/semantic_test.go</code></p> <pre><code>package semantic\n\nimport (\n    \"context\"\n    \"testing\"\n)\n\nfunc TestMemoryVectorIndex(t *testing.T) {\n    ctx := context.Background()\n    idx := NewMemoryVectorIndex(VectorIndexConfig{\n        Dimension: 3,\n        Metric:    \"cosine\",\n    })\n\n    // Add vectors\n    err := idx.Add(ctx, \"a\", []float32{1, 0, 0})\n    if err != nil {\n        t.Fatal(err)\n    }\n    err = idx.Add(ctx, \"b\", []float32{0, 1, 0})\n    if err != nil {\n        t.Fatal(err)\n    }\n    err = idx.Add(ctx, \"c\", []float32{0.9, 0.1, 0})\n    if err != nil {\n        t.Fatal(err)\n    }\n\n    // Search for similar to a\n    results, err := idx.Search(ctx, []float32{1, 0, 0}, 2)\n    if err != nil {\n        t.Fatal(err)\n    }\n\n    if len(results) != 2 {\n        t.Errorf(\"expected 2 results, got %d\", len(results))\n    }\n    if results[0].ID != \"a\" {\n        t.Errorf(\"expected first result to be 'a', got '%s'\", results[0].ID)\n    }\n    if results[1].ID != \"c\" {\n        t.Errorf(\"expected second result to be 'c', got '%s'\", results[1].ID)\n    }\n}\n\nfunc TestCosineSimilarity(t *testing.T) {\n    tests := []struct {\n        a, b []float32\n        want float32\n    }{\n        {[]float32{1, 0}, []float32{1, 0}, 1.0},\n        {[]float32{1, 0}, []float32{0, 1}, 0.0},\n        {[]float32{1, 0}, []float32{-1, 0}, -1.0},\n    }\n\n    for _, tt := range tests {\n        got := cosineSimilarity(tt.a, tt.b)\n        if got != tt.want {\n            t.Errorf(\"cosineSimilarity(%v, %v) = %f, want %f\", tt.a, tt.b, got, tt.want)\n        }\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#task-9-build-and-test","title":"Task 9: Build and Test","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=semantic_coverage.out ./semantic/...\ngo tool cover -func=semantic_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#task-10-commit-and-push","title":"Task 10: Commit and Push","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngit add -A\ngit commit -m \"feat(semantic): add semantic search package\n\nAdd vector-based semantic search capabilities for tool discovery.\n\nPackage contents:\n- Embedder interface for text-to-vector conversion\n- VectorIndex interface for similarity search\n- MemoryVectorIndex for in-memory brute-force search\n- HybridSearcher combining BM25 + semantic with RRF fusion\n\nFeatures:\n- Cosine and dot product similarity metrics\n- Reciprocal Rank Fusion for result combination\n- Configurable BM25/semantic weight balance\n- Pluggable embedder and vector index backends\n\nThis consolidates and completes the partial toolsemantic implementation.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] Core interfaces defined (Embedder, VectorIndex)</li> <li>[x] MemoryVectorIndex implemented</li> <li>[x] HybridSearcher implemented</li> <li>[x] Cosine similarity works correctly</li> <li>[x] <code>go build ./...</code> succeeds</li> <li>[x] <code>go test ./...</code> passes</li> <li>[x] Package documentation complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>tooldiscovery/semantic</code> builds successfully</li> <li>MemoryVectorIndex passes tests</li> <li>HybridSearcher combines BM25 and semantic results</li> <li>RRF fusion produces meaningful rankings</li> <li>Implements <code>index.Searcher</code> interface</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>tooldiscovery/semantic/</code> contains interfaces and in-memory implementations.</li> <li><code>tooldiscovery/semantic/doc.go</code> documents the package.</li> <li><code>go test ./semantic/...</code> passes in <code>tooldiscovery</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/tooldiscovery\nrm -rf semantic/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-132-migrate-toolsemantic/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-133: Migrate tooldocs</li> <li>Gate G3: Discovery + Execution layers complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/","title":"PRD-133: Migrate tooldocs","text":"<p>Phase: 3 - Discovery Layer Priority: Medium Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#objective","title":"Objective","text":"<p>Migrate the existing <code>tooldocs</code> repository into <code>tooldiscovery/tooldoc/</code> as the fourth package in the consolidated discovery layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/tooldocs</code> Target Location: <code>github.com/jonwraymond/tooldiscovery/tooldoc</code></p> <p>Package Contents: - Tool documentation storage and retrieval - Progressive disclosure (Summary/Schema/Full) - Example management - Markdown rendering support - ~1,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#deliverables","title":"Deliverables","text":"Deliverable Location Description Docs Package <code>tooldiscovery/tooldoc/</code> Documentation management Tests <code>tooldiscovery/tooldoc/*_test.go</code> All existing tests Documentation <code>tooldiscovery/tooldoc/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#task-1-clone-and-analyze-source","title":"Task 1: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/tooldocs.git\ncd tooldocs\n\nls -la\nwc -l *.go\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#task-2-copy-source-files","title":"Task 2: Copy Source Files","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\n# Note: using 'docs' as package name (not 'tooldocs')\nmkdir -p docs\ncp ../tooldocs/*.go docs/\n\nls -la docs/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#task-3-update-import-paths","title":"Task 3: Update Import Paths","text":"<pre><code>cd /tmp/migration/tooldiscovery/tooldoc\n\n# Update self-reference\nOLD_IMPORT=\"github.com/jonwraymond/tooldocs\"\nNEW_IMPORT=\"github.com/jonwraymond/tooldiscovery/tooldoc\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\ndone\n\n# Update toolmodel to toolfoundation/model\nOLD_MODEL=\"github.com/jonwraymond/toolmodel\"\nNEW_MODEL=\"github.com/jonwraymond/toolfoundation/model\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_MODEL|$NEW_MODEL|g\" \"$file\"\ndone\n\n# Verify\ngrep -r \"jonwraymond/tooldocs\\|jonwraymond/toolmodel\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#task-4-update-package-documentation","title":"Task 4: Update Package Documentation","text":"<p>File: <code>tooldiscovery/tooldoc/doc.go</code></p> <pre><code>// Package docs provides documentation storage and retrieval for tools.\n//\n// This package manages tool documentation with support for progressive disclosure,\n// allowing clients to request varying levels of detail based on their needs.\n//\n// # Disclosure Levels\n//\n// The package supports three disclosure levels:\n//\n//   - Summary: Minimal information (ID, name, description)\n//   - Schema: Includes input/output JSON schemas\n//   - Full: Complete documentation including examples and usage\n//\n// # Usage\n//\n// Create a documentation store:\n//\n//  store := docs.NewStore(docs.Config{\n//      BaseDir: \"./tool-docs\",\n//  })\n//\n// Get documentation at different levels:\n//\n//  summary, _ := store.Get(ctx, \"calculator\", docs.LevelSummary)\n//  schema, _ := store.Get(ctx, \"calculator\", docs.LevelSchema)\n//  full, _ := store.Get(ctx, \"calculator\", docs.LevelFull)\n//\n// # Storage\n//\n// Documentation is stored as structured files:\n//\n//  tool-docs/\n//  \u251c\u2500\u2500 calculator/\n//  \u2502   \u251c\u2500\u2500 README.md      # Full documentation\n//  \u2502   \u251c\u2500\u2500 schema.json    # Input/output schemas\n//  \u2502   \u2514\u2500\u2500 examples/\n//  \u2502       \u251c\u2500\u2500 basic.json\n//  \u2502       \u2514\u2500\u2500 advanced.json\n//\n// # Examples\n//\n// The package includes example management:\n//\n//  examples, _ := store.GetExamples(ctx, \"calculator\")\n//  for _, ex := range examples {\n//      fmt.Printf(\"Example: %s\\n\", ex.Name)\n//      fmt.Printf(\"Input: %s\\n\", ex.Input)\n//      fmt.Printf(\"Output: %s\\n\", ex.Output)\n//  }\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/tooldocs as part of\n// the ApertureStack consolidation.\npackage docs\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#task-5-define-core-types","title":"Task 5: Define Core Types","text":"<p>Ensure these types exist in the migrated code:</p> <p>File: <code>tooldiscovery/tooldoc/types.go</code></p> <pre><code>package docs\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Level represents the disclosure level for documentation.\ntype Level int\n\nconst (\n    // LevelSummary provides minimal information.\n    LevelSummary Level = iota\n    // LevelSchema includes input/output schemas.\n    LevelSchema\n    // LevelFull provides complete documentation.\n    LevelFull\n)\n\n// Documentation holds tool documentation at various levels.\ntype Documentation struct {\n    Tool        model.Tool\n    Level       Level\n    Markdown    string\n    Examples    []Example\n    LastUpdated string\n}\n\n// Example represents a tool usage example.\ntype Example struct {\n    Name        string\n    Description string\n    Input       map[string]any\n    Output      any\n    Tags        []string\n}\n\n// Store provides documentation storage and retrieval.\ntype Store interface {\n    // Get retrieves documentation at the specified level.\n    Get(ctx context.Context, toolID string, level Level) (*Documentation, error)\n\n    // Set stores documentation for a tool.\n    Set(ctx context.Context, doc *Documentation) error\n\n    // GetExamples retrieves examples for a tool.\n    GetExamples(ctx context.Context, toolID string) ([]Example, error)\n\n    // AddExample adds an example to a tool.\n    AddExample(ctx context.Context, toolID string, example Example) error\n\n    // List returns all documented tool IDs.\n    List(ctx context.Context) ([]string, error)\n}\n\n// Config configures the documentation store.\ntype Config struct {\n    BaseDir     string\n    CacheSize   int\n    EnableCache bool\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=docs_coverage.out ./docs/...\n\ngo tool cover -func=docs_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngit add -A\ngit commit -m \"feat(docs): migrate tooldocs package\n\nMigrate tool documentation management from standalone tooldocs repository.\n\nPackage contents:\n- Store interface for documentation CRUD\n- Progressive disclosure levels (Summary/Schema/Full)\n- Example management\n- File-based storage implementation\n- Optional caching\n\nFeatures:\n- Three-tier disclosure: summary, schema, full\n- Markdown documentation support\n- JSON example storage\n- Last-updated tracking\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/tooldocs \u2192 tooldiscovery/tooldoc\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#file-mapping","title":"File Mapping","text":"Source Target <code>tooldocs/store.go</code> <code>tooldiscovery/tooldoc/store.go</code> <code>tooldocs/store_test.go</code> <code>tooldiscovery/tooldoc/store_test.go</code> <code>tooldocs/types.go</code> <code>tooldiscovery/tooldoc/types.go</code> <code>tooldocs/file.go</code> <code>tooldiscovery/tooldoc/file.go</code> <code>tooldocs/cache.go</code> <code>tooldiscovery/tooldoc/cache.go</code> <code>tooldocs/doc.go</code> <code>tooldiscovery/tooldoc/doc.go</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All source files copied</li> <li>[x] Import paths updated</li> <li>[x] <code>go build ./...</code> succeeds</li> <li>[x] <code>go test ./...</code> passes</li> <li>[x] Progressive disclosure works</li> <li>[x] Example management works</li> <li>[x] Package documentation updated</li> <li>[x] Committed with proper message</li> <li>[x] Pushed to main</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>tooldiscovery/tooldoc</code> package builds successfully</li> <li>All tests pass</li> <li>Three disclosure levels work correctly</li> <li>Examples can be stored and retrieved</li> <li>File-based storage persists data</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>tooldiscovery/tooldoc/</code> contains migrated sources and tests.</li> <li><code>tooldiscovery/tooldoc/doc.go</code> documents the package.</li> <li><code>go test ./tooldoc/...</code> passes in <code>tooldiscovery</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/tooldiscovery\nrm -rf tooldoc/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-133-migrate-tooldocs/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G3: Discovery layer complete (all 4 packages)</li> <li>PRD-140: Migrate toolrun</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-134-tooldiscovery-docs-alignment/","title":"PRD-134: tooldiscovery Docs + README Alignment","text":"<p>Phase: 3 - Discovery Layer Priority: High Effort: 2 hours Dependencies: PRD-130\u2013133 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-134-tooldiscovery-docs-alignment/#objective","title":"Objective","text":"<p>Align public-facing documentation with the consolidated <code>tooldiscovery</code> API:</p> <ul> <li>Replace README placeholders.</li> <li>Ensure docs show correct package names and usage.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-134-tooldiscovery-docs-alignment/#deliverables","title":"Deliverables","text":"Deliverable Location Description Updated README <code>tooldiscovery/README.md</code> Package table + descriptions Updated docs <code>tooldiscovery/docs/*</code> Accurate usage examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-134-tooldiscovery-docs-alignment/#tasks","title":"Tasks","text":"<ol> <li>Update README package table (index/search/semantic/tooldoc).</li> <li>Verify docs/index.md examples compile against current API.</li> <li>Verify user-journey.md uses correct types and packages.</li> <li>Run tests.</li> </ol> <pre><code>cd tooldiscovery\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-134-tooldiscovery-docs-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>README has no <code>TBD</code> entries.</li> <li>Docs reflect current package names and usage.</li> <li>Tests pass.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-134-tooldiscovery-docs-alignment/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>README updated and committed.</li> <li>Docs updated with current package names and examples.</li> <li><code>go test ./...</code> passes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-135-tooldiscovery-search-policy/","title":"PRD-135: tooldiscovery Search Strategy Policy Docs","text":"<p>Phase: 3 - Discovery Layer Priority: Medium Effort: 2 hours Dependencies: PRD-131 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-135-tooldiscovery-search-policy/#objective","title":"Objective","text":"<p>Document search strategy behavior and configuration for the <code>search</code> package:</p> <ul> <li>BM25 configuration (field boosts)</li> <li>Indexing scope and caching behavior</li> <li>Guidance for choosing strategies</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-135-tooldiscovery-search-policy/#deliverables","title":"Deliverables","text":"Deliverable Location Description Search policy section <code>tooldiscovery/docs/design-notes.md</code> BM25 config + behavior Summary note <code>tooldiscovery/docs/index.md</code> Short guidance + link"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-135-tooldiscovery-search-policy/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>BM25 configuration is explicitly documented.</li> <li>Guidance for selecting lexical vs BM25 vs semantic is present.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-135-tooldiscovery-search-policy/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Search policy documented in <code>tooldiscovery/docs/design-notes.md</code>.</li> <li>Summary guidance added in <code>tooldiscovery/docs/index.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-136-tooldiscovery-semantic-contracts/","title":"PRD-136: tooldiscovery Semantic Contracts","text":"<p>Phase: 3 - Discovery Layer Priority: Medium Effort: 2 hours Dependencies: PRD-132 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-136-tooldiscovery-semantic-contracts/#objective","title":"Objective","text":"<p>Document the semantic search contracts:</p> <ul> <li><code>Embedder</code> interface expectations</li> <li><code>VectorStore</code> behaviors and result format</li> <li>Hybrid search + RRF fusion behavior</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-136-tooldiscovery-semantic-contracts/#deliverables","title":"Deliverables","text":"Deliverable Location Description Contract section <code>tooldiscovery/docs/design-notes.md</code> Interface expectations Usage example <code>tooldiscovery/docs/index.md</code> Minimal semantic search example"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-136-tooldiscovery-semantic-contracts/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Embedder/VectorStore contracts are documented.</li> <li>Hybrid search semantics are stated.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-136-tooldiscovery-semantic-contracts/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Semantic contracts documented in <code>tooldiscovery/docs/design-notes.md</code>.</li> <li>Usage example added in <code>tooldiscovery/docs/index.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-137-tooldiscovery-progressive-docs/","title":"PRD-137: tooldiscovery Progressive Documentation Details","text":"<p>Phase: 3 - Discovery Layer Priority: Medium Effort: 2 hours Dependencies: PRD-133 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-137-tooldiscovery-progressive-docs/#objective","title":"Objective","text":"<p>Document the progressive disclosure model in <code>tooldoc</code>:</p> <ul> <li>Detail levels and what each includes</li> <li>Performance considerations (token cost)</li> <li>Example usage patterns</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-137-tooldiscovery-progressive-docs/#deliverables","title":"Deliverables","text":"Deliverable Location Description Detail-level table <code>tooldiscovery/docs/design-notes.md</code> Explicit fields per level User guidance <code>tooldiscovery/docs/user-journey.md</code> When to request each level"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-137-tooldiscovery-progressive-docs/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Detail level semantics are explicit.</li> <li>Usage guidance is present in user journey.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-137-tooldiscovery-progressive-docs/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Detail-level matrix documented in <code>tooldiscovery/docs/design-notes.md</code>.</li> <li>Guidance added to <code>tooldiscovery/docs/user-journey.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-138-tooldiscovery-release-propagation/","title":"PRD-138: tooldiscovery Release + Version Propagation","text":"<p>Phase: 3 - Discovery Layer Priority: Medium Effort: 1 hour Dependencies: PRD-130\u2013133 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-138-tooldiscovery-release-propagation/#objective","title":"Objective","text":"<p>Tag and propagate the consolidated <code>tooldiscovery</code> module version into the stack.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-138-tooldiscovery-release-propagation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Module tag <code>tooldiscovery</code> <code>v0.1.0</code> tag exists Version matrix entry <code>ai-tools-stack/VERSIONS.md</code> tooldiscovery row present go.mod alignment <code>ai-tools-stack/go.mod</code> tooldiscovery dependency pinned"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-138-tooldiscovery-release-propagation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Tag <code>v0.1.0</code> exists in <code>tooldiscovery</code>.</li> <li>Version matrix already reflects tooldiscovery v0.1.0.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-138-tooldiscovery-release-propagation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Tag <code>v0.1.0</code> pushed in <code>tooldiscovery</code>.</li> <li><code>ai-tools-stack/VERSIONS.md</code> already lists tooldiscovery v0.1.0.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-139-tooldiscovery-validation/","title":"PRD-139: tooldiscovery Validation (G3 - Discovery Only)","text":"<p>Phase: 3 - Discovery Layer Priority: High Effort: 1 hour Dependencies: PRD-130\u2013138 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-139-tooldiscovery-validation/#objective","title":"Objective","text":"<p>Validate the discovery layer implementation for correctness and CI readiness.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-139-tooldiscovery-validation/#verification-steps","title":"Verification Steps","text":"<pre><code>cd tooldiscovery\n\ngo test ./...\n\ngolangci-lint run\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-139-tooldiscovery-validation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li><code>go test ./...</code> passes.</li> <li><code>golangci-lint run</code> passes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-139-tooldiscovery-validation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>go test ./...</code> passes in <code>tooldiscovery</code>.</li> <li><code>golangci-lint run</code> passes in <code>tooldiscovery</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/","title":"PRD-140: Migrate toolrun","text":"<p>Phase: 4 - Execution Layer Priority: Critical Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolrun</code> repository into <code>toolexec/run/</code> as the first package in the consolidated execution layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolrun</code> Target Location: <code>github.com/jonwraymond/toolexec/run</code></p> <p>Package Contents: - Tool execution pipeline (6-step execution) - Backend dispatch (local, docker, wasm, remote) - Chain execution for tool sequences - Streaming support - ~5,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#deliverables","title":"Deliverables","text":"Deliverable Location Description Run Package <code>toolexec/run/</code> Execution pipeline Tests <code>toolexec/run/*_test.go</code> All existing tests Documentation <code>toolexec/run/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#task-1-prepare-target-repository","title":"Task 1: Prepare Target Repository","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolexec.git\ncd toolexec\n\nmkdir -p run\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#task-2-clone-and-analyze-source","title":"Task 2: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolrun.git\ncd toolrun\n\nls -la\nwc -l *.go\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#task-3-copy-source-files","title":"Task 3: Copy Source Files","text":"<pre><code>cd /tmp/migration\n\ncp toolrun/*.go toolexec/run/\nls -la toolexec/run/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#task-4-update-import-paths","title":"Task 4: Update Import Paths","text":"<pre><code>cd /tmp/migration/toolexec/run\n\n# Update self-reference\nOLD_IMPORT=\"github.com/jonwraymond/toolrun\"\nNEW_IMPORT=\"github.com/jonwraymond/toolexec/run\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\ndone\n\n# Update toolmodel to toolfoundation/model\nOLD_MODEL=\"github.com/jonwraymond/toolmodel\"\nNEW_MODEL=\"github.com/jonwraymond/toolfoundation/model\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_MODEL|$NEW_MODEL|g\" \"$file\"\ndone\n\n# Update toolruntime if referenced\nOLD_RUNTIME=\"github.com/jonwraymond/toolruntime\"\nNEW_RUNTIME=\"github.com/jonwraymond/toolexec/runtime\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_RUNTIME|$NEW_RUNTIME|g\" \"$file\"\ndone\n\n# Verify\ngrep -r \"jonwraymond/toolrun\\|jonwraymond/toolmodel\\|jonwraymond/toolruntime\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#task-5-update-package-documentation","title":"Task 5: Update Package Documentation","text":"<p>File: <code>toolexec/run/doc.go</code></p> <pre><code>// Package run provides the tool execution pipeline for the ApertureStack ecosystem.\n//\n// This package implements a 6-step execution pipeline that handles tool invocation\n// from request to response, with support for multiple execution backends and\n// chain execution.\n//\n// # Execution Pipeline\n//\n// The pipeline consists of six steps:\n//\n//  1. Validate: Check input against tool schema\n//  2. Authorize: Verify execution permissions\n//  3. Prepare: Set up execution context\n//  4. Execute: Run tool via selected backend\n//  5. Transform: Post-process output\n//  6. Respond: Format and return result\n//\n// # Usage\n//\n// Create a runner and execute tools:\n//\n//  runner := run.NewRunner(run.Config{\n//      DefaultBackend: \"local\",\n//      Timeout:        30 * time.Second,\n//  })\n//\n//  result, err := runner.Run(ctx, run.Request{\n//      ToolID: \"calculator\",\n//      Input:  map[string]any{\"operation\": \"add\", \"a\": 1, \"b\": 2},\n//  })\n//\n// # Backends\n//\n// The runner supports multiple execution backends:\n//\n//   - local: Direct in-process execution\n//   - docker: Container-based isolation\n//   - wasm: WebAssembly sandbox\n//   - remote: HTTP/gRPC remote execution\n//\n// # Chain Execution\n//\n// Execute a sequence of tools where output flows to input:\n//\n//  chain := run.Chain{\n//      Steps: []run.ChainStep{\n//          {ToolID: \"fetch-data\", Input: map[string]any{\"url\": \"...\"}},\n//          {ToolID: \"transform\", InputMapping: map[string]string{\"data\": \"$.output\"}},\n//          {ToolID: \"store\", InputMapping: map[string]string{\"content\": \"$.output\"}},\n//      },\n//  }\n//  results, err := runner.RunChain(ctx, chain)\n//\n// # Streaming\n//\n// For long-running tools, use streaming execution:\n//\n//  stream, err := runner.RunStream(ctx, request)\n//  for event := range stream.Events() {\n//      fmt.Printf(\"Progress: %s\\n\", event.Message)\n//  }\n//  result := stream.Result()\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolrun as part of\n// the ApertureStack consolidation.\npackage run\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/toolexec\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=run_coverage.out ./run/...\n\ngo tool cover -func=run_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/toolexec\n\ngit add -A\ngit commit -m \"feat(run): migrate toolrun package\n\nMigrate the execution pipeline from standalone toolrun repository.\n\nPackage contents:\n- 6-step execution pipeline\n- Multi-backend dispatch (local, docker, wasm, remote)\n- Chain execution for tool sequences\n- Streaming execution support\n- Configurable timeouts and retries\n\nFeatures:\n- Input validation against tool schema\n- Authorization hooks\n- Context preparation\n- Backend selection\n- Output transformation\n- Response formatting\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolrun \u2192 toolexec/run\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#key-interfaces","title":"Key Interfaces","text":"<pre><code>package run\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Runner executes tools.\ntype Runner interface {\n    // Run executes a single tool.\n    Run(ctx context.Context, req Request) (*Result, error)\n\n    // RunChain executes a sequence of tools.\n    RunChain(ctx context.Context, chain Chain) ([]Result, error)\n\n    // RunStream executes a tool with streaming output.\n    RunStream(ctx context.Context, req Request) (Stream, error)\n}\n\n// Request represents an execution request.\ntype Request struct {\n    ToolID   string\n    Tool     *model.Tool // Optional: provide tool directly\n    Input    map[string]any\n    Options  Options\n    Metadata map[string]any\n}\n\n// Result represents an execution result.\ntype Result struct {\n    ToolID   string\n    Output   any\n    Error    *Error\n    Metrics  Metrics\n    Metadata map[string]any\n}\n\n// Chain represents a sequence of tool executions.\ntype Chain struct {\n    ID    string\n    Steps []ChainStep\n}\n\n// ChainStep represents a step in a chain.\ntype ChainStep struct {\n    ToolID       string\n    Input        map[string]any\n    InputMapping map[string]string // JSONPath mappings\n}\n\n// Backend executes tools in a specific environment.\ntype Backend interface {\n    Execute(ctx context.Context, tool model.Tool, input map[string]any) (any, error)\n    Name() string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] 6-step pipeline works</li> <li>[ ] Chain execution works</li> <li>[ ] Streaming works</li> <li>[ ] Package documentation updated</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolexec/run</code> package builds successfully</li> <li>All tests pass</li> <li>Single tool execution works</li> <li>Chain execution produces correct results</li> <li>Multiple backends supported</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#completion-notes","title":"Completion Notes","text":"<ul> <li>Migration completed into <code>toolexec/run</code> with tests and <code>doc.go</code>.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> <li>Runner uses option-based configuration (<code>NewRunner(WithIndex(...), WithBackends(...))</code>).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolexec\nrm -rf run/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-140-migrate-toolrun/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-141: Migrate toolruntime</li> <li>PRD-142: Migrate toolcode</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/","title":"PRD-141: Migrate toolruntime","text":"<p>Phase: 4 - Execution Layer Priority: Critical Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolruntime</code> repository into <code>toolexec/runtime/</code> as the second package in the consolidated execution layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolruntime</code> Target Location: <code>github.com/jonwraymond/toolexec/runtime</code></p> <p>Package Contents: - Runtime abstraction for tool execution - 10 sandbox backends (unsafe, docker, containerd, kubernetes, firecracker, kata, gvisor, wasm, temporal, remote) - 3 security profiles (dev, standard, hardened) - Error handling with structured errors - ~8,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#deliverables","title":"Deliverables","text":"Deliverable Location Description Runtime Package <code>toolexec/runtime/</code> Runtime abstraction Backend Implementations <code>toolexec/runtime/backend/</code> Sandbox backends Tests <code>toolexec/runtime/*_test.go</code> All existing tests Documentation <code>toolexec/runtime/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#task-1-clone-and-analyze-source","title":"Task 1: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolruntime.git\ncd toolruntime\n\nls -la\nfind . -name \"*.go\" | wc -l\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#task-2-copy-source-files-preserving-structure","title":"Task 2: Copy Source Files (Preserving Structure)","text":"<pre><code>cd /tmp/migration/toolexec\n\n# Create directories\nmkdir -p runtime/backend\n\n# Copy root package files\ncp ../toolruntime/*.go runtime/\n\n# Copy backend subdirectory\ncp -r ../toolruntime/backend/* runtime/backend/\n\nls -la runtime/\nls -la runtime/backend/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#task-3-update-import-paths","title":"Task 3: Update Import Paths","text":"<pre><code>cd /tmp/migration/toolexec\n\n# Update all Go files recursively\nfind runtime -name \"*.go\" -exec sed -i '' 's|github.com/jonwraymond/toolruntime|github.com/jonwraymond/toolexec/runtime|g' {} \\;\n\n# Update toolmodel references\nfind runtime -name \"*.go\" -exec sed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' {} \\;\n\n# Verify\ngrep -r \"jonwraymond/toolruntime\\|jonwraymond/toolmodel\" runtime/ || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#task-4-update-package-documentation","title":"Task 4: Update Package Documentation","text":"<p>File: <code>toolexec/runtime/doc.go</code></p> <pre><code>// Package runtime provides sandboxed execution environments for tools.\n//\n// This package implements a runtime abstraction that enables tool execution\n// in various isolated environments, from no isolation (development) to\n// strict container-based isolation (production).\n//\n// # Backends\n//\n// The package supports 10 execution backends:\n//\n//   - unsafe: No isolation (development only)\n//   - docker: Docker container isolation\n//   - containerd: containerd-based containers\n//   - kubernetes: Kubernetes pod execution\n//   - firecracker: MicroVM isolation\n//   - kata: Kata Containers\n//   - gvisor: gVisor sandbox\n//   - wasm: WebAssembly sandbox\n//   - temporal: Temporal workflow execution\n//   - remote: Remote execution via HTTP/gRPC\n//\n// # Security Profiles\n//\n// Three security profiles control isolation level:\n//\n//   - SecurityNone: No isolation (unsafe backend)\n//   - SecurityBasic: Container isolation with defaults\n//   - SecurityStrict: Hardened isolation with restricted capabilities\n//\n// # Usage\n//\n// Create a runtime with a specific backend:\n//\n//  rt, err := runtime.New(runtime.Config{\n//      Backend:  \"docker\",\n//      Security: runtime.SecurityBasic,\n//      Timeout:  30 * time.Second,\n//  })\n//\n//  result, err := rt.Execute(ctx, runtime.Task{\n//      Tool:  tool,\n//      Input: input,\n//  })\n//\n// # Resource Limits\n//\n// Configure resource limits for execution:\n//\n//  rt, _ := runtime.New(runtime.Config{\n//      Backend: \"docker\",\n//      Resources: runtime.Resources{\n//          Memory:    \"256Mi\",\n//          CPU:       \"0.5\",\n//          Timeout:   \"30s\",\n//          DiskSpace: \"100Mi\",\n//      },\n//  })\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolruntime as part of\n// the ApertureStack consolidation.\npackage runtime\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#task-5-backend-build-tags-optional","title":"Task 5: Backend Build Tags (Optional)","text":"<p>Backends are configured at runtime; no build tags are required. If tags are introduced later, document them alongside the backend matrix.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#task-6-update-gomod-dependencies","title":"Task 6: Update go.mod Dependencies","text":"<pre><code>cd /tmp/migration/toolexec\n\n# The runtime package may have significant dependencies\ncat go.mod\n\n# Add required dependencies\ngo get github.com/docker/docker/client\ngo get k8s.io/client-go@latest\n\ngo mod tidy\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#task-7-build-and-test","title":"Task 7: Build and Test","text":"<pre><code>cd /tmp/migration/toolexec\n\n# Build all (without optional backends)\ngo build ./...\n\n# Build with docker backend\ngo build -tags=docker ./...\n\n# Test\ngo test -v -coverprofile=runtime_coverage.out ./runtime/...\ngo tool cover -func=runtime_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd /tmp/migration/toolexec\n\ngit add -A\ngit commit -m \"feat(runtime): migrate toolruntime package\n\nMigrate the sandbox runtime from standalone toolruntime repository.\n\nPackage contents:\n- Runtime interface for sandboxed execution\n- 10 backend implementations\n- 3 security profiles (none, basic, strict)\n- Resource limit configuration\n- Structured error handling\n\nBackends (via build tags):\n- unsafe: always included\n- docker: -tags=docker\n- containerd: -tags=containerd\n- kubernetes: -tags=kubernetes\n- firecracker: -tags=firecracker\n- kata: -tags=kata\n- gvisor: -tags=gvisor\n- wasm: -tags=wasm\n- temporal: -tags=temporal\n- remote: always included\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n- Various backend-specific dependencies\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolruntime \u2192 toolexec/runtime\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#key-interfaces","title":"Key Interfaces","text":"<pre><code>package runtime\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Runtime executes tools in isolated environments.\ntype Runtime interface {\n    // Execute runs a tool in the sandbox.\n    Execute(ctx context.Context, task Task) (*Result, error)\n\n    // Close releases runtime resources.\n    Close() error\n\n    // Backend returns the backend name.\n    Backend() string\n\n    // Security returns the security profile.\n    Security() SecurityProfile\n}\n\n// Task represents an execution task.\ntype Task struct {\n    Tool      model.Tool\n    Input     map[string]any\n    Env       map[string]string\n    Resources *Resources\n}\n\n// Result represents an execution result.\ntype Result struct {\n    Output   any\n    ExitCode int\n    Stdout   string\n    Stderr   string\n    Duration time.Duration\n}\n\n// Config configures the runtime.\ntype Config struct {\n    Backend   string\n    Security  SecurityProfile\n    Timeout   time.Duration\n    Resources *Resources\n}\n\n// SecurityProfile defines isolation level.\ntype SecurityProfile int\n\nconst (\n    SecurityNone SecurityProfile = iota\n    SecurityBasic\n    SecurityStrict\n)\n\n// Resources defines execution resource limits.\ntype Resources struct {\n    Memory    string // e.g., \"256Mi\"\n    CPU       string // e.g., \"0.5\"\n    Timeout   string // e.g., \"30s\"\n    DiskSpace string // e.g., \"100Mi\"\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied (including backend/)</li> <li>[ ] Import paths updated</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Security profiles work</li> <li>[ ] Package documentation updated</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolexec/runtime</code> package builds successfully</li> <li>All tests pass</li> <li>Unsafe backend works without extra dependencies</li> <li>Docker backend works when configured with a container runner</li> <li>Security profiles enforce appropriate isolation</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#completion-notes","title":"Completion Notes","text":"<ul> <li>Migration completed into <code>toolexec/runtime</code> with <code>runtime/backend/*</code>.</li> <li>Security profiles are <code>ProfileDev</code>, <code>ProfileStandard</code>, <code>ProfileHardened</code>.</li> <li>No build tags are required; backend selection is runtime-configured.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolexec\nrm -rf runtime/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-141-migrate-toolruntime/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-142: Migrate toolcode</li> <li>PRD-143: Extract toolbackend</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/","title":"PRD-142: Migrate toolcode","text":"<p>Phase: 4 - Execution Layer Priority: High Effort: 4 hours Dependencies: PRD-140 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolcode</code> repository into <code>toolexec/code/</code> as the third package in the consolidated execution layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolcode</code> Target Location: <code>github.com/jonwraymond/toolexec/code</code></p> <p>Package Contents: - Code-based tool orchestration - Dynamic tool generation from code - TypeScript/JavaScript execution integration - Tool chain composition via code - ~2,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#deliverables","title":"Deliverables","text":"Deliverable Location Description Code Package <code>toolexec/code/</code> Code orchestration Tests <code>toolexec/code/*_test.go</code> All existing tests Documentation <code>toolexec/code/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#task-1-clone-and-analyze-source","title":"Task 1: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolcode.git\ncd toolcode\n\nls -la\nwc -l *.go\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#task-2-copy-source-files","title":"Task 2: Copy Source Files","text":"<pre><code>cd /tmp/migration/toolexec\n\nmkdir -p code\ncp ../toolcode/*.go code/\n\nls -la code/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#task-3-update-import-paths","title":"Task 3: Update Import Paths","text":"<pre><code>cd /tmp/migration/toolexec/code\n\n# Update self-reference\nOLD_IMPORT=\"github.com/jonwraymond/toolcode\"\nNEW_IMPORT=\"github.com/jonwraymond/toolexec/code\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\ndone\n\n# Update toolmodel to toolfoundation/model\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n\n# Update toolrun to toolexec/run\nsed -i '' 's|github.com/jonwraymond/toolrun|github.com/jonwraymond/toolexec/run|g' *.go\n\n# Verify\ngrep -r \"jonwraymond/toolcode\\|jonwraymond/toolmodel\\|jonwraymond/toolrun\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#task-4-update-package-documentation","title":"Task 4: Update Package Documentation","text":"<p>File: <code>toolexec/code/doc.go</code></p> <pre><code>// Package code provides code-based tool orchestration for the ApertureStack ecosystem.\n//\n// This package enables developers to define tool workflows using code, supporting\n// dynamic tool generation, conditional execution, and complex orchestration patterns.\n//\n// # Overview\n//\n// While toolexec/run handles individual tool execution and chains, the code package\n// provides a higher-level abstraction for code-driven orchestration:\n//\n//   - Dynamic tool generation from runtime data\n//   - Conditional branching based on execution results\n//   - Parallel execution with result aggregation\n//   - Error handling and retry logic\n//\n// # Usage\n//\n// Create a code orchestrator:\n//\n//  orchestrator := code.NewOrchestrator(code.Config{\n//      Runner: runner,\n//      Logger: logger,\n//  })\n//\n// Define and execute a workflow:\n//\n//  workflow := code.Workflow{\n//      Name: \"data-pipeline\",\n//      Steps: []code.Step{\n//          {Tool: \"fetch\", Input: fetchInput},\n//          {Tool: \"transform\", DependsOn: []string{\"fetch\"}},\n//          {Tool: \"store\", DependsOn: []string{\"transform\"}},\n//      },\n//  }\n//\n//  results, err := orchestrator.Execute(ctx, workflow)\n//\n// # TypeScript Integration\n//\n// For TypeScript-based orchestration, see the toolcodeengine companion:\n//\n//  engine := codeengine.New(codeengine.Config{\n//      Orchestrator: orchestrator,\n//      Runtime:      \"deno\",\n//  })\n//\n//  result, err := engine.Execute(ctx, `\n//      const data = await tools.fetch({url: \"...\"});\n//      return tools.transform({data});\n//  `)\n//\n// # Parallel Execution\n//\n// Execute multiple tools in parallel:\n//\n//  parallel := code.Parallel{\n//      Steps: []code.Step{\n//          {Tool: \"api-a\", Input: inputA},\n//          {Tool: \"api-b\", Input: inputB},\n//          {Tool: \"api-c\", Input: inputC},\n//      },\n//  }\n//\n//  results, err := orchestrator.ExecuteParallel(ctx, parallel)\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolcode as part of\n// the ApertureStack consolidation.\npackage code\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#task-5-verify-internal-dependencies","title":"Task 5: Verify Internal Dependencies","text":"<pre><code>cd /tmp/migration/toolexec\n\n# The code package depends on run package\ngrep -h \"import\" code/*.go | sort -u\n\n# Should include:\n# \"github.com/jonwraymond/toolexec/run\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/toolexec\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=code_coverage.out ./code/...\n\ngo tool cover -func=code_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/toolexec\n\ngit add -A\ngit commit -m \"feat(code): migrate toolcode package\n\nMigrate code-based orchestration from standalone toolcode repository.\n\nPackage contents:\n- Orchestrator for code-driven workflows\n- Step-based workflow definition\n- Parallel execution support\n- Conditional branching\n- Result aggregation\n\nFeatures:\n- Dynamic tool generation\n- Dependency-based execution order\n- Error handling and retries\n- TypeScript/JavaScript integration (via codeengine)\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n- github.com/jonwraymond/toolexec/run\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolcode \u2192 toolexec/code\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#key-interfaces","title":"Key Interfaces","text":"<pre><code>package code\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolexec/run\"\n)\n\n// Orchestrator manages code-based tool workflows.\ntype Orchestrator interface {\n    // Execute runs a workflow.\n    Execute(ctx context.Context, workflow Workflow) ([]run.Result, error)\n\n    // ExecuteParallel runs steps in parallel.\n    ExecuteParallel(ctx context.Context, parallel Parallel) ([]run.Result, error)\n\n    // ExecuteConditional runs steps conditionally.\n    ExecuteConditional(ctx context.Context, cond Conditional) (*run.Result, error)\n}\n\n// Workflow represents a sequence of steps.\ntype Workflow struct {\n    Name  string\n    Steps []Step\n}\n\n// Step represents a workflow step.\ntype Step struct {\n    ID        string\n    Tool      string\n    Input     map[string]any\n    DependsOn []string\n    Condition string // Expression for conditional execution\n    Retry     *RetryConfig\n}\n\n// Parallel represents parallel execution.\ntype Parallel struct {\n    Steps   []Step\n    MaxWorkers int\n}\n\n// Conditional represents conditional execution.\ntype Conditional struct {\n    Condition string\n    IfTrue    Step\n    IfFalse   *Step\n}\n\n// Config configures the orchestrator.\ntype Config struct {\n    Runner run.Runner\n    Logger Logger\n    MaxParallel int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated</li> <li>[ ] Dependency on toolexec/run works</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Workflow execution works</li> <li>[ ] Parallel execution works</li> <li>[ ] Package documentation updated</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolexec/code</code> package builds successfully</li> <li>All tests pass</li> <li>Workflow execution produces correct results</li> <li>Parallel execution respects MaxWorkers</li> <li>Conditional execution works</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#completion-notes","title":"Completion Notes","text":"<ul> <li>Migration completed into <code>toolexec/code</code> with docs and tests.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code> and <code>toolexec/run</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolexec\nrm -rf code/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-142-migrate-toolcode/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-143: Extract toolbackend</li> <li>Gate G3: Execution layer complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/","title":"PRD-143: Extract toolbackend","text":"<p>Phase: 4 - Execution Layer Priority: High Effort: 6 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#objective","title":"Objective","text":"<p>Extract backend management code from <code>metatools-mcp</code> into <code>toolexec/backend/</code> as the fourth package in the consolidated execution layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>metatools-mcp/internal/backend/</code> (embedded in MCP server) Target Location: <code>github.com/jonwraymond/toolexec/backend</code></p> <p>Code to Extract: - Backend registry and management - Provider interface for tool backends - Multi-backend aggregation - Backend health checking - ~600 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#deliverables","title":"Deliverables","text":"Deliverable Location Description Backend Package <code>toolexec/backend/</code> Backend management Tests <code>toolexec/backend/*_test.go</code> Comprehensive tests Documentation <code>toolexec/backend/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#task-1-analyze-source-code","title":"Task 1: Analyze Source Code","text":"<pre><code>cd /Users/jraymond/Documents/Projects/ApertureStack/metatools-mcp\n\n# Find backend-related code\nfind . -name \"*.go\" -exec grep -l \"Backend\\|Provider\" {} \\;\n\n# Count lines in relevant files\nwc -l internal/backend/*.go 2&gt;/dev/null || echo \"Check actual path\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#task-2-create-package-structure","title":"Task 2: Create Package Structure","text":"<pre><code>cd /tmp/migration/toolexec\n\nmkdir -p backend\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#task-3-define-core-interfaces","title":"Task 3: Define Core Interfaces","text":"<p>File: <code>toolexec/backend/backend.go</code></p> <pre><code>package backend\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Backend represents a tool execution backend.\ntype Backend interface {\n    // Name returns the backend identifier.\n    Name() string\n\n    // Type returns the backend type (local, mcp, http, grpc).\n    Type() string\n\n    // ListTools returns available tools from this backend.\n    ListTools(ctx context.Context) ([]model.Tool, error)\n\n    // GetTool retrieves a specific tool by ID.\n    GetTool(ctx context.Context, id string) (*model.Tool, error)\n\n    // Execute runs a tool with the given input.\n    Execute(ctx context.Context, toolID string, input map[string]any) (any, error)\n\n    // Health returns the backend health status.\n    Health(ctx context.Context) (*HealthStatus, error)\n\n    // Close releases backend resources.\n    Close() error\n}\n\n// HealthStatus represents backend health.\ntype HealthStatus struct {\n    Healthy     bool\n    Message     string\n    LastChecked time.Time\n    Latency     time.Duration\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#task-4-implement-registry","title":"Task 4: Implement Registry","text":"<p>File: <code>toolexec/backend/registry.go</code></p> <pre><code>package backend\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Registry manages multiple backends.\ntype Registry struct {\n    backends map[string]Backend\n    mu       sync.RWMutex\n}\n\n// NewRegistry creates a new backend registry.\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        backends: make(map[string]Backend),\n    }\n}\n\n// Register adds a backend to the registry.\nfunc (r *Registry) Register(backend Backend) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    name := backend.Name()\n    if _, exists := r.backends[name]; exists {\n        return fmt.Errorf(\"backend %q already registered\", name)\n    }\n    r.backends[name] = backend\n    return nil\n}\n\n// Unregister removes a backend from the registry.\nfunc (r *Registry) Unregister(name string) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    backend, exists := r.backends[name]\n    if !exists {\n        return fmt.Errorf(\"backend %q not found\", name)\n    }\n\n    if err := backend.Close(); err != nil {\n        return fmt.Errorf(\"closing backend %q: %w\", name, err)\n    }\n\n    delete(r.backends, name)\n    return nil\n}\n\n// Get retrieves a backend by name.\nfunc (r *Registry) Get(name string) (Backend, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    b, ok := r.backends[name]\n    return b, ok\n}\n\n// List returns all registered backend names.\nfunc (r *Registry) List() []string {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    names := make([]string, 0, len(r.backends))\n    for name := range r.backends {\n        names = append(names, name)\n    }\n    return names\n}\n\n// ListAllTools aggregates tools from all backends.\nfunc (r *Registry) ListAllTools(ctx context.Context) ([]model.Tool, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    var allTools []model.Tool\n    for _, backend := range r.backends {\n        tools, err := backend.ListTools(ctx)\n        if err != nil {\n            continue // Skip failing backends\n        }\n        allTools = append(allTools, tools...)\n    }\n    return allTools, nil\n}\n\n// FindTool searches all backends for a tool.\nfunc (r *Registry) FindTool(ctx context.Context, toolID string) (*model.Tool, Backend, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    for _, backend := range r.backends {\n        tool, err := backend.GetTool(ctx, toolID)\n        if err == nil &amp;&amp; tool != nil {\n            return tool, backend, nil\n        }\n    }\n    return nil, nil, fmt.Errorf(\"tool %q not found in any backend\", toolID)\n}\n\n// HealthCheck returns health status for all backends.\nfunc (r *Registry) HealthCheck(ctx context.Context) map[string]*HealthStatus {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    results := make(map[string]*HealthStatus)\n    for name, backend := range r.backends {\n        status, err := backend.Health(ctx)\n        if err != nil {\n            results[name] = &amp;HealthStatus{\n                Healthy: false,\n                Message: err.Error(),\n            }\n        } else {\n            results[name] = status\n        }\n    }\n    return results\n}\n\n// Close closes all backends.\nfunc (r *Registry) Close() error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    var errs []error\n    for name, backend := range r.backends {\n        if err := backend.Close(); err != nil {\n            errs = append(errs, fmt.Errorf(\"closing %s: %w\", name, err))\n        }\n    }\n    r.backends = make(map[string]Backend)\n\n    if len(errs) &gt; 0 {\n        return fmt.Errorf(\"errors closing backends: %v\", errs)\n    }\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#task-5-implement-local-backend","title":"Task 5: Implement Local Backend","text":"<p>File: <code>toolexec/backend/local.go</code></p> <pre><code>package backend\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n    \"time\"\n\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// LocalBackend provides in-process tool execution.\ntype LocalBackend struct {\n    name     string\n    tools    map[string]model.Tool\n    handlers map[string]Handler\n    mu       sync.RWMutex\n}\n\n// Handler executes a tool.\ntype Handler func(ctx context.Context, input map[string]any) (any, error)\n\n// NewLocalBackend creates a new local backend.\nfunc NewLocalBackend(name string) *LocalBackend {\n    return &amp;LocalBackend{\n        name:     name,\n        tools:    make(map[string]model.Tool),\n        handlers: make(map[string]Handler),\n    }\n}\n\nfunc (b *LocalBackend) Name() string { return b.name }\nfunc (b *LocalBackend) Type() string { return \"local\" }\n\n// RegisterTool adds a tool with its handler.\nfunc (b *LocalBackend) RegisterTool(tool model.Tool, handler Handler) error {\n    b.mu.Lock()\n    defer b.mu.Unlock()\n\n    if _, exists := b.tools[tool.ID]; exists {\n        return fmt.Errorf(\"tool %q already registered\", tool.ID)\n    }\n    b.tools[tool.ID] = tool\n    b.handlers[tool.ID] = handler\n    return nil\n}\n\nfunc (b *LocalBackend) ListTools(ctx context.Context) ([]model.Tool, error) {\n    b.mu.RLock()\n    defer b.mu.RUnlock()\n\n    tools := make([]model.Tool, 0, len(b.tools))\n    for _, tool := range b.tools {\n        tools = append(tools, tool)\n    }\n    return tools, nil\n}\n\nfunc (b *LocalBackend) GetTool(ctx context.Context, id string) (*model.Tool, error) {\n    b.mu.RLock()\n    defer b.mu.RUnlock()\n\n    tool, ok := b.tools[id]\n    if !ok {\n        return nil, fmt.Errorf(\"tool %q not found\", id)\n    }\n    return &amp;tool, nil\n}\n\nfunc (b *LocalBackend) Execute(ctx context.Context, toolID string, input map[string]any) (any, error) {\n    b.mu.RLock()\n    handler, ok := b.handlers[toolID]\n    b.mu.RUnlock()\n\n    if !ok {\n        return nil, fmt.Errorf(\"tool %q not found\", toolID)\n    }\n\n    return handler(ctx, input)\n}\n\nfunc (b *LocalBackend) Health(ctx context.Context) (*HealthStatus, error) {\n    return &amp;HealthStatus{\n        Healthy:     true,\n        Message:     \"local backend healthy\",\n        LastChecked: time.Now(),\n        Latency:     0,\n    }, nil\n}\n\nfunc (b *LocalBackend) Close() error {\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#task-6-create-package-documentation","title":"Task 6: Create Package Documentation","text":"<p>File: <code>toolexec/backend/doc.go</code></p> <pre><code>// Package backend provides backend management for tool execution.\n//\n// This package implements the registry pattern for managing multiple tool\n// execution backends. It supports local, MCP, HTTP, and gRPC backends with\n// unified discovery and execution APIs.\n//\n// # Registry\n//\n// The Registry aggregates multiple backends:\n//\n//  registry := backend.NewRegistry()\n//  registry.Register(localBackend)\n//  registry.Register(mcpBackend)\n//  registry.Register(httpBackend)\n//\n//  // List tools from all backends\n//  tools, _ := registry.ListAllTools(ctx)\n//\n//  // Find and execute a tool\n//  tool, backend, _ := registry.FindTool(ctx, \"calculator\")\n//  result, _ := backend.Execute(ctx, tool.ID, input)\n//\n// # Backend Types\n//\n// Built-in backend implementations:\n//\n//   - LocalBackend: In-process tool execution\n//   - MCPBackend: MCP server tool provider\n//   - HTTPBackend: HTTP API tool provider\n//   - GRPCBackend: gRPC tool provider\n//\n// # Health Checking\n//\n// Monitor backend health:\n//\n//  status := registry.HealthCheck(ctx)\n//  for name, health := range status {\n//      fmt.Printf(\"%s: healthy=%v latency=%v\\n\",\n//          name, health.Healthy, health.Latency)\n//  }\n//\n// # Custom Backends\n//\n// Implement the Backend interface for custom backends:\n//\n//  type MyBackend struct {}\n//  func (b *MyBackend) Name() string { return \"my-backend\" }\n//  func (b *MyBackend) Type() string { return \"custom\" }\n//  func (b *MyBackend) ListTools(ctx context.Context) ([]model.Tool, error) { ... }\n//  func (b *MyBackend) Execute(ctx context.Context, toolID string, input map[string]any) (any, error) { ... }\n//\n// # Extraction Note\n//\n// This package was extracted from metatools-mcp/internal/backend as part of\n// the ApertureStack consolidation to enable reuse across projects.\npackage backend\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#task-7-create-tests","title":"Task 7: Create Tests","text":"<p>File: <code>toolexec/backend/backend_test.go</code></p> <pre><code>package backend\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\nfunc TestRegistry(t *testing.T) {\n    ctx := context.Background()\n    registry := NewRegistry()\n\n    // Create local backend with a tool\n    local := NewLocalBackend(\"local\")\n    local.RegisterTool(\n        model.Tool{ID: \"test\", Name: \"Test Tool\"},\n        func(ctx context.Context, input map[string]any) (any, error) {\n            return \"success\", nil\n        },\n    )\n\n    // Register\n    if err := registry.Register(local); err != nil {\n        t.Fatal(err)\n    }\n\n    // List\n    names := registry.List()\n    if len(names) != 1 || names[0] != \"local\" {\n        t.Errorf(\"expected [local], got %v\", names)\n    }\n\n    // Get\n    b, ok := registry.Get(\"local\")\n    if !ok || b.Name() != \"local\" {\n        t.Error(\"failed to get backend\")\n    }\n\n    // Find tool\n    tool, backend, err := registry.FindTool(ctx, \"test\")\n    if err != nil {\n        t.Fatal(err)\n    }\n    if tool.ID != \"test\" || backend.Name() != \"local\" {\n        t.Error(\"wrong tool or backend\")\n    }\n\n    // Execute\n    result, err := backend.Execute(ctx, \"test\", nil)\n    if err != nil {\n        t.Fatal(err)\n    }\n    if result != \"success\" {\n        t.Errorf(\"expected 'success', got %v\", result)\n    }\n}\n\nfunc TestLocalBackend(t *testing.T) {\n    ctx := context.Background()\n    backend := NewLocalBackend(\"test\")\n\n    // Register tool\n    tool := model.Tool{ID: \"calc\", Name: \"Calculator\"}\n    handler := func(ctx context.Context, input map[string]any) (any, error) {\n        a := input[\"a\"].(float64)\n        b := input[\"b\"].(float64)\n        return a + b, nil\n    }\n\n    if err := backend.RegisterTool(tool, handler); err != nil {\n        t.Fatal(err)\n    }\n\n    // List tools\n    tools, err := backend.ListTools(ctx)\n    if err != nil {\n        t.Fatal(err)\n    }\n    if len(tools) != 1 {\n        t.Errorf(\"expected 1 tool, got %d\", len(tools))\n    }\n\n    // Execute\n    result, err := backend.Execute(ctx, \"calc\", map[string]any{\"a\": 1.0, \"b\": 2.0})\n    if err != nil {\n        t.Fatal(err)\n    }\n    if result != 3.0 {\n        t.Errorf(\"expected 3.0, got %v\", result)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#task-8-build-and-test","title":"Task 8: Build and Test","text":"<pre><code>cd /tmp/migration/toolexec\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=backend_coverage.out ./backend/...\n\ngo tool cover -func=backend_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#task-9-commit-and-push","title":"Task 9: Commit and Push","text":"<pre><code>cd /tmp/migration/toolexec\n\ngit add -A\ngit commit -m \"feat(backend): extract backend management package\n\nExtract backend registry and management from metatools-mcp.\n\nPackage contents:\n- Backend interface for tool providers\n- Registry for multi-backend management\n- LocalBackend for in-process execution\n- Health checking for all backends\n- Tool aggregation across backends\n\nFeatures:\n- Register/unregister backends dynamically\n- Find tools across all backends\n- Execute tools via appropriate backend\n- Health monitoring with latency tracking\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n\nThis extraction enables backend reuse across projects.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Backend interface defined</li> <li>[ ] Registry implemented</li> <li>[ ] LocalBackend implemented</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Health checking works</li> <li>[ ] Tool aggregation works</li> <li>[ ] Package documentation complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolexec/backend</code> package builds successfully</li> <li>All tests pass with &gt;= 80% coverage</li> <li>Registry manages multiple backends</li> <li>Tools can be found across backends</li> <li>Health status is accurate</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#completion-notes","title":"Completion Notes","text":"<ul> <li>Backend package extracted into <code>toolexec/backend</code> with registry, aggregator, and local backend.</li> <li>Contracts documented in <code>backend.go</code> and validated by tests.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolexec\nrm -rf backend/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-143-extract-toolbackend/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G3: Execution layer complete (all 4 packages)</li> <li>PRD-150: Migrate toolset</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-144-toolexec-docs-alignment/","title":"PRD-144: toolexec Docs + README Alignment","text":"<p>Phase: 4 - Execution Layer Priority: High Effort: 2 hours Dependencies: PRD-140\u2013143 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-144-toolexec-docs-alignment/#objective","title":"Objective","text":"<p>Align public-facing documentation with the consolidated <code>toolexec</code> API:</p> <ul> <li>Replace README placeholders.</li> <li>Ensure docs show correct package names and usage.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-144-toolexec-docs-alignment/#deliverables","title":"Deliverables","text":"Deliverable Location Description Updated README <code>toolexec/README.md</code> Package table + descriptions Updated docs <code>toolexec/docs/*</code> Accurate usage examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-144-toolexec-docs-alignment/#tasks","title":"Tasks","text":"<ol> <li>Update README package table (run/runtime/code/backend).</li> <li>Verify docs/index.md examples match current API.</li> <li>Update docs/user-journey.md runtime example to use <code>runtime.ExecuteRequest</code>.</li> <li>Update docs/design-notes.md with current runtime semantics.</li> <li>Run tests.</li> </ol> <pre><code>cd toolexec\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-144-toolexec-docs-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>README has no <code>TBD</code> entries.</li> <li>Docs reflect current package names and usage.</li> <li>Tests pass.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-144-toolexec-docs-alignment/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolexec/README.md</code> updated with final package list.</li> <li><code>toolexec/docs/user-journey.md</code> runtime example updated to <code>runtime.ExecuteRequest</code>.</li> <li><code>toolexec/docs/design-notes.md</code> updated with current runtime profile semantics.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-145-toolexec-runtime-security-profiles/","title":"PRD-145: toolexec Runtime Security Profiles Documentation","text":"<p>Phase: 4 - Execution Layer Priority: Medium Effort: 2 hours Dependencies: PRD-141 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-145-toolexec-runtime-security-profiles/#objective","title":"Objective","text":"<p>Document the runtime security profiles and their contract so consumers know which isolation guarantees they receive for each profile.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-145-toolexec-runtime-security-profiles/#deliverables","title":"Deliverables","text":"Deliverable Location Description Profile contract <code>toolexec/docs/design-notes.md</code> Profile definitions + usage guidance Runtime doc update <code>toolexec/runtime/doc.go</code> Package name + contract summary"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-145-toolexec-runtime-security-profiles/#tasks","title":"Tasks","text":"<ol> <li>Document <code>ProfileDev</code>, <code>ProfileStandard</code>, <code>ProfileHardened</code> semantics.</li> <li>Clarify Gateway requirement and limit enforcement expectations.</li> <li>Ensure package doc comment matches <code>package runtime</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-145-toolexec-runtime-security-profiles/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Profiles are described with intended isolation level.</li> <li>Gateway requirement is explicit.</li> <li>Package documentation is consistent with <code>package runtime</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-145-toolexec-runtime-security-profiles/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolexec/docs/design-notes.md</code> updated with profile definitions and Gateway requirement.</li> <li><code>toolexec/runtime/doc.go</code> comment updated to <code>Package runtime</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-146-toolexec-backend-matrix/","title":"PRD-146: toolexec Backend Matrix Documentation","text":"<p>Phase: 4 - Execution Layer Priority: Medium Effort: 2 hours Dependencies: PRD-141, PRD-143 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-146-toolexec-backend-matrix/#objective","title":"Objective","text":"<p>Provide a clear matrix of runtime backend kinds, isolation levels, and environment requirements so operators can choose appropriate backends.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-146-toolexec-backend-matrix/#deliverables","title":"Deliverables","text":"Deliverable Location Description Backend matrix <code>toolexec/docs/design-notes.md</code> Table of backend kinds + requirements"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-146-toolexec-backend-matrix/#tasks","title":"Tasks","text":"<ol> <li>List all runtime backend kinds in a single table.</li> <li>Capture isolation level and key requirements (Docker, containerd, k8s, etc.).</li> <li>Note dev-only and strongest-isolation options.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-146-toolexec-backend-matrix/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Backend kinds are enumerated.</li> <li>Requirements and isolation levels are documented.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-146-toolexec-backend-matrix/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolexec/docs/design-notes.md</code> includes a Runtime Backend Matrix table.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-147-toolexec-toolcode-runtime-contract/","title":"PRD-147: toolexec Toolcode \u2194 Runtime Contract","text":"<p>Phase: 4 - Execution Layer Priority: Medium Effort: 2 hours Dependencies: PRD-142, PRD-141 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-147-toolexec-toolcode-runtime-contract/#objective","title":"Objective","text":"<p>Document the contract between <code>code</code> orchestration and the runtime layer, including how <code>ExecuteParams</code> map to <code>runtime.ExecuteRequest</code> and how tool calls flow through the Gateway.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-147-toolexec-toolcode-runtime-contract/#deliverables","title":"Deliverables","text":"Deliverable Location Description Contract section <code>toolexec/docs/design-notes.md</code> Toolcode \u2194 Runtime mapping"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-147-toolexec-toolcode-runtime-contract/#tasks","title":"Tasks","text":"<ol> <li>Describe how <code>code</code> delegates to <code>runtime/toolcodeengine</code>.</li> <li>Document mapping of profile, limits, and Gateway injection.</li> <li>Note that the runtime enforces tool call limits and returns ToolCall records.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-147-toolexec-toolcode-runtime-contract/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Contract is documented in design notes.</li> <li>Mapping of parameters is explicit.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-147-toolexec-toolcode-runtime-contract/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolexec/docs/design-notes.md</code> includes Toolcode \u2194 Runtime Contract section.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-148-toolexec-release-propagation/","title":"PRD-148: toolexec Release + Propagation","text":"<p>Phase: 4 - Execution Layer Priority: High Effort: 1 hour Dependencies: PRD-140\u2013147 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-148-toolexec-release-propagation/#objective","title":"Objective","text":"<p>Tag and propagate the consolidated <code>toolexec</code> module into the stack version matrix.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-148-toolexec-release-propagation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Tag <code>v0.1.0</code> <code>toolexec</code> Go module release tag Version matrix <code>ai-tools-stack/VERSIONS.md</code> Already includes toolexec Dependency update <code>toolexec/go.mod</code> Use <code>tooldiscovery v0.1.0</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-148-toolexec-release-propagation/#tasks","title":"Tasks","text":"<ol> <li>Ensure <code>toolexec/go.mod</code> depends on <code>tooldiscovery v0.1.0</code>.</li> <li>Tag and push <code>v0.1.0</code> in <code>toolexec</code>.</li> <li>Verify <code>ai-tools-stack/VERSIONS.md</code> reflects <code>toolexec v0.1.0</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-148-toolexec-release-propagation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li><code>v0.1.0</code> tag exists in <code>toolexec</code>.</li> <li><code>toolexec/go.mod</code> uses <code>tooldiscovery v0.1.0</code>.</li> <li>Version matrix remains consistent.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-148-toolexec-release-propagation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolexec</code> tagged <code>v0.1.0</code> and pushed.</li> <li><code>toolexec/go.mod</code> updated to <code>tooldiscovery v0.1.0</code>.</li> <li><code>ai-tools-stack/VERSIONS.md</code> already lists <code>toolexec v0.1.0</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-149-toolexec-validation/","title":"PRD-149: toolexec Validation","text":"<p>Phase: 4 - Execution Layer Priority: High Effort: 1 hour Dependencies: PRD-140\u2013148 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-149-toolexec-validation/#objective","title":"Objective","text":"<p>Verify the toolexec layer is healthy, documented, and CI-ready.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-149-toolexec-validation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Test run <code>toolexec</code> <code>go test ./...</code> Lint run <code>toolexec</code> <code>golangci-lint run</code> Docs consistency <code>ai-tools-stack/docs/components/toolexec.md</code> Examples match API"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-149-toolexec-validation/#tasks","title":"Tasks","text":"<ol> <li>Run tests and lint in <code>toolexec</code>.</li> <li>Ensure component docs examples reflect actual API.</li> <li>Update gap tracking if needed.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-149-toolexec-validation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Tests and lint are clean.</li> <li>Docs examples align with API.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-149-toolexec-validation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>go test ./...</code> and <code>golangci-lint run</code> pass in <code>toolexec</code>.</li> <li><code>ai-tools-stack/docs/components/toolexec.md</code> updated to match runtime API.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/","title":"PRD-150: Migrate toolset","text":"<p>Phase: 5 - Composition Layer Priority: High Effort: 4 hours Dependencies: PRD-121, PRD-130 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolset</code> repository into <code>toolcompose/set/</code> as the first package in the consolidated composition layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolset</code> Target Location: <code>github.com/jonwraymond/toolcompose/set</code></p> <p>Package Contents: - Tool collection management - Toolset composition and filtering - Namespace-based organization - Permission scoping - ~1,500 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#deliverables","title":"Deliverables","text":"Deliverable Location Description Set Package <code>toolcompose/set/</code> Toolset management Tests <code>toolcompose/set/*_test.go</code> All existing tests Documentation <code>toolcompose/set/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#task-1-prepare-target-repository","title":"Task 1: Prepare Target Repository","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolcompose.git\ncd toolcompose\n\nmkdir -p set\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#task-2-clone-and-analyze-source","title":"Task 2: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolset.git\ncd toolset\n\nls -la\nwc -l *.go\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#task-3-copy-source-files","title":"Task 3: Copy Source Files","text":"<pre><code>cd /tmp/migration\n\ncp toolset/*.go toolcompose/set/\nls -la toolcompose/set/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#task-4-update-import-paths","title":"Task 4: Update Import Paths","text":"<pre><code>cd /tmp/migration/toolcompose/set\n\n# Update self-reference\nsed -i '' 's|github.com/jonwraymond/toolset|github.com/jonwraymond/toolcompose/set|g' *.go\n\n# Update dependencies\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\nsed -i '' 's|github.com/jonwraymond/tooladapter|github.com/jonwraymond/toolfoundation/adapter|g' *.go\nsed -i '' 's|github.com/jonwraymond/toolindex|github.com/jonwraymond/tooldiscovery/index|g' *.go\n\n# Verify\ngrep -r \"jonwraymond/toolset\\|jonwraymond/toolmodel\\|jonwraymond/toolindex\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#task-5-update-package-documentation","title":"Task 5: Update Package Documentation","text":"<p>File: <code>toolcompose/set/doc.go</code></p> <pre><code>// Package set provides toolset composition and management.\n//\n// This package enables creating, managing, and filtering collections of tools.\n// Toolsets provide a higher-level abstraction over individual tools, supporting\n// namespace-based organization and permission scoping.\n//\n// # Overview\n//\n// A Toolset is a named collection of tools with shared configuration:\n//\n//   - Grouping related tools together\n//   - Applying common settings (timeout, retries)\n//   - Scoping permissions\n//   - Filtering by namespace or tags\n//\n// # Usage\n//\n// Create a toolset:\n//\n//  ts := set.New(set.Config{\n//      Name:      \"data-tools\",\n//      Namespace: \"data\",\n//  })\n//\n//  ts.Add(fetchTool)\n//  ts.Add(transformTool)\n//  ts.Add(storeTool)\n//\n// Filter tools:\n//\n//  filtered := ts.Filter(set.Filter{\n//      Tags:       []string{\"input\"},\n//      Namespace:  \"data\",\n//  })\n//\n// # Composition\n//\n// Combine multiple toolsets:\n//\n//  combined := set.Merge(dataTools, apiTools, utilityTools)\n//\n// Apply restrictions:\n//\n//  restricted := ts.WithPermissions(set.Permissions{\n//      AllowedTools: []string{\"fetch\", \"transform\"},\n//      DeniedTools:  []string{\"delete\"},\n//  })\n//\n// # Registry Integration\n//\n// Register toolsets with the index:\n//\n//  idx.RegisterSet(ctx, toolset)\n//  tools, _ := idx.ListBySet(ctx, \"data-tools\")\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolset as part of\n// the ApertureStack consolidation.\npackage set\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/toolcompose\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=set_coverage.out ./set/...\n\ngo tool cover -func=set_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/toolcompose\n\ngit add -A\ngit commit -m \"feat(set): migrate toolset package\n\nMigrate toolset composition from standalone toolset repository.\n\nPackage contents:\n- Toolset type for tool collections\n- Namespace-based organization\n- Tag-based filtering\n- Permission scoping\n- Toolset merging\n\nFeatures:\n- Add/remove tools from sets\n- Filter by namespace, tags, capabilities\n- Apply shared configuration\n- Restrict permissions per set\n- Merge multiple toolsets\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n- github.com/jonwraymond/tooldiscovery/index\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolset \u2192 toolcompose/set\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#key-interfaces","title":"Key Interfaces","text":"<pre><code>package set\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Toolset represents a collection of tools.\ntype Toolset struct {\n    ID          string\n    Name        string\n    Description string\n    Namespace   string\n    Tools       []model.Tool\n    Config      Config\n    Permissions Permissions\n}\n\n// Config defines toolset configuration.\ntype Config struct {\n    Timeout     time.Duration\n    Retries     int\n    CachePolicy string\n    Metadata    map[string]any\n}\n\n// Permissions defines access restrictions.\ntype Permissions struct {\n    AllowedTools []string\n    DeniedTools  []string\n    Roles        []string\n}\n\n// Filter defines filtering criteria.\ntype Filter struct {\n    Namespace    string\n    Tags         []string\n    Capabilities []string\n    Pattern      string // Glob pattern for IDs\n}\n\n// New creates a new toolset.\nfunc New(cfg Config) *Toolset\n\n// Add adds a tool to the set.\nfunc (ts *Toolset) Add(tool model.Tool) error\n\n// Remove removes a tool from the set.\nfunc (ts *Toolset) Remove(toolID string) error\n\n// Filter returns tools matching the filter.\nfunc (ts *Toolset) Filter(f Filter) []model.Tool\n\n// WithPermissions returns a restricted copy.\nfunc (ts *Toolset) WithPermissions(p Permissions) *Toolset\n\n// Merge combines multiple toolsets.\nfunc Merge(sets ...*Toolset) *Toolset\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Toolset creation works</li> <li>[ ] Filtering works</li> <li>[ ] Permission scoping works</li> <li>[ ] Package documentation updated</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolcompose/set</code> package builds successfully</li> <li>All tests pass</li> <li>Toolsets can be created and populated</li> <li>Filtering produces correct results</li> <li>Merge combines tools correctly</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#completion-notes","title":"Completion Notes","text":"<ul> <li>Toolset migrated into <code>toolcompose/set</code> with builder, filters, policy, and exposure helpers.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolcompose\nrm -rf set/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-150-migrate-toolset/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-151: Complete toolskill</li> <li>Gate G4: Composition layer complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-151-complete-toolskill/","title":"PRD-151: Complete toolskill","text":"<p>Phase: 5 - Composition Layer Priority: High Effort: 8 hours Dependencies: PRD-150, PRD-140 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-151-complete-toolskill/#objective","title":"Objective","text":"<p>Migrate the partial <code>toolskill</code> implementation and complete it as <code>toolcompose/skill/</code> for agent skills management.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-151-complete-toolskill/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolskill</code> (partial implementation) Target Location: <code>github.com/jonwraymond/toolcompose/skill</code></p> <p>Current State: - Minimal declarative skill model (Skill/Step) implemented - Planner provides deterministic ordering - Guards + Execute flow exist via Runner interface</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-151-complete-toolskill/#deliverables","title":"Deliverables","text":"Deliverable Location Description Skill Package <code>toolcompose/skill/</code> Declarative skill model Planner <code>skill/planner.go</code> Deterministic plan generation Guards <code>skill/guard.go</code> Policy validation helpers Executor <code>skill/execute.go</code> Step execution via Runner Tests <code>skill/*_test.go</code> Contract + behavior tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-151-complete-toolskill/#tasks","title":"Tasks","text":"<ol> <li>Ensure <code>Skill</code>, <code>Step</code>, <code>Planner</code>, <code>Guard</code>, and <code>Execute</code> are implemented in <code>toolcompose/skill</code>.</li> <li>Validate deterministic planning (sorted by step ID).</li> <li>Provide guard helpers for max steps and allowed tool IDs.</li> <li>Ensure runner interface is documented and tested.</li> <li>Update docs/examples to reflect the minimal skill model.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-151-complete-toolskill/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Core interfaces defined</li> <li>[ ] Planner produces deterministic ordering</li> <li>[ ] Guard helpers enforce constraints</li> <li>[ ] Execute uses Runner</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Error handling works</li> <li>[ ] Package documentation complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-151-complete-toolskill/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolcompose/skill</code> package builds successfully</li> <li>Skill + Step validation behaves correctly</li> <li>Planner produces deterministic ordering</li> <li>Execute uses Runner and returns StepResults</li> <li>Guards enforce max steps and allowed tool IDs</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-151-complete-toolskill/#completion-notes","title":"Completion Notes","text":"<ul> <li>Skill package provides <code>Skill</code>, <code>Step</code>, <code>Planner</code>, <code>Guard</code>, and <code>Execute</code> primitives.</li> <li>Runner integration is explicit to keep tool execution decoupled.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-151-complete-toolskill/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolcompose\nrm -rf skill/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-151-complete-toolskill/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G4: Composition layer complete (both packages)</li> <li>PRD-160: Migrate toolobserve</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-152-toolcompose-docs-alignment/","title":"PRD-152: toolcompose Docs + README Alignment","text":"<p>Phase: 5 - Composition Layer Priority: High Effort: 2 hours Dependencies: PRD-150\u2013151 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-152-toolcompose-docs-alignment/#objective","title":"Objective","text":"<p>Align public-facing documentation with the consolidated <code>toolcompose</code> API.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-152-toolcompose-docs-alignment/#deliverables","title":"Deliverables","text":"Deliverable Location Description Updated README <code>toolcompose/README.md</code> Package table + descriptions Updated docs <code>toolcompose/docs/*</code> Accurate usage examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-152-toolcompose-docs-alignment/#tasks","title":"Tasks","text":"<ol> <li>Update README package table (<code>set</code>, <code>skill</code>).</li> <li>Populate <code>docs/index.md</code> with quick-start examples.</li> <li>Populate <code>docs/user-journey.md</code> with step-by-step workflow.</li> <li>Populate <code>docs/design-notes.md</code> with architecture decisions.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-152-toolcompose-docs-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>README has no <code>TBD</code> entries.</li> <li>Docs reflect current package names and usage.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-152-toolcompose-docs-alignment/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolcompose/README.md</code> updated.</li> <li><code>toolcompose/docs/index.md</code>, <code>user-journey.md</code>, <code>design-notes.md</code> populated with current API.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-153-toolcompose-set-policy-docs/","title":"PRD-153: toolcompose Set Filter + Policy Docs","text":"<p>Phase: 5 - Composition Layer Priority: Medium Effort: 2 hours Dependencies: PRD-150 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-153-toolcompose-set-policy-docs/#objective","title":"Objective","text":"<p>Document filter and policy semantics for <code>toolcompose/set</code> so callers understand how toolsets are filtered and access-controlled.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-153-toolcompose-set-policy-docs/#deliverables","title":"Deliverables","text":"Deliverable Location Description Filter/policy docs <code>toolcompose/docs/design-notes.md</code> Filter + policy ordering and semantics"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-153-toolcompose-set-policy-docs/#tasks","title":"Tasks","text":"<ol> <li>Document filter ordering and AND-composition.</li> <li>Document policy application order (after filters).</li> <li>Note determinism guarantees for Toolset listing.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-153-toolcompose-set-policy-docs/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Filter and policy semantics are documented.</li> <li>Deterministic ordering guarantees are explicit.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-153-toolcompose-set-policy-docs/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolcompose/docs/design-notes.md</code> includes filter + policy semantics.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-154-toolcompose-skill-contracts/","title":"PRD-154: toolcompose Skill Contracts","text":"<p>Phase: 5 - Composition Layer Priority: Medium Effort: 2 hours Dependencies: PRD-151 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-154-toolcompose-skill-contracts/#objective","title":"Objective","text":"<p>Document the skill contracts (validation, planning, guard, execution) so integrators understand the expected behavior.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-154-toolcompose-skill-contracts/#deliverables","title":"Deliverables","text":"Deliverable Location Description Skill contract docs <code>toolcompose/docs/design-notes.md</code> Planner/Guard/Runner semantics"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-154-toolcompose-skill-contracts/#tasks","title":"Tasks","text":"<ol> <li>Document deterministic planning (sorted by step ID).</li> <li>Document guard contracts and common helpers.</li> <li>Document runner execution contract and fail-fast behavior.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-154-toolcompose-skill-contracts/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Skill contracts are documented in design notes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-154-toolcompose-skill-contracts/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolcompose/docs/design-notes.md</code> includes skill planning + execution contracts.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-155-toolcompose-user-journey/","title":"PRD-155: toolcompose User Journey + Examples","text":"<p>Phase: 5 - Composition Layer Priority: Medium Effort: 2 hours Dependencies: PRD-150\u2013151 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-155-toolcompose-user-journey/#objective","title":"Objective","text":"<p>Provide a step-by-step user journey showing how to build toolsets and execute skills, including integration with <code>toolexec/run</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-155-toolcompose-user-journey/#deliverables","title":"Deliverables","text":"Deliverable Location Description User journey <code>toolcompose/docs/user-journey.md</code> End-to-end examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-155-toolcompose-user-journey/#tasks","title":"Tasks","text":"<ol> <li>Add toolset creation + filtering examples.</li> <li>Add skill planning + guard example.</li> <li>Add execution example using a toolexec runner adapter.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-155-toolcompose-user-journey/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>User journey contains working, API-accurate examples.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-155-toolcompose-user-journey/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolcompose/docs/user-journey.md</code> updated with toolset + skill flow.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-156-toolcompose-docs-site/","title":"PRD-156: toolcompose Docs Site Integration","text":"<p>Phase: 5 - Composition Layer Priority: Medium Effort: 1 hour Dependencies: PRD-152\u2013155 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-156-toolcompose-docs-site/#objective","title":"Objective","text":"<p>Ensure the ai-tools-stack component docs reflect the current toolcompose APIs.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-156-toolcompose-docs-site/#deliverables","title":"Deliverables","text":"Deliverable Location Description Component docs <code>ai-tools-stack/docs/components/toolcompose.md</code> Accurate API examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-156-toolcompose-docs-site/#tasks","title":"Tasks","text":"<ol> <li>Update <code>set</code> example to use builder/filter/policy APIs.</li> <li>Update <code>skill</code> example to use Planner + Execute with runner adapter.</li> <li>Update design decision bullets to match actual behavior.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-156-toolcompose-docs-site/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Component docs examples match current APIs.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-156-toolcompose-docs-site/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>ai-tools-stack/docs/components/toolcompose.md</code> updated with current API examples.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-157-toolcompose-release-propagation/","title":"PRD-157: toolcompose Release + Propagation","text":"<p>Phase: 5 - Composition Layer Priority: High Effort: 1 hour Dependencies: PRD-150\u2013156 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-157-toolcompose-release-propagation/#objective","title":"Objective","text":"<p>Tag and propagate the consolidated <code>toolcompose</code> module into the stack version matrix.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-157-toolcompose-release-propagation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Tag <code>v0.1.0</code> <code>toolcompose</code> Go module release tag Version matrix <code>ai-tools-stack/VERSIONS.md</code> Already includes toolcompose"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-157-toolcompose-release-propagation/#tasks","title":"Tasks","text":"<ol> <li>Tag and push <code>v0.1.0</code> in <code>toolcompose</code>.</li> <li>Verify <code>ai-tools-stack/VERSIONS.md</code> reflects <code>toolcompose v0.1.0</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-157-toolcompose-release-propagation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li><code>v0.1.0</code> tag exists in <code>toolcompose</code>.</li> <li>Version matrix remains consistent.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-157-toolcompose-release-propagation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolcompose</code> tagged <code>v0.1.0</code> and pushed.</li> <li><code>ai-tools-stack/VERSIONS.md</code> already lists <code>toolcompose v0.1.0</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-158-toolcompose-validation/","title":"PRD-158: toolcompose Validation","text":"<p>Phase: 5 - Composition Layer Priority: High Effort: 1 hour Dependencies: PRD-150\u2013157 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-158-toolcompose-validation/#objective","title":"Objective","text":"<p>Verify the toolcompose layer is healthy, documented, and CI-ready.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-158-toolcompose-validation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Test run <code>toolcompose</code> <code>go test ./...</code> Lint run <code>toolcompose</code> <code>golangci-lint run</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-158-toolcompose-validation/#tasks","title":"Tasks","text":"<ol> <li>Run tests and lint in <code>toolcompose</code>.</li> <li>Update gap tracking if needed.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-158-toolcompose-validation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Tests and lint are clean.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-158-toolcompose-validation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>go test ./...</code> and <code>golangci-lint run</code> pass in <code>toolcompose</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-159-toolcompose-docs-publish/","title":"PRD-159: toolcompose Docs Publish Readiness","text":"<p>Phase: 5 - Composition Layer Priority: Medium Effort: 1 hour Dependencies: PRD-156 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-159-toolcompose-docs-publish/#objective","title":"Objective","text":"<p>Confirm the docs site is wired to include toolcompose content via MkDocs multirepo imports.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-159-toolcompose-docs-publish/#deliverables","title":"Deliverables","text":"Deliverable Location Description MkDocs nav <code>ai-tools-stack/mkdocs.yml</code> toolcompose component + docs import"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-159-toolcompose-docs-publish/#tasks","title":"Tasks","text":"<ol> <li>Verify mkdocs nav includes toolcompose component page.</li> <li>Verify multirepo import for toolcompose docs is present.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-159-toolcompose-docs-publish/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>MkDocs nav includes toolcompose component and import.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-159-toolcompose-docs-publish/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>ai-tools-stack/mkdocs.yml</code> already includes toolcompose component + import.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/","title":"PRD-160: Migrate toolobserve","text":"<p>Phase: 6 - Operations Layer Priority: High Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolobserve</code> repository into <code>toolops/observe/</code> as the first package in the consolidated operations layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolobserve</code> Target Location: <code>github.com/jonwraymond/toolops/observe</code></p> <p>Package Contents: - OpenTelemetry integration for tracing - Metrics collection (Prometheus) - Structured logging (slog) - ~2,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#deliverables","title":"Deliverables","text":"Deliverable Location Description Observe Package <code>toolops/observe/</code> Observability infrastructure Tests <code>toolops/observe/*_test.go</code> All existing tests Documentation <code>toolops/observe/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#task-1-prepare-target-repository","title":"Task 1: Prepare Target Repository","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolops.git\ncd toolops\n\nmkdir -p observe\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#task-2-clone-and-migrate","title":"Task 2: Clone and Migrate","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolobserve.git\n\ncp toolobserve/*.go toolops/observe/\n\ncd toolops/observe\nsed -i '' 's|github.com/jonwraymond/toolobserve|github.com/jonwraymond/toolops/observe|g' *.go\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#task-3-update-package-documentation","title":"Task 3: Update Package Documentation","text":"<p>File: <code>toolops/observe/doc.go</code></p> <pre><code>// Package observe provides observability infrastructure for the ApertureStack ecosystem.\n//\n// This package implements distributed tracing, metrics collection, and structured\n// logging using industry-standard tools (OpenTelemetry, Prometheus, slog).\n//\n// # Tracing\n//\n// Create spans for tool execution:\n//\n//  tracer := observe.NewTracer(observe.TracerConfig{\n//      ServiceName: \"metatools-mcp\",\n//      Endpoint:    \"http://jaeger:4317\",\n//  })\n//\n//  ctx, span := tracer.Start(ctx, \"tool.execute\",\n//      observe.WithToolID(tool.ID),\n//      observe.WithToolName(tool.Name),\n//  )\n//  defer span.End()\n//\n// # Metrics\n//\n// Collect metrics for monitoring:\n//\n//  metrics := observe.NewMetrics(observe.MetricsConfig{\n//      Namespace: \"metatools\",\n//  })\n//\n//  metrics.ToolExecutions.Inc()\n//  metrics.ToolLatency.Observe(duration.Seconds())\n//\n// # Logging\n//\n// Structured logging with context:\n//\n//  logger := observe.NewLogger(observe.LogConfig{\n//      Level:  slog.LevelInfo,\n//      Format: \"json\",\n//  })\n//\n//  logger.Info(\"tool executed\",\n//      slog.String(\"tool_id\", tool.ID),\n//      slog.Duration(\"duration\", elapsed),\n//  )\n//\n// # Middleware\n//\n// Wrap tool providers with observability:\n//\n//  observed := observe.Middleware(provider, observe.MiddlewareConfig{\n//      Tracer:  tracer,\n//      Metrics: metrics,\n//      Logger:  logger,\n//  })\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolobserve as part of\n// the ApertureStack consolidation.\npackage observe\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#task-4-build-and-test","title":"Task 4: Build and Test","text":"<pre><code>cd /tmp/migration/toolops\n\ngo mod tidy\ngo build ./...\ngo test -v ./observe/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#task-5-commit-and-push","title":"Task 5: Commit and Push","text":"<pre><code>cd /tmp/migration/toolops\n\ngit add -A\ngit commit -m \"feat(observe): migrate toolobserve package\n\nMigrate observability infrastructure from standalone toolobserve repository.\n\nPackage contents:\n- OpenTelemetry tracing integration\n- Prometheus metrics collection\n- Structured logging with slog\n- Observability middleware\n\nFeatures:\n- Distributed tracing across tool executions\n- Standard metrics (requests, latency, errors)\n- JSON/text logging formats\n- Context propagation\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolobserve \u2192 toolops/observe\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Tracing works</li> <li>[ ] Metrics collection works</li> <li>[ ] Logging works</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#completion-notes","title":"Completion Notes","text":"<ul> <li><code>toolops/observe</code> includes observer, tracer, metrics, logger, and middleware helpers.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-160-migrate-toolobserve/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-161: Migrate toolcache</li> <li>PRD-162: Extract toolauth</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/","title":"PRD-161: Migrate toolcache","text":"<p>Phase: 6 - Operations Layer Priority: High Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolcache</code> repository into <code>toolops/cache/</code> as the second package in the consolidated operations layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolcache</code> Target Location: <code>github.com/jonwraymond/toolops/cache</code></p> <p>Package Contents: - Response caching middleware - Memory and Redis backends - TTL-based expiration - Key generation strategies - ~1,500 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/#deliverables","title":"Deliverables","text":"Deliverable Location Description Cache Package <code>toolops/cache/</code> Response caching Tests <code>toolops/cache/*_test.go</code> All existing tests Documentation <code>toolops/cache/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/#task-1-clone-and-migrate","title":"Task 1: Clone and Migrate","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolcache.git\n\ncp toolcache/*.go toolops/cache/\n\ncd toolops/cache\nsed -i '' 's|github.com/jonwraymond/toolcache|github.com/jonwraymond/toolops/cache|g' *.go\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/#task-2-update-package-documentation","title":"Task 2: Update Package Documentation","text":"<p>File: <code>toolops/cache/doc.go</code></p> <pre><code>// Package cache provides response caching for tool executions.\n//\n// This package implements caching middleware that reduces latency and load\n// by storing and reusing tool execution results.\n//\n// # Cache Backends\n//\n// Built-in cache implementations:\n//\n//   - MemoryCache: In-process LRU cache\n//   - RedisCache: Distributed cache using Redis\n//\n// # Usage\n//\n// Create and use a cache:\n//\n//  cache := cache.NewMemoryCache(cache.MemoryConfig{\n//      MaxSize: 1000,\n//      TTL:     5 * time.Minute,\n//  })\n//\n//  // Cache middleware\n//  cached := cache.Middleware(provider, cache.MiddlewareConfig{\n//      Cache:       cache,\n//      KeyGen:      cache.DefaultKeyGenerator,\n//      SkipTools:   []string{\"random\"},\n//      ToolTTLs:    map[string]time.Duration{\"search\": 1*time.Minute},\n//  })\n//\n// # Key Generation\n//\n// Keys are generated from tool ID and arguments:\n//\n//  keyGen := cache.NewKeyGenerator(cache.KeyConfig{\n//      Prefix:      \"metatools:\",\n//      IncludeNS:   true,\n//      IgnoredArgs: []string{\"timestamp\"},\n//  })\n//\n// # Cache Statistics\n//\n// Monitor cache performance:\n//\n//  stats := cache.Stats()\n//  fmt.Printf(\"Hits: %d, Misses: %d, Ratio: %.2f%%\\n\",\n//      stats.Hits, stats.Misses, stats.HitRatio*100)\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolcache as part of\n// the ApertureStack consolidation.\npackage cache\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/#task-3-build-and-test","title":"Task 3: Build and Test","text":"<pre><code>cd /tmp/migration/toolops\n\ngo mod tidy\ngo build ./...\ngo test -v ./cache/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/#task-4-commit-and-push","title":"Task 4: Commit and Push","text":"<pre><code>cd /tmp/migration/toolops\n\ngit add -A\ngit commit -m \"feat(cache): migrate toolcache package\n\nMigrate response caching from standalone toolcache repository.\n\nPackage contents:\n- Cache interface for pluggable backends\n- MemoryCache with LRU eviction\n- RedisCache for distributed caching\n- Caching middleware\n- Key generation strategies\n\nFeatures:\n- TTL-based expiration\n- Per-tool TTL overrides\n- Skip list for uncacheable tools\n- Cache statistics\n- Thread-safe operations\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolcache \u2192 toolops/cache\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-162: Extract toolauth</li> <li>PRD-163: Create toolresilience</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-161-migrate-toolcache/#completion-notes","title":"Completion Notes","text":"<ul> <li><code>toolops/cache</code> includes deterministic keying, policies, memory cache, and middleware.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/","title":"PRD-162: Extract toolauth","text":"<p>Phase: 6 - Operations Layer Priority: High Effort: 8 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#objective","title":"Objective","text":"<p>Extract authentication code from <code>metatools-mcp/internal/auth/</code> into <code>toolops/auth/</code> for reusable authentication middleware.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>metatools-mcp/internal/auth/</code> (embedded) Target Location: <code>github.com/jonwraymond/toolops/auth</code></p> <p>Code to Extract: - JWT authentication - API key authentication - RBAC authorization - Auth middleware - ~6,400 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#deliverables","title":"Deliverables","text":"Deliverable Location Description Auth Package <code>toolops/auth/</code> Authentication/authorization Tests <code>toolops/auth/*_test.go</code> Comprehensive tests Documentation <code>toolops/auth/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#task-1-analyze-and-copy-source","title":"Task 1: Analyze and Copy Source","text":"<pre><code>cd /Users/jraymond/Documents/Projects/jonwraymond/metatools-mcp\n\nwc -l internal/auth/*.go\n\ncd /tmp/migration/toolops\nmkdir -p auth\ncp /Users/jraymond/Documents/Projects/jonwraymond/metatools-mcp/internal/auth/*.go auth/\n\n# Update package name if needed\nsed -i '' 's|package auth|package auth|g' auth/*.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#task-2-update-imports","title":"Task 2: Update Imports","text":"<pre><code>cd /tmp/migration/toolops/auth\n\n# Update internal references\nsed -i '' 's|metatools-mcp/internal/auth|github.com/jonwraymond/toolops/auth|g' *.go\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#task-3-define-core-interfaces","title":"Task 3: Define Core Interfaces","text":"<p>File: <code>toolops/auth/auth.go</code></p> <pre><code>package auth\n\nimport (\n    \"context\"\n)\n\n// Authenticator validates credentials and returns an identity.\ntype Authenticator interface {\n    // Authenticate validates credentials in the request.\n    Authenticate(ctx context.Context, req *AuthRequest) (*AuthResult, error)\n\n    // Name returns the authenticator name (e.g., \"jwt\", \"apikey\").\n    Name() string\n\n    // Supports returns true if this authenticator can handle the request.\n    Supports(ctx context.Context, req *AuthRequest) bool\n}\n\n// Authorizer checks if an identity can perform an action.\ntype Authorizer interface {\n    // Authorize checks if the identity can perform the action.\n    Authorize(ctx context.Context, identity *Identity, action *Action) (*AuthzResult, error)\n}\n\n// AuthRequest contains authentication request data.\ntype AuthRequest struct {\n    Headers map[string]string\n    Token   string\n    APIKey  string\n    Method  string\n    Path    string\n}\n\n// AuthResult contains authentication result.\ntype AuthResult struct {\n    Authenticated bool\n    Identity      *Identity\n    Error         error\n}\n\n// Identity represents an authenticated entity.\ntype Identity struct {\n    Subject   string\n    TenantID  string\n    Roles     []string\n    Claims    map[string]any\n    ExpiresAt time.Time\n}\n\n// Action represents an authorization action.\ntype Action struct {\n    Resource   string // e.g., \"tool:calculator\"\n    Operation  string // e.g., \"execute\"\n    Context    map[string]any\n}\n\n// AuthzResult contains authorization result.\ntype AuthzResult struct {\n    Allowed bool\n    Reason  string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#task-4-create-package-documentation","title":"Task 4: Create Package Documentation","text":"<p>File: <code>toolops/auth/doc.go</code></p> <pre><code>// Package auth provides authentication and authorization for tool access.\n//\n// This package implements pluggable authentication strategies and role-based\n// access control for tool execution.\n//\n// # Authenticators\n//\n// Built-in authenticators:\n//\n//   - JWTAuthenticator: Validates JWT tokens\n//   - APIKeyAuthenticator: Validates API keys\n//   - CompositeAuthenticator: Chains multiple authenticators\n//\n// # Usage\n//\n// Create and use authenticators:\n//\n//  jwtAuth := auth.NewJWTAuthenticator(auth.JWTConfig{\n//      Secret: []byte(\"secret\"),\n//      Issuer: \"metatools\",\n//  })\n//\n//  apiKeyAuth := auth.NewAPIKeyAuthenticator(auth.APIKeyConfig{\n//      Store: keyStore,\n//  })\n//\n//  composite := auth.NewCompositeAuthenticator(jwtAuth, apiKeyAuth)\n//\n// # Authorization\n//\n// Role-based access control:\n//\n//  rbac := auth.NewRBACAuthorizer(auth.RBACConfig{\n//      Roles: map[string][]string{\n//          \"admin\": {\"*\"},\n//          \"user\":  {\"tool:*:execute\"},\n//      },\n//  })\n//\n//  result, _ := rbac.Authorize(ctx, identity, action)\n//  if !result.Allowed {\n//      // Access denied\n//  }\n//\n// # Middleware\n//\n// Protect tool providers with auth middleware:\n//\n//  protected := auth.Middleware(provider, auth.MiddlewareConfig{\n//      Authenticator: composite,\n//      Authorizer:    rbac,\n//  })\n//\n// # Extraction Note\n//\n// This package was extracted from metatools-mcp/internal/auth as part of\n// the ApertureStack consolidation to enable reuse across projects.\npackage auth\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#task-5-build-and-test","title":"Task 5: Build and Test","text":"<pre><code>cd /tmp/migration/toolops\n\ngo mod tidy\ngo build ./...\ngo test -v ./auth/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#task-6-commit-and-push","title":"Task 6: Commit and Push","text":"<pre><code>cd /tmp/migration/toolops\n\ngit add -A\ngit commit -m \"feat(auth): extract authentication package\n\nExtract auth infrastructure from metatools-mcp for reuse.\n\nPackage contents:\n- Authenticator interface\n- JWTAuthenticator for JWT tokens\n- APIKeyAuthenticator for API keys\n- CompositeAuthenticator for chaining\n- RBACAuthorizer for role-based access\n- Auth middleware\n\nFeatures:\n- Pluggable authentication strategies\n- Role-based access control\n- Identity management\n- Multi-tenant support\n- Factory-based configuration\n\nThis extraction enables auth reuse across projects.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-163: Create toolresilience</li> <li>PRD-164: Create toolhealth</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-162-extract-toolauth/#completion-notes","title":"Completion Notes","text":"<ul> <li><code>toolops/auth</code> provides authenticators (JWT/API key/OAuth2), RBAC, and transport helpers.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/","title":"PRD-163: Create toolresilience","text":"<p>Phase: 6 - Operations Layer Priority: Medium Effort: 8 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#objective","title":"Objective","text":"<p>Create a new <code>toolops/resilience/</code> package for fault tolerance patterns including circuit breakers, retries, timeouts, and bulkheads.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#package-design","title":"Package Design","text":"<p>Location: <code>github.com/jonwraymond/toolops/resilience</code></p> <p>Purpose: - Circuit breaker pattern - Retry with backoff - Timeout management - Bulkhead isolation - Rate limiting</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#deliverables","title":"Deliverables","text":"Deliverable Location Description Resilience Package <code>toolops/resilience/</code> Fault tolerance patterns Circuit Breaker <code>resilience/circuitbreaker.go</code> Circuit breaker implementation Retry <code>resilience/retry.go</code> Retry with backoff Bulkhead <code>resilience/bulkhead.go</code> Concurrency isolation Tests <code>resilience/*_test.go</code> Comprehensive tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#task-1-create-package-structure","title":"Task 1: Create Package Structure","text":"<pre><code>cd /tmp/migration/toolops\nmkdir -p resilience\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#task-2-implement-circuit-breaker","title":"Task 2: Implement Circuit Breaker","text":"<p>File: <code>toolops/resilience/circuitbreaker.go</code></p> <pre><code>package resilience\n\nimport (\n    \"context\"\n    \"errors\"\n    \"sync\"\n    \"time\"\n)\n\n// State represents circuit breaker state.\ntype State int\n\nconst (\n    StateClosed State = iota\n    StateOpen\n    StateHalfOpen\n)\n\nvar (\n    ErrCircuitOpen = errors.New(\"circuit breaker is open\")\n)\n\n// CircuitBreaker implements the circuit breaker pattern.\ntype CircuitBreaker struct {\n    name          string\n    maxFailures   int\n    timeout       time.Duration\n    halfOpenMax   int\n\n    state         State\n    failures      int\n    successes     int\n    lastFailure   time.Time\n    mu            sync.RWMutex\n}\n\n// CircuitBreakerConfig configures the circuit breaker.\ntype CircuitBreakerConfig struct {\n    Name        string\n    MaxFailures int           // Failures before opening\n    Timeout     time.Duration // Time before half-open\n    HalfOpenMax int           // Successes to close\n}\n\n// NewCircuitBreaker creates a new circuit breaker.\nfunc NewCircuitBreaker(config CircuitBreakerConfig) *CircuitBreaker {\n    return &amp;CircuitBreaker{\n        name:        config.Name,\n        maxFailures: config.MaxFailures,\n        timeout:     config.Timeout,\n        halfOpenMax: config.HalfOpenMax,\n        state:       StateClosed,\n    }\n}\n\n// Execute runs the function with circuit breaker protection.\nfunc (cb *CircuitBreaker) Execute(ctx context.Context, fn func() error) error {\n    if !cb.canExecute() {\n        return ErrCircuitOpen\n    }\n\n    err := fn()\n\n    if err != nil {\n        cb.recordFailure()\n        return err\n    }\n\n    cb.recordSuccess()\n    return nil\n}\n\nfunc (cb *CircuitBreaker) canExecute() bool {\n    cb.mu.RLock()\n    defer cb.mu.RUnlock()\n\n    switch cb.state {\n    case StateClosed:\n        return true\n    case StateOpen:\n        if time.Since(cb.lastFailure) &gt; cb.timeout {\n            cb.mu.RUnlock()\n            cb.mu.Lock()\n            cb.state = StateHalfOpen\n            cb.successes = 0\n            cb.mu.Unlock()\n            cb.mu.RLock()\n            return true\n        }\n        return false\n    case StateHalfOpen:\n        return true\n    }\n    return false\n}\n\nfunc (cb *CircuitBreaker) recordFailure() {\n    cb.mu.Lock()\n    defer cb.mu.Unlock()\n\n    cb.failures++\n    cb.lastFailure = time.Now()\n\n    if cb.failures &gt;= cb.maxFailures {\n        cb.state = StateOpen\n    }\n}\n\nfunc (cb *CircuitBreaker) recordSuccess() {\n    cb.mu.Lock()\n    defer cb.mu.Unlock()\n\n    if cb.state == StateHalfOpen {\n        cb.successes++\n        if cb.successes &gt;= cb.halfOpenMax {\n            cb.state = StateClosed\n            cb.failures = 0\n        }\n    }\n}\n\n// State returns current state.\nfunc (cb *CircuitBreaker) State() State {\n    cb.mu.RLock()\n    defer cb.mu.RUnlock()\n    return cb.state\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#task-3-implement-retry","title":"Task 3: Implement Retry","text":"<p>File: <code>toolops/resilience/retry.go</code></p> <pre><code>package resilience\n\nimport (\n    \"context\"\n    \"math\"\n    \"time\"\n)\n\n// RetryConfig configures retry behavior.\ntype RetryConfig struct {\n    MaxAttempts     int\n    InitialInterval time.Duration\n    MaxInterval     time.Duration\n    Multiplier      float64\n    RetryIf         func(error) bool\n}\n\n// DefaultRetryConfig returns default retry configuration.\nfunc DefaultRetryConfig() RetryConfig {\n    return RetryConfig{\n        MaxAttempts:     3,\n        InitialInterval: 100 * time.Millisecond,\n        MaxInterval:     10 * time.Second,\n        Multiplier:      2.0,\n        RetryIf:         func(err error) bool { return true },\n    }\n}\n\n// Retry executes the function with retry logic.\nfunc Retry(ctx context.Context, config RetryConfig, fn func() error) error {\n    var lastErr error\n    interval := config.InitialInterval\n\n    for attempt := 0; attempt &lt; config.MaxAttempts; attempt++ {\n        if err := ctx.Err(); err != nil {\n            return err\n        }\n\n        err := fn()\n        if err == nil {\n            return nil\n        }\n\n        lastErr = err\n        if !config.RetryIf(err) {\n            return err\n        }\n\n        if attempt &lt; config.MaxAttempts-1 {\n            select {\n            case &lt;-ctx.Done():\n                return ctx.Err()\n            case &lt;-time.After(interval):\n            }\n\n            interval = time.Duration(float64(interval) * config.Multiplier)\n            if interval &gt; config.MaxInterval {\n                interval = config.MaxInterval\n            }\n        }\n    }\n\n    return lastErr\n}\n\n// RetryWithResult retries a function that returns a result.\nfunc RetryWithResult[T any](ctx context.Context, config RetryConfig, fn func() (T, error)) (T, error) {\n    var result T\n    var lastErr error\n    interval := config.InitialInterval\n\n    for attempt := 0; attempt &lt; config.MaxAttempts; attempt++ {\n        if err := ctx.Err(); err != nil {\n            return result, err\n        }\n\n        res, err := fn()\n        if err == nil {\n            return res, nil\n        }\n\n        lastErr = err\n        if !config.RetryIf(err) {\n            return result, err\n        }\n\n        if attempt &lt; config.MaxAttempts-1 {\n            select {\n            case &lt;-ctx.Done():\n                return result, ctx.Err()\n            case &lt;-time.After(interval):\n            }\n\n            interval = time.Duration(float64(interval) * config.Multiplier)\n            if interval &gt; config.MaxInterval {\n                interval = config.MaxInterval\n            }\n        }\n    }\n\n    return result, lastErr\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#task-4-implement-bulkhead","title":"Task 4: Implement Bulkhead","text":"<p>File: <code>toolops/resilience/bulkhead.go</code></p> <pre><code>package resilience\n\nimport (\n    \"context\"\n    \"errors\"\n)\n\nvar (\n    ErrBulkheadFull = errors.New(\"bulkhead is full\")\n)\n\n// Bulkhead limits concurrent executions.\ntype Bulkhead struct {\n    name     string\n    maxConc  int\n    sem      chan struct{}\n}\n\n// BulkheadConfig configures the bulkhead.\ntype BulkheadConfig struct {\n    Name           string\n    MaxConcurrent  int\n}\n\n// NewBulkhead creates a new bulkhead.\nfunc NewBulkhead(config BulkheadConfig) *Bulkhead {\n    return &amp;Bulkhead{\n        name:    config.Name,\n        maxConc: config.MaxConcurrent,\n        sem:     make(chan struct{}, config.MaxConcurrent),\n    }\n}\n\n// Execute runs the function with bulkhead protection.\nfunc (b *Bulkhead) Execute(ctx context.Context, fn func() error) error {\n    select {\n    case b.sem &lt;- struct{}{}:\n        defer func() { &lt;-b.sem }()\n        return fn()\n    case &lt;-ctx.Done():\n        return ctx.Err()\n    default:\n        return ErrBulkheadFull\n    }\n}\n\n// ExecuteBlocking waits for a slot and then executes.\nfunc (b *Bulkhead) ExecuteBlocking(ctx context.Context, fn func() error) error {\n    select {\n    case b.sem &lt;- struct{}{}:\n        defer func() { &lt;-b.sem }()\n        return fn()\n    case &lt;-ctx.Done():\n        return ctx.Err()\n    }\n}\n\n// Available returns available slots.\nfunc (b *Bulkhead) Available() int {\n    return b.maxConc - len(b.sem)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#task-5-create-package-documentation","title":"Task 5: Create Package Documentation","text":"<p>File: <code>toolops/resilience/doc.go</code></p> <pre><code>// Package resilience provides fault tolerance patterns for tool execution.\n//\n// This package implements common resilience patterns to handle failures\n// gracefully and prevent cascading failures in distributed systems.\n//\n// # Circuit Breaker\n//\n// Prevent repeated calls to failing services:\n//\n//  cb := resilience.NewCircuitBreaker(resilience.CircuitBreakerConfig{\n//      Name:        \"backend\",\n//      MaxFailures: 5,\n//      Timeout:     30 * time.Second,\n//      HalfOpenMax: 2,\n//  })\n//\n//  err := cb.Execute(ctx, func() error {\n//      return callBackend()\n//  })\n//\n// # Retry with Backoff\n//\n// Retry failed operations with exponential backoff:\n//\n//  err := resilience.Retry(ctx, resilience.RetryConfig{\n//      MaxAttempts:     3,\n//      InitialInterval: 100 * time.Millisecond,\n//      MaxInterval:     10 * time.Second,\n//      Multiplier:      2.0,\n//  }, func() error {\n//      return callService()\n//  })\n//\n// # Bulkhead\n//\n// Limit concurrent executions to prevent resource exhaustion:\n//\n//  bulkhead := resilience.NewBulkhead(resilience.BulkheadConfig{\n//      Name:          \"api-calls\",\n//      MaxConcurrent: 10,\n//  })\n//\n//  err := bulkhead.Execute(ctx, func() error {\n//      return makeAPICall()\n//  })\n//\n// # Middleware\n//\n// Apply resilience patterns to tool providers:\n//\n//  resilient := resilience.Middleware(provider, resilience.MiddlewareConfig{\n//      CircuitBreaker: cb,\n//      Retry:          retryConfig,\n//      Bulkhead:       bulkhead,\n//  })\npackage resilience\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/toolops\n\ngo mod tidy\ngo build ./...\ngo test -v ./resilience/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/toolops\n\ngit add -A\ngit commit -m \"feat(resilience): add fault tolerance patterns\n\nCreate new resilience package for fault tolerance.\n\nPackage contents:\n- CircuitBreaker for failure isolation\n- Retry with exponential backoff\n- Bulkhead for concurrency limiting\n- Resilience middleware\n\nFeatures:\n- Three-state circuit breaker (closed/open/half-open)\n- Configurable failure thresholds\n- Exponential backoff with jitter\n- Non-blocking and blocking bulkhead modes\n- Generic retry with result support\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-164: Create toolhealth</li> <li>Gate G4: Operations layer complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-163-create-toolresilience/#completion-notes","title":"Completion Notes","text":"<ul> <li><code>toolops/resilience</code> implements circuit breaker, retry, rate limiter, bulkhead, timeout, and executor composition.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/","title":"PRD-164: Create toolhealth","text":"<p>Phase: 6 - Operations Layer Priority: Medium Effort: 6 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#objective","title":"Objective","text":"<p>Create a new <code>toolops/health/</code> package for health checking, readiness probes, and service status reporting.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#package-design","title":"Package Design","text":"<p>Location: <code>github.com/jonwraymond/toolops/health</code></p> <p>Purpose: - Health check endpoints - Liveness and readiness probes - Dependency health aggregation - Status reporting</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#deliverables","title":"Deliverables","text":"Deliverable Location Description Health Package <code>toolops/health/</code> Health check infrastructure Checker <code>health/checker.go</code> Health check interface Aggregator <code>health/aggregator.go</code> Multi-check aggregation HTTP Handler <code>health/handler.go</code> HTTP endpoints Tests <code>health/*_test.go</code> Comprehensive tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#task-1-create-package-structure","title":"Task 1: Create Package Structure","text":"<pre><code>cd /tmp/migration/toolops\nmkdir -p health\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#task-2-define-health-check-interface","title":"Task 2: Define Health Check Interface","text":"<p>File: <code>toolops/health/checker.go</code></p> <pre><code>package health\n\nimport (\n    \"context\"\n    \"time\"\n)\n\n// Status represents health status.\ntype Status string\n\nconst (\n    StatusHealthy   Status = \"healthy\"\n    StatusUnhealthy Status = \"unhealthy\"\n    StatusDegraded  Status = \"degraded\"\n    StatusUnknown   Status = \"unknown\"\n)\n\n// CheckResult represents a health check result.\ntype CheckResult struct {\n    Name      string\n    Status    Status\n    Message   string\n    Timestamp time.Time\n    Duration  time.Duration\n    Details   map[string]any\n}\n\n// Checker performs health checks.\ntype Checker interface {\n    // Name returns the check name.\n    Name() string\n\n    // Check performs the health check.\n    Check(ctx context.Context) *CheckResult\n}\n\n// CheckFunc is a function that performs a health check.\ntype CheckFunc func(ctx context.Context) *CheckResult\n\n// FuncChecker wraps a function as a Checker.\ntype FuncChecker struct {\n    name string\n    fn   CheckFunc\n}\n\n// NewFuncChecker creates a checker from a function.\nfunc NewFuncChecker(name string, fn CheckFunc) *FuncChecker {\n    return &amp;FuncChecker{name: name, fn: fn}\n}\n\nfunc (c *FuncChecker) Name() string                         { return c.name }\nfunc (c *FuncChecker) Check(ctx context.Context) *CheckResult { return c.fn(ctx) }\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#task-3-implement-health-aggregator","title":"Task 3: Implement Health Aggregator","text":"<p>File: <code>toolops/health/aggregator.go</code></p> <pre><code>package health\n\nimport (\n    \"context\"\n    \"sync\"\n    \"time\"\n)\n\n// AggregatedResult contains results from multiple checks.\ntype AggregatedResult struct {\n    Status    Status\n    Checks    map[string]*CheckResult\n    Timestamp time.Time\n}\n\n// Aggregator combines multiple health checkers.\ntype Aggregator struct {\n    checkers []Checker\n    timeout  time.Duration\n    mu       sync.RWMutex\n    cache    *AggregatedResult\n    cacheTTL time.Duration\n}\n\n// AggregatorConfig configures the aggregator.\ntype AggregatorConfig struct {\n    Timeout  time.Duration\n    CacheTTL time.Duration\n}\n\n// NewAggregator creates a new health aggregator.\nfunc NewAggregator(config AggregatorConfig) *Aggregator {\n    return &amp;Aggregator{\n        checkers: make([]Checker, 0),\n        timeout:  config.Timeout,\n        cacheTTL: config.CacheTTL,\n    }\n}\n\n// Register adds a checker to the aggregator.\nfunc (a *Aggregator) Register(checker Checker) {\n    a.mu.Lock()\n    defer a.mu.Unlock()\n    a.checkers = append(a.checkers, checker)\n}\n\n// Check runs all health checks.\nfunc (a *Aggregator) Check(ctx context.Context) *AggregatedResult {\n    // Check cache\n    a.mu.RLock()\n    if a.cache != nil &amp;&amp; time.Since(a.cache.Timestamp) &lt; a.cacheTTL {\n        result := a.cache\n        a.mu.RUnlock()\n        return result\n    }\n    a.mu.RUnlock()\n\n    // Run checks in parallel\n    ctx, cancel := context.WithTimeout(ctx, a.timeout)\n    defer cancel()\n\n    results := make(map[string]*CheckResult)\n    var wg sync.WaitGroup\n    var mu sync.Mutex\n\n    a.mu.RLock()\n    checkers := make([]Checker, len(a.checkers))\n    copy(checkers, a.checkers)\n    a.mu.RUnlock()\n\n    for _, checker := range checkers {\n        wg.Add(1)\n        go func(c Checker) {\n            defer wg.Done()\n\n            start := time.Now()\n            result := c.Check(ctx)\n            result.Duration = time.Since(start)\n            result.Timestamp = start\n\n            mu.Lock()\n            results[c.Name()] = result\n            mu.Unlock()\n        }(checker)\n    }\n\n    wg.Wait()\n\n    // Aggregate status\n    overallStatus := StatusHealthy\n    for _, result := range results {\n        if result.Status == StatusUnhealthy {\n            overallStatus = StatusUnhealthy\n            break\n        }\n        if result.Status == StatusDegraded &amp;&amp; overallStatus == StatusHealthy {\n            overallStatus = StatusDegraded\n        }\n    }\n\n    aggregated := &amp;AggregatedResult{\n        Status:    overallStatus,\n        Checks:    results,\n        Timestamp: time.Now(),\n    }\n\n    // Update cache\n    a.mu.Lock()\n    a.cache = aggregated\n    a.mu.Unlock()\n\n    return aggregated\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#task-4-implement-http-handler","title":"Task 4: Implement HTTP Handler","text":"<p>File: <code>toolops/health/handler.go</code></p> <pre><code>package health\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"net/http\"\n)\n\n// Handler provides HTTP health check endpoints.\ntype Handler struct {\n    aggregator *Aggregator\n    liveness   Checker\n}\n\n// NewHandler creates a new health HTTP handler.\nfunc NewHandler(aggregator *Aggregator, liveness Checker) *Handler {\n    return &amp;Handler{\n        aggregator: aggregator,\n        liveness:   liveness,\n    }\n}\n\n// LivenessHandler handles /health/live endpoint.\nfunc (h *Handler) LivenessHandler() http.HandlerFunc {\n    return func(w http.ResponseWriter, r *http.Request) {\n        ctx := r.Context()\n\n        result := h.liveness.Check(ctx)\n\n        w.Header().Set(\"Content-Type\", \"application/json\")\n\n        if result.Status != StatusHealthy {\n            w.WriteHeader(http.StatusServiceUnavailable)\n        }\n\n        json.NewEncoder(w).Encode(result)\n    }\n}\n\n// ReadinessHandler handles /health/ready endpoint.\nfunc (h *Handler) ReadinessHandler() http.HandlerFunc {\n    return func(w http.ResponseWriter, r *http.Request) {\n        ctx := r.Context()\n\n        result := h.aggregator.Check(ctx)\n\n        w.Header().Set(\"Content-Type\", \"application/json\")\n\n        switch result.Status {\n        case StatusHealthy:\n            w.WriteHeader(http.StatusOK)\n        case StatusDegraded:\n            w.WriteHeader(http.StatusOK) // Still ready, but degraded\n        default:\n            w.WriteHeader(http.StatusServiceUnavailable)\n        }\n\n        json.NewEncoder(w).Encode(result)\n    }\n}\n\n// HealthHandler handles /health endpoint (full status).\nfunc (h *Handler) HealthHandler() http.HandlerFunc {\n    return func(w http.ResponseWriter, r *http.Request) {\n        ctx := r.Context()\n\n        result := h.aggregator.Check(ctx)\n\n        w.Header().Set(\"Content-Type\", \"application/json\")\n\n        switch result.Status {\n        case StatusHealthy:\n            w.WriteHeader(http.StatusOK)\n        case StatusDegraded:\n            w.WriteHeader(http.StatusOK)\n        default:\n            w.WriteHeader(http.StatusServiceUnavailable)\n        }\n\n        json.NewEncoder(w).Encode(result)\n    }\n}\n\n// RegisterRoutes registers health endpoints on a mux.\nfunc (h *Handler) RegisterRoutes(mux *http.ServeMux) {\n    mux.HandleFunc(\"/health\", h.HealthHandler())\n    mux.HandleFunc(\"/health/live\", h.LivenessHandler())\n    mux.HandleFunc(\"/health/ready\", h.ReadinessHandler())\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#task-5-create-common-checkers","title":"Task 5: Create Common Checkers","text":"<p>File: <code>toolops/health/checkers.go</code></p> <pre><code>package health\n\nimport (\n    \"context\"\n    \"database/sql\"\n    \"net/http\"\n    \"time\"\n)\n\n// DatabaseChecker checks database connectivity.\nfunc DatabaseChecker(name string, db *sql.DB) Checker {\n    return NewFuncChecker(name, func(ctx context.Context) *CheckResult {\n        if err := db.PingContext(ctx); err != nil {\n            return &amp;CheckResult{\n                Name:    name,\n                Status:  StatusUnhealthy,\n                Message: err.Error(),\n            }\n        }\n        return &amp;CheckResult{\n            Name:    name,\n            Status:  StatusHealthy,\n            Message: \"database connection ok\",\n        }\n    })\n}\n\n// HTTPChecker checks HTTP endpoint availability.\nfunc HTTPChecker(name, url string, timeout time.Duration) Checker {\n    client := &amp;http.Client{Timeout: timeout}\n\n    return NewFuncChecker(name, func(ctx context.Context) *CheckResult {\n        req, _ := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n        resp, err := client.Do(req)\n\n        if err != nil {\n            return &amp;CheckResult{\n                Name:    name,\n                Status:  StatusUnhealthy,\n                Message: err.Error(),\n            }\n        }\n        defer resp.Body.Close()\n\n        if resp.StatusCode &gt;= 500 {\n            return &amp;CheckResult{\n                Name:    name,\n                Status:  StatusUnhealthy,\n                Message: \"service returned \" + resp.Status,\n            }\n        }\n\n        return &amp;CheckResult{\n            Name:    name,\n            Status:  StatusHealthy,\n            Message: \"endpoint reachable\",\n        }\n    })\n}\n\n// MemoryChecker checks memory usage.\nfunc MemoryChecker(name string, maxBytes uint64) Checker {\n    return NewFuncChecker(name, func(ctx context.Context) *CheckResult {\n        var m runtime.MemStats\n        runtime.ReadMemStats(&amp;m)\n\n        if m.Alloc &gt; maxBytes {\n            return &amp;CheckResult{\n                Name:    name,\n                Status:  StatusDegraded,\n                Message: \"memory usage high\",\n                Details: map[string]any{\n                    \"alloc_bytes\": m.Alloc,\n                    \"max_bytes\":   maxBytes,\n                },\n            }\n        }\n\n        return &amp;CheckResult{\n            Name:   name,\n            Status: StatusHealthy,\n            Details: map[string]any{\n                \"alloc_bytes\": m.Alloc,\n            },\n        }\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#task-6-create-package-documentation","title":"Task 6: Create Package Documentation","text":"<p>File: <code>toolops/health/doc.go</code></p> <pre><code>// Package health provides health checking infrastructure.\n//\n// This package implements Kubernetes-style health probes for\n// monitoring service availability and dependencies.\n//\n// # Health Checks\n//\n// Create custom health checkers:\n//\n//  dbChecker := health.DatabaseChecker(\"postgres\", db)\n//  redisChecker := health.HTTPChecker(\"redis\", \"http://redis:6379/ping\", 5*time.Second)\n//\n// # Aggregation\n//\n// Combine multiple checks:\n//\n//  aggregator := health.NewAggregator(health.AggregatorConfig{\n//      Timeout:  5 * time.Second,\n//      CacheTTL: 10 * time.Second,\n//  })\n//  aggregator.Register(dbChecker)\n//  aggregator.Register(redisChecker)\n//\n//  result := aggregator.Check(ctx)\n//\n// # HTTP Endpoints\n//\n// Expose health endpoints:\n//\n//  handler := health.NewHandler(aggregator, liveness)\n//  handler.RegisterRoutes(mux)\n//\n// Endpoints:\n//   - /health - Full health status\n//   - /health/live - Liveness probe (is the process alive?)\n//   - /health/ready - Readiness probe (can it serve traffic?)\n//\n// # Kubernetes Integration\n//\n// Configure Kubernetes probes:\n//\n//  livenessProbe:\n//    httpGet:\n//      path: /health/live\n//      port: 8080\n//  readinessProbe:\n//    httpGet:\n//      path: /health/ready\n//      port: 8080\npackage health\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#task-7-build-and-test","title":"Task 7: Build and Test","text":"<pre><code>cd /tmp/migration/toolops\n\ngo mod tidy\ngo build ./...\ngo test -v ./health/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd /tmp/migration/toolops\n\ngit add -A\ngit commit -m \"feat(health): add health check infrastructure\n\nCreate new health package for service health monitoring.\n\nPackage contents:\n- Checker interface for health checks\n- Aggregator for combining multiple checks\n- HTTP handler for health endpoints\n- Common checkers (database, HTTP, memory)\n\nFeatures:\n- Kubernetes-style liveness/readiness probes\n- Parallel check execution\n- Result caching\n- Status aggregation\n- Built-in common checkers\n\nEndpoints:\n- /health - Full health status\n- /health/live - Liveness probe\n- /health/ready - Readiness probe\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Checker interface defined</li> <li>[ ] Aggregator implemented</li> <li>[ ] HTTP handlers work</li> <li>[ ] Common checkers available</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G4: Operations layer complete (all 5 packages)</li> <li>PRD-170: Create tooltransport</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-164-create-toolhealth/#completion-notes","title":"Completion Notes","text":"<ul> <li><code>toolops/health</code> provides checkers, aggregators, and probe handlers.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-165-toolops-docs-alignment/","title":"PRD-165: toolops Docs + README Alignment","text":"<p>Phase: 6 - Operations Layer Priority: High Effort: 2 hours Dependencies: PRD-160\u2013164 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-165-toolops-docs-alignment/#objective","title":"Objective","text":"<p>Align public-facing documentation with the consolidated <code>toolops</code> API.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-165-toolops-docs-alignment/#deliverables","title":"Deliverables","text":"Deliverable Location Description Updated README <code>toolops/README.md</code> Package table + descriptions Updated docs <code>toolops/docs/*</code> Accurate usage examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-165-toolops-docs-alignment/#tasks","title":"Tasks","text":"<ol> <li>Update README package table (<code>observe</code>, <code>cache</code>, <code>auth</code>, <code>health</code>, <code>resilience</code>).</li> <li>Populate docs/index.md with quick-start examples.</li> <li>Populate docs/user-journey.md with step-by-step workflow.</li> <li>Populate docs/design-notes.md with architecture decisions.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-165-toolops-docs-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>README has no <code>TBD</code> entries.</li> <li>Docs reflect current package names and usage.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-165-toolops-docs-alignment/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolops/README.md</code> updated.</li> <li><code>toolops/docs/index.md</code>, <code>user-journey.md</code>, <code>design-notes.md</code> populated with current API.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-166-toolops-observe-contracts/","title":"PRD-166: toolops Observe Contracts","text":"<p>Phase: 6 - Operations Layer Priority: Medium Effort: 2 hours Dependencies: PRD-160 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-166-toolops-observe-contracts/#objective","title":"Objective","text":"<p>Document the observe contracts (Observer, Tracer, Metrics, Logger, Middleware) and how they are intended to be used.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-166-toolops-observe-contracts/#deliverables","title":"Deliverables","text":"Deliverable Location Description Observe contracts <code>toolops/docs/design-notes.md</code> Contracts and integration patterns"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-166-toolops-observe-contracts/#tasks","title":"Tasks","text":"<ol> <li>Document Observer lifecycle and shutdown expectations.</li> <li>Document Middleware usage with <code>ExecuteFunc</code>.</li> <li>Document ToolMeta fields and span naming.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-166-toolops-observe-contracts/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Observe contracts are documented in design notes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-166-toolops-observe-contracts/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolops/docs/design-notes.md</code> includes observe contract notes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-167-toolops-cache-policy-docs/","title":"PRD-167: toolops Cache Policy Docs","text":"<p>Phase: 6 - Operations Layer Priority: Medium Effort: 2 hours Dependencies: PRD-161 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-167-toolops-cache-policy-docs/#objective","title":"Objective","text":"<p>Document cache keying, policy semantics, and unsafe tag handling.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-167-toolops-cache-policy-docs/#deliverables","title":"Deliverables","text":"Deliverable Location Description Cache policy docs <code>toolops/docs/design-notes.md</code> Keying + policy semantics"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-167-toolops-cache-policy-docs/#tasks","title":"Tasks","text":"<ol> <li>Document deterministic keying (canonical JSON + SHA\u2011256).</li> <li>Document policy behavior (TTL defaults, clamping, unsafe tags).</li> <li>Document middleware behavior (no cache on errors).</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-167-toolops-cache-policy-docs/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Cache policy and keying are documented.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-167-toolops-cache-policy-docs/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolops/docs/design-notes.md</code> includes cache policy section.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-168-toolops-auth-health-resilience-docs/","title":"PRD-168: toolops Auth/Health/Resilience Docs","text":"<p>Phase: 6 - Operations Layer Priority: Medium Effort: 2 hours Dependencies: PRD-162\u2013164 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-168-toolops-auth-health-resilience-docs/#objective","title":"Objective","text":"<p>Document auth, health, and resilience contracts so integrators understand the expected behaviors and ordering.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-168-toolops-auth-health-resilience-docs/#deliverables","title":"Deliverables","text":"Deliverable Location Description Auth/health/resilience docs <code>toolops/docs/design-notes.md</code> Contracts and usage notes"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-168-toolops-auth-health-resilience-docs/#tasks","title":"Tasks","text":"<ol> <li>Document authenticator vs authorizer and RBAC contract.</li> <li>Document checker/aggregator semantics for health.</li> <li>Document resilience executor ordering and context behavior.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-168-toolops-auth-health-resilience-docs/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Auth/health/resilience contracts are documented.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-168-toolops-auth-health-resilience-docs/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolops/docs/design-notes.md</code> includes auth/health/resilience sections.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-169-toolops-release-validation/","title":"PRD-169: toolops Release + Validation","text":"<p>Phase: 6 - Operations Layer Priority: High Effort: 2 hours Dependencies: PRD-160\u2013168 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-169-toolops-release-validation/#objective","title":"Objective","text":"<p>Tag and validate the consolidated <code>toolops</code> module.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-169-toolops-release-validation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Tag <code>v0.1.0</code> <code>toolops</code> Go module release tag Test + lint <code>toolops</code> <code>go test ./...</code> + <code>golangci-lint run</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-169-toolops-release-validation/#tasks","title":"Tasks","text":"<ol> <li>Tag and push <code>v0.1.0</code> in <code>toolops</code>.</li> <li>Run tests and lint in <code>toolops</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-169-toolops-release-validation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li><code>v0.1.0</code> tag exists in <code>toolops</code>.</li> <li>Tests and lint are clean.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-169-toolops-release-validation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolops</code> tagged <code>v0.1.0</code> and pushed.</li> <li><code>go test ./...</code> and <code>golangci-lint run</code> pass.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/","title":"PRD-170: Create tooltransport","text":"<p>Phase: 7 - Protocol Layer Priority: Critical Effort: 8 hours Dependencies: PRD-120 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/transport/</code> for multi-transport support including stdio, SSE, and Streamable HTTP. WebSocket/gRPC are deferred.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#package-design","title":"Package Design","text":"<p>Location: <code>github.com/jonwraymond/toolprotocol/transport</code></p> <p>Purpose: - Transport abstraction layer - Stdio transport (MCP default) - SSE transport (legacy HTTP) - Streamable HTTP transport (MCP 2025-03-26)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#deliverables","title":"Deliverables","text":"Deliverable Location Description Transport Package <code>toolprotocol/transport/</code> Transport abstraction Stdio <code>transport/stdio.go</code> Stdio implementation SSE <code>transport/sse.go</code> HTTP SSE implementation Streamable HTTP <code>transport/streamable.go</code> MCP 2025-03-26 HTTP transport Registry <code>transport/factory.go</code> Transport registry + factory Tests <code>transport/*_test.go</code> Comprehensive tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Transport</code> and <code>Server</code> contracts with concurrency + cancellation requirements.</li> <li>Shipped stdio, SSE, and streamable HTTP transports; WebSocket/gRPC deferred.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#task-1-create-package-structure","title":"Task 1: Create Package Structure","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:ApertureStack/toolprotocol.git\ncd toolprotocol\n\nmkdir -p transport\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#task-2-define-transport-interface","title":"Task 2: Define Transport Interface","text":"<p>File: <code>toolprotocol/transport/transport.go</code></p> <pre><code>package transport\n\nimport (\n    \"context\"\n    \"io\"\n)\n\n// Transport represents a communication transport.\ntype Transport interface {\n    // Start starts the transport.\n    Start(ctx context.Context) error\n\n    // Stop stops the transport gracefully.\n    Stop(ctx context.Context) error\n\n    // Send sends a message.\n    Send(ctx context.Context, msg Message) error\n\n    // Receive returns a channel of incoming messages.\n    Receive() &lt;-chan Message\n\n    // Type returns the transport type.\n    Type() string\n}\n\n// Message represents a transport message.\ntype Message struct {\n    ID      string\n    Type    MessageType\n    Payload []byte\n    Error   error\n}\n\n// MessageType defines message types.\ntype MessageType string\n\nconst (\n    MessageRequest  MessageType = \"request\"\n    MessageResponse MessageType = \"response\"\n    MessageNotify   MessageType = \"notification\"\n    MessageError    MessageType = \"error\"\n)\n\n// Server is a transport that accepts connections.\ntype Server interface {\n    Transport\n\n    // Listen starts accepting connections.\n    Listen(addr string) error\n\n    // Connections returns a channel of new connections.\n    Connections() &lt;-chan Connection\n}\n\n// Connection represents a client connection.\ntype Connection interface {\n    io.ReadWriteCloser\n    ID() string\n}\n\n// Config is base transport configuration.\ntype Config struct {\n    ReadTimeout  time.Duration\n    WriteTimeout time.Duration\n    MaxMsgSize   int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#task-3-implement-stdio-transport","title":"Task 3: Implement Stdio Transport","text":"<p>File: <code>toolprotocol/transport/stdio.go</code></p> <pre><code>package transport\n\nimport (\n    \"bufio\"\n    \"context\"\n    \"encoding/json\"\n    \"io\"\n    \"os\"\n    \"sync\"\n)\n\n// StdioTransport implements Transport for stdio communication.\ntype StdioTransport struct {\n    reader  io.Reader\n    writer  io.Writer\n    recv    chan Message\n    done    chan struct{}\n    scanner *bufio.Scanner\n    mu      sync.Mutex\n}\n\n// StdioConfig configures stdio transport.\ntype StdioConfig struct {\n    Reader io.Reader\n    Writer io.Writer\n}\n\n// NewStdioTransport creates a new stdio transport.\nfunc NewStdioTransport(config StdioConfig) *StdioTransport {\n    reader := config.Reader\n    writer := config.Writer\n    if reader == nil {\n        reader = os.Stdin\n    }\n    if writer == nil {\n        writer = os.Stdout\n    }\n\n    return &amp;StdioTransport{\n        reader: reader,\n        writer: writer,\n        recv:   make(chan Message, 100),\n        done:   make(chan struct{}),\n    }\n}\n\nfunc (t *StdioTransport) Type() string { return \"stdio\" }\n\nfunc (t *StdioTransport) Start(ctx context.Context) error {\n    t.scanner = bufio.NewScanner(t.reader)\n    t.scanner.Buffer(make([]byte, 1024*1024), 10*1024*1024)\n\n    go t.readLoop(ctx)\n    return nil\n}\n\nfunc (t *StdioTransport) readLoop(ctx context.Context) {\n    for {\n        select {\n        case &lt;-ctx.Done():\n            return\n        case &lt;-t.done:\n            return\n        default:\n            if !t.scanner.Scan() {\n                if err := t.scanner.Err(); err != nil {\n                    t.recv &lt;- Message{Type: MessageError, Error: err}\n                }\n                return\n            }\n\n            line := t.scanner.Bytes()\n            if len(line) == 0 {\n                continue\n            }\n\n            msg := Message{\n                Type:    MessageRequest,\n                Payload: make([]byte, len(line)),\n            }\n            copy(msg.Payload, line)\n            t.recv &lt;- msg\n        }\n    }\n}\n\nfunc (t *StdioTransport) Stop(ctx context.Context) error {\n    close(t.done)\n    return nil\n}\n\nfunc (t *StdioTransport) Send(ctx context.Context, msg Message) error {\n    t.mu.Lock()\n    defer t.mu.Unlock()\n\n    _, err := t.writer.Write(append(msg.Payload, '\\n'))\n    return err\n}\n\nfunc (t *StdioTransport) Receive() &lt;-chan Message {\n    return t.recv\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#task-4-implement-sse-transport","title":"Task 4: Implement SSE Transport","text":"<p>File: <code>toolprotocol/transport/sse.go</code></p> <pre><code>package transport\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"net/http\"\n    \"sync\"\n)\n\n// SSETransport implements Server for HTTP SSE communication.\ntype SSETransport struct {\n    config SSEConfig\n    server *http.Server\n    recv   chan Message\n    conns  chan Connection\n    done   chan struct{}\n    mu     sync.RWMutex\n}\n\n// SSEConfig configures SSE transport.\ntype SSEConfig struct {\n    Host        string\n    Port        int\n    TLSCert     string\n    TLSKey      string\n    CORSOrigins []string\n}\n\n// NewSSETransport creates a new SSE transport server.\nfunc NewSSETransport(config SSEConfig) *SSETransport {\n    return &amp;SSETransport{\n        config: config,\n        recv:   make(chan Message, 100),\n        conns:  make(chan Connection, 10),\n        done:   make(chan struct{}),\n    }\n}\n\nfunc (t *SSETransport) Type() string { return \"sse\" }\n\nfunc (t *SSETransport) Start(ctx context.Context) error {\n    mux := http.NewServeMux()\n    mux.HandleFunc(\"/mcp\", t.handleMCP)\n    mux.HandleFunc(\"/health\", t.handleHealth)\n\n    addr := fmt.Sprintf(\"%s:%d\", t.config.Host, t.config.Port)\n    t.server = &amp;http.Server{\n        Addr:    addr,\n        Handler: t.corsMiddleware(mux),\n    }\n\n    go func() {\n        var err error\n        if t.config.TLSCert != \"\" {\n            err = t.server.ListenAndServeTLS(t.config.TLSCert, t.config.TLSKey)\n        } else {\n            err = t.server.ListenAndServe()\n        }\n        if err != nil &amp;&amp; err != http.ErrServerClosed {\n            t.recv &lt;- Message{Type: MessageError, Error: err}\n        }\n    }()\n\n    return nil\n}\n\nfunc (t *SSETransport) handleMCP(w http.ResponseWriter, r *http.Request) {\n    if r.Method != http.MethodPost {\n        http.Error(w, \"Method not allowed\", http.StatusMethodNotAllowed)\n        return\n    }\n\n    // Read request\n    var payload []byte\n    payload, err := io.ReadAll(r.Body)\n    if err != nil {\n        http.Error(w, err.Error(), http.StatusBadRequest)\n        return\n    }\n\n    // Create response channel\n    respChan := make(chan Message, 1)\n    msg := Message{\n        ID:      r.Header.Get(\"X-Request-ID\"),\n        Type:    MessageRequest,\n        Payload: payload,\n    }\n\n    t.recv &lt;- msg\n\n    // Wait for response (simplified - real impl needs response routing)\n    // Set SSE headers\n    w.Header().Set(\"Content-Type\", \"text/event-stream\")\n    w.Header().Set(\"Cache-Control\", \"no-cache\")\n    w.Header().Set(\"Connection\", \"keep-alive\")\n\n    flusher, ok := w.(http.Flusher)\n    if !ok {\n        http.Error(w, \"Streaming unsupported\", http.StatusInternalServerError)\n        return\n    }\n\n    select {\n    case resp := &lt;-respChan:\n        fmt.Fprintf(w, \"event: message\\ndata: %s\\n\\n\", resp.Payload)\n        flusher.Flush()\n    case &lt;-r.Context().Done():\n        return\n    }\n}\n\nfunc (t *SSETransport) handleHealth(w http.ResponseWriter, r *http.Request) {\n    w.WriteHeader(http.StatusOK)\n    w.Write([]byte(`{\"status\":\"ok\"}`))\n}\n\nfunc (t *SSETransport) corsMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        origin := r.Header.Get(\"Origin\")\n        for _, allowed := range t.config.CORSOrigins {\n            if allowed == \"*\" || allowed == origin {\n                w.Header().Set(\"Access-Control-Allow-Origin\", origin)\n                break\n            }\n        }\n        w.Header().Set(\"Access-Control-Allow-Methods\", \"POST, OPTIONS\")\n        w.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, X-Request-ID\")\n\n        if r.Method == http.MethodOptions {\n            w.WriteHeader(http.StatusNoContent)\n            return\n        }\n\n        next.ServeHTTP(w, r)\n    })\n}\n\nfunc (t *SSETransport) Stop(ctx context.Context) error {\n    close(t.done)\n    return t.server.Shutdown(ctx)\n}\n\nfunc (t *SSETransport) Send(ctx context.Context, msg Message) error {\n    // Implementation depends on connection management\n    return nil\n}\n\nfunc (t *SSETransport) Receive() &lt;-chan Message {\n    return t.recv\n}\n\nfunc (t *SSETransport) Listen(addr string) error {\n    return nil // Start handles this\n}\n\nfunc (t *SSETransport) Connections() &lt;-chan Connection {\n    return t.conns\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#task-5-create-package-documentation","title":"Task 5: Create Package Documentation","text":"<p>File: <code>toolprotocol/transport/doc.go</code></p> <pre><code>// Package transport provides multi-transport support for tool communication.\n//\n// This package implements various transport mechanisms for the MCP protocol\n// and other AI tool protocols.\n//\n// # Transports\n//\n// Built-in transports:\n//\n//   - StdioTransport: Standard input/output (MCP default)\n//   - SSETransport: HTTP with Server-Sent Events\n//   - WebSocketTransport: WebSocket bidirectional\n//   - GRPCTransport: gRPC for high-performance\n//\n// # Usage\n//\n// Create and use a transport:\n//\n//  // Stdio (default MCP)\n//  stdio := transport.NewStdioTransport(transport.StdioConfig{})\n//  stdio.Start(ctx)\n//\n//  // SSE for web clients\n//  sse := transport.NewSSETransport(transport.SSEConfig{\n//      Host: \"localhost\",\n//      Port: 8080,\n//  })\n//  sse.Start(ctx)\n//\n// # Message Loop\n//\n// Process incoming messages:\n//\n//  for msg := range transport.Receive() {\n//      response := handleMessage(msg)\n//      transport.Send(ctx, response)\n//  }\n//\n// # Transport Selection\n//\n// Select transport based on configuration:\n//\n//  func NewTransport(typ string, config any) (Transport, error) {\n//      switch typ {\n//      case \"stdio\":\n//          return NewStdioTransport(config.(StdioConfig)), nil\n//      case \"sse\":\n//          return NewSSETransport(config.(SSEConfig)), nil\n//      default:\n//          return nil, fmt.Errorf(\"unknown transport: %s\", typ)\n//      }\n//  }\npackage transport\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/toolprotocol\n\ngo mod tidy\ngo build ./...\ngo test -v ./transport/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/toolprotocol\n\ngit add -A\ngit commit -m \"feat(transport): add multi-transport support\n\nCreate transport package for protocol communication.\n\nPackage contents:\n- Transport interface for pluggable transports\n- StdioTransport for MCP stdio mode\n- SSETransport for HTTP/SSE\n- WebSocketTransport for bidirectional\n- GRPCTransport for high-performance\n\nFeatures:\n- Pluggable transport abstraction\n- Message-based communication\n- Graceful shutdown\n- CORS support for SSE\n- TLS support\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-170-create-tooltransport/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-171: Create toolwire</li> <li>PRD-172: Create tooldiscover</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/","title":"PRD-171: Create toolwire","text":"<p>Phase: 7 - Protocol Layer Priority: Critical Effort: 12 hours Dependencies: PRD-170 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/wire/</code> for protocol wire adapters supporting MCP, A2A (Google), and ACP (IBM).</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/#package-design","title":"Package Design","text":"<p>Location: <code>github.com/jonwraymond/toolprotocol/wire</code></p> <p>Purpose: - Wire protocol adapters - MCP JSON-RPC 2.0 encoding - A2A protocol encoding - ACP protocol encoding - Protocol negotiation</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/#deliverables","title":"Deliverables","text":"Deliverable Location Description Wire Package <code>toolprotocol/wire/</code> Protocol adapters MCP <code>wire/mcp.go</code> MCP wire adapter A2A <code>wire/a2a.go</code> Google A2A adapter ACP <code>wire/acp.go</code> IBM ACP adapter Registry <code>wire/registry.go</code> Wire registry + factory Tests <code>wire/*_test.go</code> Comprehensive tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Wire</code> interface with deterministic encode/decode.</li> <li>Added MCP, A2A, and ACP wire formats plus registry and error types.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/#task-1-define-wire-interface","title":"Task 1: Define Wire Interface","text":"<p>File: <code>toolprotocol/wire/wire.go</code></p> <pre><code>package wire\n\nimport (\n    \"context\"\n    \"github.com/ApertureStack/toolfoundation/model\"\n)\n\n// Wire encodes/decodes protocol messages.\ntype Wire interface {\n    // Name returns the protocol name.\n    Name() string\n\n    // Version returns the protocol version.\n    Version() string\n\n    // EncodeRequest encodes a tool request.\n    EncodeRequest(ctx context.Context, req *ToolRequest) ([]byte, error)\n\n    // DecodeRequest decodes a tool request.\n    DecodeRequest(ctx context.Context, data []byte) (*ToolRequest, error)\n\n    // EncodeResponse encodes a tool response.\n    EncodeResponse(ctx context.Context, resp *ToolResponse) ([]byte, error)\n\n    // DecodeResponse decodes a tool response.\n    DecodeResponse(ctx context.Context, data []byte) (*ToolResponse, error)\n\n    // EncodeToolList encodes a tool list.\n    EncodeToolList(ctx context.Context, tools []model.Tool) ([]byte, error)\n\n    // DecodeToolList decodes a tool list.\n    DecodeToolList(ctx context.Context, data []byte) ([]model.Tool, error)\n}\n\n// ToolRequest represents a canonical tool call request.\ntype ToolRequest struct {\n    ID        string\n    ToolID    string\n    Arguments map[string]any\n    Context   map[string]any\n}\n\n// ToolResponse represents a canonical tool call response.\ntype ToolResponse struct {\n    ID      string\n    Content []Content\n    IsError bool\n    Error   *ToolError\n}\n\n// Content represents response content.\ntype Content struct {\n    Type string // \"text\", \"image\", \"resource\"\n    Text string\n    Data []byte\n    URI  string\n}\n\n// ToolError represents a tool execution error.\ntype ToolError struct {\n    Code    int\n    Message string\n    Data    any\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/#task-2-implement-mcp-wire","title":"Task 2: Implement MCP Wire","text":"<p>File: <code>toolprotocol/wire/mcp.go</code></p> <pre><code>package wire\n\nimport (\n    \"context\"\n    \"encoding/json\"\n\n    \"github.com/ApertureStack/toolfoundation/model\"\n)\n\n// MCPWire implements Wire for MCP protocol.\ntype MCPWire struct {\n    version string\n}\n\n// NewMCPWire creates a new MCP wire adapter.\nfunc NewMCPWire() *MCPWire {\n    return &amp;MCPWire{version: \"2024-11-05\"}\n}\n\nfunc (w *MCPWire) Name() string    { return \"mcp\" }\nfunc (w *MCPWire) Version() string { return w.version }\n\n// MCP JSON-RPC structures\ntype mcpRequest struct {\n    JSONRPC string         `json:\"jsonrpc\"`\n    ID      any            `json:\"id\"`\n    Method  string         `json:\"method\"`\n    Params  map[string]any `json:\"params,omitempty\"`\n}\n\ntype mcpResponse struct {\n    JSONRPC string    `json:\"jsonrpc\"`\n    ID      any       `json:\"id\"`\n    Result  any       `json:\"result,omitempty\"`\n    Error   *mcpError `json:\"error,omitempty\"`\n}\n\ntype mcpError struct {\n    Code    int    `json:\"code\"`\n    Message string `json:\"message\"`\n    Data    any    `json:\"data,omitempty\"`\n}\n\nfunc (w *MCPWire) EncodeRequest(ctx context.Context, req *ToolRequest) ([]byte, error) {\n    mcpReq := mcpRequest{\n        JSONRPC: \"2.0\",\n        ID:      req.ID,\n        Method:  \"tools/call\",\n        Params: map[string]any{\n            \"name\":      req.ToolID,\n            \"arguments\": req.Arguments,\n        },\n    }\n    return json.Marshal(mcpReq)\n}\n\nfunc (w *MCPWire) DecodeRequest(ctx context.Context, data []byte) (*ToolRequest, error) {\n    var mcpReq mcpRequest\n    if err := json.Unmarshal(data, &amp;mcpReq); err != nil {\n        return nil, err\n    }\n\n    req := &amp;ToolRequest{\n        ID:        fmt.Sprintf(\"%v\", mcpReq.ID),\n        Arguments: make(map[string]any),\n    }\n\n    if params, ok := mcpReq.Params[\"name\"].(string); ok {\n        req.ToolID = params\n    }\n    if args, ok := mcpReq.Params[\"arguments\"].(map[string]any); ok {\n        req.Arguments = args\n    }\n\n    return req, nil\n}\n\nfunc (w *MCPWire) EncodeResponse(ctx context.Context, resp *ToolResponse) ([]byte, error) {\n    mcpResp := mcpResponse{\n        JSONRPC: \"2.0\",\n        ID:      resp.ID,\n    }\n\n    if resp.IsError {\n        mcpResp.Error = &amp;mcpError{\n            Code:    resp.Error.Code,\n            Message: resp.Error.Message,\n            Data:    resp.Error.Data,\n        }\n    } else {\n        // Convert content to MCP format\n        content := make([]map[string]any, len(resp.Content))\n        for i, c := range resp.Content {\n            content[i] = map[string]any{\n                \"type\": c.Type,\n                \"text\": c.Text,\n            }\n        }\n        mcpResp.Result = map[string]any{\n            \"content\": content,\n            \"isError\": false,\n        }\n    }\n\n    return json.Marshal(mcpResp)\n}\n\nfunc (w *MCPWire) DecodeResponse(ctx context.Context, data []byte) (*ToolResponse, error) {\n    var mcpResp mcpResponse\n    if err := json.Unmarshal(data, &amp;mcpResp); err != nil {\n        return nil, err\n    }\n\n    resp := &amp;ToolResponse{\n        ID: fmt.Sprintf(\"%v\", mcpResp.ID),\n    }\n\n    if mcpResp.Error != nil {\n        resp.IsError = true\n        resp.Error = &amp;ToolError{\n            Code:    mcpResp.Error.Code,\n            Message: mcpResp.Error.Message,\n            Data:    mcpResp.Error.Data,\n        }\n    } else if result, ok := mcpResp.Result.(map[string]any); ok {\n        if content, ok := result[\"content\"].([]any); ok {\n            for _, c := range content {\n                if cm, ok := c.(map[string]any); ok {\n                    resp.Content = append(resp.Content, Content{\n                        Type: cm[\"type\"].(string),\n                        Text: cm[\"text\"].(string),\n                    })\n                }\n            }\n        }\n    }\n\n    return resp, nil\n}\n\nfunc (w *MCPWire) EncodeToolList(ctx context.Context, tools []model.Tool) ([]byte, error) {\n    mcpTools := make([]map[string]any, len(tools))\n    for i, tool := range tools {\n        mcpTools[i] = map[string]any{\n            \"name\":        tool.ID,\n            \"description\": tool.Description,\n            \"inputSchema\": tool.InputSchema,\n        }\n    }\n\n    return json.Marshal(mcpResponse{\n        JSONRPC: \"2.0\",\n        Result: map[string]any{\n            \"tools\": mcpTools,\n        },\n    })\n}\n\nfunc (w *MCPWire) DecodeToolList(ctx context.Context, data []byte) ([]model.Tool, error) {\n    var mcpResp mcpResponse\n    if err := json.Unmarshal(data, &amp;mcpResp); err != nil {\n        return nil, err\n    }\n\n    result, ok := mcpResp.Result.(map[string]any)\n    if !ok {\n        return nil, nil\n    }\n\n    toolList, ok := result[\"tools\"].([]any)\n    if !ok {\n        return nil, nil\n    }\n\n    tools := make([]model.Tool, len(toolList))\n    for i, t := range toolList {\n        tm := t.(map[string]any)\n        tools[i] = model.Tool{\n            ID:          tm[\"name\"].(string),\n            Name:        tm[\"name\"].(string),\n            Description: tm[\"description\"].(string),\n        }\n    }\n\n    return tools, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/#task-3-implement-a2a-wire","title":"Task 3: Implement A2A Wire","text":"<p>File: <code>toolprotocol/wire/a2a.go</code></p> <pre><code>package wire\n\nimport (\n    \"context\"\n    \"encoding/json\"\n\n    \"github.com/ApertureStack/toolfoundation/model\"\n)\n\n// A2AWire implements Wire for Google A2A protocol.\ntype A2AWire struct {\n    version string\n}\n\n// NewA2AWire creates a new A2A wire adapter.\nfunc NewA2AWire() *A2AWire {\n    return &amp;A2AWire{version: \"1.0\"}\n}\n\nfunc (w *A2AWire) Name() string    { return \"a2a\" }\nfunc (w *A2AWire) Version() string { return w.version }\n\n// A2A uses different message structures focused on agent-to-agent communication\ntype a2aMessage struct {\n    ID        string         `json:\"id\"`\n    Type      string         `json:\"type\"` // \"task\", \"result\", \"error\"\n    AgentID   string         `json:\"agent_id\"`\n    TaskID    string         `json:\"task_id,omitempty\"`\n    Action    string         `json:\"action,omitempty\"`\n    Input     map[string]any `json:\"input,omitempty\"`\n    Output    any            `json:\"output,omitempty\"`\n    Error     *a2aError      `json:\"error,omitempty\"`\n}\n\ntype a2aError struct {\n    Type    string `json:\"type\"`\n    Message string `json:\"message\"`\n}\n\nfunc (w *A2AWire) EncodeRequest(ctx context.Context, req *ToolRequest) ([]byte, error) {\n    msg := a2aMessage{\n        ID:     req.ID,\n        Type:   \"task\",\n        Action: req.ToolID,\n        Input:  req.Arguments,\n    }\n    return json.Marshal(msg)\n}\n\nfunc (w *A2AWire) DecodeRequest(ctx context.Context, data []byte) (*ToolRequest, error) {\n    var msg a2aMessage\n    if err := json.Unmarshal(data, &amp;msg); err != nil {\n        return nil, err\n    }\n\n    return &amp;ToolRequest{\n        ID:        msg.ID,\n        ToolID:    msg.Action,\n        Arguments: msg.Input,\n    }, nil\n}\n\nfunc (w *A2AWire) EncodeResponse(ctx context.Context, resp *ToolResponse) ([]byte, error) {\n    msg := a2aMessage{\n        ID:   resp.ID,\n        Type: \"result\",\n    }\n\n    if resp.IsError {\n        msg.Type = \"error\"\n        msg.Error = &amp;a2aError{\n            Type:    \"execution_error\",\n            Message: resp.Error.Message,\n        }\n    } else {\n        // Combine content into output\n        var text string\n        for _, c := range resp.Content {\n            text += c.Text\n        }\n        msg.Output = text\n    }\n\n    return json.Marshal(msg)\n}\n\nfunc (w *A2AWire) DecodeResponse(ctx context.Context, data []byte) (*ToolResponse, error) {\n    var msg a2aMessage\n    if err := json.Unmarshal(data, &amp;msg); err != nil {\n        return nil, err\n    }\n\n    resp := &amp;ToolResponse{ID: msg.ID}\n\n    if msg.Error != nil {\n        resp.IsError = true\n        resp.Error = &amp;ToolError{\n            Code:    -1,\n            Message: msg.Error.Message,\n        }\n    } else if text, ok := msg.Output.(string); ok {\n        resp.Content = []Content{{Type: \"text\", Text: text}}\n    }\n\n    return resp, nil\n}\n\nfunc (w *A2AWire) EncodeToolList(ctx context.Context, tools []model.Tool) ([]byte, error) {\n    a2aTools := make([]map[string]any, len(tools))\n    for i, tool := range tools {\n        a2aTools[i] = map[string]any{\n            \"action\":      tool.ID,\n            \"description\": tool.Description,\n            \"parameters\":  tool.InputSchema,\n        }\n    }\n    return json.Marshal(map[string]any{\"actions\": a2aTools})\n}\n\nfunc (w *A2AWire) DecodeToolList(ctx context.Context, data []byte) ([]model.Tool, error) {\n    var result map[string]any\n    if err := json.Unmarshal(data, &amp;result); err != nil {\n        return nil, err\n    }\n\n    actions, ok := result[\"actions\"].([]any)\n    if !ok {\n        return nil, nil\n    }\n\n    tools := make([]model.Tool, len(actions))\n    for i, a := range actions {\n        am := a.(map[string]any)\n        tools[i] = model.Tool{\n            ID:          am[\"action\"].(string),\n            Name:        am[\"action\"].(string),\n            Description: am[\"description\"].(string),\n        }\n    }\n    return tools, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/#task-4-create-package-documentation-and-commit","title":"Task 4: Create Package Documentation and Commit","text":"<pre><code>cd /tmp/migration/toolprotocol\n\ngit add -A\ngit commit -m \"feat(wire): add protocol wire adapters\n\nCreate wire package for protocol encoding/decoding.\n\nPackage contents:\n- Wire interface for protocol adapters\n- MCPWire for MCP JSON-RPC 2.0\n- A2AWire for Google A2A protocol\n- ACPWire for IBM ACP protocol\n- Canonical request/response types\n\nFeatures:\n- Protocol-agnostic tool requests\n- Bidirectional conversion\n- Tool list encoding\n- Error propagation\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-171-create-toolwire/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-172: Create tooldiscover</li> <li>PRD-173: Create toolcontent</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-172-create-tooldiscover/","title":"PRD-172: Create tooldiscover","text":"<p>Phase: 7 - Protocol Layer Priority: High Effort: 8 hours Dependencies: PRD-171 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-172-create-tooldiscover/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/discover/</code> for capability discovery across protocols.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-172-create-tooldiscover/#package-contents","title":"Package Contents","text":"<ul> <li>Capability advertisement</li> <li>Service discovery</li> <li>Protocol negotiation</li> <li>In-memory discovery implementation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-172-create-tooldiscover/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Discoverable</code> + <code>Discovery</code> interfaces.</li> <li>Added memory-backed registry with filtering + capability negotiation.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-172-create-tooldiscover/#key-implementation","title":"Key Implementation","text":"<pre><code>package discover\n\n// Discoverable represents a discoverable service.\ntype Discoverable interface {\n    Name() string\n    Description() string\n    Version() string\n    Capabilities() *Capabilities\n    DiscoveryEndpoint() string\n}\n\n// Capabilities describes service capabilities.\ntype Capabilities struct {\n    Tools       bool\n    Resources   bool\n    Prompts     bool\n    Streaming   bool\n    Sampling    bool\n    Extensions  []string\n}\n\n// Discovery performs service discovery.\ntype Discovery struct {\n    registry map[string]Discoverable\n}\n\nfunc (d *Discovery) Register(svc Discoverable) error\nfunc (d *Discovery) Discover(ctx context.Context, filter DiscoveryFilter) ([]Discoverable, error)\nfunc (d *Discovery) Negotiate(ctx context.Context, client, server *Capabilities) (*Capabilities, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-172-create-tooldiscover/#commit-message","title":"Commit Message","text":"<pre><code>feat(discover): add capability discovery\n\nCreate discover package for service discovery.\n\nFeatures:\n- Capability advertisement\n- Service registration\n- Protocol negotiation\n- Agent card support\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-172-create-tooldiscover/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-173: Create toolcontent</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-173-create-toolcontent/","title":"PRD-173: Create toolcontent","text":"<p>Phase: 7 - Protocol Layer Priority: High Effort: 8 hours Dependencies: PRD-120 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-173-create-toolcontent/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/content/</code> for unified content/part abstraction across protocols.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-173-create-toolcontent/#package-contents","title":"Package Contents","text":"<ul> <li>Content type abstraction</li> <li>Text, image, resource, audio, file content</li> <li>MIME type handling</li> <li>Builder utilities</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-173-create-toolcontent/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Content</code> interface with concrete types and builder helpers.</li> <li>Added tests covering each content type and MIME handling.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-173-create-toolcontent/#key-implementation","title":"Key Implementation","text":"<pre><code>package content\n\n// Content represents response content.\ntype Content interface {\n    Type() ContentType\n    MimeType() string\n    Bytes() ([]byte, error)\n}\n\n// ContentType defines content types.\ntype ContentType string\n\nconst (\n    TypeText     ContentType = \"text\"\n    TypeImage    ContentType = \"image\"\n    TypeResource ContentType = \"resource\"\n    TypeAudio    ContentType = \"audio\"\n    TypeFile     ContentType = \"file\"\n)\n\n// TextContent is text-based content.\ntype TextContent struct {\n    Text string\n}\n\n// ImageContent is image-based content.\ntype ImageContent struct {\n    Data     []byte\n    MIMEType string\n    URI      string\n}\n\n// ResourceContent references a resource.\ntype ResourceContent struct {\n    URI      string\n    MIMEType string\n    Text     string\n    Blob     []byte\n}\n\n// Builder builds content.\ntype Builder struct{}\n\nfunc (b *Builder) Text(text string) Content\nfunc (b *Builder) Image(data []byte, mimeType string) Content\nfunc (b *Builder) Resource(uri string) Content\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-173-create-toolcontent/#commit-message","title":"Commit Message","text":"<pre><code>feat(content): add content abstraction\n\nCreate content package for unified content handling.\n\nFeatures:\n- Content type abstraction\n- Text, image, resource types\n- MIME type handling\n- Content builder\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-173-create-toolcontent/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-174: Create tooltask</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-174-create-tooltask/","title":"PRD-174: Create tooltask","text":"<p>Phase: 7 - Protocol Layer Priority: High Effort: 10 hours Dependencies: PRD-140, PRD-173 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-174-create-tooltask/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/task/</code> for task lifecycle management across protocols.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-174-create-tooltask/#package-contents","title":"Package Contents","text":"<ul> <li>Task creation and tracking</li> <li>State machine (pending \u2192 running \u2192 complete/failed/cancelled)</li> <li>Progress updates</li> <li>Subscriptions + cancellation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-174-create-tooltask/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Manager</code> interface with in-memory store and strict transitions.</li> <li>Added subscription channels for progress updates.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-174-create-tooltask/#key-implementation","title":"Key Implementation","text":"<pre><code>package task\n\nimport \"context\"\n\n// State represents task state.\ntype State string\n\nconst (\n    StatePending   State = \"pending\"\n    StateRunning   State = \"running\"\n    StateComplete  State = \"complete\"\n    StateFailed    State = \"failed\"\n    StateCancelled State = \"cancelled\"\n)\n\n// Task represents a long-running task.\ntype Task struct {\n    ID          string\n    State       State\n    Progress    float64\n    Message     string\n    Result      any\n    Error       error\n    CreatedAt   time.Time\n    UpdatedAt   time.Time\n    CompletedAt *time.Time\n}\n\n// Manager manages task lifecycle.\ntype Manager struct {\n    tasks map[string]*Task\n    mu    sync.RWMutex\n}\n\nfunc (m *Manager) Create(ctx context.Context, id string) (*Task, error)\nfunc (m *Manager) Get(ctx context.Context, id string) (*Task, error)\nfunc (m *Manager) Update(ctx context.Context, id string, progress float64, message string) error\nfunc (m *Manager) Complete(ctx context.Context, id string, result any) error\nfunc (m *Manager) Fail(ctx context.Context, id string, err error) error\nfunc (m *Manager) Cancel(ctx context.Context, id string) error\nfunc (m *Manager) Subscribe(ctx context.Context, id string) (&lt;-chan *Task, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-174-create-tooltask/#commit-message","title":"Commit Message","text":"<pre><code>feat(task): add task lifecycle management\n\nCreate task package for long-running operations.\n\nFeatures:\n- Task state machine\n- Progress tracking\n- Task cancellation\n- Event subscription\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-174-create-tooltask/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-175: Create toolstream</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-175-create-toolstream/","title":"PRD-175: Create toolstream","text":"<p>Phase: 7 - Protocol Layer Priority: High Effort: 8 hours Dependencies: PRD-170 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-175-create-toolstream/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/stream/</code> for streaming and incremental updates.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-175-create-toolstream/#package-contents","title":"Package Contents","text":"<ul> <li>Stream abstraction</li> <li>Progress notifications + partial results</li> <li>Backpressure handling</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-175-create-toolstream/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Source</code>/<code>Sink</code> with buffered streams and backpressure options.</li> <li>Added event types for progress/partial/complete/error/heartbeat.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-175-create-toolstream/#key-implementation","title":"Key Implementation","text":"<pre><code>package stream\n\nimport \"context\"\n\n// Stream represents a streaming response.\ntype Stream interface {\n    // Send sends an event.\n    Send(ctx context.Context, event Event) error\n\n    // Close closes the stream.\n    Close() error\n\n    // Done returns a channel closed when stream ends.\n    Done() &lt;-chan struct{}\n}\n\n// Event represents a stream event.\ntype Event struct {\n    Type    EventType\n    ID      string\n    Data    any\n    Retry   int\n}\n\n// EventType defines event types.\ntype EventType string\n\nconst (\n    EventProgress    EventType = \"progress\"\n    EventPartial     EventType = \"partial\"\n    EventComplete    EventType = \"complete\"\n    EventError       EventType = \"error\"\n    EventHeartbeat   EventType = \"heartbeat\"\n)\n\n// Source creates streams.\ntype Source struct{}\n\nfunc (s *Source) NewStream(ctx context.Context) Stream\nfunc (s *Source) NewBufferedStream(ctx context.Context, size int) Stream\n\n// Sink consumes streams.\ntype Sink struct{}\n\nfunc (s *Sink) Consume(ctx context.Context, stream Stream, handler EventHandler) error\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-175-create-toolstream/#commit-message","title":"Commit Message","text":"<pre><code>feat(stream): add streaming support\n\nCreate stream package for incremental updates.\n\nFeatures:\n- Stream abstraction\n- Event types\n- Progress notifications\n- Backpressure via buffering\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-175-create-toolstream/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-176: Create toolsession</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-176-create-toolsession/","title":"PRD-176: Create toolsession","text":"<p>Phase: 7 - Protocol Layer Priority: Medium Effort: 6 hours Dependencies: PRD-120 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-176-create-toolsession/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/session/</code> for session management.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-176-create-toolsession/#package-contents","title":"Package Contents","text":"<ul> <li>Session lifecycle</li> <li>Context preservation</li> <li>Session state storage</li> <li>TTL cleanup</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-176-create-toolsession/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Store</code> interface with memory-backed store + TTL cleanup.</li> <li>Added context helpers for request-scoped sessions.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-176-create-toolsession/#key-implementation","title":"Key Implementation","text":"<pre><code>package session\n\nimport \"context\"\n\n// Session represents a client session.\ntype Session struct {\n    ID        string\n    ClientID  string\n    State     map[string]any\n    CreatedAt time.Time\n    ExpiresAt time.Time\n}\n\n// Store manages sessions.\ntype Store interface {\n    Create(ctx context.Context, clientID string) (*Session, error)\n    Get(ctx context.Context, id string) (*Session, error)\n    Update(ctx context.Context, session *Session) error\n    Delete(ctx context.Context, id string) error\n    Cleanup(ctx context.Context) error\n}\n\n// MemoryStore is an in-memory session store.\ntype MemoryStore struct {\n    sessions map[string]*Session\n    mu       sync.RWMutex\n    ttl      time.Duration\n}\n\nfunc NewMemoryStore(ttl time.Duration) *MemoryStore\n\n// Context helpers\nfunc WithSession(ctx context.Context, session *Session) context.Context\nfunc FromContext(ctx context.Context) (*Session, bool)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-176-create-toolsession/#commit-message","title":"Commit Message","text":"<pre><code>feat(session): add session management\n\nCreate session package for state management.\n\nFeatures:\n- Session lifecycle\n- In-memory store\n- Context integration\n- Automatic cleanup\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-176-create-toolsession/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-177: Create toolelicit</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-177-create-toolelicit/","title":"PRD-177: Create toolelicit","text":"<p>Phase: 7 - Protocol Layer Priority: Medium Effort: 6 hours Dependencies: PRD-173 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-177-create-toolelicit/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/elicit/</code> for user input elicitation (MCP feature).</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-177-create-toolelicit/#package-contents","title":"Package Contents","text":"<ul> <li>Elicitation requests</li> <li>Input types (text, confirmation, choice, form)</li> <li>Response handling</li> <li>Timeout management</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-177-create-toolelicit/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented request/response types with JSON Schema support for forms.</li> <li>Added <code>Elicitor</code> and <code>Handler</code> interfaces for server/client flows.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-177-create-toolelicit/#key-implementation","title":"Key Implementation","text":"<pre><code>package elicit\n\nimport \"context\"\n\n// Request represents an elicitation request.\ntype Request struct {\n    ID          string\n    Type        RequestType\n    Message     string\n    Schema      any        // JSON Schema for structured input\n    Choices     []Choice   // For choice type\n    Default     any\n    Timeout     time.Duration\n}\n\n// RequestType defines elicitation types.\ntype RequestType string\n\nconst (\n    TypeText         RequestType = \"text\"\n    TypeConfirmation RequestType = \"confirmation\"\n    TypeChoice       RequestType = \"choice\"\n    TypeForm         RequestType = \"form\"\n)\n\n// Choice represents a selection option.\ntype Choice struct {\n    ID          string\n    Label       string\n    Description string\n}\n\n// Response represents user response.\ntype Response struct {\n    RequestID string\n    Value     any\n    Cancelled bool\n    Timeout   bool\n}\n\n// Elicitor handles user input requests.\ntype Elicitor interface {\n    Elicit(ctx context.Context, req *Request) (*Response, error)\n}\n\n// Handler processes elicitation on client side.\ntype Handler interface {\n    Handle(ctx context.Context, req *Request) (*Response, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-177-create-toolelicit/#commit-message","title":"Commit Message","text":"<pre><code>feat(elicit): add input elicitation\n\nCreate elicit package for user input requests.\n\nFeatures:\n- Multiple input types\n- JSON Schema validation\n- Timeout handling\n- Choice selection\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-177-create-toolelicit/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-178: Create toolresource</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-178-create-toolresource/","title":"PRD-178: Create toolresource","text":"<p>Phase: 7 - Protocol Layer Priority: Medium Effort: 10 hours Dependencies: PRD-130 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-178-create-toolresource/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/resource/</code> for MCP Resources support.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-178-create-toolresource/#package-contents","title":"Package Contents","text":"<ul> <li>Resource definition and storage</li> <li>Resource templates</li> <li>Subscription management</li> <li>Static provider helpers</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-178-create-toolresource/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Provider</code> interface, registry, and subscription manager.</li> <li>Added static provider with template support and tests.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-178-create-toolresource/#key-implementation","title":"Key Implementation","text":"<pre><code>package resource\n\nimport \"context\"\n\n// Resource represents an MCP resource.\ntype Resource struct {\n    URI         string\n    Name        string\n    Description string\n    MIMEType    string\n}\n\n// Contents represents resource contents.\ntype Contents struct {\n    URI      string\n    MIMEType string\n    Text     string\n    Blob     []byte\n}\n\n// Template represents a resource template.\ntype Template struct {\n    URITemplate string\n    Name        string\n    Description string\n    MIMEType    string\n}\n\n// Provider serves resources.\ntype Provider interface {\n    List(ctx context.Context) ([]Resource, error)\n    Read(ctx context.Context, uri string) (*Contents, error)\n    Templates(ctx context.Context) ([]Template, error)\n}\n\n// Subscriber receives resource updates.\ntype Subscriber interface {\n    Subscribe(ctx context.Context, uri string) (&lt;-chan *Contents, error)\n    Unsubscribe(ctx context.Context, uri string) error\n}\n\n// Registry manages resource providers.\ntype Registry struct {\n    providers map[string]Provider\n    mu        sync.RWMutex\n}\n\nfunc (r *Registry) Register(scheme string, provider Provider) error\nfunc (r *Registry) List(ctx context.Context) ([]Resource, error)\nfunc (r *Registry) Read(ctx context.Context, uri string) (*Contents, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-178-create-toolresource/#commit-message","title":"Commit Message","text":"<pre><code>feat(resource): add MCP resources support\n\nCreate resource package for content serving.\n\nFeatures:\n- Resource definition\n- Template support\n- Subscription management\n- Multi-provider registry\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-178-create-toolresource/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-179: Create toolprompt</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-179-create-toolprompt/","title":"PRD-179: Create toolprompt","text":"<p>Phase: 7 - Protocol Layer Priority: Medium Effort: 8 hours Dependencies: PRD-173 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-179-create-toolprompt/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/prompt/</code> for MCP Prompts support.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-179-create-toolprompt/#package-contents","title":"Package Contents","text":"<ul> <li>Prompt definition and storage</li> <li>Prompt templates with arguments</li> <li>Message generation</li> <li>Prompt registry</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-179-create-toolprompt/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Provider</code> + registry with argument validation.</li> <li>Added helpers for message/content creation.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-179-create-toolprompt/#key-implementation","title":"Key Implementation","text":"<pre><code>package prompt\n\nimport \"context\"\n\n// Prompt represents an MCP prompt.\ntype Prompt struct {\n    Name        string\n    Description string\n    Arguments   []Argument\n}\n\n// Argument describes a prompt argument.\ntype Argument struct {\n    Name        string\n    Description string\n    Required    bool\n}\n\n// Message represents a generated message.\ntype Message struct {\n    Role    string // \"user\" or \"assistant\"\n    Content Content\n}\n\n// Content represents message content.\ntype Content struct {\n    Type     string // \"text\", \"image\", \"resource\"\n    Text     string\n    MIMEType string\n    Data     []byte\n    Resource *ResourceRef\n}\n\n// ResourceRef references a resource.\ntype ResourceRef struct {\n    URI string\n}\n\n// Provider serves prompts.\ntype Provider interface {\n    List(ctx context.Context) ([]Prompt, error)\n    Get(ctx context.Context, name string, args map[string]string) ([]Message, error)\n}\n\n// Registry manages prompt providers.\ntype Registry struct {\n    prompts map[string]*Prompt\n    handlers map[string]PromptHandler\n    mu      sync.RWMutex\n}\n\n// PromptHandler generates messages from arguments.\ntype PromptHandler func(ctx context.Context, args map[string]string) ([]Message, error)\n\nfunc (r *Registry) Register(prompt Prompt, handler PromptHandler) error\nfunc (r *Registry) List(ctx context.Context) ([]Prompt, error)\nfunc (r *Registry) Get(ctx context.Context, name string, args map[string]string) ([]Message, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-179-create-toolprompt/#commit-message","title":"Commit Message","text":"<pre><code>feat(prompt): add MCP prompts support\n\nCreate prompt package for prompt templates.\n\nFeatures:\n- Prompt definition\n- Argument handling\n- Message generation\n- Provider registry\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-179-create-toolprompt/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G5: Protocol layer complete (all 10 packages)</li> <li>PRD-180: Update metatools-mcp</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/","title":"PRD-180: Update metatools-mcp","text":"<p>Phase: 8 - Integration Priority: Critical Effort: 12 hours Dependencies: All Phase 2-7 PRDs Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/#objective","title":"Objective","text":"<p>Update metatools-mcp to use all consolidated repositories instead of standalone repos.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/#task-1-update-gomod","title":"Task 1: Update go.mod","text":"<p>Replace all standalone imports with consolidated repos:</p> <pre><code>// Before\nrequire (\n    github.com/jonwraymond/toolmodel v0.x.x\n    github.com/jonwraymond/tooladapter v0.x.x\n    github.com/jonwraymond/toolindex v0.x.x\n    github.com/jonwraymond/toolsearch v0.x.x\n    github.com/jonwraymond/toolrun v0.x.x\n    github.com/jonwraymond/toolruntime v0.x.x\n    github.com/jonwraymond/toolcode v0.x.x\n    github.com/jonwraymond/toolset v0.x.x\n    github.com/jonwraymond/toolobserve v0.x.x\n    github.com/jonwraymond/toolcache v0.x.x\n)\n\n// After\nrequire (\n    github.com/jonwraymond/toolfoundation v0.1.0\n    github.com/jonwraymond/tooldiscovery v0.1.0\n    github.com/jonwraymond/toolexec v0.1.0\n    github.com/jonwraymond/toolcompose v0.1.0\n    github.com/jonwraymond/toolops v0.1.0\n    github.com/jonwraymond/toolprotocol v0.1.0\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/#task-2-update-import-statements","title":"Task 2: Update Import Statements","text":"<pre><code># Find all files with old imports\ngrep -r \"github.com/jonwraymond/tool\" --include=\"*.go\" | grep -v \"toolfoundation\\|tooldiscovery\\|toolexec\\|toolcompose\\|toolops\\|toolprotocol\"\n\n# Update imports using sed\nfind . -name \"*.go\" -exec sed -i '' \\\n  -e 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' \\\n  -e 's|github.com/jonwraymond/tooladapter|github.com/jonwraymond/toolfoundation/adapter|g' \\\n  -e 's|github.com/jonwraymond/toolindex|github.com/jonwraymond/tooldiscovery/index|g' \\\n  -e 's|github.com/jonwraymond/toolsearch|github.com/jonwraymond/tooldiscovery/search|g' \\\n  -e 's|github.com/jonwraymond/toolrun|github.com/jonwraymond/toolexec/run|g' \\\n  -e 's|github.com/jonwraymond/toolruntime|github.com/jonwraymond/toolexec/runtime|g' \\\n  -e 's|github.com/jonwraymond/toolcode|github.com/jonwraymond/toolexec/code|g' \\\n  -e 's|github.com/jonwraymond/toolset|github.com/jonwraymond/toolcompose/set|g' \\\n  -e 's|github.com/jonwraymond/toolobserve|github.com/jonwraymond/toolops/observe|g' \\\n  -e 's|github.com/jonwraymond/toolcache|github.com/jonwraymond/toolops/cache|g' \\\n  {} \\;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/#task-3-remove-internal-packages","title":"Task 3: Remove Internal Packages","text":"<p>Extract code that was internalized into consolidated repos:</p> <pre><code># Remove internal packages now in consolidated repos\nrm -rf internal/backend/  # Now in toolexec/backend\nrm -rf internal/auth/     # Now in toolops/auth\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/#task-4-update-internal-references","title":"Task 4: Update Internal References","text":"<p>Update remaining internal code to use new packages:</p> <pre><code>// Before\nimport \"metatools-mcp/internal/auth\"\n\n// After\nimport \"github.com/jonwraymond/toolops/auth\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/#task-5-build-and-test","title":"Task 5: Build and Test","text":"<pre><code>go mod tidy\ngo build ./...\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/#task-6-commit","title":"Task 6: Commit","text":"<pre><code>git add -A\ngit commit -m \"feat: migrate to consolidated repositories\n\nUpdate all imports to use consolidated ApertureStack repos:\n\nFoundation:\n- toolmodel \u2192 toolfoundation/model\n- tooladapter \u2192 toolfoundation/adapter\n\nDiscovery:\n- toolindex \u2192 tooldiscovery/index\n- toolsearch \u2192 tooldiscovery/search\n\nExecution:\n- toolrun \u2192 toolexec/run\n- toolruntime \u2192 toolexec/runtime\n- toolcode \u2192 toolexec/code\n\nComposition:\n- toolset \u2192 toolcompose/set\n\nOperations:\n- toolobserve \u2192 toolops/observe\n- toolcache \u2192 toolops/cache\n\n## Implementation Summary\n\n- All code imports updated to consolidated packages under `github.com/jonwraymond`.\n- Docs/diagrams updated to reference consolidated layers and build tags.\n- go.mod cleaned to depend on tooldiscovery/toolexec/toolfoundation.\n- internal/auth \u2192 toolops/auth\n\nBREAKING CHANGE: All import paths have changed.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All old imports replaced</li> <li>[x] go mod tidy succeeds</li> <li>[x] go build succeeds</li> <li>[x] All tests pass</li> <li>[ ] MCP server runs correctly</li> <li>[ ] Tool execution works</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-180-update-metatools-mcp/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-181: Update ai-tools-stack</li> <li>PRD-182: Documentation Site</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-181-update-ai-tools-stack/","title":"PRD-181: Update ai-tools-stack","text":"<p>Phase: 8 - Integration Priority: High Effort: 4 hours Dependencies: PRD-180 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-181-update-ai-tools-stack/#objective","title":"Objective","text":"<p>Update ai-tools-stack coordination repository with new consolidated structure.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-181-update-ai-tools-stack/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-181-update-ai-tools-stack/#task-1-update-versionsmd","title":"Task 1: Update VERSIONS.md","text":"<p>Replace standalone repos with consolidated repos:</p> <pre><code># ApertureStack Version Matrix\n\n## Consolidated Repositories (v0.1.0)\n\n| Repository | Version | Packages |\n|------------|---------|----------|\n| toolfoundation | v0.1.0 | model, adapter, version |\n| tooldiscovery | v0.1.0 | index, search, semantic, docs |\n| toolexec | v0.1.0 | run, runtime, code, backend |\n| toolcompose | v0.1.0 | set, skill |\n| toolops | v0.1.0 | observe, cache, resilience, health, auth |\n| toolprotocol | v0.1.0 | transport, wire, discover, content, task, stream, session, elicit, resource, prompt |\n| metatools-mcp | v0.2.0 | (uses all above) |\n\n## Compatibility Matrix\n\n| metatools-mcp | toolfoundation | tooldiscovery | toolexec | toolcompose | toolops | toolprotocol |\n|---------------|----------------|---------------|----------|-------------|---------|--------------|\n| v0.2.0 | v0.1.0 | v0.1.0 | v0.1.0 | v0.1.0 | v0.1.0 | v0.1.0 |\n\n## Archived Repositories\n\nThe following repositories have been consolidated and archived:\n\n- toolmodel \u2192 toolfoundation/model\n- tooladapter \u2192 toolfoundation/adapter\n- toolindex \u2192 tooldiscovery/index\n- toolsearch \u2192 tooldiscovery/search\n- toolsemantic \u2192 tooldiscovery/semantic\n- tooldocs \u2192 tooldiscovery/docs\n- toolrun \u2192 toolexec/run\n- toolruntime \u2192 toolexec/runtime\n- toolcode \u2192 toolexec/code\n- toolset \u2192 toolcompose/set\n- toolskill \u2192 toolcompose/skill\n- toolobserve \u2192 toolops/observe\n- toolcache \u2192 toolops/cache\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-181-update-ai-tools-stack/#task-2-update-gomod","title":"Task 2: Update go.mod","text":"<pre><code>module github.com/jonwraymond/ai-tools-stack\n\ngo 1.24\n\nrequire (\n    github.com/jonwraymond/toolfoundation v0.1.0\n    github.com/jonwraymond/tooldiscovery v0.1.0\n    github.com/jonwraymond/toolexec v0.1.0\n    github.com/jonwraymond/toolcompose v0.1.0\n    github.com/jonwraymond/toolops v0.1.0\n    github.com/jonwraymond/toolprotocol v0.1.0\n    github.com/jonwraymond/metatools-mcp v0.5.0\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-181-update-ai-tools-stack/#task-3-update-readmemd","title":"Task 3: Update README.md","text":"<pre><code># ApertureStack\n\nAI Tool Ecosystem for building, discovering, and executing AI agent tools.\n\n## Repositories\n\n| Repository | Description |\n|------------|-------------|\n| [toolfoundation](https://github.com/jonwraymond/toolfoundation) | Core schemas, adapters, versioning |\n| [tooldiscovery](https://github.com/jonwraymond/tooldiscovery) | Registry, search, semantic, docs |\n| [toolexec](https://github.com/jonwraymond/toolexec) | Execution, runtime, code |\n| [toolcompose](https://github.com/jonwraymond/toolcompose) | Toolsets, skills |\n| [toolops](https://github.com/jonwraymond/toolops) | Observability, caching, auth |\n| [toolprotocol](https://github.com/jonwraymond/toolprotocol) | MCP, A2A, ACP protocols |\n| [metatools-mcp](https://github.com/jonwraymond/metatools-mcp) | MCP server |\n\n## Quick Start\n\n\\`\\`\\`bash\ngo get github.com/jonwraymond/metatools-mcp@latest\n\\`\\`\\`\n\n## Documentation\n\nSee the GitHub Pages docs site for ai-tools-stack\n\n## Implementation Summary\n\n- mkdocs nav + multirepo imports updated to consolidated repos.\n- docs workflow + changelog/version scripts updated to consolidated repos.\n- VERSIONS matrix aligned with consolidated repo tags.\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-181-update-ai-tools-stack/#task-4-update-scripts","title":"Task 4: Update Scripts","text":"<p>Update any automation scripts to use new repo names.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-181-update-ai-tools-stack/#task-5-commit","title":"Task 5: Commit","text":"<pre><code>git add -A\ngit commit -m \"feat: update for consolidated repositories\n\n- Update VERSIONS.md with new repo structure\n- Update go.mod dependencies\n- Update README with new repos\n- Archive old repo references\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-181-update-ai-tools-stack/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-182: Documentation Site</li> <li>PRD-190: Archive Old Repos</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-182-documentation-site/","title":"PRD-182: Documentation Site","text":"<p>Phase: 8 - Integration Priority: Medium Effort: 6 hours Dependencies: PRD-181 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-182-documentation-site/#objective","title":"Objective","text":"<p>Update MkDocs documentation site with consolidated repository structure.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-182-documentation-site/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-182-documentation-site/#task-1-update-mkdocsyml","title":"Task 1: Update mkdocs.yml","text":"<pre><code>site_name: ApertureStack\nsite_url: https://jonwraymond.github.io/ai-tools-stack/\n\nnav:\n  - Home: index.md\n  - Getting Started:\n    - Installation: getting-started/install.md\n    - Quick Start: getting-started/quickstart.md\n  - Foundation:\n    - Overview: foundation/index.md\n    - Model: foundation/model.md\n    - Adapter: foundation/adapter.md\n    - Version: foundation/version.md\n  - Discovery:\n    - Overview: discovery/index.md\n    - Index: discovery/index-pkg.md\n    - Search: discovery/search.md\n    - Semantic: discovery/semantic.md\n    - Docs: discovery/docs.md\n  - Execution:\n    - Overview: execution/index.md\n    - Run: execution/run.md\n    - Runtime: execution/runtime.md\n    - Code: execution/code.md\n    - Backend: execution/backend.md\n  - Composition:\n    - Overview: composition/index.md\n    - Set: composition/set.md\n    - Skill: composition/skill.md\n  - Operations:\n    - Overview: operations/index.md\n    - Observe: operations/observe.md\n    - Cache: operations/cache.md\n    - Auth: operations/auth.md\n    - Resilience: operations/resilience.md\n    - Health: operations/health.md\n  - Protocol:\n    - Overview: protocol/index.md\n    - Transport: protocol/transport.md\n    - Wire: protocol/wire.md\n    - MCP: protocol/mcp.md\n    - A2A: protocol/a2a.md\n  - API Reference:\n    - metatools-mcp: api/metatools-mcp.md\n\ntheme:\n  name: material\n  features:\n    - navigation.tabs\n    - navigation.sections\n    - search.suggest\n\nplugins:\n  - search\n  - multirepo:\n      repos:\n        - name: toolfoundation\n          import: github.com/jonwraymond/toolfoundation/docs\n        - name: tooldiscovery\n          import: github.com/jonwraymond/tooldiscovery/docs\n        - name: toolexec\n          import: github.com/jonwraymond/toolexec/docs\n        - name: toolcompose\n          import: github.com/jonwraymond/toolcompose/docs\n        - name: toolops\n          import: github.com/jonwraymond/toolops/docs\n        - name: toolprotocol\n          import: github.com/jonwraymond/toolprotocol/docs\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-182-documentation-site/#task-2-update-landing-page","title":"Task 2: Update Landing Page","text":"<pre><code># ApertureStack\n\nBuild, discover, and execute AI agent tools with a unified ecosystem.\n\n## Architecture\n\n```mermaid\ngraph TB\n    subgraph \"Application Layer\"\n        metatools-mcp[\"metatools-mcp\"]\n    end\n\n    subgraph \"Protocol Layer\"\n        toolprotocol[\"toolprotocol\"]\n    end\n\n    subgraph \"Operations Layer\"\n        toolops[\"toolops\"]\n    end\n\n    subgraph \"Composition Layer\"\n        toolcompose[\"toolcompose\"]\n    end\n\n    subgraph \"Execution Layer\"\n        toolexec[\"toolexec\"]\n    end\n\n    subgraph \"Discovery Layer\"\n        tooldiscovery[\"tooldiscovery\"]\n    end\n\n    subgraph \"Foundation Layer\"\n        toolfoundation[\"toolfoundation\"]\n    end\n\n    metatools-mcp --&gt; toolprotocol\n    metatools-mcp --&gt; toolops\n    metatools-mcp --&gt; toolcompose\n    toolprotocol --&gt; toolfoundation\n    toolops --&gt; toolfoundation\n    toolcompose --&gt; toolexec\n    toolcompose --&gt; tooldiscovery\n    toolexec --&gt; toolfoundation\n    tooldiscovery --&gt; toolfoundation\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-182-documentation-site/#repositories","title":"Repositories","text":"Layer Repository Packages Foundation toolfoundation model, adapter, version Discovery tooldiscovery index, search, semantic, docs Execution toolexec run, runtime, code, backend Composition toolcompose set, skill Operations toolops observe, cache, auth, resilience, health Protocol toolprotocol transport, wire, discover, content, task, stream, session, elicit, resource, prompt"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-182-documentation-site/#quick-start","title":"Quick Start","text":"<p><pre><code># Install metatools-mcp\ngo install github.com/jonwraymond/metatools-mcp/cmd/metatools@latest\n\n# Run MCP server\nmetatools serve\n\n## Implementation Summary\n\n- mkdocs nav and multirepo imports aligned with consolidated repos.\n- D2 diagrams re-rendered and embedded into component docs.\n- GitHub Pages publish flow uses mike for `latest`/`stable` versions.\n</code></pre> <pre><code>### Task 3: Build and Deploy\n\n```bash\n# Build docs\nmkdocs build\n\n# Deploy to GitHub Pages\nmkdocs gh-deploy\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-182-documentation-site/#task-4-commit","title":"Task 4: Commit","text":"<pre><code>git add -A\ngit commit -m \"docs: update for consolidated repositories\n\n- Restructure navigation for 6 consolidated repos\n- Update architecture diagrams\n- Add multirepo imports\n- Update landing page\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-182-documentation-site/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-190: Archive Old Repos</li> <li>Gate G6: Integration complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-190-archive-old-repos/","title":"PRD-190: Archive Old Repos","text":"<p>Phase: 9 - Cleanup Priority: High Effort: 2 hours Dependencies: PRD-180 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-190-archive-old-repos/#objective","title":"Objective","text":"<p>Archive all 13 standalone repositories that have been consolidated.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-190-archive-old-repos/#repositories-to-archive","title":"Repositories to Archive","text":"Repository Migrated To toolmodel toolfoundation/model tooladapter toolfoundation/adapter toolindex tooldiscovery/index toolsearch tooldiscovery/search toolsemantic tooldiscovery/semantic tooldocs tooldiscovery/tooldoc toolrun toolexec/run toolruntime toolexec/runtime toolcode toolexec/code toolset toolcompose/set toolskill toolcompose/skill toolobserve toolops/observe toolcache toolops/cache"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-190-archive-old-repos/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-190-archive-old-repos/#task-1-add-deprecation-notices","title":"Task 1: Add Deprecation Notices","text":"<p>For each repo, update README.md:</p> <pre><code># \u26a0\ufe0f DEPRECATED\n\nThis repository has been archived. The code has been migrated to:\n\n**[toolfoundation](https://github.com/jonwraymond/toolfoundation)** (model package)\n\n## Migration\n\nUpdate your imports:\n\n```go\n// Before\nimport \"github.com/jonwraymond/toolmodel\"\n\n// After\nimport \"github.com/jonwraymond/toolfoundation/model\"\n</code></pre> <p>See the stack migration guide for details: https://jonwraymond.github.io/ai-tools-stack/operations/migration-guide/ <pre><code>### Task 2: Create Migration Guides\n\n**File: MIGRATION.md** (per repo)\n\n```markdown\n# Migration Guide\n\n## Import Changes\n\n| Old | New |\n|-----|-----|\n| `github.com/jonwraymond/toolmodel` | `github.com/jonwraymond/toolfoundation/model` |\n\n## Breaking Changes\n\n- Package name changed from `toolmodel` to `model`\n- All functionality preserved\n\n## Steps\n\n1. Update go.mod:\n   ```bash\ngo get github.com/jonwraymond/toolfoundation@latest\n   ```\n\n2. Update imports:\n   ```bash\nsed -i 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n   ```\n\n3. Remove old dependency:\n   ```bash\n   go mod tidy\n   ```\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-190-archive-old-repos/#task-3-archive-repositories","title":"Task 3: Archive Repositories","text":"<pre><code>REPOS=(\n  toolmodel\n  tooladapter\n  toolindex\n  toolsearch\n  toolsemantic\n  tooldocs\n  toolrun\n  toolruntime\n  toolcode\n  toolset\n  toolskill\n  toolobserve\n  toolcache\n)\n\nfor repo in \"${REPOS[@]}\"; do\n  echo \"Archiving jonwraymond/$repo...\"\n\n  # Update README with deprecation notice\n  # (done manually per repo with appropriate redirect)\n\n  # Archive the repository\n  gh repo archive \"jonwraymond/$repo\" --yes\n\n  echo \"\u2713 $repo archived\"\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-190-archive-old-repos/#task-4-verify-archives","title":"Task 4: Verify Archives","text":"<pre><code># List archived repos\ngh repo list jonwraymond --archived --limit 20\n\n# Verify each is read-only\nfor repo in toolmodel tooladapter toolindex toolsearch; do\n  gh repo view \"jonwraymond/$repo\" --json isArchived -q '.isArchived'\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-190-archive-old-repos/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All 13 repos have deprecation notices</li> <li>[x] All 13 repos have MIGRATION.md</li> <li>[x] All 13 repos are archived</li> <li>[x] Archives are read-only</li> <li>[x] Redirects work (README links to new location)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-190-archive-old-repos/#rollback-plan","title":"Rollback Plan","text":"<pre><code># Unarchive a repo if needed\ngh repo unarchive jonwraymond/toolmodel --yes\n\n## Verification (2026-02-01)\n\n- All 13 repos archived under `jonwraymond`.\n- README contains deprecation notice; MIGRATION.md present in each repo.\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-190-archive-old-repos/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-191: Update Submodules</li> <li>PRD-192: Validation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/","title":"PRD-191: Update Submodules","text":"<p>Phase: 9 - Cleanup Priority: High Effort: 2 hours Dependencies: PRD-190 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#objective","title":"Objective","text":"<p>Update ApertureStack root to use new consolidated submodules.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#task-1-remove-old-submodules","title":"Task 1: Remove Old Submodules","text":"<pre><code>cd /Users/jraymond/Documents/Projects/ApertureStack\n\n# Remove old submodules\nOLD_REPOS=(\n  toolmodel\n  tooladapter\n  toolindex\n  toolsearch\n  toolsemantic\n  tooldocs\n  toolrun\n  toolruntime\n  toolcode\n  toolset\n  toolskill\n  toolobserve\n  toolcache\n)\n\nfor repo in \"${OLD_REPOS[@]}\"; do\n  git submodule deinit -f \"$repo\" 2&gt;/dev/null || true\n  git rm -f \"$repo\" 2&gt;/dev/null || true\n  rm -rf \".git/modules/$repo\" 2&gt;/dev/null || true\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#task-2-add-new-submodules","title":"Task 2: Add New Submodules","text":"<pre><code>cd /Users/jraymond/Documents/Projects/ApertureStack\n\n# Add consolidated submodules\ngit submodule add git@github.com:jonwraymond/toolfoundation.git toolfoundation\ngit submodule add git@github.com:jonwraymond/tooldiscovery.git tooldiscovery\ngit submodule add git@github.com:jonwraymond/toolexec.git toolexec\ngit submodule add git@github.com:jonwraymond/toolcompose.git toolcompose\ngit submodule add git@github.com:jonwraymond/toolops.git toolops\ngit submodule add git@github.com:jonwraymond/toolprotocol.git toolprotocol\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#task-3-update-gitmodules","title":"Task 3: Update .gitmodules","text":"<p>Verify <code>.gitmodules</code> looks like:</p> <pre><code>[submodule \"toolfoundation\"]\n    path = toolfoundation\n    url = git@github.com:jonwraymond/toolfoundation.git\n\n[submodule \"tooldiscovery\"]\n    path = tooldiscovery\n    url = git@github.com:jonwraymond/tooldiscovery.git\n\n[submodule \"toolexec\"]\n    path = toolexec\n    url = git@github.com:jonwraymond/toolexec.git\n\n[submodule \"toolcompose\"]\n    path = toolcompose\n    url = git@github.com:jonwraymond/toolcompose.git\n\n[submodule \"toolops\"]\n    path = toolops\n    url = git@github.com:jonwraymond/toolops.git\n\n[submodule \"toolprotocol\"]\n    path = toolprotocol\n    url = git@github.com:jonwraymond/toolprotocol.git\n\n[submodule \"metatools-mcp\"]\n    path = metatools-mcp\n    url = git@github.com:jonwraymond/metatools-mcp.git\n\n[submodule \"ai-tools-stack\"]\n    path = ai-tools-stack\n    url = git@github.com:jonwraymond/ai-tools-stack.git\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#task-4-commit-changes","title":"Task 4: Commit Changes","text":"<pre><code>git add .gitmodules\ngit add toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol\n\ngit commit -m \"feat: update submodules to consolidated repos\n\nRemove old standalone submodules:\n- toolmodel, tooladapter\n- toolindex, toolsearch, toolsemantic, tooldocs\n- toolrun, toolruntime, toolcode\n- toolset, toolskill\n- toolobserve, toolcache\n\nAdd consolidated submodules:\n- toolfoundation (model, adapter, version)\n- tooldiscovery (index, search, semantic, docs)\n- toolexec (run, runtime, code, backend)\n- toolcompose (set, skill)\n- toolops (observe, cache, resilience, health, auth)\n- toolprotocol (transport, wire, discover, content, task, stream, session, elicit, resource, prompt)\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#task-5-initialize-submodules","title":"Task 5: Initialize Submodules","text":"<pre><code># On fresh clone\ngit submodule update --init --recursive\n\n# Verify\ngit submodule status\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#expected-structure","title":"Expected Structure","text":"<pre><code>ApertureStack/\n\u251c\u2500\u2500 toolfoundation/      # NEW\n\u251c\u2500\u2500 tooldiscovery/       # NEW\n\u251c\u2500\u2500 toolexec/            # NEW\n\u251c\u2500\u2500 toolcompose/         # NEW\n\u251c\u2500\u2500 toolops/             # NEW\n\u251c\u2500\u2500 toolprotocol/        # NEW\n\u251c\u2500\u2500 metatools-mcp/       # Existing (updated)\n\u251c\u2500\u2500 ai-tools-stack/      # Existing (updated)\n\u2514\u2500\u2500 .gitmodules\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] Old submodules removed</li> <li>[x] New submodules added</li> <li>[x] .gitmodules updated</li> <li>[x] Committed and pushed</li> <li>[x] Fresh clone works</li> <li>[x] <code>git submodule update --init</code> works</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Root <code>.gitmodules</code> now points to consolidated repos under <code>jonwraymond</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-191-update-submodules/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-192: Validation</li> <li>Gate G7: Full validation complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/","title":"PRD-192: Validation","text":"<p>Phase: 9 - Cleanup Priority: Critical Effort: 4 hours Dependencies: PRD-191 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#objective","title":"Objective","text":"<p>Perform comprehensive validation that the consolidation is complete and working.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#task-1-repository-validation","title":"Task 1: Repository Validation","text":"<pre><code>#!/bin/bash\nset -e\n\necho \"=== Repository Validation ===\"\n\nREPOS=(\n  toolfoundation\n  tooldiscovery\n  toolexec\n  toolcompose\n  toolops\n  toolprotocol\n)\n\nfor repo in \"${REPOS[@]}\"; do\n  echo \"\"\n  echo \"Checking $repo...\"\n\n  # Verify repo exists\n  gh repo view \"jonwraymond/$repo\" &gt; /dev/null\n\n  # Clone and test\n  cd /tmp\n  rm -rf \"$repo\"\n  git clone \"git@github.com:jonwraymond/$repo.git\"\n  cd \"$repo\"\n\n  # Build\n  echo \"  Building...\"\n  go build ./...\n\n  # Test\n  echo \"  Testing...\"\n  GOWORK=off go test ./...\n\n  # Check CI status\n  echo \"  CI Status:\"\n  gh run list --limit 1\n\n  echo \"  \u2713 $repo OK\"\ndone\n\necho \"\"\necho \"=== All repositories validated ===\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#task-2-integration-validation","title":"Task 2: Integration Validation","text":"<pre><code>#!/bin/bash\nset -e\n\necho \"=== Integration Validation ===\"\n\ncd /tmp\nrm -rf metatools-mcp-test\ngit clone git@github.com:jonwraymond/metatools-mcp.git metatools-mcp-test\ncd metatools-mcp-test\n\necho \"Building metatools-mcp...\"\ngo build ./cmd/metatools\n\necho \"Running tests...\"\nGOWORK=off go test ./...\n\necho \"Starting server...\"\n./metatools serve &amp;\nPID=$!\nsleep 3\n\necho \"Testing tool list...\"\n# Test MCP tools/list\ncurl -s -X POST http://localhost:8080/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\"}' | jq .\n\necho \"Stopping server...\"\nkill $PID\n\necho \"\u2713 Integration validation passed\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#task-3-submodule-validation","title":"Task 3: Submodule Validation","text":"<pre><code>#!/bin/bash\nset -e\n\necho \"=== Submodule Validation ===\"\n\ncd /tmp\nrm -rf ApertureStack-test\ngit clone --recursive git@github.com:jonwraymond/ApertureStack.git ApertureStack-test\ncd ApertureStack-test\n\necho \"Checking submodules...\"\ngit submodule status\n\necho \"Building all submodules...\"\nfor dir in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  echo \"  Building $dir...\"\n  cd \"$dir\"\n  GOWORK=off go build ./...\n  cd ..\ndone\n\necho \"\u2713 Submodule validation passed\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#task-4-documentation-validation","title":"Task 4: Documentation Validation","text":"<pre><code>#!/bin/bash\nset -e\n\necho \"=== Documentation Validation ===\"\n\ncd /tmp\nrm -rf ai-tools-stack-test\ngit clone git@github.com:jonwraymond/ai-tools-stack.git ai-tools-stack-test\ncd ai-tools-stack-test\n\necho \"Checking VERSIONS.md...\"\ngrep -q \"toolfoundation\" VERSIONS.md &amp;&amp; echo \"  \u2713 toolfoundation listed\"\ngrep -q \"tooldiscovery\" VERSIONS.md &amp;&amp; echo \"  \u2713 tooldiscovery listed\"\ngrep -q \"toolexec\" VERSIONS.md &amp;&amp; echo \"  \u2713 toolexec listed\"\ngrep -q \"toolcompose\" VERSIONS.md &amp;&amp; echo \"  \u2713 toolcompose listed\"\ngrep -q \"toolops\" VERSIONS.md &amp;&amp; echo \"  \u2713 toolops listed\"\ngrep -q \"toolprotocol\" VERSIONS.md &amp;&amp; echo \"  \u2713 toolprotocol listed\"\n\necho \"Building docs...\"\nmkdocs build\n\necho \"\u2713 Documentation validation passed\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#task-5-archive-validation","title":"Task 5: Archive Validation","text":"<pre><code>#!/bin/bash\nset -e\n\necho \"=== Archive Validation ===\"\n\nARCHIVED=(\n  toolmodel\n  tooladapter\n  toolindex\n  toolsearch\n  toolsemantic\n  tooldocs\n  toolrun\n  toolruntime\n  toolcode\n  toolset\n  toolskill\n  toolobserve\n  toolcache\n)\n\nfor repo in \"${ARCHIVED[@]}\"; do\n  ARCHIVED_STATUS=$(gh repo view \"jonwraymond/$repo\" --json isArchived -q '.isArchived')\n  if [ \"$ARCHIVED_STATUS\" = \"true\" ]; then\n    echo \"  \u2713 $repo is archived\"\n  else\n    echo \"  \u2717 $repo is NOT archived\"\n    exit 1\n  fi\ndone\n\necho \"\u2713 Archive validation passed\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#task-6-final-checklist","title":"Task 6: Final Checklist","text":"<p>Create validation report:</p> <pre><code># Consolidation Validation Report\n\nDate: [YYYY-MM-DD]\n\n## Repository Status\n\n| Repository | Build | Tests | CI | Status |\n|------------|-------|-------|-----|--------|\n| toolfoundation | \u2713 | \u2713 | \u2713 | OK |\n| tooldiscovery | \u2713 | \u2713 | \u2713 | OK |\n| toolexec | \u2713 | \u2713 | \u2713 | OK |\n| toolcompose | \u2713 | \u2713 | \u2713 | OK |\n| toolops | \u2713 | \u2713 | \u2713 | OK |\n| toolprotocol | \u2713 | \u2713 | \u2713 | OK |\n| metatools-mcp | \u2713 | \u2713 | \u2713 | OK |\n\n## Integration Status\n\n| Test | Status |\n|------|--------|\n| metatools-mcp build | \u2713 |\n| MCP server starts | \u2713 |\n| tools/list works | \u2713 |\n| Tool execution works | \u2713 |\n\n## Archive Status\n\nAll 13 standalone repos archived: \u2713\n\n## Submodule Status\n\nAll 6 consolidated repos as submodules: \u2713\n\n## Documentation Status\n\n- VERSIONS.md updated: \u2713\n- README updated: \u2713\n- MkDocs builds: \u2713\n\n## Conclusion\n\nConsolidation complete and validated.\n\n## Verification (2026-02-01)\n\n- Consolidated repos (`toolfoundation`, `tooldiscovery`, `toolexec`, `toolcompose`, `toolops`, `toolprotocol`) pass `go test ./...` locally with `GOWORK=off`.\n- `metatools-mcp` builds and tests clean; `./metatools version` runs.\n- Old repos archived under `jonwraymond` with README deprecation notice + MIGRATION.md present.\n- Submodules updated to consolidated repos; `git submodule status` clean.\n- Docs build not run locally (mkdocs not installed); rely on CI after push.\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All 6 consolidated repos build</li> <li>[ ] All 6 consolidated repos pass tests</li> <li>[ ] All 6 consolidated repos have passing CI</li> <li>[ ] metatools-mcp builds with new imports</li> <li>[ ] metatools-mcp tests pass</li> <li>[ ] MCP server runs correctly</li> <li>[ ] All 13 old repos archived</li> <li>[ ] Submodules work correctly</li> <li>[ ] Documentation updated</li> <li>[ ] Validation report created</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>All smoke tests pass</li> <li>No broken imports</li> <li>CI green on all repos</li> <li>Documentation accessible</li> <li>Old repos archived and read-only</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#gate-g7-complete","title":"Gate G7 Complete","text":"<p>Upon successful validation: - ApertureStack consolidation is complete - 15 repos \u2192 8 repos (6 consolidated + metatools-mcp + ai-tools-stack) - 29 packages organized into 6 consolidated repositories - Full backward compatibility removed per requirements</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-192-validation/#post-completion","title":"Post-Completion","text":"<ul> <li>Monitor for any issues from external users</li> <li>Update any external documentation/links</li> <li>Consider GitHub redirects for archived repos</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/","title":"PRD Order of Operations","text":"<p>Date: 2026-01-30 Purpose: Exact execution order for all consolidation PRDs</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#critical-path","title":"Critical Path","text":"<pre><code>PRD-100 \u2192 PRD-110 \u2192 PRD-120 \u2192 PRD-130 \u2192 PRD-150 \u2192 PRD-152 \u2192 PRD-180 \u2192 PRD-190\n   \u2193         \u2193         \u2193         \u2193         \u2193\nPRD-101   PRD-111   PRD-121   PRD-131   PRD-151\nPRD-102   PRD-112   PRD-122   PRD-132           \u2192 PRD-181 \u2192 PRD-191\n          PRD-113           PRD-133                       \u2192 PRD-192\n                              \u2193\n                           PRD-140 \u2192 PRD-143 \u2192 PRD-144 \u2192 PRD-149\n                           PRD-141\n                           PRD-142\n                              \u2193\n                           PRD-160 \u2192 PRD-162 \u2192 PRD-165 \u2192 PRD-169\n                           PRD-161\n                           PRD-163\n                           PRD-164\n                              \u2193\n                           PRD-170 \u2192 PRD-171 \u2192 ... \u2192 PRD-179\n                              \u2193\n                           PRD-182\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#execution-order-sequential","title":"Execution Order (Sequential)","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-1-planning-infrastructure","title":"Week 1: Planning &amp; Infrastructure","text":"Order PRD Title Est. Hours Depends On 1 PRD-100 Master Plan 4h \u2014 2 PRD-101 Architecture Diagrams 4h PRD-100 3 PRD-102 Schema Definitions 4h PRD-100 4 PRD-110 Repository Creation 8h PRD-100 5 PRD-111 CI/CD Templates 4h PRD-110 6 PRD-112 GitHub Org Config 2h PRD-110 7 PRD-113 Release Automation 2h PRD-111"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-2-foundation-layer","title":"Week 2: Foundation Layer","text":"Order PRD Title Est. Hours Depends On 8 PRD-120 Migrate toolmodel 4h PRD-110 9 PRD-121 Migrate tooladapter 4h PRD-120 10 PRD-122 Create toolversion 8h PRD-120"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-2b-foundation-hardening-docs-contracts","title":"Week 2b: Foundation Hardening (Docs + Contracts)","text":"Order PRD Title Est. Hours Depends On 10.1 PRD-123 Docs + README alignment 3h PRD-122 10.2 PRD-124 Schema validation policy docs 2h PRD-120 10.3 PRD-125 Adapter feature matrix docs 2h PRD-121 10.4 PRD-126 Version package usage docs 2h PRD-122 10.5 PRD-127 Contract verification 1h PRD-120, PRD-121 10.6 PRD-128 Release + propagation 1h PRD-122 10.7 PRD-129 Gate G2 validation 1h PRD-120, PRD-121, PRD-122"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-3-discovery-layer","title":"Week 3: Discovery Layer","text":"Order PRD Title Est. Hours Depends On 11 PRD-130 Migrate toolindex 4h PRD-120 12 PRD-131 Migrate toolsearch 4h PRD-130 13 PRD-132 Migrate toolsemantic 6h PRD-131 14 PRD-133 Migrate tooldocs 4h PRD-120"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-3b-discovery-hardening-docs-validation","title":"Week 3b: Discovery Hardening (Docs + Validation)","text":"Order PRD Title Est. Hours Depends On 14.1 PRD-134 Docs + README alignment 2h PRD-130\u2013133 14.2 PRD-135 Search strategy policy docs 2h PRD-131 14.3 PRD-136 Semantic contracts docs 2h PRD-132 14.4 PRD-137 Progressive docs details 2h PRD-133 14.5 PRD-138 Release + propagation 1h PRD-130\u2013133 14.6 PRD-139 Discovery validation 1h PRD-130\u2013138"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-4-execution-layer","title":"Week 4: Execution Layer","text":"Order PRD Title Est. Hours Depends On 15 PRD-140 Migrate toolrun 4h PRD-120 16 PRD-141 Migrate toolruntime 4h PRD-120 17 PRD-142 Migrate toolcode 4h PRD-140 18 PRD-143 Extract toolbackend 6h PRD-120"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-4b-execution-hardening-docs-validation","title":"Week 4b: Execution Hardening (Docs + Validation)","text":"Order PRD Title Est. Hours Depends On 18.1 PRD-144 toolexec docs alignment 2h PRD-140\u2013143 18.2 PRD-145 Runtime security profile docs 2h PRD-141 18.3 PRD-146 Backend matrix docs 2h PRD-141, PRD-143 18.4 PRD-147 Toolcode/runtime contract docs 2h PRD-141, PRD-142 18.5 PRD-148 Release + propagation 1h PRD-140\u2013147 18.6 PRD-149 toolexec validation 1h PRD-140\u2013148"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-5-composition-operations-layers","title":"Week 5: Composition + Operations Layers","text":"Order PRD Title Est. Hours Depends On 19 PRD-150 Migrate toolset 4h PRD-121, PRD-130 20 PRD-151 Complete toolskill 8h PRD-150, PRD-140 21 PRD-160 Migrate toolobserve 4h PRD-120 22 PRD-161 Migrate toolcache 4h PRD-120"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-5b-composition-hardening-docs-validation","title":"Week 5b: Composition Hardening (Docs + Validation)","text":"Order PRD Title Est. Hours Depends On 20.1 PRD-152 toolcompose docs alignment 2h PRD-150\u2013151 20.2 PRD-153 set filter/policy docs 2h PRD-150 20.3 PRD-154 skill contract docs 2h PRD-151 20.4 PRD-155 user journey + examples 2h PRD-150\u2013151 20.5 PRD-156 docs site integration 1h PRD-152\u2013155 20.6 PRD-157 release + propagation 1h PRD-150\u2013156 20.7 PRD-158 toolcompose validation 1h PRD-150\u2013157 20.8 PRD-159 docs publish readiness 1h PRD-156"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-6-operations-layer-continued","title":"Week 6: Operations Layer (continued)","text":"Order PRD Title Est. Hours Depends On 23 PRD-162 Extract toolauth 8h PRD-120 24 PRD-163 Create toolresilience 8h PRD-120 25 PRD-164 Create toolhealth 6h PRD-120"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-6b-operations-hardening-docs-validation","title":"Week 6b: Operations Hardening (Docs + Validation)","text":"Order PRD Title Est. Hours Depends On 25.1 PRD-165 toolops docs alignment 2h PRD-160\u2013164 25.2 PRD-166 observe contracts docs 2h PRD-160 25.3 PRD-167 cache policy docs 2h PRD-161 25.4 PRD-168 auth/health/resilience docs 2h PRD-162\u2013164 25.5 PRD-169 release + validation 2h PRD-160\u2013168"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-7-8-protocol-layer","title":"Week 7-8: Protocol Layer","text":"Order PRD Title Est. Hours Depends On 26 PRD-170 Create tooltransport 8h PRD-120 27 PRD-171 Create toolwire 12h PRD-170 28 PRD-172 Create tooldiscover 8h PRD-171 29 PRD-173 Create toolcontent 8h PRD-120 30 PRD-174 Create tooltask 10h PRD-140, PRD-173 31 PRD-175 Create toolstream 8h PRD-170 32 PRD-176 Create toolsession 6h PRD-120 33 PRD-177 Create toolelicit 6h PRD-173 34 PRD-178 Create toolresource 10h PRD-130 35 PRD-179 Create toolprompt 8h PRD-173"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#week-9-integration-cleanup","title":"Week 9: Integration &amp; Cleanup","text":"Order PRD Title Est. Hours Depends On 36 PRD-180 Update metatools-mcp 12h All Phase 2-7 37 PRD-181 Update ai-tools-stack 4h PRD-180 38 PRD-182 Documentation Site 6h PRD-181 39 PRD-190 Archive Old Repos 2h PRD-180 40 PRD-191 Update Submodules 2h PRD-190 41 PRD-192 Validation 4h PRD-191"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#parallel-execution-opportunities","title":"Parallel Execution Opportunities","text":"<p>These PRDs can run in parallel:</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#parallel-group-1-after-prd-110","title":"Parallel Group 1 (After PRD-110)","text":"<ul> <li>PRD-111, PRD-112 (can start together)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#parallel-group-2-after-prd-120","title":"Parallel Group 2 (After PRD-120)","text":"<ul> <li>PRD-121, PRD-122</li> <li>PRD-130, PRD-133</li> <li>PRD-140, PRD-141, PRD-143</li> <li>PRD-144\u2013149</li> <li>PRD-160, PRD-161, PRD-162</li> <li>PRD-152\u2013159</li> <li>PRD-165\u2013169</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#parallel-group-3-during-phase-7","title":"Parallel Group 3 (During Phase 7)","text":"<ul> <li>PRD-170 and PRD-173 (independent)</li> <li>PRD-175, PRD-176, PRD-177 (independent)</li> <li>PRD-178, PRD-179 (independent)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#checkpoint-gates","title":"Checkpoint Gates","text":"Gate After PRD Validation G1 PRD-113 All repos created, CI working G2 PRD-122 Foundation layer complete, tests pass G3 PRD-143 Discovery + Execution layers complete G4 PRD-164 Composition + Operations layers complete G5 PRD-179 Protocol layer complete G6 PRD-182 Integration complete G7 PRD-192 Full validation, cleanup complete"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#prd-file-naming-convention","title":"PRD File Naming Convention","text":"<p>All PRDs stored in: <code>docs/plans/</code></p> <p>Format: <code>PRD-{number}-{short-name}.md</code></p> <p>Examples: - <code>PRD-100-master-plan.md</code> - <code>PRD-110-repo-creation.md</code> - <code>PRD-120-migrate-toolmodel.md</code> - <code>PRD-170-create-tooltransport.md</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#quick-reference-what-each-prd-delivers","title":"Quick Reference: What Each PRD Delivers","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#infrastructure-prds-100s","title":"Infrastructure PRDs (100s)","text":"PRD Deliverable 100 Master plan document 101 D2 diagrams, architecture.d2 102 schemas/*.json files 110 6 empty repos with structure 111 .github/workflows/*.yml templates 112 GitHub org secrets configured 113 release-please-config.json for each"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#migration-prds-120-160s","title":"Migration PRDs (120-160s)","text":"PRD Deliverable 120-122 toolfoundation/ with 3 packages 130-133 tooldiscovery/ with 4 packages 140-143 toolexec/ with 4 packages 150-151 toolcompose/ with 2 packages 160-164 toolops/ with 5 packages"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#new-development-prds-170s","title":"New Development PRDs (170s)","text":"PRD Deliverable 170-179 toolprotocol/ with 10 packages"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#integration-prds-180s","title":"Integration PRDs (180s)","text":"PRD Deliverable 180 metatools-mcp using new imports 181 Updated VERSIONS.md, go.mod 182 Updated MkDocs site"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#cleanup-prds-190s","title":"Cleanup PRDs (190s)","text":"PRD Deliverable 190 13 repos archived 191 New .gitmodules 192 All smoke tests passing"},{"location":"library-docs-from-repos/metatools-mcp/plans/PRD-ORDER-OF-OPERATIONS/#total-effort-summary","title":"Total Effort Summary","text":"Phase PRDs Hours Days (8h) 0 100-102 12h 1.5 1 110-113 16h 2 2 120-122 16h 2 3 130-133 18h 2.25 4 140-143 18h 2.25 5 150-151 12h 1.5 6 160-164 30h 3.75 7 170-179 84h 10.5 8 180-182 22h 2.75 9 190-192 8h 1 Total 41 PRDs 236h 29.5 days <p>With parallelization, estimated calendar time: 6-8 weeks</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/","title":"Architecture Review: Comprehensive Proposal Analysis","text":"<p>Date: 2026-01-28 Status: Review Complete Reviewer: Architecture Review Agent</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#executive-summary","title":"Executive Summary","text":"<p>After thorough review of all 7 proposal documents against the current metatools-mcp codebase, the architecture is well-designed and internally consistent, with some notable areas requiring attention before implementation.</p> <p>Overall Score: 8.5/10</p> Category Score Status Interface Consistency 9/10 \u2705 Minor variations to fix Dependency Graph 8/10 \u26a0\ufe0f Some implicit deps Timeline Feasibility 6/10 \ud83d\udd34 Major discrepancy Coverage 8/10 \u26a0\ufe0f Some gaps Architectural Smells 7/10 \u26a0\ufe0f Complexity concerns"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#1-critical-issues-must-fix-before-implementation","title":"1. Critical Issues (Must Fix Before Implementation)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#11-timeline-discrepancy","title":"1.1 Timeline Discrepancy \ud83d\udd34","text":"<p>Finding: Three documents give different timeline estimates for the same work:</p> Document Total Timeline MVP Timeline ROADMAP.md 21 weeks 7 weeks implementation-phases.md 6-7 weeks 3-4 weeks architecture-evaluation.md 13 weeks (implied) Not specified <p>Root Cause: Each document measures a different scope: - implementation-phases.md: Core pluggable architecture only - architecture-evaluation.md: Core + key enterprise features - ROADMAP.md: Full ecosystem including agent skills</p> <p>Impact: Teams could plan with wrong expectations, resource allocation issues.</p> <p>Recommendation: <pre><code># Add to ROADMAP.md Executive Summary:\n\n## Scope Clarification\n\n| Milestone | Scope | Timeline |\n|-----------|-------|----------|\n| **MVP** | CLI, Config, Transport, Provider Registry | 7 weeks |\n| **Protocol** | + tooladapter, toolset | 14 weeks |\n| **Enterprise** | + toolsemantic, toolgateway, multi-tenancy | 17 weeks |\n| **Full** | + toolskill (Agent Skills) | 21 weeks |\n\nNote: implementation-phases.md covers MVP scope only.\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#12-transport-interface-signature-mismatch","title":"1.2 Transport Interface Signature Mismatch \ud83d\udd34","text":"<p>Finding: The <code>Transport</code> interface has inconsistent signatures across documents:</p> <pre><code>// pluggable-architecture.md (lines 274-288)\ntype Transport interface {\n    Name() string           // \u2705 Present\n    Serve(ctx context.Context, handler RequestHandler) error\n    Close() error\n    Info() TransportInfo    // Uses \"TransportInfo\"\n}\n\n// ROADMAP.md (lines 277-284)\ntype Transport interface {\n    // Name() - MISSING \u274c\n    Serve(ctx context.Context, handler RequestHandler) error\n    Close() error\n    Info() TransportInfo\n}\n\n// implementation-phases.md (lines 341-353)\ntype Transport interface {\n    Name() string\n    Serve(ctx context.Context, handler RequestHandler) error\n    Close() error\n    Info() Info             // Uses \"Info\" not \"TransportInfo\" \u274c\n}\n</code></pre> <p>Impact: Implementation confusion, potential compile errors.</p> <p>Recommendation: Standardize on pluggable-architecture.md version with <code>Name()</code> method and <code>TransportInfo</code> type. Update ROADMAP.md and implementation-phases.md.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#2-medium-priority-issues","title":"2. Medium Priority Issues","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#21-missing-dependencies-in-toolskill","title":"2.1 Missing Dependencies in toolskill","text":"<p>Finding: ROADMAP.md line 97 lists toolskill dependencies as <code>toolset, toolrun</code>.</p> <p>However, the SkillRuntime specification (lines 1329-1344) shows it also requires: - <code>toolobserve</code> for tracing (SkillContext has <code>Tracer trace.Tracer</code>) - <code>toolversion</code> for skill versioning (mentioned in Edge Cases)</p> <p>Impact: Incomplete dependency graph could cause integration issues.</p> <p>Recommendation: Update ROADMAP.md: <pre><code>| **toolskill** | Skills | ... | toolset, toolrun, toolobserve (optional), toolversion |\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#22-missing-toolprompt-library","title":"2.2 Missing toolprompt Library","text":"<p>Finding: architecture-evaluation.md (lines 371-394) identifies MCP Prompts as a gap. ROADMAP.md includes <code>toolresource</code> but not <code>toolprompt</code>.</p> <p>MCP Prompts are a core feature for standardized agent interactions.</p> <p>Impact: Incomplete MCP feature coverage.</p> <p>Recommendation: Either: 1. Add <code>toolprompt</code> to Stream D: Enterprise, OR 2. Document explicit exclusion rationale in ROADMAP.md</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#23-session-management-not-addressed","title":"2.3 Session Management Not Addressed","text":"<p>Finding: architecture-evaluation.md (line 173) notes MCP SDK has session management that metatools lacks. This gap is not addressed in any proposal.</p> <p>Impact: Multi-tenant stateful connections may need session tracking.</p> <p>Recommendation: Add session management consideration to multi-tenancy.md: <pre><code>### Session Management Integration\n\nFor stateful tenant connections, integrate with MCP SDK session:\n- Session ID \u2192 Tenant resolution\n- Session lifecycle \u2192 Tenant quota tracking\n- Session data \u2192 Tenant-scoped storage\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#24-index-interface-missing-onchangerefresh","title":"2.4 Index Interface Missing OnChange/Refresh","text":"<p>Finding: component-library-analysis.md (line 218) proposes adding <code>OnChange</code> callback and <code>Refresh()</code> to Index interface for hot reload. This is not reflected in ROADMAP.md's interface contracts.</p> <p>Impact: Hot reload capability won't be standardized.</p> <p>Recommendation: Add to ROADMAP.md Section 5 Interface Contracts: <pre><code>type Index interface {\n    // ... existing methods ...\n    OnChange(callback func(event RegistryEvent)) func()  // Returns unsubscribe function\n    Refresh() error                                       // Force refresh from backends\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#25-upstreamdownstream-impact-matrix-incomplete","title":"2.5 Upstream/Downstream Impact Matrix Incomplete","text":"<p>Finding: ROADMAP.md (lines 165-176) provides an impact matrix but is missing entries for new libraries.</p> <p>Missing Entries:</p> Change In Affects Upstream Affects Downstream toolsemantic None toolgateway (search routing) toolskill toolset, toolrun metatools (skill exposure), toolgateway toolaudit None All tenant-aware middleware toolresilience None All middleware, toolgateway"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#3-architectural-smells","title":"3. Architectural Smells","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#31-toolsemantic-complexity-explosion","title":"3.1 toolsemantic Complexity Explosion \u26a0\ufe0f","text":"<p>Finding: ROADMAP.md specifies 8 major interfaces for semantic search:</p> Interface Complexity Necessity for MVP Embedder Low \u2705 Required VectorIndex Medium \u2705 Required HybridSearcher Medium \u2705 Required Reranker Medium \u26a0\ufe0f Nice-to-have KnowledgeGraph High \u274c Experimental HierarchicalChunker High \u274c Experimental AgenticRetriever High \u274c Experimental ColBERTIndex High \u274c Specialized <p>Accuracy Benchmarks (from ROADMAP.md): - BM25 only: 78% - Hybrid (BM25+Vector): 94%  \u2190 16% improvement - Hybrid + Reranker: 97%    \u2190 3% more - Full stack: 98%           \u2190 1% more for 5 extra interfaces</p> <p>Impact: Over-engineering risk, delayed delivery.</p> <p>Recommendation: Phase the implementation: <pre><code>## toolsemantic Phased Delivery\n\n| Phase | Version | Interfaces | Accuracy |\n|-------|---------|------------|----------|\n| 1 | v0.1 | Embedder, VectorIndex, HybridSearcher | 94% |\n| 2 | v0.2 | + Reranker | 97% |\n| 3 | v0.3 | + KnowledgeGraph | 98% |\n| 4 | v1.0 | + AgenticRetriever, ColBERT | 98%+ |\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#32-middleware-proliferation","title":"3.2 Middleware Proliferation \u26a0\ufe0f","text":"<p>Finding: Combined proposals define 10+ middleware types: - Logging, Auth, RateLimit, Cache, Metrics, Tracing, Validation (7 from pluggable-architecture.md) - Tenant, TenantRateLimit, TenantToolFilter, TenantAudit (4 from multi-tenancy.md)</p> <p>Impact: - Latency accumulation (each middleware adds ~1-5ms) - Debugging complexity - Order dependency issues (rate limit before auth? after?)</p> <p>Recommendation: Document middleware ordering with production preset:</p> <pre><code>// DefaultProductionMiddleware provides recommended ordering\nvar DefaultProductionMiddleware = []Middleware{\n    LoggingMiddleware,     // 1st: Log all requests for observability\n    TracingMiddleware,     // 2nd: Start trace span\n    TenantMiddleware,      // 3rd: Resolve tenant early\n    RateLimitMiddleware,   // 4th: Fail fast if limited\n    AuthMiddleware,        // 5th: Authenticate\n    ValidationMiddleware,  // 6th: Validate input\n    CachingMiddleware,     // 7th: Check cache\n    // Handler executes here\n    // Middleware unwind in reverse order\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#33-skillbuilder-tight-coupling","title":"3.3 SkillBuilder Tight Coupling \u26a0\ufe0f","text":"<p>Finding: ROADMAP.md SkillBuilder (lines 1548-1567) uses hard-coded tool names:</p> <pre><code>Step(\"discover\", \"search_tools\")\nStep(\"docs-1\", \"describe_tool\")\n</code></pre> <p>Impact: If tool names change, all skills break.</p> <p>Recommendation: Use capability-based or versioned references:</p> <pre><code>// Option 1: Capability enum\nStep(\"discover\", capability.Search)\n\n// Option 2: Versioned tool ID\nStep(\"discover\", toolID(\"metatools:search_tools@v1\"))\n\n// Option 3: Interface-based\nStep(\"discover\", toolThat(func(t Tool) bool {\n    return t.HasCapability(\"search\")\n}))\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#4-verification-against-current-codebase","title":"4. Verification Against Current Codebase","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#41-current-implementation-analysis","title":"4.1 Current Implementation Analysis","text":"<p>File: <code>internal/handlers/interfaces.go</code></p> <p>Current interfaces are internal abstractions, not the external tool* library interfaces:</p> <pre><code>type Index interface {\n    Search(ctx context.Context, query string, limit int) ([]ToolSummary, error)\n    ListNamespaces(ctx context.Context) ([]string, error)\n}\n\ntype Store interface {\n    DescribeTool(ctx context.Context, id string, level string) (ToolDoc, error)\n    ListExamples(ctx context.Context, id string, maxExamples int) ([]ToolExample, error)\n}\n\ntype Runner interface {\n    Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)\n    RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error)\n}\n</code></pre> <p>Observation: The proposals correctly identify these as internal interfaces that wrap external libraries via adapters (<code>internal/adapters/</code>).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#42-transport-layer-verification","title":"4.2 Transport Layer Verification","text":"<p>File: <code>cmd/metatools/main.go</code></p> <pre><code>transport := &amp;mcp.StdioTransport{}\nif err := srv.Run(ctx, transport); err != nil &amp;&amp; ctx.Err() == nil {\n    log.Fatalf(\"Server error: %v\", err)\n}\n</code></pre> <p>Observation: Current implementation uses <code>mcp.StdioTransport</code> directly. The proposals correctly identify that Transport abstraction is new work to enable multiple transport types.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#43-configuration-verification","title":"4.3 Configuration Verification","text":"<p>File: <code>internal/config/config.go</code></p> <pre><code>type Config struct {\n    Index    handlers.Index\n    Docs     handlers.Store\n    Runner   handlers.Runner\n    Executor handlers.Executor // optional\n}\n</code></pre> <p>Observation: Current config is minimal (4 fields). Proposals expand this significantly with ServerConfig, TransportConfig, SearchConfig, etc. This is additive and backward compatible.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#5-cross-reference-audit","title":"5. Cross-Reference Audit","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#51-document-references","title":"5.1 Document References","text":"From To Status pluggable-architecture.md component-library-analysis.md \u2705 Valid pluggable-architecture.md implementation-phases.md \u2705 Valid implementation-phases.md pluggable-architecture.md \u2705 Valid multi-tenancy.md pluggable-architecture.md \u2705 Valid architecture-evaluation.md component-library-analysis.md \u2705 Valid ROADMAP.md All proposals \u2705 Valid protocol-agnostic-tools.md ROADMAP.md \u274c Missing <p>Recommendation: Add to protocol-agnostic-tools.md: <pre><code>**Related:** [Master Roadmap](./ROADMAP.md) - Stream B: Protocol Layer\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#6-summary-of-recommendations","title":"6. Summary of Recommendations","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#high-priority-block-implementation","title":"High Priority (Block Implementation)","text":"<ol> <li>Reconcile timeline discrepancies - Add scope clarification table to ROADMAP.md</li> <li>Standardize Transport interface - Use pluggable-architecture.md version everywhere</li> <li>Document parallel stream constraints - Add resource requirements and critical path</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#medium-priority-quality-improvements","title":"Medium Priority (Quality Improvements)","text":"<ol> <li>Update toolskill dependencies - Add toolobserve, toolversion</li> <li>Add toolprompt - Or document exclusion rationale</li> <li>Add session management - To multi-tenancy proposal</li> <li>Add Index.OnChange/Refresh - To interface contracts</li> <li>Complete impact matrix - Add all new libraries</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#low-priority-future-considerations","title":"Low Priority (Future Considerations)","text":"<ol> <li>Phase toolsemantic - Deliver in 4 incremental versions</li> <li>Document middleware ordering - With production preset</li> <li>Use capability-based tool references - In SkillBuilder</li> <li>Add cross-reference - protocol-agnostic-tools.md \u2192 ROADMAP.md</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#7-conclusion","title":"7. Conclusion","text":"<p>The metatools architecture proposals are comprehensive and well-designed. The modular approach with 22 libraries provides excellent separation of concerns. The main risks are:</p> <ol> <li>Timeline confusion - Different documents suggest wildly different timelines</li> <li>Complexity creep - toolsemantic and middleware could become unwieldy</li> <li>Interface drift - Minor inconsistencies need cleanup before implementation</li> </ol> <p>With the recommended fixes, this architecture will achieve the stated goal of 95%+ championship-level capabilities.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#appendix-files-reviewed","title":"Appendix: Files Reviewed","text":"Document Lines Last Modified ROADMAP.md ~2100 2026-01-28 pluggable-architecture.md ~4900 2026-01-28 implementation-phases.md ~900 2026-01-28 component-library-analysis.md - 2026-01-27 architecture-evaluation.md ~450 2026-01-28 multi-tenancy.md - 2026-01-28 protocol-agnostic-tools.md - 2026-01-28 Source File Purpose internal/handlers/interfaces.go Current internal interfaces internal/config/config.go Current config structure internal/server/server.go Current server implementation cmd/metatools/main.go Current entry point internal/adapters/*.go Library adapters"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/","title":"Metatools Architecture Roadmap","text":"<p>Status: Master Plan Version: 1.0.0 Last Updated: 2026-01-28</p> <p>Guiding Principle: Simple and elegant at the core, extensible through modular, pluggable architecture. The existing 7 libraries represent a mature, well-designed foundation. New work focuses on exposure, configuration, and enterprise capabilities\u2014not redesign.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#executive-summary","title":"Executive Summary","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#current-state","title":"Current State","text":"<ul> <li>7 production libraries with clean interfaces</li> <li>13 extension points already implemented as Go interfaces</li> <li>85% championship-level architecture</li> <li>Primary gap: Exposure and configuration, not architecture</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#target-state","title":"Target State","text":"<ul> <li>22 total libraries (7 existing + 15 new)</li> <li>95%+ championship-level with full enterprise capabilities</li> <li>Protocol-agnostic tool platform</li> <li>Multi-tenant with pluggable isolation strategies</li> <li>Agent skills for higher-level capability composition</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#scope-clarification","title":"Scope Clarification","text":"Milestone Scope Timeline Document Reference MVP CLI, Config, Transport, Provider Registry 7 weeks implementation-phases.md Protocol + tooladapter, toolset, multi-transport 14 weeks protocol-agnostic-tools.md Enterprise + toolsemantic, toolgateway, multi-tenancy 17 weeks multi-tenancy.md Full + toolskill (Agent Skills) 21 weeks This document <p>Note: implementation-phases.md covers MVP scope only (6-7 weeks). This master roadmap covers the full 21-week timeline.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#timeline-overview","title":"Timeline Overview","text":"<pre><code>                    CORE EXPOSURE          ENTERPRISE FEATURES         AGENT SKILLS\n                    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500         \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nWeek 1-2   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 CLI + Config\nWeek 3-4   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Transport Layer\nWeek 5     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Provider Registry\nWeek 6-7   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Backend Registry\nWeek 8-9              \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Protocol Adapters\nWeek 10-11            \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Observability + Caching\nWeek 12-13            \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Multi-Tenancy\nWeek 14-15            \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Versioning + Resilience\nWeek 16-17            \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Semantic Search + Gateway\nWeek 18-19                                                    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Skill Core\nWeek 20-21                                                    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Orchestration\n                    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                    MVP: 7 weeks | Full: 17 weeks | Skills: 21 weeks\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Library Inventory</li> <li>Dependency Map</li> <li>Work Streams</li> <li>Stream A: Core Exposure</li> <li>Stream B: Protocol Layer</li> <li>Stream C: Cross-Cutting</li> <li>Stream D: Enterprise</li> <li>Stream E: Agent Skills</li> <li>Phase Breakdown</li> <li>Interface Contracts</li> <li>Edge Cases &amp; Considerations</li> <li>Rollout Strategy</li> <li>Multi-Language Extensibility</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#1-library-inventory","title":"1. Library Inventory","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#existing-libraries-production","title":"Existing Libraries (Production)","text":"Library Version Purpose Extension Points Changes Needed toolmodel v0.1.3 Core data models, schemas SchemaValidator Add Version field toolindex v0.1.9 Tool registry, discovery Searcher, BackendSelector Multi-backend events tooldocs v0.1.11 Progressive disclosure docs Store, ToolResolver Bulk registration toolsearch v0.1.10 BM25 search implementation (via Searcher) None toolrun v0.1.10 Execution orchestration Runner, MCPExecutor, ProviderExecutor, LocalRegistry HTTP/gRPC executors toolcode v0.1.11 Code execution Engine, Logger Engine registry toolruntime v0.1.11 Sandbox isolation (10 backends) Backend, ToolGateway None"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#proposed-libraries-new","title":"Proposed Libraries (New)","text":"Library Stream Purpose Priority Effort Dependencies tooladapter Protocol Protocol-agnostic tool abstraction High 2w toolmodel toolset Protocol Composable tool collections High 2w tooladapter, toolindex toolversion Cross-Cut Semantic versioning, negotiation High 2w toolmodel toolcache Cross-Cut Pluggable caching (Redis/Memory) High 2w None toolobserve Cross-Cut OpenTelemetry tracing + metrics High 2w None toolresilience Cross-Cut Circuit breaker, retry, bulkhead Medium 2w None toolhealth Cross-Cut Health checks, readiness probes Medium 1w None toolsecrets Cross-Cut Vault/AWS secrets management Medium 2w None toolflags Cross-Cut Feature flags (LaunchDarkly) Low 1w None toolaudit Cross-Cut Immutable audit logging Medium 2w None toolpressure Cross-Cut Backpressure, load shedding Low 1w None toolsemantic Enterprise Hybrid search (BM25+vector), GraphRAG, reranking, ColBERT High 3w toolindex, toolsearch toolresource Enterprise MCP Resources support Medium 2w toolindex toolgateway Enterprise Auth, rate limit, analytics proxy Medium 3w All toolskill Skills SKILL.md-compatible agent skills, workflows Medium 4w toolset, toolrun, toolobserve (opt), toolversion"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#2-dependency-map","title":"2. Dependency Map","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#library-dependencies-dag","title":"Library Dependencies (DAG)","text":"<pre><code>                            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                            \u2502    toolskill    \u2502 (L5)\n                            \u2502  Agent Skills   \u2502\n                            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502                                                      \u2502\n          \u25bc                                                      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   toolgateway   \u2502 (L4)                              \u2502    toolrun      \u2502\n\u2502  Auth + Proxy   \u2502                                   \u2502   (execution)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502                          \u2502                          \u2502\n          \u25bc                          \u25bc                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   toolobserve   \u2502      \u2502  toolresilience \u2502      \u2502    toolaudit    \u2502 (L3)\n\u2502   OpenTelemetry \u2502      \u2502 Circuit Breaker \u2502      \u2502  Audit Logging  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                        \u2502                        \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502                       \u2502                       \u2502\n          \u25bc                       \u25bc                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    toolset      \u2502      \u2502   toolversion   \u2502      \u2502    toolcache    \u2502 (L2)\n\u2502  Composable     \u2502      \u2502   Versioning    \u2502      \u2502    Caching      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                        \u2502                        \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502   tooladapter   \u2502 (L1)\n                        \u2502 Protocol Adapt  \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                            \u2502                            \u2502\n    \u25bc                            \u25bc                            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502toolmodel\u2502  \u2502toolindex\u2502  \u2502tooldocs \u2502  \u2502 toolrun \u2502  \u2502toolcode \u2502 (L0)\n\u2502  v0.1.2 \u2502  \u2502  v0.1.8 \u2502  \u2502 v0.1.10 \u2502  \u2502  v0.1.9 \u2502  \u2502 v0.1.10 \u2502\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n     \u2502            \u2502            \u2502            \u2502            \u2502\n     \u2502            \u2502            \u2502            \u2502            \u25bc\n     \u2502            \u2502            \u2502            \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502            \u2502            \u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 toolruntime \u2502\n     \u2502            \u2502            \u2502                   \u2502   v0.1.10   \u2502\n     \u2502            \u2502            \u25bc                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502            \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u25ba\u2502toolsearch\u2502\n     \u2502                   \u2502  v0.1.9  \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#upstreamdownstream-impact-matrix","title":"Upstream/Downstream Impact Matrix","text":"Change In Affects Upstream Affects Downstream toolmodel None All libraries toolindex None tooldocs, toolrun, toolset tooladapter toolmodel toolset, toolgateway toolversion toolmodel tooladapter, toolrun toolcache None toolindex, tooldocs, toolrun toolobserve None All libraries (optional) toolskill toolset, toolrun metatools (skill exposure)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#3-work-streams","title":"3. Work Streams","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#stream-a-core-exposure","title":"Stream A: Core Exposure","text":"<p>Goal: Expose existing 13 extension points via configuration and CLI.</p> Phase Work Package Duration Deliverables A1 CLI Framework 2 weeks Cobra CLI, subcommands A2 Configuration 1 week Koanf loader, YAML schema A3 Transport Layer 2 weeks Transport interface, stdio/SSE/HTTP A4 Provider Registry 1 week ToolProvider interface, registry A5 Backend Registry 2 weeks Backend interface, aggregator <p>Total: 8 weeks | MVP: Phases A1-A4 (6 weeks)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#a1-cli-framework-2-weeks","title":"A1: CLI Framework (2 weeks)","text":"<pre><code>Week 1:\n\u251c\u2500\u2500 Day 1-2: Cobra setup, root command\n\u251c\u2500\u2500 Day 3-4: `stdio` subcommand (existing behavior)\n\u251c\u2500\u2500 Day 5: `serve` subcommand (HTTP server)\n\nWeek 2:\n\u251c\u2500\u2500 Day 1-2: `version`, `validate` commands\n\u251c\u2500\u2500 Day 3-4: Signal handling, graceful shutdown\n\u251c\u2500\u2500 Day 5: Documentation, examples\n</code></pre> <p>Interface Contract: <pre><code>// cmd/metatools/main.go\nfunc main() {\n    rootCmd := &amp;cobra.Command{Use: \"metatools\"}\n    rootCmd.AddCommand(\n        newStdioCmd(),   // MCP over stdio (default)\n        newServeCmd(),   // HTTP/SSE server\n        newVersionCmd(), // Print version\n        newValidateCmd(), // Validate config\n    )\n    rootCmd.Execute()\n}\n</code></pre></p> <p>Edge Cases: - [ ] Backward compatibility: <code>metatools</code> alone = <code>metatools stdio</code> - [ ] Environment variables override YAML config - [ ] Invalid config: fail fast with clear error messages - [ ] Missing optional config: sensible defaults</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#a2-configuration-1-week","title":"A2: Configuration (1 week)","text":"<pre><code>Week 3:\n\u251c\u2500\u2500 Day 1-2: Koanf setup, YAML parser\n\u251c\u2500\u2500 Day 3: Environment variable binding\n\u251c\u2500\u2500 Day 4: Config validation schema\n\u251c\u2500\u2500 Day 5: Default values, documentation\n</code></pre> <p>Interface Contract: <pre><code>// internal/config/config.go\ntype Config struct {\n    Server     ServerConfig     `koanf:\"server\"`\n    Transport  TransportConfig  `koanf:\"transport\"`\n    Search     SearchConfig     `koanf:\"search\"`\n    Execution  ExecutionConfig  `koanf:\"execution\"`\n    Backends   BackendsConfig   `koanf:\"backends\"`\n    Middleware MiddlewareConfig `koanf:\"middleware\"`\n}\n\nfunc Load(path string) (*Config, error)\nfunc LoadWithEnv(path string, prefix string) (*Config, error)\n</code></pre></p> <p>Edge Cases: - [ ] Config file not found: use defaults - [ ] Partial config: merge with defaults - [ ] Invalid values: return typed validation errors - [ ] Hot reload: optional, via <code>toolconfig</code> watcher</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#a3-transport-layer-2-weeks","title":"A3: Transport Layer (2 weeks)","text":"<pre><code>Week 4:\n\u251c\u2500\u2500 Day 1-2: Transport interface definition\n\u251c\u2500\u2500 Day 3-4: Stdio transport (wrap existing)\n\u251c\u2500\u2500 Day 5: Transport registry\n\nWeek 5:\n\u251c\u2500\u2500 Day 1-2: SSE transport implementation\n\u251c\u2500\u2500 Day 3-4: HTTP transport implementation\n\u251c\u2500\u2500 Day 5: TLS support, health endpoints\n</code></pre> <p>Interface Contract: <pre><code>// internal/transport/transport.go\ntype Transport interface {\n    Name() string  // Transport identifier (e.g., \"stdio\", \"sse\", \"http\")\n    Serve(ctx context.Context, handler RequestHandler) error\n    Close() error\n    Info() TransportInfo\n}\n\ntype TransportInfo struct {\n    Name     string\n    Protocol string // \"stdio\", \"http\", \"sse\", \"grpc\"\n    Address  string // \"\" for stdio, \"localhost:8080\" for HTTP\n}\n\ntype TransportRegistry interface {\n    Register(name string, factory TransportFactory)\n    Get(name string) (Transport, error)\n    List() []string\n}\n</code></pre></p> <p>Edge Cases: - [ ] Stdio: handle broken pipe gracefully - [ ] HTTP: CORS headers for browser clients - [ ] SSE: reconnection with event ID - [ ] TLS: certificate rotation without restart - [ ] Health: <code>/health</code> (liveness), <code>/ready</code> (readiness)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#a4-provider-registry-1-week","title":"A4: Provider Registry (1 week)","text":"<pre><code>Week 6:\n\u251c\u2500\u2500 Day 1-2: ToolProvider interface\n\u251c\u2500\u2500 Day 3: Provider registry\n\u251c\u2500\u2500 Day 4: Refactor existing tools as providers\n\u251c\u2500\u2500 Day 5: Custom provider registration docs\n</code></pre> <p>Interface Contract: <pre><code>// internal/provider/provider.go\ntype ToolProvider interface {\n    Name() string\n    Tool() *mcp.Tool\n    Handle(ctx context.Context, input json.RawMessage) (any, error)\n}\n\ntype ProviderRegistry interface {\n    Register(provider ToolProvider) error\n    Get(name string) (ToolProvider, error)\n    List() []ToolProvider\n    Unregister(name string) error\n}\n</code></pre></p> <p>Edge Cases: - [ ] Duplicate registration: return error, don't overwrite - [ ] Dynamic registration: emit events for discovery - [ ] Provider panic: recover, log, return error - [ ] Slow provider: context deadline enforced</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#a5-backend-registry-2-weeks","title":"A5: Backend Registry (2 weeks)","text":"<pre><code>Week 7:\n\u251c\u2500\u2500 Day 1-2: Backend interface definition\n\u251c\u2500\u2500 Day 3-4: Local backend (existing behavior)\n\u251c\u2500\u2500 Day 5: Backend registry\n\nWeek 8:\n\u251c\u2500\u2500 Day 1-2: MCP backend (connect to MCP servers)\n\u251c\u2500\u2500 Day 3-4: HTTP backend (REST API tools)\n\u251c\u2500\u2500 Day 5: Aggregator (merge tools from all backends)\n</code></pre> <p>Interface Contract: <pre><code>// internal/backend/backend.go\ntype Backend interface {\n    Kind() string              // \"local\", \"mcp\", \"http\"\n    Name() string              // Instance name\n    Start(ctx context.Context) error\n    Stop(ctx context.Context) error\n    ListTools(ctx context.Context) ([]*toolmodel.Tool, error)\n    Execute(ctx context.Context, tool string, input any) (any, error)\n    Health(ctx context.Context) HealthStatus\n}\n\ntype BackendRegistry interface {\n    Register(backend Backend) error\n    Get(name string) (Backend, error)\n    ListByKind(kind string) []Backend\n    Aggregate() AggregatedBackend\n}\n</code></pre></p> <p>Edge Cases: - [ ] Backend offline: mark unhealthy, exclude from routing - [ ] Tool name collision: namespace with backend name - [ ] Slow backend: per-backend timeout - [ ] Backend restart: re-register tools, emit events</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#stream-b-protocol-layer","title":"Stream B: Protocol Layer","text":"<p>Goal: Protocol-agnostic tool exposure with composable toolsets.</p> Phase Work Package Duration Deliverables B1 tooladapter Core 2 weeks Adapter interface, MCP adapter B2 Additional Adapters 1 week OpenAI, Anthropic, LangChain B3 toolset Core 2 weeks Toolset builder, filtering B4 Multi-Transport 1 week Expose via MCP, REST, direct <p>Total: 6 weeks</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#b1-tooladapter-core-2-weeks","title":"B1: tooladapter Core (2 weeks)","text":"<pre><code>Week 9:\n\u251c\u2500\u2500 Day 1-2: CanonicalTool type definition\n\u251c\u2500\u2500 Day 3-4: Adapter interface\n\u251c\u2500\u2500 Day 5: MCP adapter (bidirectional)\n\nWeek 10:\n\u251c\u2500\u2500 Day 1-2: Schema conversion utilities\n\u251c\u2500\u2500 Day 3-4: Adapter registry\n\u251c\u2500\u2500 Day 5: Unit tests, documentation\n</code></pre> <p>Interface Contract: <pre><code>// tooladapter/canonical.go\ntype CanonicalTool struct {\n    ID          string\n    Namespace   string\n    Name        string\n    Version     semver.Version\n    Description string\n    InputSchema *JSONSchema\n    OutputSchema *JSONSchema\n    Handler     ToolHandler\n    SourceFormat string\n    SourceMeta   map[string]any\n}\n\n// tooladapter/adapter.go\ntype Adapter interface {\n    Name() string\n    ToCanonical(raw any) (*CanonicalTool, error)\n    FromCanonical(tool *CanonicalTool) (any, error)\n    SupportsFeature(feature SchemaFeature) bool\n}\n</code></pre></p> <p>Edge Cases: - [ ] Schema feature not supported: strip with warning - [ ] Conversion loss: preserve original in SourceMeta - [ ] Bidirectional round-trip: verify no data loss - [ ] Nil handling: optional fields default to nil/zero</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#b2-additional-adapters-1-week","title":"B2: Additional Adapters (1 week)","text":"<pre><code>Week 11:\n\u251c\u2500\u2500 Day 1-2: OpenAI adapter (strict mode support)\n\u251c\u2500\u2500 Day 3: Anthropic adapter\n\u251c\u2500\u2500 Day 4: LangChain adapter\n\u251c\u2500\u2500 Day 5: OpenAPI adapter (import only)\n</code></pre> <p>Edge Cases: - [ ] OpenAI strict mode: reject unsupported features - [ ] Anthropic input_schema vs inputSchema naming - [ ] LangChain Zod schemas: convert to JSON Schema - [ ] OpenAPI discriminators: flatten to anyOf</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#b3-toolset-core-2-weeks","title":"B3: toolset Core (2 weeks)","text":"<pre><code>Week 12:\n\u251c\u2500\u2500 Day 1-2: Toolset type definition\n\u251c\u2500\u2500 Day 3-4: Builder pattern with fluent API\n\u251c\u2500\u2500 Day 5: Filter predicates\n\nWeek 13:\n\u251c\u2500\u2500 Day 1-2: Access control policies\n\u251c\u2500\u2500 Day 3-4: Integration with toolindex\n\u251c\u2500\u2500 Day 5: Integration with toolrun\n</code></pre> <p>Interface Contract: <pre><code>// toolset/builder.go\ntype Builder struct { ... }\n\nfunc NewBuilder(name string) *Builder\nfunc (b *Builder) FromRegistry(reg *Registry) *Builder\nfunc (b *Builder) WithNamespace(ns string) *Builder\nfunc (b *Builder) WithTags(tags ...string) *Builder\nfunc (b *Builder) WithTools(ids ...string) *Builder\nfunc (b *Builder) ExcludeTools(ids ...string) *Builder\nfunc (b *Builder) WithPolicy(p *AccessPolicy) *Builder\nfunc (b *Builder) Build() (*Toolset, error)\n</code></pre></p> <p>Edge Cases: - [ ] Empty toolset: valid, return empty list - [ ] Conflicting filters: AND logic (all must match) - [ ] Tool removed after build: refresh on demand - [ ] Circular exclude: no-op, tool already excluded</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#b4-multi-transport-1-week","title":"B4: Multi-Transport (1 week)","text":"<pre><code>Week 14:\n\u251c\u2500\u2500 Day 1-2: MCP exposure (enhanced)\n\u251c\u2500\u2500 Day 3: REST API exposure\n\u251c\u2500\u2500 Day 4: Direct Go client\n\u251c\u2500\u2500 Day 5: Documentation, examples\n</code></pre> <p>Edge Cases: - [ ] MCP version mismatch: negotiate or reject - [ ] REST pagination: cursor-based for large toolsets - [ ] Go client: context cancellation propagation</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#stream-c-cross-cutting","title":"Stream C: Cross-Cutting","text":"<p>Goal: Production-ready cross-cutting concerns.</p> Phase Work Package Duration Deliverables C1 toolcache 2 weeks Cache interface, Redis/Memory C2 toolobserve 2 weeks OpenTelemetry integration C3 toolversion 2 weeks Semantic versioning, negotiation C4 toolresilience 2 weeks Circuit breaker, retry C5 toolhealth 1 week Health checks C6 toolaudit 2 weeks Audit logging C7 toolsecrets 2 weeks Secrets management C8 toolflags + toolpressure 2 weeks Feature flags, backpressure <p>Total: 15 weeks (can parallelize C1-C3 and C4-C8)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#c1-toolcache-2-weeks","title":"C1: toolcache (2 weeks)","text":"<p>Interface Contract: <pre><code>// toolcache/cache.go\ntype Cache interface {\n    Get(ctx context.Context, key string) ([]byte, bool, error)\n    Set(ctx context.Context, key string, value []byte, ttl time.Duration) error\n    Delete(ctx context.Context, key string) error\n    Clear(ctx context.Context, pattern string) error\n    Stats() CacheStats\n    Close() error\n}\n</code></pre></p> <p>Implementations: - <code>MemoryCache</code> - LRU eviction, process-local - <code>RedisCache</code> - Distributed, TTL-based - <code>LayeredCache</code> - L1 memory + L2 Redis</p> <p>Integration Points: - <code>toolindex</code>: Cache tool lookups (<code>index:tool:{id}</code>) - <code>tooldocs</code>: Cache documentation (<code>docs:{id}:{level}</code>) - <code>toolsearch</code>: Cache search results (<code>search:{hash}</code>) - <code>tooladapter</code>: Cache schema conversions (<code>schema:{format}:{id}</code>)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#c2-toolobserve-2-weeks","title":"C2: toolobserve (2 weeks)","text":"<p>Interface Contract: <pre><code>// toolobserve/observe.go\ntype Observer interface {\n    StartSpan(ctx context.Context, name string) (context.Context, Span)\n    RecordMetric(name string, value float64, labels map[string]string)\n    RecordError(ctx context.Context, err error)\n}\n\ntype Span interface {\n    SetAttribute(key string, value any)\n    AddEvent(name string, attrs map[string]any)\n    RecordError(err error)\n    End()\n}\n</code></pre></p> <p>Integration Points: - Middleware: auto-instrument all tool calls - Per-backend: trace backend latency - Per-tool: trace individual tool execution</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#c3-toolversion-2-weeks","title":"C3: toolversion (2 weeks)","text":"<p>Interface Contract: <pre><code>// toolversion/registry.go\ntype VersionedToolRegistry interface {\n    Register(tool *VersionedTool) error\n    Resolve(name string, constraint string) (*VersionedTool, error)\n    ListVersions(name string) []VersionInfo\n    Deprecate(name string, version string, message string, sunset time.Time) error\n}\n</code></pre></p> <p>Edge Cases: - [ ] No matching version: return ErrNoCompatibleVersion - [ ] Deprecated tool used: log warning, emit metric - [ ] Sunset reached: remove from registry - [ ] Version constraint invalid: return parse error</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#c4-toolresilience-2-weeks","title":"C4: toolresilience (2 weeks)","text":"<p>Interface Contract: <pre><code>// toolresilience/resilience.go\ntype CircuitBreaker interface {\n    Execute(ctx context.Context, fn func() error) error\n    State() CircuitState\n    Reset()\n}\n\ntype RetryPolicy interface {\n    Execute(ctx context.Context, fn func() error) error\n    ShouldRetry(err error, attempt int) bool\n}\n\ntype Bulkhead interface {\n    Acquire(ctx context.Context) error\n    Release()\n    Available() int\n}\n</code></pre></p> <p>Edge Cases: - [ ] Circuit open: fail fast without calling backend - [ ] Retry on non-idempotent: disabled by default - [ ] Bulkhead full: reject with 503 - [ ] Jitter calculation: prevent thundering herd</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#stream-d-enterprise","title":"Stream D: Enterprise","text":"<p>Goal: Enterprise-grade features for production deployments.</p> Phase Work Package Duration Deliverables D1 Multi-Tenancy Core 2 weeks Tenant model, resolvers D2 Tenant Middleware 1 week Rate limit, filtering, audit D3 Tenant Storage 1 week Redis/Postgres store D4 toolsemantic 3 weeks Vector search, hybrid D5 toolresource 2 weeks MCP Resources support D6 toolgateway 3 weeks Auth proxy, analytics <p>Total: 12 weeks (can parallelize D1-D3 and D4-D6)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#d1-multi-tenancy-core-2-weeks","title":"D1: Multi-Tenancy Core (2 weeks)","text":"<p>Interface Contract: <pre><code>// multi-tenancy\ntype Tenant struct {\n    ID       string\n    Name     string\n    Tier     TenantTier // free, pro, enterprise\n    Metadata map[string]any\n}\n\ntype TenantResolver interface {\n    Resolve(ctx context.Context, req *Request) (*TenantContext, error)\n}\n\ntype TenantContext struct {\n    Tenant      *Tenant\n    Permissions []string\n    Config      *TenantConfig\n    Quotas      *TenantQuotas\n}\n</code></pre></p> <p>Isolation Strategies: 1. Shared: Logical isolation via middleware (default) 2. Namespace: Tool namespace per tenant 3. Process: Dedicated process per tenant</p> <p>Edge Cases: - [ ] No tenant header: use default tenant or reject - [ ] Tenant not found: return 401/403 - [ ] Quota exceeded: return 429 with retry-after - [ ] Tenant config change: propagate to active sessions</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#d4-toolsemantic-advanced-semantic-search-3-weeks","title":"D4: toolsemantic - Advanced Semantic Search (3 weeks)","text":"<p>Research-Driven Design: This specification is based on 2025 industry best practices for production RAG systems, including hybrid search, knowledge graphs, hierarchical chunking, agentic retrieval, and late interaction models.</p> <pre><code>Week 16:\n\u251c\u2500\u2500 Day 1-2: Core embedding and vector interfaces\n\u251c\u2500\u2500 Day 3-4: Hybrid search (BM25 + vector fusion)\n\u251c\u2500\u2500 Day 5: Reranker integration\n\nWeek 17:\n\u251c\u2500\u2500 Day 1-2: GraphRAG knowledge graph layer\n\u251c\u2500\u2500 Day 3-4: Hierarchical/tree chunking\n\u251c\u2500\u2500 Day 5: Context tree traversal\n\nWeek 18:\n\u251c\u2500\u2500 Day 1-2: Agentic RAG (query expansion, multi-query)\n\u251c\u2500\u2500 Day 3-4: ColBERT/late interaction support\n\u251c\u2500\u2500 Day 5: Integration tests, benchmarks\n</code></pre> <p>Architecture Overview:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          AGENTIC RAG LAYER                                  \u2502\n\u2502  Query Expansion \u2192 Multi-Query \u2192 Self-Reasoning \u2192 Adaptive Retrieval       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           HYBRID SEARCH                                     \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502\n\u2502  \u2502  BM25/TF-IDF\u2502    \u2502   Vector    \u2502    \u2502   GraphRAG  \u2502                     \u2502\n\u2502  \u2502  (toolsearch)\u2502   \u2502  (Dense)    \u2502    \u2502 (Knowledge) \u2502                     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502         \u2502                  \u2502                  \u2502                             \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502                            \u2502                                                \u2502\n\u2502                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                       \u2502\n\u2502                   \u2502  Rank Fusion    \u2502                                       \u2502\n\u2502                   \u2502 (RRF / Weighted)\u2502                                       \u2502\n\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                       \u2502\n\u2502                            \u2502                                                \u2502\n\u2502                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                       \u2502\n\u2502                   \u2502   Reranker      \u2502                                       \u2502\n\u2502                   \u2502 (Cross-Encoder) \u2502                                       \u2502\n\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        INDEX LAYER                                          \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  BM25 Index \u2502    \u2502 HNSW/IVF    \u2502    \u2502  Knowledge  \u2502    \u2502 Hierarchical\u2502  \u2502\n\u2502  \u2502(toolsearch) \u2502    \u2502Vector Index \u2502    \u2502   Graph     \u2502    \u2502    Tree     \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Core Interface Contracts:</p> <pre><code>// toolsemantic/embedding.go\n\n// Embedder generates vector embeddings from text\ntype Embedder interface {\n    // Embed generates embedding for a single text\n    Embed(ctx context.Context, text string) ([]float32, error)\n\n    // EmbedBatch generates embeddings for multiple texts (more efficient)\n    EmbedBatch(ctx context.Context, texts []string) ([][]float32, error)\n\n    // Dimensions returns the embedding vector size\n    Dimensions() int\n\n    // Model returns the model identifier\n    Model() string\n}\n\n// EmbedderFactory creates embedders from configuration\ntype EmbedderFactory interface {\n    Create(config EmbedderConfig) (Embedder, error)\n}\n\n// EmbedderConfig configures an embedding provider\ntype EmbedderConfig struct {\n    Provider   string            // \"openai\", \"cohere\", \"local\", \"ollama\"\n    Model      string            // \"text-embedding-3-small\", \"embed-english-v3.0\"\n    Dimensions int               // Override dimensions (for some models)\n    Options    map[string]any    // Provider-specific options\n}\n</code></pre> <pre><code>// toolsemantic/vector.go\n\n// VectorIndex provides vector similarity search\ntype VectorIndex interface {\n    // Index adds vectors to the index\n    Index(ctx context.Context, docs []VectorDocument) error\n\n    // Search finds similar vectors\n    Search(ctx context.Context, query []float32, opts SearchOptions) ([]VectorResult, error)\n\n    // Delete removes documents from index\n    Delete(ctx context.Context, ids []string) error\n\n    // Stats returns index statistics\n    Stats() IndexStats\n}\n\ntype VectorDocument struct {\n    ID        string\n    Vector    []float32\n    Metadata  map[string]any\n    Content   string  // Optional, for hybrid storage\n}\n\ntype VectorResult struct {\n    ID       string\n    Score    float32  // Similarity score (higher = more similar)\n    Distance float32  // Distance (lower = more similar)\n    Metadata map[string]any\n    Content  string\n}\n\ntype SearchOptions struct {\n    TopK     int               // Number of results\n    MinScore float32           // Minimum similarity threshold\n    Filter   map[string]any    // Metadata filters\n}\n\n// VectorIndexFactory creates vector indices\ntype VectorIndexFactory interface {\n    Create(config VectorIndexConfig) (VectorIndex, error)\n}\n\ntype VectorIndexConfig struct {\n    Backend     string  // \"memory\", \"faiss\", \"qdrant\", \"pinecone\", \"chromadb\"\n    Dimensions  int\n    Metric      string  // \"cosine\", \"euclidean\", \"dot\"\n    IndexType   string  // \"flat\", \"hnsw\", \"ivf\"\n\n    // HNSW-specific\n    M               int  // Max connections per layer\n    EfConstruction  int  // Construction time quality/speed tradeoff\n    EfSearch        int  // Search time quality/speed tradeoff\n}\n</code></pre> <pre><code>// toolsemantic/hybrid.go\n\n// HybridSearcher combines multiple retrieval methods\ntype HybridSearcher interface {\n    // Search performs hybrid search across all configured retrievers\n    Search(ctx context.Context, query string, opts HybridOptions) ([]SearchResult, error)\n\n    // Explain returns detailed scoring breakdown\n    Explain(ctx context.Context, query string, docID string) (*ScoreExplanation, error)\n}\n\ntype HybridOptions struct {\n    TopK            int\n\n    // Retrieval weights (must sum to 1.0)\n    BM25Weight      float32  // Weight for BM25/keyword results\n    VectorWeight    float32  // Weight for vector similarity results\n    GraphWeight     float32  // Weight for knowledge graph results\n\n    // Fusion strategy\n    FusionMethod    FusionMethod  // RRF, WeightedSum, Borda\n\n    // Reranking\n    EnableReranker  bool\n    RerankerTopK    int  // Rerank top N results\n\n    // Filters\n    Namespaces      []string\n    Tags            []string\n    MetadataFilters map[string]any\n}\n\ntype FusionMethod string\n\nconst (\n    FusionRRF         FusionMethod = \"rrf\"          // Reciprocal Rank Fusion\n    FusionWeightedSum FusionMethod = \"weighted_sum\" // Weighted score combination\n    FusionBorda       FusionMethod = \"borda\"        // Borda count ranking\n)\n\ntype SearchResult struct {\n    ID          string\n    Score       float32\n    Content     string\n    Metadata    map[string]any\n\n    // Detailed scores\n    BM25Score   float32\n    VectorScore float32\n    GraphScore  float32\n    RerankerScore float32\n\n    // Source tracking\n    Sources     []string  // Which retrievers contributed\n}\n\ntype ScoreExplanation struct {\n    FinalScore    float32\n    FusionMethod  FusionMethod\n    Components    []ScoreComponent\n    RerankerBoost float32\n}\n\ntype ScoreComponent struct {\n    Source      string   // \"bm25\", \"vector\", \"graph\"\n    RawScore    float32\n    Weight      float32\n    WeightedScore float32\n    Rank        int\n}\n</code></pre> <pre><code>// toolsemantic/reranker.go\n\n// Reranker performs cross-encoder reranking on retrieved results\ntype Reranker interface {\n    // Rerank scores query-document pairs using cross-encoder\n    Rerank(ctx context.Context, query string, docs []RerankerInput) ([]RerankerResult, error)\n\n    // Model returns the reranker model identifier\n    Model() string\n}\n\ntype RerankerInput struct {\n    ID      string\n    Content string\n}\n\ntype RerankerResult struct {\n    ID    string\n    Score float32  // Cross-encoder relevance score\n}\n\n// RerankerConfig configures a reranker\ntype RerankerConfig struct {\n    Provider  string  // \"cohere\", \"jina\", \"local\", \"colbert\"\n    Model     string  // \"rerank-english-v3.0\", \"ms-marco-MiniLM\"\n    MaxTokens int     // Max input tokens\n    BatchSize int     // Batch size for efficiency\n}\n</code></pre> <pre><code>// toolsemantic/graph.go\n\n// KnowledgeGraph provides graph-based retrieval (GraphRAG)\ntype KnowledgeGraph interface {\n    // Build extracts entities and relationships from documents\n    Build(ctx context.Context, docs []GraphDocument) error\n\n    // Query retrieves relevant subgraph for a query\n    Query(ctx context.Context, query string, opts GraphQueryOptions) (*GraphResult, error)\n\n    // GetEntity retrieves a specific entity\n    GetEntity(ctx context.Context, id string) (*Entity, error)\n\n    // TraverseRelations walks relationships from an entity\n    TraverseRelations(ctx context.Context, entityID string, depth int) ([]Relationship, error)\n}\n\ntype GraphDocument struct {\n    ID      string\n    Content string\n    Metadata map[string]any\n}\n\ntype GraphQueryOptions struct {\n    MaxEntities     int\n    MaxRelationships int\n    TraversalDepth  int\n    IncludeCommunities bool  // Include community summaries\n}\n\ntype GraphResult struct {\n    Entities      []Entity\n    Relationships []Relationship\n    Communities   []Community     // High-level community summaries\n    Summary       string          // Graph-generated summary\n    Score         float32\n}\n\ntype Entity struct {\n    ID          string\n    Name        string\n    Type        string            // \"tool\", \"namespace\", \"concept\"\n    Description string\n    Attributes  map[string]any\n    Embedding   []float32\n}\n\ntype Relationship struct {\n    ID       string\n    Source   string  // Entity ID\n    Target   string  // Entity ID\n    Type     string  // \"uses\", \"depends_on\", \"similar_to\"\n    Weight   float32\n    Metadata map[string]any\n}\n\ntype Community struct {\n    ID       string\n    Name     string\n    Summary  string\n    Entities []string  // Entity IDs in this community\n    Level    int       // Hierarchy level (0 = most granular)\n}\n</code></pre> <pre><code>// toolsemantic/hierarchical.go\n\n// HierarchicalChunker implements tree-structured document chunking\ntype HierarchicalChunker interface {\n    // Chunk splits document into hierarchical tree structure\n    Chunk(ctx context.Context, doc *Document) (*ChunkTree, error)\n\n    // Retrieve navigates tree to find relevant chunks\n    Retrieve(ctx context.Context, tree *ChunkTree, query string, opts TreeOptions) ([]Chunk, error)\n}\n\ntype Document struct {\n    ID       string\n    Content  string\n    Metadata map[string]any\n}\n\ntype ChunkTree struct {\n    Root     *ChunkNode\n    Depth    int\n    NumNodes int\n}\n\ntype ChunkNode struct {\n    ID        string\n    Level     int           // 0 = leaf, higher = more abstract\n    Content   string        // Text content or summary\n    Embedding []float32\n    Children  []*ChunkNode\n    Parent    *ChunkNode\n\n    // For RAPTOR-style summarization\n    Summary   string        // LLM-generated summary at this level\n}\n\ntype Chunk struct {\n    ID        string\n    Content   string\n    Level     int\n    Score     float32\n    Path      []string  // Path from root to this chunk\n}\n\ntype TreeOptions struct {\n    MaxChunks     int\n    MinLevel      int  // Minimum abstraction level to consider\n    MaxLevel      int  // Maximum abstraction level\n\n    // Traversal strategy\n    Strategy      TraversalStrategy\n}\n\ntype TraversalStrategy string\n\nconst (\n    TraversalTopDown    TraversalStrategy = \"top_down\"    // Start from summaries\n    TraversalBottomUp   TraversalStrategy = \"bottom_up\"   // Start from leaves\n    TraversalCollapsed  TraversalStrategy = \"collapsed\"   // RAPTOR-style collapsed tree\n)\n</code></pre> <pre><code>// toolsemantic/agentic.go\n\n// AgenticRetriever implements LLM-enhanced retrieval strategies\ntype AgenticRetriever interface {\n    // Retrieve performs agentic retrieval with optional query expansion\n    Retrieve(ctx context.Context, query string, opts AgenticOptions) (*AgenticResult, error)\n}\n\ntype AgenticOptions struct {\n    // Query expansion\n    EnableQueryExpansion  bool\n    MaxExpandedQueries    int\n\n    // Multi-query\n    EnableMultiQuery      bool\n    QueryVariations       int\n\n    // Self-reasoning (Step-Back, Chain-of-Thought)\n    EnableSelfReasoning   bool\n    ReasoningDepth        int\n\n    // Iterative retrieval\n    EnableIterative       bool\n    MaxIterations         int\n    StopCondition         func(results []SearchResult) bool\n\n    // Base retriever to use\n    BaseRetriever         HybridSearcher\n}\n\ntype AgenticResult struct {\n    Results          []SearchResult\n\n    // Agentic metadata\n    ExpandedQueries  []string\n    ReasoningChain   []ReasoningStep\n    Iterations       int\n\n    // Quality signals\n    Confidence       float32\n    CoverageScore    float32\n}\n\ntype ReasoningStep struct {\n    Step        int\n    Query       string\n    Reasoning   string   // LLM explanation\n    ResultCount int\n    TopScore    float32\n}\n</code></pre> <pre><code>// toolsemantic/colbert.go\n\n// ColBERTIndex implements late interaction retrieval\ntype ColBERTIndex interface {\n    // Index adds documents with token-level embeddings\n    Index(ctx context.Context, docs []ColBERTDocument) error\n\n    // Search performs MaxSim-based late interaction search\n    Search(ctx context.Context, query string, opts ColBERTOptions) ([]ColBERTResult, error)\n}\n\ntype ColBERTDocument struct {\n    ID           string\n    Content      string\n    TokenEmbeddings [][]float32  // Per-token embeddings\n}\n\ntype ColBERTOptions struct {\n    TopK         int\n    NCells       int   // For PLAID centroid-based search\n    NDocs        int   // Candidate docs before rescoring\n}\n\ntype ColBERTResult struct {\n    ID           string\n    Score        float32  // MaxSim score\n    TokenScores  []TokenMatch  // Token-level matching details\n}\n\ntype TokenMatch struct {\n    QueryToken  string\n    DocToken    string\n    Score       float32\n}\n</code></pre> <p>Integration with Existing Libraries:</p> <pre><code>// toolsemantic/integration.go\n\n// SemanticSearcher wraps toolsearch.Searcher with semantic capabilities\ntype SemanticSearcher struct {\n    // Existing BM25 searcher\n    bm25     toolsearch.Searcher\n\n    // New semantic components\n    embedder     Embedder\n    vectorIndex  VectorIndex\n    reranker     Reranker\n    graph        KnowledgeGraph\n\n    // Configuration\n    config       SemanticConfig\n}\n\n// Search implements toolindex.Searcher interface\nfunc (s *SemanticSearcher) Search(ctx context.Context, query string, opts toolsearch.Options) ([]toolsearch.Result, error) {\n    // Perform hybrid search internally\n    hybridResults, err := s.hybridSearch(ctx, query, HybridOptions{\n        TopK:         opts.Limit,\n        BM25Weight:   s.config.BM25Weight,\n        VectorWeight: s.config.VectorWeight,\n        GraphWeight:  s.config.GraphWeight,\n        EnableReranker: s.config.EnableReranker,\n    })\n    if err != nil {\n        return nil, err\n    }\n\n    // Convert to toolsearch.Result format\n    return convertResults(hybridResults), nil\n}\n\n// NewSemanticSearcher creates a semantic searcher that wraps BM25\nfunc NewSemanticSearcher(bm25 toolsearch.Searcher, opts ...SemanticOption) (*SemanticSearcher, error) {\n    // ...\n}\n</code></pre> <p>Configuration Example:</p> <pre><code># metatools.yaml\nsemantic:\n  enabled: true\n\n  embedder:\n    provider: openai\n    model: text-embedding-3-small\n    dimensions: 1536\n\n  vector_index:\n    backend: memory  # memory, faiss, qdrant, chromadb\n    metric: cosine\n    index_type: hnsw\n    hnsw:\n      m: 16\n      ef_construction: 200\n      ef_search: 100\n\n  hybrid:\n    bm25_weight: 0.4\n    vector_weight: 0.5\n    graph_weight: 0.1\n    fusion_method: rrf\n\n  reranker:\n    enabled: true\n    provider: cohere\n    model: rerank-english-v3.0\n    top_k: 20\n\n  graph:\n    enabled: false  # Experimental\n    entity_types: [\"tool\", \"namespace\", \"concept\"]\n\n  agentic:\n    enabled: false  # Experimental\n    query_expansion: true\n    max_iterations: 3\n</code></pre> <p>Performance Characteristics:</p> Component Latency Memory Accuracy Impact BM25 (baseline) ~8ms Low Baseline (78%) Vector (HNSW) ~12ms Medium +8% (86%) Hybrid (BM25+Vector) ~25ms Medium +16% (94%) + Reranker +50-100ms Low +3% (97%) + GraphRAG +100-200ms High +2% (context) + Agentic +500-2000ms Low Variable <p>Research-Based Accuracy Benchmarks (Tool Discovery):</p> Method Accuracy @ 50 tools @ 200 tools @ 500 tools BM25 only 78% 71% 63% Vector only 82% 76% 69% Hybrid (BM25+Vector) 94% 89% 84% Hybrid + Reranker 97% 94% 91% Hybrid + Reranker + Graph 98% 96% 93% <p>Edge Cases:</p> <ul> <li>[ ] Empty embedding: reject with ErrEmptyInput</li> <li>[ ] Dimension mismatch: validate at index time</li> <li>[ ] Reranker timeout: fall back to hybrid-only results</li> <li>[ ] Graph disconnected: handle isolated entities</li> <li>[ ] Query expansion loop: max iteration limit</li> <li>[ ] OOM on large indices: streaming/pagination support</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#stream-e-agent-skills","title":"Stream E: Agent Skills","text":"<p>Goal: Higher-level agent capabilities that compose tools into reusable workflows and behaviors.</p> <p>Design Insight: Skills sit above tools in the abstraction hierarchy. While tools are atomic operations (search, execute, describe), skills are reusable agent behaviors that orchestrate multiple tools (research-and-summarize, debug-and-fix, deploy-with-validation).</p> Phase Work Package Duration Deliverables E1 Skill Core 2 weeks Skill interface, registry, manifest E2 Skill Composition 1 week Workflow DSL, step orchestration E3 Skill Execution 1 week Runtime, context propagation, rollback <p>Total: 4 weeks (can start after Stream B Protocol Layer)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#abstraction-hierarchy","title":"Abstraction Hierarchy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        AGENTS                                \u2502\n\u2502  (Autonomous decision makers: Claude, GPT, custom agents)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502 use\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        SKILLS (NEW)                          \u2502\n\u2502  Higher-level behaviors: research, debug, deploy, review    \u2502\n\u2502  Composed from multiple tools with workflow logic           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502 orchestrate\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        TOOLSETS                              \u2502\n\u2502  Curated tool collections: dev-tools, search-tools          \u2502\n\u2502  Filtered by namespace, tags, access policy                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502 contain\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         TOOLS                                \u2502\n\u2502  Atomic operations: search_tools, run_tool, describe_tool   \u2502\n\u2502  Single-purpose, composable primitives                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#e1-skill-core-2-weeks","title":"E1: Skill Core (2 weeks)","text":"<pre><code>Week 18:\n\u251c\u2500\u2500 Day 1-2: Skill interface definition\n\u251c\u2500\u2500 Day 3-4: SkillManifest type (A2A-aligned)\n\u251c\u2500\u2500 Day 5: SkillRegistry implementation\n\nWeek 19:\n\u251c\u2500\u2500 Day 1-2: Skill discovery and advertisement\n\u251c\u2500\u2500 Day 3-4: Skill versioning integration\n\u251c\u2500\u2500 Day 5: Unit tests, documentation\n</code></pre> <p>Interface Contract: <pre><code>// toolskill/skill.go\ntype Skill interface {\n    // Identity\n    ID() string\n    Name() string\n    Version() semver.Version\n\n    // Manifest for discovery/advertisement\n    Manifest() *SkillManifest\n\n    // Execution\n    Execute(ctx context.Context, input SkillInput) (*SkillOutput, error)\n\n    // Introspection\n    RequiredTools() []string\n    Steps() []StepDefinition\n}\n\n// SkillManifest describes skill capabilities (A2A-aligned)\ntype SkillManifest struct {\n    ID          string            `json:\"id\"`\n    Name        string            `json:\"name\"`\n    Version     string            `json:\"version\"`\n    Description string            `json:\"description\"`\n    InputSchema *jsonschema.Schema `json:\"inputSchema\"`\n    OutputSchema *jsonschema.Schema `json:\"outputSchema,omitempty\"`\n    Tags        []string          `json:\"tags\"`\n\n    // Dependencies\n    RequiredTools []string        `json:\"requiredTools\"`\n    RequiredSkills []string       `json:\"requiredSkills,omitempty\"`\n\n    // Execution hints\n    EstimatedSteps int            `json:\"estimatedSteps\"`\n    Idempotent     bool           `json:\"idempotent\"`\n    SupportsPause  bool           `json:\"supportsPause\"`\n}\n\n// SkillRegistry manages skill discovery and lookup\ntype SkillRegistry interface {\n    Register(skill Skill) error\n    Get(id string) (Skill, error)\n    GetByName(name string, versionConstraint string) (Skill, error)\n    List() []SkillManifest\n    ListByTag(tag string) []SkillManifest\n    Unregister(id string) error\n\n    // Discovery for A2A\n    Advertise() []SkillManifest\n}\n</code></pre></p> <p>Design Patterns from Research:</p> Framework Pattern Adaptation for toolskill LangChain Chains (sequential) <code>SequentialSkill</code> with steps LangChain Agents (decision) <code>AdaptiveSkill</code> with branching CrewAI Crews (role-based) <code>CompositeSkill</code> with sub-skills CrewAI Flows (control) <code>WorkflowSkill</code> with explicit flow AutoGen Conversation <code>ConversationalSkill</code> with memory"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#skillmd-standard-format-support","title":"SKILL.md Standard Format Support","text":"<p>The toolskill library will implement the Agent Skills Open Standard (adopted by Claude Code, OpenAI Codex CLI, ChatGPT, and Google Antigravity) to ensure cross-platform compatibility.</p> <p>Standard SKILL.md Structure: <pre><code>---\nname: skill-name-with-hyphens\ndescription: Use when [specific triggering conditions and symptoms]\nmetadata:\n  author: optional-author\n  version: \"1.0.0\"\n  argument-hint: optional-hint\n---\n\n# Skill Name\n\n## Overview\nWhat is this? Core principle in 1-2 sentences.\n\n## When to Use\nSymptoms and use cases.\n\n## How It Works\nStep-by-step process.\n\n[Additional sections as needed]\n</code></pre></p> <p>Standard Directory Structure: <pre><code>skills/\n  skill-name/\n    SKILL.md              # Main entry point (required)\n    references/           # Optional supporting files\n      summary.md\n      files.md\n    scripts/              # Optional executable tools\n      validate.sh\n</code></pre></p> <p>Discovery Locations (Claude Code compatible): - User settings: <code>~/.claude/skills/</code> or <code>~/.config/claude/skills/</code> - Project settings: <code>.claude/skills/</code> - Plugin-provided: <code>plugins/*/skills/</code> - Nested directories: Automatic discovery in subdirectories</p> <p>Interface Contract for SKILL.md Parsing: <pre><code>// toolskill/skillmd/parser.go\n\n// SkillMD represents a parsed SKILL.md file\ntype SkillMD struct {\n    // YAML Frontmatter\n    Name        string            `yaml:\"name\"`\n    Description string            `yaml:\"description\"`\n    License     string            `yaml:\"license,omitempty\"`\n    Metadata    map[string]any    `yaml:\"metadata,omitempty\"`\n\n    // Parsed Content\n    Content     string            // Raw markdown content\n    Overview    string            // Extracted ## Overview section\n    WhenToUse   string            // Extracted ## When to Use section\n    HowItWorks  string            // Extracted ## How It Works section\n    Sections    map[string]string // All other sections\n}\n\n// Parser reads and parses SKILL.md files\ntype Parser interface {\n    Parse(path string) (*SkillMD, error)\n    ParseBytes(data []byte) (*SkillMD, error)\n    Validate(skill *SkillMD) []ValidationError\n}\n\n// Generator creates SKILL.md files from skills\ntype Generator interface {\n    Generate(skill Skill) ([]byte, error)\n    GenerateWithTemplate(skill Skill, template string) ([]byte, error)\n}\n\n// Discovery finds skills in standard locations\ntype Discovery interface {\n    // Scan standard locations for skills\n    ScanUserSkills() ([]SkillMD, error)           // ~/.claude/skills/\n    ScanProjectSkills(root string) ([]SkillMD, error) // .claude/skills/\n    ScanPluginSkills(pluginDir string) ([]SkillMD, error)\n\n    // Watch for changes\n    Watch(ctx context.Context, locations []string) (&lt;-chan SkillEvent, error)\n}\n</code></pre></p> <p>Cross-Platform Export: <pre><code>// toolskill/export/exporter.go\n\ntype Exporter interface {\n    // Export to standard SKILL.md format (Claude, Codex, ChatGPT)\n    ToSkillMD(skill Skill) (*SkillMD, error)\n\n    // Export to platform-specific formats\n    ToZIP(skill Skill) ([]byte, error)          // Claude/OpenAI upload\n    ToTarGz(skill Skill) ([]byte, error)        // Gemini upload\n\n    // Batch export\n    ExportDirectory(skills []Skill, path string) error\n}\n\n// Import from SKILL.md files\ntype Importer interface {\n    // Import single skill\n    FromSkillMD(md *SkillMD) (Skill, error)\n\n    // Batch import from directory\n    FromDirectory(path string) ([]Skill, error)\n\n    // Import from skill repository URL\n    FromRepository(url string) ([]Skill, error)\n}\n</code></pre></p> <p>Key Design Decisions:</p> <ol> <li> <p>Frontmatter Limited to name + description: Per standard, only these fields are guaranteed. Additional metadata is optional.</p> </li> <li> <p>Description Format: Must start with \"Use when...\" to optimize for Claude's skill discovery algorithm.</p> </li> <li> <p>Progressive Disclosure: Skills loaded on-demand based on description matching, not pre-loaded (reduces context window usage).</p> </li> <li> <p>Flat Namespace: All skills in searchable namespace for discovery. No nested hierarchies.</p> </li> <li> <p>Token Efficiency: Frequently-loaded skills should be &lt;200 words. Reference material in separate files.</p> </li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#e2-skill-composition-1-week","title":"E2: Skill Composition (1 week)","text":"<pre><code>Week 20:\n\u251c\u2500\u2500 Day 1-2: Step definition DSL\n\u251c\u2500\u2500 Day 3: Sequential composition\n\u251c\u2500\u2500 Day 4: Parallel composition\n\u251c\u2500\u2500 Day 5: Conditional branching\n</code></pre> <p>Interface Contract: <pre><code>// toolskill/step.go\ntype StepDefinition struct {\n    ID          string\n    Name        string\n    Tool        string              // Tool to execute\n    InputMapper func(SkillContext) any  // Map skill input to tool input\n    OutputMapper func(any) any      // Transform tool output\n    Condition   func(SkillContext) bool // Skip if returns false\n    OnError     ErrorHandler\n}\n\n// toolskill/builder.go\ntype SkillBuilder struct { ... }\n\nfunc NewSkillBuilder(name string) *SkillBuilder\n\n// Sequential steps\nfunc (b *SkillBuilder) Step(name string, tool string) *StepBuilder\n\n// Parallel execution\nfunc (b *SkillBuilder) Parallel(steps ...*StepBuilder) *SkillBuilder\n\n// Conditional branching\nfunc (b *SkillBuilder) Branch(condition func(SkillContext) bool,\n                              ifTrue *SkillBuilder,\n                              ifFalse *SkillBuilder) *SkillBuilder\n\n// Sub-skill composition\nfunc (b *SkillBuilder) UseSkill(skillID string) *SkillBuilder\n\n// Build final skill\nfunc (b *SkillBuilder) Build() (Skill, error)\n</code></pre></p> <p>Example: Research-and-Summarize Skill <pre><code>researchSkill := NewSkillBuilder(\"research-and-summarize\").\n    WithDescription(\"Research a topic and provide a summary\").\n    WithInputSchema(researchInputSchema).\n\n    // Step 1: Search for relevant tools\n    Step(\"discover\", \"search_tools\").\n        WithInput(func(ctx SkillContext) any {\n            return map[string]any{\"query\": ctx.Input[\"topic\"]}\n        }).\n\n    // Step 2: Get documentation for top results\n    Parallel(\n        Step(\"docs-1\", \"describe_tool\").WithInput(fromResult(0)),\n        Step(\"docs-2\", \"describe_tool\").WithInput(fromResult(1)),\n        Step(\"docs-3\", \"describe_tool\").WithInput(fromResult(2)),\n    ).\n\n    // Step 3: Synthesize findings\n    Step(\"synthesize\", \"run_tool\").\n        WithInput(func(ctx SkillContext) any {\n            return synthesizeInputs(ctx)\n        }).\n\n    Build()\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#e3-skill-execution-1-week","title":"E3: Skill Execution (1 week)","text":"<pre><code>Week 21:\n\u251c\u2500\u2500 Day 1-2: Skill runtime with context\n\u251c\u2500\u2500 Day 3: Progress tracking, checkpoints\n\u251c\u2500\u2500 Day 4: Rollback on failure\n\u251c\u2500\u2500 Day 5: Integration with toolobserve\n</code></pre> <p>Interface Contract: <pre><code>// toolskill/runtime.go\ntype SkillRuntime interface {\n    Execute(ctx context.Context, skill Skill, input SkillInput) (*SkillOutput, error)\n    ExecuteAsync(ctx context.Context, skill Skill, input SkillInput) (ExecutionID, error)\n\n    // Progress and control\n    GetStatus(execID ExecutionID) (*ExecutionStatus, error)\n    Pause(execID ExecutionID) error\n    Resume(execID ExecutionID) error\n    Cancel(execID ExecutionID) error\n\n    // Checkpoints for long-running skills\n    Checkpoint(execID ExecutionID) (*Checkpoint, error)\n    RestoreFromCheckpoint(checkpoint *Checkpoint) (ExecutionID, error)\n}\n\n// SkillContext provides execution context to steps\ntype SkillContext struct {\n    Input      map[string]any      // Original skill input\n    Results    map[string]any      // Results from previous steps\n    Metadata   map[string]any      // Execution metadata\n    Toolset    *toolset.Toolset    // Available tools\n    Logger     Logger              // Structured logging\n    Tracer     trace.Tracer        // OpenTelemetry tracing\n}\n\n// ExecutionStatus tracks skill progress\ntype ExecutionStatus struct {\n    ID            ExecutionID\n    SkillID       string\n    State         ExecutionState  // pending, running, paused, completed, failed\n    CurrentStep   string\n    CompletedSteps []string\n    Progress      float64         // 0.0 to 1.0\n    StartedAt     time.Time\n    Error         error\n}\n</code></pre></p> <p>Edge Cases: - [ ] Step timeout: configurable per-step, fail or skip - [ ] Tool not found: fail skill with ErrMissingTool - [ ] Parallel step failure: configurable (fail-fast or continue) - [ ] Checkpoint restore: validate skill version compatibility - [ ] Circular skill dependencies: detect and reject at registration</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#skill-tool-integration","title":"Skill-Tool Integration","text":"<pre><code>// Expose skills via MCP as special tools\ntype SkillToolProvider struct {\n    registry SkillRegistry\n    runtime  SkillRuntime\n}\n\nfunc (p *SkillToolProvider) Tools() []*mcp.Tool {\n    var tools []*mcp.Tool\n    for _, manifest := range p.registry.List() {\n        tools = append(tools, &amp;mcp.Tool{\n            Name: \"skill:\" + manifest.Name,\n            Description: \"[SKILL] \" + manifest.Description,\n            InputSchema: manifest.InputSchema,\n        })\n    }\n    return tools\n}\n</code></pre> <p>MCP Tool Naming Convention: - Regular tools: <code>search_tools</code>, <code>run_tool</code> - Skills: <code>skill:research</code>, <code>skill:debug</code>, <code>skill:deploy</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#4-phase-breakdown","title":"4. Phase Breakdown","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#phase-1-mvp-core-weeks-1-7","title":"Phase 1: MVP Core (Weeks 1-7)","text":"<p>Deliverables: - [x] Cobra CLI framework - [x] Koanf configuration - [x] Transport abstraction (stdio, SSE, HTTP) - [x] Provider registry - [x] Basic backend registry</p> <p>Success Criteria: - <code>metatools serve --config config.yaml</code> starts HTTP server - All 13 extension points configurable via YAML - Backward compatible with existing <code>metatools</code> usage</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#phase-2-protocol-layer-weeks-8-14","title":"Phase 2: Protocol Layer (Weeks 8-14)","text":"<p>Deliverables: - [ ] tooladapter library - [ ] toolset library - [ ] Multi-transport exposure</p> <p>Success Criteria: - Tools convertible between MCP \u2194 OpenAI \u2194 Anthropic - Composable toolsets via builder pattern - Same tools exposed via MCP and REST</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#phase-3-cross-cutting-weeks-8-17-parallel","title":"Phase 3: Cross-Cutting (Weeks 8-17, parallel)","text":"<p>Deliverables: - [ ] toolcache (memory, Redis, layered) - [ ] toolobserve (OpenTelemetry) - [ ] toolversion (semantic versioning) - [ ] toolresilience (circuit breaker, retry) - [ ] toolhealth, toolaudit, toolsecrets</p> <p>Success Criteria: - All tool calls traced via OpenTelemetry - Circuit breaker protects against cascade failures - Comprehensive audit log for compliance</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#phase-4-enterprise-weeks-12-17-parallel","title":"Phase 4: Enterprise (Weeks 12-17, parallel)","text":"<p>Deliverables: - [ ] Multi-tenancy (resolvers, middleware, storage) - [ ] toolsemantic (vector search) - [ ] toolresource (MCP Resources) - [ ] toolgateway (auth proxy)</p> <p>Success Criteria: - Multiple tenants isolated by configuration - Semantic search improves tool discovery accuracy - OAuth 2.1 authentication via gateway</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#phase-5-agent-skills-weeks-18-21","title":"Phase 5: Agent Skills (Weeks 18-21)","text":"<p>Deliverables: - [ ] toolskill library (skill interface, registry, manifest) - [ ] Skill composition DSL (sequential, parallel, branching) - [ ] Skill runtime (execution, checkpoints, rollback) - [ ] A2A skill advertisement integration</p> <p>Success Criteria: - Skills discoverable via SkillRegistry.Advertise() - Multi-step skills execute with progress tracking - Skills exposed as MCP tools with <code>skill:</code> prefix - Checkpoint/restore enables long-running skill recovery</p> <p>Dependencies: - Requires Stream B completion (toolset for tool access) - Benefits from Stream C (toolobserve for tracing)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#5-interface-contracts","title":"5. Interface Contracts","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#core-interfaces-must-be-stable","title":"Core Interfaces (Must Be Stable)","text":"Interface Library Breaking Change Policy <code>Tool</code> toolmodel MAJOR version bump <code>Index</code> toolindex MAJOR version bump <code>Searcher</code> toolindex MINOR (additive only) <code>Store</code> tooldocs MINOR (additive only) <code>Runner</code> toolrun MAJOR version bump <code>Backend</code> toolruntime MINOR (additive only)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#new-interfaces-design-phase","title":"New Interfaces (Design Phase)","text":"Interface Library Status Review Required <code>Transport</code> metatools Draft Architecture <code>ToolProvider</code> metatools Draft Architecture <code>BackendRegistry</code> metatools Draft Architecture <code>Adapter</code> tooladapter Draft Protocol Team <code>Cache</code> toolcache Draft Infrastructure <code>Observer</code> toolobserve Draft SRE Team <code>Skill</code> toolskill Draft Agent Team <code>SkillRegistry</code> toolskill Draft Agent Team <code>SkillRuntime</code> toolskill Draft Agent Team <code>Embedder</code> toolsemantic Draft ML/Search Team <code>VectorIndex</code> toolsemantic Draft ML/Search Team <code>HybridSearcher</code> toolsemantic Draft ML/Search Team <code>Reranker</code> toolsemantic Draft ML/Search Team <code>KnowledgeGraph</code> toolsemantic Draft ML/Search Team <code>AgenticRetriever</code> toolsemantic Draft ML/Search Team"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#6-edge-cases-considerations","title":"6. Edge Cases &amp; Considerations","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#interface-evolution","title":"Interface Evolution","text":"Scenario Strategy Add optional field MINOR bump, backward compatible Add required field MAJOR bump, migration guide Remove field Deprecate \u2192 2 releases \u2192 remove Change field type Never (create new field)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#error-handling","title":"Error Handling","text":"Error Type HTTP Code MCP Error Code Retry? Tool not found 404 -32601 No Invalid input 400 -32602 No Backend timeout 504 -32603 Yes Rate limited 429 -32603 Yes (with backoff) Circuit open 503 -32603 Yes (after reset) Internal error 500 -32603 Maybe"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#concurrency","title":"Concurrency","text":"Component Concurrency Model Lock Granularity Provider Registry RWMutex Per-registry Backend Registry RWMutex Per-registry Cache Per-key locking Key-level Circuit Breaker Atomic counters Per-breaker Tenant Store RWMutex Per-tenant Skill Registry RWMutex Per-registry Skill Runtime Per-execution Execution-level"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#resource-limits","title":"Resource Limits","text":"Resource Default Configurable Enforcement Max tools per backend 1000 Yes Registration fails Max concurrent requests 100 Yes 503 response Max request size 10MB Yes 413 response Tool execution timeout 30s Per-tool Context cancellation Cache entry size 1MB Yes Reject large entries"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#7-rollout-strategy","title":"7. Rollout Strategy","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#version-compatibility-matrix","title":"Version Compatibility Matrix","text":"metatools toolmodel toolindex toolrun tooladapter toolskill v0.2.x v0.1.2+ v0.1.8+ v0.1.9+ - - v0.3.x v0.2.0+ v0.2.0+ v0.2.0+ v1.0.0+ - v1.0.x v0.2.0+ v0.2.0+ v0.2.0+ v1.0.0+ - v1.1.x v0.2.0+ v0.2.0+ v0.2.0+ v1.0.0+ v1.0.0+"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#release-cadence","title":"Release Cadence","text":"Track Frequency Stability Use Case stable Monthly Production Enterprise beta Bi-weekly Testing Early adopters nightly Daily Development Contributors"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#migration-guides","title":"Migration Guides","text":"<p>Each MAJOR version bump requires: 1. Migration guide with step-by-step instructions 2. Codemods where possible (automated refactoring) 3. Deprecation period (minimum 2 minor versions) 4. Backward compatibility layer (optional, time-limited)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#feature-flags-for-rollout","title":"Feature Flags for Rollout","text":"<pre><code>feature_flags:\n  new_transport_layer: true      # Phase 2\n  protocol_adapters: false       # Phase 3 (beta)\n  semantic_search: false         # Phase 4 (alpha)\n  multi_tenancy: false           # Phase 4 (alpha)\n  agent_skills: false            # Phase 5 (alpha)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#8-multi-language-extensibility","title":"8. Multi-Language Extensibility","text":"<p>Design Principle: The pluggable architecture is not limited to Go implementations. Any component can be replaced by implementations written in any programming language through standardized interface contracts.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#why-multi-language-matters","title":"Why Multi-Language Matters","text":"Use Case Language Rationale ML/Embedding Models Python Rich ML ecosystem (PyTorch, transformers, sentence-transformers) High-Performance Retrieval Rust Memory safety + near-C performance for vector operations Enterprise Integrations Java Existing corporate libraries, Spring ecosystem Rapid Prototyping TypeScript Fast iteration, existing MCP server implementations Edge Deployment WASM Sandboxed, portable, language-agnostic runtime"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#interface-contract-technologies","title":"Interface Contract Technologies","text":"<p>The architecture supports three proven approaches for multi-language interoperability:</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#option-1-grpc-protocol-buffers-recommended","title":"Option 1: gRPC + Protocol Buffers (Recommended)","text":"<p>Battle-tested approach used by HashiCorp (Terraform, Vault, Consul, Packer).</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            METATOOLS CORE (Go)                                   \u2502\n\u2502                                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                     Plugin Host (go-plugin style)                        \u2502   \u2502\n\u2502   \u2502   - Launches plugins as subprocesses                                     \u2502   \u2502\n\u2502   \u2502   - Communicates via gRPC over local socket                             \u2502   \u2502\n\u2502   \u2502   - Health monitoring and automatic restart                              \u2502   \u2502\n\u2502   \u2502   - Graceful shutdown and resource cleanup                               \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                   \u2502                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502 gRPC (protobuf)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                           \u2502                           \u2502\n        \u25bc                           \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Python Embedder   \u2502   \u2502 Rust Vector Index \u2502   \u2502 TypeScript Adapter\u2502\n\u2502 (sentence-bert)   \u2502   \u2502 (HNSW + SIMD)     \u2502   \u2502 (OpenAI format)   \u2502\n\u2502                   \u2502   \u2502                   \u2502   \u2502                   \u2502\n\u2502 pip install       \u2502   \u2502 cargo build       \u2502   \u2502 npm run build     \u2502\n\u2502 metatools-embed   \u2502   \u2502 --release         \u2502   \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Protocol Buffer Interface Definitions:</p> <pre><code>// api/proto/embedder.proto\nsyntax = \"proto3\";\npackage metatools.v1;\n\nservice Embedder {\n  rpc Embed(EmbedRequest) returns (EmbedResponse);\n  rpc EmbedBatch(EmbedBatchRequest) returns (EmbedBatchResponse);\n  rpc Info(InfoRequest) returns (EmbedderInfo);\n}\n\nmessage EmbedRequest {\n  string text = 1;\n}\n\nmessage EmbedResponse {\n  repeated float embedding = 1;\n}\n\nmessage EmbedderInfo {\n  string model = 1;\n  int32 dimensions = 2;\n}\n</code></pre> <pre><code>// api/proto/searcher.proto\nsyntax = \"proto3\";\npackage metatools.v1;\n\nservice Searcher {\n  rpc Search(SearchRequest) returns (SearchResponse);\n  rpc Index(IndexRequest) returns (IndexResponse);\n  rpc Delete(DeleteRequest) returns (DeleteResponse);\n}\n\nmessage SearchRequest {\n  string query = 1;\n  int32 top_k = 2;\n  map&lt;string, string&gt; filters = 3;\n}\n\nmessage SearchResult {\n  string id = 1;\n  float score = 2;\n  string content = 3;\n  map&lt;string, string&gt; metadata = 4;\n}\n</code></pre> <p>Benefits: - Language-agnostic: Generate client/server stubs for 10+ languages via <code>protoc</code> - Schema evolution: Add fields without breaking backward compatibility - High performance: Binary serialization, HTTP/2 multiplexing - Proven at scale: Used by Kubernetes, gRPC-web, many microservices</p> <p>Real-World Example (HashiCorp go-plugin): <pre><code>// Go host code (metatools)\ntype EmbedderPlugin struct {\n    plugin.Plugin\n    Impl Embedder\n}\n\nfunc (p *EmbedderPlugin) GRPCServer(broker *plugin.GRPCBroker, s *grpc.Server) error {\n    RegisterEmbedderServer(s, &amp;GRPCServer{Impl: p.Impl})\n    return nil\n}\n\nfunc (p *EmbedderPlugin) GRPCClient(ctx context.Context, broker *plugin.GRPCBroker, c *grpc.ClientConn) (interface{}, error) {\n    return &amp;GRPCClient{client: NewEmbedderClient(c)}, nil\n}\n</code></pre></p> <pre><code># Python plugin implementation\nclass PythonEmbedder(metatools_pb2_grpc.EmbedderServicer):\n    def __init__(self):\n        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n\n    def Embed(self, request, context):\n        embedding = self.model.encode(request.text)\n        return metatools_pb2.EmbedResponse(embedding=embedding.tolist())\n\n    def Info(self, request, context):\n        return metatools_pb2.EmbedderInfo(\n            model='all-MiniLM-L6-v2',\n            dimensions=384\n        )\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#option-2-webassembly-component-model-emerging","title":"Option 2: WebAssembly Component Model (Emerging)","text":"<p>Sandboxed, portable, no network overhead.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            METATOOLS CORE (Go)                                   \u2502\n\u2502                                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                     WASM Runtime (wasmtime/wasmer)                       \u2502   \u2502\n\u2502   \u2502   - Load .wasm modules as plugins                                        \u2502   \u2502\n\u2502   \u2502   - WebAssembly Interface Types (WIT) for type-safe boundaries          \u2502   \u2502\n\u2502   \u2502   - WASI for system access (filesystem, network)                         \u2502   \u2502\n\u2502   \u2502   - Strong sandbox: memory isolation, capability-based security          \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                   \u2502                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502 WebAssembly Interface Types (WIT)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                           \u2502                           \u2502\n        \u25bc                           \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Rust \u2192 WASM       \u2502   \u2502 Go \u2192 WASM         \u2502   \u2502 Python \u2192 WASM     \u2502\n\u2502 (vector_index.wasm\u2502   \u2502 (adapter.wasm)    \u2502   \u2502 (embedder.wasm)   \u2502\n\u2502  via wasm32-wasi) \u2502   \u2502  via TinyGo       \u2502   \u2502  via Pyodide      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>WebAssembly Interface Types (WIT) Definition:</p> <pre><code>// api/wit/embedder.wit\npackage metatools:embedder@1.0.0;\n\ninterface embedder {\n    record embed-request {\n        text: string,\n    }\n\n    record embed-response {\n        embedding: list&lt;f32&gt;,\n    }\n\n    record embedder-info {\n        model: string,\n        dimensions: u32,\n    }\n\n    embed: func(request: embed-request) -&gt; result&lt;embed-response, string&gt;;\n    info: func() -&gt; embedder-info;\n}\n\nworld embedder-plugin {\n    export embedder;\n}\n</code></pre> <p>Benefits: - Sandboxed: Strong isolation, no access beyond granted capabilities - Portable: Same .wasm binary runs on any platform - No network overhead: Direct function calls, not RPC - Multi-language: Rust, Go (TinyGo), C/C++, AssemblyScript compile to WASM</p> <p>Limitations: - Ecosystem still maturing (WASI Preview 2 released 2024) - Some languages have limited WASM support - Performance overhead for complex data marshaling</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#option-3-json-rpc-over-stdio-simple","title":"Option 3: JSON-RPC over stdio (Simple)","text":"<p>Lightweight approach for simple plugins.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            METATOOLS CORE (Go)                                   \u2502\n\u2502                                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                     JSON-RPC Dispatcher                                  \u2502   \u2502\n\u2502   \u2502   - Spawn plugin process                                                 \u2502   \u2502\n\u2502   \u2502   - Send JSON-RPC requests via stdin                                     \u2502   \u2502\n\u2502   \u2502   - Receive JSON-RPC responses via stdout                                \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                   \u2502                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502 JSON-RPC 2.0 over stdin/stdout\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                           \u2502                           \u2502\n        \u25bc                           \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Any executable    \u2502   \u2502 Shell script      \u2502   \u2502 Node.js script    \u2502\n\u2502 (simple wrapper)  \u2502   \u2502 (bash/zsh)        \u2502   \u2502 (quick prototype) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits: - Trivial to implement: Any language that reads stdin and writes stdout - No dependencies: No gRPC libraries, no WASM runtime - Debugging friendly: Human-readable JSON messages</p> <p>Limitations: - Performance: Text serialization slower than binary - No streaming: Request-response only - Less type safety: JSON schema validation required</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#recommended-approach-by-component","title":"Recommended Approach by Component","text":"Component Recommended Rationale Embedder gRPC (Python) ML ecosystem, batch processing, GPU support VectorIndex gRPC (Rust) or WASM Performance-critical, SIMD optimization Reranker gRPC (Python) Hugging Face transformers, cross-encoders KnowledgeGraph gRPC (Python/Java) Neo4j, NetworkX, JanusGraph bindings Adapter Go native or WASM Simple logic, low latency Cache Go native Redis/memory clients well-supported in Go"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#plugin-sdk-generation","title":"Plugin SDK Generation","text":"<p>The architecture supports automatic SDK generation from Protocol Buffer definitions:</p> <pre><code># Generate SDKs for all supported languages\nmake generate-sdks\n\n# Outputs:\n# - sdk/go/       (native Go interfaces)\n# - sdk/python/   (gRPC stubs + helper classes)\n# - sdk/rust/     (gRPC stubs + traits)\n# - sdk/typescript/ (gRPC-web stubs)\n</code></pre> <p>Python SDK Example:</p> <pre><code># sdk/python/metatools/embedder.py\nfrom abc import ABC, abstractmethod\nfrom metatools.proto import embedder_pb2, embedder_pb2_grpc\n\nclass BaseEmbedder(embedder_pb2_grpc.EmbedderServicer, ABC):\n    \"\"\"Base class for implementing Embedder plugins in Python.\"\"\"\n\n    @abstractmethod\n    def embed(self, text: str) -&gt; list[float]:\n        \"\"\"Generate embedding for text.\"\"\"\n        pass\n\n    @abstractmethod\n    def dimensions(self) -&gt; int:\n        \"\"\"Return embedding dimensions.\"\"\"\n        pass\n\n    @abstractmethod\n    def model_name(self) -&gt; str:\n        \"\"\"Return model identifier.\"\"\"\n        pass\n\n    # gRPC method implementations\n    def Embed(self, request, context):\n        embedding = self.embed(request.text)\n        return embedder_pb2.EmbedResponse(embedding=embedding)\n\n    def Info(self, request, context):\n        return embedder_pb2.EmbedderInfo(\n            model=self.model_name(),\n            dimensions=self.dimensions()\n        )\n\ndef serve(embedder: BaseEmbedder, port: int = 50051):\n    \"\"\"Start the gRPC server for the embedder plugin.\"\"\"\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n    embedder_pb2_grpc.add_EmbedderServicer_to_server(embedder, server)\n    server.add_insecure_port(f'[::]:{port}')\n    server.start()\n    server.wait_for_termination()\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#configuration-for-multi-language-plugins","title":"Configuration for Multi-Language Plugins","text":"<pre><code># metatools.yaml\nplugins:\n  # gRPC plugin (Python embedder)\n  embedder:\n    type: grpc\n    command: \"python -m metatools_embedder\"\n    address: \"localhost:50051\"\n    health_check_interval: 10s\n    restart_on_failure: true\n\n  # WASM plugin (Rust vector index)\n  vector_index:\n    type: wasm\n    module: \"plugins/vector_index.wasm\"\n    memory_limit: 256MB\n    capabilities:\n      - filesystem:read:/data/indices\n\n  # JSON-RPC plugin (quick prototype)\n  custom_adapter:\n    type: jsonrpc\n    command: \"node plugins/adapter.js\"\n    timeout: 5s\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#research-references","title":"Research References","text":"<p>This multi-language architecture is informed by:</p> <ol> <li>HashiCorp go-plugin: Battle-tested gRPC plugin system used by Terraform, Vault, Consul, and Packer for 10+ years</li> <li>gRPC + Protocol Buffers: Industry standard for polyglot microservices, supports 10+ languages</li> <li>WebAssembly Component Model (WCM): Emerging standard for sandboxed, portable plugin systems</li> <li>WASI Preview 2: Standardized system interfaces for WASM (filesystem, network, clocks)</li> <li>Interface Definition Languages (IDL): Contract-first development enabling language-agnostic interoperability</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#summary-roadmap-at-a-glance","title":"Summary: Roadmap at a Glance","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           METATOOLS ROADMAP 2026                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                    \u2502\n\u2502  EXISTING (7 libs)        NEW CORE (2 libs)       CROSS-CUTTING (7 libs)          \u2502\n\u2502  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550      \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550       \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550          \u2502\n\u2502  \u2705 toolmodel             \ud83d\udd32 tooladapter          \ud83d\udd32 toolcache                     \u2502\n\u2502  \u2705 toolindex             \ud83d\udd32 toolset              \ud83d\udd32 toolobserve                   \u2502\n\u2502  \u2705 tooldocs                                      \ud83d\udd32 toolversion                   \u2502\n\u2502  \u2705 toolsearch            ENTERPRISE (5 libs)     \ud83d\udd32 toolresilience                \u2502\n\u2502  \u2705 toolrun               \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550     \ud83d\udd32 toolhealth                    \u2502\n\u2502  \u2705 toolcode              \ud83d\udd32 toolsemantic         \ud83d\udd32 toolaudit                     \u2502\n\u2502  \u2705 toolruntime           \ud83d\udd32 toolresource         \ud83d\udd32 toolsecrets                   \u2502\n\u2502                           \ud83d\udd32 toolgateway          \ud83d\udd32 toolflags                     \u2502\n\u2502                           \ud83d\udd32 toola2a (future)     \ud83d\udd32 toolpressure                  \u2502\n\u2502                           \ud83d\udd32 toolprompt (future)                                   \u2502\n\u2502                                                                                    \u2502\n\u2502  AGENT SKILLS (1 lib)                                                             \u2502\n\u2502  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                                             \u2502\n\u2502  \ud83d\udd32 toolskill             Skill composition, workflows, A2A advertisement         \u2502\n\u2502                                                                                    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502\n\u2502                                                                                    \u2502\n\u2502  TIMELINE                                                                         \u2502\n\u2502  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                                                        \u2502\n\u2502                                                                                    \u2502\n\u2502  Weeks 1-7   [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] MVP Core     \u2502\n\u2502  Weeks 8-14  [\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] Protocol     \u2502\n\u2502  Weeks 8-17  [\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591] Cross-Cut    \u2502\n\u2502  Weeks 12-17 [\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591] Enterprise   \u2502\n\u2502  Weeks 18-21 [\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2588\u2588\u2588\u2588] Agent Skills \u2502\n\u2502                                                                                    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502\n\u2502                                                                                    \u2502\n\u2502  MILESTONES                                                                       \u2502\n\u2502  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                                                       \u2502\n\u2502                                                                                    \u2502\n\u2502  Week 7:  MVP Release (v0.2.0) - CLI, Config, Transport, Providers               \u2502\n\u2502  Week 14: Protocol Release (v0.3.0) - Adapters, Toolsets, Multi-Transport        \u2502\n\u2502  Week 17: Enterprise Release (v1.0.0) - Full feature set                         \u2502\n\u2502  Week 21: Agent Skills Release (v1.1.0) - Skills, Workflows, A2A                 \u2502\n\u2502                                                                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#appendix-document-cross-references","title":"Appendix: Document Cross-References","text":"Document Purpose Status pluggable-architecture.md Core architecture design Active implementation-phases.md Phase details Active component-library-analysis.md Library analysis Complete architecture-evaluation.md Championship comparison Complete protocol-agnostic-tools.md Protocol layer design Active multi-tenancy.md Multi-tenant design Active ROADMAP.md (this document) Master roadmap Active"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#changelog","title":"Changelog","text":"Date Change 2026-01-28 Architecture Review: Added scope clarification table, fixed Transport interface (added Name()), updated toolskill dependencies 2026-01-28 Added Section 8: Multi-Language Extensibility - gRPC, WASM, JSON-RPC plugin architectures with SDK generation 2026-01-28 Added comprehensive D4 toolsemantic specification: hybrid search, GraphRAG, hierarchical chunking, agentic RAG, ColBERT, cross-encoder reranking 2026-01-28 Added SKILL.md Open Standard support to toolskill (Claude Code, Codex, ChatGPT compatible) 2026-01-28 Added Stream E: Agent Skills with toolskill library proposal 2026-01-28 Initial roadmap created from all proposal documents"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/","title":"Architecture Evaluation: Championship-Level Analysis","text":"<p>Status: Draft Date: 2026-01-28 Related: Pluggable Architecture Proposal, Component Library Analysis</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#executive-summary","title":"Executive Summary","text":"<p>This document evaluates the metatools ecosystem against championship-level implementations and industry best practices. The analysis reveals that your architecture is already at 85-90% of championship-level in core areas, with specific opportunities for advancement in emerging patterns.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Research Methodology</li> <li>Championship Implementations Analyzed</li> <li>Pattern Comparison Matrix</li> <li>What You Already Have (Championship Features)</li> <li>Gaps and Opportunities</li> <li>Recommended Extensions</li> <li>New Libraries to Consider</li> <li>Protocol Evolution (A2A + MCP)</li> <li>Implementation Roadmap</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#research-methodology","title":"Research Methodology","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#sources-analyzed","title":"Sources Analyzed","text":"Source Type Examples Key Insights Production Go Projects Tencent WeKnora (12.5k stars), go-kratos/blades (700 stars) Multi-tenant, agent orchestration patterns MCP Ecosystem Official Go SDK, fastmcp (22k stars), mcp-agent (8k stars) Protocol implementation patterns Industry Standards MCP Spec 2025-11-25, A2A Protocol, Google ADK Protocol interoperability Academic/Industry Research Anthropic context engineering, LangChain patterns Progressive disclosure, semantic discovery"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#key-references","title":"Key References","text":"<ul> <li>MCP Best Practices - Single-purpose servers, transport options</li> <li>Effective Context Engineering - Progressive disclosure</li> <li>A2A Protocol - Agent-to-agent communication</li> <li>Google ADK for Go - Multi-agent patterns</li> <li>Semantic Tool Discovery - Vector-based tool selection</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#championship-implementations-analyzed","title":"Championship Implementations Analyzed","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#1-tencent-weknora-12566-stars","title":"1. Tencent WeKnora (12,566 stars)","text":"<p>What it is: LLM-powered RAG framework with multi-tenant support</p> <p>Architecture Highlights: <pre><code>internal/\n\u251c\u2500\u2500 agent/          # Agent orchestration\n\u2502   \u2514\u2500\u2500 tools/      # Agent-specific tools\n\u251c\u2500\u2500 application/    # Business logic\n\u2502   \u251c\u2500\u2500 repository/ # Data access\n\u2502   \u2514\u2500\u2500 service/    # Service layer\n\u251c\u2500\u2500 handler/        # HTTP handlers\n\u251c\u2500\u2500 middleware/     # Cross-cutting concerns\n\u251c\u2500\u2500 models/         # LLM integrations\n\u2502   \u251c\u2500\u2500 chat/\n\u2502   \u251c\u2500\u2500 embedding/\n\u2502   \u2514\u2500\u2500 rerank/\n\u251c\u2500\u2500 runtime/        # Execution environment\n\u2514\u2500\u2500 types/\n    \u2514\u2500\u2500 interfaces/ # Contract definitions\n</code></pre></p> <p>Key Patterns: - Clean layered architecture (handler \u2192 service \u2192 repository) - Multi-tenant via middleware - Model provider abstraction (chat, embedding, rerank) - Event-driven architecture with adapters</p> <p>Comparison to metatools: | Feature | WeKnora | metatools | Gap | |---------|---------|-----------|-----| | Layered architecture | \u2705 | \u2705 | None | | Multi-tenant | \u2705 Built-in | \ud83d\udccb Proposed | Implement | | Embedding models | \u2705 | \u274c | Extension opportunity | | Reranking | \u2705 | \u274c | Extension opportunity |</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#2-go-kratosblades-700-stars","title":"2. go-kratos/blades (700 stars)","text":"<p>What it is: Multi-agent AI framework from the Kratos team</p> <p>Architecture Highlights: <pre><code>// Tool interface - remarkably similar to toolmodel.Tool\ntype Tool interface {\n    Name() string\n    Description() string\n    InputSchema() *jsonschema.Schema\n    OutputSchema() *jsonschema.Schema\n    Handler\n}\n\n// Middleware chain - identical pattern to your proposal\ntype Handler interface {\n    Handle(context.Context, *Invocation) Generator[*Message, error]\n}\ntype Middleware func(Handler) Handler\n\nfunc ChainMiddlewares(mws ...Middleware) Middleware {\n    return func(next Handler) Handler {\n        h := next\n        for i := len(mws) - 1; i &gt;= 0; i-- {\n            h = mws[i](h)\n        }\n        return h\n    }\n}\n</code></pre></p> <p>Key Patterns: - Generic tool creation with type inference (<code>NewFunc[I, O any]</code>) - Middleware chain (confirm, conversation, retry) - Agent-as-tool pattern (agents can be tools for other agents) - Streaming via Go iterators</p> <p>Comparison to metatools: | Feature | blades | metatools | Gap | |---------|--------|-----------|-----| | Tool interface | \u2705 | \u2705 toolmodel.Tool | None | | Middleware chain | \u2705 | \ud83d\udccb Proposed | Implement | | Generic tool creation | \u2705 | \u274c | Enhancement | | Agent-as-tool | \u2705 | \u274c | Extension | | Streaming | \u2705 Iterators | \u2705 Channels | Different approach |</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#3-official-mcp-go-sdk-modelcontextprotocolgo-sdk","title":"3. Official MCP Go SDK (modelcontextprotocol/go-sdk)","text":"<p>What it is: Reference implementation for MCP in Go</p> <p>Architecture Highlights: <pre><code>type Server struct {\n    impl    *Implementation\n    opts    ServerOptions\n    prompts *featureSet[*serverPrompt]\n    tools   *featureSet[*serverTool]\n    resources *featureSet[*serverResource]\n    sessions []*ServerSession\n    // ...\n}\n\ntype ServerOptions struct {\n    Instructions string\n    Logger *slog.Logger\n    InitializedHandler func(context.Context, *InitializedRequest)\n    PageSize int\n    KeepAlive time.Duration\n    // ...\n}\n</code></pre></p> <p>Key Patterns: - Feature sets for prompts, tools, resources - Session management - Handler-based configuration (functional options) - Built-in SSE support</p> <p>Comparison to metatools: | Feature | MCP SDK | metatools | Gap | |---------|---------|-----------|-----| | Tools registration | \u2705 | \u2705 toolindex | None | | Resources | \u2705 | \u274c | Extension | | Prompts | \u2705 | \u274c | Extension | | SSE transport | \u2705 | \ud83d\udccb Proposed | Implement | | Session management | \u2705 | \u274c | Enhancement |</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#4-fastmcp-22398-stars-python","title":"4. fastmcp (22,398 stars - Python)","text":"<p>What it is: Fastest way to build MCP servers</p> <p>Key Insight: Despite being Python, the architecture patterns are transferable: - Decorator-based tool registration - Context manager patterns for resources - Progressive tool loading for large toolsets</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#5-google-adk-for-go","title":"5. Google ADK for Go","text":"<p>What it is: Agent Development Kit with A2A support</p> <p>Key Features: - MCP integration out of the box - A2A protocol support for multi-agent systems - 30+ database connectors via MCP Toolbox - Built-in observability</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#pattern-comparison-matrix","title":"Pattern Comparison Matrix","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#core-architecture-patterns","title":"Core Architecture Patterns","text":"Pattern Industry Best metatools Status Priority Progressive Disclosure 3-tier (index/details/full) \u2705 tooldocs (summary/schema/full) Done Interface-Based Pluggability All components as interfaces \u2705 13 extension points Done Multi-Backend Per Tool Runtime backend selection \u2705 toolindex BackendSelector Done Middleware Chain Decorator pattern \ud83d\udccb Proposed High Security Profiles dev/standard/hardened \u2705 toolruntime Done Contract Testing Interface compliance tests \u2705 toolruntime Gateway tests Done"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#advanced-patterns","title":"Advanced Patterns","text":"Pattern Industry Best metatools Status Priority Semantic Tool Discovery Vector embeddings + BM25 \u26a0\ufe0f BM25 only (toolsearch) Medium A2A Protocol Agent-to-agent communication \u274c Not implemented Low MCP Resources File/data exposure to LLMs \u274c Not implemented Medium MCP Prompts Reusable prompt templates \u274c Not implemented Low Observability OpenTelemetry tracing \u274c Not implemented High Hot Reload Dynamic tool registration \u26a0\ufe0f Partial (UnregisterBackend) Medium"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#what-you-already-have-championship-features","title":"What You Already Have (Championship Features)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#1-progressive-disclosure-tooldocs","title":"1. Progressive Disclosure (tooldocs)","text":"<p>Your 3-tier documentation system matches industry best practice exactly:</p> <pre><code>// Your implementation matches Anthropic's recommendation\ntype DetailLevel string\nconst (\n    DetailLevelSummary DetailLevel = \"summary\"  // Layer 1: Metadata\n    DetailLevelSchema  DetailLevel = \"schema\"   // Layer 2: Structure\n    DetailLevelFull    DetailLevel = \"full\"     // Layer 3: Complete\n)\n</code></pre> <p>Industry validation: Anthropic's context engineering guide recommends exactly this pattern for token optimization.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#2-multi-backend-tool-registry-toolindex","title":"2. Multi-Backend Tool Registry (toolindex)","text":"<p>Your architecture supports what few frameworks do - multiple backends for the same tool:</p> <pre><code>// Tools can have MCP, Provider, AND Local backends simultaneously\ntype ToolBackend struct {\n    Kind     BackendKind      // mcp, provider, local\n    MCP      *MCPBackend\n    Provider *ProviderBackend\n    Local    *LocalBackend\n}\n\n// Runtime selection via pluggable BackendSelector\ntype BackendSelector func(tool Tool, backends []ToolBackend) ToolBackend\n</code></pre> <p>Industry validation: This matches Google ADK's multi-source pattern.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#3-10-sandbox-backends-toolruntime","title":"3. 10 Sandbox Backends (toolruntime)","text":"<p>Your runtime isolation options exceed most frameworks:</p> Backend Use Case Isolation Level unsafe Development None docker Standard production Container containerd Kubernetes environments Container kubernetes Multi-tenant production Pod + Namespace firecracker High security microVM kata Strong isolation VM gvisor Kernel isolation Sandboxed kernel wasm Portable execution Sandbox temporal Workflow orchestration Durable execution remote Distributed execution Network <p>Industry validation: No other open-source MCP framework offers this breadth.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#4-interface-based-extension-13-points","title":"4. Interface-Based Extension (13 Points)","text":"<p>Your 13 extension points match the Go best practice of interface-based composition:</p> # Interface Purpose 1 SchemaValidator JSON Schema validation 2 Searcher Tool search (BM25, semantic) 3 BackendSelector Multi-backend selection 4 Store Documentation storage 5 ToolResolver Tool resolution 6 Runner Execution orchestration 7 MCPExecutor MCP backend calls 8 ProviderExecutor Provider backend calls 9 LocalRegistry Local handler lookup 10 Backend Sandbox isolation 11 ToolGateway Sandboxed tool access 12 Logger Execution logging 13 Engine Code execution <p>Industry validation: Matches go-kratos/blades interface design philosophy.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#gaps-and-opportunities","title":"Gaps and Opportunities","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#high-priority","title":"High Priority","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#1-observability-tracing-metrics","title":"1. Observability (Tracing + Metrics)","text":"<p>Gap: No built-in OpenTelemetry integration.</p> <p>Why it matters: Production deployments need distributed tracing and metrics.</p> <p>Solution: <pre><code>// New package: toolobserve\ntype Tracer interface {\n    StartSpan(ctx context.Context, name string) (context.Context, Span)\n}\n\ntype MetricsRecorder interface {\n    RecordToolCall(toolID string, duration time.Duration, err error)\n    RecordSearchLatency(query string, duration time.Duration)\n}\n\n// Integration via middleware\nfunc TracingMiddleware(tracer Tracer) toolrun.ExecutionHook {\n    return &amp;tracingHook{tracer: tracer}\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#2-mcp-gateway-auth-analytics","title":"2. MCP Gateway (Auth + Analytics)","text":"<p>Gap: No proxy layer for authentication, rate limiting, analytics.</p> <p>Why it matters: Enterprise deployments need centralized auth and monitoring.</p> <p>Reference: hyprmcp/jetski - OAuth2.1, DCR, real-time logs</p> <p>Solution: <pre><code>// New package: toolgateway\ntype Gateway struct {\n    Auth       AuthProvider\n    RateLimit  RateLimiter\n    Analytics  AnalyticsRecorder\n    Upstream   MCPServer\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#medium-priority","title":"Medium Priority","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#3-semantic-tool-discovery","title":"3. Semantic Tool Discovery","text":"<p>Gap: Only BM25 lexical search, no vector/embedding search.</p> <p>Why it matters: With 50+ tools, semantic search dramatically improves accuracy.</p> <p>Reference: Semantic Tool Discovery</p> <p>Solution: <pre><code>// New package: toolsemantic (implements toolindex.Searcher)\ntype SemanticSearcher struct {\n    embedder   Embedder\n    vectorDB   VectorStore\n    bm25       toolsearch.BM25Searcher // Hybrid: semantic + lexical\n}\n\ntype Embedder interface {\n    Embed(ctx context.Context, text string) ([]float32, error)\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#4-mcp-resources-support","title":"4. MCP Resources Support","text":"<p>Gap: No file/data resource exposure to LLMs.</p> <p>Why it matters: MCP Resources allow LLMs to read files, databases, APIs.</p> <p>Solution: <pre><code>// New extension to toolindex or new package: toolresource\ntype Resource struct {\n    URI         string\n    Name        string\n    Description string\n    MimeType    string\n}\n\ntype ResourceProvider interface {\n    List(ctx context.Context) ([]Resource, error)\n    Read(ctx context.Context, uri string) (io.Reader, error)\n    Subscribe(ctx context.Context, uri string) (&lt;-chan ResourceUpdate, error)\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#low-priority-future","title":"Low Priority (Future)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#5-a2a-protocol-support","title":"5. A2A Protocol Support","text":"<p>Gap: No agent-to-agent communication.</p> <p>Why it matters: Multi-agent systems need standardized communication.</p> <p>Reference: A2A Protocol</p> <p>Solution: <pre><code>// New package: toola2a\ntype AgentCard struct {\n    Name         string\n    Description  string\n    Capabilities []Capability\n    Endpoint     string\n}\n\ntype A2AClient interface {\n    Discover(ctx context.Context, endpoint string) (*AgentCard, error)\n    Invoke(ctx context.Context, agent string, task *Task) (*TaskResult, error)\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#6-mcp-prompts-support","title":"6. MCP Prompts Support","text":"<p>Gap: No reusable prompt template system.</p> <p>Why it matters: Prompts are a core MCP feature for standardized interactions.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#recommended-extensions","title":"Recommended Extensions","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#new-libraries-to-consider","title":"New Libraries to Consider","text":"<p>Based on the analysis, here are potential new libraries that could enhance the ecosystem:</p> Library Purpose Priority Effort toolobserve OpenTelemetry tracing + metrics High 2 weeks toolsemantic Vector-based semantic search Medium 3 weeks toolresource MCP Resources support Medium 2 weeks toolgateway Auth, rate limit, analytics proxy Medium 3 weeks toola2a A2A protocol support Low 4 weeks toolprompt MCP Prompts support Low 1 week"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#updated-dependency-graph","title":"Updated Dependency Graph","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     EXPANDED METATOOLS ECOSYSTEM                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                               \u2502\n\u2502                           \u2502  metatools-mcp  \u2502                               \u2502\n\u2502                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                               \u2502\n\u2502                                    \u2502                                         \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2534\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502    \u2502                              \u2502 \u2502                              \u2502         \u2502\n\u2502    \u25bc                              \u25bc \u25bc                              \u25bc         \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502 \u2502toolgateway\u2502 NEW          \u2502 toolcode \u2502                    \u2502toolobserve\u2502 NEW\u2502\n\u2502 \u2502(auth/proxy)\u2502             \u2502          \u2502                    \u2502(tracing)  \u2502    \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                 \u2502                                            \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502         \u2502                       \u2502                           \u2502               \u2502\n\u2502         \u25bc                       \u25bc                           \u25bc               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502  \u2502  toolrun    \u2502         \u2502  tooldocs   \u2502            \u2502toolresource \u2502 NEW    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502(MCP Resources)\u2502       \u2502\n\u2502         \u2502                       \u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502         \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502         \u2502    \u2502                  \u2502                        \u2502                  \u2502\n\u2502         \u25bc    \u25bc                  \u25bc                        \u25bc                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502  \u2502 toolruntime \u2502         \u2502  toolindex  \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502toolsemantic \u2502 NEW       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502(vector search)\u2502          \u2502\n\u2502         \u2502                       \u2502                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502         \u2502                       \u2502                        \u25b2                  \u2502\n\u2502         \u2502                       \u25bc                        \u2502                  \u2502\n\u2502         \u2502                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  toolmodel  \u2502          \u2502 toolsearch  \u2502           \u2502\n\u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502 (BM25)      \u2502           \u2502\n\u2502                                 \u2502                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502                                 \u25bc                                           \u2502\n\u2502                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2502\n\u2502                   \u2502 modelcontextprotocol/   \u2502                              \u2502\n\u2502                   \u2502       go-sdk            \u2502                              \u2502\n\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502\n\u2502                                                                              \u2502\n\u2502    Future:  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                   \u2502\n\u2502             \u2502 toola2a  \u2502    \u2502toolprompt\u2502                                   \u2502\n\u2502             \u2502(A2A proto)\u2502   \u2502(MCP prompts)\u2502                                 \u2502\n\u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#protocol-evolution","title":"Protocol Evolution","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#mcp-a2a-complementary-protocols","title":"MCP + A2A Complementary Protocols","text":"<p>The industry is converging on two complementary protocols:</p> Protocol Purpose Direction Your Status MCP Agent-to-tool Vertical (depth) \u2705 Implemented A2A Agent-to-agent Horizontal (breadth) \u274c Future <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PROTOCOL LANDSCAPE                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u2502\n\u2502                         \u2502  User   \u2502                             \u2502\n\u2502                         \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502                              \u2502                                   \u2502\n\u2502                         \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510                             \u2502\n\u2502                         \u2502  Host   \u2502                             \u2502\n\u2502                         \u2502  Agent  \u2502                             \u2502\n\u2502                         \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502                              \u2502                                   \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502         \u2502                    \u2502                    \u2502             \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502    \u2502 Remote  \u2502\u25c4\u2500\u2500 A2A \u2500\u2500\u25b6\u2502 Remote \u2502\u25c4\u2500\u2500 A2A \u2500\u2500\u25b6\u2502 Remote \u2502       \u2502\n\u2502    \u2502 Agent 1 \u2502           \u2502 Agent 2\u2502           \u2502 Agent 3\u2502       \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518       \u2502\n\u2502         \u2502                     \u2502                    \u2502            \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510       \u2502\n\u2502    \u2502  MCP    \u2502           \u2502  MCP   \u2502           \u2502  MCP   \u2502       \u2502\n\u2502    \u2502 Server  \u2502           \u2502 Server \u2502           \u2502 Server \u2502       \u2502\n\u2502    \u2502 (tools) \u2502           \u2502 (tools)\u2502           \u2502 (tools)\u2502       \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                                                  \u2502\n\u2502    Legend: A2A = Agent-to-Agent (horizontal)                    \u2502\n\u2502            MCP = Agent-to-Tool (vertical)                       \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#scaling-recommendation-from-anthropic-nov-2025","title":"Scaling Recommendation (from Anthropic Nov 2025)","text":"<p>For 50+ tools, present MCP servers as code APIs instead of direct tool calls:</p> <p>\"This pattern becomes essential when scaling to many tools. You're essentially giving agents a programming environment rather than a function-calling interface.\"</p> <p>Your <code>toolcode</code> package already enables this pattern!</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#updated-timeline-with-extensions","title":"Updated Timeline with Extensions","text":"Phase Focus Duration Libraries Phase 1 CLI + Config 2 weeks metatools-mcp Phase 2 Transport + Observability 2 weeks metatools-mcp, toolobserve (new) Phase 3 Public APIs 1 week All existing Phase 4 Backend Integration 2 weeks toolruntime Phase 5 Semantic Search 2 weeks toolsemantic (new) Phase 6 MCP Resources 2 weeks toolresource (new) Phase 7 Gateway/Proxy 2 weeks toolgateway (new) Total 13 weeks 4 new libraries"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#mvp-phases-1-4-7-weeks","title":"MVP (Phases 1-4): 7 weeks","text":"<p>Core pluggable architecture with observability.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#extended-phases-5-7-6-weeks","title":"Extended (Phases 5-7): +6 weeks","text":"<p>Advanced features for enterprise/production deployments.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#summary-your-position","title":"Summary: Your Position","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#championship-scorecard","title":"Championship Scorecard","text":"Category Score Notes Core Architecture 95% Excellent layering, interfaces, patterns Pluggability 90% 13 extension points, multi-backend Security 95% 10 isolation backends, 3 security profiles Documentation 85% Progressive disclosure implemented Observability 40% Gap - needs OpenTelemetry Semantic Search 60% BM25 good, vectors needed Protocol Coverage 70% MCP tools, missing resources/prompts Overall 85% Championship-adjacent"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#key-takeaway","title":"Key Takeaway","text":"<p>Your architecture is not a framework to be built\u2014it's a mature ecosystem to be exposed and extended. The 7 tool* libraries represent years of thoughtful design that matches or exceeds most open-source alternatives.</p> <p>The path to championship level requires: 1. Exposure (CLI + config) - 2 weeks 2. Observability (toolobserve) - 2 weeks 3. Semantic search (toolsemantic) - 2 weeks 4. MCP completeness (toolresource) - 2 weeks</p> <p>Total to championship: ~8 weeks of focused work.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#changelog","title":"Changelog","text":"Date Change 2026-01-28 Initial comprehensive architecture evaluation 2026-01-28 Analyzed 5 championship-level implementations 2026-01-28 Identified 4 new potential libraries 2026-01-28 Created extended implementation roadmap"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/","title":"Pluggable Authentication &amp; Authorization Middleware","text":"<p>Status: Draft Date: 2026-01-30 Related: Multi-Tenancy Proposal, Pluggable Architecture</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#overview","title":"Overview","text":"<p>This document defines a 100% pluggable authentication and authorization middleware for the metatools ecosystem. The design supports multiple auth providers (JWT, OAuth2, API Keys, mTLS), integrates with RBAC/ABAC systems (Casbin, OPA), and provides the foundation for multi-tenancy.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#design-principles","title":"Design Principles","text":"<ol> <li>Interface-First - All components defined as interfaces, implementations are swappable</li> <li>Zero Coupling - Auth middleware knows nothing about specific providers</li> <li>Context Propagation - Identity flows through context.Context</li> <li>Fail-Safe Defaults - Deny by default, explicit allow required</li> <li>Composable - Multiple authenticators/authorizers can chain together</li> <li>Observable - Full audit trail of auth decisions</li> <li>Multi-Tenancy Ready - Identity includes tenant context</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         AUTH MIDDLEWARE ARCHITECTURE                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Request \u2192 [Transport Layer]                                                 \u2502\n\u2502                    \u2502                                                          \u2502\n\u2502                    \u25bc                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    AUTHENTICATION MIDDLEWARE                         \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502   \u2502              CompositeAuthenticator                           \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   (tries each authenticator until one succeeds)               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                                \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502   JWT   \u2502\u2192\u2502 OAuth2  \u2502\u2192\u2502 API Key \u2502\u2192\u2502  mTLS   \u2502            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502  Auth   \u2502 \u2502  Auth   \u2502 \u2502  Auth   \u2502 \u2502  Auth   \u2502            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                                \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   Output: Identity (principal, tenant, claims, method)        \u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                    \u2502                                                          \u2502\n\u2502                    \u25bc Identity in context.Context                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    AUTHORIZATION MIDDLEWARE                          \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502   \u2502              Authorizer (pluggable policy engine)             \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                                \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502 Casbin  \u2502 \u2502   OPA   \u2502 \u2502  RBAC   \u2502 \u2502 Custom  \u2502            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502Enforcer \u2502 \u2502 Rego    \u2502 \u2502 Simple  \u2502 \u2502 Policy  \u2502            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                                \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   Input: (subject, resource, action) \u2192 Output: allow/deny     \u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                    \u2502                                                          \u2502\n\u2502                    \u25bc Authorized request                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    TOOL PROVIDER (execution)                         \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#core-interfaces","title":"Core Interfaces","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#identity-model","title":"Identity Model","text":"<pre><code>// Identity represents an authenticated principal\ntype Identity struct {\n    // Principal is the unique identifier (user ID, service account, etc.)\n    Principal   string            `json:\"principal\"`\n\n    // TenantID for multi-tenant systems (empty for single-tenant)\n    TenantID    string            `json:\"tenant_id,omitempty\"`\n\n    // Roles assigned to this identity\n    Roles       []string          `json:\"roles,omitempty\"`\n\n    // Permissions granted (for PBAC systems)\n    Permissions []string          `json:\"permissions,omitempty\"`\n\n    // Claims from the auth token (JWT claims, OAuth2 scopes, etc.)\n    Claims      map[string]any    `json:\"claims,omitempty\"`\n\n    // Method used for authentication\n    Method      AuthMethod        `json:\"method\"`\n\n    // Metadata for extensibility\n    Metadata    map[string]string `json:\"metadata,omitempty\"`\n\n    // ExpiresAt when the identity/session expires\n    ExpiresAt   time.Time         `json:\"expires_at,omitempty\"`\n\n    // IssuedAt when the identity was established\n    IssuedAt    time.Time         `json:\"issued_at\"`\n}\n\n// AuthMethod identifies how the identity was authenticated\ntype AuthMethod string\n\nconst (\n    AuthMethodJWT       AuthMethod = \"jwt\"\n    AuthMethodOAuth2    AuthMethod = \"oauth2\"\n    AuthMethodAPIKey    AuthMethod = \"api_key\"\n    AuthMethodMTLS      AuthMethod = \"mtls\"\n    AuthMethodBasic     AuthMethod = \"basic\"\n    AuthMethodAnonymous AuthMethod = \"anonymous\"\n    AuthMethodCustom    AuthMethod = \"custom\"\n)\n\n// AuthResult encapsulates authentication outcome\ntype AuthResult struct {\n    // Authenticated indicates if authentication succeeded\n    Authenticated bool\n\n    // Identity is set when Authenticated is true\n    Identity *Identity\n\n    // Error describes why authentication failed (if applicable)\n    Error error\n\n    // Challenge is the WWW-Authenticate header value for 401 responses\n    Challenge string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#authenticator-interface","title":"Authenticator Interface","text":"<pre><code>// Authenticator validates credentials and returns an identity\n// This is the core pluggable interface for authentication\ntype Authenticator interface {\n    // Authenticate validates the request and returns an identity\n    // Returns AuthResult with Authenticated=false if credentials are invalid\n    // Returns error only for system failures (not auth failures)\n    Authenticate(ctx context.Context, req *AuthRequest) (*AuthResult, error)\n\n    // Name returns the authenticator name for logging/metrics\n    Name() string\n\n    // Supports checks if this authenticator handles the given request\n    // Used by CompositeAuthenticator to select appropriate authenticator\n    Supports(ctx context.Context, req *AuthRequest) bool\n}\n\n// AuthRequest contains request data for authentication\ntype AuthRequest struct {\n    // Headers from the incoming request\n    Headers map[string][]string\n\n    // Method is the request method (tools/call, tools/list, etc.)\n    Method string\n\n    // Resource is the target resource (tool name, etc.)\n    Resource string\n\n    // RemoteAddr is the client IP address\n    RemoteAddr string\n\n    // TLSInfo contains mTLS certificate info (if available)\n    TLSInfo *TLSInfo\n\n    // Raw allows access to transport-specific request data\n    Raw any\n}\n\n// TLSInfo contains client certificate information for mTLS\ntype TLSInfo struct {\n    // PeerCertificates from the TLS connection\n    PeerCertificates []*x509.Certificate\n\n    // Verified indicates if the certificate chain was verified\n    Verified bool\n\n    // CommonName from the client certificate\n    CommonName string\n\n    // DNSNames from the client certificate\n    DNSNames []string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#authorizer-interface","title":"Authorizer Interface","text":"<pre><code>// Authorizer makes access control decisions\n// Implementations can use RBAC, ABAC, ReBAC, or custom logic\ntype Authorizer interface {\n    // Authorize checks if the identity can perform action on resource\n    // Returns nil if authorized, error describing denial otherwise\n    Authorize(ctx context.Context, req *AuthzRequest) error\n\n    // Name returns the authorizer name for logging/metrics\n    Name() string\n}\n\n// AuthzRequest contains the authorization request parameters\ntype AuthzRequest struct {\n    // Subject is the identity requesting access\n    Subject *Identity\n\n    // Resource is what's being accessed (tool name, backend, etc.)\n    Resource string\n\n    // Action is what's being done (call, list, describe, etc.)\n    Action string\n\n    // ResourceType categorizes the resource (tool, backend, config, etc.)\n    ResourceType string\n\n    // Context provides additional attributes for ABAC\n    Context map[string]any\n}\n\n// AuthzResult provides detailed authorization outcome\ntype AuthzResult struct {\n    Allowed bool\n    Reason  string\n    Policy  string // Which policy made the decision\n}\n\n// Common authorization errors\nvar (\n    ErrUnauthorized     = errors.New(\"unauthorized\")\n    ErrForbidden        = errors.New(\"forbidden\")\n    ErrInsufficientRole = errors.New(\"insufficient role\")\n    ErrInvalidToken     = errors.New(\"invalid token\")\n    ErrTokenExpired     = errors.New(\"token expired\")\n    ErrMissingClaims    = errors.New(\"missing required claims\")\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#built-in-authenticators","title":"Built-in Authenticators","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#jwt-authenticator","title":"JWT Authenticator","text":"<pre><code>// JWTAuthenticator validates JWT tokens\ntype JWTAuthenticator struct {\n    // Config holds JWT validation settings\n    Config JWTConfig\n\n    // KeyProvider fetches signing keys (supports JWKS, static, etc.)\n    KeyProvider KeyProvider\n\n    // ClaimsMapper extracts identity from JWT claims\n    ClaimsMapper ClaimsMapper\n}\n\n// JWTConfig configures JWT validation\ntype JWTConfig struct {\n    // Issuer expected in the token (validates iss claim)\n    Issuer string `yaml:\"issuer\"`\n\n    // Audience expected in the token (validates aud claim)\n    Audience string `yaml:\"audience\"`\n\n    // HeaderName where to find the token (default: Authorization)\n    HeaderName string `yaml:\"header_name\"`\n\n    // TokenPrefix expected before the token (default: Bearer)\n    TokenPrefix string `yaml:\"token_prefix\"`\n\n    // ClockSkew tolerance for expiration validation\n    ClockSkew time.Duration `yaml:\"clock_skew\"`\n\n    // RequiredClaims that must be present\n    RequiredClaims []string `yaml:\"required_claims\"`\n\n    // PrincipalClaim identifies the subject (default: sub)\n    PrincipalClaim string `yaml:\"principal_claim\"`\n\n    // TenantClaim identifies the tenant (optional)\n    TenantClaim string `yaml:\"tenant_claim\"`\n\n    // RolesClaim identifies roles (optional)\n    RolesClaim string `yaml:\"roles_claim\"`\n\n    // PermissionsClaim identifies permissions (optional)\n    PermissionsClaim string `yaml:\"permissions_claim\"`\n}\n\n// KeyProvider fetches signing keys for JWT validation\ntype KeyProvider interface {\n    // GetKey returns the key for the given key ID\n    GetKey(ctx context.Context, keyID string) (any, error)\n\n    // GetKeys returns all available keys\n    GetKeys(ctx context.Context) ([]any, error)\n}\n\n// Built-in KeyProvider implementations\ntype StaticKeyProvider struct { ... }  // Single static key\ntype JWKSKeyProvider struct { ... }    // JWKS endpoint with caching\ntype FileKeyProvider struct { ... }    // Keys from filesystem\n\n// ClaimsMapper extracts Identity from JWT claims\ntype ClaimsMapper interface {\n    MapClaims(claims jwt.MapClaims) (*Identity, error)\n}\n\n// DefaultClaimsMapper uses JWTConfig to map claims\ntype DefaultClaimsMapper struct {\n    Config JWTConfig\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#api-key-authenticator","title":"API Key Authenticator","text":"<pre><code>// APIKeyAuthenticator validates API keys\ntype APIKeyAuthenticator struct {\n    Config   APIKeyConfig\n    Store    APIKeyStore\n}\n\n// APIKeyConfig configures API key validation\ntype APIKeyConfig struct {\n    // HeaderName where to find the key (default: X-API-Key)\n    HeaderName string `yaml:\"header_name\"`\n\n    // QueryParam alternative location (optional)\n    QueryParam string `yaml:\"query_param\"`\n\n    // Prefix expected before the key (optional, e.g., \"Bearer \")\n    Prefix string `yaml:\"prefix\"`\n\n    // HashAlgorithm for stored keys (none, sha256, bcrypt)\n    HashAlgorithm string `yaml:\"hash_algorithm\"`\n}\n\n// APIKeyStore retrieves API key information\ntype APIKeyStore interface {\n    // Lookup returns the identity for an API key\n    // Returns nil, nil if key not found (not an error)\n    Lookup(ctx context.Context, key string) (*APIKeyInfo, error)\n\n    // Validate checks if a key is valid without full lookup\n    Validate(ctx context.Context, key string) (bool, error)\n}\n\n// APIKeyInfo contains API key metadata\ntype APIKeyInfo struct {\n    ID          string            // Key identifier\n    Name        string            // Human-readable name\n    Principal   string            // Owner identity\n    TenantID    string            // Associated tenant\n    Roles       []string          // Assigned roles\n    Permissions []string          // Direct permissions\n    Scopes      []string          // OAuth-style scopes\n    Metadata    map[string]string // Custom metadata\n    CreatedAt   time.Time\n    ExpiresAt   *time.Time        // nil = never expires\n    LastUsedAt  *time.Time\n}\n\n// Built-in APIKeyStore implementations\ntype MemoryAPIKeyStore struct { ... }     // For testing\ntype RedisAPIKeyStore struct { ... }      // For distributed deployments\ntype PostgresAPIKeyStore struct { ... }   // For persistent storage\ntype ConfigFileAPIKeyStore struct { ... } // For static configuration\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#oauth2-authenticator","title":"OAuth2 Authenticator","text":"<pre><code>// OAuth2Authenticator validates OAuth2 access tokens\ntype OAuth2Authenticator struct {\n    Config       OAuth2Config\n    TokenStore   TokenStore       // For opaque tokens\n    Introspector TokenIntrospector // For introspection\n}\n\n// OAuth2Config configures OAuth2 validation\ntype OAuth2Config struct {\n    // Issuer URL of the OAuth2 authorization server\n    Issuer string `yaml:\"issuer\"`\n\n    // IntrospectionURL for opaque token validation\n    IntrospectionURL string `yaml:\"introspection_url\"`\n\n    // ClientID for introspection authentication\n    ClientID string `yaml:\"client_id\"`\n\n    // ClientSecret for introspection authentication\n    ClientSecret string `yaml:\"client_secret\"`\n\n    // RequiredScopes that must be present\n    RequiredScopes []string `yaml:\"required_scopes\"`\n\n    // ScopesClaim where scopes are found in JWT tokens\n    ScopesClaim string `yaml:\"scopes_claim\"`\n}\n\n// TokenIntrospector validates tokens via introspection endpoint\ntype TokenIntrospector interface {\n    Introspect(ctx context.Context, token string) (*IntrospectionResult, error)\n}\n\n// IntrospectionResult from RFC 7662\ntype IntrospectionResult struct {\n    Active    bool\n    Scope     string\n    ClientID  string\n    Username  string\n    TokenType string\n    Exp       int64\n    Iat       int64\n    Nbf       int64\n    Sub       string\n    Aud       string\n    Iss       string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#mtls-authenticator","title":"mTLS Authenticator","text":"<pre><code>// MTLSAuthenticator validates client certificates\ntype MTLSAuthenticator struct {\n    Config      MTLSConfig\n    CertMapper  CertificateMapper\n}\n\n// MTLSConfig configures mTLS validation\ntype MTLSConfig struct {\n    // RequireClientCert enforces client certificate requirement\n    RequireClientCert bool `yaml:\"require_client_cert\"`\n\n    // TrustAnchors are CA certificates to trust\n    TrustAnchors string `yaml:\"trust_anchors\"` // Path to CA bundle\n\n    // AllowedCNs restricts accepted Common Names (optional)\n    AllowedCNs []string `yaml:\"allowed_cns\"`\n\n    // AllowedDNSNames restricts accepted DNS SANs (optional)\n    AllowedDNSNames []string `yaml:\"allowed_dns_names\"`\n\n    // AllowedOUs restricts accepted Organizational Units (optional)\n    AllowedOUs []string `yaml:\"allowed_ous\"`\n\n    // CRLFile for certificate revocation checking (optional)\n    CRLFile string `yaml:\"crl_file\"`\n\n    // OCSPResponder URL for online revocation checking (optional)\n    OCSPResponder string `yaml:\"ocsp_responder\"`\n}\n\n// CertificateMapper extracts identity from client certificate\ntype CertificateMapper interface {\n    MapCertificate(cert *x509.Certificate) (*Identity, error)\n}\n\n// DefaultCertMapper uses CN as principal, OU as tenant\ntype DefaultCertMapper struct { ... }\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#composite-authenticator","title":"Composite Authenticator","text":"<pre><code>// CompositeAuthenticator tries multiple authenticators in order\ntype CompositeAuthenticator struct {\n    Authenticators []Authenticator\n\n    // RequireAll requires all authenticators to succeed (MFA)\n    RequireAll bool\n\n    // StopOnFirst stops after first successful auth\n    StopOnFirst bool\n}\n\nfunc (c *CompositeAuthenticator) Authenticate(ctx context.Context, req *AuthRequest) (*AuthResult, error) {\n    var lastResult *AuthResult\n    var lastError error\n\n    for _, auth := range c.Authenticators {\n        // Skip authenticators that don't support this request\n        if !auth.Supports(ctx, req) {\n            continue\n        }\n\n        result, err := auth.Authenticate(ctx, req)\n        if err != nil {\n            lastError = err\n            continue\n        }\n\n        if result.Authenticated {\n            if c.StopOnFirst {\n                return result, nil\n            }\n            // For RequireAll, continue checking others\n            lastResult = result\n        } else {\n            if c.RequireAll {\n                return result, nil // Any failure = overall failure\n            }\n            lastResult = result\n        }\n    }\n\n    if lastResult != nil &amp;&amp; lastResult.Authenticated {\n        return lastResult, nil\n    }\n\n    if lastResult != nil {\n        return lastResult, nil\n    }\n\n    return &amp;AuthResult{\n        Authenticated: false,\n        Challenge:     \"Bearer\",\n        Error:         errors.Join(ErrUnauthorized, lastError),\n    }, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#built-in-authorizers","title":"Built-in Authorizers","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#casbin-authorizer","title":"Casbin Authorizer","text":"<pre><code>// CasbinAuthorizer uses Casbin for RBAC/ABAC/ReBAC\ntype CasbinAuthorizer struct {\n    Enforcer *casbin.Enforcer\n    Config   CasbinConfig\n}\n\n// CasbinConfig configures the Casbin enforcer\ntype CasbinConfig struct {\n    // ModelPath is the path to the Casbin model file\n    ModelPath string `yaml:\"model_path\"`\n\n    // PolicyPath is the path to the policy file (for file adapter)\n    PolicyPath string `yaml:\"policy_path\"`\n\n    // Adapter configures policy storage\n    Adapter CasbinAdapterConfig `yaml:\"adapter\"`\n\n    // AutoLoad enables automatic policy reloading\n    AutoLoad bool `yaml:\"auto_load\"`\n\n    // AutoLoadInterval for policy refresh\n    AutoLoadInterval time.Duration `yaml:\"auto_load_interval\"`\n}\n\n// CasbinAdapterConfig configures policy storage\ntype CasbinAdapterConfig struct {\n    Type   string         `yaml:\"type\"` // file, postgres, mysql, redis\n    Config map[string]any `yaml:\"config\"`\n}\n\nfunc (a *CasbinAuthorizer) Authorize(ctx context.Context, req *AuthzRequest) error {\n    // Map to Casbin's (sub, obj, act) model\n    sub := req.Subject.Principal\n    obj := req.Resource\n    act := req.Action\n\n    // For multi-tenant, use domain\n    var ok bool\n    var err error\n\n    if req.Subject.TenantID != \"\" {\n        // RBAC with domains\n        ok, err = a.Enforcer.Enforce(sub, req.Subject.TenantID, obj, act)\n    } else {\n        ok, err = a.Enforcer.Enforce(sub, obj, act)\n    }\n\n    if err != nil {\n        return fmt.Errorf(\"casbin enforce: %w\", err)\n    }\n\n    if !ok {\n        return &amp;AuthzError{\n            Subject:  sub,\n            Resource: obj,\n            Action:   act,\n            Reason:   \"policy denied\",\n        }\n    }\n\n    return nil\n}\n\n// Example Casbin model for metatools (RBAC with domains)\n// model.conf:\n// [request_definition]\n// r = sub, dom, obj, act\n//\n// [policy_definition]\n// p = sub, dom, obj, act\n//\n// [role_definition]\n// g = _, _, _\n//\n// [policy_effect]\n// e = some(where (p.eft == allow))\n//\n// [matchers]\n// m = g(r.sub, p.sub, r.dom) &amp;&amp; r.dom == p.dom &amp;&amp; r.obj == p.obj &amp;&amp; r.act == p.act\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#opa-authorizer","title":"OPA Authorizer","text":"<pre><code>// OPAAuthorizer uses Open Policy Agent for authorization\ntype OPAAuthorizer struct {\n    Config OPAConfig\n    Client *opa.Rego\n}\n\n// OPAConfig configures OPA\ntype OPAConfig struct {\n    // PolicyPath is the path to Rego policy files\n    PolicyPath string `yaml:\"policy_path\"`\n\n    // BundleURL for fetching policy bundles\n    BundleURL string `yaml:\"bundle_url\"`\n\n    // Query is the Rego query to evaluate\n    Query string `yaml:\"query\"`\n\n    // DecisionPath in the policy output\n    DecisionPath string `yaml:\"decision_path\"`\n}\n\nfunc (a *OPAAuthorizer) Authorize(ctx context.Context, req *AuthzRequest) error {\n    input := map[string]any{\n        \"subject\": map[string]any{\n            \"principal\":   req.Subject.Principal,\n            \"tenant_id\":   req.Subject.TenantID,\n            \"roles\":       req.Subject.Roles,\n            \"permissions\": req.Subject.Permissions,\n        },\n        \"resource\":      req.Resource,\n        \"action\":        req.Action,\n        \"resource_type\": req.ResourceType,\n        \"context\":       req.Context,\n    }\n\n    results, err := a.Client.Eval(ctx, rego.EvalInput(input))\n    if err != nil {\n        return fmt.Errorf(\"opa eval: %w\", err)\n    }\n\n    if len(results) == 0 || !results[0].Expressions[0].Value.(bool) {\n        return &amp;AuthzError{\n            Subject:  req.Subject.Principal,\n            Resource: req.Resource,\n            Action:   req.Action,\n            Reason:   \"opa policy denied\",\n        }\n    }\n\n    return nil\n}\n\n// Example OPA policy for metatools:\n// package metatools.authz\n//\n// default allow = false\n//\n// allow {\n//     input.subject.roles[_] == \"admin\"\n// }\n//\n// allow {\n//     input.action == \"tools/list\"\n// }\n//\n// allow {\n//     input.action == \"tools/call\"\n//     input.resource == input.subject.permissions[_]\n// }\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#simple-rbac-authorizer","title":"Simple RBAC Authorizer","text":"<pre><code>// SimpleRBACAuthorizer provides basic RBAC without external dependencies\ntype SimpleRBACAuthorizer struct {\n    Config SimpleRBACConfig\n}\n\n// SimpleRBACConfig defines roles and permissions\ntype SimpleRBACConfig struct {\n    // Roles maps role names to permissions\n    Roles map[string]RoleConfig `yaml:\"roles\"`\n\n    // DefaultRole for unauthenticated or unassigned users\n    DefaultRole string `yaml:\"default_role\"`\n}\n\n// RoleConfig defines a role's permissions\ntype RoleConfig struct {\n    // Permissions granted to this role\n    Permissions []string `yaml:\"permissions\"`\n\n    // Inherits from other roles\n    Inherits []string `yaml:\"inherits\"`\n\n    // AllowedTools (tool name patterns)\n    AllowedTools []string `yaml:\"allowed_tools\"`\n\n    // DeniedTools (takes precedence)\n    DeniedTools []string `yaml:\"denied_tools\"`\n\n    // AllowedActions (call, list, describe, etc.)\n    AllowedActions []string `yaml:\"allowed_actions\"`\n}\n\nfunc (a *SimpleRBACAuthorizer) Authorize(ctx context.Context, req *AuthzRequest) error {\n    permissions := a.resolvePermissions(req.Subject)\n\n    // Build permission key\n    permKey := fmt.Sprintf(\"%s:%s\", req.ResourceType, req.Action)\n    toolKey := fmt.Sprintf(\"tool:%s\", req.Resource)\n\n    // Check explicit permission\n    if slices.Contains(permissions, permKey) || slices.Contains(permissions, \"*\") {\n        return nil\n    }\n\n    // Check tool-specific permission\n    if slices.Contains(permissions, toolKey) {\n        return nil\n    }\n\n    return &amp;AuthzError{\n        Subject:  req.Subject.Principal,\n        Resource: req.Resource,\n        Action:   req.Action,\n        Reason:   \"insufficient permissions\",\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#middleware-integration","title":"Middleware Integration","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#authentication-middleware","title":"Authentication Middleware","text":"<pre><code>// AuthMiddleware wraps a ToolProvider with authentication\nfunc AuthMiddleware(auth Authenticator, opts ...AuthMiddlewareOption) Middleware {\n    cfg := defaultAuthMiddlewareConfig()\n    for _, opt := range opts {\n        opt(&amp;cfg)\n    }\n\n    return func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;authMiddleware{\n            auth:   auth,\n            next:   next,\n            config: cfg,\n        }\n    }\n}\n\ntype authMiddleware struct {\n    auth   Authenticator\n    next   provider.ToolProvider\n    config authMiddlewareConfig\n}\n\ntype authMiddlewareConfig struct {\n    // AllowAnonymous allows requests without credentials\n    AllowAnonymous bool\n\n    // AnonymousIdentity used when AllowAnonymous is true\n    AnonymousIdentity *Identity\n\n    // SkipPaths that don't require authentication\n    SkipPaths []string\n\n    // OnAuthFailure callback for custom error handling\n    OnAuthFailure func(ctx context.Context, err error) error\n}\n\nfunc (m *authMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    // Build auth request from context\n    req := buildAuthRequest(ctx)\n\n    // Authenticate\n    result, err := m.auth.Authenticate(ctx, req)\n    if err != nil {\n        return nil, fmt.Errorf(\"authentication error: %w\", err)\n    }\n\n    if !result.Authenticated {\n        if m.config.AllowAnonymous {\n            ctx = WithIdentity(ctx, m.config.AnonymousIdentity)\n        } else {\n            if m.config.OnAuthFailure != nil {\n                return nil, m.config.OnAuthFailure(ctx, result.Error)\n            }\n            return nil, &amp;AuthError{\n                Code:      \"UNAUTHENTICATED\",\n                Message:   \"authentication required\",\n                Challenge: result.Challenge,\n            }\n        }\n    } else {\n        ctx = WithIdentity(ctx, result.Identity)\n    }\n\n    return m.next.Handle(ctx, input)\n}\n\n// Context helpers\nfunc WithIdentity(ctx context.Context, id *Identity) context.Context {\n    return context.WithValue(ctx, identityKey{}, id)\n}\n\nfunc IdentityFromContext(ctx context.Context) *Identity {\n    if v := ctx.Value(identityKey{}); v != nil {\n        return v.(*Identity)\n    }\n    return nil\n}\n\nfunc PrincipalFromContext(ctx context.Context) string {\n    if id := IdentityFromContext(ctx); id != nil {\n        return id.Principal\n    }\n    return \"\"\n}\n\nfunc TenantIDFromContext(ctx context.Context) string {\n    if id := IdentityFromContext(ctx); id != nil {\n        return id.TenantID\n    }\n    return \"\"\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#authorization-middleware","title":"Authorization Middleware","text":"<pre><code>// AuthzMiddleware wraps a ToolProvider with authorization\nfunc AuthzMiddleware(authz Authorizer, opts ...AuthzMiddlewareOption) Middleware {\n    cfg := defaultAuthzMiddlewareConfig()\n    for _, opt := range opts {\n        opt(&amp;cfg)\n    }\n\n    return func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;authzMiddleware{\n            authz:  authz,\n            next:   next,\n            config: cfg,\n        }\n    }\n}\n\ntype authzMiddleware struct {\n    authz  Authorizer\n    next   provider.ToolProvider\n    config authzMiddlewareConfig\n}\n\ntype authzMiddlewareConfig struct {\n    // ResourceResolver extracts resource from the request\n    ResourceResolver func(ctx context.Context, input map[string]any) string\n\n    // ActionResolver extracts action from the request\n    ActionResolver func(ctx context.Context, input map[string]any) string\n\n    // ContextBuilder adds context for ABAC decisions\n    ContextBuilder func(ctx context.Context, input map[string]any) map[string]any\n\n    // OnDenied callback for custom denial handling\n    OnDenied func(ctx context.Context, err error) error\n}\n\nfunc (m *authzMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    identity := IdentityFromContext(ctx)\n    if identity == nil {\n        return nil, &amp;AuthError{Code: \"UNAUTHENTICATED\", Message: \"no identity in context\"}\n    }\n\n    req := &amp;AuthzRequest{\n        Subject:      identity,\n        Resource:     m.config.ResourceResolver(ctx, input),\n        Action:       m.config.ActionResolver(ctx, input),\n        ResourceType: \"tool\",\n        Context:      m.config.ContextBuilder(ctx, input),\n    }\n\n    if err := m.authz.Authorize(ctx, req); err != nil {\n        if m.config.OnDenied != nil {\n            return nil, m.config.OnDenied(ctx, err)\n        }\n        return nil, &amp;AuthError{\n            Code:    \"FORBIDDEN\",\n            Message: err.Error(),\n        }\n    }\n\n    return m.next.Handle(ctx, input)\n}\n\nfunc (m *authzMiddleware) Name() string { return m.next.Name() }\nfunc (m *authzMiddleware) Description() string { return m.next.Description() }\nfunc (m *authzMiddleware) InputSchema() map[string]any { return m.next.InputSchema() }\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#factory-registration","title":"Factory Registration","text":"<pre><code>// Register auth middleware factories\nfunc init() {\n    // Authentication middleware\n    middleware.DefaultRegistry.Register(\"auth\", func(cfg map[string]any) (middleware.Middleware, error) {\n        authCfg, err := parseAuthConfig(cfg)\n        if err != nil {\n            return nil, err\n        }\n\n        auth, err := buildAuthenticator(authCfg)\n        if err != nil {\n            return nil, err\n        }\n\n        return AuthMiddleware(auth), nil\n    })\n\n    // Authorization middleware\n    middleware.DefaultRegistry.Register(\"authz\", func(cfg map[string]any) (middleware.Middleware, error) {\n        authzCfg, err := parseAuthzConfig(cfg)\n        if err != nil {\n            return nil, err\n        }\n\n        authz, err := buildAuthorizer(authzCfg)\n        if err != nil {\n            return nil, err\n        }\n\n        return AuthzMiddleware(authz), nil\n    })\n\n    // Combined auth+authz middleware\n    middleware.DefaultRegistry.Register(\"secure\", func(cfg map[string]any) (middleware.Middleware, error) {\n        auth, err := buildAuthenticator(cfg)\n        if err != nil {\n            return nil, err\n        }\n\n        authz, err := buildAuthorizer(cfg)\n        if err != nil {\n            return nil, err\n        }\n\n        return func(next provider.ToolProvider) provider.ToolProvider {\n            return AuthMiddleware(auth)(AuthzMiddleware(authz)(next))\n        }, nil\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#configuration","title":"Configuration","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#yaml-configuration","title":"YAML Configuration","text":"<pre><code># metatools.yaml - Authentication &amp; Authorization\n\nauth:\n  # Authentication configuration\n  authentication:\n    # Type: jwt, oauth2, api_key, mtls, composite\n    type: composite\n\n    # Composite authenticator configuration\n    composite:\n      stop_on_first: true\n      authenticators:\n        # JWT authentication (primary)\n        - type: jwt\n          issuer: https://auth.example.com\n          audience: metatools-api\n          jwks_url: https://auth.example.com/.well-known/jwks.json\n          principal_claim: sub\n          tenant_claim: org_id\n          roles_claim: roles\n          clock_skew: 5m\n\n        # API Key authentication (secondary)\n        - type: api_key\n          header_name: X-API-Key\n          store:\n            type: redis\n            config:\n              address: localhost:6379\n              prefix: \"apikey:\"\n\n        # mTLS (for service-to-service)\n        - type: mtls\n          require_client_cert: false  # Optional\n          trust_anchors: /etc/ssl/ca-bundle.crt\n          allowed_cns:\n            - \"*.internal.example.com\"\n\n  # Authorization configuration\n  authorization:\n    # Type: casbin, opa, simple_rbac, custom\n    type: casbin\n\n    casbin:\n      model_path: /etc/metatools/rbac_model.conf\n      adapter:\n        type: postgres\n        config:\n          connection_string: ${DATABASE_URL}\n      auto_load: true\n      auto_load_interval: 30s\n\n    # Alternative: Simple RBAC (no external dependencies)\n    # simple_rbac:\n    #   default_role: anonymous\n    #   roles:\n    #     admin:\n    #       permissions: [\"*\"]\n    #     user:\n    #       allowed_actions: [call, list, describe]\n    #       allowed_tools: [\"search_*\", \"describe_*\"]\n    #       denied_tools: [\"execute_code\"]\n    #     anonymous:\n    #       allowed_actions: [list]\n\n    # Alternative: OPA\n    # opa:\n    #   policy_path: /etc/metatools/policies\n    #   query: data.metatools.authz.allow\n\n  # Middleware options\n  middleware:\n    allow_anonymous: false\n    skip_paths:\n      - health\n      - version\n\n# Middleware chain includes auth\nmiddleware:\n  chain:\n    - auth         # Authentication (resolves identity)\n    - tenant       # Tenant resolution (from identity)\n    - authz        # Authorization (checks permissions)\n    - rate_limit   # Rate limiting (per-tenant)\n    - logging\n    - metrics\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#casbin-model-example","title":"Casbin Model Example","text":"<pre><code># rbac_with_domains_model.conf\n# For multi-tenant RBAC\n\n[request_definition]\nr = sub, dom, obj, act\n\n[policy_definition]\np = sub, dom, obj, act\n\n[role_definition]\ng = _, _, _\n\n[policy_effect]\ne = some(where (p.eft == allow))\n\n[matchers]\nm = g(r.sub, p.sub, r.dom) &amp;&amp; r.dom == p.dom &amp;&amp; keyMatch2(r.obj, p.obj) &amp;&amp; r.act == p.act\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#casbin-policy-example","title":"Casbin Policy Example","text":"<pre><code># policy.csv\n# Format: p, subject, domain(tenant), object(tool), action\n\n# Admin role has full access in all tenants\np, role:admin, *, *, *\n\n# Users can list and describe tools\np, role:user, *, *, list\np, role:user, *, *, describe\n\n# Users can call specific tools\np, role:user, *, search_*, call\np, role:user, *, describe_*, call\n\n# Enterprise tenants can execute code\np, role:user, tenant:enterprise-*, execute_code, call\n\n# Role assignments\ng, alice, role:admin, tenant:acme-corp\ng, bob, role:user, tenant:acme-corp\ng, service-account, role:admin, *\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#cli-integration","title":"CLI Integration","text":"<pre><code># Serve with authentication enabled\nmetatools serve --auth.type=jwt --auth.jwt.issuer=https://auth.example.com\n\n# Generate API key\nmetatools auth create-key --name=\"my-api-key\" --tenant=\"acme-corp\" --roles=user\n\n# Validate token\nmetatools auth validate-token --token=\"eyJ...\"\n\n# List API keys\nmetatools auth list-keys --tenant=\"acme-corp\"\n\n# Revoke API key\nmetatools auth revoke-key --id=\"key_abc123\"\n\n# Test authorization\nmetatools auth test --principal=\"alice\" --tenant=\"acme-corp\" --resource=\"execute_code\" --action=\"call\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#implementation-priority","title":"Implementation Priority","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#phase-1-core-interfaces-1-week","title":"Phase 1: Core Interfaces (1 week)","text":"<ol> <li>Define <code>Identity</code>, <code>AuthResult</code>, <code>AuthRequest</code>, <code>AuthzRequest</code> types</li> <li>Define <code>Authenticator</code>, <code>Authorizer</code> interfaces</li> <li>Implement context helpers (<code>WithIdentity</code>, <code>IdentityFromContext</code>, etc.)</li> <li>Implement <code>AuthMiddleware</code> and <code>AuthzMiddleware</code></li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#phase-2-jwt-api-key-authenticators-1-week","title":"Phase 2: JWT &amp; API Key Authenticators (1 week)","text":"<ol> <li>Implement <code>JWTAuthenticator</code> with JWKS support</li> <li>Implement <code>APIKeyAuthenticator</code> with pluggable stores</li> <li>Implement <code>CompositeAuthenticator</code></li> <li>Add factory registration</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#phase-3-rbac-authorizers-1-week","title":"Phase 3: RBAC Authorizers (1 week)","text":"<ol> <li>Implement <code>SimpleRBACAuthorizer</code> (no dependencies)</li> <li>Implement <code>CasbinAuthorizer</code> (optional dependency)</li> <li>Add configuration parsing and validation</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#phase-4-advanced-features-1-week","title":"Phase 4: Advanced Features (1 week)","text":"<ol> <li>Implement <code>OAuth2Authenticator</code> with token introspection</li> <li>Implement <code>MTLSAuthenticator</code></li> <li>Implement <code>OPAAuthorizer</code> (optional dependency)</li> <li>Add CLI commands for key management</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#testing-strategy","title":"Testing Strategy","text":"<pre><code>// Mock authenticator for testing\ntype MockAuthenticator struct {\n    AuthenticateFunc func(ctx context.Context, req *AuthRequest) (*AuthResult, error)\n    SupportsFunc     func(ctx context.Context, req *AuthRequest) bool\n}\n\n// Test helper\nfunc TestIdentity(principal, tenant string, roles ...string) *Identity {\n    return &amp;Identity{\n        Principal: principal,\n        TenantID:  tenant,\n        Roles:     roles,\n        Method:    AuthMethodJWT,\n        IssuedAt:  time.Now(),\n    }\n}\n\n// Example test\nfunc TestAuthMiddleware_ValidJWT(t *testing.T) {\n    auth := &amp;MockAuthenticator{\n        AuthenticateFunc: func(ctx context.Context, req *AuthRequest) (*AuthResult, error) {\n            return &amp;AuthResult{\n                Authenticated: true,\n                Identity:      TestIdentity(\"alice\", \"acme-corp\", \"user\"),\n            }, nil\n        },\n        SupportsFunc: func(ctx context.Context, req *AuthRequest) bool {\n            return true\n        },\n    }\n\n    mw := AuthMiddleware(auth)\n    wrapped := mw(mockProvider{})\n\n    result, err := wrapped.Handle(context.Background(), nil)\n    require.NoError(t, err)\n    // ... assertions\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#summary","title":"Summary","text":"<p>This design provides:</p> <ol> <li>100% Pluggable Authentication - Any credential type via <code>Authenticator</code> interface</li> <li>100% Pluggable Authorization - Any policy engine via <code>Authorizer</code> interface</li> <li>Multi-Provider Support - JWT, OAuth2, API Keys, mTLS all swappable</li> <li>RBAC/ABAC/ReBAC - Casbin, OPA, or simple built-in RBAC</li> <li>Multi-Tenancy Foundation - Identity includes tenant context</li> <li>Zero Coupling - Middleware knows nothing about specific implementations</li> <li>Configuration-Driven - Full YAML configuration support</li> <li>Observable - Audit logging and metrics built-in</li> </ol> <p>All components follow the existing middleware chain architecture and can be replaced or extended without code changes.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#changelog","title":"Changelog","text":"Date Change 2026-01-30 Initial auth middleware proposal based on research"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/","title":"Component Library Analysis for Pluggable Architecture","text":"<p>Status: Draft Date: 2026-01-27 Related: Pluggable Architecture Proposal, Implementation Phases</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#overview","title":"Overview","text":"<p>This document analyzes the metatools component library ecosystem and identifies changes needed to support the pluggable architecture. The analysis follows Go Architect principles: layered architecture, clean interfaces, dependency injection, and proper error handling.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#component-library-ecosystem","title":"Component Library Ecosystem","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#dependency-graph","title":"Dependency Graph","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         METATOOLS COMPONENT ECOSYSTEM                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                \u2502\n\u2502                           \u2502  metatools-mcp  \u2502                                \u2502\n\u2502                           \u2502    (v0.1.x)     \u2502                                \u2502\n\u2502                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                \u2502\n\u2502                                    \u2502                                          \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502         \u2502                          \u2502                          \u2502              \u2502\n\u2502         \u25bc                          \u25bc                          \u25bc              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502  \u2502  toolcode   \u2502           \u2502  tooldocs   \u2502           \u2502  toolrun    \u2502        \u2502\n\u2502  \u2502  (v0.1.10)  \u2502           \u2502  (v0.1.10)  \u2502           \u2502  (v0.1.9)   \u2502        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502         \u2502                         \u2502                         \u2502                \u2502\n\u2502         \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2502         \u2502    \u2502                    \u2502                                          \u2502\n\u2502         \u25bc    \u25bc                    \u25bc                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502  \u2502 toolruntime \u2502           \u2502  toolindex  \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502  \u2502  (v0.1.10)  \u2502           \u2502  (v0.1.8)   \u2502                          \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502         \u2502                         \u2502                          \u2502 toolsearch \u2502 \u2502\n\u2502         \u2502                         \u2502                          \u2502  (v0.1.9)  \u2502 \u2502\n\u2502         \u2502                         \u25bc                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502         \u2502                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  toolmodel  \u2502                                  \u2502\n\u2502                            \u2502  (v0.1.2)   \u2502                                  \u2502\n\u2502                            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                  \u2502\n\u2502                                   \u2502                                          \u2502\n\u2502                                   \u25bc                                          \u2502\n\u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u2502\n\u2502                     \u2502 modelcontextprotocol/   \u2502                             \u2502\n\u2502                     \u2502       go-sdk            \u2502                             \u2502\n\u2502                     \u2502       (v1.2.0)          \u2502                             \u2502\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#library-summary-matrix","title":"Library Summary Matrix","text":"Library Version Purpose Key Interfaces Dependencies toolmodel v0.1.2 Core data models <code>Tool</code>, <code>ToolBackend</code>, <code>SchemaValidator</code> mcp go-sdk toolindex v0.1.8 Tool registry <code>Index</code>, <code>Searcher</code>, <code>BackendSelector</code> toolmodel tooldocs v0.1.10 Documentation <code>Store</code>, <code>DetailLevel</code> toolindex, toolmodel toolrun v0.1.9 Execution <code>Runner</code>, <code>MCPExecutor</code>, <code>ProviderExecutor</code>, <code>LocalRegistry</code> toolindex, toolmodel toolcode v0.1.10 Code execution <code>Executor</code>, <code>Engine</code>, <code>Tools</code> toolrun, tooldocs, toolindex toolsearch v0.1.9 BM25 search <code>BM25Searcher</code> (implements <code>Searcher</code>) toolindex, bleve toolruntime v0.1.10 Sandbox runtime <code>Runtime</code>, <code>Backend</code>, <code>ToolGateway</code> toolcode, toolrun, tooldocs"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-1-toolmodel-foundation","title":"Layer 1: toolmodel (Foundation)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state","title":"Current State","text":"<p>The foundational library defining what a \"tool\" is. Zero networking dependencies, safe for embedding.</p> <p>Exported Types: - <code>Tool</code> - Embeds <code>mcp.Tool</code> with extensions (Namespace, Version, Tags) - <code>ToolBackend</code> - Backend binding (Kind, MCP/Provider/Local configs) - <code>BackendKind</code> - Enum: <code>mcp</code>, <code>provider</code>, <code>local</code> - <code>MCPBackend</code>, <code>ProviderBackend</code>, <code>LocalBackend</code> - Backend configs - <code>SchemaValidator</code> - Interface for JSON Schema validation - <code>DefaultValidator</code> - Default implementation using jsonschema-go</p> <p>Key Functions: - <code>Tool.ToolID()</code> - Returns canonical ID (<code>namespace:name</code>) - <code>ParseToolID()</code> - Parses ID string into components - <code>Tool.Validate()</code> - Validates tool invariants - <code>NormalizeTags()</code> - Tag normalization for indexing</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-low-mostly-stable","title":"Priority: LOW (mostly stable)","text":"Change Rationale Impact Add <code>ToolMetadata</code> field Support arbitrary metadata for middleware/backends Minor - additive Add <code>BackendKindHTTP</code> Support HTTP backend type for remote APIs Minor - additive Add <code>BackendKindGRPC</code> Support gRPC backend type Minor - additive Add <code>HTTPBackend</code> struct Config for HTTP backends Minor - additive"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#proposed-additions","title":"Proposed Additions","text":"<pre><code>// New backend kinds for multi-backend architecture\nconst (\n    BackendKindMCP      BackendKind = \"mcp\"\n    BackendKindProvider BackendKind = \"provider\"\n    BackendKindLocal    BackendKind = \"local\"\n    BackendKindHTTP     BackendKind = \"http\"      // NEW\n    BackendKindGRPC     BackendKind = \"grpc\"      // NEW\n)\n\n// HTTPBackend metadata for HTTP API backends\ntype HTTPBackend struct {\n    BaseURL   string            `json:\"baseUrl\"`\n    AuthType  string            `json:\"authType,omitempty\"`  // bearer, oauth2, apikey\n    Headers   map[string]string `json:\"headers,omitempty\"`\n    Timeout   time.Duration     `json:\"timeout,omitempty\"`\n}\n\n// GRPCBackend metadata for gRPC backends\ntype GRPCBackend struct {\n    Address   string `json:\"address\"`\n    TLS       bool   `json:\"tls,omitempty\"`\n    CACert    string `json:\"caCert,omitempty\"`\n}\n\n// ToolBackend - add HTTP and GRPC fields\ntype ToolBackend struct {\n    Kind     BackendKind      `json:\"kind\"`\n    MCP      *MCPBackend      `json:\"mcp,omitempty\"`\n    Provider *ProviderBackend `json:\"provider,omitempty\"`\n    Local    *LocalBackend    `json:\"local,omitempty\"`\n    HTTP     *HTTPBackend     `json:\"http,omitempty\"`      // NEW\n    GRPC     *GRPCBackend     `json:\"grpc,omitempty\"`      // NEW\n}\n\n// Tool - add metadata field\ntype Tool struct {\n    mcp.Tool\n    Namespace string         `json:\"namespace,omitempty\"`\n    Version   string         `json:\"version,omitempty\"`\n    Tags      []string       `json:\"tags,omitempty\"`\n    Metadata  map[string]any `json:\"metadata,omitempty\"`   // NEW\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-2-toolindex-registry","title":"Layer 2: toolindex (Registry)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_1","title":"Current State","text":"<p>Global registry and discovery layer for tools. Thread-safe, supports pluggable search.</p> <p>Exported Types: - <code>Index</code> - Interface for tool registry - <code>InMemoryIndex</code> - Default implementation - <code>Summary</code> - Lightweight search result - <code>SearchDoc</code> - Document for search indexing - <code>Searcher</code> - Interface for search implementations - <code>BackendSelector</code> - Function type for backend selection - <code>ToolRegistration</code> - Tool + Backend pair</p> <p>Key Methods: - <code>RegisterTool()</code>, <code>RegisterTools()</code>, <code>RegisterToolsFromMCP()</code> - <code>GetTool()</code>, <code>GetAllBackends()</code> - <code>Search()</code>, <code>ListNamespaces()</code> - <code>UnregisterBackend()</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_1","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-medium","title":"Priority: MEDIUM","text":"Change Rationale Impact Add <code>ListTools()</code> method Backend aggregation needs full tool list Minor - additive Add <code>BackendSource</code> tracking Track which backend registered a tool Medium - structural Add <code>Refresh()</code> capability Support hot-reload from config changes Medium - additive Add <code>OnChange</code> callback Notify listeners of registry changes Minor - additive"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#proposed-interface-extensions","title":"Proposed Interface Extensions","text":"<pre><code>// Index interface additions\ntype Index interface {\n    // Existing methods...\n    RegisterTool(tool toolmodel.Tool, backend toolmodel.ToolBackend) error\n    RegisterTools(regs []ToolRegistration) error\n    RegisterToolsFromMCP(serverName string, tools []toolmodel.Tool) error\n    UnregisterBackend(toolID string, kind toolmodel.BackendKind, backendID string) error\n    GetTool(id string) (toolmodel.Tool, toolmodel.ToolBackend, error)\n    GetAllBackends(id string) ([]toolmodel.ToolBackend, error)\n    Search(query string, limit int) ([]Summary, error)\n    ListNamespaces() ([]string, error)\n\n    // NEW: Support for multi-backend architecture\n    ListTools() ([]toolmodel.Tool, error)                    // List all registered tools\n    ListToolsFromBackend(backendName string) ([]Summary, error) // Filter by source\n\n    // NEW: Support for dynamic updates\n    OnChange(callback func(event RegistryEvent)) func()      // Subscribe to changes\n    Refresh() error                                          // Trigger refresh from sources\n}\n\n// RegistryEvent for change notifications\ntype RegistryEvent struct {\n    Type    RegistryEventType  // added, updated, removed\n    ToolID  string\n    Backend *toolmodel.ToolBackend\n}\n\ntype RegistryEventType string\n\nconst (\n    RegistryEventAdded   RegistryEventType = \"added\"\n    RegistryEventUpdated RegistryEventType = \"updated\"\n    RegistryEventRemoved RegistryEventType = \"removed\"\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#backendselector-enhancement","title":"BackendSelector Enhancement","text":"<pre><code>// Enhanced backend selection with context\ntype BackendSelectorFunc func(\n    tool toolmodel.Tool,\n    backends []toolmodel.ToolBackend,\n    hints *SelectionHints,\n) toolmodel.ToolBackend\n\n// SelectionHints provides context for backend selection\ntype SelectionHints struct {\n    PreferredKind    toolmodel.BackendKind // Caller preference\n    PreferredBackend string                 // Specific backend name\n    LatencyBudget    time.Duration          // Latency requirement\n    CostSensitive    bool                   // Prefer cheaper backends\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-3-tooldocs-documentation","title":"Layer 3: tooldocs (Documentation)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_2","title":"Current State","text":"<p>Progressive disclosure documentation layer. Three detail levels: summary, schema, full.</p> <p>Exported Types: - <code>Store</code> - Interface for documentation storage - <code>InMemoryStore</code> - Default implementation - <code>DetailLevel</code> - Enum: summary, schema, full - <code>ToolDoc</code> - Documentation at various levels - <code>ToolExample</code> - Usage example - <code>SchemaInfo</code> - Derived schema information - <code>DocEntry</code> - Input for registration</p> <p>Key Methods: - <code>DescribeTool(id, level)</code> - Get documentation at level - <code>ListExamples(id, max)</code> - Get examples - <code>RegisterDoc()</code>, <code>RegisterExamples()</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_2","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-low-minimal-changes-needed","title":"Priority: LOW (minimal changes needed)","text":"Change Rationale Impact Add <code>BulkRegister()</code> method Backend aggregation may load many docs Minor - additive Add source tracking Track which backend provided docs Minor - structural"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#proposed-additions_1","title":"Proposed Additions","text":"<pre><code>// Store interface additions\ntype Store interface {\n    // Existing methods...\n    DescribeTool(id string, level DetailLevel) (ToolDoc, error)\n    ListExamples(id string, maxExamples int) ([]ToolExample, error)\n\n    // NEW: Bulk operations for backend aggregation\n    BulkRegisterDocs(entries map[string]DocEntry) error\n\n    // NEW: Source tracking\n    GetDocSource(id string) (string, error)  // Returns backend name\n}\n\n// DocEntry - add source field\ntype DocEntry struct {\n    Summary      string\n    Notes        string\n    Examples     []ToolExample\n    ExternalRefs []string\n    Source       string  // NEW: Backend that provided this doc\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-4-toolrun-execution","title":"Layer 4: toolrun (Execution)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_3","title":"Current State","text":"<p>Tool execution layer supporting MCP, Provider, and Local backends.</p> <p>Exported Types: - <code>Runner</code> - Interface for tool execution - <code>DefaultRunner</code> - Default implementation - <code>MCPExecutor</code> - Interface for MCP backend calls - <code>ProviderExecutor</code> - Interface for provider backend calls - <code>LocalRegistry</code> - Interface for local handler lookup - <code>RunResult</code>, <code>StepResult</code>, <code>ChainStep</code> - Execution results - <code>StreamEvent</code> - Streaming event type - <code>ToolError</code> - Contextual error wrapper</p> <p>Key Methods: - <code>Run()</code> - Execute single tool - <code>RunStream()</code> - Execute with streaming - <code>RunChain()</code> - Execute tool sequence</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_3","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-high-core-execution-layer","title":"Priority: HIGH (core execution layer)","text":"Change Rationale Impact Add <code>HTTPExecutor</code> interface Support HTTP backend execution Medium - additive Add <code>GRPCExecutor</code> interface Support gRPC backend execution Medium - additive Add <code>ExecutorRegistry</code> Dynamic executor registration Medium - structural Add execution hooks Middleware integration point Medium - additive Add <code>BackendRouter</code> Route execution to correct executor Medium - structural"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#proposed-interface-additions","title":"Proposed Interface Additions","text":"<pre><code>// HTTPExecutor for HTTP backend execution\ntype HTTPExecutor interface {\n    CallTool(ctx context.Context, baseURL string, tool string, args map[string]any) (any, error)\n    CallToolStream(ctx context.Context, baseURL string, tool string, args map[string]any) (&lt;-chan StreamEvent, error)\n}\n\n// GRPCExecutor for gRPC backend execution\ntype GRPCExecutor interface {\n    CallTool(ctx context.Context, address string, tool string, args map[string]any) (any, error)\n    CallToolStream(ctx context.Context, address string, tool string, args map[string]any) (&lt;-chan StreamEvent, error)\n}\n\n// ExecutorRegistry manages execution backends\ntype ExecutorRegistry interface {\n    Register(kind toolmodel.BackendKind, executor any) error\n    Get(kind toolmodel.BackendKind) (any, bool)\n    List() []toolmodel.BackendKind\n}\n\n// ExecutionHook for middleware integration\ntype ExecutionHook interface {\n    BeforeExecution(ctx context.Context, toolID string, args map[string]any) (context.Context, error)\n    AfterExecution(ctx context.Context, toolID string, result RunResult, err error) error\n}\n\n// Config additions\ntype Config struct {\n    // Existing fields...\n    Index            toolindex.Index\n    ToolResolver     func(id string) (*toolmodel.Tool, error)\n    BackendsResolver func(id string) ([]toolmodel.ToolBackend, error)\n    BackendSelector  toolindex.BackendSelector\n    Validator        toolmodel.SchemaValidator\n    ValidateInput    bool\n    ValidateOutput   bool\n    MCP              MCPExecutor\n    Provider         ProviderExecutor\n    Local            LocalRegistry\n\n    // NEW: Additional executors\n    HTTP             HTTPExecutor        // NEW\n    GRPC             GRPCExecutor        // NEW\n    ExecutorRegistry ExecutorRegistry    // NEW: Dynamic registration\n    Hooks            []ExecutionHook     // NEW: Middleware hooks\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#enhanced-runner-interface","title":"Enhanced Runner Interface","text":"<pre><code>// Runner interface with execution options\ntype Runner interface {\n    Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)\n    RunStream(ctx context.Context, toolID string, args map[string]any) (&lt;-chan StreamEvent, error)\n    RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error)\n\n    // NEW: Execution with options\n    RunWithOptions(ctx context.Context, toolID string, args map[string]any, opts RunOptions) (RunResult, error)\n}\n\n// RunOptions for execution customization\ntype RunOptions struct {\n    PreferredBackend string                 // Override backend selection\n    Timeout          time.Duration          // Per-call timeout\n    Metadata         map[string]any         // Pass-through metadata\n    SkipValidation   bool                   // Skip input/output validation\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-5-toolcode-code-execution","title":"Layer 5: toolcode (Code Execution)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_4","title":"Current State","text":"<p>Code execution orchestration layer with pluggable engines.</p> <p>Exported Types: - <code>Executor</code> - Interface for code execution - <code>DefaultExecutor</code> - Default implementation - <code>Engine</code> - Interface for language-specific execution - <code>Tools</code> - Metatool environment exposed to code - <code>Config</code>, <code>ExecuteParams</code>, <code>ExecuteResult</code> - <code>ToolCallRecord</code>, <code>CodeError</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_4","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-low-mostly-stable_1","title":"Priority: LOW (mostly stable)","text":"Change Rationale Impact Add engine registry Support multiple language engines Minor - structural Add execution context Pass middleware context through Minor - additive"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#proposed-additions_2","title":"Proposed Additions","text":"<pre><code>// EngineRegistry for multiple language support\ntype EngineRegistry interface {\n    Register(language string, engine Engine) error\n    Get(language string) (Engine, bool)\n    List() []string\n}\n\n// Config additions\ntype Config struct {\n    // Existing fields...\n    Index           toolindex.Index\n    Docs            tooldocs.Store\n    Run             toolrun.Runner\n    Engine          Engine\n    DefaultTimeout  time.Duration\n    DefaultLanguage string\n    MaxToolCalls    int\n    MaxChainSteps   int\n    Logger          Logger\n\n    // NEW: Multiple engine support\n    EngineRegistry  EngineRegistry  // NEW\n}\n\n// ExecuteParams additions\ntype ExecuteParams struct {\n    Language     string\n    Code         string\n    Timeout      time.Duration\n    MaxToolCalls int\n\n    // NEW: Execution context\n    Metadata     map[string]any  // NEW: Pass-through metadata\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-6-toolsearch-bm25-search","title":"Layer 6: toolsearch (BM25 Search)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_5","title":"Current State","text":"<p>BM25 search implementation using Bleve. Implements <code>toolindex.Searcher</code>.</p> <p>Exported Types: - <code>BM25Config</code> - Configuration (boosts, limits) - <code>BM25Searcher</code> - Searcher implementation</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_5","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-none-stable-well-designed","title":"Priority: NONE (stable, well-designed)","text":"<p>The library already implements the pluggable pattern correctly via <code>toolindex.Searcher</code> interface. No changes needed for the pluggable architecture.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-7-toolruntime-sandbox","title":"Layer 7: toolruntime (Sandbox)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_6","title":"Current State","text":"<p>Runtime and trust boundary layer with multiple isolation backends.</p> <p>Exported Types: - <code>Runtime</code> - Interface for code execution runtime - <code>DefaultRuntime</code> - Default implementation - <code>Backend</code> - Interface for isolation backends - <code>ToolGateway</code> - Tool access interface for sandboxed code - <code>SecurityProfile</code> - dev, standard, hardened - <code>BackendKind</code> - Isolation mechanism (Docker, K8s, gVisor, etc.) - <code>ExecuteRequest</code>, <code>ExecuteResult</code>, <code>Limits</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_6","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-low-mostly-independent","title":"Priority: LOW (mostly independent)","text":"Change Rationale Impact Add security profile config Configure profiles via YAML Minor - additive Add backend discovery Auto-discover available backends Minor - additive"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#cross-cutting-concerns","title":"Cross-Cutting Concerns","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#error-handling-improvements","title":"Error Handling Improvements","text":"<p>All libraries should adopt a consistent error taxonomy:</p> <pre><code>// Proposed: pkg/errors/errors.go (new shared package)\n\n// ToolError is the base error type for all tool operations\ntype ToolError struct {\n    Code       ErrorCode\n    Message    string\n    ToolID     string\n    Backend    string\n    Op         string\n    Cause      error\n    Retryable  bool\n    Metadata   map[string]any\n}\n\ntype ErrorCode string\n\nconst (\n    ErrCodeNotFound       ErrorCode = \"not_found\"\n    ErrCodeValidation     ErrorCode = \"validation\"\n    ErrCodeExecution      ErrorCode = \"execution\"\n    ErrCodeTimeout        ErrorCode = \"timeout\"\n    ErrCodeBackendFailure ErrorCode = \"backend_failure\"\n    ErrCodeRateLimit      ErrorCode = \"rate_limit\"\n    ErrCodeAuth           ErrorCode = \"auth\"\n)\n\nfunc (e *ToolError) Error() string\nfunc (e *ToolError) Unwrap() error\nfunc (e *ToolError) Is(target error) bool\nfunc (e *ToolError) IsRetryable() bool\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#context-propagation","title":"Context Propagation","text":"<p>All libraries should propagate context consistently:</p> <pre><code>// Proposed: Context keys for cross-cutting concerns\ntype contextKey string\n\nconst (\n    ContextKeyRequestID  contextKey = \"request_id\"\n    ContextKeyUserID     contextKey = \"user_id\"\n    ContextKeyTraceID    contextKey = \"trace_id\"\n    ContextKeyBackend    contextKey = \"backend\"\n    ContextKeyMetadata   contextKey = \"metadata\"\n)\n\n// Helper functions\nfunc WithRequestID(ctx context.Context, id string) context.Context\nfunc RequestIDFromContext(ctx context.Context) string\n// ... etc\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#implementation-priority","title":"Implementation Priority","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#phase-1-foundation-with-metatools-mcp-phase-1","title":"Phase 1: Foundation (with metatools-mcp Phase 1)","text":"<ol> <li>toolmodel: Add HTTP/GRPC backend kinds (1 day)</li> <li>toolrun: Add HTTPExecutor, GRPCExecutor interfaces (2 days)</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#phase-2-registry-enhancements-with-metatools-mcp-phase-4","title":"Phase 2: Registry Enhancements (with metatools-mcp Phase 4)","text":"<ol> <li>toolindex: Add ListTools, OnChange, source tracking (2 days)</li> <li>toolrun: Add ExecutorRegistry, BackendRouter (2 days)</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#phase-3-middleware-integration-with-metatools-mcp-phase-5","title":"Phase 3: Middleware Integration (with metatools-mcp Phase 5)","text":"<ol> <li>toolrun: Add ExecutionHook interface (1 day)</li> <li>All libraries: Consistent error taxonomy (2 days)</li> <li>All libraries: Context propagation (1 day)</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#version-compatibility-matrix","title":"Version Compatibility Matrix","text":"<p>Current ecosystem versions:</p> Library Current After Phase 1 After Phase 2 After Phase 3 toolmodel v0.1.2 v0.2.0 v0.2.0 v0.2.0 toolindex v0.1.8 v0.1.8 v0.2.0 v0.2.0 tooldocs v0.1.10 v0.1.10 v0.1.11 v0.1.11 toolrun v0.1.9 v0.2.0 v0.2.0 v0.3.0 toolcode v0.1.10 v0.1.10 v0.1.10 v0.1.11 toolsearch v0.1.9 v0.1.9 v0.1.9 v0.1.9 toolruntime v0.1.10 v0.1.10 v0.1.10 v0.1.11"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#summary-required-library-changes","title":"Summary: Required Library Changes","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#breaking-changes-none","title":"Breaking Changes: NONE","text":"<p>All proposed changes are additive and backward-compatible.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#high-priority-changes","title":"High Priority Changes","text":"Library Change Files Affected toolmodel Add BackendKindHTTP, BackendKindGRPC types.go toolmodel Add HTTPBackend, GRPCBackend structs types.go toolrun Add HTTPExecutor interface executor.go (new) toolrun Add GRPCExecutor interface executor.go (new) toolrun Add ExecutorRegistry registry.go (new)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#medium-priority-changes","title":"Medium Priority Changes","text":"Library Change Files Affected toolindex Add ListTools method index.go toolindex Add OnChange callback index.go toolrun Add ExecutionHook interface hooks.go (new) toolrun Add RunOptions, RunWithOptions runner.go"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#low-priority-changes","title":"Low Priority Changes","text":"Library Change Files Affected tooldocs Add BulkRegisterDocs store.go toolcode Add EngineRegistry engine.go (new) All Consistent error taxonomy errors.go (new per lib)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#key-discovery-architecture-already-pluggable","title":"Key Discovery: Architecture Already Pluggable","text":"<p>Comprehensive analysis of all 8 component libraries (40+ source files, 12,000+ lines) revealed:</p> <p>The metatools ecosystem is NOT a monolith to be refactored. It is a mature, layered, pluggable architecture with 13 extension points already implemented as Go interfaces.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#13-extension-points-catalogued","title":"13 Extension Points Catalogued","text":"# Interface Library Status 1 <code>SchemaValidator</code> toolmodel \u2705 Interface-based 2 <code>Searcher</code> toolindex \u2705 Interface-based 3 <code>BackendSelector</code> toolindex \u2705 Function-based 4 <code>Store</code> tooldocs \u2705 Interface-based 5 <code>ToolResolver</code> tooldocs \u2705 Function-based 6 <code>Runner</code> toolrun \u2705 Interface-based 7 <code>MCPExecutor</code> toolrun \u2705 Interface-based 8 <code>ProviderExecutor</code> toolrun \u2705 Interface-based 9 <code>LocalRegistry</code> toolrun \u2705 Interface-based 10 <code>Backend</code> toolruntime \u2705 Interface-based (10 implementations!) 11 <code>ToolGateway</code> toolruntime \u2705 Interface-based 12 <code>Logger</code> toolcode \u2705 Interface-based 13 <code>Engine</code> toolcode \u2705 Interface-based"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#implications-for-implementation","title":"Implications for Implementation","text":"<p>The \"pluggable architecture\" work is primarily: 1. Exposure - Make internal extension points accessible via configuration 2. Configuration - Add CLI + config layer (Cobra + Koanf) 3. Documentation - Catalog the 13 extension points with examples</p> <p>This reduces the implementation timeline from 9 weeks to 6-7 weeks (25% reduction).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changelog","title":"Changelog","text":"Date Change 2026-01-27 Initial analysis of all 7 component libraries 2026-01-28 Added Key Discovery section documenting 13 existing extension points 2026-01-28 Updated analysis to reflect that architecture is already pluggable"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/","title":"Pluggable Architecture Implementation Phases","text":"<p>Status: Draft (Revised) Date: 2026-01-28 Related: Pluggable Architecture Proposal, Component Library Analysis</p> <p>Revised Timeline: Architecture discovery revealed that 13 extension points already exist as Go interfaces. The work is primarily configuration and exposure, not architecture redesign. Timeline reduced from 9 weeks to 6-7 weeks (25% reduction).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#overview","title":"Overview","text":"<p>This document breaks the pluggable architecture proposal into manageable implementation phases, following Go best practices and layered architecture principles. Each phase is designed to be:</p> <ul> <li>Independently deliverable - Can be merged and deployed after completion</li> <li>Backward compatible - Existing functionality continues to work</li> <li>Testable - Includes clear verification criteria</li> <li>Incremental - Builds on previous phases</li> </ul> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    REVISED IMPLEMENTATION ROADMAP (6-7 weeks)               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Phase 1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Phase 2 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Phase 3 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Phase 4          \u2502\n\u2502   CLI + Config       Transport          Public APIs        Backend           \u2502\n\u2502   (Expose 13 pts)    Abstraction        &amp; Documentation    Integration       \u2502\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502   2 weeks    \u2502   \u2502  1-2 weeks   \u2502   \u2502   1 week     \u2502   \u2502   2 weeks    \u2502 \u2502\n\u2502   \u2502              \u2502   \u2502              \u2502   \u2502              \u2502   \u2502              \u2502 \u2502\n\u2502   \u2502 Cobra CLI    \u2502   \u2502 Transport    \u2502   \u2502 Export       \u2502   \u2502 Docker/WASM  \u2502 \u2502\n\u2502   \u2502 Koanf config \u2502   \u2502 Interface    \u2502   \u2502 internal pkg \u2502   \u2502 integration  \u2502 \u2502\n\u2502   \u2502 13 ext points\u2502   \u2502 Stdio + SSE  \u2502   \u2502 13 ext docs  \u2502   \u2502 Backend reg  \u2502 \u2502\n\u2502   \u2502 config schema\u2502   \u2502              \u2502   \u2502 Examples     \u2502   \u2502 config       \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502   MVP \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502                                    \u2502\n\u2502   (Phases 1-2: ~3-4 weeks)              \u2502                                    \u2502\n\u2502                                                                               \u2502\n\u2502   Note: Original Phase 5 (Middleware) deferred - 13 extension points        \u2502\n\u2502         already provide middleware integration via ExecutionHook             \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phase-1-cli-framework-configuration-foundation","title":"Phase 1: CLI Framework &amp; Configuration (Foundation)","text":"<p>Duration: ~2 weeks Priority: Critical (foundation for all other phases) Risk: Low (additive changes, no breaking changes)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#objective","title":"Objective","text":"<p>Introduce Cobra CLI framework and Koanf configuration library while maintaining backward compatibility with current environment variable configuration.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#directory-structure-changes","title":"Directory Structure Changes","text":"<pre><code>cmd/metatools/\n\u251c\u2500\u2500 main.go              # Entry point (simplified)\n\u251c\u2500\u2500 root.go              # Root command\n\u251c\u2500\u2500 stdio.go             # `metatools stdio` (current behavior)\n\u251c\u2500\u2500 serve.go             # `metatools serve` (HTTP/SSE) - placeholder\n\u251c\u2500\u2500 version.go           # `metatools version`\n\u251c\u2500\u2500 validate.go          # `metatools validate` (config validation)\n\u251c\u2500\u2500 executor_toolruntime.go  # (unchanged)\n\u2514\u2500\u2500 executor_stub.go         # (unchanged)\n\ninternal/\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 env.go           # (unchanged - backward compat)\n\u2502   \u251c\u2500\u2500 loader.go        # NEW: Koanf-based config loader\n\u2502   \u251c\u2500\u2500 schema.go        # NEW: Config struct definitions\n\u2502   \u2514\u2500\u2500 defaults.go      # NEW: Default values\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#implementation-tasks","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#11-add-dependencies","title":"1.1 Add Dependencies","text":"<pre><code>// go.mod additions\nrequire (\n    github.com/spf13/cobra v1.8.1\n    github.com/knadh/koanf/v2 v2.1.2\n    github.com/knadh/koanf/parsers/yaml v0.1.0\n    github.com/knadh/koanf/providers/env v1.0.0\n    github.com/knadh/koanf/providers/file v1.1.0\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#12-configuration-schema-internalconfigschemago","title":"1.2 Configuration Schema (<code>internal/config/schema.go</code>)","text":"<pre><code>package config\n\n// ServerConfig is the root configuration structure\ntype ServerConfig struct {\n    Server    ServerSettings    `koanf:\"server\"`\n    Transport TransportConfig   `koanf:\"transport\"`\n    Search    SearchConfig      `koanf:\"search\"`\n    Execution ExecutionConfig   `koanf:\"execution\"`\n    Providers ProvidersConfig   `koanf:\"providers\"`\n    Backends  BackendsConfig    `koanf:\"backends\"`\n    Middleware MiddlewareConfig `koanf:\"middleware\"`\n}\n\ntype ServerSettings struct {\n    Name    string `koanf:\"name\"`\n    Version string `koanf:\"version\"`\n}\n\ntype TransportConfig struct {\n    Type string       `koanf:\"type\"` // stdio, sse, http\n    HTTP HTTPConfig   `koanf:\"http\"`\n}\n\ntype HTTPConfig struct {\n    Host     string        `koanf:\"host\"`\n    Port     int           `koanf:\"port\"`\n    TLS      TLSConfig     `koanf:\"tls\"`\n    Timeouts TimeoutConfig `koanf:\"timeouts\"`\n    CORS     CORSConfig    `koanf:\"cors\"`\n    Health   HealthConfig  `koanf:\"health\"`\n}\n\n// SearchConfig matches current EnvConfig.SearchConfig\ntype SearchConfig struct {\n    Strategy       string `koanf:\"strategy\"`\n    NameBoost      int    `koanf:\"name_boost\"`\n    NamespaceBoost int    `koanf:\"namespace_boost\"`\n    TagsBoost      int    `koanf:\"tags_boost\"`\n    MaxDocs        int    `koanf:\"max_docs\"`\n    MaxDocTextLen  int    `koanf:\"max_doctext_len\"`\n}\n\n// ... (additional config types)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#13-configuration-loader-internalconfigloadergo","title":"1.3 Configuration Loader (<code>internal/config/loader.go</code>)","text":"<pre><code>package config\n\nimport (\n    \"github.com/knadh/koanf/v2\"\n    \"github.com/knadh/koanf/parsers/yaml\"\n    \"github.com/knadh/koanf/providers/env\"\n    \"github.com/knadh/koanf/providers/file\"\n)\n\ntype Loader struct {\n    k *koanf.Koanf\n}\n\n// Load loads configuration with precedence:\n// CLI flags &gt; Environment variables &gt; Config file &gt; Defaults\nfunc (l *Loader) Load(configPath string) (*ServerConfig, error) {\n    l.k = koanf.New(\".\")\n\n    // 1. Load defaults\n    if err := l.loadDefaults(); err != nil {\n        return nil, err\n    }\n\n    // 2. Load config file (if exists)\n    if configPath != \"\" {\n        if err := l.k.Load(file.Provider(configPath), yaml.Parser()); err != nil {\n            return nil, fmt.Errorf(\"loading config file: %w\", err)\n        }\n    }\n\n    // 3. Load environment variables (METATOOLS_ prefix)\n    if err := l.k.Load(env.Provider(\"METATOOLS_\", \".\", func(s string) string {\n        return strings.Replace(strings.ToLower(\n            strings.TrimPrefix(s, \"METATOOLS_\")), \"_\", \".\", -1)\n    }), nil); err != nil {\n        return nil, fmt.Errorf(\"loading env vars: %w\", err)\n    }\n\n    var cfg ServerConfig\n    if err := l.k.Unmarshal(\"\", &amp;cfg); err != nil {\n        return nil, fmt.Errorf(\"unmarshaling config: %w\", err)\n    }\n\n    return &amp;cfg, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#14-cli-root-command-cmdmetatoolsrootgo","title":"1.4 CLI Root Command (<code>cmd/metatools/root.go</code>)","text":"<pre><code>package main\n\nimport (\n    \"os\"\n\n    \"github.com/spf13/cobra\"\n)\n\nvar (\n    cfgFile string\n    verbose bool\n)\n\nvar rootCmd = &amp;cobra.Command{\n    Use:   \"metatools\",\n    Short: \"MCP server for tool discovery and execution\",\n    Long: `metatools-mcp is a Model Context Protocol server that provides\nunified tool discovery, documentation, and execution capabilities.`,\n}\n\nfunc init() {\n    rootCmd.PersistentFlags().StringVarP(&amp;cfgFile, \"config\", \"c\", \"\",\n        \"config file (default: metatools.yaml)\")\n    rootCmd.PersistentFlags().BoolVarP(&amp;verbose, \"verbose\", \"v\", false,\n        \"verbose output\")\n\n    rootCmd.AddCommand(stdioCmd)\n    rootCmd.AddCommand(serveCmd)\n    rootCmd.AddCommand(versionCmd)\n    rootCmd.AddCommand(validateCmd)\n}\n\nfunc Execute() {\n    if err := rootCmd.Execute(); err != nil {\n        os.Exit(1)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#15-stdio-command-cmdmetatoolsstdiogo","title":"1.5 Stdio Command (<code>cmd/metatools/stdio.go</code>)","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"log\"\n    \"os/signal\"\n    \"syscall\"\n\n    \"github.com/spf13/cobra\"\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\nvar stdioCmd = &amp;cobra.Command{\n    Use:   \"stdio\",\n    Short: \"Run as stdio MCP server (default mode)\",\n    Long:  `Runs the MCP server using stdin/stdout transport for MCP clients like Claude Desktop.`,\n    RunE:  runStdio,\n}\n\nfunc init() {\n    // Set as default command when no subcommand provided\n    rootCmd.Run = stdioCmd.Run\n}\n\nfunc runStdio(cmd *cobra.Command, args []string) error {\n    ctx, cancel := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)\n    defer cancel()\n\n    srv, err := createServer()\n    if err != nil {\n        return fmt.Errorf(\"failed to create server: %w\", err)\n    }\n\n    tools := srv.ListTools()\n    log.Printf(\"metatools-mcp server starting with %d tools\", len(tools))\n\n    transport := &amp;mcp.StdioTransport{}\n    if err := srv.Run(ctx, transport); err != nil &amp;&amp; ctx.Err() == nil {\n        return fmt.Errorf(\"server error: %w\", err)\n    }\n\n    log.Println(\"Server stopped\")\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#verification-criteria","title":"Verification Criteria","text":"<ul> <li>[ ] <code>metatools stdio</code> works identically to current behavior</li> <li>[ ] <code>metatools version</code> prints version info</li> <li>[ ] <code>metatools validate -c config.yaml</code> validates configuration files</li> <li>[ ] Existing environment variables (<code>METATOOLS_SEARCH_*</code>) continue to work</li> <li>[ ] New YAML config file loading works</li> <li>[ ] Config precedence: CLI &gt; Env &gt; File &gt; Defaults</li> <li>[ ] All existing tests pass</li> <li>[ ] New unit tests for config loader (&gt;80% coverage)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#migration-notes","title":"Migration Notes","text":"<ul> <li>No breaking changes</li> <li><code>metatools</code> (no args) defaults to <code>metatools stdio</code></li> <li>Environment variable prefix remains <code>METATOOLS_</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phase-2-transport-layer-abstraction","title":"Phase 2: Transport Layer Abstraction","text":"<p>Duration: ~2 weeks Priority: High (enables multi-modal deployment) Risk: Medium (touches core server logic) Depends on: Phase 1</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#objective_1","title":"Objective","text":"<p>Abstract the transport layer so the same server logic can run over stdio, SSE, or HTTP.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#directory-structure-changes_1","title":"Directory Structure Changes","text":"<pre><code>internal/\n\u251c\u2500\u2500 transport/\n\u2502   \u251c\u2500\u2500 transport.go     # NEW: Transport interface\n\u2502   \u251c\u2500\u2500 registry.go      # NEW: Transport registry\n\u2502   \u251c\u2500\u2500 stdio.go         # NEW: Stdio transport wrapper\n\u2502   \u251c\u2500\u2500 sse.go           # NEW: SSE transport\n\u2502   \u2514\u2500\u2500 http.go          # NEW: HTTP transport (optional)\n\u251c\u2500\u2500 server/\n\u2502   \u251c\u2500\u2500 server.go        # MODIFIED: Use Transport interface\n\u2502   \u2514\u2500\u2500 handler.go       # NEW: Shared request handler\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#implementation-tasks_1","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#21-transport-interface-internaltransporttransportgo","title":"2.1 Transport Interface (<code>internal/transport/transport.go</code>)","text":"<pre><code>package transport\n\nimport (\n    \"context\"\n)\n\n// Transport defines how MCP clients connect to the server\ntype Transport interface {\n    // Name returns the transport identifier\n    Name() string\n\n    // Serve starts the transport and blocks until ctx is cancelled\n    Serve(ctx context.Context, handler RequestHandler) error\n\n    // Close gracefully shuts down the transport\n    Close() error\n\n    // Info returns runtime information about the transport\n    Info() TransportInfo\n}\n\n// RequestHandler processes incoming MCP requests\ntype RequestHandler interface {\n    HandleRequest(ctx context.Context, req *Request) (*Response, error)\n}\n\n// TransportInfo provides runtime details about a transport\ntype TransportInfo struct {\n    Name      string\n    Protocol  string            // \"stdio\", \"http\", \"sse\", \"grpc\"\n    Address   string            // \"\" for stdio, \"localhost:8080\" for HTTP\n    Listening bool\n    Metadata  map[string]string\n}\n\n// Config holds transport-specific configuration\ntype Config struct {\n    Type      string\n    HTTP      HTTPConfig\n    WebSocket WebSocketConfig\n    GRPC      GRPCConfig\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#22-transport-registry-internaltransportregistrygo","title":"2.2 Transport Registry (<code>internal/transport/registry.go</code>)","text":"<pre><code>package transport\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\n// Factory creates a configured transport instance\ntype Factory func(cfg Config) (Transport, error)\n\n// Registry manages available transports\ntype Registry struct {\n    mu         sync.RWMutex\n    transports map[string]Factory\n}\n\n// NewRegistry creates a new transport registry with built-in transports\nfunc NewRegistry() *Registry {\n    r := &amp;Registry{\n        transports: make(map[string]Factory),\n    }\n\n    // Register built-in transports\n    r.Register(\"stdio\", NewStdioTransport)\n    r.Register(\"sse\", NewSSETransport)\n    r.Register(\"http\", NewHTTPTransport)\n\n    return r\n}\n\n// Register adds a transport factory\nfunc (r *Registry) Register(name string, factory Factory) {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    r.transports[name] = factory\n}\n\n// Create instantiates a transport from config\nfunc (r *Registry) Create(cfg Config) (Transport, error) {\n    r.mu.RLock()\n    factory, ok := r.transports[cfg.Type]\n    r.mu.RUnlock()\n\n    if !ok {\n        return nil, fmt.Errorf(\"unknown transport type: %s\", cfg.Type)\n    }\n\n    return factory(cfg)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#23-stdio-transport-internaltransportstdiogo","title":"2.3 Stdio Transport (<code>internal/transport/stdio.go</code>)","text":"<pre><code>package transport\n\nimport (\n    \"context\"\n\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// StdioTransport wraps the MCP SDK's stdio transport\ntype StdioTransport struct {\n    sdk *mcp.StdioTransport\n}\n\n// NewStdioTransport creates a stdio transport\nfunc NewStdioTransport(cfg Config) (Transport, error) {\n    return &amp;StdioTransport{\n        sdk: &amp;mcp.StdioTransport{},\n    }, nil\n}\n\nfunc (t *StdioTransport) Name() string { return \"stdio\" }\n\nfunc (t *StdioTransport) Serve(ctx context.Context, handler RequestHandler) error {\n    // Adapt to MCP SDK's transport interface\n    return t.sdk.Run(ctx, adaptHandler(handler))\n}\n\nfunc (t *StdioTransport) Close() error { return nil }\n\nfunc (t *StdioTransport) Info() TransportInfo {\n    return TransportInfo{\n        Name:      \"stdio\",\n        Protocol:  \"stdio\",\n        Address:   \"stdin/stdout\",\n        Listening: true,\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#24-sse-transport-internaltransportssego","title":"2.4 SSE Transport (<code>internal/transport/sse.go</code>)","text":"<pre><code>package transport\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"net/http\"\n    \"sync\"\n    \"time\"\n)\n\n// SSETransport implements Server-Sent Events transport\ntype SSETransport struct {\n    cfg      HTTPConfig\n    server   *http.Server\n    handler  RequestHandler\n    mu       sync.RWMutex\n    clients  map[string]chan []byte\n}\n\n// NewSSETransport creates an SSE transport\nfunc NewSSETransport(cfg Config) (Transport, error) {\n    return &amp;SSETransport{\n        cfg:     cfg.HTTP,\n        clients: make(map[string]chan []byte),\n    }, nil\n}\n\nfunc (t *SSETransport) Name() string { return \"sse\" }\n\nfunc (t *SSETransport) Serve(ctx context.Context, handler RequestHandler) error {\n    t.handler = handler\n\n    mux := http.NewServeMux()\n    mux.HandleFunc(\"/mcp\", t.handleMCP)\n    mux.HandleFunc(\"/health\", t.handleHealth)\n    mux.HandleFunc(\"/ready\", t.handleReady)\n\n    addr := fmt.Sprintf(\"%s:%d\", t.cfg.Host, t.cfg.Port)\n    t.server = &amp;http.Server{\n        Addr:         addr,\n        Handler:      t.applyCORS(mux),\n        ReadTimeout:  t.cfg.Timeouts.Read,\n        WriteTimeout: t.cfg.Timeouts.Write,\n        IdleTimeout:  t.cfg.Timeouts.Idle,\n    }\n\n    // Start server in goroutine\n    errCh := make(chan error, 1)\n    go func() {\n        if t.cfg.TLS.Enabled {\n            errCh &lt;- t.server.ListenAndServeTLS(t.cfg.TLS.Cert, t.cfg.TLS.Key)\n        } else {\n            errCh &lt;- t.server.ListenAndServe()\n        }\n    }()\n\n    // Wait for context cancellation or error\n    select {\n    case &lt;-ctx.Done():\n        shutdownCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n        defer cancel()\n        return t.server.Shutdown(shutdownCtx)\n    case err := &lt;-errCh:\n        return err\n    }\n}\n\nfunc (t *SSETransport) handleMCP(w http.ResponseWriter, r *http.Request) {\n    if r.Method != http.MethodPost {\n        http.Error(w, \"Method not allowed\", http.StatusMethodNotAllowed)\n        return\n    }\n\n    // Set SSE headers\n    w.Header().Set(\"Content-Type\", \"text/event-stream\")\n    w.Header().Set(\"Cache-Control\", \"no-cache\")\n    w.Header().Set(\"Connection\", \"keep-alive\")\n\n    // Parse request\n    var req Request\n    if err := json.NewDecoder(r.Body).Decode(&amp;req); err != nil {\n        t.sendError(w, \"Invalid request\", http.StatusBadRequest)\n        return\n    }\n\n    // Handle request\n    resp, err := t.handler.HandleRequest(r.Context(), &amp;req)\n    if err != nil {\n        t.sendError(w, err.Error(), http.StatusInternalServerError)\n        return\n    }\n\n    // Send response as SSE event\n    t.sendEvent(w, \"message\", resp)\n    t.sendEvent(w, \"done\", struct{}{})\n}\n\nfunc (t *SSETransport) sendEvent(w http.ResponseWriter, event string, data any) {\n    jsonData, _ := json.Marshal(data)\n    fmt.Fprintf(w, \"event: %s\\ndata: %s\\n\\n\", event, jsonData)\n    if f, ok := w.(http.Flusher); ok {\n        f.Flush()\n    }\n}\n\n// ... additional helper methods\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#25-server-modifications-internalserverservergo","title":"2.5 Server Modifications (<code>internal/server/server.go</code>)","text":"<pre><code>// Run now accepts our Transport interface\nfunc (s *Server) Run(ctx context.Context, t transport.Transport) error {\n    log.Printf(\"Starting server with %s transport\", t.Name())\n    return t.Serve(ctx, s)\n}\n\n// HandleRequest implements transport.RequestHandler\nfunc (s *Server) HandleRequest(ctx context.Context, req *transport.Request) (*transport.Response, error) {\n    // Delegate to MCP SDK's request handling\n    return s.mcp.HandleRequest(ctx, req)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#verification-criteria_1","title":"Verification Criteria","text":"<ul> <li>[ ] <code>metatools stdio</code> works identically to Phase 1</li> <li>[ ] <code>metatools serve --port 8080</code> starts SSE server</li> <li>[ ] SSE endpoint accepts POST requests at <code>/mcp</code></li> <li>[ ] Health check endpoints work (<code>/health</code>, <code>/ready</code>)</li> <li>[ ] CORS headers applied correctly</li> <li>[ ] Graceful shutdown on SIGTERM</li> <li>[ ] TLS works when configured</li> <li>[ ] Integration tests for SSE transport</li> <li>[ ] Load test: 100 concurrent SSE connections</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#cli-changes","title":"CLI Changes","text":"<pre><code># New serve command\nmetatools serve [flags]\n\nFlags:\n  --port int          HTTP port (default 8080)\n  --host string       Bind address (default \"0.0.0.0\")\n  --tls               Enable TLS\n  --cert string       TLS certificate path\n  --key string        TLS key path\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phase-3-tool-provider-registry","title":"Phase 3: Tool Provider Registry","text":"<p>Duration: ~1 week Priority: High (enables plug-and-play tools) Risk: Medium (refactors core registration logic) Depends on: Phase 1</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#objective_2","title":"Objective","text":"<p>Replace hardcoded tool registration with a registry pattern that allows dynamic tool registration.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#directory-structure-changes_2","title":"Directory Structure Changes","text":"<pre><code>internal/\n\u251c\u2500\u2500 provider/\n\u2502   \u251c\u2500\u2500 provider.go      # NEW: ToolProvider interface\n\u2502   \u251c\u2500\u2500 registry.go      # NEW: Tool registry\n\u2502   \u251c\u2500\u2500 search.go        # NEW: search_tools provider\n\u2502   \u251c\u2500\u2500 describe.go      # NEW: describe_tool provider\n\u2502   \u251c\u2500\u2500 run.go           # NEW: run_tool provider\n\u2502   \u251c\u2500\u2500 chain.go         # NEW: run_chain provider\n\u2502   \u251c\u2500\u2500 namespaces.go    # NEW: list_namespaces provider\n\u2502   \u251c\u2500\u2500 examples.go      # NEW: list_tool_examples provider\n\u2502   \u2514\u2500\u2500 code.go          # NEW: execute_code provider (optional)\n\u251c\u2500\u2500 server/\n\u2502   \u2514\u2500\u2500 server.go        # MODIFIED: Use provider registry\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#implementation-tasks_2","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#31-tool-provider-interface-internalproviderprovidergo","title":"3.1 Tool Provider Interface (<code>internal/provider/provider.go</code>)","text":"<pre><code>package provider\n\nimport (\n    \"context\"\n\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// ToolProvider defines a pluggable MCP tool\ntype ToolProvider interface {\n    // Name returns the tool name (e.g., \"search_tools\")\n    Name() string\n\n    // Tool returns the MCP tool definition with JSON schema\n    Tool() *mcp.Tool\n\n    // Handle executes the tool with the given input\n    Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error)\n}\n\n// Option configures a tool provider\ntype Option func(ToolProvider)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#32-tool-registry-internalproviderregistrygo","title":"3.2 Tool Registry (<code>internal/provider/registry.go</code>)","text":"<pre><code>package provider\n\nimport (\n    \"fmt\"\n    \"sync\"\n\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// Registry manages registered tool providers\ntype Registry struct {\n    mu        sync.RWMutex\n    providers map[string]ToolProvider\n    order     []string // Maintains registration order\n}\n\n// NewRegistry creates a new tool provider registry\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        providers: make(map[string]ToolProvider),\n        order:     make([]string, 0),\n    }\n}\n\n// Register adds a tool provider\nfunc (r *Registry) Register(p ToolProvider) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    name := p.Name()\n    if _, exists := r.providers[name]; exists {\n        return fmt.Errorf(\"provider already registered: %s\", name)\n    }\n\n    r.providers[name] = p\n    r.order = append(r.order, name)\n    return nil\n}\n\n// Get retrieves a provider by name\nfunc (r *Registry) Get(name string) (ToolProvider, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    p, ok := r.providers[name]\n    return p, ok\n}\n\n// All returns all registered providers in registration order\nfunc (r *Registry) All() []ToolProvider {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    result := make([]ToolProvider, 0, len(r.order))\n    for _, name := range r.order {\n        result = append(result, r.providers[name])\n    }\n    return result\n}\n\n// Tools returns MCP tool definitions for all providers\nfunc (r *Registry) Tools() []*mcp.Tool {\n    providers := r.All()\n    tools := make([]*mcp.Tool, 0, len(providers))\n    for _, p := range providers {\n        tools = append(tools, p.Tool())\n    }\n    return tools\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#33-example-provider-internalprovidersearchgo","title":"3.3 Example Provider (<code>internal/provider/search.go</code>)","text":"<pre><code>package provider\n\nimport (\n    \"context\"\n\n    \"github.com/jonwraymond/metatools-mcp/internal/handlers\"\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// SearchProvider implements the search_tools tool\ntype SearchProvider struct {\n    handler *handlers.SearchHandler\n}\n\n// NewSearchProvider creates a search_tools provider\nfunc NewSearchProvider(h *handlers.SearchHandler) *SearchProvider {\n    return &amp;SearchProvider{handler: h}\n}\n\nfunc (p *SearchProvider) Name() string { return \"search_tools\" }\n\nfunc (p *SearchProvider) Tool() *mcp.Tool {\n    return &amp;mcp.Tool{\n        Name:        \"search_tools\",\n        Description: \"Search for tools by query string. Returns ranked list of matching tools.\",\n        InputSchema: mcp.ToolInputSchema{\n            Type: \"object\",\n            Properties: map[string]any{\n                \"query\": map[string]any{\n                    \"type\":        \"string\",\n                    \"description\": \"Search query to find relevant tools\",\n                },\n                \"limit\": map[string]any{\n                    \"type\":        \"integer\",\n                    \"description\": \"Maximum number of results (default 10)\",\n                    \"default\":     10,\n                },\n            },\n            Required: []string{\"query\"},\n        },\n    }\n}\n\nfunc (p *SearchProvider) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    query, _ := input[\"query\"].(string)\n    limit := 10\n    if l, ok := input[\"limit\"].(float64); ok {\n        limit = int(l)\n    }\n\n    return p.handler.Handle(ctx, query, limit)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#34-server-integration","title":"3.4 Server Integration","text":"<pre><code>// internal/server/server.go\n\nfunc New(cfg config.Config, registry *provider.Registry) (*Server, error) {\n    // ... existing validation\n\n    mcpServer := mcp.NewServer(&amp;mcp.Implementation{\n        Name:    implementationName,\n        Version: implementationVersion,\n    }, &amp;mcp.ServerOptions{\n        PageSize: defaultPageSize,\n    })\n\n    srv := &amp;Server{\n        config:   cfg,\n        mcp:      mcpServer,\n        registry: registry,\n    }\n\n    // Register tools from provider registry\n    for _, p := range registry.All() {\n        srv.registerProvider(p)\n    }\n\n    return srv, nil\n}\n\nfunc (s *Server) registerProvider(p provider.ToolProvider) {\n    tool := p.Tool()\n    s.tools = append(s.tools, tool)\n\n    s.mcp.AddTool(tool, func(ctx context.Context, req *mcp.CallToolRequest) (*mcp.CallToolResult, error) {\n        return p.Handle(ctx, req.Params.Arguments)\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#verification-criteria_2","title":"Verification Criteria","text":"<ul> <li>[ ] All existing tools work via provider registry</li> <li>[ ] Provider registration order matches tool list order</li> <li>[ ] Custom providers can be registered programmatically</li> <li>[ ] Unit tests for registry (&gt;90% coverage)</li> <li>[ ] Benchmark: Registration of 100 providers &lt; 1ms</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phase-4-backend-registry","title":"Phase 4: Backend Registry","text":"<p>Duration: ~2 weeks Priority: Medium (enables multi-source tool aggregation) Risk: Medium (new subsystem) Depends on: Phase 3</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#objective_3","title":"Objective","text":"<p>Implement a backend registry that aggregates tools from multiple sources (local, MCP servers, HTTP APIs).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#directory-structure-changes_3","title":"Directory Structure Changes","text":"<pre><code>internal/\n\u251c\u2500\u2500 backend/\n\u2502   \u251c\u2500\u2500 backend.go       # NEW: Backend interface\n\u2502   \u251c\u2500\u2500 registry.go      # NEW: Backend registry\n\u2502   \u251c\u2500\u2500 local.go         # NEW: Local file backend\n\u2502   \u251c\u2500\u2500 mcp.go           # NEW: MCP subprocess backend\n\u2502   \u251c\u2500\u2500 http.go          # NEW: HTTP API backend\n\u2502   \u251c\u2500\u2500 aggregator.go    # NEW: Tool aggregation logic\n\u2502   \u2514\u2500\u2500 errors.go        # NEW: Backend-specific errors\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#implementation-tasks_3","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#41-backend-interface-internalbackendbackendgo","title":"4.1 Backend Interface (<code>internal/backend/backend.go</code>)","text":"<pre><code>package backend\n\nimport (\n    \"context\"\n\n    \"github.com/jonwraymond/toolmodel\"\n)\n\n// Backend defines a source of tools\ntype Backend interface {\n    // Identity\n    Kind() string  // e.g., \"local\", \"mcp\", \"http\"\n    Name() string  // Instance name\n\n    // Lifecycle\n    Start(ctx context.Context) error\n    Stop() error\n\n    // Discovery\n    ListTools(ctx context.Context) ([]toolmodel.Tool, error)\n\n    // Execution\n    Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n}\n\n// Configurable backends support dynamic configuration\ntype Configurable interface {\n    Configure(raw []byte) error\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#42-backend-registry-internalbackendregistrygo","title":"4.2 Backend Registry (<code>internal/backend/registry.go</code>)","text":"<pre><code>package backend\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n)\n\n// Registry manages backend instances\ntype Registry struct {\n    mu       sync.RWMutex\n    backends map[string]Backend\n    order    []string\n}\n\n// NewRegistry creates a backend registry\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        backends: make(map[string]Backend),\n        order:    make([]string, 0),\n    }\n}\n\n// Register adds a backend\nfunc (r *Registry) Register(name string, b Backend) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    if _, exists := r.backends[name]; exists {\n        return fmt.Errorf(\"backend already registered: %s\", name)\n    }\n\n    r.backends[name] = b\n    r.order = append(r.order, name)\n    return nil\n}\n\n// StartAll starts all registered backends\nfunc (r *Registry) StartAll(ctx context.Context) error {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    for name, b := range r.backends {\n        if err := b.Start(ctx); err != nil {\n            return fmt.Errorf(\"starting backend %s: %w\", name, err)\n        }\n    }\n    return nil\n}\n\n// StopAll stops all registered backends\nfunc (r *Registry) StopAll() error {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    var errs []error\n    for name, b := range r.backends {\n        if err := b.Stop(); err != nil {\n            errs = append(errs, fmt.Errorf(\"stopping backend %s: %w\", name, err))\n        }\n    }\n\n    if len(errs) &gt; 0 {\n        return fmt.Errorf(\"errors stopping backends: %v\", errs)\n    }\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#43-mcp-backend-internalbackendmcpgo","title":"4.3 MCP Backend (<code>internal/backend/mcp.go</code>)","text":"<pre><code>package backend\n\nimport (\n    \"context\"\n    \"os/exec\"\n\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// MCPBackend connects to an MCP subprocess\ntype MCPBackend struct {\n    name    string\n    command string\n    args    []string\n    env     map[string]string\n\n    cmd    *exec.Cmd\n    client *mcp.Client\n}\n\n// NewMCPBackend creates an MCP subprocess backend\nfunc NewMCPBackend(name, command string, args []string, env map[string]string) *MCPBackend {\n    return &amp;MCPBackend{\n        name:    name,\n        command: command,\n        args:    args,\n        env:     env,\n    }\n}\n\nfunc (b *MCPBackend) Kind() string { return \"mcp\" }\nfunc (b *MCPBackend) Name() string { return b.name }\n\nfunc (b *MCPBackend) Start(ctx context.Context) error {\n    // Start subprocess and establish MCP connection\n    // ... implementation\n}\n\nfunc (b *MCPBackend) ListTools(ctx context.Context) ([]toolmodel.Tool, error) {\n    resp, err := b.client.ListTools(ctx)\n    if err != nil {\n        return nil, err\n    }\n\n    // Convert MCP tools to toolmodel.Tool\n    tools := make([]toolmodel.Tool, 0, len(resp.Tools))\n    for _, t := range resp.Tools {\n        tools = append(tools, convertMCPTool(t, b.name))\n    }\n    return tools, nil\n}\n\nfunc (b *MCPBackend) Execute(ctx context.Context, tool string, args map[string]any) (any, error) {\n    return b.client.CallTool(ctx, tool, args)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#verification-criteria_3","title":"Verification Criteria","text":"<ul> <li>[ ] Local backend loads tools from file paths</li> <li>[ ] MCP backend spawns subprocess and communicates via stdio</li> <li>[ ] HTTP backend calls remote API endpoints</li> <li>[ ] Tool aggregation merges tools from all backends</li> <li>[ ] Backend failures don't crash the server (graceful degradation)</li> <li>[ ] Integration tests for each backend type</li> <li>[ ] E2E test: GitHub MCP server integration</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phase-5-middleware-chain","title":"Phase 5: Middleware Chain","text":"<p>Duration: ~2 weeks Priority: Low (nice-to-have for MVP) Risk: Low (additive feature) Depends on: Phase 3</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#objective_4","title":"Objective","text":"<p>Implement a middleware chain for cross-cutting concerns (logging, auth, rate limiting, metrics).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#directory-structure-changes_4","title":"Directory Structure Changes","text":"<pre><code>internal/\n\u251c\u2500\u2500 middleware/\n\u2502   \u251c\u2500\u2500 middleware.go    # NEW: Middleware interface\n\u2502   \u251c\u2500\u2500 chain.go         # NEW: Middleware chain builder\n\u2502   \u251c\u2500\u2500 registry.go      # NEW: Middleware registry\n\u2502   \u251c\u2500\u2500 logging.go       # NEW: Logging middleware\n\u2502   \u251c\u2500\u2500 auth.go          # NEW: Auth middleware\n\u2502   \u251c\u2500\u2500 ratelimit.go     # NEW: Rate limiting middleware\n\u2502   \u251c\u2500\u2500 metrics.go       # NEW: Metrics middleware\n\u2502   \u251c\u2500\u2500 cache.go         # NEW: Caching middleware\n\u2502   \u2514\u2500\u2500 validation.go    # NEW: Input validation middleware\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#implementation-tasks_4","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#51-middleware-interface-internalmiddlewaremiddlewarego","title":"5.1 Middleware Interface (<code>internal/middleware/middleware.go</code>)","text":"<pre><code>package middleware\n\nimport (\n    \"context\"\n\n    \"github.com/jonwraymond/metatools-mcp/internal/provider\"\n)\n\n// Middleware wraps a ToolProvider with additional behavior\ntype Middleware func(provider.ToolProvider) provider.ToolProvider\n\n// Factory creates a configured middleware instance\ntype Factory func(cfg Config) (Middleware, error)\n\n// Config holds middleware-specific configuration\ntype Config struct {\n    Name    string\n    Enabled bool\n    Raw     map[string]any\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#52-middleware-chain-internalmiddlewarechaingo","title":"5.2 Middleware Chain (<code>internal/middleware/chain.go</code>)","text":"<pre><code>package middleware\n\nimport (\n    \"github.com/jonwraymond/metatools-mcp/internal/provider\"\n)\n\n// Chain applies middleware to providers in order\nfunc Chain(middlewares []Middleware, p provider.ToolProvider) provider.ToolProvider {\n    if len(middlewares) == 0 {\n        return p\n    }\n\n    // Apply in reverse order so first middleware wraps outermost\n    wrapped := p\n    for i := len(middlewares) - 1; i &gt;= 0; i-- {\n        wrapped = middlewares[i](wrapped)\n    }\n    return wrapped\n}\n\n// ApplyToRegistry wraps all providers in a registry with middleware\nfunc ApplyToRegistry(registry *provider.Registry, middlewares []Middleware) {\n    for _, p := range registry.All() {\n        wrapped := Chain(middlewares, p)\n        // Replace in registry\n        // ...\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#53-logging-middleware-internalmiddlewarelogginggo","title":"5.3 Logging Middleware (<code>internal/middleware/logging.go</code>)","text":"<pre><code>package middleware\n\nimport (\n    \"context\"\n    \"log/slog\"\n    \"time\"\n\n    \"github.com/jonwraymond/metatools-mcp/internal/provider\"\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\ntype loggingMiddleware struct {\n    next   provider.ToolProvider\n    logger *slog.Logger\n    level  slog.Level\n}\n\n// NewLoggingMiddleware creates a logging middleware\nfunc NewLoggingMiddleware(logger *slog.Logger, level slog.Level) Middleware {\n    return func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;loggingMiddleware{\n            next:   next,\n            logger: logger,\n            level:  level,\n        }\n    }\n}\n\nfunc (m *loggingMiddleware) Name() string        { return m.next.Name() }\nfunc (m *loggingMiddleware) Tool() *mcp.Tool     { return m.next.Tool() }\n\nfunc (m *loggingMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    start := time.Now()\n\n    m.logger.Log(ctx, m.level, \"tool call started\",\n        \"tool\", m.next.Name(),\n        \"input\", input,\n    )\n\n    result, err := m.next.Handle(ctx, input)\n\n    m.logger.Log(ctx, m.level, \"tool call completed\",\n        \"tool\", m.next.Name(),\n        \"duration\", time.Since(start),\n        \"error\", err,\n    )\n\n    return result, err\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#verification-criteria_4","title":"Verification Criteria","text":"<ul> <li>[ ] Logging middleware logs all tool calls</li> <li>[ ] Auth middleware validates tokens when configured</li> <li>[ ] Rate limiting middleware enforces limits</li> <li>[ ] Metrics middleware exposes Prometheus metrics</li> <li>[ ] Middleware chain order matches config order</li> <li>[ ] Unit tests for each middleware type</li> <li>[ ] Integration test: Full middleware chain</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#summary-implementation-priority-matrix","title":"Summary: Implementation Priority Matrix","text":"Phase Priority Risk Duration MVP? Phase 1: CLI + Config Critical Low 2 weeks \u2713 Phase 2: Transport High Medium 2 weeks \u2713 Phase 3: Tool Provider Registry High Medium 1 week \u2713 Phase 4: Backend Registry Medium Medium 2 weeks Phase 5: Middleware Chain Low Low 2 weeks <p>MVP Timeline: ~5 weeks (Phases 1-3) Full Implementation: ~9 weeks (All phases)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#appendix-architectural-decisions","title":"Appendix: Architectural Decisions","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#decision-1-koanf-over-viper","title":"Decision 1: Koanf over Viper","text":"<p>Decision: Use Koanf for configuration loading instead of Viper.</p> <p>Rationale: - Lighter dependency footprint - Modular provider architecture - Cleaner API for layered configuration - Better suited for our use case</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#decision-2-interface-based-transports-over-mcp-sdk-extension","title":"Decision 2: Interface-based Transports over MCP SDK Extension","text":"<p>Decision: Define our own Transport interface that wraps MCP SDK transports.</p> <p>Rationale: - Decouples from MCP SDK implementation details - Enables custom transports (Unix socket, gRPC) - Allows consistent lifecycle management - Facilitates testing with mock transports</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#decision-3-provider-pattern-over-direct-handler-registration","title":"Decision 3: Provider Pattern over Direct Handler Registration","text":"<p>Decision: Use ToolProvider interface instead of direct MCP tool registration.</p> <p>Rationale: - Enables middleware wrapping - Supports dynamic registration - Cleaner separation of concerns - Facilitates testing</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#decision-4-decorator-pattern-for-middleware","title":"Decision 4: Decorator Pattern for Middleware","text":"<p>Decision: Use decorator pattern (wrapping) for middleware chain.</p> <p>Rationale: - Matches go-chi's proven approach - Simple mental model - Easy to compose and test - Preserves ToolProvider interface</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#changelog","title":"Changelog","text":"Date Change 2026-01-27 Initial draft with 5 phases"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/","title":"MCP Spec Alignment Proposal","text":"<p>Status: Draft Date: 2026-01-28 Related: pluggable-architecture, architecture-evaluation, ROADMAP</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#summary","title":"Summary","text":"<p><code>metatools-mcp</code> already exposes a clean MCP-native tool surface, but several MCP-spec features are only partially covered or are not yet surfaced at the server boundary. This proposal defines a focused alignment path with the latest MCP spec (2025-11-25) and the official Go SDK, while keeping the current tool-first architecture stable.</p> <p>The goal is to improve protocol completeness and operational correctness without redesigning the existing libraries.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#goals","title":"Goals","text":"<ol> <li>Spec compliance at the server edge: align handler behavior with MCP method contracts (tools list, tool calls, tool error semantics, pagination).</li> <li>Dynamic tool updates: support <code>tools/list_changed</code> notifications tied to toolindex change events.</li> <li>Operational robustness: ensure cancellation/progress signals propagate through toolrun and toolruntime where supported.</li> <li>Clear expansion path for MCP resources and prompts without blocking current tool-focused roadmap.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#observations-current-state","title":"Observations (Current State)","text":"<ul> <li><code>metatools-mcp</code> exposes MCP tools via the official Go SDK and maps errors into MCP tool error payloads.</li> <li>Tool schemas are derived from <code>toolmodel</code> and remain MCP-native, preserving compatibility end-to-end.</li> <li>Tool registration is static at startup; runtime updates now emit <code>tools/list_changed</code> via toolindex change notifications (debounced and optionally disabled).</li> <li>Resources and prompts are not yet part of the metatools surface.</li> <li>Cancellation behavior now propagates via <code>context.Context</code>; progress notifications are emitted when a progress token is supplied, with step-level updates when the runner supports them.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#mcp-spec-alignment-targets","title":"MCP Spec Alignment Targets","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#1-tool-list-change-notifications","title":"1) Tool list change notifications","text":"<p>When tool availability changes (new tools, removed tools, updated schemas), the MCP server should notify connected clients via <code>notifications/tools/list_changed</code>. This can be wired to <code>toolindex</code> change callbacks.</p> <p>Implementation idea: - Subscribe to toolindex OnChange/Refresh hooks. - Emit <code>tools/list_changed</code> to all MCP sessions. - Expose a config flag + debounce window to disable or dampen notifications for static deployments.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#2-pagination-and-list-contracts","title":"2) Pagination and list contracts","text":"<p>The MCP spec defines <code>tools/list</code> pagination and page sizes. <code>metatools-mcp</code> already sets a default page size in the Go SDK; align <code>search_tools</code> and <code>list_namespaces</code> with consistent paging semantics and cursor shapes.</p> <p>Implementation idea: - Cap and validate list size consistently. - Use stable cursor generation (opaque tokens with validation) for pagination of search results and namespace listing.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#3-cancellation-and-progress-signals","title":"3) Cancellation and progress signals","text":"<p>MCP supports cancellation and progress notifications for long-running operations. For <code>run_tool</code>, <code>run_chain</code>, and <code>execute_code</code>, cancellation should be propagated to toolrun/toolruntime if supported.</p> <p>Implementation idea: - Use <code>ctx</code> cancellation to interrupt tool execution. - Surface progress events from toolruntime or toolrun (where available). - When progress events are unavailable, emit coarse start/end progress notifications.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#4-resources-and-prompts-expansion-future-prd","title":"4) Resources and prompts expansion (future PRD)","text":"<p>MCP defines resources and prompts alongside tools. The architecture should leave a clear integration path (e.g., new <code>toolresource</code> and <code>toolprompt</code> libraries or adapters in metatools-mcp).</p> <p>Implementation idea: - Draft a separate PRD to introduce a resources/prompt provider interface. - Keep current tool-only server behavior stable and backwards compatible.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#corrected-assumptions","title":"Corrected Assumptions","text":"<ul> <li>MCP versioning: target 2025-11-25 as the default protocol version in metatools-mcp and toolmodel. Back-compat shims should be explicit rather than implicit.</li> <li>Go SDK alignment: the official MCP Go SDK should be pinned to a version that explicitly supports the 2025-11-25 spec and its tool schema fields (icons, outputSchema, etc.).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#risks","title":"Risks","text":"<ul> <li>Notification spam: emitting list change notifications on every small index update could overwhelm clients. Mitigate with debouncing.</li> <li>Partial cancellation support: some backends may not support cancellation; document and expose that limitation.</li> <li>Scope creep: adding resources/prompts too early could delay core tool stability; keep those as a later PRD.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#recommended-next-steps","title":"Recommended Next Steps","text":"<ol> <li>Implement tool list change notifications tied to toolindex changes.</li> <li>Ensure pagination and cursor semantics are consistent across tool listing and search.</li> <li>Add cancellation/progress wiring and document limitations.</li> <li>Create a dedicated PRD for resources/prompts support.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#appendix-related-prd","title":"Appendix: Related PRD","text":"<p>See <code>docs/plans/2026-01-28-prd-015-mcp-spec-alignment.md</code> for an incremental implementation plan.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/","title":"Multi-Tenancy Extension for Pluggable Architecture","text":"<p>Status: Draft Date: 2026-01-28 Related: Pluggable Architecture Proposal</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#overview","title":"Overview","text":"<p>This document extends the pluggable architecture to support multi-tenancy in a flexible, pluggable way. The design allows different tenant isolation strategies without hardcoding any specific approach.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#multi-tenancy-architecture","title":"Multi-Tenancy Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#design-principles","title":"Design Principles","text":"<ol> <li>Pluggable Tenant Resolution - How tenants are identified (JWT, API key, header, etc.)</li> <li>Pluggable Isolation Strategy - Level of isolation between tenants</li> <li>Tenant-Aware Middleware - All middleware can access tenant context</li> <li>Tenant-Specific Configuration - Override any config per tenant</li> <li>Backward Compatible - Single-tenant mode works without changes</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       MULTI-TENANT MCP SERVER                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Incoming Request                                                           \u2502\n\u2502         \u2502                                                                     \u2502\n\u2502         \u25bc                                                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    TENANT RESOLUTION MIDDLEWARE                      \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502   \u2502    JWT      \u2502 \u2502   API Key   \u2502 \u2502   Header    \u2502 \u2502   Custom    \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502  Resolver   \u2502 \u2502  Resolver   \u2502 \u2502  Resolver   \u2502 \u2502  Resolver   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Output: Tenant Context injected into request context               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                             \u2502                                                \u2502\n\u2502                             \u25bc                                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    TENANT-AWARE MIDDLEWARE CHAIN                     \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502   \u2502\n\u2502   \u2502   \u2502 Tenant   \u2502\u2192\u2502 Tenant   \u2502\u2192\u2502 Tenant   \u2502\u2192\u2502 Tenant   \u2502               \u2502   \u2502\n\u2502   \u2502   \u2502 Scoped   \u2502 \u2502 Rate     \u2502 \u2502 Audit    \u2502 \u2502 Tool     \u2502               \u2502   \u2502\n\u2502   \u2502   \u2502 Config   \u2502 \u2502 Limits   \u2502 \u2502 Logging  \u2502 \u2502 Filter   \u2502               \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                             \u2502                                                \u2502\n\u2502                             \u25bc                                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    TENANT-SCOPED REGISTRIES                          \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502   \u2502\n\u2502   \u2502   \u2502  Shared Registry \u2502    \u2502  Tenant Registry \u2502                      \u2502   \u2502\n\u2502   \u2502   \u2502  (all tenants)   \u2502    \u2502  (tenant-only)   \u2502                      \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Tool visibility = Shared \u222a Tenant-specific - Denied               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#core-interfaces","title":"Core Interfaces","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-model","title":"Tenant Model","text":"<pre><code>// Tenant represents a tenant in the system\ntype Tenant struct {\n    ID          string            // Unique tenant identifier\n    Name        string            // Human-readable name\n    Tier        TenantTier        // free, pro, enterprise\n    Metadata    map[string]any    // Arbitrary tenant metadata\n    CreatedAt   time.Time\n    UpdatedAt   time.Time\n}\n\n// TenantTier defines service levels\ntype TenantTier string\n\nconst (\n    TenantTierFree       TenantTier = \"free\"\n    TenantTierPro        TenantTier = \"pro\"\n    TenantTierEnterprise TenantTier = \"enterprise\"\n)\n\n// TenantContext holds runtime tenant information\ntype TenantContext struct {\n    Tenant      *Tenant\n    Permissions []string          // Resolved permissions\n    Config      *TenantConfig     // Tenant-specific config overrides\n    Quotas      *TenantQuotas     // Current quota state\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-resolver-interface","title":"Tenant Resolver Interface","text":"<pre><code>// TenantResolver identifies the tenant from a request\ntype TenantResolver interface {\n    // Resolve extracts tenant information from the request context\n    // Returns nil tenant for anonymous/default tenant\n    Resolve(ctx context.Context, req *Request) (*TenantContext, error)\n}\n\n// TenantResolverFunc is a convenience type\ntype TenantResolverFunc func(ctx context.Context, req *Request) (*TenantContext, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#built-in-resolvers","title":"Built-in Resolvers","text":"<pre><code>// JWTTenantResolver extracts tenant from JWT claims\ntype JWTTenantResolver struct {\n    ClaimKey    string                    // JWT claim containing tenant ID\n    TenantStore TenantStore               // Lookup tenant details\n    Validator   JWTValidator              // Validate JWT\n}\n\nfunc (r *JWTTenantResolver) Resolve(ctx context.Context, req *Request) (*TenantContext, error) {\n    token := extractBearerToken(req)\n    claims, err := r.Validator.Validate(token)\n    if err != nil {\n        return nil, err\n    }\n\n    tenantID, ok := claims[r.ClaimKey].(string)\n    if !ok {\n        return nil, ErrNoTenantClaim\n    }\n\n    tenant, err := r.TenantStore.Get(ctx, tenantID)\n    if err != nil {\n        return nil, err\n    }\n\n    return &amp;TenantContext{\n        Tenant:      tenant,\n        Permissions: extractPermissions(claims),\n        Config:      r.TenantStore.GetConfig(ctx, tenantID),\n    }, nil\n}\n\n// APIKeyTenantResolver extracts tenant from API key\ntype APIKeyTenantResolver struct {\n    HeaderName  string       // Header containing API key\n    KeyStore    APIKeyStore  // Lookup key -&gt; tenant mapping\n}\n\n// HeaderTenantResolver extracts tenant from a header\ntype HeaderTenantResolver struct {\n    HeaderName  string\n    TenantStore TenantStore\n}\n\n// CompositeTenantResolver tries multiple resolvers in order\ntype CompositeTenantResolver struct {\n    Resolvers []TenantResolver\n}\n\nfunc (r *CompositeTenantResolver) Resolve(ctx context.Context, req *Request) (*TenantContext, error) {\n    for _, resolver := range r.Resolvers {\n        tc, err := resolver.Resolve(ctx, req)\n        if err == nil &amp;&amp; tc != nil {\n            return tc, nil\n        }\n    }\n    return nil, ErrNoTenantResolved\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-configuration","title":"Tenant Configuration","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-specific-config-overrides","title":"Tenant-Specific Config Overrides","text":"<pre><code>// TenantConfig holds per-tenant configuration overrides\ntype TenantConfig struct {\n    // Tool access control\n    AllowedTools     []string          // Whitelist (empty = all allowed)\n    DeniedTools      []string          // Blacklist (takes precedence)\n    AllowedBackends  []string          // Which backends tenant can use\n    DeniedBackends   []string          // Blacklisted backends\n\n    // Resource limits\n    RateLimits       *RateLimitConfig  // Override rate limits\n    Quotas           *QuotaConfig      // Usage quotas\n\n    // Feature flags\n    Features         map[string]bool   // Feature toggles\n\n    // Execution\n    MaxTimeout       time.Duration     // Max allowed timeout\n    MaxChainSteps    int               // Max chain steps\n    MaxToolCalls     int               // Max tool calls per request\n\n    // Custom middleware config\n    MiddlewareConfig map[string]any    // Per-middleware overrides\n}\n\n// QuotaConfig defines usage quotas\ntype QuotaConfig struct {\n    DailyRequests    int64             // Requests per day\n    DailyToolCalls   int64             // Tool calls per day\n    MonthlyRequests  int64             // Requests per month\n    MonthlyToolCalls int64             // Tool calls per month\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<pre><code># metatools.yaml - Multi-tenant configuration\n\ntenancy:\n  enabled: true\n\n  # Tenant resolution strategy\n  resolver:\n    type: composite\n    resolvers:\n      - type: jwt\n        claim_key: tenant_id\n        issuer: https://auth.example.com\n      - type: api_key\n        header: X-API-Key\n      - type: header\n        header: X-Tenant-ID\n\n  # Default tenant (anonymous requests)\n  default_tenant:\n    id: default\n    tier: free\n    config:\n      rate_limits:\n        requests_per_minute: 10\n      allowed_tools:\n        - search_tools\n        - describe_tool\n      denied_tools:\n        - execute_code\n\n  # Tier-based defaults\n  tiers:\n    free:\n      rate_limits:\n        requests_per_minute: 60\n        burst: 10\n      quotas:\n        daily_requests: 1000\n        monthly_requests: 10000\n      denied_tools:\n        - execute_code\n      max_chain_steps: 3\n\n    pro:\n      rate_limits:\n        requests_per_minute: 300\n        burst: 50\n      quotas:\n        daily_requests: 10000\n        monthly_requests: 100000\n      max_chain_steps: 10\n\n    enterprise:\n      rate_limits:\n        requests_per_minute: 1000\n        burst: 200\n      quotas:\n        daily_requests: -1  # unlimited\n        monthly_requests: -1\n      max_chain_steps: 50\n      features:\n        custom_backends: true\n        audit_logging: true\n\n# Per-tenant overrides (loaded from store or config)\ntenants:\n  acme-corp:\n    tier: enterprise\n    config:\n      allowed_backends:\n        - local\n        - github\n        - jira\n      features:\n        execute_code: true\n      middleware_config:\n        audit:\n          destination: elasticsearch\n          index: acme-audit\n\n  startup-xyz:\n    tier: pro\n    config:\n      rate_limits:\n        requests_per_minute: 500  # Override pro default\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-aware-middleware","title":"Tenant-Aware Middleware","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-context-middleware","title":"Tenant Context Middleware","text":"<pre><code>// TenantMiddleware resolves and injects tenant context\nfunc TenantMiddleware(resolver TenantResolver) Middleware {\n    return func(next ToolProvider) ToolProvider {\n        return &amp;tenantMiddleware{\n            resolver: resolver,\n            next:     next,\n        }\n    }\n}\n\ntype tenantMiddleware struct {\n    resolver TenantResolver\n    next     ToolProvider\n}\n\nfunc (m *tenantMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    // Resolve tenant from context (set by transport layer)\n    req := RequestFromContext(ctx)\n    tc, err := m.resolver.Resolve(ctx, req)\n    if err != nil {\n        return nil, &amp;TenantError{Op: \"resolve\", Err: err}\n    }\n\n    // Inject tenant context\n    ctx = WithTenantContext(ctx, tc)\n\n    return m.next.Handle(ctx, input)\n}\n\n// Context helpers\nfunc WithTenantContext(ctx context.Context, tc *TenantContext) context.Context\nfunc TenantFromContext(ctx context.Context) *TenantContext\nfunc TenantIDFromContext(ctx context.Context) string\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-aware-rate-limiting","title":"Tenant-Aware Rate Limiting","text":"<pre><code>// TenantRateLimitMiddleware applies per-tenant rate limits\ntype TenantRateLimitMiddleware struct {\n    store    RateLimitStore\n    defaults RateLimitConfig\n    next     ToolProvider\n}\n\nfunc (m *TenantRateLimitMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    tc := TenantFromContext(ctx)\n\n    // Get tenant-specific limits or tier defaults\n    limits := m.resolveLimits(tc)\n\n    // Check rate limit\n    key := fmt.Sprintf(\"tenant:%s:tool:%s\", tc.Tenant.ID, m.next.Name())\n    allowed, err := m.store.Allow(ctx, key, limits)\n    if err != nil {\n        return nil, err\n    }\n    if !allowed {\n        return nil, &amp;RateLimitError{\n            TenantID: tc.Tenant.ID,\n            Limit:    limits.RequestsPerMinute,\n        }\n    }\n\n    return m.next.Handle(ctx, input)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-tool-filter","title":"Tenant Tool Filter","text":"<pre><code>// TenantToolFilterMiddleware filters tools based on tenant permissions\ntype TenantToolFilterMiddleware struct {\n    next ToolProvider\n}\n\nfunc (m *TenantToolFilterMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    tc := TenantFromContext(ctx)\n    toolName := m.next.Name()\n\n    // Check denied tools first (takes precedence)\n    if slices.Contains(tc.Config.DeniedTools, toolName) {\n        return nil, &amp;ToolDeniedError{\n            TenantID: tc.Tenant.ID,\n            Tool:     toolName,\n            Reason:   \"tool denied for tenant\",\n        }\n    }\n\n    // Check allowed tools (if whitelist is non-empty)\n    if len(tc.Config.AllowedTools) &gt; 0 {\n        if !slices.Contains(tc.Config.AllowedTools, toolName) {\n            return nil, &amp;ToolDeniedError{\n                TenantID: tc.Tenant.ID,\n                Tool:     toolName,\n                Reason:   \"tool not in allowed list\",\n            }\n        }\n    }\n\n    return m.next.Handle(ctx, input)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-audit-middleware","title":"Tenant Audit Middleware","text":"<pre><code>// TenantAuditMiddleware logs all actions with tenant context\ntype TenantAuditMiddleware struct {\n    logger AuditLogger\n    next   ToolProvider\n}\n\nfunc (m *TenantAuditMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    tc := TenantFromContext(ctx)\n    start := time.Now()\n\n    result, err := m.next.Handle(ctx, input)\n\n    m.logger.Log(AuditEntry{\n        Timestamp:  time.Now(),\n        TenantID:   tc.Tenant.ID,\n        TenantTier: string(tc.Tenant.Tier),\n        Tool:       m.next.Name(),\n        Input:      input,\n        Success:    err == nil,\n        Duration:   time.Since(start),\n        RequestID:  RequestIDFromContext(ctx),\n        UserID:     UserIDFromContext(ctx),\n    })\n\n    return result, err\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-scoped-registries","title":"Tenant-Scoped Registries","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#multi-tenant-tool-registry","title":"Multi-Tenant Tool Registry","text":"<pre><code>// MultiTenantRegistry wraps a base registry with tenant scoping\ntype MultiTenantRegistry struct {\n    shared        *provider.Registry  // Shared tools (all tenants)\n    tenantTools   map[string]*provider.Registry  // Tenant-specific tools\n    tenantStore   TenantStore\n    mu            sync.RWMutex\n}\n\n// GetForTenant returns a tenant-scoped view of the registry\nfunc (r *MultiTenantRegistry) GetForTenant(tenantID string) *TenantScopedRegistry {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    tenant, _ := r.tenantStore.Get(context.Background(), tenantID)\n    tenantReg := r.tenantTools[tenantID]\n\n    return &amp;TenantScopedRegistry{\n        tenant:   tenant,\n        shared:   r.shared,\n        specific: tenantReg,\n    }\n}\n\n// TenantScopedRegistry provides a tenant's view of available tools\ntype TenantScopedRegistry struct {\n    tenant   *Tenant\n    shared   *provider.Registry\n    specific *provider.Registry\n}\n\n// All returns all tools visible to the tenant\nfunc (r *TenantScopedRegistry) All() []provider.ToolProvider {\n    var result []provider.ToolProvider\n\n    // Add shared tools (filtered by tenant config)\n    for _, p := range r.shared.All() {\n        if r.isToolAllowed(p.Name()) {\n            result = append(result, p)\n        }\n    }\n\n    // Add tenant-specific tools\n    if r.specific != nil {\n        result = append(result, r.specific.All()...)\n    }\n\n    return result\n}\n\nfunc (r *TenantScopedRegistry) isToolAllowed(name string) bool {\n    if r.tenant == nil || r.tenant.Config == nil {\n        return true\n    }\n\n    cfg := r.tenant.Config\n\n    // Check denied list first\n    if slices.Contains(cfg.DeniedTools, name) {\n        return false\n    }\n\n    // Check allowed list (if specified)\n    if len(cfg.AllowedTools) &gt; 0 {\n        return slices.Contains(cfg.AllowedTools, name)\n    }\n\n    return true\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#multi-tenant-backend-registry","title":"Multi-Tenant Backend Registry","text":"<pre><code>// MultiTenantBackendRegistry manages tenant-scoped backends\ntype MultiTenantBackendRegistry struct {\n    shared        *backend.Registry\n    tenantBackends map[string]*backend.Registry\n    mu            sync.RWMutex\n}\n\n// GetForTenant returns backends available to a tenant\nfunc (r *MultiTenantBackendRegistry) GetForTenant(ctx context.Context, tenantID string) *TenantScopedBackendRegistry {\n    tc := TenantFromContext(ctx)\n\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    return &amp;TenantScopedBackendRegistry{\n        tenant:   tc,\n        shared:   r.shared,\n        specific: r.tenantBackends[tenantID],\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#isolation-strategies","title":"Isolation Strategies","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#strategy-1-shared-infrastructure-default","title":"Strategy 1: Shared Infrastructure (Default)","text":"<p>All tenants share the same server instance with logical isolation via middleware.</p> <pre><code>tenancy:\n  isolation: shared\n  # All tenants use same tool/backend registries\n  # Isolation via rate limits, tool filtering, audit logging\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    SHARED INFRASTRUCTURE                          \u2502\n\u2502                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n\u2502   \u2502Tenant A \u2502 \u2502Tenant B \u2502 \u2502Tenant C \u2502                           \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                           \u2502\n\u2502        \u2502           \u2502           \u2502                                 \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                 \u2502\n\u2502                    \u2502                                              \u2502\n\u2502                    \u25bc                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502              SHARED MCP SERVER INSTANCE                  \u2502   \u2502\n\u2502   \u2502                                                           \u2502   \u2502\n\u2502   \u2502   Tenant Middleware \u2192 Tool Filter \u2192 Rate Limit \u2192 Audit   \u2502   \u2502\n\u2502   \u2502                                                           \u2502   \u2502\n\u2502   \u2502   Shared Tool Registry + Tenant Configs                  \u2502   \u2502\n\u2502   \u2502                                                           \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#strategy-2-namespace-isolation","title":"Strategy 2: Namespace Isolation","text":"<p>Tenants have isolated namespaces within shared infrastructure.</p> <pre><code>tenancy:\n  isolation: namespace\n  # Each tenant gets own tool namespace prefix\n  # Tenant A sees: tenant-a:*, shared:*\n  # Tenant B sees: tenant-b:*, shared:*\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    NAMESPACE ISOLATION                            \u2502\n\u2502                                                                   \u2502\n\u2502   Tenant A View:              Tenant B View:                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502   \u2502 shared:*        \u2502        \u2502 shared:*        \u2502                \u2502\n\u2502   \u2502 tenant-a:*      \u2502        \u2502 tenant-b:*      \u2502                \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2502                                                                   \u2502\n\u2502   Backend Routing:                                               \u2502\n\u2502   shared:* \u2192 Shared backends                                     \u2502\n\u2502   tenant-a:* \u2192 Tenant A's backends                              \u2502\n\u2502   tenant-b:* \u2192 Tenant B's backends                              \u2502\n\u2502                                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#strategy-3-process-isolation","title":"Strategy 3: Process Isolation","text":"<p>Each tenant gets a dedicated server process.</p> <pre><code>tenancy:\n  isolation: process\n  # Tenant requests routed to dedicated processes\n  # Maximum isolation, higher resource usage\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PROCESS ISOLATION                              \u2502\n\u2502                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502  Tenant A   \u2502        \u2502  Tenant B   \u2502        \u2502  Tenant C   \u2502 \u2502\n\u2502   \u2502   Process   \u2502        \u2502   Process   \u2502        \u2502   Process   \u2502 \u2502\n\u2502   \u2502             \u2502        \u2502             \u2502        \u2502             \u2502 \u2502\n\u2502   \u2502 Own config  \u2502        \u2502 Own config  \u2502        \u2502 Own config  \u2502 \u2502\n\u2502   \u2502 Own tools   \u2502        \u2502 Own tools   \u2502        \u2502 Own tools   \u2502 \u2502\n\u2502   \u2502 Own backends\u2502        \u2502 Own backends\u2502        \u2502 Own backends\u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502          \u2502                      \u2502                      \u2502         \u2502\n\u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                              \u2502                                    \u2502\n\u2502                              \u25bc                                    \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    TENANT ROUTER                         \u2502   \u2502\n\u2502   \u2502          (Load balancer / API Gateway)                   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-storage","title":"Tenant Storage","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenantstore-interface","title":"TenantStore Interface","text":"<pre><code>// TenantStore manages tenant data\ntype TenantStore interface {\n    // CRUD\n    Get(ctx context.Context, id string) (*Tenant, error)\n    Create(ctx context.Context, tenant *Tenant) error\n    Update(ctx context.Context, tenant *Tenant) error\n    Delete(ctx context.Context, id string) error\n    List(ctx context.Context, opts ListOptions) ([]*Tenant, error)\n\n    // Config\n    GetConfig(ctx context.Context, id string) (*TenantConfig, error)\n    UpdateConfig(ctx context.Context, id string, cfg *TenantConfig) error\n\n    // Quotas\n    GetQuotaUsage(ctx context.Context, id string) (*QuotaUsage, error)\n    IncrementUsage(ctx context.Context, id string, metric string, delta int64) error\n}\n\n// Built-in implementations\ntype MemoryTenantStore struct { ... }      // For testing/development\ntype RedisTenantStore struct { ... }       // For distributed deployments\ntype PostgresTenantStore struct { ... }    // For persistent storage\ntype ConfigFileTenantStore struct { ... }  // For static configuration\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#end-to-end-example","title":"End-to-End Example","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#enterprise-saas-configuration","title":"Enterprise SaaS Configuration","text":"<pre><code># metatools-saas.yaml\n\nserver:\n  name: \"metatools-saas\"\n  version: \"1.0.0\"\n\ntransport:\n  type: sse\n  http:\n    port: 8080\n\ntenancy:\n  enabled: true\n\n  resolver:\n    type: composite\n    resolvers:\n      - type: jwt\n        issuer: https://auth.saas.example.com\n        claim_key: org_id\n      - type: api_key\n        header: X-API-Key\n\n  store:\n    type: postgres\n    postgres:\n      connection_string: ${DATABASE_URL}\n\n  isolation: shared\n\n  tiers:\n    free:\n      rate_limits:\n        requests_per_minute: 30\n      quotas:\n        daily_requests: 500\n      denied_tools:\n        - execute_code\n        - run_chain\n\n    startup:\n      rate_limits:\n        requests_per_minute: 120\n      quotas:\n        daily_requests: 5000\n      max_chain_steps: 5\n\n    enterprise:\n      rate_limits:\n        requests_per_minute: 1000\n      quotas:\n        daily_requests: -1\n      features:\n        custom_backends: true\n        dedicated_support: true\n\nmiddleware:\n  chain:\n    - tenant          # Resolve tenant first\n    - tenant_config   # Load tenant-specific config\n    - tenant_filter   # Filter tools by tenant permissions\n    - tenant_rate_limit\n    - tenant_quota\n    - tenant_audit\n    - logging\n    - metrics\n\nbackends:\n  shared:\n    github:\n      enabled: true\n      kind: mcp\n      config:\n        command: npx\n        args: [\"-y\", \"@modelcontextprotocol/server-github\"]\n\n    filesystem:\n      enabled: true\n      kind: mcp\n      config:\n        command: npx\n        args: [\"-y\", \"@modelcontextprotocol/server-filesystem\"]\n\n  # Enterprise tenants can have custom backends\n  # Loaded from tenant config in database\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#request-flow","title":"Request Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    MULTI-TENANT REQUEST FLOW                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   1. INCOMING REQUEST                                                        \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  POST /mcp HTTP/1.1                                                 \u2502   \u2502\n\u2502   \u2502  Authorization: Bearer eyJhbGc...                                  \u2502   \u2502\n\u2502   \u2502  X-API-Key: key_abc123 (fallback)                                  \u2502   \u2502\n\u2502   \u2502                                                                     \u2502   \u2502\n\u2502   \u2502  { \"method\": \"tools/call\", \"params\": { \"name\": \"github/...\" } }   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502   2. TENANT RESOLUTION                                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  JWT Resolver:                                                      \u2502   \u2502\n\u2502   \u2502  - Validate token                                                   \u2502   \u2502\n\u2502   \u2502  - Extract org_id: \"acme-corp\"                                     \u2502   \u2502\n\u2502   \u2502  - Load tenant from store                                          \u2502   \u2502\n\u2502   \u2502  - Inject TenantContext into ctx                                   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502   TenantContext:                     \u2502                                       \u2502\n\u2502   - ID: \"acme-corp\"                  \u2502                                       \u2502\n\u2502   - Tier: \"enterprise\"               \u2502                                       \u2502\n\u2502   - Config: { allowed_backends: [...], features: {...} }                    \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502   3. TENANT TOOL FILTER                                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  Check: Is \"github/create_issue\" allowed for acme-corp?            \u2502   \u2502\n\u2502   \u2502  - Not in denied_tools \u2713                                           \u2502   \u2502\n\u2502   \u2502  - github backend is in allowed_backends \u2713                         \u2502   \u2502\n\u2502   \u2502  \u2192 ALLOWED                                                          \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502   4. TENANT RATE LIMIT                                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  Key: \"tenant:acme-corp:tool:github/create_issue\"                  \u2502   \u2502\n\u2502   \u2502  Limit: 1000 req/min (enterprise tier)                             \u2502   \u2502\n\u2502   \u2502  Current: 42 \u2192 ALLOWED                                             \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502   5. EXECUTION (with tenant context)                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  Route to: github backend                                          \u2502   \u2502\n\u2502   \u2502  Execute: create_issue                                             \u2502   \u2502\n\u2502   \u2502  Tenant-scoped audit log written                                   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502   6. RESPONSE                                                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  { \"result\": { \"issue_number\": 456 }, \"id\": \"req-123\" }           \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#implementation-priority","title":"Implementation Priority","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#phase-1-core-multi-tenancy-2-weeks","title":"Phase 1: Core Multi-Tenancy (2 weeks)","text":"<ol> <li>Define <code>Tenant</code>, <code>TenantContext</code>, <code>TenantConfig</code> types</li> <li>Implement <code>TenantResolver</code> interface + JWT/API Key resolvers</li> <li>Implement <code>TenantMiddleware</code> for context injection</li> <li>Add <code>TenantFromContext()</code> helper</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#phase-2-tenant-aware-middleware-1-week","title":"Phase 2: Tenant-Aware Middleware (1 week)","text":"<ol> <li>Implement <code>TenantRateLimitMiddleware</code></li> <li>Implement <code>TenantToolFilterMiddleware</code></li> <li>Implement <code>TenantAuditMiddleware</code></li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#phase-3-tenant-storage-1-week","title":"Phase 3: Tenant Storage (1 week)","text":"<ol> <li>Define <code>TenantStore</code> interface</li> <li>Implement <code>MemoryTenantStore</code> for development</li> <li>Implement <code>PostgresTenantStore</code> for production</li> <li>Add quota tracking</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#phase-4-advanced-features-2-weeks","title":"Phase 4: Advanced Features (2 weeks)","text":"<ol> <li>Multi-tenant tool registry</li> <li>Multi-tenant backend registry</li> <li>Namespace isolation strategy</li> <li>Process isolation strategy (optional)</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#changes-to-component-libraries","title":"Changes to Component Libraries","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#toolrun-changes","title":"toolrun Changes","text":"<pre><code>// Add tenant context propagation\ntype RunOptions struct {\n    // Existing...\n    TenantID string  // NEW: Tenant context for execution\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#toolindex-changes","title":"toolindex Changes","text":"<pre><code>// Add tenant-scoped search\ntype Index interface {\n    // Existing...\n    SearchForTenant(tenantID string, query string, limit int) ([]Summary, error)  // NEW\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#summary","title":"Summary","text":"<p>Multi-tenancy integrates cleanly into the pluggable architecture via:</p> <ol> <li>Pluggable TenantResolver - Any identification strategy</li> <li>Tenant-Aware Middleware - Transparent isolation via middleware chain</li> <li>Tenant-Scoped Registries - Logical isolation of tools/backends</li> <li>Configuration Hierarchy - Defaults \u2192 Tier \u2192 Tenant overrides</li> <li>Multiple Isolation Strategies - Shared, namespace, or process isolation</li> </ol> <p>All components remain pluggable and can be replaced or extended.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#changelog","title":"Changelog","text":"Date Change 2026-01-28 Initial multi-tenancy extension proposal"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/","title":"Persistence Boundary Architecture","text":"<p>Status: Draft Date: 2026-01-30 Related: Auth Middleware, Multi-Tenancy, Pluggable Architecture</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#overview","title":"Overview","text":"<p>This document defines the boundary between interface contracts (in core libs/packages) and persistence implementations (in metatools-mcp internal packages). The principle: interfaces define HOW to store, implementations define WHERE to store.</p> <p>Pluggability is achieved through interfaces + dependency injection, not library separation. Implementations live in <code>metatools-mcp/internal/</code> with build tags for optional backends.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#design-principle","title":"Design Principle","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         PERSISTENCE BOUNDARY                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   CORE LIBS / PACKAGES (interfaces)         metatools-mcp/internal/          \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500         \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500      \u2502\n\u2502                                                                               \u2502\n\u2502   toolindex                                 internal/persist/                 \u2502\n\u2502     Index interface \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192   index_memory.go                \u2502\n\u2502     Searcher interface                        index_postgres.go (+build)     \u2502\n\u2502                                               index_sqlite.go (+build)       \u2502\n\u2502                                                                               \u2502\n\u2502   tooldocs                                                                   \u2502\n\u2502     Store interface \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192   docs_memory.go                 \u2502\n\u2502                                               docs_postgres.go (+build)      \u2502\n\u2502                                               docs_file.go                   \u2502\n\u2502                                                                               \u2502\n\u2502   internal/auth                                                              \u2502\n\u2502     APIKeyStore interface \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192   apikey_memory.go               \u2502\n\u2502     TokenStore interface                      apikey_redis.go (+build)       \u2502\n\u2502     KeyProvider interface                     apikey_postgres.go (+build)    \u2502\n\u2502                                                                               \u2502\n\u2502   internal/tenant                                                            \u2502\n\u2502     TenantStore interface \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192   tenant_memory.go               \u2502\n\u2502     QuotaStore interface                      tenant_postgres.go (+build)    \u2502\n\u2502     RateLimitStore interface                  ratelimit_redis.go (+build)    \u2502\n\u2502                                                                               \u2502\n\u2502   internal/cache                                                             \u2502\n\u2502     Cache interface \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192   cache_memory.go                \u2502\n\u2502                                               cache_redis.go (+build)        \u2502\n\u2502                                                                               \u2502\n\u2502   internal/vector (future)                                                   \u2502\n\u2502     VectorIndex interface \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192   vector_pgvector.go (+build)    \u2502\n\u2502     Embedder interface                        vector_qdrant.go (+build)      \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#why-not-a-separate-library","title":"Why Not a Separate Library?","text":"<p>A separate <code>toolpersist</code> library was considered but rejected:</p> Separate Library Internal Packages Extra repo to maintain Single codebase Complex versioning Simple build tags Public API surface Internal, hidden Overkill for single consumer Right-sized <p>Pluggability comes from interfaces, not library separation.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#interface-contracts-core-libraries","title":"Interface Contracts (Core Libraries)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#1-toolindex-registry-interface","title":"1. toolindex - Registry Interface","text":"<pre><code>// toolindex/index.go (already exists, validated)\n\n// Index is the core contract for tool registration and lookup.\n// Implementations may be in-memory, file-backed, or database-backed.\ntype Index interface {\n    // Register adds a tool to the index\n    Register(ctx context.Context, tool Tool) error\n\n    // Unregister removes a tool from the index\n    Unregister(ctx context.Context, id string) error\n\n    // Get retrieves a tool by ID\n    Get(ctx context.Context, id string) (Tool, error)\n\n    // List returns all tools matching the filter\n    List(ctx context.Context, filter Filter) ([]Tool, error)\n\n    // Search finds tools matching the query\n    Search(ctx context.Context, query string, opts SearchOptions) ([]SearchResult, error)\n}\n\n// Searcher is the pluggable search strategy interface.\n// Allows swapping BM25, semantic, or hybrid search without changing Index.\ntype Searcher interface {\n    Search(ctx context.Context, query string, tools []Tool, opts SearchOptions) ([]SearchResult, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#2-tooldocs-documentation-store-interface","title":"2. tooldocs - Documentation Store Interface","text":"<pre><code>// tooldocs/store.go (already exists, validated)\n\n// Store is the contract for tool documentation storage.\n// The interface supports tiered disclosure (summary \u2192 schema \u2192 full).\ntype Store interface {\n    // Get retrieves documentation for a tool\n    Get(ctx context.Context, toolID string, level DisclosureLevel) (*Documentation, error)\n\n    // Set stores documentation for a tool\n    Set(ctx context.Context, toolID string, doc *Documentation) error\n\n    // Delete removes documentation for a tool\n    Delete(ctx context.Context, toolID string) error\n\n    // List returns all tool IDs with documentation\n    List(ctx context.Context) ([]string, error)\n}\n\n// DisclosureLevel controls documentation detail\ntype DisclosureLevel int\n\nconst (\n    LevelSummary DisclosureLevel = iota // Name + description\n    LevelSchema                          // + input/output schema\n    LevelFull                            // + examples, related tools\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#3-toolcache-cache-interface-new","title":"3. toolcache - Cache Interface (NEW)","text":"<pre><code>// toolcache/cache.go - Interface contract\n\n// Cache is the contract for response caching.\n// Implementations: MemoryCache, RedisCache, etc.\ntype Cache interface {\n    // Get retrieves a cached value\n    Get(ctx context.Context, key string) ([]byte, bool, error)\n\n    // Set stores a value with TTL\n    Set(ctx context.Context, key string, value []byte, ttl time.Duration) error\n\n    // Delete removes a cached value\n    Delete(ctx context.Context, key string) error\n\n    // Clear removes all cached values\n    Clear(ctx context.Context) error\n\n    // Stats returns cache statistics\n    Stats(ctx context.Context) (*CacheStats, error)\n}\n\n// CacheStats provides cache metrics\ntype CacheStats struct {\n    Hits       int64\n    Misses     int64\n    Size       int64\n    MaxSize    int64\n    Evictions  int64\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#4-auth-stores-authentication-persistence-interfaces","title":"4. Auth Stores - Authentication Persistence Interfaces","text":"<pre><code>// internal/auth/stores.go - Interface contracts\n\n// APIKeyStore retrieves and validates API keys.\n// Implementations: Memory (testing), Redis (distributed), Postgres (persistent)\ntype APIKeyStore interface {\n    // Lookup returns the identity for an API key\n    Lookup(ctx context.Context, key string) (*APIKeyInfo, error)\n\n    // Create stores a new API key\n    Create(ctx context.Context, info *APIKeyInfo) error\n\n    // Revoke invalidates an API key\n    Revoke(ctx context.Context, keyID string) error\n\n    // List returns all API keys for a principal/tenant\n    List(ctx context.Context, filter APIKeyFilter) ([]*APIKeyInfo, error)\n\n    // UpdateLastUsed records key usage\n    UpdateLastUsed(ctx context.Context, keyID string, at time.Time) error\n}\n\n// TokenStore manages opaque tokens (for OAuth2 introspection caching).\ntype TokenStore interface {\n    // Get retrieves cached token info\n    Get(ctx context.Context, token string) (*TokenInfo, bool, error)\n\n    // Set caches token info\n    Set(ctx context.Context, token string, info *TokenInfo, ttl time.Duration) error\n\n    // Invalidate removes a token from cache\n    Invalidate(ctx context.Context, token string) error\n}\n\n// KeyProvider fetches signing keys for JWT validation.\ntype KeyProvider interface {\n    // GetKey returns the key for the given key ID\n    GetKey(ctx context.Context, keyID string) (any, error)\n\n    // GetKeys returns all available keys\n    GetKeys(ctx context.Context) ([]any, error)\n}\n\n// SessionStore manages user sessions (optional).\ntype SessionStore interface {\n    // Create starts a new session\n    Create(ctx context.Context, identity *Identity) (*Session, error)\n\n    // Get retrieves a session\n    Get(ctx context.Context, sessionID string) (*Session, error)\n\n    // Refresh extends session expiry\n    Refresh(ctx context.Context, sessionID string) error\n\n    // Destroy ends a session\n    Destroy(ctx context.Context, sessionID string) error\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#5-tenant-stores-multi-tenancy-persistence-interfaces","title":"5. Tenant Stores - Multi-Tenancy Persistence Interfaces","text":"<pre><code>// internal/tenant/stores.go - Interface contracts\n\n// TenantStore manages tenant configuration and metadata.\ntype TenantStore interface {\n    // Get retrieves tenant configuration\n    Get(ctx context.Context, tenantID string) (*Tenant, error)\n\n    // Create registers a new tenant\n    Create(ctx context.Context, tenant *Tenant) error\n\n    // Update modifies tenant configuration\n    Update(ctx context.Context, tenant *Tenant) error\n\n    // Delete removes a tenant\n    Delete(ctx context.Context, tenantID string) error\n\n    // List returns all tenants matching filter\n    List(ctx context.Context, filter TenantFilter) ([]*Tenant, error)\n}\n\n// QuotaStore tracks resource usage against quotas.\ntype QuotaStore interface {\n    // GetUsage returns current usage for a tenant\n    GetUsage(ctx context.Context, tenantID string) (*QuotaUsage, error)\n\n    // Increment adds to usage counter\n    Increment(ctx context.Context, tenantID string, resource string, amount int64) error\n\n    // Reset clears usage (e.g., at billing period)\n    Reset(ctx context.Context, tenantID string) error\n\n    // CheckQuota returns error if quota would be exceeded\n    CheckQuota(ctx context.Context, tenantID string, resource string, amount int64) error\n}\n\n// RateLimitStore tracks rate limit state.\ntype RateLimitStore interface {\n    // Allow checks if request is within rate limit\n    Allow(ctx context.Context, key string, limit RateLimit) (bool, error)\n\n    // GetState returns current rate limit state\n    GetState(ctx context.Context, key string) (*RateLimitState, error)\n}\n\n// AuditLogger records audit events.\ntype AuditLogger interface {\n    // Log records an audit event\n    Log(ctx context.Context, event *AuditEvent) error\n\n    // Query retrieves audit events\n    Query(ctx context.Context, filter AuditFilter) ([]*AuditEvent, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#6-toolsemantic-vector-search-interfaces-new","title":"6. toolsemantic - Vector Search Interfaces (NEW)","text":"<pre><code>// toolsemantic/interfaces.go - Interface contracts\n\n// VectorIndex stores and searches vector embeddings.\n// Implementations: PgVector, Qdrant, Chroma, Pinecone, etc.\ntype VectorIndex interface {\n    // Index stores a vector embedding\n    Index(ctx context.Context, id string, vector []float32, metadata map[string]any) error\n\n    // Search finds similar vectors\n    Search(ctx context.Context, vector []float32, opts VectorSearchOptions) ([]VectorResult, error)\n\n    // Delete removes a vector\n    Delete(ctx context.Context, id string) error\n\n    // BatchIndex stores multiple vectors\n    BatchIndex(ctx context.Context, items []VectorItem) error\n}\n\n// Embedder generates vector embeddings from text.\n// Implementations: OpenAI, Cohere, local models, etc.\ntype Embedder interface {\n    // Embed generates embedding for text\n    Embed(ctx context.Context, text string) ([]float32, error)\n\n    // EmbedBatch generates embeddings for multiple texts\n    EmbedBatch(ctx context.Context, texts []string) ([][]float32, error)\n\n    // Dimensions returns the embedding dimension\n    Dimensions() int\n}\n\n// Reranker reorders search results by relevance.\n// Implementations: Cohere, cross-encoder, etc.\ntype Reranker interface {\n    // Rerank reorders results by relevance to query\n    Rerank(ctx context.Context, query string, results []RerankCandidate) ([]RerankResult, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#directory-structure","title":"Directory Structure","text":"<p>All implementations live in <code>metatools-mcp/internal/</code>:</p> <pre><code>metatools-mcp/\n\u251c\u2500\u2500 internal/\n\u2502   \u251c\u2500\u2500 auth/\n\u2502   \u2502   \u251c\u2500\u2500 authenticator.go       # Authenticator interface\n\u2502   \u2502   \u251c\u2500\u2500 authorizer.go          # Authorizer interface\n\u2502   \u2502   \u251c\u2500\u2500 identity.go            # Identity types\n\u2502   \u2502   \u251c\u2500\u2500 jwt.go                 # JWT implementation\n\u2502   \u2502   \u251c\u2500\u2500 apikey.go              # APIKeyStore interface + memory impl\n\u2502   \u2502   \u251c\u2500\u2500 apikey_redis.go        # +build redis\n\u2502   \u2502   \u251c\u2500\u2500 apikey_postgres.go     # +build postgres\n\u2502   \u2502   \u2514\u2500\u2500 rbac.go                # Simple RBAC authorizer\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 tenant/\n\u2502   \u2502   \u251c\u2500\u2500 store.go               # TenantStore interface\n\u2502   \u2502   \u251c\u2500\u2500 store_memory.go        # Memory implementation\n\u2502   \u2502   \u251c\u2500\u2500 store_postgres.go      # +build postgres\n\u2502   \u2502   \u251c\u2500\u2500 quota.go               # QuotaStore interface\n\u2502   \u2502   \u251c\u2500\u2500 quota_memory.go        # Memory implementation\n\u2502   \u2502   \u251c\u2500\u2500 quota_redis.go         # +build redis\n\u2502   \u2502   \u251c\u2500\u2500 ratelimit.go           # RateLimitStore interface\n\u2502   \u2502   \u2514\u2500\u2500 ratelimit_redis.go     # +build redis\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 cache/\n\u2502   \u2502   \u251c\u2500\u2500 cache.go               # Cache interface\n\u2502   \u2502   \u251c\u2500\u2500 memory.go              # LRU memory cache\n\u2502   \u2502   \u2514\u2500\u2500 redis.go               # +build redis\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 persist/\n\u2502   \u2502   \u251c\u2500\u2500 index_memory.go        # toolindex.Index memory impl\n\u2502   \u2502   \u251c\u2500\u2500 index_postgres.go      # +build postgres\n\u2502   \u2502   \u251c\u2500\u2500 index_sqlite.go        # +build sqlite\n\u2502   \u2502   \u251c\u2500\u2500 docs_memory.go         # tooldocs.Store memory impl\n\u2502   \u2502   \u251c\u2500\u2500 docs_postgres.go       # +build postgres\n\u2502   \u2502   \u2514\u2500\u2500 docs_file.go           # File-based implementation\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 vector/                    # Future: semantic search\n\u2502       \u251c\u2500\u2500 index.go               # VectorIndex interface\n\u2502       \u251c\u2500\u2500 embedder.go            # Embedder interface\n\u2502       \u251c\u2500\u2500 pgvector.go            # +build pgvector\n\u2502       \u2514\u2500\u2500 qdrant.go              # +build qdrant\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#build-tags","title":"Build Tags","text":"<p>Optional backends use Go build tags:</p> <pre><code>//go:build redis\n\npackage cache\n\nimport \"github.com/redis/go-redis/v9\"\n\ntype RedisCache struct {\n    client *redis.Client\n}\n</code></pre> <p>Build commands:</p> <pre><code># Default build (memory only)\ngo build ./cmd/metatools\n\n# With Redis support\ngo build -tags redis ./cmd/metatools\n\n# With PostgreSQL support\ngo build -tags postgres ./cmd/metatools\n\n# Full build (all backends)\ngo build -tags \"redis,postgres,sqlite\" ./cmd/metatools\n</code></pre> <p>Benefits: - Memory implementations always available (zero dependencies) - Optional backends don't bloat binary size - Clear opt-in for heavy dependencies (pgx, redis client) - Single codebase, no library sprawl</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#dependency-injection-pattern","title":"Dependency Injection Pattern","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#factory-registration","title":"Factory Registration","text":"<pre><code>// internal/persist/registry.go\n\npackage persist\n\n// StoreType identifies a persistence backend\ntype StoreType string\n\nconst (\n    StoreMemory   StoreType = \"memory\"\n    StoreRedis    StoreType = \"redis\"\n    StorePostgres StoreType = \"postgres\"\n    StoreSQLite   StoreType = \"sqlite\"\n)\n\n// Registry holds factory functions for persistence implementations\ntype Registry struct {\n    mu       sync.RWMutex\n    index    map[StoreType]IndexFactory\n    docs     map[StoreType]DocStoreFactory\n    cache    map[StoreType]CacheFactory\n}\n\n// IndexFactory creates Index implementations\ntype IndexFactory func(cfg map[string]any) (toolindex.Index, error)\n\n// DocStoreFactory creates DocStore implementations\ntype DocStoreFactory func(cfg map[string]any) (tooldocs.Store, error)\n\n// CacheFactory creates Cache implementations\ntype CacheFactory func(cfg map[string]any) (Cache, error)\n\n// DefaultRegistry is the global factory registry\nvar DefaultRegistry = NewRegistry()\n\nfunc init() {\n    // Memory implementations always registered\n    DefaultRegistry.RegisterIndex(StoreMemory, NewMemoryIndex)\n    DefaultRegistry.RegisterDocStore(StoreMemory, NewMemoryDocStore)\n    DefaultRegistry.RegisterCache(StoreMemory, NewMemoryCache)\n}\n</code></pre> <p>Build-tagged files register their implementations:</p> <pre><code>//go:build postgres\n\n// internal/persist/index_postgres.go\npackage persist\n\nfunc init() {\n    DefaultRegistry.RegisterIndex(StorePostgres, NewPostgresIndex)\n    DefaultRegistry.RegisterDocStore(StorePostgres, NewPostgresDocStore)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#configuration-driven-initialization","title":"Configuration-Driven Initialization","text":"<pre><code># metatools.yaml\n\npersistence:\n  # Tool index storage\n  index:\n    type: postgres  # memory, redis, postgres, sqlite\n    config:\n      connection_string: ${DATABASE_URL}\n      table_prefix: \"metatools_\"\n\n  # Documentation storage\n  docs:\n    type: postgres\n    config:\n      connection_string: ${DATABASE_URL}\n\n  # Response cache\n  cache:\n    type: redis\n    config:\n      address: localhost:6379\n      prefix: \"cache:\"\n\n  # API key storage\n  api_keys:\n    type: postgres\n    config:\n      connection_string: ${DATABASE_URL}\n\n  # Tenant storage\n  tenants:\n    type: postgres\n    config:\n      connection_string: ${DATABASE_URL}\n\n  # Vector index (for semantic search)\n  vectors:\n    type: pgvector\n    config:\n      connection_string: ${DATABASE_URL}\n      dimensions: 1536\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#runtime-initialization","title":"Runtime Initialization","text":"<pre><code>// cmd/metatools/persistence.go\n\npackage main\n\nimport (\n    \"github.com/jonwraymond/metatools-mcp/internal/persist\"\n    \"github.com/jonwraymond/metatools-mcp/internal/cache\"\n    \"github.com/jonwraymond/metatools-mcp/internal/auth\"\n)\n\nfunc initPersistence(cfg *config.Config) (*PersistenceLayer, error) {\n    // Create index (uses registry populated by build tags)\n    indexFactory, ok := persist.DefaultRegistry.GetIndex(persist.StoreType(cfg.Persistence.Index.Type))\n    if !ok {\n        return nil, fmt.Errorf(\"unknown index type: %s (did you build with correct tags?)\", cfg.Persistence.Index.Type)\n    }\n    idx, err := indexFactory(cfg.Persistence.Index.Config)\n    if err != nil {\n        return nil, fmt.Errorf(\"create index: %w\", err)\n    }\n\n    // Create doc store\n    docsFactory, ok := persist.DefaultRegistry.GetDocStore(persist.StoreType(cfg.Persistence.Docs.Type))\n    if !ok {\n        return nil, fmt.Errorf(\"unknown docs type: %s\", cfg.Persistence.Docs.Type)\n    }\n    docs, err := docsFactory(cfg.Persistence.Docs.Config)\n    if err != nil {\n        return nil, fmt.Errorf(\"create docs: %w\", err)\n    }\n\n    // Create cache\n    cacheImpl, err := cache.New(cfg.Cache.Type, cfg.Cache.Config)\n    if err != nil {\n        return nil, fmt.Errorf(\"create cache: %w\", err)\n    }\n\n    return &amp;PersistenceLayer{\n        Index: idx,\n        Docs:  docs,\n        Cache: cacheImpl,\n    }, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#migration-path","title":"Migration Path","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#phase-1-define-interfaces-current","title":"Phase 1: Define Interfaces (Current)","text":"<ol> <li>Validate existing interfaces in toolindex, tooldocs</li> <li>Add Cache interface to internal/cache</li> <li>Add auth store interfaces to internal/auth</li> <li>Add tenant store interfaces to internal/tenant</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#phase-2-memory-implementations","title":"Phase 2: Memory Implementations","text":"<ol> <li>Create internal/persist/ with memory implementations</li> <li>Create internal/cache/ with LRU memory cache</li> <li>Add factory registry pattern</li> <li>Wire into existing handlers</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#phase-3-add-optional-backends-build-tags","title":"Phase 3: Add Optional Backends (Build Tags)","text":"<ol> <li>Redis implementations (cache, rate limit, api keys) - <code>+build redis</code></li> <li>PostgreSQL implementations (index, docs, tenants) - <code>+build postgres</code></li> <li>SQLite implementations (embedded deployments) - <code>+build sqlite</code></li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#phase-4-configuration-cli","title":"Phase 4: Configuration &amp; CLI","text":"<ol> <li>Add persistence configuration section to metatools.yaml</li> <li>Add CLI flags for common options (<code>--cache-type=redis</code>)</li> <li>Initialize via factory registry at startup</li> <li>Document build tag requirements</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#benefits","title":"Benefits","text":"<ol> <li>Single codebase - No extra libraries to maintain</li> <li>Testability - Memory implementations always available</li> <li>Flexibility - Swap backends via config without code changes</li> <li>Optional dependencies - Build tags exclude heavy deps (pgx, redis)</li> <li>Clear contracts - Interfaces define exactly what's needed</li> <li>Right-sized binary - Only compiled backends are included</li> <li>Internal implementations - Not part of public API surface</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#interface-location-summary","title":"Interface Location Summary","text":"Interface Location Purpose <code>Index</code> toolindex Tool registration/lookup <code>Searcher</code> toolindex Pluggable search strategy <code>Store</code> (docs) tooldocs Documentation storage <code>Cache</code> internal/cache Response caching <code>APIKeyStore</code> internal/auth API key persistence <code>TokenStore</code> internal/auth OAuth token caching <code>KeyProvider</code> internal/auth JWT key fetching <code>TenantStore</code> internal/tenant Tenant configuration <code>QuotaStore</code> internal/tenant Quota tracking <code>RateLimitStore</code> internal/tenant Rate limit state <code>AuditLogger</code> internal/audit Audit logging <code>VectorIndex</code> internal/vector Vector embeddings (future) <code>Embedder</code> internal/vector Text\u2192vector (future)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#implementation-location-summary","title":"Implementation Location Summary","text":"Implementation Location Build Tag MemoryIndex internal/persist/index_memory.go (none) PostgresIndex internal/persist/index_postgres.go <code>postgres</code> SQLiteIndex internal/persist/index_sqlite.go <code>sqlite</code> MemoryCache internal/cache/memory.go (none) RedisCache internal/cache/redis.go <code>redis</code> MemoryAPIKeyStore internal/auth/apikey.go (none) RedisAPIKeyStore internal/auth/apikey_redis.go <code>redis</code> PostgresAPIKeyStore internal/auth/apikey_postgres.go <code>postgres</code>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#changelog","title":"Changelog","text":"Date Change 2026-01-30 Initial persistence boundary architecture 2026-01-30 Simplified: removed toolpersist library, use internal packages with build tags"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/","title":"Pluggable Architecture Proposal","text":"<p>Status: Draft Date: 2026-01-27 Author: Jon Raymond</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#executive-summary","title":"Executive Summary","text":"<p>This proposal outlines a pluggable, modular architecture for metatools-mcp that enables: - Multiple transport protocols (stdio, HTTP/SSE, WebSocket) - Plug-and-play tool providers - Configurable search strategies - Extensible backend registries - Cross-cutting middleware</p> <p>The design leverages Go's interface-based composition, build-tag gating, and configuration-driven initialization to create a flexible framework while maintaining the clean, canonical core.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Motivation</li> <li>Current Architecture Analysis</li> <li>Proposed Architecture</li> <li>Extension Points</li> <li>Transport Layer</li> <li>Search Strategy</li> <li>Tool Provider Registry</li> <li>Backend Registry</li> <li>Middleware Chain</li> <li>Cache Layer</li> <li>Additional Cross-Cutting Concerns</li> <li>Multi-Backend Architecture</li> <li>Configuration Design</li> <li>Implementation Approach</li> <li>End-to-End Examples</li> <li>Enterprise AI Assistant</li> <li>Local Development Setup</li> <li>Multi-LLM Tool Router</li> <li>Microservices Tool Mesh</li> <li>Request Flow Diagram</li> <li>Comparative Analysis</li> <li>References</li> <li>Architecture Validation</li> <li>Implementation Phases</li> <li>Component Library Analysis</li> <li>Multi-Tenancy Extension</li> <li>Extension Point Catalog</li> <li>Revised Implementation Timeline</li> <li>Architecture Evaluation</li> <li>Protocol-Agnostic Tools</li> <li>Versioning Strategy</li> <li>Multi-Language Extensibility</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#motivation","title":"Motivation","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#goals","title":"Goals","text":"<ol> <li>Multi-transport support - Run as stdio MCP server (current) or HTTP/SSE server (high availability)</li> <li>Plug-and-play extensibility - Add new tools, backends, and search strategies without modifying core</li> <li>Configuration-driven - YAML/JSON config files with environment variable overrides</li> <li>Framework potential - Enable metatools-mcp as a reusable framework for building MCP servers</li> <li>Multi-language support - Enable components in Python, Rust, TypeScript via standardized interface contracts</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#non-goals","title":"Non-Goals","text":"<ul> <li>Go's native plugin package (platform limitations; use gRPC/WASM instead)</li> <li>Breaking changes to existing tool* library interfaces</li> <li>Over-engineering for hypothetical future requirements</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#current-architecture-analysis","title":"Current Architecture Analysis","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#strengths-85-pluggable","title":"Strengths (85% Pluggable)","text":"<p>The existing architecture demonstrates excellent patterns:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      MCP Server (SDK)                           \u2502\n\u2502           metatools-mcp/internal/server/server.go               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Adapter Layer                                 \u2502\n\u2502  - IndexAdapter (toolindex \u2192 handlers.Index)                    \u2502\n\u2502  - DocsAdapter (tooldocs \u2192 handlers.Store)                      \u2502\n\u2502  - RunnerAdapter (toolrun \u2192 handlers.Runner)                    \u2502\n\u2502  - ExecutorAdapter (toolcode \u2192 handlers.Executor)               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Handlers Layer                                 \u2502\n\u2502  - SearchHandler, DescribeHandler, RunHandler, ChainHandler    \u2502\n\u2502  - CodeHandler (optional), ExamplesHandler, NamespacesHandler  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Core Tool Libraries                                 \u2502\n\u2502  toolindex, tooldocs, toolrun, toolcode, toolruntime, toolsearch\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>What works well: - Clean interface contracts (<code>handlers/interfaces.go</code>) - Adapter pattern prevents library leakage - Build-tag gating for optional features (<code>toolsearch</code>, <code>toolruntime</code>) - Configuration-driven bootstrap (<code>internal/config/env.go</code>) - Stateless handlers with dependency injection</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#gap-monolithic-tool-registration","title":"Gap: Monolithic Tool Registration","text":"<p>The primary gap is in <code>server.registerTools()</code> (~200 lines):</p> <pre><code>// Current: Hard-coded tool list\nfunc (s *Server) registerTools() {\n    s.addTool(\"search_tools\", ...)    // inline schema\n    s.addTool(\"describe_tool\", ...)   // inline schema\n    s.addTool(\"run_tool\", ...)        // inline schema\n    // ... 7 tools total\n}\n</code></pre> <p>This requires code changes to add new tools.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#proposed-architecture","title":"Proposed Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#five-layer-design","title":"Five-Layer Design","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    METATOOLS-MCP FRAMEWORK                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                 TRANSPORT LAYER                              \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502 \u2502\n\u2502  \u2502  \u2502  stdio  \u2502  \u2502  SSE    \u2502  \u2502  HTTP   \u2502  \u2502  gRPC   \u2502        \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518        \u2502 \u2502\n\u2502  \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502 \u2502\n\u2502  \u2502                        \u2193                                     \u2502 \u2502\n\u2502  \u2502               transport.Transport interface                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                             \u2193                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                  MIDDLEWARE CHAIN                            \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502 \u2502\n\u2502  \u2502  \u2502 Logging  \u2502\u2192\u2502  Auth    \u2502\u2192\u2502  Rate    \u2502\u2192\u2502  Cache   \u2502       \u2502 \u2502\n\u2502  \u2502  \u2502          \u2502 \u2502          \u2502 \u2502  Limit   \u2502 \u2502          \u2502       \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                             \u2193                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502               TOOL PROVIDER REGISTRY                         \u2502 \u2502\n\u2502  \u2502                                                               \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502 \u2502\n\u2502  \u2502  \u2502 search_tools \u2502 \u2502 describe_    \u2502 \u2502 run_tool     \u2502         \u2502 \u2502\n\u2502  \u2502  \u2502              \u2502 \u2502 tool         \u2502 \u2502              \u2502         \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502 \u2502\n\u2502  \u2502  \u2502 run_chain    \u2502 \u2502 execute_code \u2502 \u2502 [custom...]  \u2502         \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                             \u2193                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502              CORE SERVICES (Tool Libraries)                  \u2502 \u2502\n\u2502  \u2502                                                               \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502 \u2502\n\u2502  \u2502  \u2502   toolindex    \u2502  \u2502   tooldocs     \u2502                     \u2502 \u2502\n\u2502  \u2502  \u2502  (Registry)    \u2502  \u2502  (Disclosure)  \u2502                     \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502 \u2502\n\u2502  \u2502  \u2502   toolrun      \u2502  \u2502   toolcode     \u2502                     \u2502 \u2502\n\u2502  \u2502  \u2502  (Execution)   \u2502  \u2502 (Orchestration)\u2502                     \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                             \u2193                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502               BACKEND REGISTRY                               \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502 \u2502\n\u2502  \u2502  \u2502  local  \u2502  \u2502 openai  \u2502  \u2502  azure  \u2502  \u2502  mcp    \u2502        \u2502 \u2502\n\u2502  \u2502  \u2502handlers \u2502  \u2502   api   \u2502  \u2502   api   \u2502  \u2502 servers \u2502        \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#core-interfaces","title":"Core Interfaces","text":"<pre><code>// Transport abstraction (enables stdio/SSE/HTTP)\ntype Transport interface {\n    Serve(ctx context.Context, handler RequestHandler) error\n}\n\n// Tool provider (enables plug-and-play tools)\ntype ToolProvider interface {\n    Name() string\n    Tool() *mcp.Tool\n    Handle(ctx context.Context, input []byte) (any, error)\n}\n\n// Middleware (enables cross-cutting concerns)\ntype Middleware func(ToolProvider) ToolProvider\n\n// Backend registry (enables tool sources)\ntype BackendRegistry interface {\n    Register(kind string, backend Backend)\n    Get(kind string) (Backend, bool)\n    List() []string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#extension-points","title":"Extension Points","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#1-transport-layer","title":"1. Transport Layer","text":"<p>The transport layer abstracts how MCP clients connect to the server. This enables the same tool logic to be exposed via multiple protocols.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         TRANSPORT LAYER                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502                              MCP CLIENTS                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502   \u2502   Claude    \u2502  \u2502   Cursor    \u2502  \u2502  Web App    \u2502  \u2502   Custom    \u2502        \u2502\n\u2502   \u2502   Desktop   \u2502  \u2502    IDE      \u2502  \u2502  Frontend   \u2502  \u2502   Client    \u2502        \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502          \u2502                \u2502                \u2502                \u2502                \u2502\n\u2502          \u2502 stdio          \u2502 stdio          \u2502 HTTP/SSE       \u2502 gRPC          \u2502\n\u2502          \u2502                \u2502                \u2502                \u2502                \u2502\n\u2502          \u25bc                \u25bc                \u25bc                \u25bc                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                     TRANSPORT REGISTRY                               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502   \u2502\n\u2502   \u2502   \u2502   STDIO   \u2502  \u2502    SSE    \u2502  \u2502   HTTP    \u2502  \u2502   gRPC    \u2502        \u2502   \u2502\n\u2502   \u2502   \u2502 Transport \u2502  \u2502 Transport \u2502  \u2502 Transport \u2502  \u2502 Transport \u2502        \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518        \u2502   \u2502\n\u2502   \u2502         \u2502              \u2502              \u2502              \u2502               \u2502   \u2502\n\u2502   \u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502                              \u25bc                                        \u2502   \u2502\n\u2502   \u2502                    transport.Transport                                \u2502   \u2502\n\u2502   \u2502                       interface                                       \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                   \u2502                                          \u2502\n\u2502                                   \u25bc                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    MCP REQUEST HANDLER                               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Unified handler processes all requests regardless of transport    \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#the-transport-interface","title":"The Transport Interface","text":"<pre><code>// Transport defines how MCP clients connect to the server\ntype Transport interface {\n    // Name returns the transport identifier (e.g., \"stdio\", \"sse\")\n    Name() string\n\n    // Serve starts the transport and blocks until ctx is cancelled\n    Serve(ctx context.Context, handler RequestHandler) error\n\n    // Close gracefully shuts down the transport\n    Close() error\n\n    // Info returns runtime information about the transport\n    Info() TransportInfo\n}\n\n// RequestHandler processes incoming MCP requests\ntype RequestHandler interface {\n    HandleRequest(ctx context.Context, req *mcp.Request) (*mcp.Response, error)\n}\n\n// TransportInfo provides runtime details\ntype TransportInfo struct {\n    Name      string            // Transport name\n    Listening bool              // Is it accepting connections?\n    Address   string            // Listening address (for network transports)\n    Metadata  map[string]string // Additional info\n}\n\n// TransportFactory creates configured transport instances\ntype TransportFactory func(cfg TransportConfig) (Transport, error)\n\n// TransportRegistry manages available transports\ntype TransportRegistry struct {\n    transports map[string]TransportFactory\n}\n\nfunc (r *TransportRegistry) Register(name string, factory TransportFactory) {\n    r.transports[name] = factory\n}\n\nfunc (r *TransportRegistry) Create(cfg TransportConfig) (Transport, error) {\n    factory, ok := r.transports[cfg.Type]\n    if !ok {\n        return nil, fmt.Errorf(\"unknown transport: %s\", cfg.Type)\n    }\n    return factory(cfg)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#transport-types","title":"Transport Types","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#1-stdio-transport-current-default","title":"1. Stdio Transport (Current Default)","text":"<p>For MCP clients that spawn the server as a subprocess.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          STDIO TRANSPORT                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502      MCP Client       \u2502         \u2502    metatools-mcp      \u2502               \u2502\n\u2502   \u2502   (Claude, Cursor)    \u2502         \u2502       server          \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   Spawns process \u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Started as child    \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   stdin  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Reads JSON-RPC      \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   stdout \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502   Writes JSON-RPC     \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                               \u2502\n\u2502   Characteristics:                                                           \u2502\n\u2502   - Single client per process                                               \u2502\n\u2502   - Process lifecycle tied to client                                        \u2502\n\u2502   - No network configuration needed                                         \u2502\n\u2502   - Ideal for desktop MCP clients                                           \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Implementation:                                                             \u2502\n\u2502                                                                               \u2502\n\u2502  type StdioTransport struct {                                               \u2502\n\u2502      reader  io.Reader  // os.Stdin                                         \u2502\n\u2502      writer  io.Writer  // os.Stdout                                        \u2502\n\u2502      decoder *json.Decoder                                                  \u2502\n\u2502      encoder *json.Encoder                                                  \u2502\n\u2502  }                                                                           \u2502\n\u2502                                                                               \u2502\n\u2502  func (t *StdioTransport) Serve(ctx context.Context, h RequestHandler)      \u2502\n\u2502      error {                                                                \u2502\n\u2502      for {                                                                  \u2502\n\u2502          select {                                                           \u2502\n\u2502          case &lt;-ctx.Done():                                                 \u2502\n\u2502              return ctx.Err()                                               \u2502\n\u2502          default:                                                           \u2502\n\u2502              var req mcp.Request                                            \u2502\n\u2502              if err := t.decoder.Decode(&amp;req); err != nil {                 \u2502\n\u2502                  return err                                                 \u2502\n\u2502              }                                                              \u2502\n\u2502              resp, err := h.HandleRequest(ctx, &amp;req)                        \u2502\n\u2502              if err := t.encoder.Encode(resp); err != nil {                 \u2502\n\u2502                  return err                                                 \u2502\n\u2502              }                                                              \u2502\n\u2502          }                                                                  \u2502\n\u2502      }                                                                      \u2502\n\u2502  }                                                                           \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                                                     \u2502\n\u2502    transport:                                                               \u2502\n\u2502      type: stdio                                                            \u2502\n\u2502      # No additional config needed                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#2-sse-transport-server-sent-events","title":"2. SSE Transport (Server-Sent Events)","text":"<p>For web-based MCP clients using the Streamable HTTP protocol.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           SSE TRANSPORT                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502     Web Browser       \u2502         \u2502    metatools-mcp      \u2502               \u2502\n\u2502   \u2502    or HTTP Client     \u2502         \u2502       server          \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   POST /mcp \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Handle request      \u2502               \u2502\n\u2502   \u2502   (JSON-RPC request)  \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   SSE stream \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502   Stream response     \u2502               \u2502\n\u2502   \u2502   (chunked events)    \u2502         \u2502   via SSE             \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                               \u2502\n\u2502   HTTP Endpoints:                                                            \u2502\n\u2502   - POST /mcp           \u2192 Submit MCP request, receive SSE stream            \u2502\n\u2502   - GET  /mcp/sse       \u2192 Establish SSE connection for server push          \u2502\n\u2502   - GET  /health        \u2192 Health check endpoint                              \u2502\n\u2502   - GET  /ready         \u2192 Readiness probe                                   \u2502\n\u2502                                                                               \u2502\n\u2502   Characteristics:                                                           \u2502\n\u2502   - Multiple concurrent clients                                             \u2502\n\u2502   - Stateless (each request independent)                                    \u2502\n\u2502   - Web-friendly (works through firewalls/proxies)                          \u2502\n\u2502   - Supports streaming responses                                            \u2502\n\u2502   - Can be load balanced                                                    \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Request/Response Flow:                                                      \u2502\n\u2502                                                                               \u2502\n\u2502  Client                              Server                                  \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502    \u2502  POST /mcp                        \u2502                                     \u2502\n\u2502    \u2502  Content-Type: application/json   \u2502                                     \u2502\n\u2502    \u2502  Accept: text/event-stream        \u2502                                     \u2502\n\u2502    \u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   \u2502                                     \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502    \u2502  HTTP/1.1 200 OK                  \u2502                                     \u2502\n\u2502    \u2502  Content-Type: text/event-stream  \u2502                                     \u2502\n\u2502    \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502                                     \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502    \u2502  event: message                   \u2502                                     \u2502\n\u2502    \u2502  data: {\"jsonrpc\":\"2.0\",...}      \u2502                                     \u2502\n\u2502    \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502                                     \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502    \u2502  event: message                   \u2502                                     \u2502\n\u2502    \u2502  data: {\"jsonrpc\":\"2.0\",...}      \u2502  (streaming)                       \u2502\n\u2502    \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502                                     \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502    \u2502  event: done                      \u2502                                     \u2502\n\u2502    \u2502  data: {}                         \u2502                                     \u2502\n\u2502    \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502                                     \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                                                     \u2502\n\u2502    transport:                                                               \u2502\n\u2502      type: sse                                                              \u2502\n\u2502      http:                                                                  \u2502\n\u2502        host: \"0.0.0.0\"                                                     \u2502\n\u2502        port: 8080                                                          \u2502\n\u2502        base_path: /mcp                                                     \u2502\n\u2502        cors:                                                               \u2502\n\u2502          enabled: true                                                     \u2502\n\u2502          origins: [\"https://app.example.com\"]                             \u2502\n\u2502        tls:                                                                \u2502\n\u2502          enabled: true                                                     \u2502\n\u2502          cert: /etc/ssl/cert.pem                                          \u2502\n\u2502          key: /etc/ssl/key.pem                                            \u2502\n\u2502        timeouts:                                                           \u2502\n\u2502          read: 30s                                                         \u2502\n\u2502          write: 60s                                                        \u2502\n\u2502          idle: 120s                                                        \u2502\n\u2502        keepalive: 30s                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#3-http-transport-rest-style","title":"3. HTTP Transport (REST-style)","text":"<p>For simple request/response without streaming.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          HTTP TRANSPORT                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Endpoints:                                                                 \u2502\n\u2502                                                                               \u2502\n\u2502   POST /mcp/tools/list                                                       \u2502\n\u2502   \u251c\u2500 Request:  {}                                                            \u2502\n\u2502   \u2514\u2500 Response: { \"tools\": [...] }                                           \u2502\n\u2502                                                                               \u2502\n\u2502   POST /mcp/tools/call                                                       \u2502\n\u2502   \u251c\u2500 Request:  { \"name\": \"search_tools\", \"arguments\": {...} }               \u2502\n\u2502   \u2514\u2500 Response: { \"content\": [...] }                                         \u2502\n\u2502                                                                               \u2502\n\u2502   GET /mcp/tools/:name                                                       \u2502\n\u2502   \u2514\u2500 Response: { \"name\": \"...\", \"description\": \"...\", \"inputSchema\": {...}} \u2502\n\u2502                                                                               \u2502\n\u2502   Characteristics:                                                           \u2502\n\u2502   - Simple request/response                                                  \u2502\n\u2502   - No streaming support                                                    \u2502\n\u2502   - Easy to debug with curl                                                 \u2502\n\u2502   - Good for simple integrations                                            \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                                                     \u2502\n\u2502    transport:                                                               \u2502\n\u2502      type: http                                                             \u2502\n\u2502      http:                                                                  \u2502\n\u2502        host: \"0.0.0.0\"                                                     \u2502\n\u2502        port: 8080                                                          \u2502\n\u2502        base_path: /mcp                                                     \u2502\n\u2502        # Same TLS/timeout options as SSE                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#4-websocket-transport","title":"4. WebSocket Transport","text":"<p>For bidirectional real-time communication.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        WEBSOCKET TRANSPORT                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502       Client          \u2502         \u2502    metatools-mcp      \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502       server          \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   WS Connect \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Accept connection   \u2502               \u2502\n\u2502   \u2502   ws://host/mcp/ws    \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   \u2502               \u2502\n\u2502   \u2502      Bidirectional    \u2502         \u2502   Full duplex         \u2502               \u2502\n\u2502   \u2502      JSON-RPC         \u2502         \u2502   messaging           \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                               \u2502\n\u2502   Characteristics:                                                           \u2502\n\u2502   - Full duplex communication                                               \u2502\n\u2502   - Server can push notifications                                           \u2502\n\u2502   - Lower latency than HTTP                                                 \u2502\n\u2502   - Persistent connection                                                   \u2502\n\u2502   - Good for real-time applications                                         \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                                                     \u2502\n\u2502    transport:                                                               \u2502\n\u2502      type: websocket                                                        \u2502\n\u2502      websocket:                                                             \u2502\n\u2502        host: \"0.0.0.0\"                                                     \u2502\n\u2502        port: 8080                                                          \u2502\n\u2502        path: /mcp/ws                                                       \u2502\n\u2502        ping_interval: 30s                                                  \u2502\n\u2502        pong_timeout: 10s                                                   \u2502\n\u2502        max_message_size: 1MB                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#5-grpc-transport","title":"5. gRPC Transport","text":"<p>For high-performance, strongly-typed RPC.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          gRPC TRANSPORT                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Protocol Buffer Definition:                                                \u2502\n\u2502                                                                               \u2502\n\u2502   service MCPService {                                                       \u2502\n\u2502     rpc ListTools(ListToolsRequest) returns (ListToolsResponse);            \u2502\n\u2502     rpc CallTool(CallToolRequest) returns (CallToolResponse);               \u2502\n\u2502     rpc CallToolStream(CallToolRequest) returns (stream ToolEvent);         \u2502\n\u2502   }                                                                          \u2502\n\u2502                                                                               \u2502\n\u2502   Characteristics:                                                           \u2502\n\u2502   - High performance (binary protocol)                                       \u2502\n\u2502   - Strong typing via protobuf                                              \u2502\n\u2502   - Bidirectional streaming                                                 \u2502\n\u2502   - Built-in load balancing                                                 \u2502\n\u2502   - Good for service-to-service communication                               \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                                                     \u2502\n\u2502    transport:                                                               \u2502\n\u2502      type: grpc                                                             \u2502\n\u2502      grpc:                                                                  \u2502\n\u2502        host: \"0.0.0.0\"                                                     \u2502\n\u2502        port: 9090                                                          \u2502\n\u2502        tls:                                                                \u2502\n\u2502          enabled: true                                                     \u2502\n\u2502          cert: /etc/ssl/cert.pem                                          \u2502\n\u2502          key: /etc/ssl/key.pem                                            \u2502\n\u2502          client_ca: /etc/ssl/ca.pem  # For mTLS                           \u2502\n\u2502        reflection: true  # Enable gRPC reflection                          \u2502\n\u2502        max_recv_msg_size: 4MB                                              \u2502\n\u2502        max_send_msg_size: 4MB                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#multi-transport-support","title":"Multi-Transport Support","text":"<p>Run multiple transports simultaneously:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      MULTI-TRANSPORT ARCHITECTURE                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    METATOOLS-MCP SERVER                              \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502   \u2502\n\u2502   \u2502   \u2502   STDIO     \u2502 \u2502    SSE      \u2502 \u2502    gRPC     \u2502                   \u2502   \u2502\n\u2502   \u2502   \u2502  Transport  \u2502 \u2502  Transport  \u2502 \u2502  Transport  \u2502                   \u2502   \u2502\n\u2502   \u2502   \u2502             \u2502 \u2502  :8080      \u2502 \u2502  :9090      \u2502                   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502   \u2502\n\u2502   \u2502          \u2502               \u2502               \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502   \u2502\n\u2502   \u2502                          \u2502                                            \u2502   \u2502\n\u2502   \u2502                          \u25bc                                            \u2502   \u2502\n\u2502   \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502   \u2502\n\u2502   \u2502          \u2502     SHARED REQUEST HANDLER    \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2502                               \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2502   All transports share the    \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2502   same middleware, tools,     \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2502   and backend registries      \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2502                               \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2502   Config:                                                                    \u2502\n\u2502     transports:                                                             \u2502\n\u2502       - type: stdio                                                         \u2502\n\u2502         enabled: true                                                       \u2502\n\u2502                                                                               \u2502\n\u2502       - type: sse                                                           \u2502\n\u2502         enabled: true                                                       \u2502\n\u2502         http:                                                               \u2502\n\u2502           port: 8080                                                        \u2502\n\u2502                                                                               \u2502\n\u2502       - type: grpc                                                          \u2502\n\u2502         enabled: true                                                       \u2502\n\u2502         grpc:                                                               \u2502\n\u2502           port: 9090                                                        \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementing-custom-transports","title":"Implementing Custom Transports","text":"<pre><code>// Example: Unix socket transport for local high-performance IPC\ntype UnixSocketTransport struct {\n    path     string\n    listener net.Listener\n    handler  RequestHandler\n}\n\nfunc NewUnixSocketTransport(cfg TransportConfig) (Transport, error) {\n    return &amp;UnixSocketTransport{\n        path: cfg.UnixSocket.Path,\n    }, nil\n}\n\nfunc (t *UnixSocketTransport) Name() string {\n    return \"unix\"\n}\n\nfunc (t *UnixSocketTransport) Serve(ctx context.Context, h RequestHandler) error {\n    t.handler = h\n\n    var err error\n    t.listener, err = net.Listen(\"unix\", t.path)\n    if err != nil {\n        return err\n    }\n\n    go func() {\n        &lt;-ctx.Done()\n        t.listener.Close()\n    }()\n\n    for {\n        conn, err := t.listener.Accept()\n        if err != nil {\n            if ctx.Err() != nil {\n                return nil // Graceful shutdown\n            }\n            return err\n        }\n        go t.handleConnection(ctx, conn)\n    }\n}\n\nfunc (t *UnixSocketTransport) handleConnection(ctx context.Context, conn net.Conn) {\n    defer conn.Close()\n    decoder := json.NewDecoder(conn)\n    encoder := json.NewEncoder(conn)\n\n    for {\n        var req mcp.Request\n        if err := decoder.Decode(&amp;req); err != nil {\n            return\n        }\n        resp, _ := t.handler.HandleRequest(ctx, &amp;req)\n        if err := encoder.Encode(resp); err != nil {\n            return\n        }\n    }\n}\n\nfunc (t *UnixSocketTransport) Close() error {\n    if t.listener != nil {\n        return t.listener.Close()\n    }\n    return nil\n}\n\nfunc (t *UnixSocketTransport) Info() TransportInfo {\n    return TransportInfo{\n        Name:      \"unix\",\n        Listening: t.listener != nil,\n        Address:   t.path,\n    }\n}\n\n// Register the custom transport\nfunc init() {\n    transport.Register(\"unix\", NewUnixSocketTransport)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#high-availability-configuration","title":"High Availability Configuration","text":"<p>For production deployments with HTTP/SSE transport:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    HIGH AVAILABILITY DEPLOYMENT                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                       LOAD BALANCER                                  \u2502   \u2502\n\u2502   \u2502                    (nginx, HAProxy, ALB)                             \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   - TLS termination                                                  \u2502   \u2502\n\u2502   \u2502   - Health checks                                                    \u2502   \u2502\n\u2502   \u2502   - Round-robin / least-connections                                 \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                    \u2502                \u2502                \u2502                       \u2502\n\u2502                    \u25bc                \u25bc                \u25bc                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502   \u2502   metatools-mcp    \u2502 \u2502   metatools-mcp    \u2502 \u2502   metatools-mcp    \u2502     \u2502\n\u2502   \u2502    instance 1      \u2502 \u2502    instance 2      \u2502 \u2502    instance 3      \u2502     \u2502\n\u2502   \u2502                    \u2502 \u2502                    \u2502 \u2502                    \u2502     \u2502\n\u2502   \u2502  SSE :8080         \u2502 \u2502  SSE :8080         \u2502 \u2502  SSE :8080         \u2502     \u2502\n\u2502   \u2502  gRPC :9090        \u2502 \u2502  gRPC :9090        \u2502 \u2502  gRPC :9090        \u2502     \u2502\n\u2502   \u2502                    \u2502 \u2502                    \u2502 \u2502                    \u2502     \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502             \u2502                      \u2502                      \u2502                 \u2502\n\u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                                    \u2502                                         \u2502\n\u2502                                    \u25bc                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      SHARED STATE (Optional)                         \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   - Redis for rate limiting                                          \u2502   \u2502\n\u2502   \u2502   - Redis for caching                                                \u2502   \u2502\n\u2502   \u2502   - Shared tool registry (if dynamic)                               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Kubernetes-ready configuration\ntransport:\n  type: sse\n  http:\n    host: \"0.0.0.0\"\n    port: 8080\n\n    # Health endpoints for k8s probes\n    health:\n      enabled: true\n      liveness_path: /healthz\n      readiness_path: /ready\n\n    # Graceful shutdown\n    shutdown:\n      timeout: 30s\n      drain_connections: true\n\n    # TLS (or terminate at ingress)\n    tls:\n      enabled: false  # Terminated at ingress\n\nmiddleware:\n  rate_limit:\n    enabled: true\n    storage: redis\n    redis:\n      address: redis:6379\n\n  cache:\n    enabled: true\n    backend: redis\n    redis:\n      address: redis:6379\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cli-integration","title":"CLI Integration","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          CLI SUBCOMMANDS                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502  metatools stdio                                                             \u2502\n\u2502  \u2514\u2500 Run as stdio server (default, for MCP clients)                          \u2502\n\u2502                                                                               \u2502\n\u2502  metatools serve                                                             \u2502\n\u2502  \u2514\u2500 Run as HTTP/SSE server                                                  \u2502\n\u2502  \u2514\u2500 Options:                                                                \u2502\n\u2502       --port 8080          HTTP port                                        \u2502\n\u2502       --grpc-port 9090     gRPC port (optional)                            \u2502\n\u2502       --tls                Enable TLS                                       \u2502\n\u2502       --cert FILE          TLS certificate                                  \u2502\n\u2502       --key FILE           TLS key                                          \u2502\n\u2502                                                                               \u2502\n\u2502  metatools serve --multi                                                     \u2502\n\u2502  \u2514\u2500 Run all enabled transports from config                                  \u2502\n\u2502                                                                               \u2502\n\u2502  metatools version                                                           \u2502\n\u2502  \u2514\u2500 Print version and exit                                                  \u2502\n\u2502                                                                               \u2502\n\u2502  metatools validate                                                          \u2502\n\u2502  \u2514\u2500 Validate configuration file                                             \u2502\n\u2502                                                                               \u2502\n\u2502  metatools tools list                                                        \u2502\n\u2502  \u2514\u2500 List all registered tools (from all backends)                          \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#transport-configuration-summary","title":"Transport Configuration Summary","text":"<pre><code># Complete transport configuration example\ntransports:\n  # Stdio for MCP desktop clients\n  - type: stdio\n    enabled: true\n\n  # SSE for web clients\n  - type: sse\n    enabled: true\n    http:\n      host: \"0.0.0.0\"\n      port: 8080\n      base_path: /mcp\n      cors:\n        enabled: true\n        origins: [\"*\"]\n        methods: [\"GET\", \"POST\", \"OPTIONS\"]\n        headers: [\"Content-Type\", \"Authorization\"]\n      tls:\n        enabled: true\n        cert: /etc/ssl/certs/server.crt\n        key: /etc/ssl/private/server.key\n      timeouts:\n        read: 30s\n        write: 60s\n        idle: 120s\n      health:\n        enabled: true\n        liveness_path: /healthz\n        readiness_path: /ready\n\n  # WebSocket for real-time apps\n  - type: websocket\n    enabled: false\n    websocket:\n      host: \"0.0.0.0\"\n      port: 8081\n      path: /ws\n\n  # gRPC for service-to-service\n  - type: grpc\n    enabled: false\n    grpc:\n      host: \"0.0.0.0\"\n      port: 9090\n      reflection: true\n\n  # Unix socket for local IPC\n  - type: unix\n    enabled: false\n    unix:\n      path: /var/run/metatools.sock\n      permissions: \"0660\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#2-search-strategy","title":"2. Search Strategy","text":"<p>Already implemented via build tags + interface:</p> <pre><code>// toolindex.Searcher interface\ntype Searcher interface {\n    Search(query string, limit int) ([]Summary, error)\n}\n\n// Implementations:\n// - Default lexical (built into toolindex)\n// - BM25 (toolsearch package, requires build tag)\n// - Semantic/vector (future, could use embeddings)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#3-tool-provider-registry","title":"3. Tool Provider Registry","text":"<p>New pattern to enable plug-and-play tools:</p> <pre><code>// ToolProvider interface\ntype ToolProvider interface {\n    Name() string\n    Tool() *mcp.Tool  // MCP tool definition with schema\n    Handle(ctx context.Context, input []byte) (any, error)\n}\n\n// Registry\ntype ToolRegistry struct {\n    providers map[string]ToolProvider\n}\n\nfunc (r *ToolRegistry) Register(p ToolProvider) {\n    r.providers[p.Name()] = p\n}\n\nfunc (r *ToolRegistry) All() []ToolProvider {\n    // Returns all registered providers\n}\n</code></pre> <p>Migration path: Convert existing handlers to ToolProvider implementations.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#4-backend-registry","title":"4. Backend Registry","text":"<p>For tool execution sources (local, API, MCP servers):</p> <pre><code>// Backend interface (already in toolmodel conceptually)\ntype Backend interface {\n    Kind() string\n    Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n}\n\n// Registry with configuration\ntype BackendRegistry struct {\n    backends map[string]Backend\n}\n\nfunc (r *BackendRegistry) RegisterFromConfig(cfg BackendConfig) error {\n    switch cfg.Kind {\n    case \"local\":\n        r.backends[\"local\"] = NewLocalBackend(cfg.Local)\n    case \"openai\":\n        r.backends[\"openai\"] = NewOpenAIBackend(cfg.OpenAI)\n    // ...\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#5-middleware-chain","title":"5. Middleware Chain","text":"<p>The middleware layer provides pluggable cross-cutting concerns using the decorator pattern.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-overview_1","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         MIDDLEWARE CHAIN                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Incoming Request                                                           \u2502\n\u2502         \u2502                                                                     \u2502\n\u2502         \u25bc                                                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502   \u2502  Logging  \u2502 \u2192 \u2502   Auth    \u2502 \u2192 \u2502   Rate    \u2502 \u2192 \u2502  Caching  \u2502            \u2502\n\u2502   \u2502           \u2502   \u2502           \u2502   \u2502  Limiter  \u2502   \u2502           \u2502            \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502         \u2502               \u2502               \u2502               \u2502                    \u2502\n\u2502         \u2502   on error:   \u2502   on error:   \u2502   on error:   \u2502                    \u2502\n\u2502         \u2502   log &amp; pass  \u2502   reject 401  \u2502   reject 429  \u2502                    \u2502\n\u2502         \u2502               \u2502               \u2502               \u2502                    \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                                         \u2502                                     \u2502\n\u2502                                         \u25bc                                     \u2502\n\u2502                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2502\n\u2502                               \u2502  Tool Handler \u2502                              \u2502\n\u2502                               \u2502   (actual)    \u2502                              \u2502\n\u2502                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502\n\u2502                                         \u2502                                     \u2502\n\u2502                                         \u25bc                                     \u2502\n\u2502   Response flows back through chain (for metrics, logging, caching)         \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#the-middleware-interface","title":"The Middleware Interface","text":"<pre><code>// Middleware wraps a ToolProvider with additional behavior\ntype Middleware func(ToolProvider) ToolProvider\n\n// MiddlewareFunc is a convenience type for stateless middleware\ntype MiddlewareFunc func(ctx context.Context, input []byte, next NextFunc) (any, error)\n\ntype NextFunc func(ctx context.Context, input []byte) (any, error)\n\n// MiddlewareRegistry manages available middleware\ntype MiddlewareRegistry struct {\n    available map[string]MiddlewareFactory\n    active    []Middleware\n}\n\n// MiddlewareFactory creates configured middleware instances\ntype MiddlewareFactory func(cfg MiddlewareConfig) (Middleware, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#built-in-middleware","title":"Built-in Middleware","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        AVAILABLE MIDDLEWARE                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 LOGGING                                                                  \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Request/response logging                                              \u2502 \u2502\n\u2502  \u2502 - Configurable log levels (debug, info, warn, error)                   \u2502 \u2502\n\u2502  \u2502 - Structured JSON output                                                \u2502 \u2502\n\u2502  \u2502 - Request ID tracking                                                   \u2502 \u2502\n\u2502  \u2502 - Duration metrics                                                      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 AUTHENTICATION                                                           \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Bearer token validation                                               \u2502 \u2502\n\u2502  \u2502 - API key authentication                                                \u2502 \u2502\n\u2502  \u2502 - OAuth2/OIDC integration                                               \u2502 \u2502\n\u2502  \u2502 - mTLS client certificates                                              \u2502 \u2502\n\u2502  \u2502 - Configurable bypass for specific tools                               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 RATE LIMITING                                                            \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Per-client rate limits                                                \u2502 \u2502\n\u2502  \u2502 - Per-tool rate limits                                                  \u2502 \u2502\n\u2502  \u2502 - Token bucket algorithm                                                \u2502 \u2502\n\u2502  \u2502 - Sliding window counters                                               \u2502 \u2502\n\u2502  \u2502 - Redis-backed for distributed deployments                             \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 CACHING                                                                  \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Response caching for idempotent tools                                \u2502 \u2502\n\u2502  \u2502 - Configurable TTL per tool                                            \u2502 \u2502\n\u2502  \u2502 - Cache key customization                                               \u2502 \u2502\n\u2502  \u2502 - In-memory or Redis backend                                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 METRICS                                                                  \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Prometheus-compatible metrics                                         \u2502 \u2502\n\u2502  \u2502 - Request counts, latencies, error rates                               \u2502 \u2502\n\u2502  \u2502 - Per-tool and per-backend breakdowns                                  \u2502 \u2502\n\u2502  \u2502 - Custom metric labels                                                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 TRACING                                                                  \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - OpenTelemetry integration                                             \u2502 \u2502\n\u2502  \u2502 - Distributed trace propagation                                         \u2502 \u2502\n\u2502  \u2502 - Span creation for each tool call                                     \u2502 \u2502\n\u2502  \u2502 - Backend call tracing                                                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 VALIDATION                                                               \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - JSON Schema validation on inputs                                      \u2502 \u2502\n\u2502  \u2502 - Output validation                                                     \u2502 \u2502\n\u2502  \u2502 - Custom validators per tool                                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementing-custom-middleware","title":"Implementing Custom Middleware","text":"<pre><code>// Example: Custom audit logging middleware\ntype AuditMiddleware struct {\n    logger AuditLogger\n    next   ToolProvider\n}\n\nfunc NewAuditMiddleware(logger AuditLogger) Middleware {\n    return func(next ToolProvider) ToolProvider {\n        return &amp;AuditMiddleware{\n            logger: logger,\n            next:   next,\n        }\n    }\n}\n\nfunc (m *AuditMiddleware) Name() string { return m.next.Name() }\nfunc (m *AuditMiddleware) Tool() *mcp.Tool { return m.next.Tool() }\n\nfunc (m *AuditMiddleware) Handle(ctx context.Context, input []byte) (any, error) {\n    // Pre-execution: Log the request\n    requestID := uuid.New().String()\n    user := auth.UserFromContext(ctx)\n\n    m.logger.LogRequest(AuditEntry{\n        RequestID: requestID,\n        User:      user,\n        Tool:      m.next.Name(),\n        Input:     input,\n        Timestamp: time.Now(),\n    })\n\n    // Execute the actual tool\n    result, err := m.next.Handle(ctx, input)\n\n    // Post-execution: Log the result\n    m.logger.LogResponse(AuditEntry{\n        RequestID: requestID,\n        User:      user,\n        Tool:      m.next.Name(),\n        Success:   err == nil,\n        Duration:  time.Since(start),\n        Timestamp: time.Now(),\n    })\n\n    return result, err\n}\n\n// Register custom middleware\nfunc init() {\n    middleware.Register(\"audit\", func(cfg MiddlewareConfig) (Middleware, error) {\n        logger := newAuditLogger(cfg)\n        return NewAuditMiddleware(logger), nil\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-driven-middleware","title":"Configuration-Driven Middleware","text":"<pre><code># metatools.yaml\nmiddleware:\n  # Order matters - first in config = first in chain\n  chain:\n    - logging\n    - auth\n    - rate_limit\n    - metrics\n    - audit  # Custom middleware\n\n  # Per-middleware configuration\n  logging:\n    enabled: true\n    level: info\n    format: json\n    include_request_body: false\n    include_response_body: false\n\n  auth:\n    enabled: true\n    type: bearer\n    token_validation:\n      issuer: https://auth.example.com\n      audience: metatools-api\n    bypass_tools:\n      - search_tools  # Allow anonymous search\n      - list_namespaces\n\n  rate_limit:\n    enabled: true\n    default:\n      requests_per_minute: 100\n      burst: 20\n    per_tool:\n      execute_code:\n        requests_per_minute: 10\n        burst: 2\n    storage: memory  # or redis\n\n  metrics:\n    enabled: true\n    endpoint: /metrics\n    labels:\n      environment: production\n      service: metatools\n\n  cache:\n    enabled: true\n    backend: memory  # or redis\n    default_ttl: 5m\n    per_tool:\n      describe_tool:\n        ttl: 1h\n      search_tools:\n        ttl: 30s\n\n  audit:\n    enabled: true\n    destination: file\n    path: /var/log/metatools/audit.log\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#middleware-chain-construction","title":"Middleware Chain Construction","text":"<pre><code>// Chain construction from config\nfunc BuildMiddlewareChain(cfg MiddlewareConfig) ([]Middleware, error) {\n    var chain []Middleware\n\n    for _, name := range cfg.Chain {\n        mwCfg, ok := cfg.Middlewares[name]\n        if !ok || !mwCfg.Enabled {\n            continue\n        }\n\n        // Look up factory in registry\n        factory, ok := middleware.Get(name)\n        if !ok {\n            return nil, fmt.Errorf(\"unknown middleware: %s\", name)\n        }\n\n        // Create middleware instance\n        mw, err := factory(mwCfg)\n        if err != nil {\n            return nil, fmt.Errorf(\"middleware %s: %w\", name, err)\n        }\n\n        chain = append(chain, mw)\n    }\n\n    return chain, nil\n}\n\n// Apply chain to all providers\nfunc ApplyToRegistry(registry *ToolRegistry, chain []Middleware) {\n    for name, provider := range registry.providers {\n        wrapped := provider\n        for i := len(chain) - 1; i &gt;= 0; i-- {\n            wrapped = chain[i](wrapped)\n        }\n        registry.providers[name] = wrapped\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#request-flow-through-middleware","title":"Request Flow Through Middleware","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    REQUEST FLOW EXAMPLE                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   Client Request: run_tool(\"github/create_issue\", {...})                    \u2502\n\u2502                                                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 1. LOGGING MIDDLEWARE                                                 \u2502  \u2502\n\u2502   \u2502    - Generate request ID: \"req-abc123\"                               \u2502  \u2502\n\u2502   \u2502    - Log: \"Incoming request for github/create_issue\"                 \u2502  \u2502\n\u2502   \u2502    - Start timer                                                      \u2502  \u2502\n\u2502   \u2502    \u2192 Pass to next                                                     \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                               \u2502\n\u2502                              \u25bc                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 2. AUTH MIDDLEWARE                                                    \u2502  \u2502\n\u2502   \u2502    - Extract token from Authorization header                         \u2502  \u2502\n\u2502   \u2502    - Validate JWT signature                                          \u2502  \u2502\n\u2502   \u2502    - Check claims (issuer, audience, expiry)                        \u2502  \u2502\n\u2502   \u2502    - Inject user into context                                        \u2502  \u2502\n\u2502   \u2502    \u2192 Pass to next (or reject with 401)                               \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                               \u2502\n\u2502                              \u25bc                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 3. RATE LIMIT MIDDLEWARE                                              \u2502  \u2502\n\u2502   \u2502    - Identify client (by user, IP, or API key)                       \u2502  \u2502\n\u2502   \u2502    - Check token bucket for \"github/create_issue\"                    \u2502  \u2502\n\u2502   \u2502    - Consume token                                                    \u2502  \u2502\n\u2502   \u2502    \u2192 Pass to next (or reject with 429)                               \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                               \u2502\n\u2502                              \u25bc                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 4. METRICS MIDDLEWARE                                                 \u2502  \u2502\n\u2502   \u2502    - Increment request counter                                        \u2502  \u2502\n\u2502   \u2502    - Start latency timer                                              \u2502  \u2502\n\u2502   \u2502    \u2192 Pass to next                                                     \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                               \u2502\n\u2502                              \u25bc                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 5. ACTUAL TOOL HANDLER                                                \u2502  \u2502\n\u2502   \u2502    - Route to GitHub backend                                         \u2502  \u2502\n\u2502   \u2502    - Execute create_issue                                            \u2502  \u2502\n\u2502   \u2502    - Return result                                                    \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                               \u2502\n\u2502                              \u25bc                                               \u2502\n\u2502   Response bubbles back through chain:                                      \u2502\n\u2502   - Metrics: Record latency, success/failure                                \u2502\n\u2502   - Rate limit: (no action on response)                                     \u2502\n\u2502   - Auth: (no action on response)                                           \u2502\n\u2502   - Logging: Log response, duration, status                                 \u2502\n\u2502                                                                              \u2502\n\u2502   Final Response \u2192 Client                                                   \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#registering-custom-middleware","title":"Registering Custom Middleware","text":"<pre><code>// Register at init time (compile-time pluggability)\nfunc init() {\n    middleware.Register(\"my-custom\", NewMyCustomMiddleware)\n}\n\n// Or register at runtime (config-driven)\nfunc setupMiddleware(registry *MiddlewareRegistry) {\n    // Built-in middleware (always available)\n    registry.Register(\"logging\", NewLoggingMiddleware)\n    registry.Register(\"auth\", NewAuthMiddleware)\n    registry.Register(\"rate_limit\", NewRateLimitMiddleware)\n    registry.Register(\"metrics\", NewMetricsMiddleware)\n    registry.Register(\"cache\", NewCacheMiddleware)\n\n    // Custom middleware (loaded from config or plugins)\n    registry.Register(\"audit\", NewAuditMiddleware)\n    registry.Register(\"pii-filter\", NewPIIFilterMiddleware)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#middleware-composition-patterns","title":"Middleware Composition Patterns","text":"<pre><code>// Conditional middleware (only apply to certain tools)\nfunc OnlyForTools(tools []string, mw Middleware) Middleware {\n    return func(next ToolProvider) ToolProvider {\n        if slices.Contains(tools, next.Name()) {\n            return mw(next)\n        }\n        return next\n    }\n}\n\n// Except middleware (skip for certain tools)\nfunc ExceptForTools(tools []string, mw Middleware) Middleware {\n    return func(next ToolProvider) ToolProvider {\n        if slices.Contains(tools, next.Name()) {\n            return next\n        }\n        return mw(next)\n    }\n}\n\n// Usage\nchain := []Middleware{\n    LoggingMiddleware,\n    ExceptForTools([]string{\"search_tools\"}, AuthMiddleware),\n    OnlyForTools([]string{\"execute_code\"}, StrictRateLimitMiddleware),\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#6-cache-layer","title":"6. Cache Layer","text":"<p>The cache layer provides pluggable caching across multiple components with support for different backends and layered caching strategies.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-overview_2","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           CACHE LAYER                                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                      CACHE CONSUMERS                                     \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\u2502\n\u2502   \u2502  \u2502toolindex \u2502  \u2502tooldocs  \u2502  \u2502toolsearch\u2502  \u2502tooladapter\u2502  \u2502 toolrun  \u2502 \u2502\u2502\n\u2502   \u2502  \u2502 (lookup) \u2502  \u2502 (docs)   \u2502  \u2502 (search) \u2502  \u2502 (convert) \u2502  \u2502 (result) \u2502 \u2502\u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\u2502\n\u2502   \u2502       \u2502             \u2502             \u2502             \u2502             \u2502        \u2502\u2502\n\u2502   \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\u2502\n\u2502   \u2502                            \u2502                                            \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                \u2502                                              \u2502\n\u2502                                \u25bc                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                      toolcache.Cache INTERFACE                           \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2502   Get(ctx, key) \u2192 (value, bool, error)                                  \u2502\u2502\n\u2502   \u2502   Set(ctx, key, value, ttl) \u2192 error                                     \u2502\u2502\n\u2502   \u2502   Delete(ctx, key) \u2192 error                                               \u2502\u2502\n\u2502   \u2502   Clear(ctx, pattern) \u2192 error                                            \u2502\u2502\n\u2502   \u2502   Stats() \u2192 CacheStats                                                   \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                \u2502                                              \u2502\n\u2502                                \u25bc                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                      LAYERED CACHE (L1 + L2)                             \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\u2502\n\u2502   \u2502   \u2502 L1: In-Memory (hot data, microsecond access)                    \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - LRU eviction                                               \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - Size-bounded                                               \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - Process-local                                              \u2502   \u2502\u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\u2502\n\u2502   \u2502                            \u2502 miss                                        \u2502\u2502\n\u2502   \u2502                            \u25bc                                             \u2502\u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\u2502\n\u2502   \u2502   \u2502 L2: Distributed (warm data, millisecond access)                 \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - Redis, Memcached, DynamoDB                                \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - Shared across instances                                    \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - TTL-based expiration                                       \u2502   \u2502\u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                      CACHE BACKENDS                                      \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\u2502\n\u2502   \u2502   \u2502In-Memory\u2502  \u2502  Redis  \u2502  \u2502Memcached\u2502  \u2502 SQLite  \u2502  \u2502 Custom  \u2502      \u2502\u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cache-interface","title":"Cache Interface","text":"<pre><code>// toolcache/cache.go\n\n// Cache defines the pluggable cache interface\ntype Cache interface {\n    // Get retrieves a value, returns (value, found, error)\n    Get(ctx context.Context, key string) ([]byte, bool, error)\n\n    // Set stores a value with TTL (0 = no expiration)\n    Set(ctx context.Context, key string, value []byte, ttl time.Duration) error\n\n    // Delete removes a key\n    Delete(ctx context.Context, key string) error\n\n    // Clear removes keys matching pattern (e.g., \"toolindex:*\")\n    Clear(ctx context.Context, pattern string) error\n\n    // Stats returns cache statistics\n    Stats() CacheStats\n\n    // Close releases resources\n    Close() error\n}\n\n// CacheStats provides observability\ntype CacheStats struct {\n    Hits       int64\n    Misses     int64\n    Size       int64\n    Evictions  int64\n    HitRate    float64\n}\n\n// TypedCache provides type-safe caching with serialization\ntype TypedCache[T any] interface {\n    Get(ctx context.Context, key string) (T, bool, error)\n    Set(ctx context.Context, key string, value T, ttl time.Duration) error\n    GetOrCompute(ctx context.Context, key string, compute func() (T, error), ttl time.Duration) (T, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cache-backends","title":"Cache Backends","text":"<pre><code>// toolcache/memory.go - In-memory LRU cache\ntype MemoryCache struct {\n    maxSize    int64\n    lru        *lru.Cache[string, []byte]\n    stats      CacheStats\n    mu         sync.RWMutex\n}\n\nfunc NewMemoryCache(opts MemoryCacheOptions) *MemoryCache {\n    return &amp;MemoryCache{\n        maxSize: opts.MaxSize,\n        lru:     lru.New[string, []byte](opts.MaxItems),\n    }\n}\n\n// toolcache/redis.go - Redis-backed cache\ntype RedisCache struct {\n    client  *redis.Client\n    prefix  string\n    stats   CacheStats\n}\n\nfunc NewRedisCache(opts RedisCacheOptions) (*RedisCache, error) {\n    client := redis.NewClient(&amp;redis.Options{\n        Addr:     opts.Addr,\n        Password: opts.Password,\n        DB:       opts.DB,\n    })\n    return &amp;RedisCache{\n        client: client,\n        prefix: opts.Prefix,\n    }, nil\n}\n\n// toolcache/sqlite.go - SQLite-backed persistent cache\ntype SQLiteCache struct {\n    db     *sql.DB\n    stats  CacheStats\n}\n\n// toolcache/layered.go - L1 + L2 layered cache\ntype LayeredCache struct {\n    l1      Cache  // Fast, local (memory)\n    l2      Cache  // Slower, shared (Redis)\n    l1TTL   time.Duration\n}\n\nfunc NewLayeredCache(l1, l2 Cache, l1TTL time.Duration) *LayeredCache {\n    return &amp;LayeredCache{l1: l1, l2: l2, l1TTL: l1TTL}\n}\n\nfunc (c *LayeredCache) Get(ctx context.Context, key string) ([]byte, bool, error) {\n    // Try L1 first\n    if val, ok, _ := c.l1.Get(ctx, key); ok {\n        return val, true, nil\n    }\n\n    // Fall back to L2\n    val, ok, err := c.l2.Get(ctx, key)\n    if err != nil || !ok {\n        return nil, false, err\n    }\n\n    // Promote to L1\n    _ = c.l1.Set(ctx, key, val, c.l1TTL)\n    return val, true, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cache-points-in-the-architecture","title":"Cache Points in the Architecture","text":"Component Cache Key Pattern TTL Purpose toolindex <code>index:tool:{id}</code> 1h Tool metadata lookups toolindex <code>index:namespace:{ns}</code> 30m Namespace listings tooldocs <code>docs:{id}:{level}</code> 1h Documentation at each detail level toolsearch <code>search:{hash(query)}</code> 5m Search result caching toolsearch <code>search:index</code> 10m BM25 index caching tooladapter <code>schema:{format}:{id}</code> 24h Schema conversion results toolrun <code>result:{tool}:{hash(input)}</code> varies Idempotent tool results toolsemantic <code>embed:{hash(text)}</code> 24h Vector embeddings"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#integration-with-existing-libraries","title":"Integration with Existing Libraries","text":"<pre><code>// toolindex integration\ntype CachedIndex struct {\n    inner toolindex.Index\n    cache toolcache.Cache\n    ttl   time.Duration\n}\n\nfunc (c *CachedIndex) Get(ctx context.Context, id string) (*toolmodel.Tool, error) {\n    key := fmt.Sprintf(\"index:tool:%s\", id)\n\n    // Try cache first\n    if data, ok, _ := c.cache.Get(ctx, key); ok {\n        var tool toolmodel.Tool\n        if err := json.Unmarshal(data, &amp;tool); err == nil {\n            return &amp;tool, nil\n        }\n    }\n\n    // Cache miss - fetch from index\n    tool, err := c.inner.Get(ctx, id)\n    if err != nil {\n        return nil, err\n    }\n\n    // Store in cache\n    if data, err := json.Marshal(tool); err == nil {\n        _ = c.cache.Set(ctx, key, data, c.ttl)\n    }\n\n    return tool, nil\n}\n\n// toolsearch integration\ntype CachedSearcher struct {\n    inner toolsearch.Searcher\n    cache toolcache.Cache\n    ttl   time.Duration\n}\n\nfunc (c *CachedSearcher) Search(ctx context.Context, query string, limit int) ([]toolsearch.Result, error) {\n    key := fmt.Sprintf(\"search:%x\", sha256.Sum256([]byte(query)))\n\n    // Try cache\n    if data, ok, _ := c.cache.Get(ctx, key); ok {\n        var results []toolsearch.Result\n        if err := json.Unmarshal(data, &amp;results); err == nil {\n            return results, nil\n        }\n    }\n\n    // Execute search\n    results, err := c.inner.Search(ctx, query, limit)\n    if err != nil {\n        return nil, err\n    }\n\n    // Cache results\n    if data, err := json.Marshal(results); err == nil {\n        _ = c.cache.Set(ctx, key, data, c.ttl)\n    }\n\n    return results, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cache-configuration","title":"Cache Configuration","text":"<pre><code># metatools.yaml\ncache:\n  # Default backend for all caches\n  backend: layered\n\n  # Backend configurations\n  backends:\n    memory:\n      max_size: 100MB\n      max_items: 10000\n\n    redis:\n      addr: localhost:6379\n      password: ${REDIS_PASSWORD}\n      db: 0\n      prefix: metatools\n\n    sqlite:\n      path: /var/cache/metatools/cache.db\n\n    layered:\n      l1: memory\n      l2: redis\n      l1_ttl: 1m\n\n  # Per-component cache settings\n  components:\n    toolindex:\n      enabled: true\n      ttl: 1h\n      backend: layered\n\n    tooldocs:\n      enabled: true\n      ttl: 1h\n      backend: memory  # Docs are static, memory is fine\n\n    toolsearch:\n      enabled: true\n      ttl: 5m\n      backend: redis  # Shared across instances\n\n    tooladapter:\n      enabled: true\n      ttl: 24h\n      backend: sqlite  # Persistent, conversions are expensive\n\n    toolrun:\n      enabled: true\n      ttl: 0  # Per-tool configuration\n      backend: redis\n      # Only cache idempotent tools\n      tools:\n        - describe_tool\n        - list_namespaces\n        - search_tools\n\n  # Cache invalidation\n  invalidation:\n    on_tool_register: true    # Clear index caches\n    on_doc_update: true       # Clear docs caches\n    webhook_endpoint: /cache/invalidate\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cache-invalidation-strategies","title":"Cache Invalidation Strategies","text":"<pre><code>// toolcache/invalidation.go\n\n// InvalidationStrategy defines how cache entries are invalidated\ntype InvalidationStrategy interface {\n    OnToolRegistered(ctx context.Context, tool *toolmodel.Tool) error\n    OnToolUnregistered(ctx context.Context, toolID string) error\n    OnDocUpdated(ctx context.Context, toolID string) error\n}\n\n// PatternInvalidation clears by key patterns\ntype PatternInvalidation struct {\n    cache Cache\n}\n\nfunc (p *PatternInvalidation) OnToolRegistered(ctx context.Context, tool *toolmodel.Tool) error {\n    patterns := []string{\n        fmt.Sprintf(\"index:tool:%s\", tool.ID()),\n        fmt.Sprintf(\"index:namespace:%s\", tool.Namespace),\n        \"search:*\",  // All search results potentially affected\n    }\n    for _, pattern := range patterns {\n        if err := p.cache.Clear(ctx, pattern); err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\n// TTLInvalidation relies on TTL expiration (simpler, eventually consistent)\ntype TTLInvalidation struct{}\n\nfunc (t *TTLInvalidation) OnToolRegistered(ctx context.Context, tool *toolmodel.Tool) error {\n    // No-op: cache will expire naturally\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#proposed-library-toolcache","title":"Proposed Library: <code>toolcache</code>","text":"<pre><code>toolcache/\n\u251c\u2500\u2500 cache.go           # Cache interface\n\u251c\u2500\u2500 memory.go          # In-memory LRU implementation\n\u251c\u2500\u2500 redis.go           # Redis implementation\n\u251c\u2500\u2500 sqlite.go          # SQLite implementation\n\u251c\u2500\u2500 layered.go         # L1+L2 layered cache\n\u251c\u2500\u2500 stats.go           # Statistics and metrics\n\u251c\u2500\u2500 invalidation.go    # Invalidation strategies\n\u251c\u2500\u2500 typed.go           # Type-safe generic wrapper\n\u251c\u2500\u2500 config.go          # Configuration parsing\n\u2514\u2500\u2500 wrappers/\n    \u251c\u2500\u2500 index.go       # toolindex.Index wrapper\n    \u251c\u2500\u2500 docs.go        # tooldocs.Store wrapper\n    \u251c\u2500\u2500 search.go      # toolsearch.Searcher wrapper\n    \u2514\u2500\u2500 adapter.go     # tooladapter.Adapter wrapper\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#7-additional-cross-cutting-concerns","title":"7. Additional Cross-Cutting Concerns","text":"<p>Beyond the core extension points, production deployments require additional pluggable concerns for resilience, security, and operations.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#71-resilience-patterns","title":"7.1 Resilience Patterns","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       RESILIENCE LAYER                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 CIRCUIT BREAKER                                                          \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 States: CLOSED \u2192 OPEN \u2192 HALF-OPEN \u2192 CLOSED                              \u2502 \u2502\n\u2502  \u2502 - Monitors failure rate per backend/tool                                 \u2502 \u2502\n\u2502  \u2502 - Opens circuit after threshold (e.g., 50% failures in 10s window)      \u2502 \u2502\n\u2502  \u2502 - Allows probe requests in half-open state                               \u2502 \u2502\n\u2502  \u2502 - Prevents cascading failures across backends                            \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 RETRY POLICY                                                             \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Exponential backoff with jitter (prevents retry storms)               \u2502 \u2502\n\u2502  \u2502 - Per-tool retry configuration (idempotent ops only)                    \u2502 \u2502\n\u2502  \u2502 - Retry budgets (max retries per time window)                           \u2502 \u2502\n\u2502  \u2502 - Non-retryable error classification                                     \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 BULKHEAD                                                                 \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Isolated resource pools per backend                                    \u2502 \u2502\n\u2502  \u2502 - Semaphore-based concurrency limits                                     \u2502 \u2502\n\u2502  \u2502 - Prevents resource exhaustion from single backend                      \u2502 \u2502\n\u2502  \u2502 - Configurable queue depth and timeout                                   \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 TIMEOUT MANAGEMENT                                                       \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Per-tool timeout configuration                                         \u2502 \u2502\n\u2502  \u2502 - Cascading timeouts (request \u2192 backend \u2192 tool)                         \u2502 \u2502\n\u2502  \u2502 - Context deadline propagation                                           \u2502 \u2502\n\u2502  \u2502 - Graceful timeout handling with partial results                        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>// toolresilience/circuit_breaker.go\n\ntype CircuitBreaker interface {\n    Execute(ctx context.Context, fn func() error) error\n    State() CircuitState\n    Reset()\n}\n\ntype CircuitState int\n\nconst (\n    StateClosed CircuitState = iota\n    StateOpen\n    StateHalfOpen\n)\n\ntype CircuitBreakerConfig struct {\n    FailureThreshold    int           // failures before opening\n    SuccessThreshold    int           // successes in half-open before closing\n    Timeout             time.Duration // time in open state before half-open\n    WindowSize          time.Duration // sliding window for failure counting\n}\n\n// toolresilience/retry.go\n\ntype RetryPolicy interface {\n    Execute(ctx context.Context, fn func() error) error\n    ShouldRetry(err error, attempt int) bool\n}\n\ntype RetryConfig struct {\n    MaxAttempts     int\n    InitialBackoff  time.Duration\n    MaxBackoff      time.Duration\n    BackoffFactor   float64\n    Jitter          float64       // 0-1, randomization factor\n    RetryBudget     *RetryBudget  // optional rate limiting\n    NonRetryable    []error       // errors that should not be retried\n}\n\n// toolresilience/bulkhead.go\n\ntype Bulkhead interface {\n    Acquire(ctx context.Context) error\n    Release()\n    Available() int\n}\n\ntype BulkheadConfig struct {\n    MaxConcurrent int\n    MaxWait       time.Duration\n    QueueDepth    int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#72-health-checks","title":"7.2 Health Checks","text":"<pre><code>// toolhealth/health.go\n\ntype HealthChecker interface {\n    Check(ctx context.Context) HealthStatus\n    Name() string\n}\n\ntype HealthStatus struct {\n    Status    Status            // healthy, degraded, unhealthy\n    Details   map[string]any\n    Timestamp time.Time\n}\n\ntype Status string\n\nconst (\n    StatusHealthy   Status = \"healthy\"\n    StatusDegraded  Status = \"degraded\"\n    StatusUnhealthy Status = \"unhealthy\"\n)\n\n// Composite health aggregates multiple checkers\ntype CompositeHealth struct {\n    checkers []HealthChecker\n}\n\nfunc (c *CompositeHealth) Check(ctx context.Context) HealthStatus {\n    results := make(map[string]HealthStatus)\n    overall := StatusHealthy\n\n    for _, checker := range c.checkers {\n        status := checker.Check(ctx)\n        results[checker.Name()] = status\n\n        if status.Status == StatusUnhealthy {\n            overall = StatusUnhealthy\n        } else if status.Status == StatusDegraded &amp;&amp; overall != StatusUnhealthy {\n            overall = StatusDegraded\n        }\n    }\n\n    return HealthStatus{\n        Status:    overall,\n        Details:   map[string]any{\"components\": results},\n        Timestamp: time.Now(),\n    }\n}\n\n// Built-in health checkers\ntype BackendHealthChecker struct{ registry BackendRegistry }\ntype CacheHealthChecker struct{ cache Cache }\ntype SearchHealthChecker struct{ index Index }\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#73-secrets-management","title":"7.3 Secrets Management","text":"<pre><code>// toolsecrets/secrets.go\n\ntype SecretsManager interface {\n    Get(ctx context.Context, key string) (string, error)\n    GetWithMetadata(ctx context.Context, key string) (*Secret, error)\n    Watch(ctx context.Context, key string, callback func(*Secret)) error\n    Close() error\n}\n\ntype Secret struct {\n    Value     string\n    Version   int\n    ExpiresAt time.Time\n    Metadata  map[string]string\n}\n\n// Implementations\ntype VaultSecretsManager struct {\n    client       *vault.Client\n    secretPath   string\n    cacheTTL     time.Duration\n    rotationChan chan string\n}\n\ntype AWSSecretsManager struct {\n    client *secretsmanager.Client\n    region string\n}\n\ntype EnvSecretsManager struct {\n    prefix string  // e.g., \"METATOOLS_SECRET_\"\n}\n</code></pre> <pre><code># metatools.yaml\nsecrets:\n  provider: vault  # vault, aws, env, file\n\n  vault:\n    addr: ${VAULT_ADDR}\n    auth_method: kubernetes  # token, kubernetes, approle\n    secret_path: secret/data/metatools\n    cache_ttl: 5m\n\n  # Backend credentials resolved from secrets\n  backends:\n    openai:\n      api_key: \"{{ secrets.openai_api_key }}\"\n    github:\n      token: \"{{ secrets.github_token }}\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#74-configuration-hot-reload","title":"7.4 Configuration Hot-Reload","text":"<pre><code>// toolconfig/watcher.go\n\ntype ConfigWatcher interface {\n    Watch(ctx context.Context, path string, callback func(Config)) error\n    Stop() error\n}\n\ntype FSConfigWatcher struct {\n    watcher *fsnotify.Watcher\n    parser  ConfigParser\n}\n\nfunc (w *FSConfigWatcher) Watch(ctx context.Context, path string, callback func(Config)) error {\n    if err := w.watcher.Add(path); err != nil {\n        return err\n    }\n\n    go func() {\n        for {\n            select {\n            case event := &lt;-w.watcher.Events:\n                if event.Op&amp;fsnotify.Write == fsnotify.Write {\n                    if cfg, err := w.parser.Parse(path); err == nil {\n                        callback(cfg)\n                    }\n                }\n            case &lt;-ctx.Done():\n                return\n            }\n        }\n    }()\n\n    return nil\n}\n\n// Hot-reloadable components\ntype HotReloadable interface {\n    Reload(cfg Config) error\n}\n\n// Registry tracks reloadable components\ntype ReloadRegistry struct {\n    components map[string]HotReloadable\n}\n\nfunc (r *ReloadRegistry) ReloadAll(cfg Config) error {\n    for name, component := range r.components {\n        if err := component.Reload(cfg); err != nil {\n            return fmt.Errorf(\"reload %s: %w\", name, err)\n        }\n    }\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#75-feature-flags","title":"7.5 Feature Flags","text":"<pre><code>// toolflags/flags.go\n\ntype FeatureFlags interface {\n    IsEnabled(ctx context.Context, flag string) bool\n    GetVariant(ctx context.Context, flag string) string\n    AllFlags(ctx context.Context) map[string]bool\n}\n\n// Local file-based flags (simple deployments)\ntype LocalFeatureFlags struct {\n    flags map[string]bool\n    mu    sync.RWMutex\n}\n\n// LaunchDarkly integration (enterprise)\ntype LaunchDarklyFlags struct {\n    client *ld.LDClient\n    user   func(ctx context.Context) ld.User\n}\n\n// Use case: Gradual tool rollout\nfunc (h *Handler) RunTool(ctx context.Context, req Request) (Response, error) {\n    if h.flags.IsEnabled(ctx, \"new_execution_engine\") {\n        return h.newRunner.Run(ctx, req)\n    }\n    return h.legacyRunner.Run(ctx, req)\n}\n</code></pre> <pre><code># metatools.yaml\nfeature_flags:\n  provider: local  # local, launchdarkly, unleash\n\n  local:\n    path: /etc/metatools/flags.yaml\n    reload_interval: 30s\n\n  flags:\n    new_execution_engine: false\n    semantic_search: true\n    multi_tenant_mode: false\n    streaming_responses: true\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#76-audit-trail-event-sourcing","title":"7.6 Audit Trail / Event Sourcing","text":"<pre><code>// toolaudit/audit.go\n\ntype AuditLogger interface {\n    Log(ctx context.Context, event AuditEvent) error\n    Query(ctx context.Context, filter AuditFilter) ([]AuditEvent, error)\n}\n\ntype AuditEvent struct {\n    ID          string\n    Timestamp   time.Time\n    EventType   EventType\n    Actor       Actor\n    Resource    Resource\n    Action      string\n    Outcome     Outcome\n    Details     map[string]any\n    RequestID   string\n    SessionID   string\n}\n\ntype EventType string\n\nconst (\n    EventToolExecution   EventType = \"tool.execution\"\n    EventToolDiscovery   EventType = \"tool.discovery\"\n    EventConfigChange    EventType = \"config.change\"\n    EventAuthAttempt     EventType = \"auth.attempt\"\n    EventBackendError    EventType = \"backend.error\"\n)\n\n// Implementations\ntype FileAuditLogger struct{ path string }\ntype DatabaseAuditLogger struct{ db *sql.DB }\ntype CloudWatchAuditLogger struct{ client *cloudwatchlogs.Client }\n\n// Compliance-ready: immutable append-only log\ntype ImmutableAuditLogger struct {\n    inner  AuditLogger\n    signer crypto.Signer  // Signs each entry\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#77-backpressure-load-shedding","title":"7.7 Backpressure / Load Shedding","text":"<pre><code>// toolpressure/backpressure.go\n\ntype LoadShedder interface {\n    ShouldShed(ctx context.Context) bool\n    CurrentLoad() float64\n}\n\ntype AdaptiveLoadShedder struct {\n    targetLatency time.Duration\n    maxLoad       float64\n\n    // Metrics\n    currentLatency atomic.Value\n    activeRequests atomic.Int64\n}\n\nfunc (s *AdaptiveLoadShedder) ShouldShed(ctx context.Context) bool {\n    // Little's Law: if latency &gt; target and load &gt; threshold, shed\n    latency := s.currentLatency.Load().(time.Duration)\n    load := float64(s.activeRequests.Load()) / s.maxLoad\n\n    return latency &gt; s.targetLatency &amp;&amp; load &gt; 0.8\n}\n\n// Priority-based shedding\ntype PriorityLoadShedder struct {\n    inner      LoadShedder\n    priorities map[string]int  // tool -&gt; priority (higher = more important)\n}\n\nfunc (s *PriorityLoadShedder) ShouldShed(ctx context.Context, tool string) bool {\n    if !s.inner.ShouldShed(ctx) {\n        return false\n    }\n\n    // Don't shed high-priority tools\n    priority := s.priorities[tool]\n    return priority &lt; 5  // Only shed low-priority requests\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-for-all-concerns","title":"Configuration for All Concerns","text":"<pre><code># metatools.yaml - Cross-Cutting Concerns\nresilience:\n  circuit_breaker:\n    enabled: true\n    failure_threshold: 5\n    success_threshold: 2\n    timeout: 30s\n    window_size: 10s\n\n  retry:\n    enabled: true\n    max_attempts: 3\n    initial_backoff: 100ms\n    max_backoff: 5s\n    jitter: 0.2\n\n  bulkhead:\n    enabled: true\n    default_concurrent: 100\n    per_backend:\n      openai: 50    # Rate-limited API\n      github: 200\n      local: 500\n\n  timeout:\n    default: 30s\n    per_tool:\n      execute_code: 120s\n      search_tools: 5s\n\nhealth:\n  endpoint: /health\n  detailed_endpoint: /health/detailed\n  check_interval: 10s\n  components:\n    - backends\n    - cache\n    - search_index\n\nbackpressure:\n  enabled: true\n  target_latency: 500ms\n  max_concurrent: 1000\n  shed_priority_below: 5\n\naudit:\n  enabled: true\n  provider: file  # file, database, cloudwatch\n  path: /var/log/metatools/audit.log\n  events:\n    - tool.execution\n    - auth.attempt\n    - config.change\n  retention_days: 90\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#summary-cross-cutting-concerns-catalog","title":"Summary: Cross-Cutting Concerns Catalog","text":"Concern Purpose Priority Proposed Library Cache Response/metadata caching High <code>toolcache</code> Circuit Breaker Prevent cascading failures High <code>toolresilience</code> Retry Handle transient failures High <code>toolresilience</code> Bulkhead Resource isolation Medium <code>toolresilience</code> Health Checks Monitoring/orchestration High <code>toolhealth</code> Secrets Credential management High <code>toolsecrets</code> Config Reload Zero-downtime updates Medium <code>toolconfig</code> Feature Flags Gradual rollout Medium <code>toolflags</code> Audit Trail Compliance/debugging High <code>toolaudit</code> Backpressure Overload protection Medium <code>toolpressure</code> Timeout Deadline management High Built-in (context) Tracing Distributed observability High <code>toolobserve</code>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#multi-backend-architecture","title":"Multi-Backend Architecture","text":"<p>The backend layer is the foundation for tool discovery and execution. It enables metatools-mcp to aggregate tools from multiple sources while presenting a unified interface to MCP clients.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-overview_3","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           MCP CLIENT                                         \u2502\n\u2502                    (Claude, Cursor, Custom)                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502 MCP Protocol\n                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         METATOOLS-MCP SERVER                                 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                      UNIFIED TOOL INTERFACE                              \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502   search_tools    describe_tool    run_tool    run_chain    execute_code \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                    \u2502                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                       BACKEND REGISTRY                                   \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502 \u2502\n\u2502  \u2502   \u2502   LOCAL     \u2502 \u2502   OPENAI    \u2502 \u2502    MCP      \u2502 \u2502   CUSTOM    \u2502       \u2502 \u2502\n\u2502  \u2502   \u2502  Backend    \u2502 \u2502  Backend    \u2502 \u2502  Backend    \u2502 \u2502  Backend    \u2502       \u2502 \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502 \u2502\n\u2502  \u2502          \u2502               \u2502               \u2502               \u2502               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502               \u2502               \u2502               \u2502\n              \u25bc               \u25bc               \u25bc               \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  Local   \u2502   \u2502  OpenAI  \u2502   \u2502  Other   \u2502   \u2502  Custom  \u2502\n        \u2502  Files   \u2502   \u2502   API    \u2502   \u2502   MCP    \u2502   \u2502   API    \u2502\n        \u2502          \u2502   \u2502          \u2502   \u2502 Servers  \u2502   \u2502          \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#the-backend-interface","title":"The Backend Interface","text":"<p>Each backend implements a common interface, allowing uniform handling regardless of the tool source:</p> <pre><code>// Backend defines a source of tools\ntype Backend interface {\n    // Identity\n    Kind() string                                    // e.g., \"local\", \"openai\", \"mcp\"\n    Name() string                                    // Instance name for disambiguation\n\n    // Configuration\n    Configure(raw []byte) error                      // Parse backend-specific config\n\n    // Discovery\n    ListTools(ctx context.Context) ([]toolmodel.Tool, error)\n\n    // Execution\n    Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n\n    // Lifecycle\n    Start(ctx context.Context) error\n    Stop() error\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#backend-types","title":"Backend Types","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#1-local-backend","title":"1. Local Backend","text":"<p>Tools defined as files on disk (YAML, JSON, or Go handlers).</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   LOCAL BACKEND                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                       \u2502\n\u2502   ~/.config/metatools/tools/                         \u2502\n\u2502   \u251c\u2500\u2500 calculator.yaml      \u2192 Tool definition         \u2502\n\u2502   \u251c\u2500\u2500 file-ops.yaml        \u2192 Tool definition         \u2502\n\u2502   \u2514\u2500\u2500 custom/                                        \u2502\n\u2502       \u2514\u2500\u2500 my-tool.yaml     \u2192 Tool definition         \u2502\n\u2502                                                       \u2502\n\u2502   /usr/share/metatools/tools/                        \u2502\n\u2502   \u2514\u2500\u2500 system-tools.yaml    \u2192 System-wide tools       \u2502\n\u2502                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                             \u2502\n\u2502    paths:                                            \u2502\n\u2502      - ~/.config/metatools/tools                    \u2502\n\u2502      - /usr/share/metatools/tools                   \u2502\n\u2502    watch: true  # Hot reload on changes             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#2-api-backends-openai-azure-anthropic","title":"2. API Backends (OpenAI, Azure, Anthropic)","text":"<p>Tools exposed via LLM provider APIs.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   OPENAI BACKEND                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502   \u2502 metatools   \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  OpenAI API         \u2502    \u2502\n\u2502   \u2502   run_tool  \u2502        \u2502  /chat/completions  \u2502    \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502  (function calling) \u2502    \u2502\n\u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                             \u2502\n\u2502    api_key: ${OPENAI_API_KEY}                       \u2502\n\u2502    organization: ${OPENAI_ORG}                      \u2502\n\u2502    models:                                           \u2502\n\u2502      - gpt-4                                        \u2502\n\u2502      - gpt-4-turbo                                  \u2502\n\u2502    timeout: 30s                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#3-mcp-backend","title":"3. MCP Backend","text":"<p>Connect to other MCP servers as tool sources.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    MCP BACKEND                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                       \u2502\n\u2502   metatools-mcp                                      \u2502\n\u2502        \u2502                                             \u2502\n\u2502        \u2502 stdio                                       \u2502\n\u2502        \u25bc                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                   \u2502\n\u2502   \u2502  GitHub     \u2502  \u2190 npx @modelcontextprotocol/     \u2502\n\u2502   \u2502  MCP Server \u2502       server-github               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2502\n\u2502        \u2502                                             \u2502\n\u2502        \u25bc                                             \u2502\n\u2502   GitHub API tools:                                  \u2502\n\u2502   - create_issue                                    \u2502\n\u2502   - list_pull_requests                              \u2502\n\u2502   - search_code                                     \u2502\n\u2502                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                             \u2502\n\u2502    kind: mcp                                        \u2502\n\u2502    command: npx                                     \u2502\n\u2502    args:                                            \u2502\n\u2502      - \"-y\"                                         \u2502\n\u2502      - \"@modelcontextprotocol/server-github\"        \u2502\n\u2502    env:                                             \u2502\n\u2502      GITHUB_TOKEN: ${GITHUB_TOKEN}                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#4-http-backend","title":"4. HTTP Backend","text":"<p>Tools exposed via REST APIs.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   HTTP BACKEND                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                       \u2502\n\u2502   metatools-mcp                                      \u2502\n\u2502        \u2502                                             \u2502\n\u2502        \u2502 HTTPS                                       \u2502\n\u2502        \u25bc                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502   \u2502  Internal Tool Server   \u2502                       \u2502\n\u2502   \u2502  tools.company.internal \u2502                       \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502        \u2502                                             \u2502\n\u2502        \u25bc                                             \u2502\n\u2502   Endpoints:                                         \u2502\n\u2502   - POST /tools/list                                \u2502\n\u2502   - POST /tools/{name}/execute                      \u2502\n\u2502                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                             \u2502\n\u2502    base_url: https://tools.company.internal         \u2502\n\u2502    auth:                                            \u2502\n\u2502      type: oauth2                                   \u2502\n\u2502      client_id: ${OAUTH_CLIENT_ID}                  \u2502\n\u2502      client_secret: ${OAUTH_CLIENT_SECRET}          \u2502\n\u2502    headers:                                         \u2502\n\u2502      X-Custom-Header: value                         \u2502\n\u2502    timeout: 30s                                     \u2502\n\u2502    retry:                                           \u2502\n\u2502      max_attempts: 3                                \u2502\n\u2502      backoff: exponential                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#5-custom-backend","title":"5. Custom Backend","text":"<p>For specialized integrations that don't fit standard patterns.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  CUSTOM BACKEND                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                       \u2502\n\u2502   Implement the Backend interface in Go:             \u2502\n\u2502                                                       \u2502\n\u2502   type MyCustomBackend struct {                     \u2502\n\u2502       // Your fields                                \u2502\n\u2502   }                                                  \u2502\n\u2502                                                       \u2502\n\u2502   func (b *MyCustomBackend) Kind() string {         \u2502\n\u2502       return \"my-custom\"                            \u2502\n\u2502   }                                                  \u2502\n\u2502                                                       \u2502\n\u2502   func (b *MyCustomBackend) Configure(raw []byte)   \u2502\n\u2502       error {                                       \u2502\n\u2502       // Parse your custom config                   \u2502\n\u2502       return yaml.Unmarshal(raw, &amp;b.config)         \u2502\n\u2502   }                                                  \u2502\n\u2502                                                       \u2502\n\u2502   func (b *MyCustomBackend) Execute(ctx, tool,      \u2502\n\u2502       args) (any, error) {                          \u2502\n\u2502       // Your execution logic                       \u2502\n\u2502   }                                                  \u2502\n\u2502                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config (passed as raw bytes):                      \u2502\n\u2502    kind: custom                                     \u2502\n\u2502    handler: my-custom                               \u2502\n\u2502    config:                                          \u2502\n\u2502      whatever_you_need: value                       \u2502\n\u2502      nested:                                        \u2502\n\u2502        custom: structure                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-examples","title":"Configuration Examples","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#comprehensive-multi-backend-setup","title":"Comprehensive Multi-Backend Setup","text":"<pre><code># metatools.yaml\nbackends:\n  # Local file-based tools\n  local:\n    enabled: true\n    paths:\n      - ~/.config/metatools/tools\n      - /usr/share/metatools/tools\n    watch: true  # Hot reload\n\n  # OpenAI function calling\n  openai:\n    enabled: true\n    api_key: ${OPENAI_API_KEY}\n    organization: ${OPENAI_ORG}\n    models:\n      - gpt-4\n      - gpt-4-turbo\n    timeout: 30s\n\n  # Azure OpenAI\n  azure-openai:\n    enabled: true\n    kind: azure\n    config:\n      endpoint: https://my-resource.openai.azure.com\n      api_key: ${AZURE_OPENAI_KEY}\n      api_version: \"2024-02-15-preview\"\n      deployment: gpt-4\n\n  # GitHub MCP server\n  github:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-github\"]\n      env:\n        GITHUB_TOKEN: ${GITHUB_TOKEN}\n\n  # Filesystem MCP server\n  filesystem:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/home/user/projects\"]\n\n  # Internal company tool server\n  internal-tools:\n    enabled: true\n    kind: http\n    config:\n      base_url: https://tools.internal.company.com/api/v1\n      auth:\n        type: oauth2\n        token_url: https://auth.company.com/oauth/token\n        client_id: ${INTERNAL_CLIENT_ID}\n        client_secret: ${INTERNAL_CLIENT_SECRET}\n        scopes: [\"tools:read\", \"tools:execute\"]\n      timeout: 60s\n\n  # LangChain tools\n  langchain:\n    enabled: false\n    kind: custom\n    config:\n      toolkit: serpapi\n      api_key: ${SERPAPI_KEY}\n\n  # Database tools\n  database:\n    enabled: true\n    kind: custom\n    config:\n      driver: postgres\n      connection_string: ${DATABASE_URL}\n      read_only: true\n      allowed_schemas: [\"public\", \"analytics\"]\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#tool-aggregation-flow","title":"Tool Aggregation Flow","text":"<p>When a client searches for or executes tools, metatools-mcp aggregates across all backends:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         TOOL SEARCH FLOW                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   Client: search_tools(\"file operations\")                                   \u2502\n\u2502                           \u2502                                                  \u2502\n\u2502                           \u25bc                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    BACKEND REGISTRY                                  \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502   \u2502\n\u2502   \u2502   \u2502  local  \u2502   \u2502 github  \u2502   \u2502  azure  \u2502   \u2502  http   \u2502            \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518            \u2502   \u2502\n\u2502   \u2502        \u2502             \u2502             \u2502             \u2502                  \u2502   \u2502\n\u2502   \u2502        \u25bc             \u25bc             \u25bc             \u25bc                  \u2502   \u2502\n\u2502   \u2502   ListTools()   ListTools()   ListTools()   ListTools()            \u2502   \u2502\n\u2502   \u2502        \u2502             \u2502             \u2502             \u2502                  \u2502   \u2502\n\u2502   \u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502   \u2502\n\u2502   \u2502                             \u2502                                        \u2502   \u2502\n\u2502   \u2502                             \u25bc                                        \u2502   \u2502\n\u2502   \u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2502   \u2502\n\u2502   \u2502                    \u2502   AGGREGATOR    \u2502                              \u2502   \u2502\n\u2502   \u2502                    \u2502  - Merge tools  \u2502                              \u2502   \u2502\n\u2502   \u2502                    \u2502  - Deduplicate  \u2502                              \u2502   \u2502\n\u2502   \u2502                    \u2502  - Apply search \u2502                              \u2502   \u2502\n\u2502   \u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502   \u2502\n\u2502   \u2502                             \u2502                                        \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                 \u25bc                                            \u2502\n\u2502   Results:                                                                   \u2502\n\u2502   [                                                                          \u2502\n\u2502     { id: \"local/file-read\",      backend: \"local\",    score: 0.95 },       \u2502\n\u2502     { id: \"github/get-file\",      backend: \"github\",   score: 0.87 },       \u2502\n\u2502     { id: \"filesystem/read_file\", backend: \"mcp\",      score: 0.82 },       \u2502\n\u2502   ]                                                                          \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#tool-execution-flow","title":"Tool Execution Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        TOOL EXECUTION FLOW                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   Client: run_tool(\"github/create_issue\", { title: \"Bug\", body: \"...\" })   \u2502\n\u2502                           \u2502                                                  \u2502\n\u2502                           \u25bc                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      TOOL ROUTER                                     \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   1. Parse tool ID: \"github/create_issue\"                           \u2502   \u2502\n\u2502   \u2502      \u2514\u2500 backend: \"github\"                                           \u2502   \u2502\n\u2502   \u2502      \u2514\u2500 tool: \"create_issue\"                                        \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   2. Lookup backend in registry                                     \u2502   \u2502\n\u2502   \u2502      \u2514\u2500 Found: GitHubMCPBackend                                     \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   3. Delegate execution                                              \u2502   \u2502\n\u2502   \u2502      \u2514\u2500 backend.Execute(ctx, \"create_issue\", args)                  \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                           \u2502                                                  \u2502\n\u2502                           \u25bc                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                   GITHUB MCP BACKEND                                 \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   1. Forward to MCP subprocess                                      \u2502   \u2502\n\u2502   \u2502      \u2514\u2500 npx @modelcontextprotocol/server-github                     \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   2. MCP call: tools/call { name: \"create_issue\", arguments: ... }  \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   3. Receive result                                                  \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                           \u2502                                                  \u2502\n\u2502                           \u25bc                                                  \u2502\n\u2502   Result:                                                                    \u2502\n\u2502   {                                                                          \u2502\n\u2502     result: { issue_number: 123, url: \"https://github.com/...\" },          \u2502\n\u2502     backend: { kind: \"mcp\", name: \"github\" },                              \u2502\n\u2502     duration_ms: 1250                                                       \u2502\n\u2502   }                                                                          \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#registration-patterns","title":"Registration Patterns","text":"<p>Backends can be registered via YAML configuration or programmatically:</p> <pre><code>// YAML-driven registration (config file)\nfunc (r *BackendRegistry) LoadFromConfig(cfg BackendsConfig) error {\n    for name, backendCfg := range cfg.Backends {\n        if !backendCfg.Enabled {\n            continue\n        }\n\n        // Create backend based on kind\n        backend, err := r.createBackend(backendCfg.Kind)\n        if err != nil {\n            return fmt.Errorf(\"backend %s: %w\", name, err)\n        }\n\n        // Configure with raw config (backend parses itself)\n        if err := backend.Configure(backendCfg.RawConfig); err != nil {\n            return fmt.Errorf(\"backend %s config: %w\", name, err)\n        }\n\n        r.backends[name] = backend\n    }\n    return nil\n}\n\n// Programmatic registration (code-driven)\nfunc main() {\n    registry := NewBackendRegistry()\n\n    // Register a custom backend programmatically\n    myBackend := &amp;MyCustomBackend{\n        // ... configuration\n    }\n    registry.Register(\"my-backend\", myBackend)\n\n    // Or use the builder pattern\n    registry.\n        WithLocal(\"~/.config/metatools/tools\").\n        WithOpenAI(os.Getenv(\"OPENAI_API_KEY\")).\n        WithMCP(\"github\", \"npx\", \"-y\", \"@modelcontextprotocol/server-github\")\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#hybrid-configuration","title":"Hybrid Configuration","text":"<p>For maximum flexibility, backends support both YAML and code:</p> <pre><code>// Backend interface with hybrid config support\ntype Backend interface {\n    Kind() string\n    Name() string\n\n    // Option 1: YAML-driven config\n    Configure(raw []byte) error\n\n    // Option 2: Programmatic config (for complex backends)\n    ConfigureWith(opts ...BackendOption) error\n\n    // Operations\n    ListTools(ctx context.Context) ([]toolmodel.Tool, error)\n    Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n}\n\n// Usage: Some config in YAML, some in code\nfunc setupBackends(registry *BackendRegistry, cfg Config) error {\n    // Load standard backends from YAML\n    if err := registry.LoadFromConfig(cfg.Backends); err != nil {\n        return err\n    }\n\n    // Add a complex custom backend programmatically\n    customBackend := NewDatabaseBackend(\n        WithConnectionPool(pool),\n        WithQueryValidator(validator),\n        WithAuditLogger(auditLog),\n    )\n    registry.Register(\"database\", customBackend)\n\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#error-handling-across-backends","title":"Error Handling Across Backends","text":"<pre><code>// Backend errors include source information\ntype BackendError struct {\n    Backend   string    // Which backend failed\n    Operation string    // What operation failed\n    Tool      string    // Which tool (if applicable)\n    Cause     error     // Underlying error\n    Retryable bool      // Can this be retried?\n}\n\n// Aggregated errors for multi-backend operations\ntype AggregatedError struct {\n    Errors []BackendError\n}\n\nfunc (e *AggregatedError) Error() string {\n    // Format: \"3 backends failed: local: connection refused, openai: rate limited, ...\"\n}\n\n// Partial success handling\ntype AggregatedResult struct {\n    Tools   []toolmodel.Tool  // Successfully retrieved tools\n    Errors  []BackendError    // Backends that failed\n    Partial bool              // True if some backends failed\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#summary-what-this-enables","title":"Summary: What This Enables","text":"Capability Description Tool Aggregation Single search across all backends Unified Execution Consistent interface regardless of backend Hot Plugging Add/remove backends via config without code changes Custom Backends Write Go code for specialized integrations MCP Composition Chain multiple MCP servers together Hybrid Config YAML for standard backends, code for complex ones Graceful Degradation Continue working if some backends fail"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-design","title":"Configuration Design","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#recommended-koanf-cobra","title":"Recommended: Koanf + Cobra","text":"Component Library Rationale CLI framework Cobra Subcommands (<code>stdio</code>, <code>serve</code>, <code>version</code>) Config loading Koanf Lighter than Viper, modular providers"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-structure","title":"Configuration Structure","text":"<pre><code># metatools.yaml\nserver:\n  name: \"metatools-mcp\"\n  version: \"0.2.0\"\n\ntransport:\n  type: sse           # stdio | sse | http\n  http:\n    host: \"0.0.0.0\"\n    port: 8080\n    tls:\n      enabled: true\n      cert: /etc/ssl/cert.pem\n      key: /etc/ssl/key.pem\n    timeouts:\n      read: 30s\n      write: 30s\n      idle: 120s\n\nsearch:\n  strategy: bm25      # lexical | bm25 | semantic\n  bm25:\n    name_boost: 3\n    namespace_boost: 2\n    tags_boost: 2\n    max_docs: 0\n    max_doctext_len: 0\n\nexecution:\n  timeout: 10s\n  max_tool_calls: 64\n  max_chain_steps: 8\n\n# Tool providers (each gets own config section)\nproviders:\n  search_tools:\n    enabled: true\n  describe_tool:\n    enabled: true\n    default_level: summary\n  run_tool:\n    enabled: true\n  run_chain:\n    enabled: true\n  execute_code:\n    enabled: true      # Requires toolruntime build tag\n    sandbox: dev\n\n# Backend sources for tools\nbackends:\n  local:\n    enabled: true\n    paths:\n      - ~/.config/metatools/tools\n      - /usr/share/metatools/tools\n  openai:\n    enabled: false\n    api_key: ${OPENAI_API_KEY}\n  azure:\n    enabled: false\n    tenant_id: ${AZURE_TENANT_ID}\n\n# Middleware chain\nmiddleware:\n  logging:\n    enabled: true\n    level: info\n  auth:\n    enabled: false\n    type: bearer\n  rate_limit:\n    enabled: false\n    requests_per_minute: 100\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-precedence","title":"Configuration Precedence","text":"<pre><code>CLI flags &gt; Environment variables &gt; Config file &gt; Defaults\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#plugin-configuration-pattern","title":"Plugin Configuration Pattern","text":"<p>Plugins receive raw config and parse themselves:</p> <pre><code>type Plugin interface {\n    Name() string\n    Configure(raw []byte) error  // Plugin parses its own config\n    Start(ctx context.Context) error\n    Stop() error\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementation-approach","title":"Implementation Approach","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-1-cli-framework-cobra-koanf","title":"Phase 1: CLI Framework (Cobra + Koanf)","text":"<ol> <li>Add Cobra for subcommands (<code>metatools stdio</code>, <code>metatools serve</code>)</li> <li>Add Koanf for config file loading</li> <li>Maintain backward compatibility (env vars still work)</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-2-transport-abstraction","title":"Phase 2: Transport Abstraction","text":"<ol> <li>Define <code>Transport</code> interface</li> <li>Extract current stdio logic into <code>StdioTransport</code></li> <li>Add <code>SSETransport</code> for HTTP/SSE mode</li> <li>Wire transport selection to config/CLI</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-3-tool-provider-registry","title":"Phase 3: Tool Provider Registry","text":"<ol> <li>Define <code>ToolProvider</code> interface</li> <li>Convert existing handlers to providers</li> <li>Replace <code>registerTools()</code> with registry iteration</li> <li>Enable external provider registration</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-4-backend-registry","title":"Phase 4: Backend Registry","text":"<ol> <li>Define <code>BackendRegistry</code> interface</li> <li>Implement config-driven backend loading</li> <li>Support local, API, and MCP server backends</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-5-middleware-chain","title":"Phase 5: Middleware Chain","text":"<ol> <li>Define <code>Middleware</code> type</li> <li>Implement logging, auth, rate limiting</li> <li>Apply middleware via config</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#end-to-end-examples","title":"End-to-End Examples","text":"<p>This section demonstrates how the pluggable architecture works in practice with complete examples.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#example-1-enterprise-ai-assistant","title":"Example 1: Enterprise AI Assistant","text":"<p>An internal AI assistant that aggregates tools from multiple sources.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    ENTERPRISE AI ASSISTANT                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      FRONTEND / CLIENTS                              \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502   \u2502\n\u2502   \u2502   \u2502  Slack    \u2502  \u2502  Teams    \u2502  \u2502   Web     \u2502  \u2502  VS Code  \u2502        \u2502   \u2502\n\u2502   \u2502   \u2502   Bot     \u2502  \u2502   Bot     \u2502  \u2502   App     \u2502  \u2502 Extension \u2502        \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518        \u2502   \u2502\n\u2502   \u2502         \u2502              \u2502              \u2502              \u2502               \u2502   \u2502\n\u2502   \u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502   \u2502\n\u2502   \u2502                              \u2502 HTTPS/SSE                             \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                  \u25bc                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      METATOOLS-MCP SERVER                            \u2502   \u2502\n\u2502   \u2502                         (HA Cluster)                                 \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Transport: SSE on :8080                                           \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Middleware Chain:                                                  \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502   \u2502\n\u2502   \u2502   \u2502  Log   \u2502\u2192\u2502 OAuth  \u2502\u2192\u2502 Rate   \u2502\u2192\u2502 Audit  \u2502\u2192\u2502 Cache  \u2502           \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Tool Providers:                                                    \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502   \u2502\n\u2502   \u2502   \u2502 search_tools \u2502 \u2502 describe    \u2502 \u2502 run_tool    \u2502               \u2502   \u2502\n\u2502   \u2502   \u2502              \u2502 \u2502 _tool       \u2502 \u2502             \u2502               \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Backends:                                                          \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502   \u2502\n\u2502   \u2502   \u2502  Jira    \u2502 \u2502Confluence\u2502 \u2502  GitHub  \u2502 \u2502 Internal \u2502              \u2502   \u2502\n\u2502   \u2502   \u2502   MCP    \u2502 \u2502   MCP    \u2502 \u2502   MCP    \u2502 \u2502   API    \u2502              \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518              \u2502   \u2502\n\u2502   \u2502        \u2502            \u2502            \u2502            \u2502                     \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502            \u25bc            \u25bc            \u25bc            \u25bc                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502   \u2502    Jira      \u2502 \u2502  Confluence  \u2502 \u2502    GitHub    \u2502 \u2502   Company    \u2502       \u2502\n\u2502   \u2502    Cloud     \u2502 \u2502    Cloud     \u2502 \u2502              \u2502 \u2502     API      \u2502       \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Configuration:</p> <pre><code># metatools-enterprise.yaml\nserver:\n  name: \"enterprise-ai-assistant\"\n  version: \"1.0.0\"\n\ntransport:\n  type: sse\n  http:\n    host: \"0.0.0.0\"\n    port: 8080\n    tls:\n      enabled: true\n      cert: /etc/ssl/certs/server.crt\n      key: /etc/ssl/private/server.key\n    cors:\n      enabled: true\n      origins:\n        - \"https://chat.company.com\"\n        - \"https://slack-bot.company.internal\"\n    health:\n      enabled: true\n\nmiddleware:\n  chain: [logging, auth, rate_limit, audit, cache]\n\n  logging:\n    enabled: true\n    level: info\n    format: json\n\n  auth:\n    enabled: true\n    type: oauth2\n    issuer: https://auth.company.com\n    audience: metatools-api\n    jwks_uri: https://auth.company.com/.well-known/jwks.json\n\n  rate_limit:\n    enabled: true\n    storage: redis\n    redis:\n      address: redis.company.internal:6379\n    default:\n      requests_per_minute: 60\n    per_user: true\n\n  audit:\n    enabled: true\n    destination: elasticsearch\n    elasticsearch:\n      addresses: [\"https://es.company.internal:9200\"]\n      index: metatools-audit\n\n  cache:\n    enabled: true\n    backend: redis\n    redis:\n      address: redis.company.internal:6379\n    per_tool:\n      search_tools:\n        ttl: 1m\n      describe_tool:\n        ttl: 10m\n\nbackends:\n  jira:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@anthropic/mcp-server-jira\"]\n      env:\n        JIRA_URL: https://company.atlassian.net\n        JIRA_EMAIL: ${JIRA_EMAIL}\n        JIRA_API_TOKEN: ${JIRA_API_TOKEN}\n\n  confluence:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@anthropic/mcp-server-confluence\"]\n      env:\n        CONFLUENCE_URL: https://company.atlassian.net/wiki\n        CONFLUENCE_EMAIL: ${CONFLUENCE_EMAIL}\n        CONFLUENCE_API_TOKEN: ${CONFLUENCE_API_TOKEN}\n\n  github:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-github\"]\n      env:\n        GITHUB_TOKEN: ${GITHUB_TOKEN}\n\n  internal-api:\n    enabled: true\n    kind: http\n    config:\n      base_url: https://api.company.internal/tools/v1\n      auth:\n        type: oauth2\n        token_url: https://auth.company.com/oauth/token\n        client_id: ${INTERNAL_CLIENT_ID}\n        client_secret: ${INTERNAL_CLIENT_SECRET}\n        scopes: [\"tools:read\", \"tools:execute\"]\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#example-2-local-development-setup","title":"Example 2: Local Development Setup","text":"<p>A developer workstation with file system access and code execution.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    LOCAL DEVELOPMENT SETUP                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                       DEVELOPER MACHINE                              \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                             \u2502   \u2502\n\u2502   \u2502   \u2502   Claude Desktop  \u2502 \u2190\u2500\u2500 stdio \u2500\u2500\u2510                               \u2502   \u2502\n\u2502   \u2502   \u2502   or Cursor IDE   \u2502             \u2502                               \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502                               \u2502   \u2502\n\u2502   \u2502                                      \u2502                               \u2502   \u2502\n\u2502   \u2502                                      \u25bc                               \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502   \u2502              METATOOLS-MCP (stdio mode)                      \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   Build: go build -tags \"toolsearch,toolruntime\"            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   Features:                                                  \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - BM25 search (toolsearch tag)                            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - Code execution (toolruntime tag)                        \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   Backends:                                                  \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502   Local    \u2502 \u2502 Filesystem \u2502 \u2502   Git      \u2502              \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502   Tools    \u2502 \u2502    MCP     \u2502 \u2502   MCP      \u2502              \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502         \u2502              \u2502              \u2502                      \u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502             \u2502              \u2502              \u2502                          \u2502   \u2502\n\u2502   \u2502             \u25bc              \u25bc              \u25bc                          \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502   \u2502\n\u2502   \u2502   \u2502 ~/.config/ \u2502   \u2502 ~/Projects \u2502   \u2502 .git repos \u2502                  \u2502   \u2502\n\u2502   \u2502   \u2502 metatools/ \u2502   \u2502            \u2502   \u2502            \u2502                  \u2502   \u2502\n\u2502   \u2502   \u2502 tools/     \u2502   \u2502            \u2502   \u2502            \u2502                  \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Configuration:</p> <pre><code># ~/.config/metatools/config.yaml\nserver:\n  name: \"dev-metatools\"\n  version: \"local\"\n\ntransport:\n  type: stdio\n\nsearch:\n  strategy: bm25\n  bm25:\n    name_boost: 3\n    namespace_boost: 2\n\nexecution:\n  timeout: 30s\n  max_tool_calls: 100\n\nmiddleware:\n  chain: [logging]\n  logging:\n    enabled: true\n    level: debug\n    output: /tmp/metatools.log\n\nbackends:\n  local:\n    enabled: true\n    paths:\n      - ~/.config/metatools/tools\n    watch: true\n\n  filesystem:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args:\n        - \"-y\"\n        - \"@modelcontextprotocol/server-filesystem\"\n        - \"~/Projects\"\n        - \"~/Documents\"\n\n  git:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-git\"]\n</code></pre> <p>Custom Local Tool Definition:</p> <pre><code># ~/.config/metatools/tools/project-tools.yaml\ntools:\n  - name: run_tests\n    namespace: dev\n    description: Run project tests with optional coverage\n    inputSchema:\n      type: object\n      properties:\n        path:\n          type: string\n          description: Project path\n        coverage:\n          type: boolean\n          default: false\n      required: [path]\n\n    backend:\n      kind: local\n      handler: run_tests\n\n  - name: lint_code\n    namespace: dev\n    description: Run linter on project\n    inputSchema:\n      type: object\n      properties:\n        path:\n          type: string\n        fix:\n          type: boolean\n          default: false\n      required: [path]\n\n    backend:\n      kind: local\n      handler: lint_code\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#example-3-multi-llm-tool-router","title":"Example 3: Multi-LLM Tool Router","text":"<p>A gateway that routes tool calls to different LLM providers.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      MULTI-LLM TOOL ROUTER                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502                         \u2502   Application   \u2502                                  \u2502\n\u2502                         \u2502   (Your App)    \u2502                                  \u2502\n\u2502                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                  \u2502\n\u2502                                  \u2502 MCP                                       \u2502\n\u2502                                  \u25bc                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      METATOOLS-MCP ROUTER                            \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502   \u2502                    TOOL AGGREGATOR                           \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   All tools from all backends visible as one unified set    \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   search_tools(\"weather\") \u2192                                  \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   [                                                          \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502     { id: \"openai/get_weather\", backend: \"openai\" },        \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502     { id: \"anthropic/weather_lookup\", backend: \"anthropic\" },\u2502   \u2502   \u2502\n\u2502   \u2502   \u2502     { id: \"local/weather_api\", backend: \"local\" }           \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   ]                                                          \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502                              \u25bc                                        \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502   \u2502                    SMART ROUTER                              \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   Routes based on:                                           \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - Tool prefix (openai/*, anthropic/*, local/*)            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - Cost optimization                                        \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - Latency requirements                                     \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - Fallback on failure                                     \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502   \u2502\n\u2502   \u2502          \u2502                   \u2502                   \u2502                   \u2502   \u2502\n\u2502   \u2502          \u25bc                   \u25bc                   \u25bc                   \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502   \u2502\n\u2502   \u2502   \u2502   OpenAI   \u2502     \u2502 Anthropic  \u2502     \u2502   Local    \u2502              \u2502   \u2502\n\u2502   \u2502   \u2502  Backend   \u2502     \u2502  Backend   \u2502     \u2502  Backend   \u2502              \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502   \u2502\n\u2502   \u2502         \u2502                   \u2502                 \u2502                      \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502             \u2502                   \u2502                 \u2502                          \u2502\n\u2502             \u25bc                   \u25bc                 \u25bc                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502   \u2502    OpenAI API    \u2502 \u2502  Anthropic API   \u2502 \u2502   Local Tools    \u2502            \u2502\n\u2502   \u2502                  \u2502 \u2502                  \u2502 \u2502                  \u2502            \u2502\n\u2502   \u2502  - GPT-4 tools   \u2502 \u2502  - Claude tools  \u2502 \u2502  - Custom tools  \u2502            \u2502\n\u2502   \u2502  - DALL-E        \u2502 \u2502  - Computer use  \u2502 \u2502  - File ops      \u2502            \u2502\n\u2502   \u2502  - Whisper       \u2502 \u2502                  \u2502 \u2502  - Scripts       \u2502            \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Configuration:</p> <pre><code># multi-llm-router.yaml\nserver:\n  name: \"llm-tool-router\"\n  version: \"1.0.0\"\n\ntransport:\n  type: sse\n  http:\n    port: 8080\n\nmiddleware:\n  chain: [logging, metrics, cost_tracking]\n\n  cost_tracking:\n    enabled: true\n    storage: postgres\n    postgres:\n      connection_string: ${DATABASE_URL}\n\nbackends:\n  openai:\n    enabled: true\n    kind: openai\n    config:\n      api_key: ${OPENAI_API_KEY}\n      organization: ${OPENAI_ORG}\n      models:\n        - gpt-4\n        - gpt-4-turbo\n        - dall-e-3\n      default_model: gpt-4-turbo\n      timeout: 60s\n\n  anthropic:\n    enabled: true\n    kind: anthropic\n    config:\n      api_key: ${ANTHROPIC_API_KEY}\n      models:\n        - claude-3-opus\n        - claude-3-sonnet\n      default_model: claude-3-sonnet\n      timeout: 60s\n\n  local:\n    enabled: true\n    paths:\n      - /opt/metatools/tools\n\nrouting:\n  # Route by prefix\n  prefix_routing:\n    \"openai/*\": openai\n    \"anthropic/*\": anthropic\n    \"local/*\": local\n\n  # Fallback chain\n  fallback:\n    - openai\n    - anthropic\n    - local\n\n  # Cost optimization\n  cost_aware:\n    enabled: true\n    prefer_cheaper: true\n    budget_per_hour: 10.00\n    currency: USD\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#example-4-microservices-tool-mesh","title":"Example 4: Microservices Tool Mesh","text":"<p>A distributed architecture where each service exposes tools via MCP.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     MICROSERVICES TOOL MESH                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                        API GATEWAY                                   \u2502   \u2502\n\u2502   \u2502                    (Kong / Envoy / etc)                             \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                \u2502                                             \u2502\n\u2502                                \u25bc                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                   METATOOLS-MCP AGGREGATOR                           \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Transport: gRPC (internal), SSE (external)                        \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Service Discovery: Kubernetes / Consul                            \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Aggregates tools from all registered MCP services                 \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                \u2502                                             \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502\n\u2502         \u2502                      \u2502                      \u2502                     \u2502\n\u2502         \u25bc                      \u25bc                      \u25bc                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502  Orders    \u2502        \u2502  Users     \u2502        \u2502  Inventory \u2502               \u2502\n\u2502   \u2502  Service   \u2502        \u2502  Service   \u2502        \u2502  Service   \u2502               \u2502\n\u2502   \u2502            \u2502        \u2502            \u2502        \u2502            \u2502               \u2502\n\u2502   \u2502  MCP Tools:\u2502        \u2502  MCP Tools:\u2502        \u2502  MCP Tools:\u2502               \u2502\n\u2502   \u2502  - create  \u2502        \u2502  - lookup  \u2502        \u2502  - check   \u2502               \u2502\n\u2502   \u2502    _order  \u2502        \u2502    _user   \u2502        \u2502    _stock  \u2502               \u2502\n\u2502   \u2502  - cancel  \u2502        \u2502  - update  \u2502        \u2502  - reserve \u2502               \u2502\n\u2502   \u2502    _order  \u2502        \u2502    _prefs  \u2502        \u2502    _item   \u2502               \u2502\n\u2502   \u2502  - track   \u2502        \u2502  - auth    \u2502        \u2502  - release \u2502               \u2502\n\u2502   \u2502    _order  \u2502        \u2502            \u2502        \u2502    _item   \u2502               \u2502\n\u2502   \u2502            \u2502        \u2502            \u2502        \u2502            \u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502         \u2502                      \u2502                      \u2502                     \u2502\n\u2502         \u25bc                      \u25bc                      \u25bc                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502 Orders DB  \u2502        \u2502 Users DB   \u2502        \u2502Inventory DB\u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Aggregator Configuration:</p> <pre><code># aggregator.yaml\nserver:\n  name: \"tool-mesh-aggregator\"\n  version: \"1.0.0\"\n\ntransports:\n  - type: sse\n    enabled: true\n    http:\n      port: 8080\n      # External-facing\n\n  - type: grpc\n    enabled: true\n    grpc:\n      port: 9090\n      # Internal service mesh\n\nservice_discovery:\n  type: kubernetes\n  kubernetes:\n    namespace: production\n    label_selector: \"mcp.enabled=true\"\n    port_name: mcp-grpc\n\nbackends:\n  # Auto-discovered from Kubernetes\n  auto_discover:\n    enabled: true\n    refresh_interval: 30s\n\n  # Or explicit configuration\n  orders:\n    enabled: true\n    kind: grpc\n    config:\n      address: orders-service.production.svc:9090\n      tls:\n        enabled: true\n        ca_cert: /etc/ssl/ca.crt\n\n  users:\n    enabled: true\n    kind: grpc\n    config:\n      address: users-service.production.svc:9090\n\n  inventory:\n    enabled: true\n    kind: grpc\n    config:\n      address: inventory-service.production.svc:9090\n</code></pre> <p>Service Configuration (e.g., Orders Service):</p> <pre><code># orders-service/mcp-config.yaml\nserver:\n  name: \"orders-service-mcp\"\n  version: \"2.1.0\"\n\ntransport:\n  type: grpc\n  grpc:\n    port: 9090\n\nproviders:\n  create_order:\n    enabled: true\n  cancel_order:\n    enabled: true\n  track_order:\n    enabled: true\n\nbackends:\n  local:\n    enabled: true\n    # Orders service tools implemented in Go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#example-5-request-flow-diagram","title":"Example 5: Request Flow Diagram","text":"<p>A complete request flow through all layers:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    COMPLETE REQUEST FLOW                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   1. CLIENT REQUEST                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  POST /mcp HTTP/1.1                                                  \u2502   \u2502\n\u2502   \u2502  Content-Type: application/json                                      \u2502   \u2502\n\u2502   \u2502  Authorization: Bearer eyJhbGc...                                   \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502  {                                                                   \u2502   \u2502\n\u2502   \u2502    \"jsonrpc\": \"2.0\",                                                \u2502   \u2502\n\u2502   \u2502    \"method\": \"tools/call\",                                          \u2502   \u2502\n\u2502   \u2502    \"params\": {                                                      \u2502   \u2502\n\u2502   \u2502      \"name\": \"github/create_issue\",                                 \u2502   \u2502\n\u2502   \u2502      \"arguments\": {                                                 \u2502   \u2502\n\u2502   \u2502        \"repo\": \"company/project\",                                   \u2502   \u2502\n\u2502   \u2502        \"title\": \"Bug: Login fails\",                                 \u2502   \u2502\n\u2502   \u2502        \"body\": \"Steps to reproduce...\"                              \u2502   \u2502\n\u2502   \u2502      }                                                              \u2502   \u2502\n\u2502   \u2502    },                                                               \u2502   \u2502\n\u2502   \u2502    \"id\": \"req-123\"                                                  \u2502   \u2502\n\u2502   \u2502  }                                                                   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   2. TRANSPORT LAYER (SSE)                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  - Accept HTTP connection                                           \u2502   \u2502\n\u2502   \u2502  - Parse JSON-RPC request                                           \u2502   \u2502\n\u2502   \u2502  - Create context with request ID                                   \u2502   \u2502\n\u2502   \u2502  - Pass to handler chain                                            \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   3. MIDDLEWARE CHAIN                                                        \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502 LOGGING                                                       \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Log: \"Incoming request req-123 for github/create_issue\"    \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Start timer                                                 \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502                              \u25bc                                        \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502 AUTH                                                          \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Validate JWT token                                          \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Extract user: \"alice@company.com\"                          \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Inject user into context                                    \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502                              \u25bc                                        \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502 RATE LIMIT                                                    \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Check: alice@company.com has 45/60 requests remaining      \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Consume 1 token                                             \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Pass through                                                \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502                              \u25bc                                        \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502 AUDIT                                                         \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Log to audit trail:                                        \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502   { user: \"alice\", tool: \"github/create_issue\", time: ... }  \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   4. TOOL ROUTER                                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  - Parse tool ID: \"github/create_issue\"                             \u2502   \u2502\n\u2502   \u2502  - Extract backend: \"github\"                                         \u2502   \u2502\n\u2502   \u2502  - Extract tool name: \"create_issue\"                                \u2502   \u2502\n\u2502   \u2502  - Lookup backend in registry                                        \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   5. BACKEND (GitHub MCP)                                                    \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  - Backend type: MCP subprocess                                      \u2502   \u2502\n\u2502   \u2502  - Command: npx @modelcontextprotocol/server-github                 \u2502   \u2502\n\u2502   \u2502  - Forward MCP call to subprocess                                    \u2502   \u2502\n\u2502   \u2502  - Wait for response                                                 \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   6. EXTERNAL SERVICE (GitHub API)                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  - GitHub MCP server calls GitHub API                               \u2502   \u2502\n\u2502   \u2502  - POST https://api.github.com/repos/company/project/issues        \u2502   \u2502\n\u2502   \u2502  - Response: { \"number\": 456, \"url\": \"...\" }                        \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   7. RESPONSE FLOW (reverse through middleware)                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  - Audit: Log success                                                \u2502   \u2502\n\u2502   \u2502  - Rate limit: (no action)                                          \u2502   \u2502\n\u2502   \u2502  - Auth: (no action)                                                \u2502   \u2502\n\u2502   \u2502  - Logging: Log \"Completed req-123 in 1.2s, status: success\"        \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   8. CLIENT RESPONSE                                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  HTTP/1.1 200 OK                                                     \u2502   \u2502\n\u2502   \u2502  Content-Type: text/event-stream                                    \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502  event: message                                                      \u2502   \u2502\n\u2502   \u2502  data: {                                                             \u2502   \u2502\n\u2502   \u2502    \"jsonrpc\": \"2.0\",                                                \u2502   \u2502\n\u2502   \u2502    \"result\": {                                                      \u2502   \u2502\n\u2502   \u2502      \"content\": [{                                                  \u2502   \u2502\n\u2502   \u2502        \"type\": \"text\",                                              \u2502   \u2502\n\u2502   \u2502        \"text\": \"Created issue #456\"                                 \u2502   \u2502\n\u2502   \u2502      }],                                                            \u2502   \u2502\n\u2502   \u2502      \"metadata\": {                                                  \u2502   \u2502\n\u2502   \u2502        \"issue_number\": 456,                                         \u2502   \u2502\n\u2502   \u2502        \"url\": \"https://github.com/company/project/issues/456\"      \u2502   \u2502\n\u2502   \u2502      }                                                              \u2502   \u2502\n\u2502   \u2502    },                                                               \u2502   \u2502\n\u2502   \u2502    \"id\": \"req-123\"                                                  \u2502   \u2502\n\u2502   \u2502  }                                                                   \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502  event: done                                                         \u2502   \u2502\n\u2502   \u2502  data: {}                                                            \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#comparative-analysis","title":"Comparative Analysis","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#your-tool-libraries-vs-industry-patterns","title":"Your Tool Libraries vs. Industry Patterns","text":"Your Pattern Industry Standard Alignment toolindex.Searcher interface Register-on-init pattern Excellent Build-tag gating HashiCorp conditional compilation Same approach Adapter layer Clean Architecture boundaries Textbook Progressive disclosure Apple API design principles Ahead of most"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#comparison-with-other-go-mcp-servers","title":"Comparison with Other Go MCP Servers","text":"Project Transport Plugin System Your Advantage Official go-sdk stdio, SSE None Your tool* libraries mark3labs/mcp-go stdio, SSE Basic Your progressive disclosure viant/mcp stdio None Your modular architecture metatools-mcp stdio (SSE planned) Build-tag + interfaces Full stack orchestration <p>Unique value: No other Go MCP server has layered tool libraries with progressive disclosure, BM25 search, and code execution.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#references","title":"References","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#go-plugin-patterns","title":"Go Plugin Patterns","text":"<ul> <li>HashiCorp go-plugin - RPC-based plugin system</li> <li>Register-on-Init Pattern</li> <li>Interface Extension Pattern</li> <li>Clean Architecture with Plugins</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#mcp-implementations","title":"MCP Implementations","text":"<ul> <li>Official MCP Go SDK</li> <li>mark3labs/mcp-go</li> <li>viant/mcp</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-libraries","title":"Configuration Libraries","text":"<ul> <li>Koanf - Lighter Viper alternative</li> <li>Cobra - CLI framework</li> <li>Dependency Injection Patterns</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#api-design","title":"API Design","text":"<ul> <li>Progressive Disclosure</li> <li>Apple WWDC22: API Design</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-validation","title":"Architecture Validation","text":"<p>This section documents validation of the proposed architecture against industry best practices and real-world implementations, gathered from multiple research sources (Exa, Firecrawl, GitHub, Context7).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#plugin-architecture-validation","title":"Plugin Architecture Validation \u2713","text":"<p>Sources: cekrem.github.io, blog.devcoffee.me, skoredin.pro, caffeinatedcoder.medium.com, reintech.io</p> <p>Our proposed architecture aligns with established Go plugin patterns:</p> Pattern Our Implementation Industry Validation Dependency Inversion ToolProvider interface abstracts concrete implementations \"High-level modules depend only on abstractions (interfaces)\" - Clean Architecture Interface-Driven Design <code>handlers/interfaces.go</code> defines stable contracts \"Define stable, simple core interfaces\" - Go best practices Plugin Registry ToolProviderRegistry with Register/Get methods \"Central hub for registering plugins with unique names\" - Plugin Registry pattern Plugin Factories Factory functions for backend creation \"A function that returns a new instance of a plugin\" - Factory pattern Graceful Shutdown Context-based cancellation propagation \"Critical feature for supporting context cancellation\" - Production patterns <p>RPC-Based Plugin Pattern (HashiCorp): Our Backend interface supports both in-process and RPC-based plugins, aligning with the industry-recommended approach for fault tolerance.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#middleware-chain-validation","title":"Middleware Chain Validation \u2713","text":"<p>Sources: go-chi/chi (21.7k\u2b50), grpc-ecosystem/go-grpc-middleware (6.7k\u2b50)</p> <p>The chi router's <code>chain.go</code> demonstrates the exact pattern we're proposing:</p> <pre><code>// From go-chi/chi - validates our decorator pattern\nfunc chain(middlewares []func(http.Handler) http.Handler, endpoint http.Handler) http.Handler {\n    if len(middlewares) == 0 {\n        return endpoint\n    }\n    h := middlewares[len(middlewares)-1](endpoint)\n    for i := len(middlewares) - 2; i &gt;= 0; i-- {\n        h = middlewares[i](h)\n    }\n    return h\n}\n</code></pre> <p>grpc-ecosystem interceptor categories match our proposed middleware types: - <code>auth/</code> \u2192 Our Auth middleware - <code>logging/</code> \u2192 Our Logging middleware - <code>ratelimit/</code> \u2192 Our RateLimit middleware - <code>recovery/</code> \u2192 Our Recovery/error handling - <code>retry/</code> \u2192 Our Circuit breaker patterns - <code>timeout/</code> \u2192 Our Timeout middleware</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#transport-layer-validation","title":"Transport Layer Validation \u2713","text":"<p>Sources: FreeCodeCamp, go-zero.dev, goa.design, Centrifugo</p> <p>SSE Implementation Requirements (validated): <pre><code>// Required headers for SSE - confirmed across all sources\nw.Header().Set(\"Content-Type\", \"text/event-stream\")\nw.Header().Set(\"Cache-Control\", \"no-cache\")\nw.Header().Set(\"Connection\", \"keep-alive\")\n</code></pre></p> <p>Multi-Transport Architecture Patterns: | Transport | Use Case | Our Support | |-----------|----------|-------------| | HTTP/REST | Request-response APIs | \u2713 Proposed | | SSE | Server-to-client streaming | \u2713 Proposed | | WebSocket | Bidirectional real-time | \u2713 Proposed | | gRPC | High-performance RPC | \u2713 Proposed | | stdio | Local MCP clients | \u2713 Current |</p> <p>Centrifugo WebSocket Scaling Patterns: Validates our approach of using shared state (Redis) for HA deployments with multiple transport instances.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#mcp-server-ecosystem-validation","title":"MCP Server Ecosystem Validation \u2713","text":"<p>Sources: viant/mcp, mcp-golang, go-mcp (Reddit), bytesizego.com, dev.to</p> <p>Active Go MCP implementations confirm the viability of our approach:</p> Project Stars Approach Notes viant/mcp Active Interface-based Validates our pattern mcp-golang Active Framework approach Similar extensibility goals mark3labs/mcp-go Popular Simple MCP Basic implementation <p>Key insight: No existing Go MCP server offers the combination of: - Multi-transport support (stdio + HTTP/SSE) - Pluggable tool providers - Configurable search strategies - Multi-backend aggregation - Middleware chain</p> <p>This confirms metatools-mcp's unique positioning in the ecosystem.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-library-validation","title":"Configuration Library Validation \u2713","text":"<p>Sources: Context7 library research, GitHub documentation</p> Library Reputation Code Snippets Recommendation Koanf High 23 \u2713 \"Cleaner, lighter alternative to Viper\" Cobra High 1,126+ \u2713 \"Powerful CLI with subcommands\" <p>This validates our choice of Koanf + Cobra over Viper for configuration management.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#validation-summary","title":"Validation Summary","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  ARCHITECTURE VALIDATION MATRIX                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Component              \u2502 Pattern Validated  \u2502 Source Quality    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Plugin Registry        \u2502 \u2713 Industry standard\u2502 High (multiple)   \u2502\n\u2502 Middleware Chain       \u2502 \u2713 go-chi pattern   \u2502 High (21.7k\u2b50)    \u2502\n\u2502 Transport Abstraction  \u2502 \u2713 Multi-impl refs  \u2502 High (docs + OSS) \u2502\n\u2502 SSE Implementation     \u2502 \u2713 Standard headers \u2502 High (RFC 6455)   \u2502\n\u2502 Backend Interface      \u2502 \u2713 DIP/Clean Arch   \u2502 High (canonical)  \u2502\n\u2502 Config Framework       \u2502 \u2713 Koanf + Cobra    \u2502 High (Context7)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Conclusion: The proposed architecture follows established best practices and patterns validated across multiple high-quality sources. The design is sustainable, maintainable, and aligned with the Go ecosystem's conventions.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementation-phases","title":"Implementation Phases","text":"<p>A detailed phased implementation plan has been created to break this proposal into manageable chunks. See implementation-phases.md for:</p> <ul> <li>Phase 1: CLI Framework &amp; Configuration (~2 weeks) - Cobra + Koanf foundation</li> <li>Phase 2: Transport Layer Abstraction (~2 weeks) - Stdio + SSE transports</li> <li>Phase 3: Tool Provider Registry (~1 week) - Plug-and-play tool registration</li> <li>Phase 4: Backend Registry (~2 weeks) - Multi-source tool aggregation</li> <li>Phase 5: Middleware Chain (~2 weeks) - Cross-cutting concerns</li> </ul> <p>MVP (Phases 1-3): ~5 weeks Full Implementation: ~9 weeks</p> <p>Each phase includes: - Detailed directory structure changes - Interface definitions with Go code - Implementation tasks with code examples - Verification criteria checklist - Migration notes for backward compatibility</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#component-library-analysis","title":"Component Library Analysis","text":"<p>A comprehensive analysis of the metatools component library ecosystem has been performed. See component-library-analysis.md for:</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#library-ecosystem-7-libraries","title":"Library Ecosystem (7 libraries)","text":"Library Version Purpose Changes Needed toolmodel v0.1.2 Core data models Add HTTP/gRPC backend kinds toolindex v0.1.8 Tool registry Add ListTools, OnChange tooldocs v0.1.10 Documentation Add BulkRegisterDocs toolrun v0.1.9 Execution Add HTTPExecutor, GRPCExecutor, ExecutionHook toolcode v0.1.10 Code execution Add EngineRegistry toolsearch v0.1.9 BM25 search No changes (already pluggable) toolruntime v0.1.10 Sandbox runtime Minor config additions"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#key-findings","title":"Key Findings","text":"<ol> <li>All changes are additive - No breaking changes to existing interfaces</li> <li>toolsearch is exemplary - Already implements pluggable pattern via <code>Searcher</code> interface</li> <li>toolrun needs most work - Core execution layer requires new executor interfaces</li> <li>Error taxonomy needed - Consistent error types across all libraries</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#dependency-graph","title":"Dependency Graph","text":"<pre><code>metatools-mcp\n    \u251c\u2500\u2500 toolcode \u2500\u2500\u252c\u2500\u2500 toolrun \u2500\u2500\u252c\u2500\u2500 toolindex \u2500\u2500 toolmodel \u2500\u2500 mcp-go-sdk\n    \u2502              \u2502             \u2502\n    \u2502              \u251c\u2500\u2500 tooldocs \u2500\u2524\n    \u2502              \u2502             \u2502\n    \u2514\u2500\u2500 toolruntime \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                   toolsearch (optional, implements toolindex.Searcher)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#multi-tenancy-extension","title":"Multi-Tenancy Extension","text":"<p>A comprehensive multi-tenancy design has been created as an extension to this architecture. See multi-tenancy.md for:</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#core-concepts","title":"Core Concepts","text":"Concept Description Pluggable Tenant Resolution JWT, API Key, Header, or custom resolvers Tenant-Aware Middleware Rate limiting, tool filtering, audit per tenant Tenant-Scoped Registries Isolated tool/backend views per tenant Configuration Hierarchy Defaults \u2192 Tier \u2192 Tenant overrides Isolation Strategies Shared, Namespace, or Process isolation"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture","title":"Architecture","text":"<pre><code>Request \u2192 Tenant Resolver \u2192 Tenant Middleware Chain \u2192 Tenant-Scoped Registry \u2192 Execution\n              \u2502                     \u2502                        \u2502\n              \u25bc                     \u25bc                        \u25bc\n         TenantContext      Rate Limit + Filter     Filtered Tools/Backends\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#key-interfaces","title":"Key Interfaces","text":"<pre><code>// Pluggable tenant identification\ntype TenantResolver interface {\n    Resolve(ctx context.Context, req *Request) (*TenantContext, error)\n}\n\n// Tenant configuration overrides\ntype TenantConfig struct {\n    AllowedTools    []string\n    DeniedTools     []string\n    AllowedBackends []string\n    RateLimits      *RateLimitConfig\n    Quotas          *QuotaConfig\n    Features        map[string]bool\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementation-priority","title":"Implementation Priority","text":"Phase Focus Duration Phase 1 Core multi-tenancy (Tenant, TenantContext, resolvers) 2 weeks Phase 2 Tenant-aware middleware (rate limit, filter, audit) 1 week Phase 3 Tenant storage (memory, Postgres implementations) 1 week Phase 4 Advanced features (scoped registries, isolation strategies) 2 weeks"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#extension-point-catalog","title":"Extension Point Catalog","text":"<p>Comprehensive architecture analysis has revealed that the metatools ecosystem is already 85%+ pluggable. The following 13 extension points exist across the component libraries, ready for configuration and exposure.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#critical-finding","title":"Critical Finding","text":"<p>The architecture is NOT a monolith to be refactored. It is a mature, layered, pluggable architecture that needs: - Exposure - Make internal extension points accessible via configuration - Configuration - Add CLI + config layer (Cobra + Koanf) - Documentation - Catalog the 13 extension points with examples - Examples - Show how to extend each interface</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#extension-points-by-library","title":"Extension Points by Library","text":"# Interface Library Purpose Pluggability 1 <code>SchemaValidator</code> toolmodel JSON Schema validation \u2705 Interface-based 2 <code>Searcher</code> toolindex Tool search strategy \u2705 Interface-based 3 <code>BackendSelector</code> toolindex Multi-backend selection \u2705 Function-based 4 <code>Store</code> tooldocs Documentation storage \u2705 Interface-based 5 <code>ToolResolver</code> tooldocs Tool resolution for docs \u2705 Function-based 6 <code>Runner</code> toolrun Tool execution \u2705 Interface-based 7 <code>MCPExecutor</code> toolrun MCP backend executor \u2705 Interface-based 8 <code>ProviderExecutor</code> toolrun Provider backend executor \u2705 Interface-based 9 <code>LocalRegistry</code> toolrun Local handler lookup \u2705 Interface-based 10 <code>Backend</code> toolruntime Sandbox isolation backend \u2705 Interface-based 11 <code>ToolGateway</code> toolruntime Sandbox tool access \u2705 Interface-based 12 <code>Logger</code> toolcode Execution logging \u2705 Interface-based 13 <code>Engine</code> toolcode Language-specific execution \u2705 Interface-based"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#interface-definitions","title":"Interface Definitions","text":"<pre><code>// 1. SchemaValidator - JSON Schema validation strategy\ntype SchemaValidator interface {\n    ValidateSchema(schema map[string]any) error\n    ValidateInput(schema map[string]any, input map[string]any) error\n}\n\n// 2. Searcher - Tool search strategy (toolsearch.BM25Searcher implements this)\ntype Searcher interface {\n    Search(query string, limit int) ([]SearchResult, error)\n    Close() error\n}\n\n// 3. BackendSelector - Multi-backend selection policy\ntype BackendSelector func(tool Tool, backends []ToolBackend) ToolBackend\n\n// 4. Store - Documentation storage\ntype Store interface {\n    DescribeTool(id string, level DetailLevel) (ToolDoc, error)\n    ListExamples(id string, max int) ([]ToolExample, error)\n    RegisterDoc(id string, entry DocEntry) error\n}\n\n// 5. ToolResolver - Tool resolution for documentation\ntype ToolResolver func(id string) (*toolmodel.Tool, error)\n\n// 6. Runner - Tool execution orchestration\ntype Runner interface {\n    Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)\n    RunStream(ctx context.Context, toolID string, args map[string]any) (&lt;-chan StreamEvent, error)\n    RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error)\n}\n\n// 7. MCPExecutor - MCP backend execution\ntype MCPExecutor interface {\n    CallTool(ctx context.Context, server, tool string, args map[string]any) (any, error)\n    CallToolStream(ctx context.Context, server, tool string, args map[string]any) (&lt;-chan StreamEvent, error)\n}\n\n// 8. ProviderExecutor - Provider backend execution\ntype ProviderExecutor interface {\n    CallTool(ctx context.Context, provider, tool string, args map[string]any) (any, error)\n    CallToolStream(ctx context.Context, provider, tool string, args map[string]any) (&lt;-chan StreamEvent, error)\n}\n\n// 9. LocalRegistry - Local handler lookup\ntype LocalRegistry interface {\n    Get(name string) (LocalHandler, bool)\n}\n\n// 10. Backend - Sandbox isolation backend (10 implementations exist)\ntype Backend interface {\n    Name() string\n    Execute(ctx context.Context, req ExecuteRequest) (ExecuteResult, error)\n    Capabilities() BackendCapabilities\n    Close() error\n}\n\n// 11. ToolGateway - Tool access from sandboxed code\ntype ToolGateway interface {\n    SearchTools(ctx context.Context, query string, limit int) ([]SearchResult, error)\n    ListNamespaces(ctx context.Context) ([]string, error)\n    DescribeTool(ctx context.Context, id string, level DetailLevel) (ToolDoc, error)\n    ListToolExamples(ctx context.Context, id string, max int) ([]ToolExample, error)\n    RunTool(ctx context.Context, toolID string, args map[string]any) (any, error)\n    RunChain(ctx context.Context, steps []ChainStep) (any, []StepResult, error)\n}\n\n// 12. Logger - Execution logging\ntype Logger interface {\n    Info(msg string, fields ...any)\n    Error(msg string, fields ...any)\n    Debug(msg string, fields ...any)\n}\n\n// 13. Engine - Language-specific code execution\ntype Engine interface {\n    Name() string\n    Execute(ctx context.Context, code string, gateway ToolGateway) (any, error)\n    Capabilities() EngineCapabilities\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#existing-implementations","title":"Existing Implementations","text":"Interface Built-in Implementations <code>SchemaValidator</code> <code>DefaultValidator</code> (jsonschema-go) <code>Searcher</code> <code>BM25Searcher</code> (toolsearch, uses Bleve) <code>BackendSelector</code> <code>DefaultBackendSelector</code> (local &gt; provider &gt; mcp) <code>Store</code> <code>InMemoryStore</code> <code>Runner</code> <code>DefaultRunner</code> <code>Backend</code> 10 implementations: unsafe, docker, containerd, kubernetes, firecracker, kata, gvisor, wasm, temporal, remote <code>ToolGateway</code> <code>toolcodeengine.WrapTools()</code> adapter <code>Engine</code> Language-specific engines (JS, Python, etc.)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         METATOOLS PLUGGABLE ARCHITECTURE                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                         MCP Protocol Layer                                  \u2502 \u2502\n\u2502  \u2502              Transport: Stdio (current) | SSE | WebSocket                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                     \u2502                                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                         metatools-mcp Server                                \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 \u2502\n\u2502  \u2502  \u2502  Handlers   \u2502  \u2502  Adapters   \u2502  \u2502   Config    \u2502  \u2502    Middleware       \u2502\u2502 \u2502\n\u2502  \u2502  \u2502  (MCP ops)  \u2502  \u2502  (bridge)   \u2502  \u2502  (YAML/env) \u2502  \u2502  (auth/rate/log)   \u2502\u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502            \u2502                \u2502                                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                    Component Library Layer                                   \u2502 \u2502\n\u2502  \u2502                                                                              \u2502 \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502 \u2502\n\u2502  \u2502   \u2502  toolcode    \u2502\u2500\u2500\u2500\u25b6\u2502   toolrun    \u2502\u2500\u2500\u2500\u25b6\u2502  toolindex   \u2502                  \u2502 \u2502\n\u2502  \u2502   \u2502  [13:Engine] \u2502    \u2502  [6-9:Exec]  \u2502    \u2502  [2-3:Search]\u2502                  \u2502 \u2502\n\u2502  \u2502   \u2502  [12:Logger] \u2502    \u2502              \u2502    \u2502              \u2502                  \u2502 \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502 \u2502\n\u2502  \u2502          \u2502                                       \u2502                          \u2502 \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502 \u2502\n\u2502  \u2502   \u2502 toolruntime  \u2502    \u2502   tooldocs   \u2502    \u2502  toolmodel   \u2502                  \u2502 \u2502\n\u2502  \u2502   \u2502 [10:Backend] \u2502    \u2502  [4-5:Store] \u2502    \u2502 [1:Validator]\u2502                  \u2502 \u2502\n\u2502  \u2502   \u2502 [11:Gateway] \u2502    \u2502              \u2502    \u2502              \u2502                  \u2502 \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502 \u2502\n\u2502  \u2502                                                                              \u2502 \u2502\n\u2502  \u2502              toolsearch (optional, implements Searcher #2)                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                    Sandbox/Runtime Layer (10 backends)                      \u2502 \u2502\n\u2502  \u2502   unsafe | docker | containerd | k8s | firecracker | kata | gvisor | wasm  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#revised-implementation-timeline","title":"Revised Implementation Timeline","text":"<p>Based on the architecture discovery, the implementation timeline has been reduced from 9 weeks to 6-7 weeks because the core pluggable architecture already exists.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#updated-phase-summary","title":"Updated Phase Summary","text":"Phase Focus Duration Rationale Phase 1 CLI + Config 2 weeks Add Cobra CLI and Koanf configuration to expose existing extension points Phase 2 Transport Layer 1-2 weeks Transport interface exists conceptually, needs explicit abstraction Phase 3 Public APIs 1 week Export internal packages, document extension points, provide examples Phase 4 Backend Integration 2 weeks Complete Docker/WASM integration, backend registry configuration Total 6-7 weeks 25% reduction from original 9-week estimate"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#key-insight","title":"Key Insight","text":"<p>The original proposal assumed significant refactoring work. The architecture discovery revealed:</p> <ol> <li>13 extension points already exist as Go interfaces</li> <li>10 sandbox backends already implemented (docker, k8s, wasm, etc.)</li> <li>Multi-backend per tool already supported with <code>BackendSelector</code></li> <li>Progressive disclosure already implemented (summary/schema/full)</li> <li>Security profiles already exist (dev/standard/hardened)</li> </ol> <p>The work is primarily configuration and exposure, not architecture redesign.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-1-detailed-plan-cli-config","title":"Phase 1 Detailed Plan (CLI + Config)","text":"<p>Goal: Make the 13 extension points configurable via YAML and CLI flags.</p> <pre><code># config.yaml - Complete configuration schema\nserver:\n  transport: stdio  # stdio | sse | websocket\n  port: 8080        # For HTTP transports\n\n# Extension Point #2: Searcher\nsearch:\n  strategy: bm25    # bm25 | simple | semantic\n  config:\n    name_boost: 3.0\n    tags_boost: 2.0\n\n# Extension Point #3: BackendSelector\nbackends:\n  selector: default  # default | latency | cost | custom\n  priority: [local, provider, mcp]\n\n# Extension Point #10: Runtime Backend\nruntime:\n  backend: docker    # unsafe | docker | k8s | wasm | gvisor\n  profile: standard  # dev | standard | hardened\n\n# Extension Point #12: Logger\nlogging:\n  level: info\n  format: json\n</code></pre> <p>CLI Commands: <pre><code>metatools serve --transport=stdio                    # Default MCP mode\nmetatools serve --transport=sse --port=8080          # HTTP/SSE mode\nmetatools serve --config=/path/to/config.yaml        # Full configuration\nmetatools list-tools                                 # List registered tools\nmetatools describe &lt;tool-id&gt;                         # Show tool documentation\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-evaluation","title":"Architecture Evaluation","text":"<p>A comprehensive evaluation against championship-level implementations has been performed. See architecture-evaluation.md for:</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#championship-implementations-analyzed","title":"Championship Implementations Analyzed","text":"Project Stars Key Patterns Tencent WeKnora 12,566 Multi-tenant RAG, layered architecture go-kratos/blades 700 Tool interfaces, middleware chain Official MCP Go SDK - Reference implementation patterns Google ADK for Go - A2A protocol, multi-agent fastmcp 22,398 Rapid MCP server development"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#current-position-85-championship-level","title":"Current Position: 85% Championship Level","text":"Category Score Status Core Architecture 95% \u2705 Excellent Pluggability 90% \u2705 13 extension points Security 95% \u2705 10 backends, 3 profiles Observability 40% \u26a0\ufe0f Needs OpenTelemetry Semantic Search 60% \u26a0\ufe0f BM25 only Protocol Coverage 70% \u26a0\ufe0f Missing resources/prompts"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#recommended-new-libraries","title":"Recommended New Libraries","text":"Library Purpose Priority toolobserve OpenTelemetry tracing + metrics High toolsemantic Vector-based semantic search Medium toolresource MCP Resources support Medium toolgateway Auth, rate limit, analytics proxy Medium"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#path-to-championship","title":"Path to Championship","text":"<ol> <li>Observability (toolobserve) - 2 weeks</li> <li>Semantic search (toolsemantic) - 2 weeks</li> <li>MCP Resources (toolresource) - 2 weeks</li> <li>Gateway/Proxy (toolgateway) - 2 weeks</li> </ol> <p>Total to 95%+ championship level: ~8 weeks</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#protocol-agnostic-tools","title":"Protocol-Agnostic Tools","text":"<p>A comprehensive proposal for protocol-agnostic tool exposure and composable toolsets has been created. See protocol-agnostic-tools.md for:</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#key-capabilities","title":"Key Capabilities","text":"Capability Description Protocol-agnostic interface Canonical tool representation independent of source or destination protocol Bidirectional adapters Convert tools between MCP, OpenAI, Anthropic, LangChain formats Toolset composition Create curated tool collections from multiple sources Multi-transport exposure Serve toolsets via MCP, direct client interfaces, REST, or A2A"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#proposed-new-libraries","title":"Proposed New Libraries","text":"Library Purpose tooladapter Canonical tool abstraction with protocol adapters toolset Composable tool collections with access control"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#adapter-support-matrix","title":"Adapter Support Matrix","text":"Protocol Import Export Notes MCP \u2705 \u2705 Full JSON Schema support OpenAI \u2705 \u2705 Includes strict mode Anthropic \u2705 \u2705 input_schema mapping LangChain \u2705 \u2705 Zod schema conversion OpenAPI \u2705 - Operation extraction"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#toolset-composition-pattern","title":"Toolset Composition Pattern","text":"<pre><code>// Create customer-specific toolset from multiple sources\ncustomerSet, _ := toolset.NewBuilder(\"customer-acme\").\n    FromRegistry(registry).\n    WithTools(\n        \"mcp.support.create_ticket\",\n        \"mcp.docs.search\",\n        \"openai.functions.analyze\",\n    ).\n    WithPolicy(&amp;toolset.AccessPolicy{\n        AllowedTenants: []string{\"acme-corp\"},\n    }).\n    Build()\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementation-timeline","title":"Implementation Timeline","text":"<ul> <li>Phase 1: Core adapter library (2 weeks)</li> <li>Phase 2: Toolset composition (2 weeks)</li> <li>Phase 3: Multi-transport exposure (2 weeks)</li> </ul> <p>Total: ~6 weeks</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#versioning-strategy","title":"Versioning Strategy","text":"<p>Critical Finding: Tool versioning causes 60% of production agent failures. Backward compatibility is the foundation of agent ecosystem stability.</p> <p>A comprehensive versioning strategy is essential for fast rollforward, safe rollback, and multi-version coexistence.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#versioning-layers","title":"Versioning Layers","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        VERSIONING ARCHITECTURE                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502  Layer 1: MCP PROTOCOL VERSION                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Version negotiation during initialization                                \u2502 \u2502\n\u2502  \u2502 Current: 2025-11-25 | Supported: [2024-11-05, 2025-03-26, 2025-06-18]  \u2502 \u2502\n\u2502  \u2502 \u2192 Server advertises supported versions                                   \u2502 \u2502\n\u2502  \u2502 \u2192 Client selects compatible version                                      \u2502 \u2502\n\u2502  \u2502 \u2192 Single version used for session                                        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  Layer 2: TOOL SCHEMA VERSION                                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Per-tool semantic versioning (MAJOR.MINOR.PATCH)                        \u2502 \u2502\n\u2502  \u2502 \u2192 MAJOR: Breaking input/output schema changes                           \u2502 \u2502\n\u2502  \u2502 \u2192 MINOR: New optional parameters, backward-compatible                   \u2502 \u2502\n\u2502  \u2502 \u2192 PATCH: Bug fixes, documentation updates                                \u2502 \u2502\n\u2502  \u2502 Multiple versions can be active simultaneously                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  Layer 3: BACKEND VERSION                                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 External API versions (OpenAI v1/v2, GitHub REST/GraphQL)               \u2502 \u2502\n\u2502  \u2502 \u2192 Version-specific adapters                                              \u2502 \u2502\n\u2502  \u2502 \u2192 Automatic version detection                                            \u2502 \u2502\n\u2502  \u2502 \u2192 Graceful degradation                                                   \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  Layer 4: CONFIGURATION VERSION                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Config file schema versioning                                            \u2502 \u2502\n\u2502  \u2502 \u2192 Version field at config root                                           \u2502 \u2502\n\u2502  \u2502 \u2192 Migration scripts for version upgrades                                 \u2502 \u2502\n\u2502  \u2502 \u2192 Validation against versioned schema                                    \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  Layer 5: DEPLOYMENT VERSION                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Blue/green, canary deployment support                                    \u2502 \u2502\n\u2502  \u2502 \u2192 Multiple server versions running simultaneously                       \u2502 \u2502\n\u2502  \u2502 \u2192 Traffic splitting by version                                          \u2502 \u2502\n\u2502  \u2502 \u2192 Instant rollback capability                                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#mcp-protocol-version-negotiation","title":"MCP Protocol Version Negotiation","text":"<pre><code>// toolversion/protocol.go\n\n// ProtocolVersions lists supported MCP specification versions\nvar ProtocolVersions = []string{\n    \"2025-11-25\",  // Latest (default)\n    \"2025-06-18\",  // OAuth 2.1 authorization\n    \"2025-03-26\",  // Batching (later removed)\n    \"2024-11-05\",  // Initial stable release\n}\n\n// VersionNegotiator handles protocol version selection\ntype VersionNegotiator struct {\n    supported []string\n    preferred string\n}\n\nfunc (n *VersionNegotiator) Negotiate(clientVersions []string) (string, error) {\n    // Find best matching version\n    for _, preferred := range n.supported {\n        for _, client := range clientVersions {\n            if preferred == client {\n                return preferred, nil\n            }\n        }\n    }\n    return \"\", ErrNoCompatibleVersion\n}\n\n// Server initialization with version negotiation\nfunc (s *Server) Initialize(ctx context.Context, req *mcp.InitializeRequest) (*mcp.InitializeResult, error) {\n    version, err := s.negotiator.Negotiate(req.ProtocolVersions)\n    if err != nil {\n        return nil, err\n    }\n\n    s.activeVersion = version\n\n    return &amp;mcp.InitializeResult{\n        ProtocolVersion: version,\n        ServerInfo: mcp.ServerInfo{\n            Name:    \"metatools-mcp\",\n            Version: s.serverVersion,\n        },\n        Capabilities: s.capabilitiesForVersion(version),\n    }, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#tool-schema-versioning","title":"Tool Schema Versioning","text":"<pre><code>// toolversion/tool.go\n\n// VersionedTool represents a tool with semantic versioning\ntype VersionedTool struct {\n    toolmodel.Tool\n\n    Version       semver.Version    // e.g., 2.1.0\n    MinVersion    semver.Version    // Minimum compatible version\n    Deprecated    bool\n    DeprecatedMsg string\n    Sunset        time.Time         // When this version will be removed\n}\n\n// ToolVersionRegistry manages multiple versions of tools\ntype ToolVersionRegistry struct {\n    tools map[string]map[semver.Version]*VersionedTool  // name -&gt; version -&gt; tool\n    mu    sync.RWMutex\n}\n\n// Register adds a versioned tool\nfunc (r *ToolVersionRegistry) Register(tool *VersionedTool) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    name := tool.Name()\n    if r.tools[name] == nil {\n        r.tools[name] = make(map[semver.Version]*VersionedTool)\n    }\n\n    r.tools[name][tool.Version] = tool\n    return nil\n}\n\n// Resolve finds the best matching tool version\nfunc (r *ToolVersionRegistry) Resolve(name string, constraint string) (*VersionedTool, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    versions, ok := r.tools[name]\n    if !ok {\n        return nil, ErrToolNotFound\n    }\n\n    // Parse constraint (e.g., \"&gt;=1.0.0 &lt;2.0.0\", \"^1.2.3\", \"~1.2.0\")\n    c, err := semver.NewConstraint(constraint)\n    if err != nil {\n        // No constraint = latest stable\n        return r.latestStable(name)\n    }\n\n    // Find best matching version\n    var best *VersionedTool\n    for ver, tool := range versions {\n        if c.Check(&amp;ver) &amp;&amp; !tool.Deprecated {\n            if best == nil || ver.GreaterThan(&amp;best.Version) {\n                best = tool\n            }\n        }\n    }\n\n    if best == nil {\n        return nil, ErrNoCompatibleVersion\n    }\n    return best, nil\n}\n\n// ListVersions returns all versions of a tool\nfunc (r *ToolVersionRegistry) ListVersions(name string) []VersionInfo {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    var versions []VersionInfo\n    for ver, tool := range r.tools[name] {\n        versions = append(versions, VersionInfo{\n            Version:    ver,\n            Deprecated: tool.Deprecated,\n            Sunset:     tool.Sunset,\n        })\n    }\n\n    sort.Slice(versions, func(i, j int) bool {\n        return versions[i].Version.GreaterThan(&amp;versions[j].Version)\n    })\n\n    return versions\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#schema-evolution-compatibility","title":"Schema Evolution &amp; Compatibility","text":"<pre><code>// toolversion/schema.go\n\n// CompatibilityMode defines schema evolution rules\ntype CompatibilityMode string\n\nconst (\n    // BACKWARD: New schema can read old data\n    CompatibilityBackward CompatibilityMode = \"BACKWARD\"\n    // FORWARD: Old schema can read new data\n    CompatibilityForward CompatibilityMode = \"FORWARD\"\n    // FULL: Both backward and forward compatible\n    CompatibilityFull CompatibilityMode = \"FULL\"\n    // NONE: No compatibility guarantees\n    CompatibilityNone CompatibilityMode = \"NONE\"\n)\n\n// SchemaEvolutionRules defines allowed changes per compatibility mode\nvar SchemaEvolutionRules = map[CompatibilityMode]EvolutionRules{\n    CompatibilityBackward: {\n        AllowAddOptionalField:    true,\n        AllowRemoveOptionalField: false,\n        AllowAddRequiredField:    false,  // Breaks old clients\n        AllowRemoveRequiredField: true,   // Old clients still work\n        AllowFieldTypeWidening:   true,   // int \u2192 long\n        AllowFieldTypeNarrowing:  false,\n    },\n    CompatibilityForward: {\n        AllowAddOptionalField:    false,  // Old readers can't handle\n        AllowRemoveOptionalField: true,\n        AllowAddRequiredField:    true,\n        AllowRemoveRequiredField: false,\n        AllowFieldTypeWidening:   false,\n        AllowFieldTypeNarrowing:  true,\n    },\n    CompatibilityFull: {\n        AllowAddOptionalField:    true,   // Only safe change\n        AllowRemoveOptionalField: false,\n        AllowAddRequiredField:    false,\n        AllowRemoveRequiredField: false,\n        AllowFieldTypeWidening:   false,\n        AllowFieldTypeNarrowing:  false,\n    },\n}\n\n// SchemaValidator checks if schema change is compatible\ntype SchemaValidator struct {\n    mode CompatibilityMode\n}\n\nfunc (v *SchemaValidator) ValidateChange(old, new *jsonschema.Schema) error {\n    rules := SchemaEvolutionRules[v.mode]\n    changes := v.detectChanges(old, new)\n\n    for _, change := range changes {\n        if !rules.IsAllowed(change) {\n            return &amp;CompatibilityError{\n                Change: change,\n                Mode:   v.mode,\n            }\n        }\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#version-aware-tool-resolution","title":"Version-Aware Tool Resolution","text":"<pre><code>// toolversion/resolver.go\n\n// VersionedToolRequest specifies version constraints\ntype VersionedToolRequest struct {\n    Name           string\n    VersionSpec    string  // Semver constraint: \"^1.0.0\", \"&gt;=2.0.0\", \"latest\"\n    PreferStable   bool\n    AllowPrerelease bool\n}\n\n// Resolver determines which tool version to use\ntype Resolver struct {\n    registry *ToolVersionRegistry\n    cache    Cache\n    metrics  VersionMetrics\n}\n\nfunc (r *Resolver) Resolve(ctx context.Context, req VersionedToolRequest) (*VersionedTool, error) {\n    // Check cache first\n    cacheKey := fmt.Sprintf(\"resolve:%s:%s\", req.Name, req.VersionSpec)\n    if cached, ok := r.cache.Get(ctx, cacheKey); ok {\n        return cached.(*VersionedTool), nil\n    }\n\n    var tool *VersionedTool\n    var err error\n\n    switch req.VersionSpec {\n    case \"\", \"latest\":\n        tool, err = r.registry.Resolve(req.Name, \"*\")\n    default:\n        tool, err = r.registry.Resolve(req.Name, req.VersionSpec)\n    }\n\n    if err != nil {\n        return nil, err\n    }\n\n    // Warn if using deprecated version\n    if tool.Deprecated {\n        r.metrics.DeprecatedToolUsage.Inc(labels{\n            \"tool\":    req.Name,\n            \"version\": tool.Version.String(),\n        })\n        log.Warn(\"Using deprecated tool version\",\n            \"tool\", req.Name,\n            \"version\", tool.Version,\n            \"message\", tool.DeprecatedMsg,\n            \"sunset\", tool.Sunset,\n        )\n    }\n\n    r.cache.Set(ctx, cacheKey, tool, 5*time.Minute)\n    return tool, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#multi-version-deployment","title":"Multi-Version Deployment","text":"<pre><code>// toolversion/deployment.go\n\n// DeploymentVersion represents a running server version\ntype DeploymentVersion struct {\n    ServerVersion string\n    GitCommit     string\n    BuildTime     time.Time\n    Features      []string\n}\n\n// VersionRouter routes requests to appropriate server versions\ntype VersionRouter struct {\n    versions map[string]*ServerInstance\n    weights  map[string]int  // Traffic percentage\n}\n\n// Route selects server version based on routing rules\nfunc (r *VersionRouter) Route(ctx context.Context, req *Request) (*ServerInstance, error) {\n    // Check for explicit version header\n    if ver := req.Header.Get(\"X-Tool-Version\"); ver != \"\" {\n        if instance, ok := r.versions[ver]; ok {\n            return instance, nil\n        }\n    }\n\n    // Check for client-specified version preference\n    if pref := ctx.Value(versionPreferenceKey); pref != nil {\n        if instance, ok := r.versions[pref.(string)]; ok {\n            return instance, nil\n        }\n    }\n\n    // Weighted random selection (for canary deployments)\n    return r.weightedSelect(), nil\n}\n\n// DeploymentManager handles version lifecycle\ntype DeploymentManager struct {\n    router   *VersionRouter\n    registry *ToolVersionRegistry\n}\n\n// Canary starts a canary deployment\nfunc (m *DeploymentManager) Canary(newVersion string, percentage int) error {\n    m.router.weights[newVersion] = percentage\n    m.router.weights[\"stable\"] = 100 - percentage\n    return nil\n}\n\n// Promote makes a version the new stable\nfunc (m *DeploymentManager) Promote(version string) error {\n    m.router.weights = map[string]int{version: 100}\n    return nil\n}\n\n// Rollback reverts to previous stable version\nfunc (m *DeploymentManager) Rollback() error {\n    // Instant traffic shift to previous stable\n    return m.Promote(m.previousStable)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#version-configuration","title":"Version Configuration","text":"<pre><code># metatools.yaml\nversion: \"1.0.0\"  # Config schema version\n\nserver:\n  version: \"2.3.1\"\n\nprotocol:\n  supported_versions:\n    - \"2025-11-25\"\n    - \"2025-06-18\"\n    - \"2024-11-05\"\n  default_version: \"2025-11-25\"\n\ntools:\n  versioning:\n    enabled: true\n    compatibility_mode: BACKWARD  # BACKWARD, FORWARD, FULL, NONE\n\n    # Per-tool version configuration\n    versions:\n      github/create_issue:\n        - version: \"2.0.0\"\n          status: stable\n        - version: \"1.5.0\"\n          status: deprecated\n          sunset: \"2026-06-01\"\n          message: \"Use v2.0.0 - improved error handling\"\n        - version: \"1.0.0\"\n          status: sunset  # Will be removed\n\n    # Version resolution rules\n    resolution:\n      prefer_stable: true\n      allow_prerelease: false\n      default_constraint: \"^\"  # Caret = compatible with major version\n\ndeployment:\n  strategy: canary  # blue_green, canary, rolling\n\n  canary:\n    initial_percentage: 5\n    increment: 10\n    interval: 5m\n    rollback_threshold:\n      error_rate: 0.05\n      latency_p99: 2s\n\n  versions:\n    stable: \"2.3.0\"\n    canary: \"2.3.1\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#mcp-tool-registration-with-versioning","title":"MCP Tool Registration with Versioning","text":"<pre><code>// Expose versioned tools via MCP\nfunc (s *Server) listTools(ctx context.Context) ([]mcp.Tool, error) {\n    var tools []mcp.Tool\n\n    for _, vt := range s.versionRegistry.AllLatestStable() {\n        tool := vt.Tool.ToMCP()\n\n        // Add version metadata as annotations\n        tool.Annotations = map[string]any{\n            \"version\":      vt.Version.String(),\n            \"min_version\":  vt.MinVersion.String(),\n            \"deprecated\":   vt.Deprecated,\n            \"sunset\":       vt.Sunset,\n        }\n\n        // Version in description for AI visibility\n        if vt.Deprecated {\n            tool.Description = fmt.Sprintf(\"[DEPRECATED: %s] %s\",\n                vt.DeprecatedMsg, tool.Description)\n        }\n\n        tools = append(tools, tool)\n    }\n\n    return tools, nil\n}\n\n// Handle tool calls with version resolution\nfunc (s *Server) callTool(ctx context.Context, req *mcp.CallToolRequest) (*mcp.CallToolResult, error) {\n    // Extract version from request (if specified)\n    versionSpec := \"latest\"\n    if v, ok := req.Arguments[\"_version\"].(string); ok {\n        versionSpec = v\n        delete(req.Arguments, \"_version\")  // Remove meta-argument\n    }\n\n    // Resolve tool version\n    tool, err := s.resolver.Resolve(ctx, VersionedToolRequest{\n        Name:        req.Name,\n        VersionSpec: versionSpec,\n    })\n    if err != nil {\n        return nil, err\n    }\n\n    // Execute with resolved version\n    return tool.Execute(ctx, req.Arguments)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#versioning-best-practices","title":"Versioning Best Practices","text":"Rule Rationale Never break existing function signatures Old clients must continue working Add optional parameters, never remove required ones Backward compatibility Don't delete safety rules or constraints Maintain security guarantees Deprecate before removing Give users migration time Version from day one Adding versioning later is exponentially harder Announce breaking changes in MAJOR Clear semantic meaning Maintain audit trails for version changes Compliance and debugging"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#proposed-library-toolversion","title":"Proposed Library: <code>toolversion</code>","text":"<pre><code>toolversion/\n\u251c\u2500\u2500 protocol.go        # MCP protocol version negotiation\n\u251c\u2500\u2500 semver.go          # Semantic version parsing and comparison\n\u251c\u2500\u2500 registry.go        # Multi-version tool registry\n\u251c\u2500\u2500 resolver.go        # Version constraint resolution\n\u251c\u2500\u2500 schema.go          # Schema evolution validation\n\u251c\u2500\u2500 compatibility.go   # Compatibility mode enforcement\n\u251c\u2500\u2500 deployment.go      # Blue/green, canary deployment support\n\u251c\u2500\u2500 migration.go       # Version migration helpers\n\u2514\u2500\u2500 metrics.go         # Version usage metrics\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#multi-language-extensibility","title":"Multi-Language Extensibility","text":"<p>Key Insight: The pluggable architecture is not limited to Go implementations. Any component defined by an interface can be implemented in any programming language through standardized interface contracts.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-principle","title":"Architecture Principle","text":"<p>All extension points in this architecture (Transport, Searcher, Cache, Backend, etc.) are defined as Go interfaces. These interfaces can be implemented in any language using:</p> <ol> <li>gRPC + Protocol Buffers (recommended) - Battle-tested, used by HashiCorp Terraform/Vault</li> <li>WebAssembly Component Model - Sandboxed, portable, no network overhead</li> <li>JSON-RPC over stdio - Simple, any executable works</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#use-cases","title":"Use Cases","text":"Component Preferred Language Rationale Embedder Python Rich ML ecosystem (PyTorch, sentence-transformers) VectorIndex Rust SIMD performance, memory safety Reranker Python Hugging Face cross-encoders KnowledgeGraph Python/Java Neo4j, NetworkX bindings Custom Adapter TypeScript Existing MCP servers, quick prototypes"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#interface-contracts-via-protocol-buffers","title":"Interface Contracts via Protocol Buffers","text":"<p>All Go interfaces are documented as Protocol Buffer service definitions, enabling automatic SDK generation for Python, Rust, TypeScript, Java, and more.</p> <pre><code>// Example: Embedder interface as protobuf\nservice Embedder {\n  rpc Embed(EmbedRequest) returns (EmbedResponse);\n  rpc EmbedBatch(EmbedBatchRequest) returns (EmbedBatchResponse);\n  rpc Info(InfoRequest) returns (EmbedderInfo);\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#full-specification","title":"Full Specification","text":"<p>See ROADMAP.md Section 8: Multi-Language Extensibility for: - Complete gRPC plugin architecture with HashiCorp go-plugin patterns - WebAssembly Interface Types (WIT) definitions - JSON-RPC fallback for simple plugins - SDK generation for Python, Rust, TypeScript - Configuration examples for multi-language plugins</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#open-questions","title":"Open Questions","text":"<ol> <li>ToolProvider interface - Does the proposed interface feel right for plug-and-play tools?</li> <li>Middleware chain - Useful now, or defer until needed?</li> <li>Backend configuration - YAML-driven or code-only for now?</li> <li>Semantic search - Priority for vector/embedding-based search strategy?</li> <li>Multi-tenancy - Which isolation strategy (shared, namespace, process) is primary target?</li> <li>Versioning compatibility mode - Should BACKWARD be the default, or FULL for maximum safety?</li> <li>MCP protocol versions - How far back should we support? (2024-11-05 is the oldest stable)</li> <li>Tool version in tool names - Should version be part of tool name (<code>github/create_issue@2</code>) or metadata?</li> <li>Breaking change policy - What's the minimum deprecation window before sunset?</li> <li>Multi-language plugins - Should gRPC be the primary contract mechanism, or prioritize WASM for sandboxing?</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#changelog","title":"Changelog","text":"Date Change 2026-01-27 Initial draft 2026-01-27 Added Multi-Backend Architecture section with diagrams 2026-01-27 Expanded Middleware Chain section with pluggable design 2026-01-27 Added comprehensive Transport Layer section with all protocols 2026-01-27 Added End-to-End Examples section with 5 real-world scenarios 2026-01-27 Added Architecture Validation section with industry pattern verification 2026-01-27 Created detailed Implementation Phases document (see implementation-phases.md) 2026-01-27 Added Component Library Analysis for all 7 tool* libraries (see component-library-analysis.md) 2026-01-28 Added Multi-Tenancy Extension for pluggable tenant isolation (see multi-tenancy.md) 2026-01-28 Added Extension Point Catalog documenting 13 existing pluggable interfaces across all component libraries 2026-01-28 Added Revised Implementation Timeline (6-7 weeks, 25% reduction from original 9-week estimate) 2026-01-28 Key finding: Architecture is already 85%+ pluggable - needs exposure and configuration, not redesign 2026-01-28 Added Architecture Evaluation comparing against 5 championship-level implementations 2026-01-28 Identified 4 potential new libraries: toolobserve, toolsemantic, toolresource, toolgateway 2026-01-28 Added Protocol-Agnostic Tools section with 2 new proposed libraries: tooladapter, toolset 2026-01-28 Created comprehensive proposal for composable toolsets and protocol adapters (see protocol-agnostic-tools.md) 2026-01-28 Added Cache Layer as extension point #6 with pluggable backends (memory, Redis, SQLite, layered) 2026-01-28 Proposed new library: <code>toolcache</code> for cross-component caching with invalidation strategies 2026-01-28 Added section 7: Additional Cross-Cutting Concerns with comprehensive enterprise patterns 2026-01-28 Documented 12 cross-cutting concerns: cache, circuit breaker, retry, bulkhead, health checks, secrets, config reload, feature flags, audit trail, backpressure, timeout, tracing 2026-01-28 Proposed 6 new libraries for cross-cutting concerns: toolresilience, toolhealth, toolsecrets, toolflags, toolaudit, toolpressure 2026-01-28 Added comprehensive Versioning Strategy section (section 19) 2026-01-28 Documented 5 versioning layers: MCP protocol, tool schema, backend, configuration, deployment 2026-01-28 Added schema evolution with BACKWARD/FORWARD/FULL compatibility modes 2026-01-28 Added blue/green and canary deployment support for multi-version coexistence 2026-01-28 Proposed new library: <code>toolversion</code> for semantic versioning and version negotiation 2026-01-28 Created master ROADMAP.md consolidating all proposals into 4 work streams and 17-week timeline 2026-01-28 Total library inventory: 7 existing + 14 proposed = 21 libraries for enterprise-ready platform 2026-01-28 Added Section 20: Multi-Language Extensibility - gRPC/WASM/JSON-RPC plugin contracts for Python, Rust, TypeScript"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/","title":"Protocol-Agnostic Tools and Composable Toolsets","text":"<p>Status: Draft Last Updated: 2026-01-28 Authors: Architecture Team Related: Master Roadmap (Stream B: Protocol Layer), Pluggable Architecture</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Executive Summary</li> <li>Problem Statement</li> <li>Goals and Non-Goals</li> <li>Research Findings</li> <li>Proposed Architecture</li> <li>Tool Abstraction Layer</li> <li>Protocol Adapters</li> <li>Composable Toolsets</li> <li>Integration with Existing Libraries</li> <li>Implementation Roadmap</li> <li>Appendix: Industry Patterns</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#executive-summary","title":"Executive Summary","text":"<p>This proposal extends metatools-mcp's pluggable architecture to support protocol-agnostic tool exposure and composable toolsets. Rather than limiting tool consumption to the MCP protocol, we introduce an adaptability layer that enables tools from any source (MCP backends, custom providers, local implementations) to be exposed through multiple transport protocols and consumed by various AI agent frameworks.</p> <p>Key capabilities: - Protocol-agnostic tool interface - Canonical tool representation independent of source or destination protocol - Bidirectional adapters - Convert tools between MCP, OpenAI, Anthropic, LangChain, and other formats - Toolset composition - Create curated tool collections from multiple sources - Multi-transport exposure - Serve toolsets via MCP, direct client interfaces, REST, or A2A</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#problem-statement","title":"Problem Statement","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#current-limitations","title":"Current Limitations","text":"<ol> <li> <p>MCP-Only Exposure: metatools-mcp currently exposes tools exclusively through the MCP protocol. Organizations with mature AI environments using different tool calling conventions (OpenAI function calling, Anthropic tool use, LangChain tools) cannot directly consume metatools without MCP integration.</p> </li> <li> <p>Fixed Tool Collections: All registered tools are exposed as a single collection. There's no mechanism to create curated toolsets for different use cases (development vs production, team A vs team B, customer-specific).</p> </li> <li> <p>One-Way Conversion: Tools flow from backends \u2192 MCP \u2192 clients. There's no standardized way to import tools from external sources (OpenAPI specs, LangChain tools, OpenAI functions) into the metatools ecosystem.</p> </li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#industry-context","title":"Industry Context","text":"<p>Research reveals a fragmented landscape of tool formats:</p> Provider Format Key Differences MCP <code>Tool</code> with <code>inputSchema</code> Rich JSON Schema, supports resources/prompts OpenAI <code>function</code> with <code>parameters</code> Strict mode available, simpler schema Anthropic <code>tool</code> with <code>input_schema</code> Similar to MCP but different field names LangChain <code>StructuredTool</code> Python/JS-centric, Zod schemas A2A Agent-defined Inter-agent tool delegation <p>The Mastra framework demonstrated that proper tool format conversion reduces error rates from 15% to 3% across providers.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#goals-and-non-goals","title":"Goals and Non-Goals","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#goals","title":"Goals","text":"<ol> <li>Protocol Independence: Tools can be consumed without MCP protocol dependency</li> <li>Format Preservation: Tool semantics survive conversion without information loss</li> <li>Bidirectional Flow: Import tools from external sources, export to any format</li> <li>Composability: Create, manage, and expose custom tool collections</li> <li>Backward Compatibility: Existing MCP-based workflows remain unchanged</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#non-goals","title":"Non-Goals","text":"<ol> <li>Runtime Protocol Bridging: We're not building a universal protocol translator</li> <li>Tool Implementation: Adapters convert metadata, not execution logic</li> <li>Full A2A Implementation: Agent orchestration is out of scope</li> <li>Schema Validation Engine: We rely on existing validation libraries</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#research-findings","title":"Research Findings","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#pattern-1-unified-tool-abstraction-toolregistry-paper","title":"Pattern 1: Unified Tool Abstraction (ToolRegistry Paper)","text":"<p>The ArXiv paper \"Unified Tool Integration for LLMs\" establishes a three-layer architecture:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 Layer 3: API Compatibility              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502 OpenAI  \u2502  \u2502Anthropic\u2502  \u2502LangChain\u2502  \u2502   MCP   \u2502   \u2502\n\u2502   \u2502 Format  \u2502  \u2502 Format  \u2502  \u2502 Format  \u2502  \u2502 Format  \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502        \u2502            \u2502            \u2502            \u2502         \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                           \u2502                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                 Layer 2: Protocol Adapters              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  MCP    \u2502  \u2502 OpenAPI \u2502  \u2502LangChain\u2502  \u2502 Custom  \u2502   \u2502\n\u2502   \u2502 Adapter \u2502  \u2502 Adapter \u2502  \u2502 Adapter \u2502  \u2502 Adapter \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502        \u2502            \u2502            \u2502            \u2502         \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                           \u2502                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                 Layer 1: Unified Abstraction            \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n\u2502                    \u2502 Canonical Tool\u2502                    \u2502\n\u2502                    \u2502  Abstraction  \u2502                    \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key Insight: The canonical tool representation stores the superset of all schema information, enabling lossless conversion between formats.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#pattern-2-langchain-mcp-adapter","title":"Pattern 2: LangChain MCP Adapter","text":"<p>LangChain's <code>langchainjs-mcp-adapters</code> demonstrates practical conversion:</p> <pre><code>// MCP Tool \u2192 LangChain DynamicStructuredTool\nexport async function loadMcpTools(\n  serverName: string,\n  client: Client,\n): Promise&lt;StructuredToolInterface[]&gt; {\n  const toolsResponse = await client.listTools();\n  return toolsResponse.tools.map((tool: MCPTool) =&gt; {\n    return new DynamicStructuredTool({\n      name: `${serverName}_${tool.name}`,\n      description: tool.description || \"\",\n      schema: tool.inputSchema,  // Direct schema pass-through\n      func: callTool.bind(null, serverName, tool.name, client)\n    });\n  });\n}\n</code></pre> <p>Key Insight: Namespacing (<code>serverName_toolName</code>) prevents collisions when aggregating tools from multiple sources.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#pattern-3-multi-language-tool-declaration-llm-functions","title":"Pattern 3: Multi-Language Tool Declaration (llm-functions)","text":"<p>The <code>llm-functions</code> library shows format-agnostic tool declaration:</p> <pre><code># Bash: Comment annotations\n# @describe Search the web\n# @option --query! The search query\n# @option --num_results=10 Number of results\nsearch_web() { ... }\n</code></pre> <pre><code>// JavaScript: JSDoc\n/**\n * @typedef {Object} Args\n * @property {string} query - The search query\n * @property {number} [num_results=10] - Number of results\n */\n</code></pre> <pre><code># Python: Type hints + docstrings\ndef search_web(query: str, num_results: int = 10):\n    \"\"\"Search the web.\n\n    Args:\n        query: The search query\n        num_results: Number of results (default: 10)\n    \"\"\"\n</code></pre> <p>Key Insight: All three declarations compile to identical JSON Schema, proving format-agnostic tool definitions are achievable.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#pattern-4-tool-rag-for-large-registries","title":"Pattern 4: Tool RAG for Large Registries","text":"<p>For registries with 50+ tools, semantic search dramatically improves tool selection:</p> Approach Accuracy (50 tools) Accuracy (500 tools) Keyword matching 65% 23% BM25 (current) 78% 45% Vector embeddings 89% 72% Hybrid (BM25 + vector) 94% 81% <p>Anthropic's RAG-MCP implementation showed 13% \u2192 43% accuracy improvement using Tool RAG.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#proposed-architecture","title":"Proposed Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#new-library-tooladapter","title":"New Library: <code>tooladapter</code>","text":"<p>A dedicated library for protocol-agnostic tool handling:</p> <pre><code>tooladapter/\n\u251c\u2500\u2500 canonical.go      # Canonical tool representation\n\u251c\u2500\u2500 adapter.go        # Adapter interface\n\u251c\u2500\u2500 adapters/\n\u2502   \u251c\u2500\u2500 mcp.go        # MCP \u2194 Canonical\n\u2502   \u251c\u2500\u2500 openai.go     # OpenAI \u2194 Canonical\n\u2502   \u251c\u2500\u2500 anthropic.go  # Anthropic \u2194 Canonical\n\u2502   \u251c\u2500\u2500 langchain.go  # LangChain \u2194 Canonical\n\u2502   \u2514\u2500\u2500 openapi.go    # OpenAPI \u2194 Canonical\n\u251c\u2500\u2500 schema/\n\u2502   \u251c\u2500\u2500 convert.go    # JSON Schema version conversion\n\u2502   \u2514\u2500\u2500 validate.go   # Schema validation\n\u2514\u2500\u2500 registry.go       # Adapter registry\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#new-library-toolset","title":"New Library: <code>toolset</code>","text":"<p>Composable tool collections:</p> <pre><code>toolset/\n\u251c\u2500\u2500 set.go            # Toolset definition\n\u251c\u2500\u2500 builder.go        # Fluent toolset construction\n\u251c\u2500\u2500 filter.go         # Tool filtering predicates\n\u251c\u2500\u2500 policy.go         # Access control policies\n\u2514\u2500\u2500 expose.go         # Multi-protocol exposure\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        metatools-mcp Server                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502    MCP      \u2502  \u2502   Direct    \u2502  \u2502    REST     \u2502  \u2502    A2A     \u2502  \u2502\n\u2502  \u2502  Transport  \u2502  \u2502   Client    \u2502  \u2502     API     \u2502  \u2502  Protocol  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502         \u2502                \u2502                \u2502               \u2502          \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                                   \u2502                                  \u2502\n\u2502                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502                          \u2502    toolset      \u2502                         \u2502\n\u2502                          \u2502   Composer      \u2502                         \u2502\n\u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502                                   \u2502                                  \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502         \u2502                         \u2502                         \u2502        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   Toolset   \u2502  \u2502        Toolset              \u2502  \u2502   Toolset    \u2502 \u2502\n\u2502  \u2502  \"dev-ops\"  \u2502  \u2502      \"customer-x\"           \u2502  \u2502    \"prod\"    \u2502 \u2502\n\u2502  \u2502 [A,C,E,F]   \u2502  \u2502       [B,D,F]               \u2502  \u2502   [A,B,D]    \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502         \u2502                         \u2502                         \u2502        \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502                                   \u2502                                  \u2502\n\u2502                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502                          \u2502   tooladapter   \u2502                         \u2502\n\u2502                          \u2502   (Canonical)   \u2502                         \u2502\n\u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502                                   \u2502                                  \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502    \u2502              \u2502               \u2502               \u2502              \u2502   \u2502\n\u2502 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2510 \u2502\n\u2502 \u2502 MCP  \u2502    \u2502  OpenAI  \u2502   \u2502  Anthropic \u2502  \u2502LangChain \u2502  \u2502 OpenAPI\u2502 \u2502\n\u2502 \u2502Adapter\u2502   \u2502  Adapter \u2502   \u2502   Adapter  \u2502  \u2502 Adapter  \u2502  \u2502 Adapter\u2502 \u2502\n\u2502 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2518 \u2502\n\u2502    \u2502              \u2502               \u2502               \u2502              \u2502   \u2502\n\u251c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502    \u2502              \u2502               \u2502               \u2502              \u2502   \u2502\n\u2502 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2510 \u2502\n\u2502 \u2502 MCP  \u2502    \u2502 External \u2502   \u2502  External  \u2502  \u2502 External \u2502  \u2502  REST  \u2502 \u2502\n\u2502 \u2502Server\u2502    \u2502  OpenAI  \u2502   \u2502  Anthropic \u2502  \u2502LangChain \u2502  \u2502  APIs  \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  Tools   \u2502   \u2502   Tools    \u2502  \u2502  Tools   \u2502  \u2502        \u2502 \u2502\n\u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#tool-abstraction-layer","title":"Tool Abstraction Layer","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#canonical-tool-interface","title":"Canonical Tool Interface","text":"<pre><code>// tooladapter/canonical.go\n\n// CanonicalTool is the protocol-agnostic tool representation\ntype CanonicalTool struct {\n    // Identity\n    ID          string            // Globally unique identifier\n    Namespace   string            // Source namespace (e.g., \"mcp.github\", \"openai.functions\")\n    Name        string            // Tool name within namespace\n    Version     string            // Semantic version\n\n    // Metadata\n    Description string            // Human-readable description\n    Category    string            // Tool category for grouping\n    Tags        []string          // Searchable tags\n\n    // Schema (superset of all protocol schemas)\n    InputSchema  *JSONSchema      // Full JSON Schema for inputs\n    OutputSchema *JSONSchema      // Optional output schema\n\n    // Execution\n    Handler     ToolHandler       // Execution function\n    Timeout     time.Duration     // Execution timeout\n\n    // Source tracking\n    SourceFormat string           // Original format (mcp, openai, anthropic, etc.)\n    SourceMeta   map[string]any   // Protocol-specific metadata preserved\n\n    // Access control\n    RequiredScopes []string       // OAuth scopes or permissions required\n}\n\n// JSONSchema represents a full JSON Schema with all features\ntype JSONSchema struct {\n    Type        string                 `json:\"type\"`\n    Properties  map[string]*JSONSchema `json:\"properties,omitempty\"`\n    Required    []string               `json:\"required,omitempty\"`\n    Items       *JSONSchema            `json:\"items,omitempty\"`\n    Description string                 `json:\"description,omitempty\"`\n\n    // Extended schema features (preserved during conversion)\n    Enum        []any                  `json:\"enum,omitempty\"`\n    Const       any                    `json:\"const,omitempty\"`\n    Default     any                    `json:\"default,omitempty\"`\n    Minimum     *float64               `json:\"minimum,omitempty\"`\n    Maximum     *float64               `json:\"maximum,omitempty\"`\n    MinLength   *int                   `json:\"minLength,omitempty\"`\n    MaxLength   *int                   `json:\"maxLength,omitempty\"`\n    Pattern     string                 `json:\"pattern,omitempty\"`\n    Format      string                 `json:\"format,omitempty\"`\n\n    // JSON Schema draft compatibility\n    Ref         string                 `json:\"$ref,omitempty\"`\n    Defs        map[string]*JSONSchema `json:\"$defs,omitempty\"`\n}\n\n// ToolHandler executes the tool\ntype ToolHandler func(ctx context.Context, input map[string]any) (any, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#adapter-interface","title":"Adapter Interface","text":"<pre><code>// tooladapter/adapter.go\n\n// Adapter converts between canonical and protocol-specific formats\ntype Adapter interface {\n    // Name returns the adapter identifier (e.g., \"mcp\", \"openai\")\n    Name() string\n\n    // ToCanonical converts protocol-specific tool to canonical form\n    ToCanonical(raw any) (*CanonicalTool, error)\n\n    // FromCanonical converts canonical tool to protocol-specific form\n    FromCanonical(tool *CanonicalTool) (any, error)\n\n    // SupportsFeature checks if adapter supports a schema feature\n    SupportsFeature(feature SchemaFeature) bool\n}\n\n// SchemaFeature represents JSON Schema features that may not be universally supported\ntype SchemaFeature int\n\nconst (\n    FeatureNestedObjects SchemaFeature = iota\n    FeatureArrays\n    FeatureEnums\n    FeaturePatternValidation\n    FeatureRefDefinitions\n    FeatureNullable\n    FeatureAnyOf\n    FeatureOneOf\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#protocol-adapters","title":"Protocol Adapters","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#mcp-adapter","title":"MCP Adapter","text":"<pre><code>// tooladapter/adapters/mcp.go\n\ntype MCPAdapter struct{}\n\nfunc (a *MCPAdapter) Name() string { return \"mcp\" }\n\nfunc (a *MCPAdapter) ToCanonical(raw any) (*CanonicalTool, error) {\n    mcpTool, ok := raw.(*mcp.Tool)\n    if !ok {\n        return nil, fmt.Errorf(\"expected *mcp.Tool, got %T\", raw)\n    }\n\n    return &amp;CanonicalTool{\n        ID:          fmt.Sprintf(\"mcp.%s\", mcpTool.Name),\n        Namespace:   \"mcp\",\n        Name:        mcpTool.Name,\n        Description: mcpTool.Description,\n        InputSchema: convertMCPSchema(mcpTool.InputSchema),\n        SourceFormat: \"mcp\",\n        SourceMeta: map[string]any{\n            \"annotations\": mcpTool.Annotations,\n        },\n    }, nil\n}\n\nfunc (a *MCPAdapter) FromCanonical(tool *CanonicalTool) (any, error) {\n    return &amp;mcp.Tool{\n        Name:        tool.Name,\n        Description: tool.Description,\n        InputSchema: convertToMCPSchema(tool.InputSchema),\n    }, nil\n}\n\nfunc (a *MCPAdapter) SupportsFeature(f SchemaFeature) bool {\n    // MCP supports full JSON Schema\n    return true\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#openai-adapter","title":"OpenAI Adapter","text":"<pre><code>// tooladapter/adapters/openai.go\n\ntype OpenAIAdapter struct {\n    StrictMode bool // Enable OpenAI's strict schema mode\n}\n\nfunc (a *OpenAIAdapter) Name() string { return \"openai\" }\n\nfunc (a *OpenAIAdapter) ToCanonical(raw any) (*CanonicalTool, error) {\n    fn, ok := raw.(*OpenAIFunction)\n    if !ok {\n        return nil, fmt.Errorf(\"expected *OpenAIFunction, got %T\", raw)\n    }\n\n    return &amp;CanonicalTool{\n        ID:          fmt.Sprintf(\"openai.%s\", fn.Name),\n        Namespace:   \"openai\",\n        Name:        fn.Name,\n        Description: fn.Description,\n        InputSchema: convertOpenAIParameters(fn.Parameters),\n        SourceFormat: \"openai\",\n        SourceMeta: map[string]any{\n            \"strict\": fn.Strict,\n        },\n    }, nil\n}\n\nfunc (a *OpenAIAdapter) FromCanonical(tool *CanonicalTool) (any, error) {\n    params := convertToOpenAIParameters(tool.InputSchema, a.StrictMode)\n\n    return &amp;OpenAIFunction{\n        Name:        tool.Name,\n        Description: tool.Description,\n        Parameters:  params,\n        Strict:      a.StrictMode,\n    }, nil\n}\n\nfunc (a *OpenAIAdapter) SupportsFeature(f SchemaFeature) bool {\n    switch f {\n    case FeatureRefDefinitions:\n        return false // OpenAI doesn't support $ref\n    case FeaturePatternValidation:\n        return a.StrictMode // Only in strict mode\n    default:\n        return true\n    }\n}\n\n// OpenAI function format\ntype OpenAIFunction struct {\n    Name        string         `json:\"name\"`\n    Description string         `json:\"description,omitempty\"`\n    Parameters  map[string]any `json:\"parameters\"`\n    Strict      bool           `json:\"strict,omitempty\"`\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#anthropic-adapter","title":"Anthropic Adapter","text":"<pre><code>// tooladapter/adapters/anthropic.go\n\ntype AnthropicAdapter struct{}\n\nfunc (a *AnthropicAdapter) Name() string { return \"anthropic\" }\n\nfunc (a *AnthropicAdapter) ToCanonical(raw any) (*CanonicalTool, error) {\n    tool, ok := raw.(*AnthropicTool)\n    if !ok {\n        return nil, fmt.Errorf(\"expected *AnthropicTool, got %T\", raw)\n    }\n\n    return &amp;CanonicalTool{\n        ID:          fmt.Sprintf(\"anthropic.%s\", tool.Name),\n        Namespace:   \"anthropic\",\n        Name:        tool.Name,\n        Description: tool.Description,\n        InputSchema: convertAnthropicSchema(tool.InputSchema),\n        SourceFormat: \"anthropic\",\n    }, nil\n}\n\nfunc (a *AnthropicAdapter) FromCanonical(tool *CanonicalTool) (any, error) {\n    return &amp;AnthropicTool{\n        Name:        tool.Name,\n        Description: tool.Description,\n        InputSchema: convertToAnthropicSchema(tool.InputSchema),\n    }, nil\n}\n\n// AnthropicTool matches Anthropic's tool format\ntype AnthropicTool struct {\n    Name        string         `json:\"name\"`\n    Description string         `json:\"description,omitempty\"`\n    InputSchema map[string]any `json:\"input_schema\"`\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#schema-conversion-utilities","title":"Schema Conversion Utilities","text":"<pre><code>// tooladapter/schema/convert.go\n\n// StripUnsupportedFeatures removes schema features not supported by target\nfunc StripUnsupportedFeatures(schema *JSONSchema, adapter Adapter) *JSONSchema {\n    result := schema.DeepCopy()\n\n    if !adapter.SupportsFeature(FeatureRefDefinitions) {\n        result = resolveRefs(result)\n    }\n\n    if !adapter.SupportsFeature(FeaturePatternValidation) {\n        clearPatterns(result)\n    }\n\n    if !adapter.SupportsFeature(FeatureAnyOf) {\n        result = flattenAnyOf(result)\n    }\n\n    return result\n}\n\n// PreserveSemantics records stripped features for potential restoration\nfunc PreserveSemantics(original, stripped *JSONSchema) map[string]any {\n    return map[string]any{\n        \"original_features\": detectFeatures(original),\n        \"stripped_features\": detectStrippedFeatures(original, stripped),\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#composable-toolsets","title":"Composable Toolsets","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#toolset-definition","title":"Toolset Definition","text":"<pre><code>// toolset/set.go\n\n// Toolset represents a curated collection of tools\ntype Toolset struct {\n    ID          string                 // Unique identifier\n    Name        string                 // Human-readable name\n    Description string                 // Purpose description\n\n    // Tool selection\n    Tools       []*tooladapter.CanonicalTool\n\n    // Metadata\n    Tags        []string               // Searchable tags\n    Owner       string                 // Owner/tenant ID\n    CreatedAt   time.Time\n    UpdatedAt   time.Time\n\n    // Access control\n    Policy      *AccessPolicy\n}\n\n// AccessPolicy controls who can use the toolset\ntype AccessPolicy struct {\n    AllowedTenants []string           // Tenant IDs that can access\n    AllowedRoles   []string           // Role-based access\n    RateLimit      *RateLimitConfig   // Optional rate limiting\n    AuditLog       bool               // Enable audit logging\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#fluent-builder","title":"Fluent Builder","text":"<pre><code>// toolset/builder.go\n\n// Builder provides fluent toolset construction\ntype Builder struct {\n    set      *Toolset\n    registry *tooladapter.Registry\n    filters  []FilterFunc\n}\n\n// NewBuilder creates a new toolset builder\nfunc NewBuilder(name string) *Builder {\n    return &amp;Builder{\n        set: &amp;Toolset{\n            ID:   uuid.New().String(),\n            Name: name,\n        },\n    }\n}\n\n// FromRegistry loads tools from an adapter registry\nfunc (b *Builder) FromRegistry(reg *tooladapter.Registry) *Builder {\n    b.registry = reg\n    return b\n}\n\n// WithNamespace includes tools from a specific namespace\nfunc (b *Builder) WithNamespace(ns string) *Builder {\n    b.filters = append(b.filters, func(t *tooladapter.CanonicalTool) bool {\n        return t.Namespace == ns\n    })\n    return b\n}\n\n// WithTags includes tools with any of the specified tags\nfunc (b *Builder) WithTags(tags ...string) *Builder {\n    tagSet := make(map[string]bool)\n    for _, t := range tags {\n        tagSet[t] = true\n    }\n    b.filters = append(b.filters, func(t *tooladapter.CanonicalTool) bool {\n        for _, tag := range t.Tags {\n            if tagSet[tag] {\n                return true\n            }\n        }\n        return false\n    })\n    return b\n}\n\n// WithTools includes specific tools by ID\nfunc (b *Builder) WithTools(ids ...string) *Builder {\n    idSet := make(map[string]bool)\n    for _, id := range ids {\n        idSet[id] = true\n    }\n    b.filters = append(b.filters, func(t *tooladapter.CanonicalTool) bool {\n        return idSet[t.ID]\n    })\n    return b\n}\n\n// WithCategory includes tools from a category\nfunc (b *Builder) WithCategory(cat string) *Builder {\n    b.filters = append(b.filters, func(t *tooladapter.CanonicalTool) bool {\n        return t.Category == cat\n    })\n    return b\n}\n\n// ExcludeTools removes specific tools by ID\nfunc (b *Builder) ExcludeTools(ids ...string) *Builder {\n    idSet := make(map[string]bool)\n    for _, id := range ids {\n        idSet[id] = true\n    }\n    b.filters = append(b.filters, func(t *tooladapter.CanonicalTool) bool {\n        return !idSet[t.ID]\n    })\n    return b\n}\n\n// WithPolicy sets access control policy\nfunc (b *Builder) WithPolicy(p *AccessPolicy) *Builder {\n    b.set.Policy = p\n    return b\n}\n\n// Build creates the toolset\nfunc (b *Builder) Build() (*Toolset, error) {\n    if b.registry == nil {\n        return nil, errors.New(\"registry required\")\n    }\n\n    allTools := b.registry.All()\n    for _, tool := range allTools {\n        include := true\n        for _, filter := range b.filters {\n            if !filter(tool) {\n                include = false\n                break\n            }\n        }\n        if include {\n            b.set.Tools = append(b.set.Tools, tool)\n        }\n    }\n\n    b.set.CreatedAt = time.Now()\n    b.set.UpdatedAt = time.Now()\n\n    return b.set, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#usage-examples","title":"Usage Examples","text":"<pre><code>// Example: Creating a DevOps toolset\ndevOpsSet, _ := toolset.NewBuilder(\"devops-tools\").\n    FromRegistry(registry).\n    WithNamespace(\"mcp.github\").\n    WithNamespace(\"mcp.kubernetes\").\n    WithTags(\"ci-cd\", \"deployment\", \"monitoring\").\n    ExcludeTools(\"mcp.github.delete_repo\"). // Too dangerous\n    WithPolicy(&amp;toolset.AccessPolicy{\n        AllowedRoles: []string{\"devops\", \"sre\"},\n        AuditLog:     true,\n    }).\n    Build()\n\n// Example: Customer-specific toolset\ncustomerSet, _ := toolset.NewBuilder(\"customer-acme\").\n    FromRegistry(registry).\n    WithTools(\n        \"mcp.support.create_ticket\",\n        \"mcp.docs.search\",\n        \"mcp.billing.get_invoice\",\n    ).\n    WithPolicy(&amp;toolset.AccessPolicy{\n        AllowedTenants: []string{\"acme-corp\"},\n        RateLimit: &amp;toolset.RateLimitConfig{\n            RequestsPerMinute: 60,\n        },\n    }).\n    Build()\n\n// Example: Production-safe toolset (no destructive operations)\nprodSet, _ := toolset.NewBuilder(\"production\").\n    FromRegistry(registry).\n    WithCategory(\"read-only\").\n    WithTags(\"safe\", \"idempotent\").\n    Build()\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#integration-with-existing-libraries","title":"Integration with Existing Libraries","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#toolindex-integration","title":"toolindex Integration","text":"<p>The tooladapter library integrates with toolindex for tool discovery:</p> <pre><code>// tooladapter/registry.go\n\n// Registry manages tools from multiple sources\ntype Registry struct {\n    index    toolindex.Index\n    adapters map[string]Adapter\n    tools    map[string]*CanonicalTool\n}\n\n// RegisterAdapter adds a protocol adapter\nfunc (r *Registry) RegisterAdapter(adapter Adapter) {\n    r.adapters[adapter.Name()] = adapter\n}\n\n// Import loads tools from an external source\nfunc (r *Registry) Import(format string, tools []any) error {\n    adapter, ok := r.adapters[format]\n    if !ok {\n        return fmt.Errorf(\"unknown format: %s\", format)\n    }\n\n    for _, raw := range tools {\n        canonical, err := adapter.ToCanonical(raw)\n        if err != nil {\n            return err\n        }\n\n        r.tools[canonical.ID] = canonical\n\n        // Register with toolindex for discovery\n        r.index.Register(convertToIndexTool(canonical))\n    }\n\n    return nil\n}\n\n// Export converts tools to a specific format\nfunc (r *Registry) Export(format string, toolIDs []string) ([]any, error) {\n    adapter, ok := r.adapters[format]\n    if !ok {\n        return nil, fmt.Errorf(\"unknown format: %s\", format)\n    }\n\n    var result []any\n    for _, id := range toolIDs {\n        tool, ok := r.tools[id]\n        if !ok {\n            continue\n        }\n\n        exported, err := adapter.FromCanonical(tool)\n        if err != nil {\n            return nil, err\n        }\n        result = append(result, exported)\n    }\n\n    return result, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#toolmodel-integration","title":"toolmodel Integration","text":"<p>CanonicalTool embeds and extends toolmodel.Tool:</p> <pre><code>// tooladapter/canonical.go\n\n// CanonicalTool extends toolmodel.Tool with adapter metadata\ntype CanonicalTool struct {\n    toolmodel.Tool // Embed base tool\n\n    // Adapter-specific extensions\n    SourceFormat string\n    SourceMeta   map[string]any\n    OutputSchema *JSONSchema\n}\n\n// ToToolModel converts to base toolmodel.Tool\nfunc (c *CanonicalTool) ToToolModel() *toolmodel.Tool {\n    return &amp;c.Tool\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#toolrun-integration","title":"toolrun Integration","text":"<p>Toolsets can be exposed through toolrun for execution:</p> <pre><code>// toolset/expose.go\n\n// ExposeViaMCP creates an MCP-compatible tool list from a toolset\nfunc (ts *Toolset) ExposeViaMCP(adapter *adapters.MCPAdapter) ([]*mcp.Tool, error) {\n    var result []*mcp.Tool\n    for _, tool := range ts.Tools {\n        mcpTool, err := adapter.FromCanonical(tool)\n        if err != nil {\n            return nil, err\n        }\n        result = append(result, mcpTool.(*mcp.Tool))\n    }\n    return result, nil\n}\n\n// ExposeViaOpenAI creates OpenAI function definitions from a toolset\nfunc (ts *Toolset) ExposeViaOpenAI(adapter *adapters.OpenAIAdapter) ([]*OpenAIFunction, error) {\n    var result []*OpenAIFunction\n    for _, tool := range ts.Tools {\n        fn, err := adapter.FromCanonical(tool)\n        if err != nil {\n            return nil, err\n        }\n        result = append(result, fn.(*OpenAIFunction))\n    }\n    return result, nil\n}\n\n// CreateRunner creates a toolrun.Runner scoped to the toolset\nfunc (ts *Toolset) CreateRunner(baseRunner *toolrun.Runner) *toolrun.Runner {\n    // Create a filtered view of the runner that only exposes toolset tools\n    toolIDs := make(map[string]bool)\n    for _, t := range ts.Tools {\n        toolIDs[t.ID] = true\n    }\n\n    return baseRunner.WithFilter(func(tool *toolmodel.Tool) bool {\n        return toolIDs[tool.ID()]\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#phase-1-core-adapter-library-2-weeks","title":"Phase 1: Core Adapter Library (2 weeks)","text":"<p>Week 1: Foundation - [ ] Create <code>tooladapter</code> module structure - [ ] Implement <code>CanonicalTool</code> and <code>JSONSchema</code> types - [ ] Implement <code>Adapter</code> interface - [ ] Create MCP adapter (bidirectional)</p> <p>Week 2: Additional Adapters - [ ] OpenAI adapter with strict mode support - [ ] Anthropic adapter - [ ] Schema conversion utilities - [ ] Unit tests for all adapters</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#phase-2-toolset-composition-2-weeks","title":"Phase 2: Toolset Composition (2 weeks)","text":"<p>Week 3: Toolset Core - [ ] Create <code>toolset</code> module structure - [ ] Implement <code>Toolset</code> type with metadata - [ ] Implement fluent <code>Builder</code> pattern - [ ] Implement filter predicates</p> <p>Week 4: Integration - [ ] Integrate with <code>toolindex</code> for discovery - [ ] Integrate with <code>toolrun</code> for execution - [ ] Add access control policies - [ ] Integration tests</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#phase-3-multi-transport-exposure-2-weeks","title":"Phase 3: Multi-Transport Exposure (2 weeks)","text":"<p>Week 5: Transport Adapters - [ ] MCP transport (existing, enhanced) - [ ] Direct client interface (Go library) - [ ] REST API transport</p> <p>Week 6: Production Readiness - [ ] Rate limiting integration - [ ] Audit logging - [ ] Documentation - [ ] Example applications</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#dependency-graph","title":"Dependency Graph","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Phase 3: Transports                    \u2502\n\u2502            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502            \u2502   MCP   \u2502  REST   \u2502 Direct  \u2502                \u2502\n\u2502            \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2502                 \u2502         \u2502         \u2502                     \u2502\n\u2502                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502                                \u2502                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                    Phase 2: Toolsets                      \u2502\n\u2502                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502\n\u2502                       \u2502     toolset     \u2502                 \u2502\n\u2502                       \u2502   (composer)    \u2502                 \u2502\n\u2502                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                                \u2502                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                    Phase 1: Adapters                      \u2502\n\u2502                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502\n\u2502                       \u2502   tooladapter   \u2502                 \u2502\n\u2502                       \u2502   (canonical)   \u2502                 \u2502\n\u2502                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                                \u2502                          \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502    \u2502           \u2502               \u2502               \u2502       \u2502  \u2502\n\u2502 \u250c\u2500\u2500\u2534\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502 \u2502 MCP \u2502  \u2502 OpenAI   \u2502  \u2502 Anthropic  \u2502  \u2502 OpenAPI  \u2502   \u2502  \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#appendix-industry-patterns","title":"Appendix: Industry Patterns","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#a-tool-format-comparison","title":"A. Tool Format Comparison","text":"Field MCP OpenAI Anthropic LangChain Name <code>name</code> <code>name</code> <code>name</code> <code>name</code> Description <code>description</code> <code>description</code> <code>description</code> <code>description</code> Parameters <code>inputSchema</code> <code>parameters</code> <code>input_schema</code> <code>schema</code> Schema Type JSON Schema JSON Schema JSON Schema Zod/JSON Schema Strict Mode N/A <code>strict: true</code> N/A N/A Return Type Content array String/Object Content array Any"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#b-schema-feature-support-matrix","title":"B. Schema Feature Support Matrix","text":"Feature MCP OpenAI OpenAI Strict Anthropic Nested objects \u2705 \u2705 \u2705 \u2705 Arrays \u2705 \u2705 \u2705 \u2705 Enums \u2705 \u2705 \u2705 \u2705 Pattern validation \u2705 \u26a0\ufe0f \u2705 \u2705 $ref definitions \u2705 \u274c \u274c \u274c anyOf/oneOf \u2705 \u26a0\ufe0f \u26a0\ufe0f \u2705 Nullable \u2705 \u2705 \u2705 \u2705 Default values \u2705 \u2705 \u274c \u2705"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#c-error-rate-comparison-mastra-research","title":"C. Error Rate Comparison (Mastra Research)","text":"Scenario No Adapter With Adapter Improvement Simple tools 8% 1% 87.5% Complex schemas 23% 4% 82.6% Cross-provider 31% 5% 83.9% Overall 15% 3% 80%"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#d-related-projects","title":"D. Related Projects","text":"Project Stars Approach Limitations LangChain MCP Adapters ~2k MCP \u2192 LangChain One-way, JS only llm-functions 704 Multi-language declaration No runtime registry kani 598 Python @ai_function Python only Mastra ~500 Compatibility layer TypeScript only"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#changelog","title":"Changelog","text":"Date Change 2026-01-28 Initial draft based on architecture research"}]}