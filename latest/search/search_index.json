{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Tools Stack","text":"<p>Welcome to the unified documentation for the AI Tools Stack. This site brings all tool libraries together in one place and shows how they compose into a progressive-disclosure MCP surface.</p> <p>Simple and elegant at the core, extensible through modular, pluggable architecture.</p> <p></p>"},{"location":"#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"#what-this-stack-provides","title":"What this stack provides","text":"<ul> <li>Canonical tool schemas (toolmodel)</li> <li>Registry and discovery (toolindex)</li> <li>Docs and examples (tooldocs)</li> <li>Execution and chaining (toolrun)</li> <li>Code-mode orchestration (toolcode)</li> <li>Sandbox/runtime backends (toolruntime)</li> <li>Search strategies (toolsearch)</li> <li>MCP server wiring (metatools-mcp)</li> </ul>"},{"location":"#design-notes-and-user-journeys","title":"Design Notes and User Journeys","text":"<p>For deeper context, see the aggregated indexes:</p> <ul> <li>Design Notes Index \u2014 per\u2011repo tradeoffs and error semantics</li> <li>User Journeys Index \u2014 end\u2011to\u2011end agent workflows</li> </ul>"},{"location":"#high-level-flow","title":"High-level flow","text":""},{"location":"#quickstart","title":"Quickstart","text":"<ol> <li>Start with <code>toolmodel</code> for your canonical schemas.</li> <li>Register tools in <code>toolindex</code> for discovery.</li> <li>Add docs/examples in <code>tooldocs</code>.</li> <li>Execute tools via <code>toolrun</code>.</li> <li>Expose the MCP surface using <code>metatools-mcp</code>.</li> </ol> <p>See the Components section for per-library examples and diagrams.</p>"},{"location":"#docs-from-each-repo","title":"Docs from each repo","text":"<p>Under Library Docs (from repos) you will find the docs imported directly from each repository at build time.</p>"},{"location":"architecture/design-notes/","title":"Design Notes Index","text":"<p>This page aggregates the per\u2011repo Design Notes pages that document tradeoffs and error semantics for each component. Use these when you want to understand why a design decision was made or how to handle specific failure modes.</p>"},{"location":"architecture/design-notes/#perrepo-design-notes","title":"Per\u2011repo Design Notes","text":"<ul> <li>toolmodel \u2014 <code>library-docs-from-repos/toolmodel/design-notes.md</code></li> <li>toolindex \u2014 <code>library-docs-from-repos/toolindex/design-notes.md</code></li> <li>tooldocs \u2014 <code>library-docs-from-repos/tooldocs/design-notes.md</code></li> <li>toolrun \u2014 <code>library-docs-from-repos/toolrun/design-notes.md</code></li> <li>toolcode \u2014 <code>library-docs-from-repos/toolcode/design-notes.md</code></li> <li>toolruntime \u2014 <code>library-docs-from-repos/toolruntime/design-notes.md</code></li> <li>toolsearch \u2014 <code>library-docs-from-repos/toolsearch/design-notes.md</code></li> <li>metatools\u2011mcp \u2014 <code>library-docs-from-repos/metatools-mcp/design-notes.md</code></li> </ul>"},{"location":"architecture/design-notes/#when-to-read-these","title":"When to read these","text":"<ul> <li>You\u2019re debugging failure modes or error propagation.</li> <li>You want to compare tradeoffs (latency vs safety, flexibility vs simplicity).</li> <li>You\u2019re deciding where to plug in a custom implementation.</li> </ul>"},{"location":"architecture/overview/","title":"Stack Architecture","text":"<p>This stack is built around progressive disclosure and a clean separation of schema, discovery, docs, execution, and transport.</p>"},{"location":"architecture/overview/#layering-model","title":"Layering model","text":""},{"location":"architecture/overview/#progressive-disclosure-pipeline","title":"Progressive disclosure pipeline","text":""},{"location":"architecture/overview/#tool-execution-and-runtime-isolation","title":"Tool execution and runtime isolation","text":""},{"location":"architecture/overview/#search-strategy-layering","title":"Search strategy layering","text":""},{"location":"architecture/pluggable-architecture/","title":"Pluggable Architecture","text":"<p>The stack is designed so each layer is replaceable without changing the others. This keeps the core stable while allowing experimentation and integration.</p>"},{"location":"architecture/pluggable-architecture/#extension-points","title":"Extension points","text":""},{"location":"architecture/pluggable-architecture/#what-you-can-plug-in","title":"What you can plug in","text":"<ul> <li>Search: swap lexical for BM25 or semantic ranking</li> <li>Execution: add MCP servers, local handlers, or provider adapters</li> <li>Code execution: change engines or language runtimes</li> <li>Runtime isolation: choose the sandbox backend per environment</li> </ul>"},{"location":"architecture/pluggable-architecture/#design-goal","title":"Design goal","text":"<p>The default implementations are intentionally simple and safe. Advanced capabilities are injected rather than baked into the core.</p>"},{"location":"architecture/progressive-disclosure/","title":"Progressive Disclosure","text":"<p>Progressive disclosure is the core usability strategy of this stack. It lets agents discover just enough information to choose the right tool, then retrieve deeper details only when needed.</p>"},{"location":"architecture/progressive-disclosure/#why-it-matters","title":"Why it matters","text":"<ul> <li>Lower token cost: most tools are never fully expanded</li> <li>Faster decisions: summary-level signals are enough to pick candidates</li> <li>Safer execution: schema and examples are fetched only after a tool is chosen</li> </ul>"},{"location":"architecture/progressive-disclosure/#flow","title":"Flow","text":""},{"location":"architecture/progressive-disclosure/#component-roles","title":"Component roles","text":"<ul> <li><code>toolindex</code>: fast, summary-only discovery</li> <li><code>tooldocs</code>: structured detail (schema/full/examples)</li> <li><code>toolrun</code>: execution with validation + consistent errors</li> <li><code>toolcode</code>: optional code-mode orchestration</li> </ul>"},{"location":"architecture/user-journeys/","title":"User Journeys Index","text":"<p>This page aggregates the per\u2011repo User Journey pages that describe full end\u2011to\u2011end workflows. These are ideal for onboarding and for validating that the progressive\u2011disclosure flow is coherent across layers.</p>"},{"location":"architecture/user-journeys/#perrepo-user-journeys","title":"Per\u2011repo User Journeys","text":"<ul> <li>toolmodel \u2014 <code>library-docs-from-repos/toolmodel/user-journey.md</code></li> <li>toolindex \u2014 <code>library-docs-from-repos/toolindex/user-journey.md</code></li> <li>tooldocs \u2014 <code>library-docs-from-repos/tooldocs/user-journey.md</code></li> <li>toolrun \u2014 <code>library-docs-from-repos/toolrun/user-journey.md</code></li> <li>toolcode \u2014 <code>library-docs-from-repos/toolcode/user-journey.md</code></li> <li>toolruntime \u2014 <code>library-docs-from-repos/toolruntime/user-journey.md</code></li> <li>toolsearch \u2014 <code>library-docs-from-repos/toolsearch/user-journey.md</code></li> <li>metatools\u2011mcp \u2014 <code>library-docs-from-repos/metatools-mcp/user-journey.md</code></li> </ul>"},{"location":"architecture/user-journeys/#when-to-read-these","title":"When to read these","text":"<ul> <li>You want to understand how an agent discovers, inspects, and runs tools.</li> <li>You\u2019re validating the progressive disclosure path across components.</li> <li>You want examples that show how the pieces fit together end\u2011to\u2011end.</li> </ul>"},{"location":"architecture/why-go/","title":"Why Go","text":"<p>Go is a strong fit for this stack because it pairs high performance with a simple concurrency model and a clean interface story.</p>"},{"location":"architecture/why-go/#advantages-for-this-stack","title":"Advantages for this stack","text":""},{"location":"architecture/why-go/#compiled-fast-startup","title":"Compiled + fast startup","text":"<ul> <li>Small binaries and quick startup times are ideal for MCP servers</li> <li>Predictable performance for low-latency tool calls</li> </ul>"},{"location":"architecture/why-go/#concurrency-without-complexity","title":"Concurrency without complexity","text":"<ul> <li>Goroutines and channels make async tool execution straightforward</li> <li><code>context.Context</code> enables timeouts and cancellation across the stack</li> </ul>"},{"location":"architecture/why-go/#interface-first-extensibility","title":"Interface-first extensibility","text":"<ul> <li>Each layer (<code>Searcher</code>, <code>Runner</code>, <code>Engine</code>, <code>Backend</code>) is interface-driven</li> <li>You can plug in new languages, providers, or runtimes without redesigning</li> </ul>"},{"location":"architecture/why-go/#operational-simplicity","title":"Operational simplicity","text":"<ul> <li>Static binaries simplify deployment</li> <li>Works equally well in containers, VMs, or bare metal</li> </ul>"},{"location":"architecture/why-go/#summary","title":"Summary","text":"<p>Go lets you build a composable system that is fast, concurrent, and easy to extend. That is exactly what this stack needs.</p>"},{"location":"components/metatools-mcp/","title":"metatools-mcp","text":"<p>MCP server that exposes the tool stack via standardized MCP tools with a progressive-disclosure flow.</p>"},{"location":"components/metatools-mcp/#motivation","title":"Motivation","text":"<ul> <li>Provide a minimal, consistent MCP surface</li> <li>Keep discovery cheap and execution safe</li> <li>Enable pluggable search and optional code execution</li> </ul>"},{"location":"components/metatools-mcp/#core-responsibilities","title":"Core responsibilities","text":"<ul> <li>Expose <code>search_tools</code>, <code>list_namespaces</code></li> <li>Expose <code>describe_tool</code>, <code>list_tool_examples</code></li> <li>Expose <code>run_tool</code>, <code>run_chain</code></li> <li>Optionally expose <code>execute_code</code></li> <li>Use the official MCP Go SDK</li> </ul>"},{"location":"components/metatools-mcp/#example","title":"Example","text":"<pre><code>srv, _ := server.New(cfg)\n_ = srv.Run(context.Background(), &amp;mcp.StdioTransport{})\n</code></pre>"},{"location":"components/metatools-mcp/#diagram","title":"Diagram","text":""},{"location":"components/metatools-mcp/#usability-notes","title":"Usability notes","text":"<ul> <li>Small tool surface reduces prompt complexity</li> <li>Schemas and examples are fetched on demand</li> </ul>"},{"location":"components/toolcode/","title":"toolcode","text":"<p>Code-mode orchestration layer that wraps search, docs, and execution into a single programmable surface.</p>"},{"location":"components/toolcode/#motivation","title":"Motivation","text":"<ul> <li>Enable conditional logic and multi-step orchestration</li> <li>Keep tool orchestration explicit and testable</li> <li>Provide call traces for debugging</li> </ul>"},{"location":"components/toolcode/#core-responsibilities","title":"Core responsibilities","text":"<ul> <li>Execute short orchestration snippets</li> <li>Provide a minimal in-sandbox API (SearchTools, DescribeTool, RunTool)</li> <li>Enforce timeouts and limits</li> </ul>"},{"location":"components/toolcode/#example","title":"Example","text":"<pre><code>executor := toolcode.NewDefaultExecutor(toolcode.Config{\n  Index:  idx,\n  Docs:   docs,\n  Run:    runner,\n  Engine: engine,\n})\n\nres, _ := executor.ExecuteCode(ctx, toolcode.ExecuteParams{\n  Language: \"go\",\n  Code:     \"__out = 2 + 2\",\n})\n</code></pre>"},{"location":"components/toolcode/#diagram","title":"Diagram","text":""},{"location":"components/toolcode/#usability-notes","title":"Usability notes","text":"<ul> <li><code>ExecuteResult</code> includes tool call traces</li> <li>Limits are enforced consistently across engines</li> </ul>"},{"location":"components/tooldocs/","title":"tooldocs","text":"<p>Progressive, structured documentation and examples for tools. Designed for schema-first usage and token-efficient guidance.</p>"},{"location":"components/tooldocs/#motivation","title":"Motivation","text":"<ul> <li>Pull full schemas only when needed</li> <li>Reduce tool call errors with examples</li> <li>Keep long docs out of the critical path</li> </ul>"},{"location":"components/tooldocs/#core-responsibilities","title":"Core responsibilities","text":"<ul> <li>Detail tiers: summary \u2192 schema \u2192 full</li> <li>Short usage examples with caps</li> <li>Notes and external references</li> </ul>"},{"location":"components/tooldocs/#example","title":"Example","text":"<pre><code>store := tooldocs.NewInMemoryStore(tooldocs.StoreOptions{Index: idx})\n\n_ = store.RegisterDoc(\"github:get_repo\", tooldocs.DocEntry{\n  Summary: \"Fetch repository metadata\",\n  Notes:   \"Requires authentication.\",\n})\n\nschema, _ := store.DescribeTool(\"github:get_repo\", tooldocs.DetailSchema)\nexamples, _ := store.ListExamples(\"github:get_repo\", 2)\n</code></pre>"},{"location":"components/tooldocs/#diagram","title":"Diagram","text":""},{"location":"components/tooldocs/#usability-notes","title":"Usability notes","text":"<ul> <li>Example caps protect token budgets</li> <li>Summary tier is safe for discovery</li> <li>Schema tier is designed for tool invocation</li> </ul>"},{"location":"components/toolindex/","title":"toolindex","text":"<p>Global registry and search layer for tools. Provides progressive discovery and canonical lookup by tool ID.</p>"},{"location":"components/toolindex/#motivation","title":"Motivation","text":"<ul> <li>Keep discovery fast and cheap</li> <li>Decouple search quality from core registry</li> <li>Provide a single source of truth for tool IDs and backends</li> </ul>"},{"location":"components/toolindex/#core-responsibilities","title":"Core responsibilities","text":"<ul> <li>Register tools + backends</li> <li>Search by name/namespace/description/tags</li> <li>List namespaces</li> <li>Resolve tools by canonical ID</li> </ul>"},{"location":"components/toolindex/#example","title":"Example","text":"<pre><code>idx := toolindex.NewInMemoryIndex()\n\n_ = idx.RegisterTool(tool, backend)\n\nsummaries, _ := idx.Search(\"repo\", 5)\nfor _, s := range summaries {\n  fmt.Println(s.ID, s.ShortDescription)\n}\n</code></pre>"},{"location":"components/toolindex/#diagram","title":"Diagram","text":""},{"location":"components/toolindex/#usability-notes","title":"Usability notes","text":"<ul> <li>Summaries are token-cheap</li> <li>Namespace listing enables simple filtering</li> <li>Backends are swappable without changing IDs</li> </ul>"},{"location":"components/toolmodel/","title":"toolmodel","text":"<p>Canonical schema definitions for all tools. This is the source of truth for IDs, schemas, tags, and backend bindings.</p>"},{"location":"components/toolmodel/#motivation","title":"Motivation","text":"<ul> <li>Standardize tool definitions across the stack</li> <li>Align directly with MCP via the official Go SDK</li> <li>Keep schemas portable and validation deterministic</li> </ul>"},{"location":"components/toolmodel/#core-types","title":"Core types","text":"<ul> <li><code>Tool</code> (embeds MCP <code>mcp.Tool</code>, adds <code>Namespace</code>, <code>Version</code>, <code>Tags</code>)</li> <li><code>ToolBackend</code> (execution binding: mcp, provider, local)</li> <li><code>SchemaValidator</code> (input/output validation)</li> </ul>"},{"location":"components/toolmodel/#example","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolmodel\"\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\ntool := toolmodel.Tool{\n  Namespace: \"github\",\n  Tool: mcp.Tool{\n    Name:        \"get_repo\",\n    Description: \"Fetch repository metadata\",\n    InputSchema: map[string]any{\n      \"type\": \"object\",\n      \"properties\": map[string]any{\n        \"owner\": {\"type\": \"string\"},\n        \"repo\":  {\"type\": \"string\"},\n      },\n      \"required\": []string{\"owner\", \"repo\"},\n    },\n  },\n  Tags: toolmodel.NormalizeTags([]string{\"GitHub\", \"repos\"}),\n}\n\n_ = tool.Validate()\n</code></pre>"},{"location":"components/toolmodel/#diagram","title":"Diagram","text":""},{"location":"components/toolmodel/#usability-notes","title":"Usability notes","text":"<ul> <li>Schemas accept maps or JSON bytes</li> <li>Tags are normalized for fast search</li> <li>IDs are stable and human\u2011readable</li> </ul>"},{"location":"components/toolrun/","title":"toolrun","text":"<p>Execution layer for tools and chains. Backend-agnostic and aligned to MCP <code>run_tool</code> and <code>run_chain</code> semantics.</p>"},{"location":"components/toolrun/#motivation","title":"Motivation","text":"<ul> <li>Provide consistent execution semantics across backends</li> <li>Validate inputs/outputs for safety</li> <li>Offer deterministic chain behavior</li> </ul>"},{"location":"components/toolrun/#core-responsibilities","title":"Core responsibilities","text":"<ul> <li>Resolve tools and backends</li> <li>Validate inputs/outputs with toolmodel schemas</li> <li>Dispatch to MCP, provider, or local backends</li> <li>Execute chains with <code>previous</code> injection</li> </ul>"},{"location":"components/toolrun/#example","title":"Example","text":"<pre><code>runner := toolrun.NewRunner(\n  toolrun.WithIndex(idx),\n  toolrun.WithLocalRegistry(localRegistry),\n)\n\nresult, _ := runner.Run(ctx, \"github:get_repo\", map[string]any{\n  \"owner\": \"octo\",\n  \"repo\":  \"hello\",\n})\n</code></pre>"},{"location":"components/toolrun/#diagram","title":"Diagram","text":""},{"location":"components/toolrun/#usability-notes","title":"Usability notes","text":"<ul> <li>Streaming is optional; non-streaming backends return <code>ErrStreamNotSupported</code></li> <li>Backend selection is deterministic by default</li> </ul>"},{"location":"components/toolruntime/","title":"toolruntime","text":"<p>Sandbox/runtime abstraction for executing code securely. Provides multiple backends with a single interface.</p>"},{"location":"components/toolruntime/#motivation","title":"Motivation","text":"<ul> <li>Create an explicit trust boundary for code execution</li> <li>Swap isolation backends without changing APIs</li> <li>Apply security profiles consistently</li> </ul>"},{"location":"components/toolruntime/#core-responsibilities","title":"Core responsibilities","text":"<ul> <li>Runtime interface + default implementation</li> <li>Backends (unsafe host, docker, kubernetes, gvisor, firecracker, wasm)</li> <li>Security profiles and execution limits</li> </ul>"},{"location":"components/toolruntime/#example","title":"Example","text":"<pre><code>rt := toolruntime.NewDefaultRuntime(toolruntime.RuntimeConfig{\n  Backends: map[toolruntime.SecurityProfile]toolruntime.Backend{\n    toolruntime.ProfileDev: unsafe.New(unsafe.Config{Mode: unsafe.ModeSubprocess}),\n  },\n  DefaultProfile: toolruntime.ProfileDev,\n})\n</code></pre>"},{"location":"components/toolruntime/#diagram","title":"Diagram","text":""},{"location":"components/toolruntime/#usability-notes","title":"Usability notes","text":"<ul> <li>Profiles separate policy from implementation</li> <li>Backends are swappable per environment</li> </ul>"},{"location":"components/toolsearch/","title":"toolsearch","text":"<p>Search strategy library that plugs into toolindex. Currently provides BM25 with room for semantic/hybrid search.</p>"},{"location":"components/toolsearch/#motivation","title":"Motivation","text":"<ul> <li>Keep <code>toolindex</code> minimal</li> <li>Allow search experimentation without destabilizing the core</li> <li>Improve relevance without changing IDs or schemas</li> </ul>"},{"location":"components/toolsearch/#core-responsibilities","title":"Core responsibilities","text":"<ul> <li>Provide BM25 ranking</li> <li>Keep search logic decoupled from the index</li> <li>Support pluggable scoring</li> </ul>"},{"location":"components/toolsearch/#example","title":"Example","text":"<pre><code>searcher := toolsearch.NewBM25Searcher(toolsearch.BM25Config{K1: 1.5, B: 0.75})\nidx := toolindex.NewInMemoryIndex(toolindex.IndexOptions{Searcher: searcher})\n</code></pre>"},{"location":"components/toolsearch/#diagram","title":"Diagram","text":""},{"location":"components/toolsearch/#usability-notes","title":"Usability notes","text":"<ul> <li>Deterministic ranking avoids jitter</li> <li>BM25 is opt-in and isolated by design</li> </ul>"},{"location":"operations/ci-and-versioning/","title":"CI and Versioning","text":""},{"location":"operations/ci-and-versioning/#ci-checks","title":"CI checks","text":"<p>Each repo runs CI for:</p> <ul> <li>go vet</li> <li>go test</li> <li>lint + security (golangci-lint + gosec)</li> </ul>"},{"location":"operations/ci-and-versioning/#version-alignment","title":"Version alignment","text":"<ul> <li><code>ai-tools-stack/go.mod</code> is the source of truth.</li> <li><code>VERSIONS.md</code> is generated in each repo and updated via:</li> </ul> <pre><code>scripts/update-version-matrix.sh --apply\n</code></pre>"},{"location":"operations/ci-and-versioning/#dependency-bumping","title":"Dependency bumping","text":"<p>Use the DAG-aware bump tool:</p> <pre><code>scripts/bump-dep.sh --dep toolruntime --latest --apply\n</code></pre> <p>This updates all downstream repos and ai-tools-stack in order.</p>"},{"location":"operations/ci-and-versioning/#docs-automation","title":"Docs automation","text":"<p>The unified docs site is built from this repo using MkDocs + the multirepo plugin. GitHub Actions runs on push to main and nightly (scheduled) to pull fresh docs from the tool repos.</p> <p>Versioned docs are published with <code>mike</code>:</p> <ul> <li><code>latest</code> alias is deployed from <code>main</code></li> <li>tag builds deploy versioned docs (for example, <code>v0.1.8</code>) and set <code>stable</code></li> </ul> <p>Local preview:</p> <pre><code>pip install -r requirements.txt\n./scripts/prepare-mkdocs-multirepo.sh\nmkdocs serve\n</code></pre> <p>Versioned preview:</p> <pre><code>pip install -r requirements.txt\n./scripts/prepare-mkdocs-multirepo.sh\nmike serve\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/","title":"toolmodel","text":"<p><code>toolmodel</code> is the canonical, MCP-aligned data model for tools across the stack. It embeds the official MCP Go SDK <code>mcp.Tool</code>, adds namespace + tags, and provides schema validation helpers.</p> <p></p>"},{"location":"library-docs-from-repos/toolmodel/#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolmodel/#motivation","title":"Motivation","text":"<ul> <li>Single source of truth for tool schemas and IDs</li> <li>Protocol alignment by embedding the official MCP SDK type</li> <li>Safe validation with deterministic, dependency-light JSON Schema checks</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/#key-apis","title":"Key APIs","text":"<ul> <li><code>Tool</code> (embeds <code>mcp.Tool</code>, adds <code>Namespace</code>, <code>Version</code>, <code>Tags</code>)</li> <li><code>ToolBackend</code> (mcp/provider/local binding)</li> <li><code>SchemaValidator</code> + <code>NewDefaultValidator()</code></li> <li><code>NormalizeTags</code>, <code>ToolID</code>, <code>ParseToolID</code></li> </ul>"},{"location":"library-docs-from-repos/toolmodel/#quickstart","title":"Quickstart","text":"<pre><code>package main\n\nimport (\n  \"fmt\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolmodel\"\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\nfunc main() {\n  tool := toolmodel.Tool{\n    Namespace: \"github\",\n    Tool: mcp.Tool{\n      Name:        \"get_repo\",\n      Description: \"Fetch repository metadata\",\n      InputSchema: map[string]any{\n        \"type\": \"object\",\n        \"properties\": map[string]any{\n          \"owner\": {\"type\": \"string\"},\n          \"repo\":  {\"type\": \"string\"},\n        },\n        \"required\": []string{\"owner\", \"repo\"},\n      },\n    },\n    Tags: toolmodel.NormalizeTags([]string{\"GitHub\", \"repos\"}),\n  }\n\n  if err := tool.Validate(); err != nil {\n    log.Fatal(err)\n  }\n\n  fmt.Println(tool.ToolID()) // github:get_repo\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/#usability-notes","title":"Usability notes","text":"<ul> <li><code>InputSchema</code>/<code>OutputSchema</code> accept <code>map[string]any</code> or JSON bytes</li> <li>Tags are normalized for search (<code>toolindex</code> + <code>toolsearch</code>)</li> <li>Canonical IDs are stable and human-friendly</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/#next","title":"Next","text":"<ul> <li>Architecture and placement in the stack: <code>architecture.md</code></li> <li>Usage patterns and validation: <code>usage.md</code></li> <li>Additional examples: <code>examples.md</code></li> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolmodel/api/","title":"API Reference","text":"<p>This is a concise map of the public types and interfaces. See code for details.</p>"},{"location":"library-docs-from-repos/toolmodel/api/#tool","title":"Tool","text":"<p><code>toolmodel.Tool</code> embeds <code>mcp.Tool</code> and adds:</p> <ul> <li><code>Namespace string</code></li> <li><code>Version string</code></li> <li><code>Tags []string</code></li> </ul> <p>Common fields from <code>mcp.Tool</code> used in this stack:</p> <ul> <li><code>Name string</code></li> <li><code>Title string</code></li> <li><code>Description string</code></li> <li><code>InputSchema any</code></li> <li><code>OutputSchema any</code></li> </ul>"},{"location":"library-docs-from-repos/toolmodel/api/#ids","title":"IDs","text":"<ul> <li><code>Tool.ToolID() string</code></li> <li><code>ParseToolID(id string) (namespace, name string, err error)</code></li> </ul>"},{"location":"library-docs-from-repos/toolmodel/api/#backends","title":"Backends","text":"<pre><code>type BackendKind string\nconst (\n  BackendKindMCP      BackendKind = \"mcp\"\n  BackendKindProvider BackendKind = \"provider\"\n  BackendKindLocal    BackendKind = \"local\"\n)\n\ntype ToolBackend struct {\n  Kind     BackendKind\n  MCP      *MCPBackend\n  Provider *ProviderBackend\n  Local    *LocalBackend\n}\n\ntype MCPBackend struct {\n  ServerName string\n}\n\ntype ProviderBackend struct {\n  ProviderID string\n  ToolID     string\n}\n\ntype LocalBackend struct {\n  Name string\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/api/#validation","title":"Validation","text":"<pre><code>type SchemaValidator interface {\n  Validate(schema any, instance any) error\n  ValidateInput(tool *Tool, args any) error\n  ValidateOutput(tool *Tool, result any) error\n}\n\nfunc NewDefaultValidator() *DefaultValidator\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/api/#utilities","title":"Utilities","text":"<ul> <li><code>NormalizeTags([]string) []string</code></li> <li><code>Tool.Validate() error</code></li> <li><code>ToolBackend.Validate() error</code></li> </ul>"},{"location":"library-docs-from-repos/toolmodel/architecture/","title":"Architecture","text":"<p><code>toolmodel</code> sits at the bottom of the stack. Everything else consumes its types and uses it as the canonical source of truth.</p>"},{"location":"library-docs-from-repos/toolmodel/architecture/#component-view","title":"Component view","text":""},{"location":"library-docs-from-repos/toolmodel/architecture/#data-model-view","title":"Data model view","text":""},{"location":"library-docs-from-repos/toolmodel/architecture/#validation-pipeline","title":"Validation pipeline","text":""},{"location":"library-docs-from-repos/toolmodel/architecture/#design-notes","title":"Design notes","text":"<ul> <li>Embeds <code>mcp.Tool</code> to stay aligned with the official MCP SDK.</li> <li>Adds <code>Namespace</code>, <code>Version</code>, and <code>Tags</code> without altering MCP semantics.</li> <li>Keeps validation dependency-light and deterministic.</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/design-notes/","title":"Design Notes","text":"<p>This page captures the tradeoffs and error semantics that guided <code>toolmodel</code>.</p>"},{"location":"library-docs-from-repos/toolmodel/design-notes/#design-tradeoffs","title":"Design tradeoffs","text":"<ul> <li>Spec alignment over custom types. <code>Tool</code> embeds the official MCP Go SDK <code>mcp.Tool</code> to stay 1:1 with the spec and JSON tags. This minimizes drift but means <code>InputSchema</code>/<code>OutputSchema</code> are <code>any</code>, so validation must be handled explicitly.</li> <li>Minimal extensions. <code>Namespace</code>, <code>Version</code>, and <code>Tags</code> are the only additions to the MCP shape. These are intentionally kept small to preserve transport compatibility and keep higher layers in control of semantics.</li> <li>Explicit tool IDs. Canonical IDs are <code>namespace:name</code> (or just <code>name</code>), computed by <code>ToolID()</code>. This keeps IDs stable across backends while remaining human-readable.</li> <li>Validation boundary. <code>Tool.Validate()</code> enforces naming and required fields only. JSON Schema validation is delegated to <code>SchemaValidator</code> to keep <code>Tool</code> lightweight and reusable.</li> <li>Safe schema validation. The default validator blocks external <code>$ref</code> resolution to avoid network access and non-determinism. This trades off remote schema reuse for safety and predictability.</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/design-notes/#error-semantics","title":"Error semantics","text":"<p><code>toolmodel</code> uses sentinel errors so callers can reliably classify failures:</p> <ul> <li><code>ErrInvalidToolID</code> \u2013 malformed tool IDs (empty, extra <code>:</code> separators, missing parts).</li> <li><code>ErrInvalidTool</code> \u2013 invalid tool definition (missing name, invalid characters, missing input schema).</li> <li><code>ErrInvalidSchema</code> \u2013 schema is not valid JSON Schema or cannot be parsed.</li> <li><code>ErrUnsupportedSchema</code> \u2013 schema dialect is not supported (only 2020-12 and draft-07 are accepted).</li> <li><code>ErrExternalRef</code> \u2013 external <code>$ref</code> resolution attempted (blocked by default).</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/design-notes/#validation-behavior","title":"Validation behavior","text":"<ul> <li><code>Tool.Validate()</code> enforces name format and <code>InputSchema != nil</code>.</li> <li><code>DefaultValidator.ValidateInput</code> and <code>ValidateOutput</code> return <code>ErrInvalidSchema</code> or <code>ErrUnsupportedSchema</code> when schema parsing or dialect checks fail.</li> <li>Output validation is optional by design; <code>OutputSchema</code> can be absent.</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/design-notes/#extension-points","title":"Extension points","text":"<ul> <li>Custom schema validation: implement <code>SchemaValidator</code> if you need different dialects, format checking, or external reference resolution.</li> <li>Tag strategies: <code>NormalizeTags</code> can be replaced at higher layers (e.g., for hierarchical tags or full-text indexing).</li> <li>Tool ingestion: higher layers can deserialize MCP tool JSON via <code>FromMCPJSON</code> and then enrich with <code>Namespace</code> and <code>Tags</code>.</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/design-notes/#operational-guidance","title":"Operational guidance","text":"<ul> <li>Keep <code>Namespace</code> stable even if backend endpoints change.</li> <li>Use short, searchable <code>Tags</code>; <code>NormalizeTags</code> caps to 20 items and 64 chars each.</li> <li>Prefer JSON Schema 2020-12 with explicit <code>type</code> and <code>required</code> fields for best downstream schema derivation.</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/toolmodel/examples/#tag-normalization","title":"Tag normalization","text":"<pre><code>normalized := toolmodel.NormalizeTags([]string{\n  \"  GitHub Repos \",\n  \"GITHUB  repos\",\n  \"  ci/cd  \",\n})\n// =&gt; [\"github-repos\", \"ci-cd\"]\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/examples/#validate-output","title":"Validate output","text":"<pre><code>result := map[string]any{\n  \"full_name\": \"octo/hello\",\n}\n\nif err := validator.ValidateOutput(&amp;tool, result); err != nil {\n  // handle schema mismatch\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/examples/#canonical-id-parsing","title":"Canonical ID parsing","text":"<pre><code>ns, name, err := toolmodel.ParseToolID(\"github:get_repo\")\n// ns = \"github\", name = \"get_repo\"\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/toolmodel/usage/#define-a-tool","title":"Define a tool","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolmodel\"\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\ntool := toolmodel.Tool{\n  Namespace: \"tickets\",\n  Tool: mcp.Tool{\n    Name:        \"create\",\n    Description: \"Create a support ticket\",\n    InputSchema: map[string]any{\n      \"type\": \"object\",\n      \"properties\": map[string]any{\n        \"title\":    {\"type\": \"string\"},\n        \"priority\": {\"type\": \"string\", \"enum\": []string{\"low\", \"high\"}},\n      },\n      \"required\": []string{\"title\"},\n    },\n  },\n  Tags: toolmodel.NormalizeTags([]string{\"Support\", \"Tickets\"}),\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/usage/#tool-ids","title":"Tool IDs","text":"<pre><code>id := tool.ToolID()                 // tickets:create\nns, name, _ := toolmodel.ParseToolID(id)\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/usage/#backends","title":"Backends","text":"<p><code>toolmodel</code> does not execute anything. It only describes how a tool can be executed. These backends are consumed by <code>toolrun</code>.</p> <pre><code>mcpBackend := toolmodel.ToolBackend{\n  Kind: toolmodel.BackendKindMCP,\n  MCP:  &amp;toolmodel.MCPBackend{ServerName: \"github\"},\n}\n\nproviderBackend := toolmodel.ToolBackend{\n  Kind: toolmodel.BackendKindProvider,\n  Provider: &amp;toolmodel.ProviderBackend{\n    ProviderID: \"internal-api\",\n    ToolID:     \"tickets.create\",\n  },\n}\n\nlocalBackend := toolmodel.ToolBackend{\n  Kind: toolmodel.BackendKindLocal,\n  Local: &amp;toolmodel.LocalBackend{Name: \"create_ticket\"},\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/usage/#validation","title":"Validation","text":"<pre><code>validator := toolmodel.NewDefaultValidator()\n\nif err := validator.ValidateInput(&amp;tool, map[string]any{\"title\": \"Help\"}); err != nil {\n  // handle validation error\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/usage/#dialects-and-safety","title":"Dialects and safety","text":"<ul> <li>JSON Schema 2020-12 is assumed when <code>$schema</code> is missing.</li> <li>draft-07 is accepted (normalized internally).</li> <li>External <code>$ref</code> is blocked (no network resolution).</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/user-journey/","title":"User Journey","text":"<p>This journey shows how a tool definition flows from authoring to execution across the stack, with <code>toolmodel</code> as the source of truth.</p>"},{"location":"library-docs-from-repos/toolmodel/user-journey/#end-to-end-flow-stack-view","title":"End-to-end flow (stack view)","text":""},{"location":"library-docs-from-repos/toolmodel/user-journey/#step-by-step","title":"Step-by-step","text":"<ol> <li>Author defines a tool using <code>toolmodel.Tool</code> with an MCP-compatible schema.</li> <li>Tool is validated (<code>Tool.Validate()</code> + optional schema validation).</li> <li>Tool is registered into <code>toolindex</code> with a backend binding.</li> <li>Agent discovers tools via <code>search_tools</code> (powered by <code>toolindex</code>).</li> <li>Agent inspects schema/docs via <code>describe_tool</code> (powered by <code>tooldocs</code>).</li> <li>Agent executes the tool via <code>run_tool</code> (powered by <code>toolrun</code>).</li> </ol>"},{"location":"library-docs-from-repos/toolmodel/user-journey/#example-define-a-tool","title":"Example: define a tool","text":"<pre><code>import (\n  \"encoding/json\"\n  \"github.com/jonwraymond/toolmodel\"\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\ninputSchema := json.RawMessage(`{\n  \"type\": \"object\",\n  \"properties\": {\n    \"owner\": {\"type\": \"string\"},\n    \"repo\": {\"type\": \"string\"}\n  },\n  \"required\": [\"owner\", \"repo\"]\n}`)\n\nrepoTool := toolmodel.Tool{\n  Tool: mcp.Tool{\n    Name:        \"get_repo\",\n    Title:       \"Get repo details\",\n    Description: \"Fetch repository metadata.\",\n    InputSchema: inputSchema,\n  },\n  Namespace: \"github\",\n  Tags:      []string{\"repo\", \"git\", \"metadata\"},\n}\n\nif err := repoTool.Validate(); err != nil {\n  // handle invalid tool\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolmodel/user-journey/#expected-outcomes","title":"Expected outcomes","text":"<ul> <li>A stable tool ID (<code>github:get_repo</code>) that downstream components can resolve.</li> <li>Schema-driven validation for inputs and outputs (via <code>SchemaValidator</code>).</li> <li>Token-efficient discovery by pushing only summaries into search results.</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/user-journey/#common-failure-modes","title":"Common failure modes","text":"<ul> <li>Invalid tool ID: <code>ErrInvalidToolID</code> when parsing malformed IDs.</li> <li>Invalid tool fields: <code>ErrInvalidTool</code> when name is missing/invalid or input schema is nil.</li> <li>Unsupported schema dialect: <code>ErrUnsupportedSchema</code> for non-2020-12/draft-07 schemas.</li> <li>External refs blocked: <code>ErrExternalRef</code> if the schema attempts external <code>$ref</code>.</li> </ul>"},{"location":"library-docs-from-repos/toolmodel/user-journey/#why-this-matters","title":"Why this matters","text":"<p><code>toolmodel</code> keeps the entire stack aligned with the official MCP tool shape while still providing namespaces, versions, and tags needed for real-world registries.</p>"},{"location":"library-docs-from-repos/toolindex/","title":"toolindex","text":"<p><code>toolindex</code> is the global registry and progressive discovery layer for tools. It stores <code>toolmodel.Tool</code> + <code>toolmodel.ToolBackend</code>, provides search, and returns token-cheap summaries.</p> <p></p>"},{"location":"library-docs-from-repos/toolindex/#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolindex/#motivation","title":"Motivation","text":"<ul> <li>Progressive disclosure: search returns summaries, not schemas</li> <li>Deterministic lookup: canonical tool IDs resolve to stable backends</li> <li>Pluggable search: swap lexical search for BM25 or semantic ranking</li> </ul>"},{"location":"library-docs-from-repos/toolindex/#key-apis","title":"Key APIs","text":"<ul> <li><code>Index</code> interface</li> <li><code>InMemoryIndex</code> implementation</li> <li><code>Search</code> + <code>ListNamespaces</code></li> <li><code>RegisterTool(s)</code> + <code>GetTool</code></li> <li><code>Searcher</code> interface for pluggable ranking</li> </ul>"},{"location":"library-docs-from-repos/toolindex/#quickstart","title":"Quickstart","text":"<pre><code>idx := toolindex.NewInMemoryIndex()\n\n_ = idx.RegisterTool(tool, backend)\n\nsummaries, _ := idx.Search(\"repo\", 5)\nfor _, s := range summaries {\n  fmt.Println(s.ID, s.ShortDescription)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/#usability-notes","title":"Usability notes","text":"<ul> <li>Summaries are token-cheap and safe to display in discovery</li> <li>Namespaces group tools for easy filtering</li> <li>Backends can be replaced without changing the tool ID</li> </ul>"},{"location":"library-docs-from-repos/toolindex/#next","title":"Next","text":"<ul> <li>Architecture and data flow: <code>architecture.md</code></li> <li>Usage patterns and options: <code>usage.md</code></li> <li>Searcher examples: <code>examples.md</code></li> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolindex/api/","title":"API Reference","text":""},{"location":"library-docs-from-repos/toolindex/api/#index-interface","title":"Index interface","text":"<pre><code>type Index interface {\n  RegisterTool(tool toolmodel.Tool, backend toolmodel.ToolBackend) error\n  RegisterTools(regs []ToolRegistration) error\n  RegisterToolsFromMCP(serverName string, tools []toolmodel.Tool) error\n\n  UnregisterBackend(toolID string, kind toolmodel.BackendKind, backendID string) error\n\n  GetTool(id string) (toolmodel.Tool, toolmodel.ToolBackend, error)\n  GetAllBackends(id string) ([]toolmodel.ToolBackend, error)\n\n  Search(query string, limit int) ([]Summary, error)\n  ListNamespaces() ([]string, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/api/#change-notifications-optional","title":"Change notifications (optional)","text":"<pre><code>type ChangeType string\n\nconst (\n  ChangeRegistered     ChangeType = \"registered\"\n  ChangeUpdated        ChangeType = \"updated\"\n  ChangeBackendRemoved ChangeType = \"backend_removed\"\n  ChangeToolRemoved    ChangeType = \"tool_removed\"\n  ChangeRefreshed      ChangeType = \"refreshed\"\n)\n\ntype ChangeEvent struct {\n  Type    ChangeType\n  ToolID  string\n  Backend toolmodel.ToolBackend\n  Version uint64\n}\n\ntype ChangeListener func(ChangeEvent)\n\ntype ChangeNotifier interface {\n  OnChange(listener ChangeListener) (unsubscribe func())\n}\n\ntype Refresher interface {\n  Refresh() uint64\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/api/#summary","title":"Summary","text":"<pre><code>type Summary struct {\n  ID               string\n  Name             string\n  Namespace        string\n  ShortDescription string\n  Tags             []string\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/api/#registration","title":"Registration","text":"<pre><code>type ToolRegistration struct {\n  Tool    toolmodel.Tool\n  Backend toolmodel.ToolBackend\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/api/#searcher","title":"Searcher","text":"<pre><code>type Searcher interface {\n  Search(query string, limit int, docs []SearchDoc) ([]Summary, error)\n}\n\ntype SearchDoc struct {\n  ID      string\n  DocText string\n  Summary Summary\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/api/#options","title":"Options","text":"<pre><code>type IndexOptions struct {\n  BackendSelector BackendSelector\n  Searcher        Searcher\n}\n\ntype BackendSelector func([]toolmodel.ToolBackend) toolmodel.ToolBackend\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/api/#errors","title":"Errors","text":"<ul> <li><code>ErrNotFound</code></li> <li><code>ErrInvalidTool</code></li> <li><code>ErrInvalidBackend</code></li> </ul>"},{"location":"library-docs-from-repos/toolindex/architecture/","title":"Architecture","text":"<p><code>toolindex</code> maintains a canonical map of tools and a cached search document set. It is optimized for frequent reads and infrequent writes.</p>"},{"location":"library-docs-from-repos/toolindex/architecture/#registration-search-flow","title":"Registration + search flow","text":""},{"location":"library-docs-from-repos/toolindex/architecture/#search-sequence","title":"Search sequence","text":""},{"location":"library-docs-from-repos/toolindex/architecture/#progressive-disclosure-contract","title":"Progressive disclosure contract","text":"<ul> <li><code>Search</code> returns summaries only</li> <li>Schema and examples are retrieved later via <code>tooldocs</code></li> </ul>"},{"location":"library-docs-from-repos/toolindex/architecture/#default-backend-policy","title":"Default backend policy","text":"<p>The default backend selector prefers:</p> <ol> <li>local</li> <li>provider</li> <li>mcp</li> </ol> <p>Exported as <code>toolindex.DefaultBackendSelector</code>.</p>"},{"location":"library-docs-from-repos/toolindex/design-notes/","title":"Design Notes","text":"<p>This page captures the tradeoffs and error semantics behind <code>toolindex</code>.</p>"},{"location":"library-docs-from-repos/toolindex/design-notes/#design-tradeoffs","title":"Design tradeoffs","text":"<ul> <li>In-memory first. <code>InMemoryIndex</code> favors low latency and zero dependencies. It trades persistence for speed and simplicity (persistence can be added later behind the same <code>Index</code> interface).</li> <li>Progressive disclosure. Search returns summaries only; full schemas stay out of the discovery path to keep token costs low.</li> <li>Deterministic behavior. Search docs are cached and sorted by tool ID to keep results reproducible across runs.</li> <li>Protocol-agnostic backends. Backends are stored as metadata only; the index does not execute tools or depend on transport details.</li> <li>MCP-field consistency check. If multiple backends register the same tool ID, the MCP tool fields must match. This prevents silent divergence across backends.</li> <li>Pluggable search. <code>Searcher</code> allows swapping lexical search with BM25 or semantic search without changing the index API.</li> </ul>"},{"location":"library-docs-from-repos/toolindex/design-notes/#error-semantics","title":"Error semantics","text":"<p><code>toolindex</code> exposes sentinel errors for predictable failure handling:</p> <ul> <li><code>ErrNotFound</code> \u2013 tool or backend not present.</li> <li><code>ErrInvalidTool</code> \u2013 tool validation failed (delegates to <code>toolmodel.Tool.Validate</code>).</li> <li><code>ErrInvalidBackend</code> \u2013 backend is missing required fields for its kind.</li> </ul>"},{"location":"library-docs-from-repos/toolindex/design-notes/#registration-failures","title":"Registration failures","text":"<ul> <li>If a tool with the same ID is registered and its MCP fields differ, registration fails with <code>ErrInvalidTool</code>.</li> <li>Invalid backend structures return <code>ErrInvalidBackend</code> with a descriptive message.</li> </ul>"},{"location":"library-docs-from-repos/toolindex/design-notes/#lookup-failures","title":"Lookup failures","text":"<ul> <li><code>GetTool</code> / <code>GetAllBackends</code> return <code>ErrNotFound</code> when the tool ID is missing.</li> <li><code>UnregisterBackend</code> returns <code>ErrNotFound</code> if the tool or backend is not present.</li> </ul>"},{"location":"library-docs-from-repos/toolindex/design-notes/#search-behavior","title":"Search behavior","text":"<ul> <li>Lexical default: substring matching with scoring (name &gt; namespace &gt; description/tags).</li> <li>Empty queries: return the first N tools (deterministic order).</li> <li>Tags: normalized via <code>toolmodel.NormalizeTags</code> and included in the search corpus.</li> </ul>"},{"location":"library-docs-from-repos/toolindex/design-notes/#extension-points","title":"Extension points","text":"<ul> <li>Custom backend selector: inject a policy (e.g., \u201cprefer MCP over local\u201d).</li> <li>Custom searcher: replace lexical search with <code>toolsearch</code> BM25 or a semantic engine.</li> <li>External indexing: implement <code>Index</code> with a DB-backed or remote store in the future.</li> </ul>"},{"location":"library-docs-from-repos/toolindex/design-notes/#operational-guidance","title":"Operational guidance","text":"<ul> <li>Prefer <code>RegisterToolsFromMCP</code> for ingesting MCP server tools.</li> <li>Normalize tags at ingestion to keep search results consistent.</li> <li>Keep namespaces stable so tool IDs remain durable across deployments.</li> </ul>"},{"location":"library-docs-from-repos/toolindex/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/toolindex/examples/#custom-backend-selection","title":"Custom backend selection","text":"<pre><code>selector := func(backends []toolmodel.ToolBackend) toolmodel.ToolBackend {\n  // Prefer MCP for this app\n  for _, b := range backends {\n    if b.Kind == toolmodel.BackendKindMCP {\n      return b\n    }\n  }\n  return toolindex.DefaultBackendSelector(backends)\n}\n\nidx := toolindex.NewInMemoryIndex(toolindex.IndexOptions{BackendSelector: selector})\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/examples/#inject-bm25-searcher","title":"Inject BM25 searcher","text":"<pre><code>searcher := toolsearch.NewBM25Searcher(toolsearch.BM25Config{K1: 1.4, B: 0.75})\nidx := toolindex.NewInMemoryIndex(toolindex.IndexOptions{Searcher: searcher})\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/examples/#multiple-backends","title":"Multiple backends","text":"<pre><code>_ = idx.RegisterTool(tool, toolmodel.ToolBackend{\n  Kind: toolmodel.BackendKindMCP,\n  MCP:  &amp;toolmodel.MCPBackend{ServerName: \"github\"},\n})\n\n_ = idx.RegisterTool(tool, toolmodel.ToolBackend{\n  Kind:  toolmodel.BackendKindLocal,\n  Local: &amp;toolmodel.LocalBackend{Name: \"get_repo\"},\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/toolindex/usage/#register-tools","title":"Register tools","text":"<pre><code>idx := toolindex.NewInMemoryIndex()\n\nreg := toolindex.ToolRegistration{Tool: tool, Backend: backend}\nif err := idx.RegisterTools([]toolindex.ToolRegistration{reg}); err != nil {\n  // handle error\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/usage/#search","title":"Search","text":"<pre><code>summaries, err := idx.Search(\"repo metadata\", 5)\nif err != nil {\n  // handle error\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/usage/#lookup-and-backends","title":"Lookup and backends","text":"<pre><code>t, defaultBackend, err := idx.GetTool(\"github:get_repo\")\nif err != nil {\n  // handle not found\n}\n\nallBackends, _ := idx.GetAllBackends(t.ToolID())\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/usage/#register-from-mcp","title":"Register from MCP","text":"<pre><code>_ = idx.RegisterToolsFromMCP(\"github\", []toolmodel.Tool{toolA, toolB})\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/usage/#options","title":"Options","text":"<pre><code>idx := toolindex.NewInMemoryIndex(toolindex.IndexOptions{\n  BackendSelector: mySelector,\n  Searcher:        mySearcher,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/user-journey/","title":"User Journey","text":"<p>This journey shows how <code>toolindex</code> supports end-to-end agent workflows by powering discovery and canonical lookup.</p>"},{"location":"library-docs-from-repos/toolindex/user-journey/#end-to-end-flow-stack-view","title":"End-to-end flow (stack view)","text":""},{"location":"library-docs-from-repos/toolindex/user-journey/#step-by-step","title":"Step-by-step","text":"<ol> <li>Ingest tools from MCP servers or local registries:</li> <li><code>RegisterToolsFromMCP(serverName, tools)</code></li> <li><code>RegisterTool(tool, backend)</code> for local/provider tools</li> <li>Agent discovers tools via <code>search_tools</code> (summary only).</li> <li>Agent selects a tool ID and requests schema/docs (<code>describe_tool</code>).</li> <li>Agent executes via <code>run_tool</code> or <code>run_chain</code>.</li> </ol>"},{"location":"library-docs-from-repos/toolindex/user-journey/#example-register-and-search","title":"Example: register and search","text":"<pre><code>idx := toolindex.NewInMemoryIndex()\n\n// MCP-backed tools\n_ = idx.RegisterToolsFromMCP(\"github\", []toolmodel.Tool{repoTool})\n\n// Local tool\n_ = idx.RegisterTool(localTool, toolmodel.ToolBackend{\n  Kind: toolmodel.BackendKindLocal,\n  Local: &amp;toolmodel.LocalBackend{Name: \"local_handler\"},\n})\n\nsummaries, _ := idx.Search(\"repo\", 5)\nfor _, s := range summaries {\n  fmt.Println(s.ID, s.ShortDescription)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolindex/user-journey/#expected-outcomes","title":"Expected outcomes","text":"<ul> <li>Fast, deterministic search results.</li> <li>Stable tool IDs across backends.</li> <li>Safe summaries for progressive disclosure.</li> </ul>"},{"location":"library-docs-from-repos/toolindex/user-journey/#common-failure-modes","title":"Common failure modes","text":"<ul> <li><code>ErrInvalidTool</code> when tool validation fails.</li> <li><code>ErrInvalidBackend</code> when backend metadata is incomplete.</li> <li><code>ErrNotFound</code> for missing tool IDs or backends.</li> </ul>"},{"location":"library-docs-from-repos/toolindex/user-journey/#why-this-matters","title":"Why this matters","text":"<p><code>toolindex</code> is the \u201cfront door\u201d for tool discovery. It keeps discovery cheap and consistent while letting execution and documentation happen elsewhere.</p>"},{"location":"library-docs-from-repos/tooldocs/","title":"tooldocs","text":"<p><code>tooldocs</code> provides progressive documentation and examples for tools defined in <code>toolmodel</code> and discovered via <code>toolindex</code>.</p> <p></p>"},{"location":"library-docs-from-repos/tooldocs/#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/tooldocs/#motivation","title":"Motivation","text":"<ul> <li>Token efficiency: fetch details only when needed</li> <li>Better tool usage: schema + examples reduce call errors</li> <li>Usability: humans and agents see consistent, structured guidance</li> </ul>"},{"location":"library-docs-from-repos/tooldocs/#key-apis","title":"Key APIs","text":"<ul> <li><code>Store</code> interface</li> <li><code>InMemoryStore</code> implementation</li> <li><code>DescribeTool</code> (summary/schema/full)</li> <li><code>ListExamples</code></li> <li><code>DocEntry</code> + <code>ToolExample</code></li> </ul>"},{"location":"library-docs-from-repos/tooldocs/#quickstart","title":"Quickstart","text":"<pre><code>store := tooldocs.NewInMemoryStore(tooldocs.StoreOptions{Index: idx})\n\n_ = store.RegisterDoc(\"github:get_repo\", tooldocs.DocEntry{\n  Summary: \"Fetch repository metadata\",\n  Notes:   \"Requires authentication.\",\n})\n\ndoc, _ := store.DescribeTool(\"github:get_repo\", tooldocs.DetailSchema)\nexamples, _ := store.ListExamples(\"github:get_repo\", 2)\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/#usability-notes","title":"Usability notes","text":"<ul> <li>Summary and schema are safe defaults for discovery</li> <li>Examples are capped to prevent token blowups</li> <li>Notes and external refs are optional but highly recommended</li> </ul>"},{"location":"library-docs-from-repos/tooldocs/#next","title":"Next","text":"<ul> <li>Detail tiers and resolution: <code>architecture.md</code></li> <li>Registration and caps: <code>usage.md</code></li> <li>Examples: <code>examples.md</code></li> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/tooldocs/api/","title":"API Reference","text":""},{"location":"library-docs-from-repos/tooldocs/api/#store-interface","title":"Store interface","text":"<pre><code>type Store interface {\n  DescribeTool(id string, level DetailLevel) (ToolDoc, error)\n  ListExamples(id string, maxExamples int) ([]ToolExample, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/api/#detail-levels","title":"Detail levels","text":"<pre><code>const (\n  DetailSummary DetailLevel = \"summary\"\n  DetailSchema  DetailLevel = \"schema\"\n  DetailFull    DetailLevel = \"full\"\n)\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/api/#tooldoc","title":"ToolDoc","text":"<pre><code>type ToolDoc struct {\n  Tool         *toolmodel.Tool\n  Summary      string\n  SchemaInfo   *SchemaInfo\n  Notes        string\n  Examples     []ToolExample\n  ExternalRefs []string\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/api/#toolexample","title":"ToolExample","text":"<pre><code>type ToolExample struct {\n  ID          string\n  Title       string\n  Description string\n  Args        map[string]any\n  ResultHint  string\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/api/#schemainfo","title":"SchemaInfo","text":"<pre><code>type SchemaInfo struct {\n  Required []string\n  Defaults map[string]any\n  Types    map[string][]string\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/api/#storeoptions","title":"StoreOptions","text":"<pre><code>type StoreOptions struct {\n  Index        toolindex.Index\n  ToolResolver func(id string) (*toolmodel.Tool, error)\n  MaxExamples  int\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/api/#inmemorystore","title":"InMemoryStore","text":"<pre><code>func NewInMemoryStore(opts StoreOptions) *InMemoryStore\nfunc (s *InMemoryStore) RegisterDoc(id string, entry DocEntry) error\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/api/#errors","title":"Errors","text":"<ul> <li><code>ErrNotFound</code></li> <li><code>ErrInvalidDetail</code></li> <li><code>ErrNoTool</code></li> <li><code>ErrArgsTooLarge</code></li> </ul>"},{"location":"library-docs-from-repos/tooldocs/architecture/","title":"Architecture","text":"<p><code>tooldocs</code> adds a documentation layer on top of <code>toolmodel</code>. It does not change schemas; it augments them with guidance and examples.</p>"},{"location":"library-docs-from-repos/tooldocs/architecture/#tiered-disclosure","title":"Tiered disclosure","text":""},{"location":"library-docs-from-repos/tooldocs/architecture/#resolution-sequence","title":"Resolution sequence","text":""},{"location":"library-docs-from-repos/tooldocs/architecture/#progressive-disclosure-contract","title":"Progressive disclosure contract","text":"<ul> <li><code>DetailSummary</code>: short text only</li> <li><code>DetailSchema</code>: full tool + derived schema info</li> <li><code>DetailFull</code>: schema + notes + examples</li> </ul>"},{"location":"library-docs-from-repos/tooldocs/architecture/#resolution-modes","title":"Resolution modes","text":"<ul> <li>via <code>toolindex.Index</code> (preferred)</li> <li>via a custom <code>ToolResolver</code> function</li> </ul>"},{"location":"library-docs-from-repos/tooldocs/design-notes/","title":"Design Notes","text":"<p>This page explains the design choices and error semantics for <code>tooldocs</code>.</p>"},{"location":"library-docs-from-repos/tooldocs/design-notes/#design-tradeoffs","title":"Design tradeoffs","text":"<ul> <li>Progressive detail tiers. <code>DetailSummary</code>, <code>DetailSchema</code>, and <code>DetailFull</code> keep large docs out of the default path while still allowing rich guidance on demand.</li> <li>Schema-first truth. <code>ToolDoc.Tool</code> (from <code>toolmodel</code>) remains the canonical schema source; docs only augment, they do not override.</li> <li>Token safety caps. Examples, summaries, notes, and args are capped to prevent context bloat in downstream LLM usage.</li> <li>Best-effort schema derivation. <code>SchemaInfo</code> is derived from JSON Schema when possible; missing or complex schema features simply result in empty fields.</li> <li>Mutable-safety. Args are deep-copied and normalized to MCP-native shapes on registration and retrieval to avoid mutation bugs.</li> <li>Flexible resolution. Docs can be served from the index or a custom resolver, enabling file-backed or remote sources without changing the interface.</li> </ul>"},{"location":"library-docs-from-repos/tooldocs/design-notes/#error-semantics","title":"Error semantics","text":"<p><code>tooldocs</code> exposes sentinel errors for predictable handling:</p> <ul> <li><code>ErrNotFound</code> \u2013 no docs and no tool found for the given ID.</li> <li><code>ErrInvalidDetail</code> \u2013 unknown detail level requested.</li> <li><code>ErrNoTool</code> \u2013 schema/full requested but tool is not resolvable.</li> <li><code>ErrArgsTooLarge</code> \u2013 example args exceed depth/size caps.</li> </ul>"},{"location":"library-docs-from-repos/tooldocs/design-notes/#behavior-by-level","title":"Behavior by level","text":"<ul> <li>Summary: works when either docs or tool exist; returns <code>ErrNotFound</code> only if both are missing.</li> <li>Schema/Full: requires <code>toolmodel.Tool</code> (from <code>toolindex</code> or <code>ToolResolver</code>), otherwise returns <code>ErrNoTool</code>.</li> </ul>"},{"location":"library-docs-from-repos/tooldocs/design-notes/#extension-points","title":"Extension points","text":"<ul> <li>Custom resolvers: provide <code>ToolResolver</code> when tools are not in <code>toolindex</code>.</li> <li>Alternative stores: implement <code>Store</code> for file-backed or remote doc sources.</li> <li>Docs generation: generate <code>DocEntry</code> from code comments or external sources and register at startup.</li> </ul>"},{"location":"library-docs-from-repos/tooldocs/design-notes/#operational-guidance","title":"Operational guidance","text":"<ul> <li>Keep examples short and bounded; the caps (<code>MaxArgsDepth</code>, <code>MaxArgsKeys</code>, etc.) are enforced at registration time.</li> <li>Prefer a small number of high-quality examples over many low-signal ones.</li> <li>Use <code>SchemaInfo</code> only for UI hints and human guidance; use actual schemas for validation.</li> </ul>"},{"location":"library-docs-from-repos/tooldocs/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/tooldocs/examples/#schema-level-detail","title":"Schema-level detail","text":"<pre><code>doc, _ := store.DescribeTool(\"github:get_repo\", tooldocs.DetailSchema)\nfmt.Println(doc.Tool.InputSchema)\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/examples/#full-detail-with-examples","title":"Full detail with examples","text":"<pre><code>full, _ := store.DescribeTool(\"github:get_repo\", tooldocs.DetailFull)\nfor _, ex := range full.Examples {\n  fmt.Println(ex.Title, ex.Args)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/examples/#resolver-only-usage-no-toolindex","title":"Resolver-only usage (no toolindex)","text":"<pre><code>store := tooldocs.NewInMemoryStore(tooldocs.StoreOptions{\n  ToolResolver: func(id string) (*toolmodel.Tool, error) {\n    if id != \"tickets:create\" {\n      return nil, fmt.Errorf(\"unknown: %s\", id)\n    }\n    t := toolmodel.Tool{Namespace: \"tickets\"}\n    t.Name = \"create\"\n    t.Description = \"Create a support ticket\"\n    t.InputSchema = map[string]any{\"type\": \"object\"}\n    return &amp;t, nil\n  },\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/tooldocs/usage/#register-docs","title":"Register docs","text":"<pre><code>store := tooldocs.NewInMemoryStore(tooldocs.StoreOptions{\n  Index:       idx,\n  MaxExamples: 3,\n})\n\nerr := store.RegisterDoc(\"tickets:create\", tooldocs.DocEntry{\n  Summary: \"Create a support ticket\",\n  Notes:   \"Requires authentication. Supports idempotency via request_id.\",\n  Examples: []tooldocs.ToolExample{\n    {\n      Title:       \"Minimal\",\n      Description: \"Create a low-priority ticket\",\n      Args:        map[string]any{\"title\": \"Login broken\"},\n      ResultHint:  \"Ticket object with id and status\",\n    },\n  },\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/usage/#describe-tools","title":"Describe tools","text":"<pre><code>doc, _ := store.DescribeTool(\"tickets:create\", tooldocs.DetailSchema)\nfull, _ := store.DescribeTool(\"tickets:create\", tooldocs.DetailFull)\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/usage/#list-examples","title":"List examples","text":"<pre><code>examples, _ := store.ListExamples(\"tickets:create\", 2)\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/usage/#size-caps","title":"Size caps","text":"<p>Examples are validated at registration time:</p> <ul> <li><code>MaxArgsDepth = 5</code></li> <li><code>MaxArgsKeys = 50</code></li> <li><code>MaxDescriptionLen = 300</code></li> <li><code>MaxResultHintLen = 200</code></li> </ul>"},{"location":"library-docs-from-repos/tooldocs/user-journey/","title":"User Journey","text":"<p>This journey shows how <code>tooldocs</code> provides progressive disclosure in an end-to-end agent workflow.</p>"},{"location":"library-docs-from-repos/tooldocs/user-journey/#end-to-end-flow-stack-view","title":"End-to-end flow (stack view)","text":""},{"location":"library-docs-from-repos/tooldocs/user-journey/#step-by-step","title":"Step-by-step","text":"<ol> <li>Discovery: agent finds candidate tools via <code>search_tools</code>.</li> <li>Schema retrieval: agent requests <code>detail_level=\"schema\"</code> to see required parameters.</li> <li>Full guidance: agent requests <code>detail_level=\"full\"</code> or <code>list_tool_examples</code> when extra guidance is needed.</li> <li>Execution: agent calls the tool using <code>toolrun</code> with validated args.</li> </ol>"},{"location":"library-docs-from-repos/tooldocs/user-journey/#example-register-docs-and-fetch","title":"Example: register docs and fetch","text":"<pre><code>store := tooldocs.NewInMemoryStore(tooldocs.StoreOptions{Index: idx})\n\n_ = store.RegisterDoc(\"github:create_issue\", tooldocs.DocEntry{\n  Summary: \"Create a GitHub issue.\",\n  Notes:   \"Use labels sparingly; title is required.\",\n  Examples: []tooldocs.ToolExample{\n    {\n      Title:       \"Create a bug issue\",\n      Description: \"Create a bug ticket with a label.\",\n      Args: map[string]any{\n        \"owner\": \"acme\",\n        \"repo\": \"app\",\n        \"title\": \"Crash on login\",\n        \"labels\": []any{\"bug\"},\n      },\n      ResultHint: \"Returns the issue number and URL.\",\n    },\n  },\n})\n\ndoc, _ := store.DescribeTool(\"github:create_issue\", tooldocs.DetailFull)\n</code></pre>"},{"location":"library-docs-from-repos/tooldocs/user-journey/#expected-outcomes","title":"Expected outcomes","text":"<ul> <li>Clear, compact guidance without shipping the full schema by default.</li> <li>Predictable errors when docs are missing or a tool cannot be resolved.</li> <li>Examples that are safe to include in LLM context.</li> </ul>"},{"location":"library-docs-from-repos/tooldocs/user-journey/#common-failure-modes","title":"Common failure modes","text":"<ul> <li><code>ErrNoTool</code> when requesting schema/full without tool registration.</li> <li><code>ErrArgsTooLarge</code> when example payloads exceed caps.</li> <li><code>ErrInvalidDetail</code> for invalid detail levels.</li> </ul>"},{"location":"library-docs-from-repos/toolrun/","title":"toolrun","text":"<p><code>toolrun</code> executes tools and chains. It resolves tools/backends, validates inputs/outputs against JSON Schema, dispatches to the correct executor, and normalizes results.</p> <p></p>"},{"location":"library-docs-from-repos/toolrun/#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolrun/#motivation","title":"Motivation","text":"<ul> <li>Consistent execution across MCP, provider, and local tools</li> <li>Safety via schema validation and normalized results</li> <li>Usability with clear error wrapping and chain semantics</li> </ul>"},{"location":"library-docs-from-repos/toolrun/#key-apis","title":"Key APIs","text":"<ul> <li><code>Runner</code> interface</li> <li><code>DefaultRunner</code> (via <code>NewRunner</code>)</li> <li><code>Run</code>, <code>RunStream</code>, <code>RunChain</code></li> <li><code>ChainStep</code>, <code>RunResult</code>, <code>StreamEvent</code></li> </ul>"},{"location":"library-docs-from-repos/toolrun/#quickstart","title":"Quickstart","text":"<pre><code>runner := toolrun.NewRunner(\n  toolrun.WithIndex(idx),\n  toolrun.WithMCPExecutor(mcpExec),\n  toolrun.WithLocalRegistry(localRegistry),\n)\n\nres, _ := runner.Run(ctx, \"github:get_repo\", map[string]any{\"owner\": \"o\", \"repo\": \"r\"})\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/#usability-notes","title":"Usability notes","text":"<ul> <li>Backend selection is deterministic by default</li> <li>Chain steps can inject <code>previous</code> results</li> <li>Streaming is optional; non-streaming backends return <code>ErrStreamNotSupported</code></li> </ul>"},{"location":"library-docs-from-repos/toolrun/#next","title":"Next","text":"<ul> <li>Execution pipeline: <code>architecture.md</code></li> <li>Configuration and options: <code>usage.md</code></li> <li>Examples: <code>examples.md</code></li> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolrun/api/","title":"API Reference","text":""},{"location":"library-docs-from-repos/toolrun/api/#runner-interface","title":"Runner interface","text":"<pre><code>type Runner interface {\n  Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)\n  RunStream(ctx context.Context, toolID string, args map[string]any) (&lt;-chan StreamEvent, error)\n  RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/api/#config","title":"Config","text":"<pre><code>type Config struct {\n  Index           toolindex.Index\n  ToolResolver    func(id string) (*toolmodel.Tool, error)\n  BackendsResolver func(id string) ([]toolmodel.ToolBackend, error)\n  BackendSelector toolindex.BackendSelector\n  Validator       toolmodel.SchemaValidator\n  ValidateInput   bool\n  ValidateOutput  bool\n  MCP      MCPExecutor\n  Provider ProviderExecutor\n  Local    LocalRegistry\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/api/#executors","title":"Executors","text":"<pre><code>type MCPExecutor interface {\n  CallTool(ctx context.Context, serverName string, params *mcp.CallToolParams) (*mcp.CallToolResult, error)\n  CallToolStream(ctx context.Context, serverName string, params *mcp.CallToolParams) (&lt;-chan StreamEvent, error)\n}\n\ntype ProviderExecutor interface {\n  CallTool(ctx context.Context, providerID, toolID string, args map[string]any) (any, error)\n  CallToolStream(ctx context.Context, providerID, toolID string, args map[string]any) (&lt;-chan StreamEvent, error)\n}\n\ntype LocalRegistry interface {\n  Get(name string) (LocalHandler, bool)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/api/#results","title":"Results","text":"<pre><code>type ChainStep struct {\n  ToolID      string\n  Args        map[string]any\n  UsePrevious bool\n}\n\ntype RunResult struct {\n  Tool       toolmodel.Tool\n  Backend    toolmodel.ToolBackend\n  Structured any\n  MCPResult  *mcp.CallToolResult\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/api/#streaming","title":"Streaming","text":"<pre><code>type StreamEvent struct {\n  Kind  StreamEventKind\n  ToolID string\n  Data  any\n  Err   error\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/api/#errors","title":"Errors","text":"<ul> <li><code>ErrNotFound</code></li> <li><code>ErrNoBackends</code></li> <li><code>ErrValidation</code></li> <li><code>ErrOutputValidation</code></li> <li><code>ErrExecution</code></li> <li><code>ErrStreamNotSupported</code></li> </ul>"},{"location":"library-docs-from-repos/toolrun/architecture/","title":"Architecture","text":"<p><code>toolrun</code> implements a consistent execution pipeline with validation and backend dispatch. It is transport-agnostic and depends on <code>toolmodel</code> types.</p>"},{"location":"library-docs-from-repos/toolrun/architecture/#single-tool-execution","title":"Single-tool execution","text":""},{"location":"library-docs-from-repos/toolrun/architecture/#chain-execution","title":"Chain execution","text":""},{"location":"library-docs-from-repos/toolrun/design-notes/","title":"Design Notes","text":"<p>This page documents the key tradeoffs and error semantics behind <code>toolrun</code>.</p>"},{"location":"library-docs-from-repos/toolrun/design-notes/#design-tradeoffs","title":"Design tradeoffs","text":"<ul> <li>Backend-agnostic execution. The runner dispatches to MCP, provider, or local backends through narrow executor interfaces. This keeps tool execution pluggable without embedding transport details.</li> <li>Index-first resolution. When configured, <code>toolindex</code> is the primary source for tool definitions and backends. Optional resolvers allow ad-hoc tools or dynamic backends without an index.</li> <li>Validation on by default. Input and output validation is enabled by default to catch schema errors early. This trades a small amount of latency for correctness and safety.</li> <li>Strict chaining policy. Chains stop on the first error (v1) and inject previous results at <code>args[\"previous\"]</code> when requested. This is deterministic and easy to reason about, but not a branching workflow engine.</li> <li>Structured-first results. For MCP backends, <code>StructuredContent</code> is preferred; otherwise text content is best-effort parsed as JSON. This avoids losing structure while preserving fallback behavior.</li> </ul>"},{"location":"library-docs-from-repos/toolrun/design-notes/#error-semantics","title":"Error semantics","text":"<p><code>toolrun</code> uses sentinel errors and wrapped context via <code>ToolError</code>:</p> <ul> <li><code>ErrToolNotFound</code> \u2013 no tool definition could be resolved.</li> <li><code>ErrNoBackends</code> \u2013 tool exists but no backend is available.</li> <li><code>ErrValidation</code> \u2013 input validation failed.</li> <li><code>ErrExecution</code> \u2013 backend execution failed.</li> <li><code>ErrOutputValidation</code> \u2013 output validation failed.</li> <li><code>ErrStreamNotSupported</code> \u2013 streaming is not supported by the selected backend.</li> </ul> <p><code>ToolError</code> wraps these with <code>ToolID</code>, <code>Backend</code>, and <code>Op</code> (e.g., <code>resolve</code>, <code>execute</code>, <code>validate_input</code>).</p>"},{"location":"library-docs-from-repos/toolrun/design-notes/#extension-points","title":"Extension points","text":"<ul> <li>Custom backend selection: provide <code>BackendSelector</code> to prioritize specific backends.</li> <li>Custom validation: plug in a different <code>SchemaValidator</code> implementation.</li> <li>Custom executors: implement <code>MCPExecutor</code>, <code>ProviderExecutor</code>, or <code>LocalRegistry</code> for your runtime.</li> </ul>"},{"location":"library-docs-from-repos/toolrun/design-notes/#operational-guidance","title":"Operational guidance","text":"<ul> <li>Prefer registering tools in <code>toolindex</code> for consistent resolution and backends.</li> <li>Enable output validation in production to catch schema drift early.</li> <li>Use streaming only when your backend supports it; otherwise expect <code>ErrStreamNotSupported</code>.</li> </ul>"},{"location":"library-docs-from-repos/toolrun/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/toolrun/examples/#local-tool-execution","title":"Local tool execution","text":"<pre><code>registry := toolrun.NewLocalRegistry()\nregistry.Register(\"ping\", func(ctx context.Context, args map[string]any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n\nrunner := toolrun.NewRunner(\n  toolrun.WithIndex(idx),\n  toolrun.WithLocalRegistry(registry),\n)\n\nres, _ := runner.Run(ctx, \"local:ping\", map[string]any{})\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/examples/#streaming","title":"Streaming","text":"<pre><code>ch, err := runner.RunStream(ctx, \"logs:stream\", map[string]any{\"tail\": 100})\nif err != nil {\n  // handle ErrStreamNotSupported\n}\nfor ev := range ch {\n  fmt.Println(ev.Data)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/examples/#backend-resolution-fallback","title":"Backend resolution fallback","text":"<pre><code>runner := toolrun.NewRunner(\n  toolrun.WithToolResolver(func(id string) (*toolmodel.Tool, error) {\n    // resolve from external store\n    return &amp;tool, nil\n  }),\n  toolrun.WithBackendsResolver(func(id string) ([]toolmodel.ToolBackend, error) {\n    return []toolmodel.ToolBackend{backend}, nil\n  }),\n)\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/toolrun/usage/#configure-a-runner","title":"Configure a runner","text":"<pre><code>runner := toolrun.NewRunner(\n  toolrun.WithIndex(idx),\n  toolrun.WithMCPExecutor(mcpExec),\n  toolrun.WithProviderExecutor(providerExec),\n  toolrun.WithLocalRegistry(localRegistry),\n)\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/usage/#validation-control","title":"Validation control","text":"<pre><code>runner := toolrun.NewRunner(\n  toolrun.WithIndex(idx),\n  toolrun.WithValidation(true, false), // validate input, skip output\n)\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/usage/#run-a-tool","title":"Run a tool","text":"<pre><code>res, err := runner.Run(ctx, \"github:get_repo\", map[string]any{\n  \"owner\": \"octo\",\n  \"repo\":  \"hello\",\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/usage/#run-a-chain","title":"Run a chain","text":"<pre><code>steps := []toolrun.ChainStep{\n  {ToolID: \"user:get\", Args: map[string]any{\"user_id\": \"123\"}},\n  {ToolID: \"orders:list\", UsePrevious: true},\n}\n\nfinal, all, err := runner.RunChain(ctx, steps)\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/user-journey/","title":"User Journey","text":"<p>This journey shows how <code>toolrun</code> executes tools and chains in a full end-to-end agent flow.</p>"},{"location":"library-docs-from-repos/toolrun/user-journey/#end-to-end-flow-stack-view","title":"End-to-end flow (stack view)","text":""},{"location":"library-docs-from-repos/toolrun/user-journey/#step-by-step","title":"Step-by-step","text":"<ol> <li>Resolve the tool and its backends (via <code>toolindex</code> or resolver callbacks).</li> <li>Select the backend (default priority: local &gt; provider &gt; MCP).</li> <li>Validate input against JSON Schema.</li> <li>Dispatch to the selected backend.</li> <li>Normalize output (structured content preferred).</li> <li>Validate output (optional).</li> </ol>"},{"location":"library-docs-from-repos/toolrun/user-journey/#example-run-a-tool","title":"Example: run a tool","text":"<pre><code>runner := toolrun.NewRunner(\n  toolrun.WithIndex(idx),\n  toolrun.WithMCPExecutor(mcpExec),\n)\n\nres, err := runner.Run(ctx, \"github:get_repo\", map[string]any{\n  \"owner\": \"acme\",\n  \"repo\":  \"app\",\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/user-journey/#example-chain-two-tools","title":"Example: chain two tools","text":"<pre><code>steps := []toolrun.ChainStep{\n  {ToolID: \"github:get_repo\", Args: map[string]any{\"owner\": \"acme\", \"repo\": \"app\"}},\n  {ToolID: \"github:list_issues\", UsePrevious: true},\n}\n\nfinal, stepsOut, err := runner.RunChain(ctx, steps)\n</code></pre>"},{"location":"library-docs-from-repos/toolrun/user-journey/#expected-outcomes","title":"Expected outcomes","text":"<ul> <li>Consistent execution across backends.</li> <li>Structured results suitable for chaining.</li> <li>Explicit error classification with <code>ToolError</code>.</li> </ul>"},{"location":"library-docs-from-repos/toolrun/user-journey/#common-failure-modes","title":"Common failure modes","text":"<ul> <li><code>ErrToolNotFound</code> if the tool is missing.</li> <li><code>ErrValidation</code> for schema violations.</li> <li><code>ErrExecution</code> for backend errors.</li> <li><code>ErrStreamNotSupported</code> when streaming is requested but unsupported.</li> </ul>"},{"location":"library-docs-from-repos/toolcode/","title":"toolcode","text":"<p><code>toolcode</code> executes short orchestration snippets over the tool stack. It exposes Search/Describe/Run helpers to code, enforces timeouts and limits, and records tool calls for observability.</p> <p></p>"},{"location":"library-docs-from-repos/toolcode/#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolcode/#motivation","title":"Motivation","text":"<ul> <li>Programmable orchestration: loops, conditionals, fallbacks</li> <li>Uniform tool surface: same helpers regardless of backend</li> <li>Traceability: tool call records for debugging and audits</li> </ul>"},{"location":"library-docs-from-repos/toolcode/#key-apis","title":"Key APIs","text":"<ul> <li><code>Executor</code> interface (<code>ExecuteCode</code>)</li> <li><code>DefaultExecutor</code> implementation</li> <li><code>Engine</code> interface (pluggable runtime)</li> <li><code>ExecuteParams</code>, <code>ExecuteResult</code>, <code>ToolCallRecord</code></li> </ul>"},{"location":"library-docs-from-repos/toolcode/#quickstart","title":"Quickstart","text":"<pre><code>exec, _ := toolcode.NewDefaultExecutor(toolcode.Config{\n  Index:  idx,\n  Docs:   docs,\n  Run:    runner,\n  Engine: engine,\n})\n\nres, _ := exec.ExecuteCode(ctx, toolcode.ExecuteParams{\n  Language: \"go\",\n  Code:     \"__out = 2 + 2\",\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/#usability-notes","title":"Usability notes","text":"<ul> <li><code>ExecuteParams</code> supports per-call timeouts</li> <li>Tool calls are capped via config and params</li> <li><code>ExecuteResult</code> includes tool call traces</li> </ul>"},{"location":"library-docs-from-repos/toolcode/#next","title":"Next","text":"<ul> <li>Execution pipeline: <code>architecture.md</code></li> <li>Config, limits, and params: <code>usage.md</code></li> <li>Examples: <code>examples.md</code></li> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolcode/api/","title":"API Reference","text":""},{"location":"library-docs-from-repos/toolcode/api/#executor","title":"Executor","text":"<pre><code>type Executor interface {\n  ExecuteCode(ctx context.Context, params ExecuteParams) (ExecuteResult, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/api/#engine","title":"Engine","text":"<pre><code>type Engine interface {\n  Execute(ctx context.Context, params ExecuteParams, tools Tools) (ExecuteResult, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/api/#tools-surface","title":"Tools surface","text":"<pre><code>type Tools interface {\n  SearchTools(query string, limit int) ([]toolindex.Summary, error)\n  ListNamespaces() ([]string, error)\n  DescribeTool(id string, level tooldocs.DetailLevel) (tooldocs.ToolDoc, error)\n  ListToolExamples(id string, maxExamples int) ([]tooldocs.ToolExample, error)\n  RunTool(ctx context.Context, id string, args map[string]any) (toolrun.RunResult, error)\n  RunChain(ctx context.Context, steps []toolrun.ChainStep) (toolrun.RunResult, []toolrun.StepResult, error)\n  Println(args ...any)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/api/#params-results","title":"Params + results","text":"<pre><code>type ExecuteParams struct {\n  Language     string\n  Code         string\n  Timeout      time.Duration\n  MaxToolCalls int\n}\n\ntype ExecuteResult struct {\n  Value      any\n  Stdout     string\n  Stderr     string\n  ToolCalls  []ToolCallRecord\n  DurationMs int64\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/api/#toolcallrecord","title":"ToolCallRecord","text":"<pre><code>type ToolCallRecord struct {\n  ToolID     string\n  Args       map[string]any\n  Structured any\n  BackendKind string\n  Error      string\n  ErrorOp    string\n  DurationMs int64\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/api/#config","title":"Config","text":"<pre><code>type Config struct {\n  Index          toolindex.Index\n  Docs           tooldocs.Store\n  Run            toolrun.Runner\n  Engine         Engine\n  DefaultTimeout time.Duration\n  DefaultLanguage string\n  MaxToolCalls   int\n  MaxChainSteps  int\n  Logger         Logger\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/architecture/","title":"Architecture","text":"<p><code>toolcode</code> wraps tool discovery, docs, and execution into a single programmable surface. The actual code execution is delegated to an injected <code>Engine</code>.</p>"},{"location":"library-docs-from-repos/toolcode/architecture/#execution-flow","title":"Execution flow","text":""},{"location":"library-docs-from-repos/toolcode/architecture/#snippet-lifecycle","title":"Snippet lifecycle","text":""},{"location":"library-docs-from-repos/toolcode/architecture/#control-points","title":"Control points","text":"<ul> <li><code>Config</code> controls limits and defaults</li> <li><code>Engine</code> controls the execution sandbox</li> <li><code>Tools</code> surface mediates tool calls and captures traces</li> </ul>"},{"location":"library-docs-from-repos/toolcode/design-notes/","title":"Design Notes","text":"<p>This page explains the tradeoffs and error semantics behind <code>toolcode</code>.</p>"},{"location":"library-docs-from-repos/toolcode/design-notes/#design-tradeoffs","title":"Design tradeoffs","text":"<ul> <li>Engine abstraction. <code>toolcode</code> does not execute code directly. It delegates to a pluggable <code>Engine</code> so you can swap in different interpreters or sandboxes without changing the API.</li> <li>Narrow tools surface. Code snippets only see a constrained <code>Tools</code> interface (SearchTools, DescribeTool, RunTool, RunChain, Println). This limits what code can do and keeps behavior consistent.</li> <li>Limits-first design. Max tool calls and chain steps are enforced in the tools environment. Timeouts are enforced at the executor level.</li> <li>Structured observability. Every tool call is recorded with duration, backend kind, and error op for auditability.</li> <li>Default language. If not specified, <code>DefaultLanguage</code> is used (\"go\" by default), but the engine decides how that language is implemented.</li> <li>Deep copy normalization. Arguments and results are normalized to MCP-native shapes when recorded. Supported shapes include <code>map[string]any</code>, <code>[]any</code>, and common typed slices/maps; unsupported types are passed through without deep copy.</li> </ul>"},{"location":"library-docs-from-repos/toolcode/design-notes/#error-semantics","title":"Error semantics","text":"<p><code>toolcode</code> uses sentinel errors for predictable handling:</p> <ul> <li><code>ErrCodeExecution</code> \u2013 syntax/runtime errors in the snippet.</li> <li><code>ErrConfiguration</code> \u2013 missing required config (Index, Docs, Run, Engine).</li> <li><code>ErrLimitExceeded</code> \u2013 timeouts, max tool calls, or max chain steps exceeded.</li> </ul> <p><code>CodeError</code> wraps engine errors with optional line/column info.</p>"},{"location":"library-docs-from-repos/toolcode/design-notes/#extension-points","title":"Extension points","text":"<ul> <li>Custom engines: implement <code>Engine</code> for a sandboxed interpreter, WASM runtime, or remote execution service.</li> <li>Custom logging: provide a <code>Logger</code> to track tool calls and execution duration.</li> <li>Runtime integration: use <code>toolruntime/toolcodeengine</code> to run <code>toolcode</code> on top of secure runtime backends.</li> </ul>"},{"location":"library-docs-from-repos/toolcode/design-notes/#operational-guidance","title":"Operational guidance","text":"<ul> <li>Keep snippets short and deterministic; <code>ExecuteParams</code> is intended for orchestration, not full applications.</li> <li>Use <code>MaxToolCalls</code> to prevent runaway tool usage in long snippets.</li> <li>Treat <code>Stdout</code> as diagnostic output only; use <code>Value</code> for structured results.</li> </ul>"},{"location":"library-docs-from-repos/toolcode/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/toolcode/examples/#minimal-snippet","title":"Minimal snippet","text":"<pre><code>res, _ := exec.ExecuteCode(ctx, toolcode.ExecuteParams{\n  Language: \"go\",\n  Code:     \"__out = 2 + 2\",\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/examples/#tool-selection-execution","title":"Tool selection + execution","text":"<pre><code>code := `\n  tools := SearchTools(\"get repo\", 3)\n  if len(tools) == 0 {\n    __out = \"no tools\"\n  } else {\n    __out = RunTool(tools[0].ID, map[string]any{\"owner\":\"octo\",\"repo\":\"hello\"})\n  }\n`\n\nres, _ := exec.ExecuteCode(ctx, toolcode.ExecuteParams{Language: \"go\", Code: code})\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/examples/#chain-helper","title":"Chain helper","text":"<pre><code>steps := []ChainStep{\n  {ToolID: \"user:get\", Args: map[string]any{\"user_id\": \"123\"}},\n  {ToolID: \"orders:list\", UsePrevious: true},\n}\n\ncode := `__out = RunChain(steps)`\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/toolcode/usage/#configure-an-executor","title":"Configure an executor","text":"<pre><code>exec, err := toolcode.NewDefaultExecutor(toolcode.Config{\n  Index:          idx,\n  Docs:           docs,\n  Run:            runner,\n  Engine:         engine,\n  DefaultTimeout: 5 * time.Second,\n  MaxToolCalls:   32,\n  MaxChainSteps:  8,\n})\nif err != nil {\n  // handle config error\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/usage/#execute-a-snippet","title":"Execute a snippet","text":"<pre><code>res, err := exec.ExecuteCode(ctx, toolcode.ExecuteParams{\n  Language: \"go\",\n  Code: `\n    tools := SearchTools(\"repo\", 3)\n    repo := RunTool(tools[0].ID, map[string]any{\"owner\":\"o\",\"repo\":\"r\"})\n    __out = repo\n  `,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/usage/#limits","title":"Limits","text":"<ul> <li><code>MaxToolCalls</code> caps tool invocations per execution</li> <li><code>MaxChainSteps</code> caps chain length</li> <li><code>DefaultTimeout</code> applies when params omit a timeout</li> </ul>"},{"location":"library-docs-from-repos/toolcode/user-journey/","title":"User Journey","text":"<p>This journey shows how <code>toolcode</code> enables end-to-end orchestration using code snippets.</p>"},{"location":"library-docs-from-repos/toolcode/user-journey/#end-to-end-flow-stack-view","title":"End-to-end flow (stack view)","text":""},{"location":"library-docs-from-repos/toolcode/user-journey/#step-by-step","title":"Step-by-step","text":"<ol> <li>Agent submits a snippet to <code>execute_code</code>.</li> <li>Executor sets limits (timeout, tool call caps).</li> <li>Engine runs the snippet with a <code>Tools</code> environment.</li> <li>Snippet orchestrates tools via Search/Describe/Run APIs.</li> <li>Result is returned as <code>ExecuteResult</code> (Value + ToolCalls + Stdout).</li> </ol>"},{"location":"library-docs-from-repos/toolcode/user-journey/#example-pick-a-tool-and-run-it","title":"Example: pick a tool and run it","text":"<pre><code>code := `\nresults, _ := SearchTools(\"create issue\", 5)\nchoice := results[0]\n\nschema, _ := DescribeTool(choice.ID, \"schema\")\n_ = schema // use schema in real code\n\nres, _ := RunTool(choice.ID, map[string]any{\"title\": \"Bug\", \"body\": \"...\"})\n__out = res.Structured\n`\n\nexec, _ := toolcode.NewDefaultExecutor(cfg)\nresult, err := exec.ExecuteCode(ctx, toolcode.ExecuteParams{Code: code})\n</code></pre>"},{"location":"library-docs-from-repos/toolcode/user-journey/#expected-outcomes","title":"Expected outcomes","text":"<ul> <li>A deterministic orchestration surface with strong limits.</li> <li>Tool call traces for audit/debugging.</li> <li>Easy integration with secure runtimes via <code>toolruntime</code> adapters.</li> </ul>"},{"location":"library-docs-from-repos/toolcode/user-journey/#common-failure-modes","title":"Common failure modes","text":"<ul> <li><code>ErrConfiguration</code> if required dependencies are missing.</li> <li><code>ErrLimitExceeded</code> if timeouts or tool call caps are hit.</li> <li><code>ErrCodeExecution</code> if the engine rejects the snippet.</li> </ul>"},{"location":"library-docs-from-repos/toolruntime/","title":"toolruntime","text":"<p><code>toolruntime</code> defines the runtime and trust boundary for executing code in <code>toolcode</code>. It routes execution to backends with configurable security profiles.</p> <p></p>"},{"location":"library-docs-from-repos/toolruntime/#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolruntime/#motivation","title":"Motivation","text":"<ul> <li>Isolation for untrusted or semi-trusted code</li> <li>Portability across environments (host, containers, VMs)</li> <li>Policy via explicit security profiles</li> </ul>"},{"location":"library-docs-from-repos/toolruntime/#key-apis","title":"Key APIs","text":"<ul> <li><code>Runtime</code> interface</li> <li><code>DefaultRuntime</code> implementation</li> <li><code>Backend</code> interface</li> <li><code>SecurityProfile</code> (dev/standard/hardened)</li> <li><code>ExecuteRequest</code> / <code>ExecuteResult</code></li> </ul>"},{"location":"library-docs-from-repos/toolruntime/#quickstart-dev","title":"Quickstart (dev)","text":"<pre><code>backend := unsafe.New(unsafe.Config{Mode: unsafe.ModeSubprocess})\n\nrt := toolruntime.NewDefaultRuntime(toolruntime.RuntimeConfig{\n  Backends: map[toolruntime.SecurityProfile]toolruntime.Backend{\n    toolruntime.ProfileDev: backend,\n  },\n  DefaultProfile: toolruntime.ProfileDev,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/#usability-notes","title":"Usability notes","text":"<ul> <li>Profiles keep policy separate from implementation</li> <li>Backends are swappable without changing the executor API</li> <li>Tool calls are mediated via the gateway interface</li> </ul>"},{"location":"library-docs-from-repos/toolruntime/#next","title":"Next","text":"<ul> <li>Runtime pipeline and profiles: <code>architecture.md</code></li> <li>Backend configuration: <code>usage.md</code></li> <li>Examples: <code>examples.md</code></li> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolruntime/api/","title":"API Reference","text":""},{"location":"library-docs-from-repos/toolruntime/api/#runtime","title":"Runtime","text":"<pre><code>type Runtime interface {\n  Execute(ctx context.Context, req ExecuteRequest) (ExecuteResult, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/api/#backend","title":"Backend","text":"<pre><code>type Backend interface {\n  Kind() BackendKind\n  Execute(ctx context.Context, req ExecuteRequest) (ExecuteResult, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/api/#securityprofile","title":"SecurityProfile","text":"<pre><code>type SecurityProfile string\nconst (\n  ProfileDev      SecurityProfile = \"dev\"\n  ProfileStandard SecurityProfile = \"standard\"\n  ProfileHardened SecurityProfile = \"hardened\"\n)\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/api/#executerequest-executeresult","title":"ExecuteRequest / ExecuteResult","text":"<pre><code>type ExecuteRequest struct {\n  Language string\n  Code     string\n  Args     map[string]any\n  Profile  SecurityProfile\n  Gateway  ToolGateway\n  Timeout  time.Duration\n}\n\ntype ExecuteResult struct {\n  Value      any\n  Stdout     string\n  Stderr     string\n  ToolCalls  []ToolCallRecord\n  Duration   time.Duration\n  Backend    BackendInfo\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/api/#toolgateway","title":"ToolGateway","text":"<pre><code>type ToolGateway interface {\n  SearchTools(query string, limit int) ([]toolindex.Summary, error)\n  DescribeTool(id string, level tooldocs.DetailLevel) (tooldocs.ToolDoc, error)\n  RunTool(ctx context.Context, id string, args map[string]any) (toolrun.RunResult, error)\n  RunChain(ctx context.Context, steps []toolrun.ChainStep) (toolrun.RunResult, []toolrun.StepResult, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/api/#runtimeconfig","title":"RuntimeConfig","text":"<pre><code>type RuntimeConfig struct {\n  Backends           map[SecurityProfile]Backend\n  DenyUnsafeProfiles []SecurityProfile\n  DefaultProfile     SecurityProfile\n  Logger             Logger\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/architecture/","title":"Architecture","text":"<p><code>toolruntime</code> is the execution boundary underneath <code>toolcode</code>. It chooses a backend based on the requested security profile.</p>"},{"location":"library-docs-from-repos/toolruntime/architecture/#runtime-selection","title":"Runtime selection","text":""},{"location":"library-docs-from-repos/toolruntime/architecture/#execution-sequence","title":"Execution sequence","text":""},{"location":"library-docs-from-repos/toolruntime/architecture/#profiles","title":"Profiles","text":"<ul> <li><code>dev</code>: convenience, unsafe host allowed</li> <li><code>standard</code>: safer defaults, may deny unsafe backend</li> <li><code>hardened</code>: expected to require strong isolation</li> </ul>"},{"location":"library-docs-from-repos/toolruntime/design-notes/","title":"Design Notes","text":"<p>This page documents the tradeoffs and error semantics behind <code>toolruntime</code>.</p>"},{"location":"library-docs-from-repos/toolruntime/design-notes/#design-tradeoffs","title":"Design tradeoffs","text":"<ul> <li>Runtime as router. <code>toolruntime</code> does not execute code itself; it routes requests to backends based on a security profile. This keeps policy separate from execution.</li> <li>Explicit security profiles. <code>dev</code>, <code>standard</code>, and <code>hardened</code> provide predictable isolation tiers. This trades flexibility for clarity and safer defaults.</li> <li>Gateway boundary. Executed code never talks to toolindex/tooldocs/toolrun directly. Instead it receives a <code>ToolGateway</code>, which preserves the trust boundary.</li> <li>Backend diversity. Backends represent different isolation levels (host, containers, microVMs, WASM, remote). This lets deployments match security and performance needs.</li> <li>Limits are declarative. <code>Limits</code> are requested by the caller, and backends report which limits were actually enforced.</li> </ul>"},{"location":"library-docs-from-repos/toolruntime/design-notes/#error-semantics","title":"Error semantics","text":"<p><code>toolruntime</code> uses sentinel errors for classification:</p> <ul> <li><code>ErrRuntimeUnavailable</code> \u2013 no backend exists for the requested profile.</li> <li><code>ErrBackendDenied</code> \u2013 policy denies the backend (e.g., unsafe host for hardened profile).</li> <li><code>ErrSandboxViolation</code> \u2013 sandbox policy was violated.</li> <li><code>ErrTimeout</code> \u2013 execution exceeded timeout.</li> <li><code>ErrResourceLimit</code> \u2013 resource limits exceeded.</li> <li><code>ErrMissingGateway</code> / <code>ErrMissingCode</code> \u2013 invalid <code>ExecuteRequest</code>.</li> <li><code>ErrInvalidLimits</code> \u2013 limits validation failed.</li> </ul> <p><code>RuntimeError</code> wraps backend failures with <code>BackendKind</code>, <code>Op</code>, and <code>Retryable</code>.</p>"},{"location":"library-docs-from-repos/toolruntime/design-notes/#extension-points","title":"Extension points","text":"<ul> <li>Custom backends: implement <code>Backend</code> to integrate Docker, containerd, Kubernetes, gVisor, WASM, or a remote execution service.</li> <li>Custom gateways: use <code>gateway/direct</code> for in-process execution or <code>gateway/proxy</code> for RPC-mediated execution.</li> <li>Toolcode integration: <code>toolcodeengine</code> adapts <code>toolruntime</code> into a <code>toolcode.Engine</code>.</li> </ul>"},{"location":"library-docs-from-repos/toolruntime/design-notes/#operational-guidance","title":"Operational guidance","text":"<ul> <li>Use <code>ProfileStandard</code> by default; reserve <code>ProfileDev</code> for trusted environments.</li> <li>Enforce <code>DenyUnsafeProfiles</code> to prevent accidental unsafe execution.</li> <li>Report <code>LimitsEnforced</code> accurately so callers can detect degraded enforcement.</li> </ul>"},{"location":"library-docs-from-repos/toolruntime/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/toolruntime/examples/#toolcode-integration","title":"Toolcode integration","text":"<pre><code>engine, err := toolcodeengine.New(toolcodeengine.Config{\n  Runtime: rt,\n  Profile: toolruntime.ProfileDev,\n})\nif err != nil {\n  return err\n}\n\nexec, _ := toolcode.NewDefaultExecutor(toolcode.Config{\n  Index:  idx,\n  Docs:   docs,\n  Run:    runner,\n  Engine: engine,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/examples/#inspect-tool-calls","title":"Inspect tool calls","text":"<pre><code>res, _ := rt.Execute(ctx, toolruntime.ExecuteRequest{\n  Language: \"go\",\n  Code:     \"__out = 1\",\n  Profile:  toolruntime.ProfileDev,\n  Gateway:  gw,\n})\n\nfor _, call := range res.ToolCalls {\n  fmt.Println(call.ToolID, call.Duration)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/toolruntime/usage/#create-a-runtime","title":"Create a runtime","text":"<pre><code>rt := toolruntime.NewDefaultRuntime(toolruntime.RuntimeConfig{\n  Backends: map[toolruntime.SecurityProfile]toolruntime.Backend{\n    toolruntime.ProfileDev: unsafe.New(unsafe.Config{Mode: unsafe.ModeSubprocess}),\n  },\n  DefaultProfile: toolruntime.ProfileDev,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/usage/#execute-code","title":"Execute code","text":"<pre><code>res, err := rt.Execute(ctx, toolruntime.ExecuteRequest{\n  Language: \"go\",\n  Code:     \"__out = 2 + 2\",\n  Profile:  toolruntime.ProfileDev,\n  Gateway:  gw,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/usage/#deny-unsafe-backend","title":"Deny unsafe backend","text":"<pre><code>rt := toolruntime.NewDefaultRuntime(toolruntime.RuntimeConfig{\n  Backends: map[toolruntime.SecurityProfile]toolruntime.Backend{\n    toolruntime.ProfileDev: unsafe.New(unsafe.Config{Mode: unsafe.ModeSubprocess}),\n  },\n  DenyUnsafeProfiles: []toolruntime.SecurityProfile{toolruntime.ProfileStandard},\n  DefaultProfile:     toolruntime.ProfileStandard,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/user-journey/","title":"User Journey","text":"<p>This journey shows how <code>toolruntime</code> powers secure code execution in the broader stack.</p>"},{"location":"library-docs-from-repos/toolruntime/user-journey/#end-to-end-flow-stack-view","title":"End-to-end flow (stack view)","text":""},{"location":"library-docs-from-repos/toolruntime/user-journey/#step-by-step","title":"Step-by-step","text":"<ol> <li>Configure runtime with backends keyed by security profile.</li> <li>Wrap tool access using a <code>ToolGateway</code> (direct or proxy).</li> <li>Execute request is routed to the backend based on profile.</li> <li>Backend runs code with controlled access to tools via the gateway.</li> <li>Result and tool calls are returned, with <code>LimitsEnforced</code> indicating actual enforcement.</li> </ol>"},{"location":"library-docs-from-repos/toolruntime/user-journey/#example-wire-runtime-to-toolcode","title":"Example: wire runtime to toolcode","text":"<pre><code>rt := toolruntime.NewDefaultRuntime(toolruntime.RuntimeConfig{\n  Backends: map[toolruntime.SecurityProfile]toolruntime.Backend{\n    toolruntime.ProfileStandard: mySandboxBackend,\n  },\n  DefaultProfile: toolruntime.ProfileStandard,\n})\n\nengine, err := toolcodeengine.New(toolcodeengine.Config{\n  Runtime: rt,\n  Profile: toolruntime.ProfileStandard,\n})\nif err != nil {\n  return err\n}\n\nexec, _ := toolcode.NewDefaultExecutor(toolcode.Config{\n  Index: idx,\n  Docs:  docs,\n  Run:   runner,\n  Engine: engine,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolruntime/user-journey/#expected-outcomes","title":"Expected outcomes","text":"<ul> <li>Clear security posture by profile.</li> <li>Consistent tool access via a gateway boundary.</li> <li>Transparent limit enforcement reporting.</li> </ul>"},{"location":"library-docs-from-repos/toolruntime/user-journey/#common-failure-modes","title":"Common failure modes","text":"<ul> <li><code>ErrRuntimeUnavailable</code> if no backend is registered for the profile.</li> <li><code>ErrBackendDenied</code> when policy blocks unsafe backends.</li> <li><code>ErrTimeout</code> / <code>ErrResourceLimit</code> on enforced limits.</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/","title":"toolsearch","text":"<p><code>toolsearch</code> provides higher-quality search strategies for <code>toolindex</code> while keeping heavy dependencies out of the core registry. Today it ships a BM25 searcher backed by Bleve.</p> <p></p>"},{"location":"library-docs-from-repos/toolsearch/#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolsearch/#motivation","title":"Motivation","text":"<ul> <li>Keep toolindex small while enabling stronger ranking</li> <li>Experiment safely with search without changing core behavior</li> <li>Deterministic results for stable agent behavior</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/#key-apis","title":"Key APIs","text":"<ul> <li><code>BM25Searcher</code> (implements <code>toolindex.Searcher</code>)</li> <li><code>BM25Config</code> for ranking and safety caps</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/#quickstart","title":"Quickstart","text":"<pre><code>searcher := toolsearch.NewBM25Searcher(toolsearch.BM25Config{})\nidx := toolindex.NewInMemoryIndex(toolindex.IndexOptions{Searcher: searcher})\n</code></pre>"},{"location":"library-docs-from-repos/toolsearch/#usability-notes","title":"Usability notes","text":"<ul> <li>Deterministic ordering avoids jitter in tool selection</li> <li>Index fingerprinting avoids rebuilds on no-op updates</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/#next","title":"Next","text":"<ul> <li>Ranking pipeline: <code>architecture.md</code></li> <li>Configuration and caps: <code>usage.md</code></li> <li>Examples: <code>examples.md</code></li> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/toolsearch/api/","title":"API Reference","text":""},{"location":"library-docs-from-repos/toolsearch/api/#bm25config","title":"BM25Config","text":"<pre><code>type BM25Config struct {\n  NameBoost      int\n  NamespaceBoost int\n  TagsBoost      int\n  MaxDocs        int\n  MaxDocTextLen  int\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolsearch/api/#bm25searcher","title":"BM25Searcher","text":"<pre><code>type BM25Searcher struct {}\n\nfunc NewBM25Searcher(cfg BM25Config) *BM25Searcher\n\n// implements toolindex.Searcher\nfunc (s *BM25Searcher) Search(query string, limit int, docs []toolindex.SearchDoc) ([]toolindex.Summary, error)\n</code></pre>"},{"location":"library-docs-from-repos/toolsearch/architecture/","title":"Architecture","text":"<p><code>toolsearch</code> is a pluggable search strategy for <code>toolindex</code>.</p>"},{"location":"library-docs-from-repos/toolsearch/architecture/#indexing-flow","title":"Indexing flow","text":""},{"location":"library-docs-from-repos/toolsearch/architecture/#search-sequence","title":"Search sequence","text":""},{"location":"library-docs-from-repos/toolsearch/architecture/#determinism","title":"Determinism","text":"<ul> <li>Docs are sorted by ID before indexing</li> <li>Tie-breaking uses score DESC, then ID ASC</li> <li>Fingerprints ensure stable caching</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/design-notes/","title":"Design Notes","text":"<p>This page documents the tradeoffs and error semantics behind <code>toolsearch</code>.</p>"},{"location":"library-docs-from-repos/toolsearch/design-notes/#design-tradeoffs","title":"Design tradeoffs","text":"<ul> <li>BM25 via Bleve. <code>toolsearch</code> uses Bleve's BM25 implementation for a strong lexical baseline without bringing in a full search stack.</li> <li>Field weighting by duplication. Instead of multi-field indexing, the searcher builds a single weighted document by duplicating name/namespace/tag tokens. This keeps the index schema simple and predictable.</li> <li>Deterministic ordering. Documents are sorted by tool ID before indexing. Ties are broken by tool ID to avoid nondeterministic results.</li> <li>In-memory index. Uses Bleve's in-memory index for speed and simplicity; this trades persistence for low overhead.</li> <li>Fingerprint-based rebuild. Index rebuilds only when the tool set changes (based on a fingerprint), reducing overhead for repeated searches.</li> <li>Safe query parsing. Uses a plain <code>MatchQuery</code> (no operator syntax) to prevent query syntax injection.</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/design-notes/#error-semantics","title":"Error semantics","text":"<ul> <li>BM25 search returns standard <code>error</code> values from Bleve.</li> <li><code>Search</code> returns empty slices on empty queries or no docs; it does not treat these as errors.</li> <li><code>Close</code> frees index resources; callers should treat errors from <code>Close</code> as operational warnings.</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/design-notes/#extension-points","title":"Extension points","text":"<ul> <li>Custom weights: configure <code>NameBoost</code>, <code>NamespaceBoost</code>, and <code>TagsBoost</code>.</li> <li>Safety caps: limit search surface with <code>MaxDocs</code> or <code>MaxDocTextLen</code>.</li> <li>Alternative engines: implement <code>toolindex.Searcher</code> to swap BM25 out for semantic search later.</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/design-notes/#operational-guidance","title":"Operational guidance","text":"<ul> <li>Start with BM25 if lexical search quality matters; switch to semantic only if needed.</li> <li>Keep <code>MaxDocTextLen</code> modest to avoid oversized indices from long descriptions.</li> <li>Use deterministic doc ordering to keep search results stable across deploys.</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/toolsearch/examples/#deterministic-ranking","title":"Deterministic ranking","text":"<pre><code>searcher := toolsearch.NewBM25Searcher(toolsearch.BM25Config{})\nidx := toolindex.NewInMemoryIndex(toolindex.IndexOptions{Searcher: searcher})\n\nresults, _ := idx.Search(\"repo\", 10)\n// results are deterministic across runs\n</code></pre>"},{"location":"library-docs-from-repos/toolsearch/examples/#custom-boosts","title":"Custom boosts","text":"<pre><code>searcher := toolsearch.NewBM25Searcher(toolsearch.BM25Config{\n  NameBoost:      5,\n  NamespaceBoost: 3,\n  TagsBoost:      1,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolsearch/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/toolsearch/usage/#configure-bm25","title":"Configure BM25","text":"<pre><code>searcher := toolsearch.NewBM25Searcher(toolsearch.BM25Config{\n  NameBoost:      3,\n  NamespaceBoost: 2,\n  TagsBoost:      2,\n  MaxDocs:        5000,\n  MaxDocTextLen:  2000,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolsearch/usage/#inject-into-toolindex","title":"Inject into toolindex","text":"<pre><code>idx := toolindex.NewInMemoryIndex(toolindex.IndexOptions{Searcher: searcher})\n</code></pre>"},{"location":"library-docs-from-repos/toolsearch/usage/#safety-controls","title":"Safety controls","text":"<ul> <li><code>MaxDocs</code>: cap indexed documents</li> <li><code>MaxDocTextLen</code>: truncate long descriptions</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/user-journey/","title":"User Journey","text":"<p>This journey shows how <code>toolsearch</code> slots into the end-to-end workflow as a pluggable search engine.</p>"},{"location":"library-docs-from-repos/toolsearch/user-journey/#end-to-end-flow-stack-view","title":"End-to-end flow (stack view)","text":""},{"location":"library-docs-from-repos/toolsearch/user-journey/#step-by-step","title":"Step-by-step","text":"<ol> <li>Enable BM25 in <code>metatools-mcp</code> using the <code>toolsearch</code> build tag.</li> <li>Set env vars (e.g., <code>METATOOLS_SEARCH_STRATEGY=bm25</code>).</li> <li>Search requests now flow through the BM25 searcher.</li> </ol>"},{"location":"library-docs-from-repos/toolsearch/user-journey/#example-configure-bm25-via-env","title":"Example: configure BM25 via env","text":"<pre><code># build with toolsearch support\nGOFLAGS=\"-tags=toolsearch\" go build ./cmd/metatools\n\n# choose BM25 strategy at runtime\nexport METATOOLS_SEARCH_STRATEGY=bm25\nexport METATOOLS_SEARCH_BM25_NAME_BOOST=4\nexport METATOOLS_SEARCH_BM25_TAGS_BOOST=2\n</code></pre>"},{"location":"library-docs-from-repos/toolsearch/user-journey/#expected-outcomes","title":"Expected outcomes","text":"<ul> <li>Higher-quality lexical ranking for tool discovery.</li> <li>Deterministic ordering and tie-breaking.</li> <li>No API changes required in <code>toolindex</code> or <code>metatools-mcp</code>.</li> </ul>"},{"location":"library-docs-from-repos/toolsearch/user-journey/#common-failure-modes","title":"Common failure modes","text":"<ul> <li>Build without the <code>toolsearch</code> tag and request <code>bm25</code> strategy (fails fast).</li> <li>Oversized tool descriptions if <code>MaxDocTextLen</code> is not capped.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/","title":"metatools-mcp","text":"<p><code>metatools-mcp</code> is the MCP server that exposes the tool stack via a small, progressive-disclosure tool surface. It composes toolmodel, toolindex, tooldocs, toolrun, and optionally toolcode/toolruntime.</p> <p></p>"},{"location":"library-docs-from-repos/metatools-mcp/#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#motivation","title":"Motivation","text":"<ul> <li>One MCP surface for discovery, docs, and execution</li> <li>Progressive disclosure to keep tool context small</li> <li>Pluggable design for search, runtimes, and engines</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#mcp-tools-exposed","title":"MCP tools exposed","text":"<ul> <li><code>search_tools</code></li> <li><code>list_namespaces</code></li> <li><code>describe_tool</code></li> <li><code>list_tool_examples</code></li> <li><code>run_tool</code></li> <li><code>run_chain</code></li> <li><code>execute_code</code> (optional)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#quickstart","title":"Quickstart","text":"<pre><code>idx := toolindex.NewInMemoryIndex()\ndocs := tooldocs.NewInMemoryStore(tooldocs.StoreOptions{Index: idx})\nrunner := toolrun.NewRunner(toolrun.WithIndex(idx))\n\ncfg := adapters.NewConfig(idx, docs, runner, nil)\nserver, _ := server.New(cfg)\n\n_ = server.Run(context.Background(), &amp;mcp.StdioTransport{})\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/#usability-notes","title":"Usability notes","text":"<ul> <li>Fewer MCP tools means simpler agent prompts</li> <li>Outputs are structured and aligned to MCP schemas</li> <li>Search and execution behaviors are deterministic by default</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#next","title":"Next","text":"<ul> <li>Server architecture: <code>architecture.md</code></li> <li>Ordered execution plan: <code>plan-of-record.md</code></li> <li>Configuration and env vars: <code>usage.md</code></li> <li>Examples: <code>examples.md</code></li> <li>Design Notes: <code>design-notes.md</code></li> <li>User Journey: <code>user-journey.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#proposals","title":"Proposals","text":"<p>Master Plan: - ROADMAP - Master roadmap with all work streams, phases, and milestones</p> <p>Architecture: - Pluggable Architecture - Extensible, modular design - Architecture Evaluation - Championship-level comparison - Component Library Analysis - Tool* library ecosystem - Architecture Review - Comprehensive proposal analysis and consistency check - MCP Spec Alignment - Targeted spec compliance improvements</p> <p>Features: - Protocol-Agnostic Tools - Composable toolsets and protocol adapters - Multi-Tenancy Extension - Tenant isolation patterns - Agent Skills - Higher-level capability composition (see ROADMAP)</p> <p>Implementation: - Implementation Phases - Phased rollout plan</p>"},{"location":"library-docs-from-repos/metatools-mcp/api/","title":"API Reference","text":""},{"location":"library-docs-from-repos/metatools-mcp/api/#server","title":"Server","text":"<pre><code>func New(cfg config.Config) (*Server, error)\nfunc (s *Server) Run(ctx context.Context, transport mcp.Transport) error\nfunc (s *Server) MCPServer() *mcp.Server\nfunc (s *Server) ListTools() []*mcp.Tool\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/api/#config","title":"Config","text":"<pre><code>type Config struct {\n  Index    toolindex.Index\n  Docs     tooldocs.Store\n  Runner   toolrun.Runner\n  Executor toolcode.Executor // optional\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/api/#mcp-tool-io-types","title":"MCP tool I/O types","text":"<p>These are exported in <code>pkg/metatools</code>:</p> <ul> <li><code>SearchToolsInput</code> / <code>SearchToolsOutput</code></li> <li><code>ListNamespacesInput</code> / <code>ListNamespacesOutput</code></li> <li><code>DescribeToolInput</code> / <code>DescribeToolOutput</code></li> <li><code>ListToolExamplesInput</code> / <code>ListToolExamplesOutput</code></li> <li><code>RunToolInput</code> / <code>RunToolOutput</code></li> <li><code>RunChainInput</code> / <code>RunChainOutput</code></li> <li><code>ExecuteCodeInput</code> / <code>ExecuteCodeOutput</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/api/#error-codes","title":"Error codes","text":"<p>Metatools surfaces standardized error codes (strings), including:</p> <ul> <li><code>tool_not_found</code></li> <li><code>no_backends</code></li> <li><code>validation_input</code></li> <li><code>validation_output</code></li> <li><code>execution_failed</code></li> <li><code>stream_not_supported</code></li> <li><code>chain_step_failed</code></li> <li><code>internal</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/architecture/","title":"Architecture","text":"<p><code>metatools-mcp</code> composes the core libraries and exposes a small MCP tool surface.</p>"},{"location":"library-docs-from-repos/metatools-mcp/architecture/#component-wiring","title":"Component wiring","text":""},{"location":"library-docs-from-repos/metatools-mcp/architecture/#progressive-disclosure-flow","title":"Progressive disclosure flow","text":""},{"location":"library-docs-from-repos/metatools-mcp/architecture/#mcp-tool-mapping","title":"MCP tool mapping","text":""},{"location":"library-docs-from-repos/metatools-mcp/design-notes/","title":"Design Notes","text":"<p>This page documents the tradeoffs and error semantics behind <code>metatools-mcp</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#design-tradeoffs","title":"Design tradeoffs","text":"<ul> <li>MCP-native surface. All metatools (search, describe, run, chain, execute_code) are exposed via the official MCP Go SDK types to keep wire compatibility.</li> <li>Adapters, not re-implementation. The server delegates to toolindex/tooldocs/toolrun/toolcode via thin adapters so the libraries remain the source of truth.</li> <li>Structured error objects. Tool-level errors are returned in a consistent <code>ErrorObject</code> shape rather than raw Go errors, preserving the MCP tool contract.</li> <li>Explicit limits. Inputs such as <code>limit</code> and <code>max</code> are capped for safe defaults (e.g., search limit cap 100, examples cap 5).</li> <li>Pluggable search. BM25 is optional via build tags (<code>toolsearch</code>) and runtime config via env vars.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#error-semantics","title":"Error semantics","text":"<p><code>metatools-mcp</code> distinguishes protocol errors from tool errors:</p> <ul> <li>Protocol errors (invalid input) return a non-nil error from handlers.</li> <li>Tool errors are wrapped into <code>ErrorObject</code> and returned with <code>isError = true</code> so MCP clients treat them as tool failures.</li> </ul> <p>Key error behaviors:</p> <ul> <li><code>run_tool</code> rejects <code>stream=true</code> and <code>backend_override</code> in the default handler (not supported yet).</li> <li><code>run_chain</code> stops on first error and returns partial results with an <code>ErrorObject</code>.</li> <li><code>describe_tool</code>/<code>list_tool_examples</code> return validation errors when required fields are missing.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#extension-points","title":"Extension points","text":"<ul> <li>Search strategy: enable BM25 via the <code>toolsearch</code> build tag and env vars.</li> <li>Tool execution: swap <code>toolrun</code> runner implementation or configure different backends.</li> <li>Code execution: plug in a different <code>toolcode.Engine</code> (e.g., toolruntime-backed).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#operational-guidance","title":"Operational guidance","text":"<ul> <li>Use environment variables to configure search strategy:</li> <li><code>METATOOLS_SEARCH_STRATEGY=lexical|bm25</code></li> <li><code>METATOOLS_SEARCH_BM25_*</code> for weighting and caps</li> <li>Keep tool schemas in <code>toolmodel</code> to preserve MCP compatibility end-to-end.</li> <li>Treat metatools as the stable surface; update libraries behind it as needed.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/metatools-mcp/examples/#register-a-local-tool-expose-mcp-server","title":"Register a local tool + expose MCP server","text":"<pre><code>idx := toolindex.NewInMemoryIndex()\n\nlocal := toolrun.NewLocalRegistry()\nlocal.Register(\"ping\", func(ctx context.Context, args map[string]any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n\n_ = idx.RegisterTool(toolmodel.Tool{\n  Namespace: \"local\",\n  Tool: mcp.Tool{\n    Name:        \"ping\",\n    Description: \"Simple health check\",\n    InputSchema: map[string]any{\"type\": \"object\"},\n  },\n}, toolmodel.ToolBackend{\n  Kind:  toolmodel.BackendKindLocal,\n  Local: &amp;toolmodel.LocalBackend{Name: \"ping\"},\n})\n\nrunner := toolrun.NewRunner(toolrun.WithIndex(idx), toolrun.WithLocalRegistry(local))\n\ncfg := adapters.NewConfig(idx, tooldocs.NewInMemoryStore(tooldocs.StoreOptions{Index: idx}), runner, nil)\nserver, _ := server.New(cfg)\n_ = server.Run(context.Background(), &amp;mcp.StdioTransport{})\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/examples/#tool-search-and-execution","title":"Tool search and execution","text":"<pre><code>summaries, _ := idx.Search(\"ping\", 3)\n\nres, _ := runner.Run(ctx, summaries[0].ID, map[string]any{})\nfmt.Println(res.Structured)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/","title":"Plan of Record (Ordered Execution)","text":"<p>This page consolidates all proposals and PRDs into a single, ordered execution sequence. It is intentionally Go\u2011architecture focused: concurrency safety, context propagation, and production operational boundaries are explicit in each phase.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#principles-go-architect-evaluation","title":"Principles (Go Architect Evaluation)","text":"<ul> <li>Context propagation is a contract: every long\u2011running or remote execution path must honor <code>context.Context</code> for cancellation and timeouts.</li> <li>Concurrency safety by default: all registries and caches must be thread\u2011safe under concurrent reads/writes.</li> <li>Errors are data: tool errors should be structured and preserved end\u2011to\u2011end rather than surfaced as raw panics.</li> <li>Stable seams first: prioritize interfaces, wiring, and deterministic behaviors before adding new feature surface.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#current-baseline-already-in-place","title":"Current Baseline (already in place)","text":"<p>These libraries and contracts are the foundation and must remain stable:</p> <ul> <li><code>toolmodel</code> \u2013 core types and MCP schema compatibility</li> <li><code>toolindex</code> \u2013 registry + discovery</li> <li><code>tooldocs</code> \u2013 progressive disclosure docs/examples</li> <li><code>toolrun</code> \u2013 execution and chaining</li> <li><code>toolcode</code> \u2013 code orchestration (optional)</li> <li><code>toolruntime</code> \u2013 sandbox/runtime isolation (optional)</li> <li><code>toolsearch</code> \u2013 BM25 search implementation (optional)</li> </ul> <p>See the master roadmap for the current version matrix: ROADMAP</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-0-spec-alignment-server-correctness-p1","title":"Phase 0 \u2014 Spec Alignment &amp; Server Correctness (P1)","text":"<p>Goal: Ensure the MCP server edge is protocol\u2011correct before expanding capability.</p> <ol> <li>MCP spec alignment (PRD\u2011015)</li> <li><code>notifications/tools/list_changed</code></li> <li>pagination/cursor consistency</li> <li>cancellation propagation</li> <li>optional progress forwarding</li> </ol> <p>Docs: - Proposal: MCP Spec Alignment - PRD: PRD\u2011015</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-1-core-exposure-mvp-foundation","title":"Phase 1 \u2014 Core Exposure (MVP Foundation)","text":"<p>Goal: Provide CLI, configuration, transport, and provider/backends for production use.</p> <ol> <li>CLI foundation (PRD\u2011002)</li> <li>Configuration layer (PRD\u2011003)</li> <li>Transport layer (PRD\u2011004)</li> <li>Tool provider registry (PRD\u2011005)</li> <li>Backend registry (PRD\u2011006)</li> <li>Middleware chain (PRD\u2011007)</li> </ol> <p>Docs: - PRDs: PRD\u2011002, PRD\u2011003,   PRD\u2011004, PRD\u2011005,   PRD\u2011006, PRD\u2011007</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-2-protocol-layer","title":"Phase 2 \u2014 Protocol Layer","text":"<p>Goal: Normalize tools into composable, protocol\u2011agnostic sets without changing core semantics.</p> <ol> <li>tooladapter (PRD\u2011008)</li> <li>toolset (PRD\u2011009)</li> </ol> <p>Docs: - PRD\u2011008 - PRD\u2011009</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-3-crosscutting-observability-caching","title":"Phase 3 \u2014 Cross\u2011Cutting Observability &amp; Caching","text":"<p>Goal: Make the system operationally measurable and resilient.</p> <ol> <li>toolobserve (PRD\u2011010)</li> <li>toolcache (PRD\u2011011)</li> </ol> <p>Docs: - PRD\u2011010 - PRD\u2011011</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-4-enterprise-extensions","title":"Phase 4 \u2014 Enterprise Extensions","text":"<p>Goal: Enable scale, isolation, and advanced discovery without destabilizing core APIs.</p> <ol> <li>Multi\u2011tenancy core (PRD\u2011012)</li> <li>toolsemantic (PRD\u2011013)</li> </ol> <p>Docs: - PRD\u2011012 - PRD\u2011013</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-5-agent-skills","title":"Phase 5 \u2014 Agent Skills","text":"<p>Goal: Higher\u2011level capability composition for reusable workflows.</p> <ol> <li>toolskill (PRD\u2011014)</li> </ol> <p>Docs: - PRD\u2011014</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-6-runtime-expansion","title":"Phase 6 \u2014 Runtime Expansion","text":"<p>Goal: Expand sandbox options and isolation strategies.</p> <ol> <li>toolruntime Docker backend (PRD\u2011001)</li> </ol> <p>Docs: - PRD\u2011001</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#go-architecture-review-summary","title":"Go Architecture Review (Summary)","text":"<ul> <li>Context propagation: enforce in all public execution APIs; cancellation must be honored by toolrun/toolruntime to avoid leaked goroutines.</li> <li>Concurrency safety: all registries must be RW\u2011safe; avoid maps without guards under write paths.</li> <li>Pagination correctness: use stable cursors and cap limits across list endpoints.</li> <li>Error semantics: preserve tool errors as structured data; avoid panics in runtime paths.</li> <li>Observability: add tracing hooks before multi\u2011tenant and semantic layers to avoid blind spots.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#reference-docs","title":"Reference Docs","text":"<ul> <li>ROADMAP</li> <li>Pluggable Architecture</li> <li>Implementation Phases</li> <li>Architecture Evaluation</li> <li>Protocol\u2011Agnostic Tools</li> <li>Multi\u2011Tenancy</li> <li>Architecture Review</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/metatools-mcp/usage/#build-and-run-stdio","title":"Build and run (stdio)","text":"<pre><code>go run ./cmd/metatools\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#enable-bm25-search-build-tag-env","title":"Enable BM25 search (build tag + env)","text":"<pre><code>go build -tags toolsearch ./cmd/metatools\nMETATOOLS_SEARCH_STRATEGY=bm25 ./metatools\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#environment-variables","title":"Environment variables","text":"Variable Default Description <code>METATOOLS_SEARCH_STRATEGY</code> <code>lexical</code> <code>lexical</code> or <code>bm25</code> <code>METATOOLS_SEARCH_BM25_NAME_BOOST</code> <code>3</code> BM25 name field boost <code>METATOOLS_SEARCH_BM25_NAMESPACE_BOOST</code> <code>2</code> BM25 namespace field boost <code>METATOOLS_SEARCH_BM25_TAGS_BOOST</code> <code>2</code> BM25 tags field boost <code>METATOOLS_SEARCH_BM25_MAX_DOCS</code> <code>0</code> Max docs to index (0=unlimited) <code>METATOOLS_SEARCH_BM25_MAX_DOCTEXT_LEN</code> <code>0</code> Max doc text length (0=unlimited)"},{"location":"library-docs-from-repos/metatools-mcp/usage/#optional-toolruntime-support","title":"Optional toolruntime support","text":"<pre><code>go run -tags toolruntime ./cmd/metatools\n</code></pre> <p>This enables <code>execute_code</code> backed by a <code>toolruntime</code> engine.</p>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/","title":"User Journey","text":"<p>This journey shows the full end-to-end agent workflow via MCP metatools.</p>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#end-to-end-flow-agent-view","title":"End-to-end flow (agent view)","text":""},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#step-by-step","title":"Step-by-step","text":"<ol> <li>Discover tools with <code>search_tools</code> (summary-only results).</li> <li>Inspect schema using <code>describe_tool</code> (schema or full detail).</li> <li>Execute a single tool with <code>run_tool</code> or a sequence with <code>run_chain</code>.</li> <li>Orchestrate complex flows using <code>execute_code</code> (optional).</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#example-full-agent-workflow","title":"Example: full agent workflow","text":"<pre><code>1) search_tools(\"create issue\", limit=5)\n2) describe_tool(\"github:create_issue\", detail_level=\"schema\")\n3) run_tool(\"github:create_issue\", args={...})\n4) run_chain([{tool_id:\"github:get_issue\"}, {tool_id:\"github:add_label\", use_previous:true}])\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#expected-outcomes","title":"Expected outcomes","text":"<ul> <li>Stable MCP-compatible APIs for discovery, documentation, and execution.</li> <li>Consistent error objects for tool failures.</li> <li>Progressive disclosure to minimize token costs.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#common-failure-modes","title":"Common failure modes","text":"<ul> <li>Invalid input payloads (handler validation errors).</li> <li>Tool-level errors returned in <code>ErrorObject</code> with <code>code</code> and <code>op</code> fields.</li> <li>Unsupported options (e.g., <code>stream=true</code> for <code>run_tool</code>).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/","title":"metatools-mcp Implementation Plans","text":"<p>This directory contains Product Requirement Documents (PRDs) for incremental improvements to the metatools-mcp codebase. Each PRD follows TDD methodology with bite-sized tasks.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/#prd-index","title":"PRD Index","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/#stream-a-core-exposure-mvp-foundation","title":"Stream A: Core Exposure (MVP Foundation)","text":"PRD Title Priority Status Dependencies PRD-001 toolruntime Docker Backend P0 Ready None PRD-002 CLI Foundation with Cobra P0 Ready None PRD-003 Configuration Layer with Koanf P0 Ready PRD-002 PRD-004 SSE Transport Layer P1 Ready PRD-002, PRD-003 PRD-005 Tool Provider Registry P0 Ready PRD-002, PRD-003 PRD-006 Backend Registry P1 Ready PRD-002, PRD-003, PRD-005 PRD-007 Middleware Chain P2 Ready PRD-002, PRD-003, PRD-005 PRD-015 MCP Spec Alignment (Tools) P1 Ready PRD-005"},{"location":"library-docs-from-repos/metatools-mcp/plans/#stream-b-protocol-layer","title":"Stream B: Protocol Layer","text":"PRD Title Priority Status Dependencies PRD-008 tooladapter Library P1 Ready toolmodel PRD-009 toolset Composition P1 Ready PRD-008, toolindex"},{"location":"library-docs-from-repos/metatools-mcp/plans/#stream-c-cross-cutting-concerns","title":"Stream C: Cross-Cutting Concerns","text":"PRD Title Priority Status Dependencies PRD-010 toolobserve Library P1 Ready None PRD-011 toolcache Library P2 Ready None"},{"location":"library-docs-from-repos/metatools-mcp/plans/#stream-d-enterprise-features","title":"Stream D: Enterprise Features","text":"PRD Title Priority Status Dependencies PRD-012 Multi-tenancy Core P2 Ready PRD-005, PRD-007 PRD-013 toolsemantic Library P2 Ready toolindex, toolsearch"},{"location":"library-docs-from-repos/metatools-mcp/plans/#stream-e-agent-skills","title":"Stream E: Agent Skills","text":"PRD Title Priority Status Dependencies PRD-014 toolskill Library P3 Ready PRD-009, toolrun, PRD-010 (opt)"},{"location":"library-docs-from-repos/metatools-mcp/plans/#execution-guidelines","title":"Execution Guidelines","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/#for-claude-use-superpowersexecuting-plans","title":"For Claude: Use superpowers:executing-plans","text":"<p>When implementing any PRD: 1. Read the PRD completely 2. Execute tasks sequentially 3. Run tests after each step 4. Commit after each task</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/#task-structure","title":"Task Structure","text":"<p>Each task follows this pattern: 1. Write failing test - TDD red phase 2. Run test to verify it fails - Confirm test setup 3. Implement minimal code - TDD green phase 4. Run test to verify it passes - Confirm implementation 5. Commit - Atomic commits per task</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/#verification","title":"Verification","text":"<p>Before marking a PRD complete: - [ ] All tests pass - [ ] Code coverage &gt; 80% - [ ] Documentation updated - [ ] No breaking changes (unless noted)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/#architecture-alignment","title":"Architecture Alignment","text":"<p>These PRDs implement the pluggable architecture defined in: - ROADMAP.md - Master plan - pluggable-architecture.md - Architecture spec - implementation-phases.md - Phase timeline</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/#work-streams","title":"Work Streams","text":"Stream Focus PRDs Timeline A Core Exposure 001-007 Weeks 1-8 B Protocol Layer 008-009 Weeks 5-10 C Cross-Cutting 010-011 Weeks 3-18 D Enterprise 012-013 Weeks 8-17 E Agent Skills 014 Weeks 17-21"},{"location":"library-docs-from-repos/metatools-mcp/plans/#principles","title":"Principles","text":"<ol> <li>Incremental - Each PRD delivers a workable outcome</li> <li>TDD - Tests before implementation</li> <li>DRY/YAGNI - No unnecessary code</li> <li>Stable - No breaking changes unless essential</li> <li>Pluggable - Maintain extensibility</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/","title":"PRD-001: toolruntime Docker Backend Implementation","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement a production-ready Docker isolation backend for toolruntime, replacing the current stub implementation.</p> <p>Architecture: The Docker backend will use the official Docker SDK for Go to create ephemeral containers with resource limits, network isolation, and filesystem sandboxing. It integrates with the existing Backend interface and SecurityProfile system.</p> <p>Tech Stack: Docker SDK (github.com/docker/docker), Go 1.21+, existing toolruntime interfaces</p> <p>Priority: P0 - Critical (9 of 10 backends are stubs; Docker is the most practical production backend)</p> <p>Scope: Single backend implementation with full test coverage</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#context","title":"Context","text":"<p>The toolruntime library defines 10 isolation backends but only UnsafeHost is implemented. The Docker backend stub at <code>backend/docker/docker.go</code> returns <code>ErrBackendUnavailable</code>. This PRD implements a production-ready Docker backend.</p> <p>Current State: <pre><code>// backend/docker/docker.go (current stub)\nfunc (b *Backend) Execute(ctx context.Context, req gateway.Request) (gateway.Response, error) {\n    return gateway.Response{}, gateway.ErrBackendUnavailable\n}\n</code></pre></p> <p>Target State: Full Docker isolation with: - Container lifecycle management - Resource limits (CPU, memory, disk) - Network isolation modes - Filesystem sandboxing - Timeout enforcement - Output capture (stdout/stderr)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#task-1-add-docker-sdk-dependency","title":"Task 1: Add Docker SDK Dependency","text":"<p>Files: - Modify: <code>go.mod</code> - Modify: <code>go.sum</code></p> <p>Step 1: Add Docker SDK to go.mod</p> <p>Run: <pre><code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go get github.com/docker/docker@v24.0.7\n</code></pre></p> <p>Step 2: Verify import works</p> <p>Run: <pre><code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go build ./...\n</code></pre> Expected: Build succeeds</p> <p>Step 3: Commit</p> <pre><code>git add go.mod go.sum\ngit commit -m \"$(cat &lt;&lt;'EOF'\ndeps: add Docker SDK for container backend\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#task-2-define-docker-backend-configuration","title":"Task 2: Define Docker Backend Configuration","text":"<p>Files: - Modify: <code>backend/docker/docker.go</code> - Test: <code>backend/docker/docker_test.go</code></p> <p>Step 1: Write failing test for Config validation</p> <pre><code>// backend/docker/docker_test.go\npackage docker\n\nimport (\n    \"testing\"\n)\n\nfunc TestConfig_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        config  Config\n        wantErr bool\n    }{\n        {\n            name:    \"empty config uses defaults\",\n            config:  Config{},\n            wantErr: false,\n        },\n        {\n            name:    \"explicit valid config\",\n            config:  Config{Image: \"python:3.11-slim\", Timeout: 30},\n            wantErr: false,\n        },\n        {\n            name:    \"negative timeout invalid\",\n            config:  Config{Timeout: -1},\n            wantErr: true,\n        },\n        {\n            name:    \"zero memory limit uses default\",\n            config:  Config{MemoryLimitMB: 0},\n            wantErr: false,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            err := tt.config.Validate()\n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Config.Validate() error = %v, wantErr %v\", err, tt.wantErr)\n            }\n        })\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go test ./backend/docker/... -run TestConfig_Validate -v</code> Expected: FAIL - Config type doesn't have Validate method</p> <p>Step 3: Implement Config struct with validation</p> <pre><code>// backend/docker/docker.go\npackage docker\n\nimport (\n    \"errors\"\n    \"time\"\n)\n\n// Config holds Docker backend configuration.\ntype Config struct {\n    // Image is the Docker image to use (default: \"python:3.11-slim\")\n    Image string\n\n    // Timeout in seconds for execution (default: 30)\n    Timeout int\n\n    // MemoryLimitMB is the memory limit in MB (default: 256)\n    MemoryLimitMB int64\n\n    // CPUShares is the relative CPU weight (default: 512)\n    CPUShares int64\n\n    // NetworkMode: \"none\", \"bridge\", \"host\" (default: \"none\")\n    NetworkMode string\n\n    // WorkDir inside container (default: \"/workspace\")\n    WorkDir string\n}\n\n// DefaultConfig returns sensible defaults for Docker execution.\nfunc DefaultConfig() Config {\n    return Config{\n        Image:         \"python:3.11-slim\",\n        Timeout:       30,\n        MemoryLimitMB: 256,\n        CPUShares:     512,\n        NetworkMode:   \"none\",\n        WorkDir:       \"/workspace\",\n    }\n}\n\n// Validate checks config values are sensible.\nfunc (c *Config) Validate() error {\n    if c.Timeout &lt; 0 {\n        return errors.New(\"timeout cannot be negative\")\n    }\n    if c.MemoryLimitMB &lt; 0 {\n        return errors.New(\"memory limit cannot be negative\")\n    }\n    return nil\n}\n\n// withDefaults fills zero values with defaults.\nfunc (c Config) withDefaults() Config {\n    defaults := DefaultConfig()\n    if c.Image == \"\" {\n        c.Image = defaults.Image\n    }\n    if c.Timeout == 0 {\n        c.Timeout = defaults.Timeout\n    }\n    if c.MemoryLimitMB == 0 {\n        c.MemoryLimitMB = defaults.MemoryLimitMB\n    }\n    if c.CPUShares == 0 {\n        c.CPUShares = defaults.CPUShares\n    }\n    if c.NetworkMode == \"\" {\n        c.NetworkMode = defaults.NetworkMode\n    }\n    if c.WorkDir == \"\" {\n        c.WorkDir = defaults.WorkDir\n    }\n    return c\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go test ./backend/docker/... -run TestConfig_Validate -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add backend/docker/docker.go backend/docker/docker_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(docker): add Config struct with validation and defaults\n\n- Define Config with Image, Timeout, MemoryLimitMB, CPUShares, NetworkMode, WorkDir\n- Add DefaultConfig() for sensible production defaults\n- Add Validate() to catch invalid configurations\n- Add withDefaults() to fill zero values\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#task-3-implement-docker-client-initialization","title":"Task 3: Implement Docker Client Initialization","text":"<p>Files: - Modify: <code>backend/docker/docker.go</code> - Test: <code>backend/docker/docker_test.go</code></p> <p>Step 1: Write failing test for Backend initialization</p> <pre><code>func TestNewBackend(t *testing.T) {\n    // Skip if Docker not available\n    if _, err := exec.LookPath(\"docker\"); err != nil {\n        t.Skip(\"Docker not available\")\n    }\n\n    t.Run(\"creates backend with default config\", func(t *testing.T) {\n        b, err := NewBackend(Config{})\n        if err != nil {\n            t.Fatalf(\"NewBackend() error = %v\", err)\n        }\n        if b == nil {\n            t.Fatal(\"NewBackend() returned nil\")\n        }\n        defer b.Close()\n    })\n\n    t.Run(\"creates backend with custom config\", func(t *testing.T) {\n        b, err := NewBackend(Config{\n            Image:         \"alpine:latest\",\n            Timeout:       60,\n            MemoryLimitMB: 512,\n        })\n        if err != nil {\n            t.Fatalf(\"NewBackend() error = %v\", err)\n        }\n        defer b.Close()\n    })\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go test ./backend/docker/... -run TestNewBackend -v</code> Expected: FAIL - NewBackend doesn't exist or returns stub</p> <p>Step 3: Implement NewBackend with Docker client</p> <pre><code>import (\n    \"context\"\n    \"errors\"\n    \"os/exec\"\n    \"time\"\n\n    \"github.com/docker/docker/client\"\n)\n\n// Backend implements gateway.Backend using Docker containers.\ntype Backend struct {\n    client *client.Client\n    config Config\n}\n\n// NewBackend creates a Docker backend with the given configuration.\nfunc NewBackend(cfg Config) (*Backend, error) {\n    if err := cfg.Validate(); err != nil {\n        return nil, err\n    }\n\n    cfg = cfg.withDefaults()\n\n    // Create Docker client from environment\n    cli, err := client.NewClientWithOpts(client.FromEnv, client.WithAPIVersionNegotiation())\n    if err != nil {\n        return nil, err\n    }\n\n    // Verify Docker is accessible\n    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n    defer cancel()\n\n    if _, err := cli.Ping(ctx); err != nil {\n        cli.Close()\n        return nil, err\n    }\n\n    return &amp;Backend{\n        client: cli,\n        config: cfg,\n    }, nil\n}\n\n// Close releases Docker client resources.\nfunc (b *Backend) Close() error {\n    if b.client != nil {\n        return b.client.Close()\n    }\n    return nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go test ./backend/docker/... -run TestNewBackend -v</code> Expected: PASS (or SKIP if Docker not available)</p> <p>Step 5: Commit</p> <pre><code>git add backend/docker/docker.go backend/docker/docker_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(docker): implement NewBackend with Docker client initialization\n\n- Create Docker client from environment\n- Verify connectivity with Ping\n- Clean up on error\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#task-4-implement-container-creation-and-execution","title":"Task 4: Implement Container Creation and Execution","text":"<p>Files: - Modify: <code>backend/docker/docker.go</code> - Test: <code>backend/docker/docker_test.go</code></p> <p>Step 1: Write failing test for Execute</p> <pre><code>func TestBackend_Execute(t *testing.T) {\n    if _, err := exec.LookPath(\"docker\"); err != nil {\n        t.Skip(\"Docker not available\")\n    }\n\n    b, err := NewBackend(Config{\n        Image:   \"alpine:latest\",\n        Timeout: 10,\n    })\n    if err != nil {\n        t.Fatalf(\"NewBackend() error = %v\", err)\n    }\n    defer b.Close()\n\n    t.Run(\"executes simple command\", func(t *testing.T) {\n        resp, err := b.Execute(context.Background(), gateway.Request{\n            Code:     \"echo 'hello world'\",\n            Language: \"sh\",\n        })\n        if err != nil {\n            t.Fatalf(\"Execute() error = %v\", err)\n        }\n        if resp.ExitCode != 0 {\n            t.Errorf(\"ExitCode = %d, want 0\", resp.ExitCode)\n        }\n        if !strings.Contains(resp.Stdout, \"hello world\") {\n            t.Errorf(\"Stdout = %q, want contains 'hello world'\", resp.Stdout)\n        }\n    })\n\n    t.Run(\"captures stderr\", func(t *testing.T) {\n        resp, err := b.Execute(context.Background(), gateway.Request{\n            Code:     \"echo 'error message' &gt;&amp;2\",\n            Language: \"sh\",\n        })\n        if err != nil {\n            t.Fatalf(\"Execute() error = %v\", err)\n        }\n        if !strings.Contains(resp.Stderr, \"error message\") {\n            t.Errorf(\"Stderr = %q, want contains 'error message'\", resp.Stderr)\n        }\n    })\n\n    t.Run(\"respects timeout\", func(t *testing.T) {\n        ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)\n        defer cancel()\n\n        _, err := b.Execute(ctx, gateway.Request{\n            Code:     \"sleep 60\",\n            Language: \"sh\",\n        })\n        if err == nil {\n            t.Error(\"Execute() should timeout\")\n        }\n    })\n\n    t.Run(\"returns non-zero exit code\", func(t *testing.T) {\n        resp, err := b.Execute(context.Background(), gateway.Request{\n            Code:     \"exit 42\",\n            Language: \"sh\",\n        })\n        if err != nil {\n            t.Fatalf(\"Execute() error = %v\", err)\n        }\n        if resp.ExitCode != 42 {\n            t.Errorf(\"ExitCode = %d, want 42\", resp.ExitCode)\n        }\n    })\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go test ./backend/docker/... -run TestBackend_Execute -v</code> Expected: FAIL - Execute returns ErrBackendUnavailable</p> <p>Step 3: Implement Execute method</p> <pre><code>import (\n    \"bytes\"\n    \"context\"\n    \"io\"\n    \"time\"\n\n    \"github.com/docker/docker/api/types/container\"\n    \"github.com/docker/docker/api/types/image\"\n    \"github.com/docker/docker/pkg/stdcopy\"\n\n    \"github.com/your-org/toolruntime/gateway\"\n)\n\n// Execute runs code in an ephemeral Docker container.\nfunc (b *Backend) Execute(ctx context.Context, req gateway.Request) (gateway.Response, error) {\n    // Apply timeout from config if not set in context\n    if _, ok := ctx.Deadline(); !ok {\n        var cancel context.CancelFunc\n        ctx, cancel = context.WithTimeout(ctx, time.Duration(b.config.Timeout)*time.Second)\n        defer cancel()\n    }\n\n    // Ensure image is available\n    if err := b.ensureImage(ctx); err != nil {\n        return gateway.Response{}, err\n    }\n\n    // Create container\n    containerConfig := &amp;container.Config{\n        Image:      b.config.Image,\n        Cmd:        []string{\"sh\", \"-c\", req.Code},\n        WorkingDir: b.config.WorkDir,\n        Tty:        false,\n    }\n\n    hostConfig := &amp;container.HostConfig{\n        Resources: container.Resources{\n            Memory:    b.config.MemoryLimitMB * 1024 * 1024,\n            CPUShares: b.config.CPUShares,\n        },\n        NetworkMode: container.NetworkMode(b.config.NetworkMode),\n        AutoRemove:  true,\n    }\n\n    resp, err := b.client.ContainerCreate(ctx, containerConfig, hostConfig, nil, nil, \"\")\n    if err != nil {\n        return gateway.Response{}, err\n    }\n    containerID := resp.ID\n\n    // Start container\n    if err := b.client.ContainerStart(ctx, containerID, container.StartOptions{}); err != nil {\n        return gateway.Response{}, err\n    }\n\n    // Wait for completion\n    statusCh, errCh := b.client.ContainerWait(ctx, containerID, container.WaitConditionNotRunning)\n\n    var exitCode int64\n    select {\n    case err := &lt;-errCh:\n        if err != nil {\n            // Try to stop container on error\n            _ = b.client.ContainerStop(context.Background(), containerID, container.StopOptions{})\n            return gateway.Response{}, err\n        }\n    case status := &lt;-statusCh:\n        exitCode = status.StatusCode\n    case &lt;-ctx.Done():\n        _ = b.client.ContainerStop(context.Background(), containerID, container.StopOptions{})\n        return gateway.Response{}, ctx.Err()\n    }\n\n    // Get logs\n    logs, err := b.client.ContainerLogs(ctx, containerID, container.LogsOptions{\n        ShowStdout: true,\n        ShowStderr: true,\n    })\n    if err != nil {\n        return gateway.Response{ExitCode: int(exitCode)}, nil\n    }\n    defer logs.Close()\n\n    var stdout, stderr bytes.Buffer\n    _, _ = stdcopy.StdCopy(&amp;stdout, &amp;stderr, logs)\n\n    return gateway.Response{\n        Stdout:   stdout.String(),\n        Stderr:   stderr.String(),\n        ExitCode: int(exitCode),\n    }, nil\n}\n\n// ensureImage pulls the image if not present locally.\nfunc (b *Backend) ensureImage(ctx context.Context) error {\n    _, _, err := b.client.ImageInspectWithRaw(ctx, b.config.Image)\n    if err == nil {\n        return nil // Image exists\n    }\n\n    reader, err := b.client.ImagePull(ctx, b.config.Image, image.PullOptions{})\n    if err != nil {\n        return err\n    }\n    defer reader.Close()\n\n    // Drain the reader to complete the pull\n    _, _ = io.Copy(io.Discard, reader)\n    return nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go test ./backend/docker/... -run TestBackend_Execute -v -timeout 120s</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add backend/docker/docker.go backend/docker/docker_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(docker): implement Execute with container lifecycle management\n\n- Create ephemeral containers with resource limits\n- Capture stdout/stderr separately\n- Respect context timeout and cancellation\n- Auto-pull images when not present\n- Auto-remove containers after execution\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#task-5-implement-backend-interface-methods","title":"Task 5: Implement Backend Interface Methods","text":"<p>Files: - Modify: <code>backend/docker/docker.go</code> - Test: <code>backend/docker/docker_test.go</code></p> <p>Step 1: Write failing test for interface compliance</p> <pre><code>func TestBackend_Interface(t *testing.T) {\n    // Verify Backend implements gateway.Backend\n    var _ gateway.Backend = (*Backend)(nil)\n}\n\nfunc TestBackend_Name(t *testing.T) {\n    if _, err := exec.LookPath(\"docker\"); err != nil {\n        t.Skip(\"Docker not available\")\n    }\n\n    b, _ := NewBackend(Config{})\n    defer b.Close()\n\n    if got := b.Name(); got != \"docker\" {\n        t.Errorf(\"Name() = %q, want %q\", got, \"docker\")\n    }\n}\n\nfunc TestBackend_Available(t *testing.T) {\n    if _, err := exec.LookPath(\"docker\"); err != nil {\n        t.Skip(\"Docker not available\")\n    }\n\n    b, _ := NewBackend(Config{})\n    defer b.Close()\n\n    if !b.Available() {\n        t.Error(\"Available() = false, want true\")\n    }\n}\n\nfunc TestBackend_Supports(t *testing.T) {\n    if _, err := exec.LookPath(\"docker\"); err != nil {\n        t.Skip(\"Docker not available\")\n    }\n\n    b, _ := NewBackend(Config{Image: \"python:3.11-slim\"})\n    defer b.Close()\n\n    tests := []struct {\n        language string\n        want     bool\n    }{\n        {\"python\", true},\n        {\"sh\", true},\n        {\"bash\", true},\n        {\"unknown\", false},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.language, func(t *testing.T) {\n            if got := b.Supports(tt.language); got != tt.want {\n                t.Errorf(\"Supports(%q) = %v, want %v\", tt.language, got, tt.want)\n            }\n        })\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go test ./backend/docker/... -run 'TestBackend_(Interface|Name|Available|Supports)' -v</code> Expected: FAIL - Methods not implemented</p> <p>Step 3: Implement interface methods</p> <pre><code>// Name returns the backend identifier.\nfunc (b *Backend) Name() string {\n    return \"docker\"\n}\n\n// Available checks if Docker daemon is accessible.\nfunc (b *Backend) Available() bool {\n    ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)\n    defer cancel()\n\n    _, err := b.client.Ping(ctx)\n    return err == nil\n}\n\n// Supports checks if the backend can execute the given language.\n// Docker supports any language available in the configured image.\nfunc (b *Backend) Supports(language string) bool {\n    // Common languages supported by default images\n    supported := map[string]bool{\n        \"sh\":     true,\n        \"bash\":   true,\n        \"python\": true,\n        \"python3\": true,\n        \"node\":   true,\n        \"ruby\":   true,\n        \"perl\":   true,\n    }\n\n    // Check image-specific support\n    if strings.Contains(b.config.Image, \"python\") {\n        supported[\"python\"] = true\n        supported[\"python3\"] = true\n    }\n    if strings.Contains(b.config.Image, \"node\") {\n        supported[\"javascript\"] = true\n        supported[\"node\"] = true\n    }\n    if strings.Contains(b.config.Image, \"alpine\") || strings.Contains(b.config.Image, \"ubuntu\") {\n        // Base images support shell\n        supported[\"sh\"] = true\n    }\n\n    return supported[language]\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go test ./backend/docker/... -run 'TestBackend_(Interface|Name|Available|Supports)' -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add backend/docker/docker.go backend/docker/docker_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(docker): implement gateway.Backend interface methods\n\n- Name() returns \"docker\"\n- Available() checks Docker daemon connectivity\n- Supports() returns true for languages in configured image\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#task-6-add-security-profile-integration","title":"Task 6: Add Security Profile Integration","text":"<p>Files: - Modify: <code>backend/docker/docker.go</code> - Test: <code>backend/docker/docker_test.go</code></p> <p>Step 1: Write failing test for security profiles</p> <pre><code>func TestBackend_SecurityProfiles(t *testing.T) {\n    if _, err := exec.LookPath(\"docker\"); err != nil {\n        t.Skip(\"Docker not available\")\n    }\n\n    t.Run(\"dev profile allows network\", func(t *testing.T) {\n        b, _ := NewBackend(Config{\n            NetworkMode: \"bridge\",\n        })\n        defer b.Close()\n\n        // In dev mode, network access should work\n        resp, err := b.Execute(context.Background(), gateway.Request{\n            Code:     \"echo 'network test'\",\n            Language: \"sh\",\n        })\n        if err != nil {\n            t.Fatalf(\"Execute() error = %v\", err)\n        }\n        if resp.ExitCode != 0 {\n            t.Errorf(\"ExitCode = %d, want 0\", resp.ExitCode)\n        }\n    })\n\n    t.Run(\"hardened profile denies network\", func(t *testing.T) {\n        b, _ := NewBackend(Config{\n            NetworkMode: \"none\",\n        })\n        defer b.Close()\n\n        // Network should be isolated\n        if b.config.NetworkMode != \"none\" {\n            t.Error(\"Hardened profile should have NetworkMode=none\")\n        }\n    })\n}\n</code></pre> <p>Step 2: Run test to verify it passes (already implemented via NetworkMode)</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go test ./backend/docker/... -run TestBackend_SecurityProfiles -v</code> Expected: PASS</p> <p>Step 3: Commit</p> <pre><code>git add backend/docker/docker_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\ntest(docker): add security profile integration tests\n\n- Verify dev profile allows network access\n- Verify hardened profile isolates network\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#task-7-integration-test-with-toolruntime","title":"Task 7: Integration Test with toolruntime","text":"<p>Files: - Create: <code>backend/docker/integration_test.go</code></p> <p>Step 1: Write integration test</p> <pre><code>//go:build integration\n\npackage docker\n\nimport (\n    \"context\"\n    \"os/exec\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/your-org/toolruntime/gateway\"\n)\n\nfunc TestIntegration_PythonExecution(t *testing.T) {\n    if _, err := exec.LookPath(\"docker\"); err != nil {\n        t.Skip(\"Docker not available\")\n    }\n\n    b, err := NewBackend(Config{\n        Image:   \"python:3.11-slim\",\n        Timeout: 30,\n    })\n    if err != nil {\n        t.Fatalf(\"NewBackend() error = %v\", err)\n    }\n    defer b.Close()\n\n    code := `\nimport json\nresult = {\"sum\": 1 + 2, \"product\": 2 * 3}\nprint(json.dumps(result))\n`\n\n    resp, err := b.Execute(context.Background(), gateway.Request{\n        Code:     code,\n        Language: \"python\",\n    })\n    if err != nil {\n        t.Fatalf(\"Execute() error = %v\", err)\n    }\n\n    if resp.ExitCode != 0 {\n        t.Errorf(\"ExitCode = %d, want 0\\nStderr: %s\", resp.ExitCode, resp.Stderr)\n    }\n\n    expected := `{\"sum\": 3, \"product\": 6}`\n    if !strings.Contains(resp.Stdout, expected) {\n        t.Errorf(\"Stdout = %q, want contains %q\", resp.Stdout, expected)\n    }\n}\n\nfunc TestIntegration_ResourceLimits(t *testing.T) {\n    if _, err := exec.LookPath(\"docker\"); err != nil {\n        t.Skip(\"Docker not available\")\n    }\n\n    b, err := NewBackend(Config{\n        Image:         \"alpine:latest\",\n        Timeout:       5,\n        MemoryLimitMB: 32, // Very low memory\n    })\n    if err != nil {\n        t.Fatalf(\"NewBackend() error = %v\", err)\n    }\n    defer b.Close()\n\n    // Try to allocate more memory than allowed\n    code := `dd if=/dev/zero of=/dev/null bs=64M count=1`\n\n    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n    defer cancel()\n\n    resp, _ := b.Execute(ctx, gateway.Request{\n        Code:     code,\n        Language: \"sh\",\n    })\n\n    // Should either fail or be killed due to memory limits\n    t.Logf(\"ExitCode: %d, Stderr: %s\", resp.ExitCode, resp.Stderr)\n}\n</code></pre> <p>Step 2: Run integration test</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/toolruntime &amp;&amp; go test ./backend/docker/... -tags=integration -run TestIntegration -v -timeout 300s</code> Expected: PASS</p> <p>Step 3: Commit</p> <pre><code>git add backend/docker/integration_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\ntest(docker): add integration tests for Python execution and resource limits\n\n- Test Python code execution in container\n- Test memory limit enforcement\n- Requires Docker daemon for execution\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#task-8-update-readme-and-documentation","title":"Task 8: Update README and Documentation","text":"<p>Files: - Modify: <code>backend/docker/README.md</code> (create if not exists)</p> <p>Step 1: Write documentation</p> <pre><code># Docker Backend for toolruntime\n\nProduction-ready Docker isolation backend for code execution.\n\n## Features\n\n- Ephemeral containers with automatic cleanup\n- Resource limits (CPU, memory)\n- Network isolation modes\n- Timeout enforcement\n- stdout/stderr capture\n\n## Usage\n\n```go\nimport \"github.com/your-org/toolruntime/backend/docker\"\n\n// Create with defaults (python:3.11-slim, 30s timeout, 256MB memory)\nb, err := docker.NewBackend(docker.Config{})\n\n// Create with custom config\nb, err := docker.NewBackend(docker.Config{\n    Image:         \"node:18-alpine\",\n    Timeout:       60,\n    MemoryLimitMB: 512,\n    NetworkMode:   \"none\",  // Isolated\n})\n\n// Execute code\nresp, err := b.Execute(ctx, gateway.Request{\n    Code:     \"console.log('hello')\",\n    Language: \"javascript\",\n})\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#configuration","title":"Configuration","text":"Field Type Default Description Image string python:3.11-slim Docker image to use Timeout int 30 Execution timeout in seconds MemoryLimitMB int64 256 Memory limit in MB CPUShares int64 512 Relative CPU weight NetworkMode string none none, bridge, or host WorkDir string /workspace Working directory in container"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#security-profiles","title":"Security Profiles","text":"<p>Map to security profiles via configuration:</p> Profile NetworkMode MemoryLimitMB Use Case dev bridge 1024 Local development standard none 256 Production default hardened none 128 Untrusted code <pre><code>**Step 2: Commit**\n\n```bash\ngit add backend/docker/README.md\ngit commit -m \"$(cat &lt;&lt;'EOF'\ndocs(docker): add README with usage examples and configuration reference\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Docker SDK dependency added</li> <li>[ ] Config struct with validation and defaults</li> <li>[ ] NewBackend with client initialization</li> <li>[ ] Execute with container lifecycle</li> <li>[ ] Interface methods (Name, Available, Supports)</li> <li>[ ] Security profile integration</li> <li>[ ] Integration tests pass</li> <li>[ ] Documentation complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-001-toolruntime-docker-backend/#definition-of-done","title":"Definition of Done","text":"<ol> <li>All unit tests pass: <code>go test ./backend/docker/...</code></li> <li>Integration tests pass: <code>go test ./backend/docker/... -tags=integration</code></li> <li>Code coverage &gt; 80%</li> <li>Documentation complete</li> <li>No breaking changes to existing interfaces</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/","title":"PRD-002: CLI Foundation with Cobra","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Add Cobra CLI framework to metatools-mcp enabling subcommands (<code>serve</code>, <code>version</code>, <code>config</code>) and establishing the foundation for configuration-driven extensibility.</p> <p>Architecture: Introduce Cobra as the CLI framework with a root command and initial subcommands. This replaces direct MCP server invocation with a structured CLI that supports flags, environment variables, and future config file integration. The existing stdio server behavior becomes <code>metatools serve --transport=stdio</code>.</p> <p>Tech Stack: Cobra (github.com/spf13/cobra), Go 1.21+, existing metatools-mcp codebase</p> <p>Priority: P0 - Foundation (Stream A, Phase 1 prerequisite)</p> <p>Scope: CLI structure only - no config file loading yet (that's PRD-003)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#context","title":"Context","text":"<p>The current metatools-mcp server starts directly via <code>main()</code> without CLI structure. The pluggable architecture proposal requires: 1. Subcommand support (<code>serve</code>, <code>version</code>, <code>config validate</code>) 2. Flag-based configuration (<code>--transport</code>, <code>--port</code>, <code>--config</code>) 3. Environment variable fallbacks 4. Help text and documentation</p> <p>Current State: <pre><code>// cmd/metatools-mcp/main.go (current)\nfunc main() {\n    server, _ := server.New(cfg)\n    _ = server.Run(context.Background(), &amp;mcp.StdioTransport{})\n}\n</code></pre></p> <p>Target State: <pre><code>metatools serve              # Default: stdio transport\nmetatools serve --transport=sse --port=8080\nmetatools version\nmetatools config validate --config=metatools.yaml\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#task-1-add-cobra-dependency","title":"Task 1: Add Cobra Dependency","text":"<p>Files: - Modify: <code>go.mod</code> - Modify: <code>go.sum</code></p> <p>Step 1: Add Cobra to go.mod</p> <p>Run: <pre><code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go get github.com/spf13/cobra@v1.8.0\n</code></pre></p> <p>Step 2: Verify import works</p> <p>Run: <pre><code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go build ./...\n</code></pre> Expected: Build succeeds</p> <p>Step 3: Commit</p> <pre><code>git add go.mod go.sum\ngit commit -m \"$(cat &lt;&lt;'EOF'\ndeps: add Cobra CLI framework\n\nFoundation for subcommand-based CLI structure.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#task-2-create-root-command-structure","title":"Task 2: Create Root Command Structure","text":"<p>Files: - Create: <code>cmd/metatools-mcp/cmd/root.go</code> - Test: <code>cmd/metatools-mcp/cmd/root_test.go</code></p> <p>Step 1: Write failing test for root command</p> <pre><code>// cmd/metatools-mcp/cmd/root_test.go\npackage cmd\n\nimport (\n    \"bytes\"\n    \"testing\"\n)\n\nfunc TestRootCmd_Help(t *testing.T) {\n    cmd := NewRootCmd()\n    buf := new(bytes.Buffer)\n    cmd.SetOut(buf)\n    cmd.SetArgs([]string{\"--help\"})\n\n    err := cmd.Execute()\n    if err != nil {\n        t.Fatalf(\"Execute() error = %v\", err)\n    }\n\n    output := buf.String()\n    if !contains(output, \"metatools-mcp\") {\n        t.Errorf(\"Help should contain 'metatools-mcp', got: %s\", output)\n    }\n    if !contains(output, \"serve\") {\n        t.Errorf(\"Help should list 'serve' subcommand, got: %s\", output)\n    }\n    if !contains(output, \"version\") {\n        t.Errorf(\"Help should list 'version' subcommand, got: %s\", output)\n    }\n}\n\nfunc contains(s, substr string) bool {\n    return bytes.Contains([]byte(s), []byte(substr))\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -run TestRootCmd_Help -v</code> Expected: FAIL - NewRootCmd doesn't exist</p> <p>Step 3: Implement root command</p> <pre><code>// cmd/metatools-mcp/cmd/root.go\npackage cmd\n\nimport (\n    \"github.com/spf13/cobra\"\n)\n\nvar (\n    // Version information (set at build time)\n    Version   = \"dev\"\n    GitCommit = \"unknown\"\n    BuildDate = \"unknown\"\n)\n\n// NewRootCmd creates the root command for metatools-mcp.\nfunc NewRootCmd() *cobra.Command {\n    rootCmd := &amp;cobra.Command{\n        Use:   \"metatools-mcp\",\n        Short: \"MCP server for progressive tool discovery and execution\",\n        Long: `metatools-mcp is the MCP server that exposes the tool stack via a small,\nprogressive-disclosure tool surface. It composes toolmodel, toolindex, tooldocs,\ntoolrun, and optionally toolcode/toolruntime.\n\nUse subcommands to start the server or manage configuration.`,\n        SilenceUsage:  true,\n        SilenceErrors: true,\n    }\n\n    // Add subcommands\n    rootCmd.AddCommand(newServeCmd())\n    rootCmd.AddCommand(newVersionCmd())\n\n    return rootCmd\n}\n\n// Execute runs the root command.\nfunc Execute() error {\n    return NewRootCmd().Execute()\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -run TestRootCmd_Help -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add cmd/metatools-mcp/cmd/root.go cmd/metatools-mcp/cmd/root_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(cli): add Cobra root command structure\n\n- Create NewRootCmd() with program description\n- Add Version, GitCommit, BuildDate variables for build-time injection\n- Prepare for serve and version subcommands\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#task-3-implement-version-command","title":"Task 3: Implement Version Command","text":"<p>Files: - Create: <code>cmd/metatools-mcp/cmd/version.go</code> - Test: <code>cmd/metatools-mcp/cmd/version_test.go</code></p> <p>Step 1: Write failing test for version command</p> <pre><code>// cmd/metatools-mcp/cmd/version_test.go\npackage cmd\n\nimport (\n    \"bytes\"\n    \"testing\"\n)\n\nfunc TestVersionCmd(t *testing.T) {\n    // Set test values\n    Version = \"1.2.3\"\n    GitCommit = \"abc123\"\n    BuildDate = \"2026-01-28\"\n\n    cmd := NewRootCmd()\n    buf := new(bytes.Buffer)\n    cmd.SetOut(buf)\n    cmd.SetArgs([]string{\"version\"})\n\n    err := cmd.Execute()\n    if err != nil {\n        t.Fatalf(\"Execute() error = %v\", err)\n    }\n\n    output := buf.String()\n    if !contains(output, \"1.2.3\") {\n        t.Errorf(\"Version output should contain version, got: %s\", output)\n    }\n    if !contains(output, \"abc123\") {\n        t.Errorf(\"Version output should contain git commit, got: %s\", output)\n    }\n}\n\nfunc TestVersionCmd_JSON(t *testing.T) {\n    Version = \"1.2.3\"\n    GitCommit = \"abc123\"\n    BuildDate = \"2026-01-28\"\n\n    cmd := NewRootCmd()\n    buf := new(bytes.Buffer)\n    cmd.SetOut(buf)\n    cmd.SetArgs([]string{\"version\", \"--json\"})\n\n    err := cmd.Execute()\n    if err != nil {\n        t.Fatalf(\"Execute() error = %v\", err)\n    }\n\n    output := buf.String()\n    if !contains(output, `\"version\"`) {\n        t.Errorf(\"JSON output should contain version field, got: %s\", output)\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -run TestVersionCmd -v</code> Expected: FAIL - newVersionCmd doesn't exist</p> <p>Step 3: Implement version command</p> <pre><code>// cmd/metatools-mcp/cmd/version.go\npackage cmd\n\nimport (\n    \"encoding/json\"\n    \"fmt\"\n    \"runtime\"\n\n    \"github.com/spf13/cobra\"\n)\n\ntype versionInfo struct {\n    Version   string `json:\"version\"`\n    GitCommit string `json:\"gitCommit\"`\n    BuildDate string `json:\"buildDate\"`\n    GoVersion string `json:\"goVersion\"`\n    Platform  string `json:\"platform\"`\n}\n\nfunc newVersionCmd() *cobra.Command {\n    var jsonOutput bool\n\n    cmd := &amp;cobra.Command{\n        Use:   \"version\",\n        Short: \"Print version information\",\n        Long:  \"Print the version, git commit, build date, and Go version.\",\n        RunE: func(cmd *cobra.Command, args []string) error {\n            info := versionInfo{\n                Version:   Version,\n                GitCommit: GitCommit,\n                BuildDate: BuildDate,\n                GoVersion: runtime.Version(),\n                Platform:  fmt.Sprintf(\"%s/%s\", runtime.GOOS, runtime.GOARCH),\n            }\n\n            if jsonOutput {\n                enc := json.NewEncoder(cmd.OutOrStdout())\n                enc.SetIndent(\"\", \"  \")\n                return enc.Encode(info)\n            }\n\n            fmt.Fprintf(cmd.OutOrStdout(), \"metatools-mcp %s\\n\", info.Version)\n            fmt.Fprintf(cmd.OutOrStdout(), \"  Git commit: %s\\n\", info.GitCommit)\n            fmt.Fprintf(cmd.OutOrStdout(), \"  Build date: %s\\n\", info.BuildDate)\n            fmt.Fprintf(cmd.OutOrStdout(), \"  Go version: %s\\n\", info.GoVersion)\n            fmt.Fprintf(cmd.OutOrStdout(), \"  Platform:   %s\\n\", info.Platform)\n            return nil\n        },\n    }\n\n    cmd.Flags().BoolVar(&amp;jsonOutput, \"json\", false, \"Output version as JSON\")\n\n    return cmd\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -run TestVersionCmd -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add cmd/metatools-mcp/cmd/version.go cmd/metatools-mcp/cmd/version_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(cli): add version subcommand with JSON output option\n\n- Display version, git commit, build date, Go version, platform\n- Support --json flag for machine-readable output\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#task-4-implement-serve-command-with-transport-flag","title":"Task 4: Implement Serve Command with Transport Flag","text":"<p>Files: - Create: <code>cmd/metatools-mcp/cmd/serve.go</code> - Test: <code>cmd/metatools-mcp/cmd/serve_test.go</code></p> <p>Step 1: Write failing test for serve command flags</p> <pre><code>// cmd/metatools-mcp/cmd/serve_test.go\npackage cmd\n\nimport (\n    \"testing\"\n)\n\nfunc TestServeCmd_Flags(t *testing.T) {\n    cmd := newServeCmd()\n\n    // Check transport flag exists\n    transportFlag := cmd.Flags().Lookup(\"transport\")\n    if transportFlag == nil {\n        t.Fatal(\"--transport flag not found\")\n    }\n    if transportFlag.DefValue != \"stdio\" {\n        t.Errorf(\"--transport default = %q, want %q\", transportFlag.DefValue, \"stdio\")\n    }\n\n    // Check port flag exists\n    portFlag := cmd.Flags().Lookup(\"port\")\n    if portFlag == nil {\n        t.Fatal(\"--port flag not found\")\n    }\n    if portFlag.DefValue != \"8080\" {\n        t.Errorf(\"--port default = %q, want %q\", portFlag.DefValue, \"8080\")\n    }\n\n    // Check config flag exists\n    configFlag := cmd.Flags().Lookup(\"config\")\n    if configFlag == nil {\n        t.Fatal(\"--config flag not found\")\n    }\n}\n\nfunc TestServeCmd_TransportValidation(t *testing.T) {\n    tests := []struct {\n        transport string\n        wantErr   bool\n    }{\n        {\"stdio\", false},\n        {\"sse\", false},\n        {\"http\", false},\n        {\"invalid\", true},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.transport, func(t *testing.T) {\n            err := validateTransport(tt.transport)\n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"validateTransport(%q) error = %v, wantErr %v\", tt.transport, err, tt.wantErr)\n            }\n        })\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -run TestServeCmd -v</code> Expected: FAIL - newServeCmd doesn't exist</p> <p>Step 3: Implement serve command</p> <pre><code>// cmd/metatools-mcp/cmd/serve.go\npackage cmd\n\nimport (\n    \"context\"\n    \"errors\"\n    \"fmt\"\n    \"os\"\n    \"os/signal\"\n    \"syscall\"\n\n    \"github.com/spf13/cobra\"\n)\n\n// ServeConfig holds serve command configuration.\ntype ServeConfig struct {\n    Transport string\n    Port      int\n    Host      string\n    Config    string\n}\n\nvar validTransports = []string{\"stdio\", \"sse\", \"http\"}\n\nfunc validateTransport(transport string) error {\n    for _, valid := range validTransports {\n        if transport == valid {\n            return nil\n        }\n    }\n    return fmt.Errorf(\"invalid transport %q, must be one of: %v\", transport, validTransports)\n}\n\nfunc newServeCmd() *cobra.Command {\n    cfg := &amp;ServeConfig{}\n\n    cmd := &amp;cobra.Command{\n        Use:   \"serve\",\n        Short: \"Start the MCP server\",\n        Long: `Start the metatools-mcp server with the specified transport.\n\nTransports:\n  stdio  - Standard input/output (default, for MCP clients like Claude Desktop)\n  sse    - Server-Sent Events over HTTP (for web clients)\n  http   - Simple HTTP request/response (for REST clients)\n\nExamples:\n  metatools-mcp serve                           # stdio mode (default)\n  metatools-mcp serve --transport=sse --port=8080\n  metatools-mcp serve --config=metatools.yaml`,\n        PreRunE: func(cmd *cobra.Command, args []string) error {\n            return validateTransport(cfg.Transport)\n        },\n        RunE: func(cmd *cobra.Command, args []string) error {\n            return runServe(cmd.Context(), cfg)\n        },\n    }\n\n    // Flags\n    cmd.Flags().StringVarP(&amp;cfg.Transport, \"transport\", \"t\", \"stdio\", \"Transport type (stdio, sse, http)\")\n    cmd.Flags().IntVarP(&amp;cfg.Port, \"port\", \"p\", 8080, \"Port for HTTP transports\")\n    cmd.Flags().StringVar(&amp;cfg.Host, \"host\", \"0.0.0.0\", \"Host to bind for HTTP transports\")\n    cmd.Flags().StringVarP(&amp;cfg.Config, \"config\", \"c\", \"\", \"Path to config file\")\n\n    return cmd\n}\n\nfunc runServe(ctx context.Context, cfg *ServeConfig) error {\n    // Setup signal handling\n    ctx, cancel := signal.NotifyContext(ctx, os.Interrupt, syscall.SIGTERM)\n    defer cancel()\n\n    // For now, just print what would happen\n    // The actual server integration will be added in the next task\n    fmt.Printf(\"Starting server with transport=%s\\n\", cfg.Transport)\n    if cfg.Transport != \"stdio\" {\n        fmt.Printf(\"Listening on %s:%d\\n\", cfg.Host, cfg.Port)\n    }\n\n    // TODO: Integrate with existing server code\n    // This placeholder will be replaced when we integrate with the server package\n\n    &lt;-ctx.Done()\n    fmt.Println(\"Shutting down...\")\n    return nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -run TestServeCmd -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add cmd/metatools-mcp/cmd/serve.go cmd/metatools-mcp/cmd/serve_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(cli): add serve subcommand with transport, port, config flags\n\n- Support --transport flag (stdio, sse, http)\n- Support --port and --host flags for HTTP transports\n- Support --config flag for config file path\n- Add transport validation\n- Placeholder for server integration\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#task-5-update-main-to-use-cobra","title":"Task 5: Update Main to Use Cobra","text":"<p>Files: - Modify: <code>cmd/metatools-mcp/main.go</code> - Test: Manual verification</p> <p>Step 1: Read current main.go</p> <p>Run: Read the current main.go to understand the existing structure.</p> <p>Step 2: Update main.go to use Cobra</p> <pre><code>// cmd/metatools-mcp/main.go\npackage main\n\nimport (\n    \"fmt\"\n    \"os\"\n\n    \"github.com/your-org/metatools-mcp/cmd/metatools-mcp/cmd\"\n)\n\nfunc main() {\n    if err := cmd.Execute(); err != nil {\n        fmt.Fprintln(os.Stderr, err)\n        os.Exit(1)\n    }\n}\n</code></pre> <p>Step 3: Verify it builds</p> <p>Run: <pre><code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go build ./cmd/metatools-mcp/...\n</code></pre> Expected: Build succeeds</p> <p>Step 4: Verify help works</p> <p>Run: <pre><code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; ./cmd/metatools-mcp/metatools-mcp --help\n</code></pre> Expected: Shows help with serve and version subcommands</p> <p>Step 5: Commit</p> <pre><code>git add cmd/metatools-mcp/main.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(cli): update main.go to use Cobra CLI\n\n- Replace direct server invocation with Cobra Execute()\n- Maintain backward compatibility via 'serve' subcommand\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#task-6-integrate-serve-command-with-existing-server","title":"Task 6: Integrate Serve Command with Existing Server","text":"<p>Files: - Modify: <code>cmd/metatools-mcp/cmd/serve.go</code> - Test: <code>cmd/metatools-mcp/cmd/serve_test.go</code></p> <p>Step 1: Write integration test</p> <pre><code>// Add to serve_test.go\nfunc TestServeCmd_StdioIntegration(t *testing.T) {\n    // This test verifies the serve command can create a server\n    // It doesn't run the full server, just validates wiring\n\n    cfg := &amp;ServeConfig{\n        Transport: \"stdio\",\n    }\n\n    // Verify we can create server config from CLI config\n    serverCfg, err := buildServerConfig(cfg)\n    if err != nil {\n        t.Fatalf(\"buildServerConfig() error = %v\", err)\n    }\n\n    if serverCfg == nil {\n        t.Fatal(\"buildServerConfig() returned nil\")\n    }\n}\n</code></pre> <p>Step 2: Implement server integration</p> <p>Update <code>serve.go</code> to integrate with the existing server package:</p> <pre><code>// Add to serve.go\nimport (\n    \"github.com/your-org/metatools-mcp/internal/adapters\"\n    \"github.com/your-org/metatools-mcp/internal/server\"\n    \"github.com/mark3labs/mcp-go/mcp\"\n    // ... existing imports\n)\n\nfunc buildServerConfig(cfg *ServeConfig) (*adapters.Config, error) {\n    // Build server configuration from CLI flags\n    // This bridges CLI config to the existing server config\n\n    // For now, use existing defaults\n    // Future PRDs will add Koanf config file loading here\n\n    idx := toolindex.NewInMemoryIndex()\n    docs := tooldocs.NewInMemoryStore(tooldocs.StoreOptions{Index: idx})\n    runner := toolrun.NewRunner(toolrun.WithIndex(idx))\n\n    return adapters.NewConfig(idx, docs, runner, nil), nil\n}\n\nfunc runServe(ctx context.Context, cfg *ServeConfig) error {\n    ctx, cancel := signal.NotifyContext(ctx, os.Interrupt, syscall.SIGTERM)\n    defer cancel()\n\n    serverCfg, err := buildServerConfig(cfg)\n    if err != nil {\n        return fmt.Errorf(\"build server config: %w\", err)\n    }\n\n    srv, err := server.New(serverCfg)\n    if err != nil {\n        return fmt.Errorf(\"create server: %w\", err)\n    }\n\n    // Select transport based on flag\n    var transport mcp.Transport\n    switch cfg.Transport {\n    case \"stdio\":\n        transport = &amp;mcp.StdioTransport{}\n    case \"sse\", \"http\":\n        // SSE/HTTP transports will be implemented in PRD-004\n        return fmt.Errorf(\"transport %q not yet implemented\", cfg.Transport)\n    default:\n        return fmt.Errorf(\"unknown transport: %s\", cfg.Transport)\n    }\n\n    fmt.Fprintf(os.Stderr, \"Starting metatools-mcp server (transport=%s)\\n\", cfg.Transport)\n    return srv.Run(ctx, transport)\n}\n</code></pre> <p>Step 3: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -v</code> Expected: PASS</p> <p>Step 4: Commit</p> <pre><code>git add cmd/metatools-mcp/cmd/serve.go cmd/metatools-mcp/cmd/serve_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(cli): integrate serve command with existing server package\n\n- Bridge CLI config to adapters.Config\n- Create server with stdio transport\n- Placeholder for SSE/HTTP transports (future PRD)\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#task-7-add-build-time-version-injection","title":"Task 7: Add Build-Time Version Injection","text":"<p>Files: - Modify: <code>Makefile</code> (or create if not exists) - Modify: <code>.goreleaser.yaml</code> (if using goreleaser)</p> <p>Step 1: Create/update Makefile</p> <pre><code># Makefile\nVERSION ?= $(shell git describe --tags --always --dirty)\nGIT_COMMIT ?= $(shell git rev-parse --short HEAD)\nBUILD_DATE ?= $(shell date -u +\"%Y-%m-%dT%H:%M:%SZ\")\n\nLDFLAGS := -X github.com/your-org/metatools-mcp/cmd/metatools-mcp/cmd.Version=$(VERSION)\nLDFLAGS += -X github.com/your-org/metatools-mcp/cmd/metatools-mcp/cmd.GitCommit=$(GIT_COMMIT)\nLDFLAGS += -X github.com/your-org/metatools-mcp/cmd/metatools-mcp/cmd.BuildDate=$(BUILD_DATE)\n\n.PHONY: build\nbuild:\n    go build -ldflags \"$(LDFLAGS)\" -o bin/metatools-mcp ./cmd/metatools-mcp\n\n.PHONY: install\ninstall:\n    go install -ldflags \"$(LDFLAGS)\" ./cmd/metatools-mcp\n\n.PHONY: test\ntest:\n    go test ./...\n\n.PHONY: clean\nclean:\n    rm -rf bin/\n</code></pre> <p>Step 2: Verify build with version injection</p> <p>Run: <pre><code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; make build &amp;&amp; ./bin/metatools-mcp version\n</code></pre> Expected: Shows actual git version and commit</p> <p>Step 3: Commit</p> <pre><code>git add Makefile\ngit commit -m \"$(cat &lt;&lt;'EOF'\nbuild: add Makefile with version injection via ldflags\n\n- Inject Version, GitCommit, BuildDate at build time\n- Add build, install, test, clean targets\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#task-8-add-environment-variable-support","title":"Task 8: Add Environment Variable Support","text":"<p>Files: - Modify: <code>cmd/metatools-mcp/cmd/serve.go</code> - Test: <code>cmd/metatools-mcp/cmd/serve_test.go</code></p> <p>Step 1: Write failing test for env var support</p> <pre><code>// Add to serve_test.go\nfunc TestServeCmd_EnvVars(t *testing.T) {\n    // Save and restore env\n    oldTransport := os.Getenv(\"METATOOLS_TRANSPORT\")\n    oldPort := os.Getenv(\"METATOOLS_PORT\")\n    defer func() {\n        os.Setenv(\"METATOOLS_TRANSPORT\", oldTransport)\n        os.Setenv(\"METATOOLS_PORT\", oldPort)\n    }()\n\n    os.Setenv(\"METATOOLS_TRANSPORT\", \"sse\")\n    os.Setenv(\"METATOOLS_PORT\", \"9090\")\n\n    cmd := newServeCmd()\n\n    // Parse empty args to trigger env var loading\n    cmd.ParseFlags([]string{})\n\n    // Flags should pick up env vars\n    transport, _ := cmd.Flags().GetString(\"transport\")\n    port, _ := cmd.Flags().GetInt(\"port\")\n\n    if transport != \"sse\" {\n        t.Errorf(\"transport = %q, want %q from env\", transport, \"sse\")\n    }\n    if port != 9090 {\n        t.Errorf(\"port = %d, want %d from env\", port, 9090)\n    }\n}\n</code></pre> <p>Step 2: Implement env var support</p> <p>Update <code>serve.go</code> to read env vars:</p> <pre><code>// Add to serve.go in newServeCmd()\nfunc newServeCmd() *cobra.Command {\n    cfg := &amp;ServeConfig{}\n\n    // ... existing code ...\n\n    // Bind environment variables\n    // Cobra doesn't have built-in env support, so we do it manually\n    cmd.PreRun = func(cmd *cobra.Command, args []string) {\n        // Only use env if flag wasn't explicitly set\n        if !cmd.Flags().Changed(\"transport\") {\n            if v := os.Getenv(\"METATOOLS_TRANSPORT\"); v != \"\" {\n                cfg.Transport = v\n            }\n        }\n        if !cmd.Flags().Changed(\"port\") {\n            if v := os.Getenv(\"METATOOLS_PORT\"); v != \"\" {\n                if port, err := strconv.Atoi(v); err == nil {\n                    cfg.Port = port\n                }\n            }\n        }\n        if !cmd.Flags().Changed(\"host\") {\n            if v := os.Getenv(\"METATOOLS_HOST\"); v != \"\" {\n                cfg.Host = v\n            }\n        }\n        if !cmd.Flags().Changed(\"config\") {\n            if v := os.Getenv(\"METATOOLS_CONFIG\"); v != \"\" {\n                cfg.Config = v\n            }\n        }\n    }\n\n    return cmd\n}\n</code></pre> <p>Step 3: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -run TestServeCmd_EnvVars -v</code> Expected: PASS</p> <p>Step 4: Commit</p> <pre><code>git add cmd/metatools-mcp/cmd/serve.go cmd/metatools-mcp/cmd/serve_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(cli): add environment variable support for serve flags\n\nEnvironment variables (lower precedence than flags):\n- METATOOLS_TRANSPORT\n- METATOOLS_PORT\n- METATOOLS_HOST\n- METATOOLS_CONFIG\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Cobra dependency added</li> <li>[ ] Root command with help text</li> <li>[ ] Version subcommand with --json flag</li> <li>[ ] Serve subcommand with --transport, --port, --host, --config flags</li> <li>[ ] Transport validation (stdio, sse, http)</li> <li>[ ] Environment variable fallbacks</li> <li>[ ] Build-time version injection</li> <li>[ ] Integration with existing server package</li> <li>[ ] All tests pass</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#definition-of-done","title":"Definition of Done","text":"<ol> <li>All unit tests pass: <code>go test ./cmd/metatools-mcp/...</code></li> <li><code>metatools-mcp --help</code> shows all subcommands</li> <li><code>metatools-mcp version</code> displays version info</li> <li><code>metatools-mcp serve</code> starts stdio server (backward compatible)</li> <li><code>METATOOLS_TRANSPORT=sse metatools-mcp serve</code> reads from env</li> <li>Build injects version: <code>make build &amp;&amp; ./bin/metatools-mcp version</code></li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-002-cli-cobra-foundation/#next-prd","title":"Next PRD","text":"<p>PRD-003 will add Koanf configuration file support, enabling <code>metatools.yaml</code> config files.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/","title":"PRD-003: Configuration Layer with Koanf","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Add Koanf configuration file support enabling YAML-based configuration for all extension points, with environment variable overrides and validation.</p> <p>Architecture: Introduce Koanf as the configuration library with a structured Config type that maps to all 13 extension points. Configuration is loaded in order: defaults \u2192 config file \u2192 environment variables \u2192 CLI flags. The config exposes search strategy, backend selection, runtime settings, and middleware options.</p> <p>Tech Stack: Koanf (github.com/knadh/koanf), Go 1.21+, existing Cobra CLI from PRD-002</p> <p>Priority: P0 - Foundation (Stream A, Phase 1 - enables all pluggability)</p> <p>Scope: Config loading and validation - actual feature flags/middleware deferred to later PRDs</p> <p>Dependencies: PRD-002 (CLI Foundation)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#context","title":"Context","text":"<p>With Cobra CLI in place (PRD-002), we need configuration file support. The pluggable architecture proposal defines a comprehensive config schema covering: - Server settings (name, version) - Transport settings (type, port, TLS) - Search strategy (bm25, semantic) - Execution settings (timeout, limits) - Backend configuration (local, MCP, API) - Middleware chain (logging, auth, rate limit)</p> <p>Current State: CLI flags only, no config file support</p> <p>Target State: <pre><code># metatools.yaml\nserver:\n  name: metatools-mcp\n  version: \"0.2.0\"\n\ntransport:\n  type: stdio  # or sse, http\n\nsearch:\n  strategy: bm25\n  bm25:\n    name_boost: 3.0\n\nexecution:\n  timeout: 30s\n  max_tool_calls: 64\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#task-1-add-koanf-dependency","title":"Task 1: Add Koanf Dependency","text":"<p>Files: - Modify: <code>go.mod</code> - Modify: <code>go.sum</code></p> <p>Step 1: Add Koanf with YAML and env providers</p> <p>Run: <pre><code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; \\\ngo get github.com/knadh/koanf/v2@v2.1.0 &amp;&amp; \\\ngo get github.com/knadh/koanf/parsers/yaml@v0.1.0 &amp;&amp; \\\ngo get github.com/knadh/koanf/providers/file@v0.1.0 &amp;&amp; \\\ngo get github.com/knadh/koanf/providers/env@v0.1.0 &amp;&amp; \\\ngo get github.com/knadh/koanf/providers/structs@v0.1.0\n</code></pre></p> <p>Step 2: Verify import works</p> <p>Run: <pre><code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go build ./...\n</code></pre> Expected: Build succeeds</p> <p>Step 3: Commit</p> <pre><code>git add go.mod go.sum\ngit commit -m \"$(cat &lt;&lt;'EOF'\ndeps: add Koanf configuration library with YAML and env providers\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#task-2-define-configuration-struct","title":"Task 2: Define Configuration Struct","text":"<p>Files: - Create: <code>internal/config/config.go</code> - Test: <code>internal/config/config_test.go</code></p> <p>Step 1: Write failing test for Config struct</p> <pre><code>// internal/config/config_test.go\npackage config\n\nimport (\n    \"testing\"\n    \"time\"\n)\n\nfunc TestDefaultConfig(t *testing.T) {\n    cfg := DefaultConfig()\n\n    // Server defaults\n    if cfg.Server.Name != \"metatools-mcp\" {\n        t.Errorf(\"Server.Name = %q, want %q\", cfg.Server.Name, \"metatools-mcp\")\n    }\n\n    // Transport defaults\n    if cfg.Transport.Type != \"stdio\" {\n        t.Errorf(\"Transport.Type = %q, want %q\", cfg.Transport.Type, \"stdio\")\n    }\n    if cfg.Transport.HTTP.Port != 8080 {\n        t.Errorf(\"Transport.HTTP.Port = %d, want %d\", cfg.Transport.HTTP.Port, 8080)\n    }\n\n    // Search defaults\n    if cfg.Search.Strategy != \"bm25\" {\n        t.Errorf(\"Search.Strategy = %q, want %q\", cfg.Search.Strategy, \"bm25\")\n    }\n\n    // Execution defaults\n    if cfg.Execution.Timeout != 30*time.Second {\n        t.Errorf(\"Execution.Timeout = %v, want %v\", cfg.Execution.Timeout, 30*time.Second)\n    }\n    if cfg.Execution.MaxToolCalls != 64 {\n        t.Errorf(\"Execution.MaxToolCalls = %d, want %d\", cfg.Execution.MaxToolCalls, 64)\n    }\n}\n\nfunc TestConfig_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        modify  func(*Config)\n        wantErr bool\n    }{\n        {\n            name:    \"default config is valid\",\n            modify:  func(c *Config) {},\n            wantErr: false,\n        },\n        {\n            name:    \"invalid transport type\",\n            modify:  func(c *Config) { c.Transport.Type = \"invalid\" },\n            wantErr: true,\n        },\n        {\n            name:    \"invalid search strategy\",\n            modify:  func(c *Config) { c.Search.Strategy = \"invalid\" },\n            wantErr: true,\n        },\n        {\n            name:    \"negative timeout\",\n            modify:  func(c *Config) { c.Execution.Timeout = -1 * time.Second },\n            wantErr: true,\n        },\n        {\n            name:    \"zero max tool calls uses default\",\n            modify:  func(c *Config) { c.Execution.MaxToolCalls = 0 },\n            wantErr: false,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            cfg := DefaultConfig()\n            tt.modify(&amp;cfg)\n            err := cfg.Validate()\n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Validate() error = %v, wantErr %v\", err, tt.wantErr)\n            }\n        })\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/config/... -v</code> Expected: FAIL - Config type doesn't exist</p> <p>Step 3: Implement Config struct</p> <pre><code>// internal/config/config.go\npackage config\n\nimport (\n    \"errors\"\n    \"fmt\"\n    \"time\"\n)\n\n// Config holds all metatools-mcp configuration.\ntype Config struct {\n    Server    ServerConfig    `koanf:\"server\"`\n    Transport TransportConfig `koanf:\"transport\"`\n    Search    SearchConfig    `koanf:\"search\"`\n    Execution ExecutionConfig `koanf:\"execution\"`\n    Providers ProvidersConfig `koanf:\"providers\"`\n    Backends  BackendsConfig  `koanf:\"backends\"`\n}\n\n// ServerConfig holds server identity settings.\ntype ServerConfig struct {\n    Name    string `koanf:\"name\"`\n    Version string `koanf:\"version\"`\n}\n\n// TransportConfig holds transport layer settings.\ntype TransportConfig struct {\n    Type string           `koanf:\"type\"`\n    HTTP HTTPConfig       `koanf:\"http\"`\n}\n\n// HTTPConfig holds HTTP transport settings.\ntype HTTPConfig struct {\n    Host     string `koanf:\"host\"`\n    Port     int    `koanf:\"port\"`\n    TLS      TLSConfig `koanf:\"tls\"`\n}\n\n// TLSConfig holds TLS settings.\ntype TLSConfig struct {\n    Enabled  bool   `koanf:\"enabled\"`\n    CertFile string `koanf:\"cert\"`\n    KeyFile  string `koanf:\"key\"`\n}\n\n// SearchConfig holds search strategy settings.\ntype SearchConfig struct {\n    Strategy string      `koanf:\"strategy\"`\n    BM25     BM25Config  `koanf:\"bm25\"`\n}\n\n// BM25Config holds BM25 search settings.\ntype BM25Config struct {\n    NameBoost      float64 `koanf:\"name_boost\"`\n    NamespaceBoost float64 `koanf:\"namespace_boost\"`\n    TagsBoost      float64 `koanf:\"tags_boost\"`\n    MaxDocs        int     `koanf:\"max_docs\"`\n    MaxDocTextLen  int     `koanf:\"max_doctext_len\"`\n}\n\n// ExecutionConfig holds tool execution settings.\ntype ExecutionConfig struct {\n    Timeout       time.Duration `koanf:\"timeout\"`\n    MaxToolCalls  int           `koanf:\"max_tool_calls\"`\n    MaxChainSteps int           `koanf:\"max_chain_steps\"`\n}\n\n// ProvidersConfig holds tool provider settings.\ntype ProvidersConfig struct {\n    SearchTools  ProviderEnabled `koanf:\"search_tools\"`\n    DescribeTool ProviderEnabled `koanf:\"describe_tool\"`\n    RunTool      ProviderEnabled `koanf:\"run_tool\"`\n    RunChain     ProviderEnabled `koanf:\"run_chain\"`\n    ExecuteCode  ExecuteCodeConfig `koanf:\"execute_code\"`\n}\n\n// ProviderEnabled is a simple on/off provider config.\ntype ProviderEnabled struct {\n    Enabled bool `koanf:\"enabled\"`\n}\n\n// ExecuteCodeConfig holds code execution provider settings.\ntype ExecuteCodeConfig struct {\n    Enabled bool   `koanf:\"enabled\"`\n    Sandbox string `koanf:\"sandbox\"`\n}\n\n// BackendsConfig holds backend source settings.\ntype BackendsConfig struct {\n    Local   LocalBackendConfig `koanf:\"local\"`\n    // Future: OpenAI, MCP, HTTP backends\n}\n\n// LocalBackendConfig holds local tool backend settings.\ntype LocalBackendConfig struct {\n    Enabled bool     `koanf:\"enabled\"`\n    Paths   []string `koanf:\"paths\"`\n    Watch   bool     `koanf:\"watch\"`\n}\n\n// Valid transport types.\nvar validTransports = map[string]bool{\n    \"stdio\": true,\n    \"sse\":   true,\n    \"http\":  true,\n}\n\n// Valid search strategies.\nvar validSearchStrategies = map[string]bool{\n    \"bm25\":     true,\n    \"lexical\":  true,\n    \"semantic\": true,\n}\n\n// DefaultConfig returns the default configuration.\nfunc DefaultConfig() Config {\n    return Config{\n        Server: ServerConfig{\n            Name:    \"metatools-mcp\",\n            Version: \"0.2.0\",\n        },\n        Transport: TransportConfig{\n            Type: \"stdio\",\n            HTTP: HTTPConfig{\n                Host: \"0.0.0.0\",\n                Port: 8080,\n            },\n        },\n        Search: SearchConfig{\n            Strategy: \"bm25\",\n            BM25: BM25Config{\n                NameBoost:      3.0,\n                NamespaceBoost: 2.0,\n                TagsBoost:      2.0,\n                MaxDocs:        0,        // unlimited\n                MaxDocTextLen:  0,        // unlimited\n            },\n        },\n        Execution: ExecutionConfig{\n            Timeout:       30 * time.Second,\n            MaxToolCalls:  64,\n            MaxChainSteps: 8,\n        },\n        Providers: ProvidersConfig{\n            SearchTools:  ProviderEnabled{Enabled: true},\n            DescribeTool: ProviderEnabled{Enabled: true},\n            RunTool:      ProviderEnabled{Enabled: true},\n            RunChain:     ProviderEnabled{Enabled: true},\n            ExecuteCode:  ExecuteCodeConfig{Enabled: false, Sandbox: \"dev\"},\n        },\n        Backends: BackendsConfig{\n            Local: LocalBackendConfig{\n                Enabled: true,\n                Paths:   []string{},\n                Watch:   false,\n            },\n        },\n    }\n}\n\n// Validate checks the configuration for errors.\nfunc (c *Config) Validate() error {\n    // Transport validation\n    if !validTransports[c.Transport.Type] {\n        return fmt.Errorf(\"invalid transport type %q, must be one of: stdio, sse, http\", c.Transport.Type)\n    }\n\n    // HTTP validation\n    if c.Transport.Type != \"stdio\" {\n        if c.Transport.HTTP.Port &lt;= 0 || c.Transport.HTTP.Port &gt; 65535 {\n            return fmt.Errorf(\"invalid port %d, must be 1-65535\", c.Transport.HTTP.Port)\n        }\n    }\n\n    // Search validation\n    if !validSearchStrategies[c.Search.Strategy] {\n        return fmt.Errorf(\"invalid search strategy %q, must be one of: bm25, lexical, semantic\", c.Search.Strategy)\n    }\n\n    // Execution validation\n    if c.Execution.Timeout &lt; 0 {\n        return errors.New(\"execution timeout cannot be negative\")\n    }\n\n    return nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/config/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/config/config.go internal/config/config_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(config): add Config struct with defaults and validation\n\nDefine configuration for:\n- Server (name, version)\n- Transport (type, HTTP settings)\n- Search (strategy, BM25 params)\n- Execution (timeout, limits)\n- Providers (enabled flags)\n- Backends (local paths)\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#task-3-implement-koanf-loader","title":"Task 3: Implement Koanf Loader","text":"<p>Files: - Create: <code>internal/config/loader.go</code> - Test: <code>internal/config/loader_test.go</code></p> <p>Step 1: Write failing test for config loading</p> <pre><code>// internal/config/loader_test.go\npackage config\n\nimport (\n    \"os\"\n    \"path/filepath\"\n    \"testing\"\n    \"time\"\n)\n\nfunc TestLoad_DefaultsWhenNoFile(t *testing.T) {\n    cfg, err := Load(\"\")\n    if err != nil {\n        t.Fatalf(\"Load() error = %v\", err)\n    }\n\n    // Should have defaults\n    if cfg.Transport.Type != \"stdio\" {\n        t.Errorf(\"Transport.Type = %q, want %q\", cfg.Transport.Type, \"stdio\")\n    }\n}\n\nfunc TestLoad_FromYAMLFile(t *testing.T) {\n    // Create temp config file\n    dir := t.TempDir()\n    configPath := filepath.Join(dir, \"metatools.yaml\")\n\n    yaml := `\nserver:\n  name: test-server\ntransport:\n  type: sse\n  http:\n    port: 9090\nsearch:\n  strategy: bm25\n  bm25:\n    name_boost: 5.0\nexecution:\n  timeout: 60s\n`\n    if err := os.WriteFile(configPath, []byte(yaml), 0644); err != nil {\n        t.Fatalf(\"WriteFile() error = %v\", err)\n    }\n\n    cfg, err := Load(configPath)\n    if err != nil {\n        t.Fatalf(\"Load() error = %v\", err)\n    }\n\n    if cfg.Server.Name != \"test-server\" {\n        t.Errorf(\"Server.Name = %q, want %q\", cfg.Server.Name, \"test-server\")\n    }\n    if cfg.Transport.Type != \"sse\" {\n        t.Errorf(\"Transport.Type = %q, want %q\", cfg.Transport.Type, \"sse\")\n    }\n    if cfg.Transport.HTTP.Port != 9090 {\n        t.Errorf(\"Transport.HTTP.Port = %d, want %d\", cfg.Transport.HTTP.Port, 9090)\n    }\n    if cfg.Search.BM25.NameBoost != 5.0 {\n        t.Errorf(\"Search.BM25.NameBoost = %f, want %f\", cfg.Search.BM25.NameBoost, 5.0)\n    }\n    if cfg.Execution.Timeout != 60*time.Second {\n        t.Errorf(\"Execution.Timeout = %v, want %v\", cfg.Execution.Timeout, 60*time.Second)\n    }\n}\n\nfunc TestLoad_EnvOverrides(t *testing.T) {\n    // Set env vars\n    os.Setenv(\"METATOOLS_TRANSPORT_TYPE\", \"http\")\n    os.Setenv(\"METATOOLS_TRANSPORT_HTTP_PORT\", \"3000\")\n    defer func() {\n        os.Unsetenv(\"METATOOLS_TRANSPORT_TYPE\")\n        os.Unsetenv(\"METATOOLS_TRANSPORT_HTTP_PORT\")\n    }()\n\n    cfg, err := Load(\"\")\n    if err != nil {\n        t.Fatalf(\"Load() error = %v\", err)\n    }\n\n    if cfg.Transport.Type != \"http\" {\n        t.Errorf(\"Transport.Type = %q, want %q from env\", cfg.Transport.Type, \"http\")\n    }\n    if cfg.Transport.HTTP.Port != 3000 {\n        t.Errorf(\"Transport.HTTP.Port = %d, want %d from env\", cfg.Transport.HTTP.Port, 3000)\n    }\n}\n\nfunc TestLoad_InvalidYAML(t *testing.T) {\n    dir := t.TempDir()\n    configPath := filepath.Join(dir, \"bad.yaml\")\n\n    if err := os.WriteFile(configPath, []byte(\"invalid: yaml: [\"), 0644); err != nil {\n        t.Fatalf(\"WriteFile() error = %v\", err)\n    }\n\n    _, err := Load(configPath)\n    if err == nil {\n        t.Error(\"Load() should fail with invalid YAML\")\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/config/... -run TestLoad -v</code> Expected: FAIL - Load function doesn't exist</p> <p>Step 3: Implement Koanf loader</p> <pre><code>// internal/config/loader.go\npackage config\n\nimport (\n    \"fmt\"\n    \"os\"\n    \"strings\"\n\n    \"github.com/knadh/koanf/parsers/yaml\"\n    \"github.com/knadh/koanf/providers/env\"\n    \"github.com/knadh/koanf/providers/file\"\n    \"github.com/knadh/koanf/providers/structs\"\n    \"github.com/knadh/koanf/v2\"\n)\n\n// Load loads configuration from file and environment.\n// Order of precedence (lowest to highest):\n// 1. Default values\n// 2. Config file (if path provided)\n// 3. Environment variables (METATOOLS_*)\nfunc Load(configPath string) (*Config, error) {\n    k := koanf.New(\".\")\n\n    // 1. Load defaults\n    defaults := DefaultConfig()\n    if err := k.Load(structs.Provider(defaults, \"koanf\"), nil); err != nil {\n        return nil, fmt.Errorf(\"load defaults: %w\", err)\n    }\n\n    // 2. Load config file if provided\n    if configPath != \"\" {\n        if _, err := os.Stat(configPath); err == nil {\n            if err := k.Load(file.Provider(configPath), yaml.Parser()); err != nil {\n                return nil, fmt.Errorf(\"load config file: %w\", err)\n            }\n        } else if !os.IsNotExist(err) {\n            return nil, fmt.Errorf(\"stat config file: %w\", err)\n        }\n    }\n\n    // 3. Load environment variables\n    // METATOOLS_TRANSPORT_TYPE -&gt; transport.type\n    envProvider := env.Provider(\"METATOOLS_\", \".\", func(s string) string {\n        return strings.Replace(\n            strings.ToLower(strings.TrimPrefix(s, \"METATOOLS_\")),\n            \"_\",\n            \".\",\n            -1,\n        )\n    })\n    if err := k.Load(envProvider, nil); err != nil {\n        return nil, fmt.Errorf(\"load env vars: %w\", err)\n    }\n\n    // Unmarshal to Config struct\n    var cfg Config\n    if err := k.Unmarshal(\"\", &amp;cfg); err != nil {\n        return nil, fmt.Errorf(\"unmarshal config: %w\", err)\n    }\n\n    // Validate\n    if err := cfg.Validate(); err != nil {\n        return nil, fmt.Errorf(\"validate config: %w\", err)\n    }\n\n    return &amp;cfg, nil\n}\n\n// MustLoad loads configuration or panics.\nfunc MustLoad(configPath string) *Config {\n    cfg, err := Load(configPath)\n    if err != nil {\n        panic(err)\n    }\n    return cfg\n}\n\n// LoadWithOverrides loads config with CLI flag overrides.\nfunc LoadWithOverrides(configPath string, overrides map[string]interface{}) (*Config, error) {\n    k := koanf.New(\".\")\n\n    // 1. Load defaults\n    defaults := DefaultConfig()\n    if err := k.Load(structs.Provider(defaults, \"koanf\"), nil); err != nil {\n        return nil, fmt.Errorf(\"load defaults: %w\", err)\n    }\n\n    // 2. Load config file\n    if configPath != \"\" {\n        if _, err := os.Stat(configPath); err == nil {\n            if err := k.Load(file.Provider(configPath), yaml.Parser()); err != nil {\n                return nil, fmt.Errorf(\"load config file: %w\", err)\n            }\n        }\n    }\n\n    // 3. Load environment variables\n    envProvider := env.Provider(\"METATOOLS_\", \".\", func(s string) string {\n        return strings.Replace(\n            strings.ToLower(strings.TrimPrefix(s, \"METATOOLS_\")),\n            \"_\",\n            \".\",\n            -1,\n        )\n    })\n    if err := k.Load(envProvider, nil); err != nil {\n        return nil, fmt.Errorf(\"load env vars: %w\", err)\n    }\n\n    // 4. Apply CLI overrides (highest precedence)\n    for key, value := range overrides {\n        k.Set(key, value)\n    }\n\n    // Unmarshal\n    var cfg Config\n    if err := k.Unmarshal(\"\", &amp;cfg); err != nil {\n        return nil, fmt.Errorf(\"unmarshal config: %w\", err)\n    }\n\n    // Validate\n    if err := cfg.Validate(); err != nil {\n        return nil, fmt.Errorf(\"validate config: %w\", err)\n    }\n\n    return &amp;cfg, nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/config/... -run TestLoad -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/config/loader.go internal/config/loader_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(config): implement Koanf config loader with env overrides\n\n- Load defaults, config file, then env vars (in order of precedence)\n- Support METATOOLS_* environment variables\n- Add LoadWithOverrides for CLI flag integration\n- Validate config after loading\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#task-4-integrate-config-with-serve-command","title":"Task 4: Integrate Config with Serve Command","text":"<p>Files: - Modify: <code>cmd/metatools-mcp/cmd/serve.go</code> - Test: <code>cmd/metatools-mcp/cmd/serve_test.go</code></p> <p>Step 1: Write integration test</p> <pre><code>// Add to serve_test.go\nfunc TestServeCmd_ConfigFile(t *testing.T) {\n    // Create temp config file\n    dir := t.TempDir()\n    configPath := filepath.Join(dir, \"metatools.yaml\")\n\n    yaml := `\ntransport:\n  type: sse\n  http:\n    port: 9999\n`\n    if err := os.WriteFile(configPath, []byte(yaml), 0644); err != nil {\n        t.Fatalf(\"WriteFile() error = %v\", err)\n    }\n\n    cfg, err := loadServeConfig(configPath, &amp;ServeConfig{})\n    if err != nil {\n        t.Fatalf(\"loadServeConfig() error = %v\", err)\n    }\n\n    if cfg.Transport.Type != \"sse\" {\n        t.Errorf(\"Transport.Type = %q, want %q\", cfg.Transport.Type, \"sse\")\n    }\n    if cfg.Transport.HTTP.Port != 9999 {\n        t.Errorf(\"Transport.HTTP.Port = %d, want %d\", cfg.Transport.HTTP.Port, 9999)\n    }\n}\n\nfunc TestServeCmd_CLIOverridesConfig(t *testing.T) {\n    // Create temp config file with port 9999\n    dir := t.TempDir()\n    configPath := filepath.Join(dir, \"metatools.yaml\")\n\n    yaml := `\ntransport:\n  type: sse\n  http:\n    port: 9999\n`\n    if err := os.WriteFile(configPath, []byte(yaml), 0644); err != nil {\n        t.Fatalf(\"WriteFile() error = %v\", err)\n    }\n\n    // CLI flag should override config file\n    cliCfg := &amp;ServeConfig{\n        Transport: \"http\",  // Override from CLI\n        Port:      3000,    // Override from CLI\n    }\n\n    cfg, err := loadServeConfig(configPath, cliCfg)\n    if err != nil {\n        t.Fatalf(\"loadServeConfig() error = %v\", err)\n    }\n\n    // CLI should win over config file\n    if cfg.Transport.Type != \"http\" {\n        t.Errorf(\"Transport.Type = %q, want %q from CLI\", cfg.Transport.Type, \"http\")\n    }\n    if cfg.Transport.HTTP.Port != 3000 {\n        t.Errorf(\"Transport.HTTP.Port = %d, want %d from CLI\", cfg.Transport.HTTP.Port, 3000)\n    }\n}\n</code></pre> <p>Step 2: Update serve.go to use config</p> <pre><code>// Update serve.go\nimport (\n    \"github.com/your-org/metatools-mcp/internal/config\"\n    // ... existing imports\n)\n\n// loadServeConfig loads config with CLI overrides.\nfunc loadServeConfig(configPath string, cli *ServeConfig) (*config.Config, error) {\n    // Build overrides from CLI flags\n    overrides := make(map[string]interface{})\n\n    // Only override if CLI flag was explicitly set (non-default)\n    if cli.Transport != \"\" &amp;&amp; cli.Transport != \"stdio\" {\n        overrides[\"transport.type\"] = cli.Transport\n    }\n    if cli.Port != 0 &amp;&amp; cli.Port != 8080 {\n        overrides[\"transport.http.port\"] = cli.Port\n    }\n    if cli.Host != \"\" &amp;&amp; cli.Host != \"0.0.0.0\" {\n        overrides[\"transport.http.host\"] = cli.Host\n    }\n\n    return config.LoadWithOverrides(configPath, overrides)\n}\n\n// Update runServe to use config\nfunc runServe(ctx context.Context, cliCfg *ServeConfig) error {\n    ctx, cancel := signal.NotifyContext(ctx, os.Interrupt, syscall.SIGTERM)\n    defer cancel()\n\n    // Load configuration\n    cfg, err := loadServeConfig(cliCfg.Config, cliCfg)\n    if err != nil {\n        return fmt.Errorf(\"load config: %w\", err)\n    }\n\n    // Build server from config\n    serverCfg, err := buildServerConfigFromConfig(cfg)\n    if err != nil {\n        return fmt.Errorf(\"build server config: %w\", err)\n    }\n\n    srv, err := server.New(serverCfg)\n    if err != nil {\n        return fmt.Errorf(\"create server: %w\", err)\n    }\n\n    // Select transport\n    var transport mcp.Transport\n    switch cfg.Transport.Type {\n    case \"stdio\":\n        transport = &amp;mcp.StdioTransport{}\n    case \"sse\", \"http\":\n        return fmt.Errorf(\"transport %q not yet implemented\", cfg.Transport.Type)\n    default:\n        return fmt.Errorf(\"unknown transport: %s\", cfg.Transport.Type)\n    }\n\n    fmt.Fprintf(os.Stderr, \"Starting %s (transport=%s)\\n\", cfg.Server.Name, cfg.Transport.Type)\n    return srv.Run(ctx, transport)\n}\n</code></pre> <p>Step 3: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -v</code> Expected: PASS</p> <p>Step 4: Commit</p> <pre><code>git add cmd/metatools-mcp/cmd/serve.go cmd/metatools-mcp/cmd/serve_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(cli): integrate Koanf config with serve command\n\n- Load config file via --config flag\n- CLI flags override config file values\n- Precedence: defaults &lt; config &lt; env &lt; CLI\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#task-5-add-config-validate-command","title":"Task 5: Add Config Validate Command","text":"<p>Files: - Create: <code>cmd/metatools-mcp/cmd/config.go</code> - Test: <code>cmd/metatools-mcp/cmd/config_test.go</code></p> <p>Step 1: Write failing test for config validate</p> <pre><code>// cmd/metatools-mcp/cmd/config_test.go\npackage cmd\n\nimport (\n    \"bytes\"\n    \"os\"\n    \"path/filepath\"\n    \"testing\"\n)\n\nfunc TestConfigValidateCmd(t *testing.T) {\n    t.Run(\"valid config\", func(t *testing.T) {\n        dir := t.TempDir()\n        configPath := filepath.Join(dir, \"metatools.yaml\")\n\n        yaml := `\nserver:\n  name: test\ntransport:\n  type: stdio\n`\n        os.WriteFile(configPath, []byte(yaml), 0644)\n\n        cmd := NewRootCmd()\n        buf := new(bytes.Buffer)\n        cmd.SetOut(buf)\n        cmd.SetArgs([]string{\"config\", \"validate\", \"--config\", configPath})\n\n        err := cmd.Execute()\n        if err != nil {\n            t.Fatalf(\"Execute() error = %v\", err)\n        }\n\n        if !contains(buf.String(), \"valid\") {\n            t.Errorf(\"Output should indicate config is valid, got: %s\", buf.String())\n        }\n    })\n\n    t.Run(\"invalid config\", func(t *testing.T) {\n        dir := t.TempDir()\n        configPath := filepath.Join(dir, \"metatools.yaml\")\n\n        yaml := `\ntransport:\n  type: invalid_transport\n`\n        os.WriteFile(configPath, []byte(yaml), 0644)\n\n        cmd := NewRootCmd()\n        cmd.SetArgs([]string{\"config\", \"validate\", \"--config\", configPath})\n\n        err := cmd.Execute()\n        if err == nil {\n            t.Error(\"Execute() should fail with invalid config\")\n        }\n    })\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -run TestConfigValidateCmd -v</code> Expected: FAIL - config command doesn't exist</p> <p>Step 3: Implement config command</p> <pre><code>// cmd/metatools-mcp/cmd/config.go\npackage cmd\n\nimport (\n    \"fmt\"\n\n    \"github.com/spf13/cobra\"\n    \"github.com/your-org/metatools-mcp/internal/config\"\n)\n\nfunc newConfigCmd() *cobra.Command {\n    cmd := &amp;cobra.Command{\n        Use:   \"config\",\n        Short: \"Configuration management commands\",\n        Long:  \"Commands for validating and inspecting configuration.\",\n    }\n\n    cmd.AddCommand(newConfigValidateCmd())\n    cmd.AddCommand(newConfigShowCmd())\n\n    return cmd\n}\n\nfunc newConfigValidateCmd() *cobra.Command {\n    var configPath string\n\n    cmd := &amp;cobra.Command{\n        Use:   \"validate\",\n        Short: \"Validate configuration file\",\n        Long:  \"Load and validate the configuration file, reporting any errors.\",\n        RunE: func(cmd *cobra.Command, args []string) error {\n            cfg, err := config.Load(configPath)\n            if err != nil {\n                return fmt.Errorf(\"configuration invalid: %w\", err)\n            }\n\n            fmt.Fprintln(cmd.OutOrStdout(), \"Configuration is valid\")\n            fmt.Fprintf(cmd.OutOrStdout(), \"  Server: %s\\n\", cfg.Server.Name)\n            fmt.Fprintf(cmd.OutOrStdout(), \"  Transport: %s\\n\", cfg.Transport.Type)\n            fmt.Fprintf(cmd.OutOrStdout(), \"  Search: %s\\n\", cfg.Search.Strategy)\n\n            return nil\n        },\n    }\n\n    cmd.Flags().StringVarP(&amp;configPath, \"config\", \"c\", \"\", \"Path to config file (required)\")\n    cmd.MarkFlagRequired(\"config\")\n\n    return cmd\n}\n\nfunc newConfigShowCmd() *cobra.Command {\n    var configPath string\n\n    cmd := &amp;cobra.Command{\n        Use:   \"show\",\n        Short: \"Show effective configuration\",\n        Long:  \"Load configuration and display the effective values after all merging.\",\n        RunE: func(cmd *cobra.Command, args []string) error {\n            cfg, err := config.Load(configPath)\n            if err != nil {\n                return err\n            }\n\n            // Pretty print config\n            fmt.Fprintf(cmd.OutOrStdout(), \"server:\\n\")\n            fmt.Fprintf(cmd.OutOrStdout(), \"  name: %s\\n\", cfg.Server.Name)\n            fmt.Fprintf(cmd.OutOrStdout(), \"  version: %s\\n\", cfg.Server.Version)\n            fmt.Fprintf(cmd.OutOrStdout(), \"\\ntransport:\\n\")\n            fmt.Fprintf(cmd.OutOrStdout(), \"  type: %s\\n\", cfg.Transport.Type)\n            fmt.Fprintf(cmd.OutOrStdout(), \"  http:\\n\")\n            fmt.Fprintf(cmd.OutOrStdout(), \"    host: %s\\n\", cfg.Transport.HTTP.Host)\n            fmt.Fprintf(cmd.OutOrStdout(), \"    port: %d\\n\", cfg.Transport.HTTP.Port)\n            fmt.Fprintf(cmd.OutOrStdout(), \"\\nsearch:\\n\")\n            fmt.Fprintf(cmd.OutOrStdout(), \"  strategy: %s\\n\", cfg.Search.Strategy)\n            fmt.Fprintf(cmd.OutOrStdout(), \"\\nexecution:\\n\")\n            fmt.Fprintf(cmd.OutOrStdout(), \"  timeout: %s\\n\", cfg.Execution.Timeout)\n            fmt.Fprintf(cmd.OutOrStdout(), \"  max_tool_calls: %d\\n\", cfg.Execution.MaxToolCalls)\n\n            return nil\n        },\n    }\n\n    cmd.Flags().StringVarP(&amp;configPath, \"config\", \"c\", \"\", \"Path to config file\")\n\n    return cmd\n}\n</code></pre> <p>Step 4: Add config command to root</p> <p>Update <code>root.go</code>: <pre><code>func NewRootCmd() *cobra.Command {\n    // ... existing code ...\n\n    rootCmd.AddCommand(newServeCmd())\n    rootCmd.AddCommand(newVersionCmd())\n    rootCmd.AddCommand(newConfigCmd())  // Add this line\n\n    return rootCmd\n}\n</code></pre></p> <p>Step 5: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./cmd/metatools-mcp/cmd/... -run TestConfigValidateCmd -v</code> Expected: PASS</p> <p>Step 6: Commit</p> <pre><code>git add cmd/metatools-mcp/cmd/config.go cmd/metatools-mcp/cmd/config_test.go cmd/metatools-mcp/cmd/root.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(cli): add config validate and show subcommands\n\n- 'config validate' loads and validates config file\n- 'config show' displays effective configuration after merging\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#task-6-create-example-config-file","title":"Task 6: Create Example Config File","text":"<p>Files: - Create: <code>metatools.example.yaml</code></p> <p>Step 1: Create example config</p> <pre><code># metatools.example.yaml\n# Example configuration for metatools-mcp\n# Copy to metatools.yaml and customize\n\nserver:\n  name: metatools-mcp\n  version: \"0.2.0\"\n\n# Transport configuration\ntransport:\n  type: stdio  # stdio | sse | http\n\n  # HTTP settings (used when type is sse or http)\n  http:\n    host: \"0.0.0.0\"\n    port: 8080\n    tls:\n      enabled: false\n      cert: /etc/ssl/cert.pem\n      key: /etc/ssl/key.pem\n\n# Search strategy configuration\nsearch:\n  strategy: bm25  # bm25 | lexical | semantic\n\n  # BM25-specific settings\n  bm25:\n    name_boost: 3.0\n    namespace_boost: 2.0\n    tags_boost: 2.0\n    max_docs: 0        # 0 = unlimited\n    max_doctext_len: 0  # 0 = unlimited\n\n# Execution settings\nexecution:\n  timeout: 30s\n  max_tool_calls: 64\n  max_chain_steps: 8\n\n# Tool provider settings\nproviders:\n  search_tools:\n    enabled: true\n  describe_tool:\n    enabled: true\n  run_tool:\n    enabled: true\n  run_chain:\n    enabled: true\n  execute_code:\n    enabled: false  # Requires toolruntime build tag\n    sandbox: dev    # dev | standard | hardened\n\n# Backend settings\nbackends:\n  local:\n    enabled: true\n    paths:\n      - ~/.config/metatools/tools\n      - /usr/share/metatools/tools\n    watch: false  # Hot reload on changes\n\n# Environment variable overrides:\n# METATOOLS_TRANSPORT_TYPE=sse\n# METATOOLS_TRANSPORT_HTTP_PORT=9090\n# METATOOLS_SEARCH_STRATEGY=semantic\n# METATOOLS_EXECUTION_TIMEOUT=60s\n</code></pre> <p>Step 2: Commit</p> <pre><code>git add metatools.example.yaml\ngit commit -m \"$(cat &lt;&lt;'EOF'\ndocs: add example configuration file\n\nComplete example showing all configuration options with documentation.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Koanf dependency added</li> <li>[ ] Config struct with all fields</li> <li>[ ] DefaultConfig() with sensible defaults</li> <li>[ ] Validate() with error messages</li> <li>[ ] Load() from file + env</li> <li>[ ] LoadWithOverrides() for CLI integration</li> <li>[ ] Serve command uses config</li> <li>[ ] Config validate command works</li> <li>[ ] Config show command works</li> <li>[ ] Example config file</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#definition-of-done","title":"Definition of Done","text":"<ol> <li>All tests pass: <code>go test ./internal/config/... &amp;&amp; go test ./cmd/metatools-mcp/cmd/...</code></li> <li><code>metatools-mcp config validate --config=metatools.yaml</code> validates config</li> <li><code>metatools-mcp config show</code> displays effective config</li> <li><code>metatools-mcp serve --config=metatools.yaml</code> uses config file</li> <li>Environment variables override config file</li> <li>CLI flags override environment variables</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-003-koanf-config/#next-prd","title":"Next PRD","text":"<p>PRD-004 will implement the SSE Transport Layer, enabling HTTP/SSE mode for web clients.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/","title":"PRD-004: SSE Transport Layer","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement the Server-Sent Events (SSE) transport layer enabling metatools-mcp to serve web clients and support concurrent connections.</p> <p>Architecture: Create a Transport interface that abstracts protocol details. Implement SSETransport using net/http with proper SSE headers, event streaming, and connection management. The existing stdio behavior becomes StdioTransport implementing the same interface.</p> <p>Tech Stack: net/http, SSE protocol (text/event-stream), existing MCP handler logic</p> <p>Priority: P1 - Stream A, Phase 2 (enables web clients)</p> <p>Scope: Transport abstraction + SSE implementation only - HTTP/REST deferred</p> <p>Dependencies: PRD-002 (CLI), PRD-003 (Config)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#context","title":"Context","text":"<p>With CLI and config foundation in place, we need HTTP transport for web clients. The MCP protocol supports SSE for server-to-client streaming. This enables: - Web-based chat interfaces - Multiple concurrent clients - Load-balanced deployments - Streaming responses</p> <p>Current State: Only stdio transport, hardcoded</p> <p>Target State: <pre><code>metatools-mcp serve --transport=sse --port=8080\n# Client connects: POST /mcp \u2192 SSE response stream\n</code></pre></p> <p>MCP SSE Protocol: 1. Client POSTs JSON-RPC request to <code>/mcp</code> 2. Server responds with <code>Content-Type: text/event-stream</code> 3. Server sends SSE events: <code>event: message\\ndata: {...}\\n\\n</code> 4. Connection closes after response (or stays open for streaming tools)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#task-1-define-transport-interface","title":"Task 1: Define Transport Interface","text":"<p>Files: - Create: <code>internal/transport/transport.go</code> - Test: <code>internal/transport/transport_test.go</code></p> <p>Step 1: Write failing test for Transport interface</p> <pre><code>// internal/transport/transport_test.go\npackage transport\n\nimport (\n    \"context\"\n    \"testing\"\n)\n\nfunc TestTransportInterface(t *testing.T) {\n    // Verify interface is defined correctly\n    var _ Transport = (*StdioTransport)(nil)\n    var _ Transport = (*SSETransport)(nil)\n}\n\nfunc TestTransportInfo(t *testing.T) {\n    tests := []struct {\n        name      string\n        transport Transport\n        wantName  string\n    }{\n        {\n            name:      \"stdio transport\",\n            transport: &amp;StdioTransport{},\n            wantName:  \"stdio\",\n        },\n        {\n            name:      \"sse transport\",\n            transport: &amp;SSETransport{Config: SSEConfig{Port: 8080}},\n            wantName:  \"sse\",\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            info := tt.transport.Info()\n            if info.Name != tt.wantName {\n                t.Errorf(\"Info().Name = %q, want %q\", info.Name, tt.wantName)\n            }\n        })\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/transport/... -v</code> Expected: FAIL - Transport type doesn't exist</p> <p>Step 3: Implement Transport interface</p> <pre><code>// internal/transport/transport.go\npackage transport\n\nimport (\n    \"context\"\n)\n\n// Transport defines the interface for MCP protocol transports.\ntype Transport interface {\n    // Name returns the transport identifier.\n    Name() string\n\n    // Serve starts the transport and blocks until context is cancelled.\n    Serve(ctx context.Context, handler Handler) error\n\n    // Close gracefully shuts down the transport.\n    Close() error\n\n    // Info returns transport metadata.\n    Info() TransportInfo\n}\n\n// TransportInfo provides metadata about a transport.\ntype TransportInfo struct {\n    Name     string\n    Address  string // e.g., \"localhost:8080\" for HTTP, \"stdio\" for stdio\n    Protocol string // e.g., \"MCP/1.0\"\n}\n\n// Handler processes MCP requests.\ntype Handler interface {\n    // HandleRequest processes a single MCP request and returns the response.\n    HandleRequest(ctx context.Context, request []byte) ([]byte, error)\n\n    // HandleStream processes a streaming MCP request.\n    // Returns a channel that will receive response events.\n    HandleStream(ctx context.Context, request []byte) (&lt;-chan []byte, error)\n}\n\n// TransportFactory creates transports from configuration.\ntype TransportFactory func(cfg interface{}) (Transport, error)\n\n// Registry holds registered transport factories.\ntype Registry struct {\n    factories map[string]TransportFactory\n}\n\n// NewRegistry creates a new transport registry.\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        factories: make(map[string]TransportFactory),\n    }\n}\n\n// Register adds a transport factory to the registry.\nfunc (r *Registry) Register(name string, factory TransportFactory) {\n    r.factories[name] = factory\n}\n\n// Create creates a transport by name.\nfunc (r *Registry) Create(name string, cfg interface{}) (Transport, error) {\n    factory, ok := r.factories[name]\n    if !ok {\n        return nil, ErrUnknownTransport{Name: name}\n    }\n    return factory(cfg)\n}\n\n// ErrUnknownTransport is returned when a transport is not found.\ntype ErrUnknownTransport struct {\n    Name string\n}\n\nfunc (e ErrUnknownTransport) Error() string {\n    return \"unknown transport: \" + e.Name\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/transport/... -v</code> Expected: PASS (after adding stub types in next tasks)</p> <p>Step 5: Commit</p> <pre><code>git add internal/transport/transport.go internal/transport/transport_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(transport): define Transport interface and registry\n\n- Transport interface with Serve, Close, Info methods\n- Handler interface for MCP request processing\n- TransportFactory and Registry for pluggable transports\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#task-2-implement-stdiotransport","title":"Task 2: Implement StdioTransport","text":"<p>Files: - Create: <code>internal/transport/stdio.go</code> - Test: <code>internal/transport/stdio_test.go</code></p> <p>Step 1: Write failing test for StdioTransport</p> <pre><code>// internal/transport/stdio_test.go\npackage transport\n\nimport (\n    \"bytes\"\n    \"context\"\n    \"io\"\n    \"testing\"\n)\n\ntype mockHandler struct {\n    response []byte\n}\n\nfunc (m *mockHandler) HandleRequest(ctx context.Context, request []byte) ([]byte, error) {\n    return m.response, nil\n}\n\nfunc (m *mockHandler) HandleStream(ctx context.Context, request []byte) (&lt;-chan []byte, error) {\n    ch := make(chan []byte, 1)\n    ch &lt;- m.response\n    close(ch)\n    return ch, nil\n}\n\nfunc TestStdioTransport_Name(t *testing.T) {\n    transport := &amp;StdioTransport{}\n    if got := transport.Name(); got != \"stdio\" {\n        t.Errorf(\"Name() = %q, want %q\", got, \"stdio\")\n    }\n}\n\nfunc TestStdioTransport_Info(t *testing.T) {\n    transport := &amp;StdioTransport{}\n    info := transport.Info()\n\n    if info.Name != \"stdio\" {\n        t.Errorf(\"Info().Name = %q, want %q\", info.Name, \"stdio\")\n    }\n    if info.Address != \"stdio\" {\n        t.Errorf(\"Info().Address = %q, want %q\", info.Address, \"stdio\")\n    }\n}\n\nfunc TestStdioTransport_Serve(t *testing.T) {\n    // Create pipes for testing\n    inputRead, inputWrite := io.Pipe()\n    outputRead, outputWrite := io.Pipe()\n\n    transport := &amp;StdioTransport{\n        Input:  inputRead,\n        Output: outputWrite,\n    }\n\n    handler := &amp;mockHandler{\n        response: []byte(`{\"jsonrpc\":\"2.0\",\"result\":\"ok\",\"id\":1}`),\n    }\n\n    ctx, cancel := context.WithCancel(context.Background())\n    defer cancel()\n\n    // Start server in goroutine\n    errCh := make(chan error, 1)\n    go func() {\n        errCh &lt;- transport.Serve(ctx, handler)\n    }()\n\n    // Send a request\n    request := []byte(`{\"jsonrpc\":\"2.0\",\"method\":\"test\",\"id\":1}`)\n    go func() {\n        inputWrite.Write(request)\n        inputWrite.Close()\n    }()\n\n    // Read response\n    response, err := io.ReadAll(outputRead)\n    if err != nil {\n        t.Fatalf(\"ReadAll() error = %v\", err)\n    }\n\n    if !bytes.Contains(response, []byte(\"ok\")) {\n        t.Errorf(\"Response should contain 'ok', got: %s\", response)\n    }\n\n    // Stop server\n    cancel()\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/transport/... -run TestStdioTransport -v</code> Expected: FAIL - StdioTransport not implemented</p> <p>Step 3: Implement StdioTransport</p> <pre><code>// internal/transport/stdio.go\npackage transport\n\nimport (\n    \"bufio\"\n    \"context\"\n    \"io\"\n    \"os\"\n    \"sync\"\n)\n\n// StdioTransport implements Transport for stdio-based MCP communication.\ntype StdioTransport struct {\n    Input  io.Reader\n    Output io.Writer\n\n    mu     sync.Mutex\n    closed bool\n}\n\n// NewStdioTransport creates a stdio transport using os.Stdin and os.Stdout.\nfunc NewStdioTransport() *StdioTransport {\n    return &amp;StdioTransport{\n        Input:  os.Stdin,\n        Output: os.Stdout,\n    }\n}\n\n// Name returns \"stdio\".\nfunc (t *StdioTransport) Name() string {\n    return \"stdio\"\n}\n\n// Info returns transport metadata.\nfunc (t *StdioTransport) Info() TransportInfo {\n    return TransportInfo{\n        Name:     \"stdio\",\n        Address:  \"stdio\",\n        Protocol: \"MCP/1.0\",\n    }\n}\n\n// Serve reads requests from stdin and writes responses to stdout.\nfunc (t *StdioTransport) Serve(ctx context.Context, handler Handler) error {\n    reader := bufio.NewReader(t.Input)\n\n    for {\n        select {\n        case &lt;-ctx.Done():\n            return ctx.Err()\n        default:\n        }\n\n        // Read line (JSON-RPC messages are newline-delimited)\n        line, err := reader.ReadBytes('\\n')\n        if err != nil {\n            if err == io.EOF {\n                return nil // Normal termination\n            }\n            return err\n        }\n\n        // Skip empty lines\n        if len(line) &lt;= 1 {\n            continue\n        }\n\n        // Process request\n        response, err := handler.HandleRequest(ctx, line)\n        if err != nil {\n            // Log error but continue processing\n            continue\n        }\n\n        // Write response\n        t.mu.Lock()\n        _, err = t.Output.Write(response)\n        if err == nil {\n            _, err = t.Output.Write([]byte(\"\\n\"))\n        }\n        t.mu.Unlock()\n\n        if err != nil {\n            return err\n        }\n    }\n}\n\n// Close marks the transport as closed.\nfunc (t *StdioTransport) Close() error {\n    t.mu.Lock()\n    defer t.mu.Unlock()\n    t.closed = true\n    return nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/transport/... -run TestStdioTransport -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/transport/stdio.go internal/transport/stdio_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(transport): implement StdioTransport\n\n- Read JSON-RPC messages from stdin\n- Write responses to stdout\n- Support context cancellation\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#task-3-implement-ssetransport-configuration","title":"Task 3: Implement SSETransport Configuration","text":"<p>Files: - Create: <code>internal/transport/sse_config.go</code> - Test: <code>internal/transport/sse_config_test.go</code></p> <p>Step 1: Write failing test for SSE config</p> <pre><code>// internal/transport/sse_config_test.go\npackage transport\n\nimport (\n    \"testing\"\n    \"time\"\n)\n\nfunc TestSSEConfig_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        config  SSEConfig\n        wantErr bool\n    }{\n        {\n            name:    \"valid config\",\n            config:  SSEConfig{Host: \"0.0.0.0\", Port: 8080},\n            wantErr: false,\n        },\n        {\n            name:    \"zero port invalid\",\n            config:  SSEConfig{Host: \"0.0.0.0\", Port: 0},\n            wantErr: true,\n        },\n        {\n            name:    \"port too high\",\n            config:  SSEConfig{Host: \"0.0.0.0\", Port: 70000},\n            wantErr: true,\n        },\n        {\n            name:    \"negative timeout\",\n            config:  SSEConfig{Host: \"0.0.0.0\", Port: 8080, ReadTimeout: -1 * time.Second},\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            err := tt.config.Validate()\n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Validate() error = %v, wantErr %v\", err, tt.wantErr)\n            }\n        })\n    }\n}\n\nfunc TestSSEConfig_Defaults(t *testing.T) {\n    cfg := DefaultSSEConfig()\n\n    if cfg.Port != 8080 {\n        t.Errorf(\"Port = %d, want %d\", cfg.Port, 8080)\n    }\n    if cfg.ReadTimeout != 30*time.Second {\n        t.Errorf(\"ReadTimeout = %v, want %v\", cfg.ReadTimeout, 30*time.Second)\n    }\n    if cfg.WriteTimeout != 30*time.Second {\n        t.Errorf(\"WriteTimeout = %v, want %v\", cfg.WriteTimeout, 30*time.Second)\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/transport/... -run TestSSEConfig -v</code> Expected: FAIL - SSEConfig doesn't exist</p> <p>Step 3: Implement SSEConfig</p> <pre><code>// internal/transport/sse_config.go\npackage transport\n\nimport (\n    \"errors\"\n    \"fmt\"\n    \"time\"\n)\n\n// SSEConfig holds SSE transport configuration.\ntype SSEConfig struct {\n    // Host to bind to (default: \"0.0.0.0\")\n    Host string\n\n    // Port to listen on (default: 8080)\n    Port int\n\n    // ReadTimeout for incoming requests\n    ReadTimeout time.Duration\n\n    // WriteTimeout for outgoing responses\n    WriteTimeout time.Duration\n\n    // IdleTimeout for keep-alive connections\n    IdleTimeout time.Duration\n\n    // CORSOrigins allowed for cross-origin requests\n    CORSOrigins []string\n\n    // TLS configuration\n    TLSCert string\n    TLSKey  string\n\n    // MaxRequestSize in bytes (default: 1MB)\n    MaxRequestSize int64\n}\n\n// DefaultSSEConfig returns sensible defaults for SSE transport.\nfunc DefaultSSEConfig() SSEConfig {\n    return SSEConfig{\n        Host:           \"0.0.0.0\",\n        Port:           8080,\n        ReadTimeout:    30 * time.Second,\n        WriteTimeout:   30 * time.Second,\n        IdleTimeout:    120 * time.Second,\n        CORSOrigins:    []string{\"*\"},\n        MaxRequestSize: 1 &lt;&lt; 20, // 1MB\n    }\n}\n\n// Validate checks the configuration for errors.\nfunc (c *SSEConfig) Validate() error {\n    if c.Port &lt;= 0 || c.Port &gt; 65535 {\n        return fmt.Errorf(\"invalid port %d, must be 1-65535\", c.Port)\n    }\n    if c.ReadTimeout &lt; 0 {\n        return errors.New(\"read timeout cannot be negative\")\n    }\n    if c.WriteTimeout &lt; 0 {\n        return errors.New(\"write timeout cannot be negative\")\n    }\n    if c.IdleTimeout &lt; 0 {\n        return errors.New(\"idle timeout cannot be negative\")\n    }\n    return nil\n}\n\n// Address returns the listen address as \"host:port\".\nfunc (c *SSEConfig) Address() string {\n    return fmt.Sprintf(\"%s:%d\", c.Host, c.Port)\n}\n\n// WithDefaults fills zero values with defaults.\nfunc (c SSEConfig) WithDefaults() SSEConfig {\n    defaults := DefaultSSEConfig()\n\n    if c.Host == \"\" {\n        c.Host = defaults.Host\n    }\n    if c.Port == 0 {\n        c.Port = defaults.Port\n    }\n    if c.ReadTimeout == 0 {\n        c.ReadTimeout = defaults.ReadTimeout\n    }\n    if c.WriteTimeout == 0 {\n        c.WriteTimeout = defaults.WriteTimeout\n    }\n    if c.IdleTimeout == 0 {\n        c.IdleTimeout = defaults.IdleTimeout\n    }\n    if len(c.CORSOrigins) == 0 {\n        c.CORSOrigins = defaults.CORSOrigins\n    }\n    if c.MaxRequestSize == 0 {\n        c.MaxRequestSize = defaults.MaxRequestSize\n    }\n\n    return c\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/transport/... -run TestSSEConfig -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/transport/sse_config.go internal/transport/sse_config_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(transport): add SSEConfig with validation and defaults\n\n- Host, Port, Timeouts, CORS, TLS settings\n- Validation for required fields\n- WithDefaults() for zero-value handling\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#task-4-implement-ssetransport-server","title":"Task 4: Implement SSETransport Server","text":"<p>Files: - Create: <code>internal/transport/sse.go</code> - Test: <code>internal/transport/sse_test.go</code></p> <p>Step 1: Write failing test for SSE transport</p> <pre><code>// internal/transport/sse_test.go\npackage transport\n\nimport (\n    \"bytes\"\n    \"context\"\n    \"io\"\n    \"net/http\"\n    \"net/http/httptest\"\n    \"strings\"\n    \"testing\"\n    \"time\"\n)\n\nfunc TestSSETransport_Name(t *testing.T) {\n    transport := NewSSETransport(SSEConfig{Port: 8080})\n    if got := transport.Name(); got != \"sse\" {\n        t.Errorf(\"Name() = %q, want %q\", got, \"sse\")\n    }\n}\n\nfunc TestSSETransport_Info(t *testing.T) {\n    transport := NewSSETransport(SSEConfig{Host: \"localhost\", Port: 9090})\n    info := transport.Info()\n\n    if info.Name != \"sse\" {\n        t.Errorf(\"Info().Name = %q, want %q\", info.Name, \"sse\")\n    }\n    if info.Address != \"localhost:9090\" {\n        t.Errorf(\"Info().Address = %q, want %q\", info.Address, \"localhost:9090\")\n    }\n}\n\nfunc TestSSETransport_HandleRequest(t *testing.T) {\n    handler := &amp;mockHandler{\n        response: []byte(`{\"jsonrpc\":\"2.0\",\"result\":\"hello\",\"id\":1}`),\n    }\n\n    transport := NewSSETransport(SSEConfig{Port: 0}) // Port 0 for testing\n\n    // Create test request\n    body := bytes.NewReader([]byte(`{\"jsonrpc\":\"2.0\",\"method\":\"test\",\"id\":1}`))\n    req := httptest.NewRequest(http.MethodPost, \"/mcp\", body)\n    req.Header.Set(\"Content-Type\", \"application/json\")\n\n    rec := httptest.NewRecorder()\n\n    // Handle request directly (without starting server)\n    transport.handleMCP(rec, req, handler)\n\n    resp := rec.Result()\n    defer resp.Body.Close()\n\n    // Check SSE headers\n    if ct := resp.Header.Get(\"Content-Type\"); !strings.HasPrefix(ct, \"text/event-stream\") {\n        t.Errorf(\"Content-Type = %q, want text/event-stream\", ct)\n    }\n\n    // Check response body\n    respBody, _ := io.ReadAll(resp.Body)\n    if !bytes.Contains(respBody, []byte(\"hello\")) {\n        t.Errorf(\"Response should contain 'hello', got: %s\", respBody)\n    }\n    if !bytes.Contains(respBody, []byte(\"event: message\")) {\n        t.Errorf(\"Response should contain SSE event, got: %s\", respBody)\n    }\n}\n\nfunc TestSSETransport_CORS(t *testing.T) {\n    handler := &amp;mockHandler{\n        response: []byte(`{\"jsonrpc\":\"2.0\",\"result\":\"ok\",\"id\":1}`),\n    }\n\n    transport := NewSSETransport(SSEConfig{\n        Port:        0,\n        CORSOrigins: []string{\"https://example.com\"},\n    })\n\n    // OPTIONS request (CORS preflight)\n    req := httptest.NewRequest(http.MethodOptions, \"/mcp\", nil)\n    req.Header.Set(\"Origin\", \"https://example.com\")\n    rec := httptest.NewRecorder()\n\n    transport.handleMCP(rec, req, handler)\n\n    resp := rec.Result()\n    if resp.Header.Get(\"Access-Control-Allow-Origin\") != \"https://example.com\" {\n        t.Errorf(\"CORS header not set correctly\")\n    }\n}\n\nfunc TestSSETransport_Serve(t *testing.T) {\n    handler := &amp;mockHandler{\n        response: []byte(`{\"jsonrpc\":\"2.0\",\"result\":\"test\",\"id\":1}`),\n    }\n\n    transport := NewSSETransport(SSEConfig{\n        Host: \"127.0.0.1\",\n        Port: 0, // Random available port\n    })\n\n    ctx, cancel := context.WithCancel(context.Background())\n    defer cancel()\n\n    // Start server in goroutine\n    errCh := make(chan error, 1)\n    go func() {\n        errCh &lt;- transport.Serve(ctx, handler)\n    }()\n\n    // Wait for server to start\n    time.Sleep(100 * time.Millisecond)\n\n    // Server should be running (we can't easily test the full flow here)\n    // Just verify it starts without error\n    cancel()\n\n    select {\n    case err := &lt;-errCh:\n        if err != nil &amp;&amp; err != context.Canceled &amp;&amp; err != http.ErrServerClosed {\n            t.Errorf(\"Serve() error = %v\", err)\n        }\n    case &lt;-time.After(time.Second):\n        t.Error(\"Serve() did not return after cancel\")\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/transport/... -run TestSSETransport -v</code> Expected: FAIL - SSETransport not implemented</p> <p>Step 3: Implement SSETransport</p> <pre><code>// internal/transport/sse.go\npackage transport\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"io\"\n    \"net\"\n    \"net/http\"\n    \"sync\"\n    \"time\"\n)\n\n// SSETransport implements Transport for HTTP/SSE-based MCP communication.\ntype SSETransport struct {\n    Config SSEConfig\n\n    server   *http.Server\n    listener net.Listener\n    mu       sync.Mutex\n}\n\n// NewSSETransport creates a new SSE transport with the given configuration.\nfunc NewSSETransport(cfg SSEConfig) *SSETransport {\n    return &amp;SSETransport{\n        Config: cfg.WithDefaults(),\n    }\n}\n\n// Name returns \"sse\".\nfunc (t *SSETransport) Name() string {\n    return \"sse\"\n}\n\n// Info returns transport metadata.\nfunc (t *SSETransport) Info() TransportInfo {\n    return TransportInfo{\n        Name:     \"sse\",\n        Address:  t.Config.Address(),\n        Protocol: \"MCP/1.0\",\n    }\n}\n\n// Serve starts the HTTP server and blocks until context is cancelled.\nfunc (t *SSETransport) Serve(ctx context.Context, handler Handler) error {\n    mux := http.NewServeMux()\n\n    // MCP endpoint\n    mux.HandleFunc(\"/mcp\", func(w http.ResponseWriter, r *http.Request) {\n        t.handleMCP(w, r, handler)\n    })\n\n    // Health check\n    mux.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n        w.Header().Set(\"Content-Type\", \"application/json\")\n        w.WriteHeader(http.StatusOK)\n        json.NewEncoder(w).Encode(map[string]string{\"status\": \"ok\"})\n    })\n\n    t.server = &amp;http.Server{\n        Addr:         t.Config.Address(),\n        Handler:      mux,\n        ReadTimeout:  t.Config.ReadTimeout,\n        WriteTimeout: t.Config.WriteTimeout,\n        IdleTimeout:  t.Config.IdleTimeout,\n    }\n\n    // Start listening\n    var err error\n    t.listener, err = net.Listen(\"tcp\", t.Config.Address())\n    if err != nil {\n        return fmt.Errorf(\"listen: %w\", err)\n    }\n\n    // Handle graceful shutdown\n    go func() {\n        &lt;-ctx.Done()\n        shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n        defer cancel()\n        t.server.Shutdown(shutdownCtx)\n    }()\n\n    // Serve requests\n    if t.Config.TLSCert != \"\" &amp;&amp; t.Config.TLSKey != \"\" {\n        err = t.server.ServeTLS(t.listener, t.Config.TLSCert, t.Config.TLSKey)\n    } else {\n        err = t.server.Serve(t.listener)\n    }\n\n    if err == http.ErrServerClosed {\n        return nil\n    }\n    return err\n}\n\n// Close shuts down the server.\nfunc (t *SSETransport) Close() error {\n    t.mu.Lock()\n    defer t.mu.Unlock()\n\n    if t.server != nil {\n        return t.server.Close()\n    }\n    return nil\n}\n\n// handleMCP processes MCP requests with SSE response.\nfunc (t *SSETransport) handleMCP(w http.ResponseWriter, r *http.Request, handler Handler) {\n    // Handle CORS\n    t.setCORSHeaders(w, r)\n    if r.Method == http.MethodOptions {\n        w.WriteHeader(http.StatusOK)\n        return\n    }\n\n    // Only accept POST\n    if r.Method != http.MethodPost {\n        http.Error(w, \"Method not allowed\", http.StatusMethodNotAllowed)\n        return\n    }\n\n    // Read request body\n    body, err := io.ReadAll(io.LimitReader(r.Body, t.Config.MaxRequestSize))\n    if err != nil {\n        http.Error(w, \"Failed to read request\", http.StatusBadRequest)\n        return\n    }\n    defer r.Body.Close()\n\n    // Set SSE headers\n    w.Header().Set(\"Content-Type\", \"text/event-stream\")\n    w.Header().Set(\"Cache-Control\", \"no-cache\")\n    w.Header().Set(\"Connection\", \"keep-alive\")\n    w.Header().Set(\"X-Accel-Buffering\", \"no\") // Disable nginx buffering\n\n    // Flush headers\n    if f, ok := w.(http.Flusher); ok {\n        f.Flush()\n    }\n\n    // Process request\n    response, err := handler.HandleRequest(r.Context(), body)\n    if err != nil {\n        t.writeSSEEvent(w, \"error\", []byte(fmt.Sprintf(`{\"error\":\"%s\"}`, err.Error())))\n        return\n    }\n\n    // Write response as SSE event\n    t.writeSSEEvent(w, \"message\", response)\n\n    // Write done event\n    t.writeSSEEvent(w, \"done\", []byte(\"{}\"))\n}\n\n// writeSSEEvent writes a single SSE event.\nfunc (t *SSETransport) writeSSEEvent(w http.ResponseWriter, event string, data []byte) {\n    fmt.Fprintf(w, \"event: %s\\n\", event)\n    fmt.Fprintf(w, \"data: %s\\n\\n\", data)\n\n    if f, ok := w.(http.Flusher); ok {\n        f.Flush()\n    }\n}\n\n// setCORSHeaders sets CORS headers based on configuration.\nfunc (t *SSETransport) setCORSHeaders(w http.ResponseWriter, r *http.Request) {\n    origin := r.Header.Get(\"Origin\")\n    if origin == \"\" {\n        return\n    }\n\n    // Check if origin is allowed\n    allowed := false\n    for _, o := range t.Config.CORSOrigins {\n        if o == \"*\" || o == origin {\n            allowed = true\n            break\n        }\n    }\n\n    if allowed {\n        w.Header().Set(\"Access-Control-Allow-Origin\", origin)\n        w.Header().Set(\"Access-Control-Allow-Methods\", \"POST, OPTIONS\")\n        w.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, Authorization\")\n        w.Header().Set(\"Access-Control-Max-Age\", \"86400\")\n    }\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/transport/... -run TestSSETransport -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/transport/sse.go internal/transport/sse_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(transport): implement SSETransport with HTTP server\n\n- POST /mcp endpoint with SSE response\n- CORS support with configurable origins\n- Health check endpoint at /health\n- TLS support\n- Graceful shutdown\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#task-5-integrate-transports-with-serve-command","title":"Task 5: Integrate Transports with Serve Command","text":"<p>Files: - Modify: <code>cmd/metatools-mcp/cmd/serve.go</code> - Test: <code>cmd/metatools-mcp/cmd/serve_test.go</code></p> <p>Step 1: Update serve.go to use Transport interface</p> <pre><code>// Update serve.go imports\nimport (\n    \"github.com/your-org/metatools-mcp/internal/transport\"\n    // ... existing imports\n)\n\n// Update runServe to use Transport\nfunc runServe(ctx context.Context, cliCfg *ServeConfig) error {\n    ctx, cancel := signal.NotifyContext(ctx, os.Interrupt, syscall.SIGTERM)\n    defer cancel()\n\n    // Load configuration\n    cfg, err := loadServeConfig(cliCfg.Config, cliCfg)\n    if err != nil {\n        return fmt.Errorf(\"load config: %w\", err)\n    }\n\n    // Build server\n    serverCfg, err := buildServerConfigFromConfig(cfg)\n    if err != nil {\n        return fmt.Errorf(\"build server config: %w\", err)\n    }\n\n    srv, err := server.New(serverCfg)\n    if err != nil {\n        return fmt.Errorf(\"create server: %w\", err)\n    }\n\n    // Create transport based on config\n    var trans transport.Transport\n    switch cfg.Transport.Type {\n    case \"stdio\":\n        trans = transport.NewStdioTransport()\n    case \"sse\":\n        trans = transport.NewSSETransport(transport.SSEConfig{\n            Host:        cfg.Transport.HTTP.Host,\n            Port:        cfg.Transport.HTTP.Port,\n            TLSCert:     cfg.Transport.HTTP.TLS.CertFile,\n            TLSKey:      cfg.Transport.HTTP.TLS.KeyFile,\n            CORSOrigins: []string{\"*\"}, // TODO: Add to config\n        })\n    case \"http\":\n        return fmt.Errorf(\"transport %q not yet implemented\", cfg.Transport.Type)\n    default:\n        return fmt.Errorf(\"unknown transport: %s\", cfg.Transport.Type)\n    }\n\n    // Log startup\n    info := trans.Info()\n    fmt.Fprintf(os.Stderr, \"Starting %s\\n\", cfg.Server.Name)\n    fmt.Fprintf(os.Stderr, \"  Transport: %s\\n\", info.Name)\n    fmt.Fprintf(os.Stderr, \"  Address:   %s\\n\", info.Address)\n\n    // Create handler adapter\n    handler := &amp;serverHandler{server: srv}\n\n    // Start server\n    return trans.Serve(ctx, handler)\n}\n\n// serverHandler adapts the MCP server to the Transport Handler interface.\ntype serverHandler struct {\n    server *server.Server\n}\n\nfunc (h *serverHandler) HandleRequest(ctx context.Context, request []byte) ([]byte, error) {\n    // TODO: Forward to actual MCP server\n    // This is a placeholder that will be connected to the real server\n    return request, nil\n}\n\nfunc (h *serverHandler) HandleStream(ctx context.Context, request []byte) (&lt;-chan []byte, error) {\n    ch := make(chan []byte, 1)\n    response, err := h.HandleRequest(ctx, request)\n    if err != nil {\n        close(ch)\n        return ch, err\n    }\n    ch &lt;- response\n    close(ch)\n    return ch, nil\n}\n</code></pre> <p>Step 2: Run test to verify it works</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go build ./cmd/metatools-mcp/... &amp;&amp; ./cmd/metatools-mcp/metatools-mcp serve --help</code> Expected: Shows help with transport options</p> <p>Step 3: Commit</p> <pre><code>git add cmd/metatools-mcp/cmd/serve.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(cli): integrate Transport interface with serve command\n\n- Create stdio or SSE transport based on config\n- Add serverHandler adapter for MCP server\n- Log transport info on startup\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#task-6-add-integration-test","title":"Task 6: Add Integration Test","text":"<p>Files: - Create: <code>internal/transport/integration_test.go</code></p> <p>Step 1: Write integration test</p> <pre><code>//go:build integration\n\n// internal/transport/integration_test.go\npackage transport\n\nimport (\n    \"bytes\"\n    \"context\"\n    \"encoding/json\"\n    \"io\"\n    \"net/http\"\n    \"testing\"\n    \"time\"\n)\n\nfunc TestIntegration_SSETransport(t *testing.T) {\n    handler := &amp;mockHandler{\n        response: []byte(`{\"jsonrpc\":\"2.0\",\"result\":{\"message\":\"hello\"},\"id\":1}`),\n    }\n\n    transport := NewSSETransport(SSEConfig{\n        Host: \"127.0.0.1\",\n        Port: 19090, // Use unusual port for testing\n    })\n\n    ctx, cancel := context.WithCancel(context.Background())\n    defer cancel()\n\n    // Start server\n    errCh := make(chan error, 1)\n    go func() {\n        errCh &lt;- transport.Serve(ctx, handler)\n    }()\n\n    // Wait for server to start\n    time.Sleep(200 * time.Millisecond)\n\n    // Send request\n    client := &amp;http.Client{Timeout: 5 * time.Second}\n\n    reqBody := []byte(`{\"jsonrpc\":\"2.0\",\"method\":\"test\",\"params\":{},\"id\":1}`)\n    resp, err := client.Post(\n        \"http://127.0.0.1:19090/mcp\",\n        \"application/json\",\n        bytes.NewReader(reqBody),\n    )\n    if err != nil {\n        t.Fatalf(\"POST error = %v\", err)\n    }\n    defer resp.Body.Close()\n\n    // Check response\n    if resp.StatusCode != http.StatusOK {\n        t.Errorf(\"Status = %d, want %d\", resp.StatusCode, http.StatusOK)\n    }\n\n    if ct := resp.Header.Get(\"Content-Type\"); ct != \"text/event-stream\" {\n        t.Errorf(\"Content-Type = %q, want text/event-stream\", ct)\n    }\n\n    // Read SSE response\n    body, _ := io.ReadAll(resp.Body)\n    if !bytes.Contains(body, []byte(\"hello\")) {\n        t.Errorf(\"Response should contain 'hello', got: %s\", body)\n    }\n\n    // Test health endpoint\n    healthResp, err := client.Get(\"http://127.0.0.1:19090/health\")\n    if err != nil {\n        t.Fatalf(\"GET /health error = %v\", err)\n    }\n    defer healthResp.Body.Close()\n\n    var health map[string]string\n    json.NewDecoder(healthResp.Body).Decode(&amp;health)\n    if health[\"status\"] != \"ok\" {\n        t.Errorf(\"Health status = %q, want 'ok'\", health[\"status\"])\n    }\n\n    // Shutdown\n    cancel()\n}\n</code></pre> <p>Step 2: Run integration test</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/transport/... -tags=integration -run TestIntegration -v</code> Expected: PASS</p> <p>Step 3: Commit</p> <pre><code>git add internal/transport/integration_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\ntest(transport): add SSE transport integration test\n\n- Test full HTTP request/response cycle\n- Test SSE headers and event format\n- Test health endpoint\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Transport interface defined</li> <li>[ ] StdioTransport implemented</li> <li>[ ] SSEConfig with validation</li> <li>[ ] SSETransport with HTTP server</li> <li>[ ] CORS support</li> <li>[ ] Health endpoint</li> <li>[ ] Serve command integration</li> <li>[ ] Integration tests pass</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#definition-of-done","title":"Definition of Done","text":"<ol> <li>All tests pass: <code>go test ./internal/transport/...</code></li> <li>Integration tests pass: <code>go test ./internal/transport/... -tags=integration</code></li> <li><code>metatools-mcp serve --transport=stdio</code> works as before</li> <li><code>metatools-mcp serve --transport=sse --port=8080</code> starts HTTP server</li> <li><code>curl -X POST http://localhost:8080/mcp -d '{...}'</code> returns SSE response</li> <li><code>curl http://localhost:8080/health</code> returns OK</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-004-transport-sse/#next-prd","title":"Next PRD","text":"<p>PRD-005 will implement the Tool Provider Registry, enabling plug-and-play tool registration.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/","title":"PRD-005: Tool Provider Registry","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement a Tool Provider Registry enabling plug-and-play tool registration, replacing the hard-coded <code>registerTools()</code> function with a dynamic, configuration-driven system.</p> <p>Architecture: Define a ToolProvider interface that wraps tool definition and execution. Create a ProviderRegistry that manages provider lifecycle and discovery. Refactor existing handlers (search_tools, describe_tool, run_tool, etc.) into providers implementing the interface. Enable configuration-driven provider loading.</p> <p>Tech Stack: Go interfaces, existing handler implementations, config integration from PRD-003</p> <p>Priority: P0 - Stream A, Phase 3 (enables extensibility)</p> <p>Scope: Provider interface + registry + refactored built-in providers</p> <p>Dependencies: PRD-002 (CLI), PRD-003 (Config)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#context","title":"Context","text":"<p>The current server has a ~200-line <code>registerTools()</code> function that hard-codes tool schemas. The pluggable architecture requires: 1. Dynamic tool registration 2. Configuration-driven enable/disable 3. Custom provider support 4. Runtime provider discovery</p> <p>Current State: <pre><code>// server/server.go (current)\nfunc (s *Server) registerTools() {\n    // 200+ lines of hard-coded tool schemas\n    s.AddTool(searchToolSchema)\n    s.AddTool(describeToolSchema)\n    // ...\n}\n</code></pre></p> <p>Target State: <pre><code>// Provider interface\ntype ToolProvider interface {\n    Name() string\n    Tool() mcp.Tool\n    Handle(ctx context.Context, args map[string]any) (any, error)\n}\n\n// Registry-driven registration\nregistry.Register(\"search_tools\", &amp;SearchToolsProvider{...})\nregistry.Register(\"describe_tool\", &amp;DescribeToolProvider{...})\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#task-1-define-toolprovider-interface","title":"Task 1: Define ToolProvider Interface","text":"<p>Files: - Create: <code>internal/provider/provider.go</code> - Test: <code>internal/provider/provider_test.go</code></p> <p>Step 1: Write failing test for ToolProvider interface</p> <pre><code>// internal/provider/provider_test.go\npackage provider\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/mark3labs/mcp-go/mcp\"\n)\n\n// mockProvider implements ToolProvider for testing\ntype mockProvider struct {\n    name     string\n    enabled  bool\n    tool     mcp.Tool\n    handleFn func(ctx context.Context, args map[string]any) (any, error)\n}\n\nfunc (m *mockProvider) Name() string       { return m.name }\nfunc (m *mockProvider) Enabled() bool      { return m.enabled }\nfunc (m *mockProvider) Tool() mcp.Tool     { return m.tool }\nfunc (m *mockProvider) Handle(ctx context.Context, args map[string]any) (any, error) {\n    if m.handleFn != nil {\n        return m.handleFn(ctx, args)\n    }\n    return nil, nil\n}\n\nfunc TestToolProvider_Interface(t *testing.T) {\n    // Verify interface is implemented correctly\n    var _ ToolProvider = (*mockProvider)(nil)\n}\n\nfunc TestToolProvider_Methods(t *testing.T) {\n    provider := &amp;mockProvider{\n        name:    \"test_tool\",\n        enabled: true,\n        tool: mcp.Tool{\n            Name:        \"test_tool\",\n            Description: \"A test tool\",\n        },\n        handleFn: func(ctx context.Context, args map[string]any) (any, error) {\n            return \"result\", nil\n        },\n    }\n\n    if provider.Name() != \"test_tool\" {\n        t.Errorf(\"Name() = %q, want %q\", provider.Name(), \"test_tool\")\n    }\n\n    if !provider.Enabled() {\n        t.Error(\"Enabled() = false, want true\")\n    }\n\n    tool := provider.Tool()\n    if tool.Name != \"test_tool\" {\n        t.Errorf(\"Tool().Name = %q, want %q\", tool.Name, \"test_tool\")\n    }\n\n    result, err := provider.Handle(context.Background(), nil)\n    if err != nil {\n        t.Errorf(\"Handle() error = %v\", err)\n    }\n    if result != \"result\" {\n        t.Errorf(\"Handle() = %v, want %v\", result, \"result\")\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/provider/... -v</code> Expected: FAIL - ToolProvider type doesn't exist</p> <p>Step 3: Implement ToolProvider interface</p> <pre><code>// internal/provider/provider.go\npackage provider\n\nimport (\n    \"context\"\n\n    \"github.com/mark3labs/mcp-go/mcp\"\n)\n\n// ToolProvider defines the interface for MCP tool providers.\n// A provider encapsulates a tool's definition and execution logic.\ntype ToolProvider interface {\n    // Name returns the unique identifier for this provider.\n    Name() string\n\n    // Enabled returns whether this provider is currently enabled.\n    Enabled() bool\n\n    // Tool returns the MCP tool definition.\n    Tool() mcp.Tool\n\n    // Handle processes a tool invocation.\n    Handle(ctx context.Context, args map[string]any) (any, error)\n}\n\n// ConfigurableProvider is a provider that can be configured at runtime.\ntype ConfigurableProvider interface {\n    ToolProvider\n\n    // Configure applies configuration to the provider.\n    Configure(cfg map[string]any) error\n}\n\n// StreamingProvider is a provider that supports streaming responses.\ntype StreamingProvider interface {\n    ToolProvider\n\n    // HandleStream processes a streaming tool invocation.\n    // Returns a channel that emits response parts.\n    HandleStream(ctx context.Context, args map[string]any) (&lt;-chan any, error)\n}\n\n// ProviderFactory creates provider instances.\ntype ProviderFactory func() ToolProvider\n\n// ProviderInfo contains metadata about a provider.\ntype ProviderInfo struct {\n    Name        string\n    Description string\n    Version     string\n    Author      string\n    Streaming   bool\n}\n\n// GetInfo returns provider metadata if available.\nfunc GetInfo(p ToolProvider) ProviderInfo {\n    info := ProviderInfo{\n        Name: p.Name(),\n    }\n\n    tool := p.Tool()\n    info.Description = tool.Description\n\n    // Check if streaming\n    _, info.Streaming = p.(StreamingProvider)\n\n    return info\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/provider/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/provider/provider.go internal/provider/provider_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(provider): define ToolProvider interface\n\n- ToolProvider with Name, Enabled, Tool, Handle methods\n- ConfigurableProvider for runtime configuration\n- StreamingProvider for streaming responses\n- ProviderFactory and ProviderInfo types\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#task-2-implement-provider-registry","title":"Task 2: Implement Provider Registry","text":"<p>Files: - Create: <code>internal/provider/registry.go</code> - Test: <code>internal/provider/registry_test.go</code></p> <p>Step 1: Write failing test for registry</p> <pre><code>// internal/provider/registry_test.go\npackage provider\n\nimport (\n    \"testing\"\n)\n\nfunc TestRegistry_Register(t *testing.T) {\n    registry := NewRegistry()\n\n    provider := &amp;mockProvider{\n        name:    \"test_tool\",\n        enabled: true,\n    }\n\n    err := registry.Register(provider)\n    if err != nil {\n        t.Fatalf(\"Register() error = %v\", err)\n    }\n\n    // Duplicate registration should fail\n    err = registry.Register(provider)\n    if err == nil {\n        t.Error(\"Register() should fail on duplicate\")\n    }\n}\n\nfunc TestRegistry_Get(t *testing.T) {\n    registry := NewRegistry()\n\n    provider := &amp;mockProvider{\n        name:    \"test_tool\",\n        enabled: true,\n    }\n    registry.Register(provider)\n\n    got, ok := registry.Get(\"test_tool\")\n    if !ok {\n        t.Fatal(\"Get() returned false\")\n    }\n    if got.Name() != \"test_tool\" {\n        t.Errorf(\"Get().Name() = %q, want %q\", got.Name(), \"test_tool\")\n    }\n\n    _, ok = registry.Get(\"nonexistent\")\n    if ok {\n        t.Error(\"Get() should return false for nonexistent provider\")\n    }\n}\n\nfunc TestRegistry_List(t *testing.T) {\n    registry := NewRegistry()\n\n    registry.Register(&amp;mockProvider{name: \"tool_a\", enabled: true})\n    registry.Register(&amp;mockProvider{name: \"tool_b\", enabled: true})\n    registry.Register(&amp;mockProvider{name: \"tool_c\", enabled: false})\n\n    // List all\n    all := registry.List()\n    if len(all) != 3 {\n        t.Errorf(\"List() returned %d providers, want 3\", len(all))\n    }\n\n    // List enabled only\n    enabled := registry.ListEnabled()\n    if len(enabled) != 2 {\n        t.Errorf(\"ListEnabled() returned %d providers, want 2\", len(enabled))\n    }\n}\n\nfunc TestRegistry_Tools(t *testing.T) {\n    registry := NewRegistry()\n\n    registry.Register(&amp;mockProvider{\n        name:    \"tool_a\",\n        enabled: true,\n        tool:    mcp.Tool{Name: \"tool_a\", Description: \"Tool A\"},\n    })\n    registry.Register(&amp;mockProvider{\n        name:    \"tool_b\",\n        enabled: true,\n        tool:    mcp.Tool{Name: \"tool_b\", Description: \"Tool B\"},\n    })\n    registry.Register(&amp;mockProvider{\n        name:    \"tool_c\",\n        enabled: false,\n        tool:    mcp.Tool{Name: \"tool_c\", Description: \"Tool C\"},\n    })\n\n    tools := registry.Tools()\n    if len(tools) != 2 { // Only enabled providers\n        t.Errorf(\"Tools() returned %d tools, want 2\", len(tools))\n    }\n}\n\nfunc TestRegistry_Unregister(t *testing.T) {\n    registry := NewRegistry()\n\n    provider := &amp;mockProvider{name: \"test_tool\", enabled: true}\n    registry.Register(provider)\n\n    registry.Unregister(\"test_tool\")\n\n    _, ok := registry.Get(\"test_tool\")\n    if ok {\n        t.Error(\"Get() should return false after Unregister()\")\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/provider/... -run TestRegistry -v</code> Expected: FAIL - Registry doesn't exist</p> <p>Step 3: Implement Registry</p> <pre><code>// internal/provider/registry.go\npackage provider\n\nimport (\n    \"errors\"\n    \"fmt\"\n    \"sort\"\n    \"sync\"\n\n    \"github.com/mark3labs/mcp-go/mcp\"\n)\n\n// ErrProviderExists is returned when registering a duplicate provider.\nvar ErrProviderExists = errors.New(\"provider already registered\")\n\n// ErrProviderNotFound is returned when a provider is not found.\nvar ErrProviderNotFound = errors.New(\"provider not found\")\n\n// Registry manages tool providers.\ntype Registry struct {\n    providers map[string]ToolProvider\n    mu        sync.RWMutex\n}\n\n// NewRegistry creates a new provider registry.\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        providers: make(map[string]ToolProvider),\n    }\n}\n\n// Register adds a provider to the registry.\nfunc (r *Registry) Register(p ToolProvider) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    name := p.Name()\n    if _, exists := r.providers[name]; exists {\n        return fmt.Errorf(\"%w: %s\", ErrProviderExists, name)\n    }\n\n    r.providers[name] = p\n    return nil\n}\n\n// MustRegister adds a provider or panics.\nfunc (r *Registry) MustRegister(p ToolProvider) {\n    if err := r.Register(p); err != nil {\n        panic(err)\n    }\n}\n\n// Unregister removes a provider from the registry.\nfunc (r *Registry) Unregister(name string) {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    delete(r.providers, name)\n}\n\n// Get retrieves a provider by name.\nfunc (r *Registry) Get(name string) (ToolProvider, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    p, ok := r.providers[name]\n    return p, ok\n}\n\n// List returns all registered providers.\nfunc (r *Registry) List() []ToolProvider {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    providers := make([]ToolProvider, 0, len(r.providers))\n    for _, p := range r.providers {\n        providers = append(providers, p)\n    }\n\n    // Sort by name for consistency\n    sort.Slice(providers, func(i, j int) bool {\n        return providers[i].Name() &lt; providers[j].Name()\n    })\n\n    return providers\n}\n\n// ListEnabled returns only enabled providers.\nfunc (r *Registry) ListEnabled() []ToolProvider {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    providers := make([]ToolProvider, 0, len(r.providers))\n    for _, p := range r.providers {\n        if p.Enabled() {\n            providers = append(providers, p)\n        }\n    }\n\n    sort.Slice(providers, func(i, j int) bool {\n        return providers[i].Name() &lt; providers[j].Name()\n    })\n\n    return providers\n}\n\n// Tools returns MCP tool definitions for all enabled providers.\nfunc (r *Registry) Tools() []mcp.Tool {\n    enabled := r.ListEnabled()\n    tools := make([]mcp.Tool, 0, len(enabled))\n    for _, p := range enabled {\n        tools = append(tools, p.Tool())\n    }\n    return tools\n}\n\n// Handle invokes the provider for the given tool name.\nfunc (r *Registry) Handle(ctx context.Context, name string, args map[string]any) (any, error) {\n    p, ok := r.Get(name)\n    if !ok {\n        return nil, fmt.Errorf(\"%w: %s\", ErrProviderNotFound, name)\n    }\n\n    if !p.Enabled() {\n        return nil, fmt.Errorf(\"provider disabled: %s\", name)\n    }\n\n    return p.Handle(ctx, args)\n}\n\n// Count returns the number of registered providers.\nfunc (r *Registry) Count() int {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    return len(r.providers)\n}\n\n// Clear removes all providers.\nfunc (r *Registry) Clear() {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    r.providers = make(map[string]ToolProvider)\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/provider/... -run TestRegistry -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/provider/registry.go internal/provider/registry_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(provider): implement Provider Registry\n\n- Register/Unregister providers by name\n- Get/List/ListEnabled for provider lookup\n- Tools() returns MCP tool definitions\n- Handle() invokes provider by name\n- Thread-safe with RWMutex\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#task-3-create-base-provider-implementation","title":"Task 3: Create Base Provider Implementation","text":"<p>Files: - Create: <code>internal/provider/base.go</code> - Test: <code>internal/provider/base_test.go</code></p> <p>Step 1: Write failing test for BaseProvider</p> <pre><code>// internal/provider/base_test.go\npackage provider\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/mark3labs/mcp-go/mcp\"\n)\n\nfunc TestBaseProvider(t *testing.T) {\n    handler := func(ctx context.Context, args map[string]any) (any, error) {\n        return args[\"input\"], nil\n    }\n\n    provider := NewBaseProvider(BaseProviderConfig{\n        Name:        \"test_tool\",\n        Description: \"A test tool\",\n        InputSchema: map[string]any{\n            \"type\": \"object\",\n            \"properties\": map[string]any{\n                \"input\": map[string]any{\"type\": \"string\"},\n            },\n        },\n        Handler: handler,\n    })\n\n    // Test Name\n    if provider.Name() != \"test_tool\" {\n        t.Errorf(\"Name() = %q, want %q\", provider.Name(), \"test_tool\")\n    }\n\n    // Test Enabled (default true)\n    if !provider.Enabled() {\n        t.Error(\"Enabled() = false, want true\")\n    }\n\n    // Test Tool\n    tool := provider.Tool()\n    if tool.Name != \"test_tool\" {\n        t.Errorf(\"Tool().Name = %q, want %q\", tool.Name, \"test_tool\")\n    }\n    if tool.Description != \"A test tool\" {\n        t.Errorf(\"Tool().Description = %q, want %q\", tool.Description, \"A test tool\")\n    }\n\n    // Test Handle\n    result, err := provider.Handle(context.Background(), map[string]any{\"input\": \"hello\"})\n    if err != nil {\n        t.Errorf(\"Handle() error = %v\", err)\n    }\n    if result != \"hello\" {\n        t.Errorf(\"Handle() = %v, want %v\", result, \"hello\")\n    }\n}\n\nfunc TestBaseProvider_Disabled(t *testing.T) {\n    provider := NewBaseProvider(BaseProviderConfig{\n        Name:    \"disabled_tool\",\n        Enabled: false,\n        Handler: func(ctx context.Context, args map[string]any) (any, error) {\n            return nil, nil\n        },\n    })\n\n    if provider.Enabled() {\n        t.Error(\"Enabled() = true, want false\")\n    }\n}\n\nfunc TestBaseProvider_Configure(t *testing.T) {\n    provider := NewBaseProvider(BaseProviderConfig{\n        Name: \"configurable_tool\",\n        Handler: func(ctx context.Context, args map[string]any) (any, error) {\n            return nil, nil\n        },\n    })\n\n    // Configure should enable/disable\n    err := provider.Configure(map[string]any{\"enabled\": false})\n    if err != nil {\n        t.Errorf(\"Configure() error = %v\", err)\n    }\n\n    if provider.Enabled() {\n        t.Error(\"Enabled() = true after Configure(enabled: false)\")\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/provider/... -run TestBaseProvider -v</code> Expected: FAIL - BaseProvider doesn't exist</p> <p>Step 3: Implement BaseProvider</p> <pre><code>// internal/provider/base.go\npackage provider\n\nimport (\n    \"context\"\n    \"sync\"\n\n    \"github.com/mark3labs/mcp-go/mcp\"\n)\n\n// HandlerFunc is the function signature for tool handlers.\ntype HandlerFunc func(ctx context.Context, args map[string]any) (any, error)\n\n// BaseProviderConfig configures a base provider.\ntype BaseProviderConfig struct {\n    Name        string\n    Description string\n    InputSchema map[string]any\n    Enabled     bool\n    Handler     HandlerFunc\n}\n\n// BaseProvider provides a simple implementation of ToolProvider.\ntype BaseProvider struct {\n    name        string\n    description string\n    inputSchema map[string]any\n    enabled     bool\n    handler     HandlerFunc\n\n    mu sync.RWMutex\n}\n\n// NewBaseProvider creates a new base provider.\nfunc NewBaseProvider(cfg BaseProviderConfig) *BaseProvider {\n    enabled := true\n    if cfg.Enabled == false &amp;&amp; cfg.Handler != nil {\n        // Only set enabled=false if explicitly configured\n        // This handles the zero-value case\n    } else if !cfg.Enabled {\n        enabled = cfg.Enabled\n    }\n\n    // Actually, simpler logic: if Handler is set, default to enabled\n    enabled = cfg.Handler != nil\n    if cfg.InputSchema != nil || cfg.Description != \"\" {\n        enabled = true // Has tool definition, so enabled\n    }\n\n    return &amp;BaseProvider{\n        name:        cfg.Name,\n        description: cfg.Description,\n        inputSchema: cfg.InputSchema,\n        enabled:     enabled,\n        handler:     cfg.Handler,\n    }\n}\n\n// Name returns the provider name.\nfunc (p *BaseProvider) Name() string {\n    return p.name\n}\n\n// Enabled returns whether the provider is enabled.\nfunc (p *BaseProvider) Enabled() bool {\n    p.mu.RLock()\n    defer p.mu.RUnlock()\n    return p.enabled\n}\n\n// SetEnabled enables or disables the provider.\nfunc (p *BaseProvider) SetEnabled(enabled bool) {\n    p.mu.Lock()\n    defer p.mu.Unlock()\n    p.enabled = enabled\n}\n\n// Tool returns the MCP tool definition.\nfunc (p *BaseProvider) Tool() mcp.Tool {\n    return mcp.Tool{\n        Name:        p.name,\n        Description: p.description,\n        InputSchema: mcp.ToolInputSchema{\n            Type:       \"object\",\n            Properties: p.inputSchema,\n        },\n    }\n}\n\n// Handle invokes the tool handler.\nfunc (p *BaseProvider) Handle(ctx context.Context, args map[string]any) (any, error) {\n    if p.handler == nil {\n        return nil, ErrProviderNotFound\n    }\n    return p.handler(ctx, args)\n}\n\n// Configure applies configuration to the provider.\nfunc (p *BaseProvider) Configure(cfg map[string]any) error {\n    p.mu.Lock()\n    defer p.mu.Unlock()\n\n    if enabled, ok := cfg[\"enabled\"].(bool); ok {\n        p.enabled = enabled\n    }\n\n    return nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/provider/... -run TestBaseProvider -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/provider/base.go internal/provider/base_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(provider): implement BaseProvider for simple tools\n\n- NewBaseProvider with config struct\n- Name, Enabled, Tool, Handle methods\n- Configure for runtime enable/disable\n- Thread-safe enabled flag\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#task-4-refactor-search_tools-provider","title":"Task 4: Refactor search_tools Provider","text":"<p>Files: - Create: <code>internal/provider/builtin/search_tools.go</code> - Test: <code>internal/provider/builtin/search_tools_test.go</code></p> <p>Step 1: Write failing test for SearchToolsProvider</p> <pre><code>// internal/provider/builtin/search_tools_test.go\npackage builtin\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\nfunc TestSearchToolsProvider_Interface(t *testing.T) {\n    // Verify it implements ToolProvider\n    var _ provider.ToolProvider = (*SearchToolsProvider)(nil)\n}\n\nfunc TestSearchToolsProvider_Name(t *testing.T) {\n    p := NewSearchToolsProvider(nil) // nil deps for now\n    if p.Name() != \"search_tools\" {\n        t.Errorf(\"Name() = %q, want %q\", p.Name(), \"search_tools\")\n    }\n}\n\nfunc TestSearchToolsProvider_Tool(t *testing.T) {\n    p := NewSearchToolsProvider(nil)\n    tool := p.Tool()\n\n    if tool.Name != \"search_tools\" {\n        t.Errorf(\"Tool().Name = %q, want %q\", tool.Name, \"search_tools\")\n    }\n\n    // Check schema has required properties\n    schema := tool.InputSchema\n    if schema.Type != \"object\" {\n        t.Errorf(\"InputSchema.Type = %q, want %q\", schema.Type, \"object\")\n    }\n}\n\nfunc TestSearchToolsProvider_Handle(t *testing.T) {\n    // Create mock searcher\n    mockSearcher := &amp;mockSearcher{\n        results: []SearchResult{\n            {ID: \"tool1\", Score: 0.9},\n            {ID: \"tool2\", Score: 0.8},\n        },\n    }\n\n    p := NewSearchToolsProvider(SearchToolsDeps{\n        Searcher: mockSearcher,\n    })\n\n    result, err := p.Handle(context.Background(), map[string]any{\n        \"query\": \"test query\",\n        \"limit\": 10,\n    })\n\n    if err != nil {\n        t.Fatalf(\"Handle() error = %v\", err)\n    }\n\n    // Check result structure\n    results, ok := result.([]SearchResult)\n    if !ok {\n        t.Fatalf(\"Handle() result type = %T, want []SearchResult\", result)\n    }\n\n    if len(results) != 2 {\n        t.Errorf(\"Handle() returned %d results, want 2\", len(results))\n    }\n}\n\n// Mock searcher for testing\ntype mockSearcher struct {\n    results []SearchResult\n}\n\nfunc (m *mockSearcher) Search(query string, limit int) ([]SearchResult, error) {\n    return m.results, nil\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/provider/builtin/... -v</code> Expected: FAIL - SearchToolsProvider doesn't exist</p> <p>Step 3: Implement SearchToolsProvider</p> <pre><code>// internal/provider/builtin/search_tools.go\npackage builtin\n\nimport (\n    \"context\"\n\n    \"github.com/mark3labs/mcp-go/mcp\"\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\n// SearchResult represents a search result.\ntype SearchResult struct {\n    ID          string  `json:\"id\"`\n    Name        string  `json:\"name\"`\n    Namespace   string  `json:\"namespace\"`\n    Description string  `json:\"description\"`\n    Score       float64 `json:\"score\"`\n}\n\n// Searcher interface for tool search.\ntype Searcher interface {\n    Search(query string, limit int) ([]SearchResult, error)\n}\n\n// SearchToolsDeps holds dependencies for SearchToolsProvider.\ntype SearchToolsDeps struct {\n    Searcher Searcher\n}\n\n// SearchToolsProvider implements the search_tools MCP tool.\ntype SearchToolsProvider struct {\n    deps    SearchToolsDeps\n    enabled bool\n}\n\n// NewSearchToolsProvider creates a new search_tools provider.\nfunc NewSearchToolsProvider(deps SearchToolsDeps) *SearchToolsProvider {\n    return &amp;SearchToolsProvider{\n        deps:    deps,\n        enabled: true,\n    }\n}\n\n// Name returns \"search_tools\".\nfunc (p *SearchToolsProvider) Name() string {\n    return \"search_tools\"\n}\n\n// Enabled returns whether the provider is enabled.\nfunc (p *SearchToolsProvider) Enabled() bool {\n    return p.enabled\n}\n\n// SetEnabled enables or disables the provider.\nfunc (p *SearchToolsProvider) SetEnabled(enabled bool) {\n    p.enabled = enabled\n}\n\n// Tool returns the MCP tool definition.\nfunc (p *SearchToolsProvider) Tool() mcp.Tool {\n    return mcp.Tool{\n        Name:        \"search_tools\",\n        Description: \"Search for tools by query. Returns ranked results with tool IDs and descriptions.\",\n        InputSchema: mcp.ToolInputSchema{\n            Type: \"object\",\n            Properties: map[string]any{\n                \"query\": map[string]any{\n                    \"type\":        \"string\",\n                    \"description\": \"Search query to find relevant tools\",\n                },\n                \"limit\": map[string]any{\n                    \"type\":        \"integer\",\n                    \"description\": \"Maximum number of results to return\",\n                    \"default\":     10,\n                    \"minimum\":     1,\n                    \"maximum\":     100,\n                },\n            },\n            Required: []string{\"query\"},\n        },\n    }\n}\n\n// Handle processes a search_tools request.\nfunc (p *SearchToolsProvider) Handle(ctx context.Context, args map[string]any) (any, error) {\n    // Extract arguments\n    query, _ := args[\"query\"].(string)\n    limit := 10\n    if l, ok := args[\"limit\"].(float64); ok {\n        limit = int(l)\n    } else if l, ok := args[\"limit\"].(int); ok {\n        limit = l\n    }\n\n    // Perform search\n    if p.deps.Searcher == nil {\n        return []SearchResult{}, nil\n    }\n\n    results, err := p.deps.Searcher.Search(query, limit)\n    if err != nil {\n        return nil, err\n    }\n\n    return results, nil\n}\n\n// Configure applies configuration.\nfunc (p *SearchToolsProvider) Configure(cfg map[string]any) error {\n    if enabled, ok := cfg[\"enabled\"].(bool); ok {\n        p.enabled = enabled\n    }\n    return nil\n}\n\n// Ensure SearchToolsProvider implements ToolProvider and ConfigurableProvider\nvar _ provider.ToolProvider = (*SearchToolsProvider)(nil)\nvar _ provider.ConfigurableProvider = (*SearchToolsProvider)(nil)\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/provider/builtin/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/provider/builtin/search_tools.go internal/provider/builtin/search_tools_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(provider): add SearchToolsProvider\n\n- Implements ToolProvider interface\n- MCP tool definition with query and limit params\n- Configurable enabled state\n- Dependency injection for Searcher\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#task-5-create-default-registry-with-built-in-providers","title":"Task 5: Create Default Registry with Built-in Providers","text":"<p>Files: - Create: <code>internal/provider/builtin/registry.go</code> - Test: <code>internal/provider/builtin/registry_test.go</code></p> <p>Step 1: Write failing test</p> <pre><code>// internal/provider/builtin/registry_test.go\npackage builtin\n\nimport (\n    \"testing\"\n\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\nfunc TestDefaultRegistry(t *testing.T) {\n    deps := Dependencies{\n        // Minimal deps for testing\n    }\n\n    registry := NewDefaultRegistry(deps)\n\n    // Should have built-in providers\n    if registry.Count() == 0 {\n        t.Error(\"DefaultRegistry has no providers\")\n    }\n\n    // search_tools should exist\n    _, ok := registry.Get(\"search_tools\")\n    if !ok {\n        t.Error(\"search_tools provider not found\")\n    }\n}\n\nfunc TestDefaultRegistry_Tools(t *testing.T) {\n    deps := Dependencies{}\n    registry := NewDefaultRegistry(deps)\n\n    tools := registry.Tools()\n    if len(tools) == 0 {\n        t.Error(\"Tools() returned empty slice\")\n    }\n\n    // Check tool names\n    hasSearchTools := false\n    for _, tool := range tools {\n        if tool.Name == \"search_tools\" {\n            hasSearchTools = true\n        }\n    }\n\n    if !hasSearchTools {\n        t.Error(\"Tools() missing search_tools\")\n    }\n}\n</code></pre> <p>Step 2: Implement default registry</p> <pre><code>// internal/provider/builtin/registry.go\npackage builtin\n\nimport (\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\n// Dependencies holds all dependencies for built-in providers.\ntype Dependencies struct {\n    Searcher    Searcher\n    // Future: Index, Docs, Runner, etc.\n}\n\n// NewDefaultRegistry creates a registry with all built-in providers.\nfunc NewDefaultRegistry(deps Dependencies) *provider.Registry {\n    registry := provider.NewRegistry()\n\n    // Register built-in providers\n    registry.MustRegister(NewSearchToolsProvider(SearchToolsDeps{\n        Searcher: deps.Searcher,\n    }))\n\n    // Future providers:\n    // registry.MustRegister(NewDescribeToolProvider(...))\n    // registry.MustRegister(NewRunToolProvider(...))\n    // registry.MustRegister(NewRunChainProvider(...))\n    // registry.MustRegister(NewListNamespacesProvider(...))\n\n    return registry\n}\n\n// BuiltinProviders returns a list of built-in provider names.\nfunc BuiltinProviders() []string {\n    return []string{\n        \"search_tools\",\n        \"describe_tool\",\n        \"run_tool\",\n        \"run_chain\",\n        \"list_namespaces\",\n        \"list_tool_examples\",\n        \"execute_code\",\n    }\n}\n</code></pre> <p>Step 3: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/provider/builtin/... -v</code> Expected: PASS</p> <p>Step 4: Commit</p> <pre><code>git add internal/provider/builtin/registry.go internal/provider/builtin/registry_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(provider): add DefaultRegistry with built-in providers\n\n- NewDefaultRegistry creates registry with all built-ins\n- Dependency injection for provider dependencies\n- BuiltinProviders() lists all built-in provider names\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#task-6-integrate-registry-with-server","title":"Task 6: Integrate Registry with Server","text":"<p>Files: - Modify: <code>internal/server/server.go</code> (or create adapter) - Test: Integration test</p> <p>Step 1: Create server integration</p> <pre><code>// internal/server/provider_adapter.go\npackage server\n\nimport (\n    \"context\"\n\n    \"github.com/mark3labs/mcp-go/mcp\"\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\n// ProviderAdapter adapts the provider registry to the MCP server.\ntype ProviderAdapter struct {\n    registry *provider.Registry\n}\n\n// NewProviderAdapter creates a new adapter.\nfunc NewProviderAdapter(registry *provider.Registry) *ProviderAdapter {\n    return &amp;ProviderAdapter{registry: registry}\n}\n\n// RegisterTools registers all enabled providers as MCP tools.\nfunc (a *ProviderAdapter) RegisterTools(server *Server) error {\n    for _, p := range a.registry.ListEnabled() {\n        tool := p.Tool()\n\n        // Add tool to server\n        server.AddTool(tool, a.createHandler(p))\n    }\n    return nil\n}\n\n// createHandler creates an MCP handler for a provider.\nfunc (a *ProviderAdapter) createHandler(p provider.ToolProvider) mcp.ToolHandler {\n    return func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {\n        args := request.Params.Arguments\n\n        result, err := p.Handle(ctx, args)\n        if err != nil {\n            return nil, err\n        }\n\n        return &amp;mcp.CallToolResult{\n            Content: []mcp.Content{\n                mcp.TextContent{\n                    Type: \"text\",\n                    Text: formatResult(result),\n                },\n            },\n        }, nil\n    }\n}\n\n// formatResult converts a result to string for MCP response.\nfunc formatResult(result any) string {\n    // JSON encode the result\n    data, err := json.Marshal(result)\n    if err != nil {\n        return fmt.Sprintf(\"%v\", result)\n    }\n    return string(data)\n}\n</code></pre> <p>Step 2: Write integration test</p> <pre><code>// internal/server/provider_adapter_test.go\npackage server\n\nimport (\n    \"testing\"\n\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n    \"github.com/your-org/metatools-mcp/internal/provider/builtin\"\n)\n\nfunc TestProviderAdapter_RegisterTools(t *testing.T) {\n    // Create registry with test providers\n    registry := provider.NewRegistry()\n    registry.MustRegister(builtin.NewSearchToolsProvider(builtin.SearchToolsDeps{}))\n\n    adapter := NewProviderAdapter(registry)\n\n    // Create mock server\n    server := &amp;mockServer{tools: make(map[string]mcp.Tool)}\n\n    err := adapter.RegisterTools(server)\n    if err != nil {\n        t.Fatalf(\"RegisterTools() error = %v\", err)\n    }\n\n    if len(server.tools) == 0 {\n        t.Error(\"No tools registered\")\n    }\n\n    if _, ok := server.tools[\"search_tools\"]; !ok {\n        t.Error(\"search_tools not registered\")\n    }\n}\n</code></pre> <p>Step 3: Commit</p> <pre><code>git add internal/server/provider_adapter.go internal/server/provider_adapter_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(server): add ProviderAdapter for registry integration\n\n- RegisterTools adds providers as MCP tools\n- Creates handler wrappers for provider.Handle\n- Formats results as MCP response content\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] ToolProvider interface defined</li> <li>[ ] ConfigurableProvider interface</li> <li>[ ] StreamingProvider interface</li> <li>[ ] Registry with Register/Get/List</li> <li>[ ] BaseProvider implementation</li> <li>[ ] SearchToolsProvider implemented</li> <li>[ ] DefaultRegistry with built-ins</li> <li>[ ] ProviderAdapter for server integration</li> <li>[ ] All tests pass</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#definition-of-done","title":"Definition of Done","text":"<ol> <li>All tests pass: <code>go test ./internal/provider/...</code></li> <li>Built-in providers implement ToolProvider interface</li> <li>Registry manages provider lifecycle</li> <li>Server uses registry instead of hard-coded tools</li> <li>Providers can be enabled/disabled via config</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-005-tool-provider-registry/#next-prd","title":"Next PRD","text":"<p>PRD-006 will implement the Backend Registry for multi-source tool aggregation.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/","title":"PRD-006: Backend Registry","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement a Backend Registry enabling multi-source tool aggregation, where tools can be discovered and executed from local handlers, MCP servers, HTTP APIs, and other external sources through a unified interface.</p> <p>Architecture: Define a Backend interface that abstracts tool sources. Create a BackendRegistry that manages backend lifecycle, discovery, and routing. Implement LocalBackend for in-process handlers. Enable configuration-driven backend loading with automatic tool aggregation.</p> <p>Tech Stack: Go interfaces, toolmodel.Tool integration, config integration from PRD-003</p> <p>Priority: P1 - Stream A, Phase 4 (completes core exposure)</p> <p>Scope: Backend interface + registry + local backend + tool aggregation</p> <p>Dependencies: PRD-002 (CLI), PRD-003 (Config), PRD-005 (Provider Registry)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#context","title":"Context","text":"<p>The current architecture supports only local tool handlers. The pluggable architecture requires: 1. Multiple tool sources (local, MCP, HTTP, custom) 2. Unified tool discovery across backends 3. Transparent execution routing 4. Configuration-driven backend management</p> <p>Current State: <pre><code>// All tools are local handlers\nhandlers := map[string]Handler{\n    \"search_tools\": searchHandler,\n    \"run_tool\": runHandler,\n}\n</code></pre></p> <p>Target State: <pre><code>// Backend interface for any tool source\ntype Backend interface {\n    Kind() string\n    Name() string\n    ListTools(ctx context.Context) ([]toolmodel.Tool, error)\n    Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n}\n\n// Registry aggregates all backends\nregistry.Register(\"local\", &amp;LocalBackend{...})\nregistry.Register(\"github\", &amp;MCPBackend{...})  // Future PRD\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#task-1-define-backend-interface","title":"Task 1: Define Backend Interface","text":"<p>Files: - Create: <code>internal/backend/backend.go</code> - Test: <code>internal/backend/backend_test.go</code></p> <p>Step 1: Write failing test for Backend interface</p> <pre><code>// internal/backend/backend_test.go\npackage backend\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/jraymond/toolmodel\"\n)\n\n// mockBackend implements Backend for testing\ntype mockBackend struct {\n    kind     string\n    name     string\n    enabled  bool\n    tools    []toolmodel.Tool\n    execFn   func(ctx context.Context, tool string, args map[string]any) (any, error)\n}\n\nfunc (m *mockBackend) Kind() string    { return m.kind }\nfunc (m *mockBackend) Name() string    { return m.name }\nfunc (m *mockBackend) Enabled() bool   { return m.enabled }\n\nfunc (m *mockBackend) ListTools(ctx context.Context) ([]toolmodel.Tool, error) {\n    return m.tools, nil\n}\n\nfunc (m *mockBackend) Execute(ctx context.Context, tool string, args map[string]any) (any, error) {\n    if m.execFn != nil {\n        return m.execFn(ctx, tool, args)\n    }\n    return nil, nil\n}\n\nfunc (m *mockBackend) Start(ctx context.Context) error { return nil }\nfunc (m *mockBackend) Stop() error                     { return nil }\n\nfunc TestBackend_Interface(t *testing.T) {\n    // Verify interface is implemented correctly\n    var _ Backend = (*mockBackend)(nil)\n}\n\nfunc TestBackend_Methods(t *testing.T) {\n    backend := &amp;mockBackend{\n        kind:    \"local\",\n        name:    \"test-backend\",\n        enabled: true,\n        tools: []toolmodel.Tool{\n            {Name: \"test_tool\", Description: \"A test tool\"},\n        },\n        execFn: func(ctx context.Context, tool string, args map[string]any) (any, error) {\n            return \"executed\", nil\n        },\n    }\n\n    if backend.Kind() != \"local\" {\n        t.Errorf(\"Kind() = %q, want %q\", backend.Kind(), \"local\")\n    }\n\n    if backend.Name() != \"test-backend\" {\n        t.Errorf(\"Name() = %q, want %q\", backend.Name(), \"test-backend\")\n    }\n\n    if !backend.Enabled() {\n        t.Error(\"Enabled() = false, want true\")\n    }\n\n    tools, err := backend.ListTools(context.Background())\n    if err != nil {\n        t.Fatalf(\"ListTools() error = %v\", err)\n    }\n    if len(tools) != 1 {\n        t.Errorf(\"ListTools() returned %d tools, want 1\", len(tools))\n    }\n\n    result, err := backend.Execute(context.Background(), \"test_tool\", nil)\n    if err != nil {\n        t.Fatalf(\"Execute() error = %v\", err)\n    }\n    if result != \"executed\" {\n        t.Errorf(\"Execute() = %v, want %v\", result, \"executed\")\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/backend/... -v</code> Expected: FAIL - Backend type doesn't exist</p> <p>Step 3: Implement Backend interface</p> <pre><code>// internal/backend/backend.go\npackage backend\n\nimport (\n    \"context\"\n    \"errors\"\n\n    \"github.com/jraymond/toolmodel\"\n)\n\n// Common errors for backend operations\nvar (\n    ErrBackendNotFound    = errors.New(\"backend not found\")\n    ErrBackendDisabled    = errors.New(\"backend disabled\")\n    ErrToolNotFound       = errors.New(\"tool not found in backend\")\n    ErrBackendUnavailable = errors.New(\"backend unavailable\")\n)\n\n// Backend defines a source of tools.\n// Backends can be local handlers, MCP servers, HTTP APIs, or custom implementations.\ntype Backend interface {\n    // Kind returns the backend type (e.g., \"local\", \"mcp\", \"http\")\n    Kind() string\n\n    // Name returns the unique instance name for this backend\n    Name() string\n\n    // Enabled returns whether this backend is currently enabled\n    Enabled() bool\n\n    // ListTools returns all tools available from this backend\n    ListTools(ctx context.Context) ([]toolmodel.Tool, error)\n\n    // Execute invokes a tool on this backend\n    Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n\n    // Start initializes the backend (connect to remote, start subprocess, etc.)\n    Start(ctx context.Context) error\n\n    // Stop gracefully shuts down the backend\n    Stop() error\n}\n\n// ConfigurableBackend is a backend that can be configured from raw bytes (YAML/JSON)\ntype ConfigurableBackend interface {\n    Backend\n\n    // Configure applies configuration from raw bytes\n    Configure(raw []byte) error\n}\n\n// StreamingBackend supports streaming responses\ntype StreamingBackend interface {\n    Backend\n\n    // ExecuteStream returns a channel of response chunks\n    ExecuteStream(ctx context.Context, tool string, args map[string]any) (&lt;-chan any, error)\n}\n\n// BackendFactory creates backend instances from configuration\ntype BackendFactory func(name string) (Backend, error)\n\n// BackendInfo contains metadata about a backend\ntype BackendInfo struct {\n    Kind        string\n    Name        string\n    Enabled     bool\n    ToolCount   int\n    Streaming   bool\n    Configurable bool\n}\n\n// GetInfo returns metadata about a backend\nfunc GetInfo(b Backend) BackendInfo {\n    info := BackendInfo{\n        Kind:    b.Kind(),\n        Name:    b.Name(),\n        Enabled: b.Enabled(),\n    }\n\n    // Check capabilities\n    _, info.Streaming = b.(StreamingBackend)\n    _, info.Configurable = b.(ConfigurableBackend)\n\n    // Get tool count (best effort)\n    if tools, err := b.ListTools(context.Background()); err == nil {\n        info.ToolCount = len(tools)\n    }\n\n    return info\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/backend/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/backend/backend.go internal/backend/backend_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(backend): define Backend interface\n\n- Backend with Kind, Name, Enabled, ListTools, Execute methods\n- Start/Stop for lifecycle management\n- ConfigurableBackend for YAML/JSON config\n- StreamingBackend for streaming responses\n- BackendFactory and BackendInfo types\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#task-2-implement-backend-registry","title":"Task 2: Implement Backend Registry","text":"<p>Files: - Create: <code>internal/backend/registry.go</code> - Test: <code>internal/backend/registry_test.go</code></p> <p>Step 1: Write failing test for registry</p> <pre><code>// internal/backend/registry_test.go\npackage backend\n\nimport (\n    \"context\"\n    \"testing\"\n)\n\nfunc TestRegistry_Register(t *testing.T) {\n    registry := NewRegistry()\n\n    backend := &amp;mockBackend{\n        kind:    \"local\",\n        name:    \"test\",\n        enabled: true,\n    }\n\n    err := registry.Register(backend)\n    if err != nil {\n        t.Fatalf(\"Register() error = %v\", err)\n    }\n\n    // Duplicate registration should fail\n    err = registry.Register(backend)\n    if err == nil {\n        t.Error(\"Register() should fail on duplicate\")\n    }\n}\n\nfunc TestRegistry_Get(t *testing.T) {\n    registry := NewRegistry()\n\n    backend := &amp;mockBackend{\n        kind:    \"local\",\n        name:    \"test\",\n        enabled: true,\n    }\n    registry.Register(backend)\n\n    got, ok := registry.Get(\"test\")\n    if !ok {\n        t.Fatal(\"Get() returned false\")\n    }\n    if got.Name() != \"test\" {\n        t.Errorf(\"Get().Name() = %q, want %q\", got.Name(), \"test\")\n    }\n\n    _, ok = registry.Get(\"nonexistent\")\n    if ok {\n        t.Error(\"Get() should return false for nonexistent backend\")\n    }\n}\n\nfunc TestRegistry_List(t *testing.T) {\n    registry := NewRegistry()\n\n    registry.Register(&amp;mockBackend{kind: \"local\", name: \"a\", enabled: true})\n    registry.Register(&amp;mockBackend{kind: \"mcp\", name: \"b\", enabled: true})\n    registry.Register(&amp;mockBackend{kind: \"http\", name: \"c\", enabled: false})\n\n    // List all\n    all := registry.List()\n    if len(all) != 3 {\n        t.Errorf(\"List() returned %d backends, want 3\", len(all))\n    }\n\n    // List enabled only\n    enabled := registry.ListEnabled()\n    if len(enabled) != 2 {\n        t.Errorf(\"ListEnabled() returned %d backends, want 2\", len(enabled))\n    }\n}\n\nfunc TestRegistry_ListByKind(t *testing.T) {\n    registry := NewRegistry()\n\n    registry.Register(&amp;mockBackend{kind: \"local\", name: \"local1\", enabled: true})\n    registry.Register(&amp;mockBackend{kind: \"local\", name: \"local2\", enabled: true})\n    registry.Register(&amp;mockBackend{kind: \"mcp\", name: \"mcp1\", enabled: true})\n\n    locals := registry.ListByKind(\"local\")\n    if len(locals) != 2 {\n        t.Errorf(\"ListByKind(local) returned %d backends, want 2\", len(locals))\n    }\n\n    mcps := registry.ListByKind(\"mcp\")\n    if len(mcps) != 1 {\n        t.Errorf(\"ListByKind(mcp) returned %d backends, want 1\", len(mcps))\n    }\n}\n\nfunc TestRegistry_Unregister(t *testing.T) {\n    registry := NewRegistry()\n\n    backend := &amp;mockBackend{kind: \"local\", name: \"test\", enabled: true}\n    registry.Register(backend)\n\n    registry.Unregister(\"test\")\n\n    _, ok := registry.Get(\"test\")\n    if ok {\n        t.Error(\"Get() should return false after Unregister()\")\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/backend/... -run TestRegistry -v</code> Expected: FAIL - Registry doesn't exist</p> <p>Step 3: Implement Registry</p> <pre><code>// internal/backend/registry.go\npackage backend\n\nimport (\n    \"fmt\"\n    \"sort\"\n    \"sync\"\n)\n\n// ErrBackendExists is returned when registering a duplicate backend\nvar ErrBackendExists = errors.New(\"backend already registered\")\n\n// Registry manages backend instances\ntype Registry struct {\n    backends  map[string]Backend\n    factories map[string]BackendFactory\n    mu        sync.RWMutex\n}\n\n// NewRegistry creates a new backend registry\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        backends:  make(map[string]Backend),\n        factories: make(map[string]BackendFactory),\n    }\n}\n\n// RegisterFactory registers a factory for creating backends of a given kind\nfunc (r *Registry) RegisterFactory(kind string, factory BackendFactory) {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    r.factories[kind] = factory\n}\n\n// Register adds a backend to the registry\nfunc (r *Registry) Register(b Backend) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    name := b.Name()\n    if _, exists := r.backends[name]; exists {\n        return fmt.Errorf(\"%w: %s\", ErrBackendExists, name)\n    }\n\n    r.backends[name] = b\n    return nil\n}\n\n// MustRegister adds a backend or panics\nfunc (r *Registry) MustRegister(b Backend) {\n    if err := r.Register(b); err != nil {\n        panic(err)\n    }\n}\n\n// Unregister removes a backend from the registry\nfunc (r *Registry) Unregister(name string) {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    if b, exists := r.backends[name]; exists {\n        b.Stop() // Best effort cleanup\n        delete(r.backends, name)\n    }\n}\n\n// Get retrieves a backend by name\nfunc (r *Registry) Get(name string) (Backend, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    b, ok := r.backends[name]\n    return b, ok\n}\n\n// List returns all registered backends\nfunc (r *Registry) List() []Backend {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    backends := make([]Backend, 0, len(r.backends))\n    for _, b := range r.backends {\n        backends = append(backends, b)\n    }\n\n    // Sort by name for consistency\n    sort.Slice(backends, func(i, j int) bool {\n        return backends[i].Name() &lt; backends[j].Name()\n    })\n\n    return backends\n}\n\n// ListEnabled returns only enabled backends\nfunc (r *Registry) ListEnabled() []Backend {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    backends := make([]Backend, 0, len(r.backends))\n    for _, b := range r.backends {\n        if b.Enabled() {\n            backends = append(backends, b)\n        }\n    }\n\n    sort.Slice(backends, func(i, j int) bool {\n        return backends[i].Name() &lt; backends[j].Name()\n    })\n\n    return backends\n}\n\n// ListByKind returns backends of a specific kind\nfunc (r *Registry) ListByKind(kind string) []Backend {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    backends := make([]Backend, 0)\n    for _, b := range r.backends {\n        if b.Kind() == kind {\n            backends = append(backends, b)\n        }\n    }\n\n    sort.Slice(backends, func(i, j int) bool {\n        return backends[i].Name() &lt; backends[j].Name()\n    })\n\n    return backends\n}\n\n// Count returns the number of registered backends\nfunc (r *Registry) Count() int {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    return len(r.backends)\n}\n\n// StartAll starts all enabled backends\nfunc (r *Registry) StartAll(ctx context.Context) error {\n    for _, b := range r.ListEnabled() {\n        if err := b.Start(ctx); err != nil {\n            return fmt.Errorf(\"start backend %s: %w\", b.Name(), err)\n        }\n    }\n    return nil\n}\n\n// StopAll stops all backends\nfunc (r *Registry) StopAll() error {\n    var firstErr error\n    for _, b := range r.List() {\n        if err := b.Stop(); err != nil &amp;&amp; firstErr == nil {\n            firstErr = fmt.Errorf(\"stop backend %s: %w\", b.Name(), err)\n        }\n    }\n    return firstErr\n}\n\n// Clear removes all backends\nfunc (r *Registry) Clear() {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    for _, b := range r.backends {\n        b.Stop()\n    }\n    r.backends = make(map[string]Backend)\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/backend/... -run TestRegistry -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/backend/registry.go internal/backend/registry_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(backend): implement Backend Registry\n\n- Register/Unregister backends by name\n- Get/List/ListEnabled/ListByKind for lookup\n- RegisterFactory for kind-based creation\n- StartAll/StopAll for lifecycle management\n- Thread-safe with RWMutex\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#task-3-implement-local-backend","title":"Task 3: Implement Local Backend","text":"<p>Files: - Create: <code>internal/backend/local/local.go</code> - Test: <code>internal/backend/local/local_test.go</code></p> <p>Step 1: Write failing test for LocalBackend</p> <pre><code>// internal/backend/local/local_test.go\npackage local\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/your-org/metatools-mcp/internal/backend\"\n)\n\nfunc TestLocalBackend_Interface(t *testing.T) {\n    // Verify it implements Backend\n    var _ backend.Backend = (*Backend)(nil)\n}\n\nfunc TestLocalBackend_Kind(t *testing.T) {\n    b := New(\"test\")\n    if b.Kind() != \"local\" {\n        t.Errorf(\"Kind() = %q, want %q\", b.Kind(), \"local\")\n    }\n}\n\nfunc TestLocalBackend_Name(t *testing.T) {\n    b := New(\"my-local\")\n    if b.Name() != \"my-local\" {\n        t.Errorf(\"Name() = %q, want %q\", b.Name(), \"my-local\")\n    }\n}\n\nfunc TestLocalBackend_RegisterHandler(t *testing.T) {\n    b := New(\"test\")\n\n    handler := func(ctx context.Context, args map[string]any) (any, error) {\n        return \"handled\", nil\n    }\n\n    b.RegisterHandler(\"my_tool\", ToolDef{\n        Name:        \"my_tool\",\n        Description: \"A test tool\",\n        Handler:     handler,\n    })\n\n    tools, err := b.ListTools(context.Background())\n    if err != nil {\n        t.Fatalf(\"ListTools() error = %v\", err)\n    }\n\n    if len(tools) != 1 {\n        t.Fatalf(\"ListTools() returned %d tools, want 1\", len(tools))\n    }\n\n    if tools[0].Name != \"my_tool\" {\n        t.Errorf(\"Tool.Name = %q, want %q\", tools[0].Name, \"my_tool\")\n    }\n}\n\nfunc TestLocalBackend_Execute(t *testing.T) {\n    b := New(\"test\")\n\n    b.RegisterHandler(\"echo\", ToolDef{\n        Name:        \"echo\",\n        Description: \"Echo input\",\n        Handler: func(ctx context.Context, args map[string]any) (any, error) {\n            return args[\"message\"], nil\n        },\n    })\n\n    result, err := b.Execute(context.Background(), \"echo\", map[string]any{\n        \"message\": \"hello\",\n    })\n\n    if err != nil {\n        t.Fatalf(\"Execute() error = %v\", err)\n    }\n\n    if result != \"hello\" {\n        t.Errorf(\"Execute() = %v, want %v\", result, \"hello\")\n    }\n}\n\nfunc TestLocalBackend_ExecuteNotFound(t *testing.T) {\n    b := New(\"test\")\n\n    _, err := b.Execute(context.Background(), \"nonexistent\", nil)\n    if err == nil {\n        t.Error(\"Execute() should fail for nonexistent tool\")\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/backend/local/... -v</code> Expected: FAIL - Backend doesn't exist</p> <p>Step 3: Implement LocalBackend</p> <pre><code>// internal/backend/local/local.go\npackage local\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n\n    \"github.com/jraymond/toolmodel\"\n    \"github.com/mark3labs/mcp-go/mcp\"\n    \"github.com/your-org/metatools-mcp/internal/backend\"\n)\n\n// HandlerFunc is the function signature for tool handlers\ntype HandlerFunc func(ctx context.Context, args map[string]any) (any, error)\n\n// ToolDef defines a local tool with its handler\ntype ToolDef struct {\n    Name        string\n    Description string\n    InputSchema map[string]any\n    Handler     HandlerFunc\n}\n\n// Backend implements the Backend interface for local tool handlers\ntype Backend struct {\n    name     string\n    enabled  bool\n    handlers map[string]ToolDef\n    mu       sync.RWMutex\n}\n\n// New creates a new local backend\nfunc New(name string) *Backend {\n    return &amp;Backend{\n        name:     name,\n        enabled:  true,\n        handlers: make(map[string]ToolDef),\n    }\n}\n\n// Kind returns \"local\"\nfunc (b *Backend) Kind() string {\n    return \"local\"\n}\n\n// Name returns the backend instance name\nfunc (b *Backend) Name() string {\n    return b.name\n}\n\n// Enabled returns whether the backend is enabled\nfunc (b *Backend) Enabled() bool {\n    b.mu.RLock()\n    defer b.mu.RUnlock()\n    return b.enabled\n}\n\n// SetEnabled enables or disables the backend\nfunc (b *Backend) SetEnabled(enabled bool) {\n    b.mu.Lock()\n    defer b.mu.Unlock()\n    b.enabled = enabled\n}\n\n// RegisterHandler adds a tool handler\nfunc (b *Backend) RegisterHandler(name string, def ToolDef) {\n    b.mu.Lock()\n    defer b.mu.Unlock()\n    b.handlers[name] = def\n}\n\n// UnregisterHandler removes a tool handler\nfunc (b *Backend) UnregisterHandler(name string) {\n    b.mu.Lock()\n    defer b.mu.Unlock()\n    delete(b.handlers, name)\n}\n\n// ListTools returns all registered tools\nfunc (b *Backend) ListTools(ctx context.Context) ([]toolmodel.Tool, error) {\n    b.mu.RLock()\n    defer b.mu.RUnlock()\n\n    tools := make([]toolmodel.Tool, 0, len(b.handlers))\n    for _, def := range b.handlers {\n        tool := toolmodel.Tool{\n            Tool: mcp.Tool{\n                Name:        def.Name,\n                Description: def.Description,\n                InputSchema: mcp.ToolInputSchema{\n                    Type:       \"object\",\n                    Properties: def.InputSchema,\n                },\n            },\n            Namespace: b.name,\n        }\n        tools = append(tools, tool)\n    }\n\n    return tools, nil\n}\n\n// Execute invokes a tool handler\nfunc (b *Backend) Execute(ctx context.Context, tool string, args map[string]any) (any, error) {\n    b.mu.RLock()\n    def, ok := b.handlers[tool]\n    b.mu.RUnlock()\n\n    if !ok {\n        return nil, fmt.Errorf(\"%w: %s\", backend.ErrToolNotFound, tool)\n    }\n\n    if def.Handler == nil {\n        return nil, fmt.Errorf(\"tool %s has no handler\", tool)\n    }\n\n    return def.Handler(ctx, args)\n}\n\n// Start is a no-op for local backends\nfunc (b *Backend) Start(ctx context.Context) error {\n    return nil\n}\n\n// Stop is a no-op for local backends\nfunc (b *Backend) Stop() error {\n    return nil\n}\n\n// Ensure Backend implements backend.Backend\nvar _ backend.Backend = (*Backend)(nil)\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/backend/local/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/backend/local/local.go internal/backend/local/local_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(backend): implement LocalBackend for in-process handlers\n\n- RegisterHandler/UnregisterHandler for tool management\n- ListTools returns toolmodel.Tool with namespace\n- Execute invokes handler with context and args\n- Thread-safe handler access\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#task-4-implement-tool-aggregator","title":"Task 4: Implement Tool Aggregator","text":"<p>Files: - Create: <code>internal/backend/aggregator.go</code> - Test: <code>internal/backend/aggregator_test.go</code></p> <p>Step 1: Write failing test for Aggregator</p> <pre><code>// internal/backend/aggregator_test.go\npackage backend\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/jraymond/toolmodel\"\n)\n\nfunc TestAggregator_ListAllTools(t *testing.T) {\n    registry := NewRegistry()\n\n    registry.Register(&amp;mockBackend{\n        kind:    \"local\",\n        name:    \"local1\",\n        enabled: true,\n        tools: []toolmodel.Tool{\n            {Name: \"tool_a\", Namespace: \"local1\"},\n            {Name: \"tool_b\", Namespace: \"local1\"},\n        },\n    })\n\n    registry.Register(&amp;mockBackend{\n        kind:    \"mcp\",\n        name:    \"github\",\n        enabled: true,\n        tools: []toolmodel.Tool{\n            {Name: \"create_issue\", Namespace: \"github\"},\n        },\n    })\n\n    registry.Register(&amp;mockBackend{\n        kind:    \"local\",\n        name:    \"disabled\",\n        enabled: false,\n        tools: []toolmodel.Tool{\n            {Name: \"should_not_appear\"},\n        },\n    })\n\n    agg := NewAggregator(registry)\n\n    tools, err := agg.ListAllTools(context.Background())\n    if err != nil {\n        t.Fatalf(\"ListAllTools() error = %v\", err)\n    }\n\n    if len(tools) != 3 {\n        t.Errorf(\"ListAllTools() returned %d tools, want 3\", len(tools))\n    }\n}\n\nfunc TestAggregator_Execute(t *testing.T) {\n    registry := NewRegistry()\n\n    registry.Register(&amp;mockBackend{\n        kind:    \"local\",\n        name:    \"local\",\n        enabled: true,\n        execFn: func(ctx context.Context, tool string, args map[string]any) (any, error) {\n            if tool == \"echo\" {\n                return args[\"msg\"], nil\n            }\n            return nil, ErrToolNotFound\n        },\n    })\n\n    agg := NewAggregator(registry)\n\n    // Execute with backend prefix\n    result, err := agg.Execute(context.Background(), \"local/echo\", map[string]any{\n        \"msg\": \"hello\",\n    })\n\n    if err != nil {\n        t.Fatalf(\"Execute() error = %v\", err)\n    }\n\n    if result != \"hello\" {\n        t.Errorf(\"Execute() = %v, want %v\", result, \"hello\")\n    }\n}\n\nfunc TestAggregator_ExecuteNotFound(t *testing.T) {\n    registry := NewRegistry()\n    agg := NewAggregator(registry)\n\n    _, err := agg.Execute(context.Background(), \"nonexistent/tool\", nil)\n    if err == nil {\n        t.Error(\"Execute() should fail for nonexistent backend\")\n    }\n}\n\nfunc TestAggregator_ParseToolID(t *testing.T) {\n    tests := []struct {\n        id              string\n        wantBackend     string\n        wantTool        string\n        wantErr         bool\n    }{\n        {\"local/echo\", \"local\", \"echo\", false},\n        {\"github/create_issue\", \"github\", \"create_issue\", false},\n        {\"my-backend/my_tool\", \"my-backend\", \"my_tool\", false},\n        {\"no_slash\", \"\", \"\", true},\n        {\"\", \"\", \"\", true},\n    }\n\n    for _, tt := range tests {\n        backend, tool, err := ParseToolID(tt.id)\n        if (err != nil) != tt.wantErr {\n            t.Errorf(\"ParseToolID(%q) error = %v, wantErr = %v\", tt.id, err, tt.wantErr)\n            continue\n        }\n        if backend != tt.wantBackend {\n            t.Errorf(\"ParseToolID(%q) backend = %q, want %q\", tt.id, backend, tt.wantBackend)\n        }\n        if tool != tt.wantTool {\n            t.Errorf(\"ParseToolID(%q) tool = %q, want %q\", tt.id, tool, tt.wantTool)\n        }\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/backend/... -run TestAggregator -v</code> Expected: FAIL - Aggregator doesn't exist</p> <p>Step 3: Implement Aggregator</p> <pre><code>// internal/backend/aggregator.go\npackage backend\n\nimport (\n    \"context\"\n    \"errors\"\n    \"fmt\"\n    \"strings\"\n    \"sync\"\n\n    \"github.com/jraymond/toolmodel\"\n)\n\n// ErrInvalidToolID is returned for malformed tool IDs\nvar ErrInvalidToolID = errors.New(\"invalid tool ID format (expected backend/tool)\")\n\n// Aggregator combines tools from multiple backends\ntype Aggregator struct {\n    registry *Registry\n}\n\n// NewAggregator creates a new tool aggregator\nfunc NewAggregator(registry *Registry) *Aggregator {\n    return &amp;Aggregator{registry: registry}\n}\n\n// ListAllTools returns tools from all enabled backends\nfunc (a *Aggregator) ListAllTools(ctx context.Context) ([]toolmodel.Tool, error) {\n    backends := a.registry.ListEnabled()\n\n    var allTools []toolmodel.Tool\n    var mu sync.Mutex\n    var wg sync.WaitGroup\n    var firstErr error\n\n    for _, b := range backends {\n        wg.Add(1)\n        go func(backend Backend) {\n            defer wg.Done()\n\n            tools, err := backend.ListTools(ctx)\n            if err != nil {\n                mu.Lock()\n                if firstErr == nil {\n                    firstErr = fmt.Errorf(\"backend %s: %w\", backend.Name(), err)\n                }\n                mu.Unlock()\n                return\n            }\n\n            // Add backend prefix to tool IDs\n            for i := range tools {\n                if tools[i].Namespace == \"\" {\n                    tools[i].Namespace = backend.Name()\n                }\n            }\n\n            mu.Lock()\n            allTools = append(allTools, tools...)\n            mu.Unlock()\n        }(b)\n    }\n\n    wg.Wait()\n\n    if firstErr != nil {\n        return nil, firstErr\n    }\n\n    return allTools, nil\n}\n\n// Execute invokes a tool on the appropriate backend\nfunc (a *Aggregator) Execute(ctx context.Context, toolID string, args map[string]any) (any, error) {\n    backendName, toolName, err := ParseToolID(toolID)\n    if err != nil {\n        return nil, err\n    }\n\n    backend, ok := a.registry.Get(backendName)\n    if !ok {\n        return nil, fmt.Errorf(\"%w: %s\", ErrBackendNotFound, backendName)\n    }\n\n    if !backend.Enabled() {\n        return nil, fmt.Errorf(\"%w: %s\", ErrBackendDisabled, backendName)\n    }\n\n    return backend.Execute(ctx, toolName, args)\n}\n\n// ExecuteResult contains execution result with metadata\ntype ExecuteResult struct {\n    Result    any\n    Backend   string\n    Tool      string\n    Duration  int64 // milliseconds\n}\n\n// ExecuteWithInfo invokes a tool and returns detailed result\nfunc (a *Aggregator) ExecuteWithInfo(ctx context.Context, toolID string, args map[string]any) (*ExecuteResult, error) {\n    backendName, toolName, err := ParseToolID(toolID)\n    if err != nil {\n        return nil, err\n    }\n\n    backend, ok := a.registry.Get(backendName)\n    if !ok {\n        return nil, fmt.Errorf(\"%w: %s\", ErrBackendNotFound, backendName)\n    }\n\n    if !backend.Enabled() {\n        return nil, fmt.Errorf(\"%w: %s\", ErrBackendDisabled, backendName)\n    }\n\n    result, err := backend.Execute(ctx, toolName, args)\n    if err != nil {\n        return nil, err\n    }\n\n    return &amp;ExecuteResult{\n        Result:  result,\n        Backend: backendName,\n        Tool:    toolName,\n    }, nil\n}\n\n// ParseToolID splits a qualified tool ID into backend and tool names\nfunc ParseToolID(id string) (backend, tool string, err error) {\n    if id == \"\" {\n        return \"\", \"\", ErrInvalidToolID\n    }\n\n    parts := strings.SplitN(id, \"/\", 2)\n    if len(parts) != 2 || parts[0] == \"\" || parts[1] == \"\" {\n        return \"\", \"\", fmt.Errorf(\"%w: %s\", ErrInvalidToolID, id)\n    }\n\n    return parts[0], parts[1], nil\n}\n\n// FormatToolID creates a qualified tool ID from backend and tool names\nfunc FormatToolID(backend, tool string) string {\n    return fmt.Sprintf(\"%s/%s\", backend, tool)\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/backend/... -run TestAggregator -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/backend/aggregator.go internal/backend/aggregator_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(backend): implement Tool Aggregator\n\n- ListAllTools aggregates from all enabled backends (parallel)\n- Execute routes to correct backend by tool ID prefix\n- ParseToolID/FormatToolID for qualified IDs (backend/tool)\n- ExecuteWithInfo returns result with metadata\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#task-5-add-backend-configuration-support","title":"Task 5: Add Backend Configuration Support","text":"<p>Files: - Create: <code>internal/backend/config.go</code> - Test: <code>internal/backend/config_test.go</code></p> <p>Step 1: Write failing test for config loading</p> <pre><code>// internal/backend/config_test.go\npackage backend\n\nimport (\n    \"testing\"\n)\n\nfunc TestBackendConfig_Unmarshal(t *testing.T) {\n    yaml := `\nbackends:\n  local:\n    enabled: true\n    paths:\n      - ~/.config/metatools/tools\n  github:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-github\"]\n`\n    cfg, err := ParseBackendsConfig([]byte(yaml))\n    if err != nil {\n        t.Fatalf(\"ParseBackendsConfig() error = %v\", err)\n    }\n\n    if len(cfg.Backends) != 2 {\n        t.Errorf(\"Expected 2 backends, got %d\", len(cfg.Backends))\n    }\n\n    local, ok := cfg.Backends[\"local\"]\n    if !ok {\n        t.Fatal(\"local backend not found\")\n    }\n    if !local.Enabled {\n        t.Error(\"local backend should be enabled\")\n    }\n\n    github, ok := cfg.Backends[\"github\"]\n    if !ok {\n        t.Fatal(\"github backend not found\")\n    }\n    if github.Kind != \"mcp\" {\n        t.Errorf(\"github.Kind = %q, want %q\", github.Kind, \"mcp\")\n    }\n}\n\nfunc TestBackendConfig_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        cfg     BackendConfig\n        wantErr bool\n    }{\n        {\n            name:    \"valid local\",\n            cfg:     BackendConfig{Kind: \"local\", Enabled: true},\n            wantErr: false,\n        },\n        {\n            name:    \"valid mcp\",\n            cfg:     BackendConfig{Kind: \"mcp\", Enabled: true},\n            wantErr: false,\n        },\n        {\n            name:    \"empty kind defaults to local\",\n            cfg:     BackendConfig{Enabled: true},\n            wantErr: false,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            err := tt.cfg.Validate()\n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Validate() error = %v, wantErr = %v\", err, tt.wantErr)\n            }\n        })\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/backend/... -run TestBackendConfig -v</code> Expected: FAIL - Config types don't exist</p> <p>Step 3: Implement config types</p> <pre><code>// internal/backend/config.go\npackage backend\n\nimport (\n    \"fmt\"\n\n    \"gopkg.in/yaml.v3\"\n)\n\n// BackendsConfig is the top-level backends configuration\ntype BackendsConfig struct {\n    Backends map[string]BackendConfig `yaml:\"backends\" koanf:\"backends\"`\n}\n\n// BackendConfig configures a single backend\ntype BackendConfig struct {\n    // Kind is the backend type (local, mcp, http, custom)\n    // Defaults to \"local\" if not specified\n    Kind string `yaml:\"kind\" koanf:\"kind\"`\n\n    // Enabled determines if the backend is active\n    Enabled bool `yaml:\"enabled\" koanf:\"enabled\"`\n\n    // Config contains backend-specific configuration\n    // This is passed as raw bytes to ConfigurableBackend.Configure()\n    Config map[string]any `yaml:\"config\" koanf:\"config\"`\n\n    // Common fields extracted for convenience\n    Paths   []string `yaml:\"paths,omitempty\" koanf:\"paths\"`\n    Command string   `yaml:\"command,omitempty\" koanf:\"command\"`\n    Args    []string `yaml:\"args,omitempty\" koanf:\"args\"`\n    BaseURL string   `yaml:\"base_url,omitempty\" koanf:\"base_url\"`\n}\n\n// ParseBackendsConfig parses YAML configuration\nfunc ParseBackendsConfig(data []byte) (*BackendsConfig, error) {\n    var cfg BackendsConfig\n    if err := yaml.Unmarshal(data, &amp;cfg); err != nil {\n        return nil, fmt.Errorf(\"parse backends config: %w\", err)\n    }\n\n    // Set defaults\n    for name, bc := range cfg.Backends {\n        if bc.Kind == \"\" {\n            bc.Kind = \"local\"\n            cfg.Backends[name] = bc\n        }\n    }\n\n    return &amp;cfg, nil\n}\n\n// Validate checks the configuration is valid\nfunc (c *BackendConfig) Validate() error {\n    // Kind defaults to local\n    if c.Kind == \"\" {\n        c.Kind = \"local\"\n    }\n\n    switch c.Kind {\n    case \"local\", \"mcp\", \"http\", \"custom\":\n        // Valid kinds\n    default:\n        return fmt.Errorf(\"unknown backend kind: %s\", c.Kind)\n    }\n\n    return nil\n}\n\n// RawConfig returns the config section as YAML bytes for ConfigurableBackend\nfunc (c *BackendConfig) RawConfig() ([]byte, error) {\n    if c.Config == nil {\n        return nil, nil\n    }\n    return yaml.Marshal(c.Config)\n}\n\n// LoadFromConfig creates backends from configuration\nfunc (r *Registry) LoadFromConfig(cfg *BackendsConfig) error {\n    for name, backendCfg := range cfg.Backends {\n        if err := backendCfg.Validate(); err != nil {\n            return fmt.Errorf(\"backend %s: %w\", name, err)\n        }\n\n        if !backendCfg.Enabled {\n            continue\n        }\n\n        // Get factory for this kind\n        factory, ok := r.factories[backendCfg.Kind]\n        if !ok {\n            // For now, only local is built-in; others require explicit registration\n            if backendCfg.Kind != \"local\" {\n                return fmt.Errorf(\"no factory for backend kind: %s\", backendCfg.Kind)\n            }\n            continue // Local backend handled separately\n        }\n\n        // Create backend\n        backend, err := factory(name)\n        if err != nil {\n            return fmt.Errorf(\"create backend %s: %w\", name, err)\n        }\n\n        // Configure if possible\n        if configurable, ok := backend.(ConfigurableBackend); ok {\n            raw, err := backendCfg.RawConfig()\n            if err != nil {\n                return fmt.Errorf(\"serialize config for %s: %w\", name, err)\n            }\n            if raw != nil {\n                if err := configurable.Configure(raw); err != nil {\n                    return fmt.Errorf(\"configure backend %s: %w\", name, err)\n                }\n            }\n        }\n\n        // Register\n        if err := r.Register(backend); err != nil {\n            return fmt.Errorf(\"register backend %s: %w\", name, err)\n        }\n    }\n\n    return nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/backend/... -run TestBackendConfig -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/backend/config.go internal/backend/config_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(backend): add configuration support\n\n- BackendsConfig and BackendConfig types\n- ParseBackendsConfig for YAML parsing\n- Validate() for config validation\n- LoadFromConfig to create backends from config\n- RawConfig() for passing to ConfigurableBackend\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#task-6-integrate-with-server","title":"Task 6: Integrate with Server","text":"<p>Files: - Create: <code>internal/server/backend_adapter.go</code> - Test: <code>internal/server/backend_adapter_test.go</code></p> <p>Step 1: Write integration test</p> <pre><code>// internal/server/backend_adapter_test.go\npackage server\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/your-org/metatools-mcp/internal/backend\"\n    \"github.com/your-org/metatools-mcp/internal/backend/local\"\n)\n\nfunc TestBackendAdapter_GetTools(t *testing.T) {\n    registry := backend.NewRegistry()\n\n    // Create local backend with a test tool\n    localBackend := local.New(\"local\")\n    localBackend.RegisterHandler(\"echo\", local.ToolDef{\n        Name:        \"echo\",\n        Description: \"Echo input\",\n        Handler: func(ctx context.Context, args map[string]any) (any, error) {\n            return args[\"message\"], nil\n        },\n    })\n\n    registry.Register(localBackend)\n\n    adapter := NewBackendAdapter(registry)\n\n    tools, err := adapter.GetTools(context.Background())\n    if err != nil {\n        t.Fatalf(\"GetTools() error = %v\", err)\n    }\n\n    if len(tools) == 0 {\n        t.Error(\"GetTools() returned empty tools\")\n    }\n}\n\nfunc TestBackendAdapter_Execute(t *testing.T) {\n    registry := backend.NewRegistry()\n\n    localBackend := local.New(\"local\")\n    localBackend.RegisterHandler(\"echo\", local.ToolDef{\n        Name:        \"echo\",\n        Description: \"Echo input\",\n        Handler: func(ctx context.Context, args map[string]any) (any, error) {\n            return args[\"message\"], nil\n        },\n    })\n\n    registry.Register(localBackend)\n\n    adapter := NewBackendAdapter(registry)\n\n    result, err := adapter.Execute(context.Background(), \"local/echo\", map[string]any{\n        \"message\": \"hello world\",\n    })\n\n    if err != nil {\n        t.Fatalf(\"Execute() error = %v\", err)\n    }\n\n    if result != \"hello world\" {\n        t.Errorf(\"Execute() = %v, want %v\", result, \"hello world\")\n    }\n}\n</code></pre> <p>Step 2: Implement adapter</p> <pre><code>// internal/server/backend_adapter.go\npackage server\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n\n    \"github.com/mark3labs/mcp-go/mcp\"\n    \"github.com/your-org/metatools-mcp/internal/backend\"\n)\n\n// BackendAdapter adapts the backend registry for the MCP server\ntype BackendAdapter struct {\n    registry   *backend.Registry\n    aggregator *backend.Aggregator\n}\n\n// NewBackendAdapter creates a new adapter\nfunc NewBackendAdapter(registry *backend.Registry) *BackendAdapter {\n    return &amp;BackendAdapter{\n        registry:   registry,\n        aggregator: backend.NewAggregator(registry),\n    }\n}\n\n// GetTools returns all tools from all enabled backends\nfunc (a *BackendAdapter) GetTools(ctx context.Context) ([]mcp.Tool, error) {\n    tools, err := a.aggregator.ListAllTools(ctx)\n    if err != nil {\n        return nil, err\n    }\n\n    mcpTools := make([]mcp.Tool, 0, len(tools))\n    for _, t := range tools {\n        // Use qualified ID (backend/tool)\n        qualifiedName := backend.FormatToolID(t.Namespace, t.Name)\n        mcpTool := mcp.Tool{\n            Name:        qualifiedName,\n            Description: t.Description,\n            InputSchema: t.InputSchema,\n        }\n        mcpTools = append(mcpTools, mcpTool)\n    }\n\n    return mcpTools, nil\n}\n\n// Execute invokes a tool through the backend registry\nfunc (a *BackendAdapter) Execute(ctx context.Context, toolID string, args map[string]any) (any, error) {\n    return a.aggregator.Execute(ctx, toolID, args)\n}\n\n// CreateToolHandler creates an MCP tool handler for backend tools\nfunc (a *BackendAdapter) CreateToolHandler() mcp.ToolHandler {\n    return func(ctx context.Context, req mcp.CallToolRequest) (*mcp.CallToolResult, error) {\n        result, err := a.Execute(ctx, req.Params.Name, req.Params.Arguments)\n        if err != nil {\n            return nil, err\n        }\n\n        // Format result as JSON\n        text, err := formatAsText(result)\n        if err != nil {\n            return nil, err\n        }\n\n        return &amp;mcp.CallToolResult{\n            Content: []mcp.Content{\n                mcp.TextContent{\n                    Type: \"text\",\n                    Text: text,\n                },\n            },\n        }, nil\n    }\n}\n\n// formatAsText converts a result to string\nfunc formatAsText(result any) (string, error) {\n    switch v := result.(type) {\n    case string:\n        return v, nil\n    case []byte:\n        return string(v), nil\n    default:\n        data, err := json.MarshalIndent(result, \"\", \"  \")\n        if err != nil {\n            return fmt.Sprintf(\"%v\", result), nil\n        }\n        return string(data), nil\n    }\n}\n\n// Start starts all backends\nfunc (a *BackendAdapter) Start(ctx context.Context) error {\n    return a.registry.StartAll(ctx)\n}\n\n// Stop stops all backends\nfunc (a *BackendAdapter) Stop() error {\n    return a.registry.StopAll()\n}\n</code></pre> <p>Step 3: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/server/... -run TestBackendAdapter -v</code> Expected: PASS</p> <p>Step 4: Commit</p> <pre><code>git add internal/server/backend_adapter.go internal/server/backend_adapter_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(server): add BackendAdapter for registry integration\n\n- GetTools aggregates tools from all backends\n- Execute routes to correct backend by tool ID\n- CreateToolHandler for MCP server integration\n- Start/Stop for backend lifecycle\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Backend interface defined with Kind, Name, Enabled, ListTools, Execute</li> <li>[ ] ConfigurableBackend interface for YAML config</li> <li>[ ] StreamingBackend interface for streaming responses</li> <li>[ ] Registry with Register/Get/List/ListByKind</li> <li>[ ] LocalBackend implementation</li> <li>[ ] Aggregator for multi-backend tool listing and execution</li> <li>[ ] ParseToolID/FormatToolID for qualified IDs</li> <li>[ ] BackendsConfig for YAML configuration</li> <li>[ ] BackendAdapter for server integration</li> <li>[ ] All tests pass</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#definition-of-done","title":"Definition of Done","text":"<ol> <li>All tests pass: <code>go test ./internal/backend/...</code></li> <li>Backend interface enables multiple tool sources</li> <li>LocalBackend works for in-process handlers</li> <li>Aggregator combines tools from all backends</li> <li>Configuration supports YAML-based backend definition</li> <li>Server can use backends for tool discovery and execution</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-006-backend-registry/#next-prd","title":"Next PRD","text":"<p>PRD-007 will implement the Middleware Chain for cross-cutting concerns (logging, auth, rate limiting).</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/","title":"PRD-007: Middleware Chain","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement a Middleware Chain enabling cross-cutting concerns (logging, auth, rate limiting, metrics) to be applied to tool providers through composable, configuration-driven middleware functions.</p> <p>Architecture: Define a Middleware type as a function that wraps a ToolProvider. Create a MiddlewareRegistry for managing available middleware. Implement core middleware (logging, metrics). Enable configuration-driven chain construction with per-tool customization.</p> <p>Tech Stack: Go interfaces, provider integration from PRD-005, config integration from PRD-003</p> <p>Priority: P2 - Stream A, Phase 5 (completes core exposure)</p> <p>Scope: Middleware interface + registry + chain builder + logging middleware + metrics middleware</p> <p>Dependencies: PRD-002 (CLI), PRD-003 (Config), PRD-005 (Provider Registry)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#context","title":"Context","text":"<p>The current architecture lacks cross-cutting concerns that are essential for production deployments: 1. Request/response logging for debugging and audit 2. Metrics collection for observability 3. Rate limiting for protection 4. Authentication for security</p> <p>Current State: <pre><code>// No middleware - each provider handles concerns independently\nprovider.Handle(ctx, args)  // No logging, no metrics\n</code></pre></p> <p>Target State: <pre><code>// Middleware wraps providers with cross-cutting concerns\ntype Middleware func(provider.ToolProvider) provider.ToolProvider\n\n// Chain applies multiple middleware in order\nwrapped := chain.Apply(\n    LoggingMiddleware,\n    MetricsMiddleware,\n    provider,\n)\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#task-1-define-middleware-type-and-registry","title":"Task 1: Define Middleware Type and Registry","text":"<p>Files: - Create: <code>internal/middleware/middleware.go</code> - Test: <code>internal/middleware/middleware_test.go</code></p> <p>Step 1: Write failing test for Middleware type</p> <pre><code>// internal/middleware/middleware_test.go\npackage middleware\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/mark3labs/mcp-go/mcp\"\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\n// mockProvider for testing\ntype mockProvider struct {\n    name     string\n    enabled  bool\n    handleFn func(ctx context.Context, args map[string]any) (any, error)\n}\n\nfunc (m *mockProvider) Name() string       { return m.name }\nfunc (m *mockProvider) Enabled() bool      { return m.enabled }\nfunc (m *mockProvider) Tool() mcp.Tool     { return mcp.Tool{Name: m.name} }\nfunc (m *mockProvider) Handle(ctx context.Context, args map[string]any) (any, error) {\n    if m.handleFn != nil {\n        return m.handleFn(ctx, args)\n    }\n    return nil, nil\n}\n\nfunc TestMiddleware_Wrapping(t *testing.T) {\n    called := false\n\n    // Simple middleware that sets a flag\n    mw := func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;wrappedProvider{\n            ToolProvider: next,\n            beforeFn: func() {\n                called = true\n            },\n        }\n    }\n\n    original := &amp;mockProvider{name: \"test\", enabled: true}\n    wrapped := mw(original)\n\n    wrapped.Handle(context.Background(), nil)\n\n    if !called {\n        t.Error(\"Middleware was not invoked\")\n    }\n}\n\nfunc TestMiddleware_ChainOrder(t *testing.T) {\n    var order []string\n\n    mw1 := func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;wrappedProvider{\n            ToolProvider: next,\n            beforeFn:     func() { order = append(order, \"mw1-before\") },\n            afterFn:      func() { order = append(order, \"mw1-after\") },\n        }\n    }\n\n    mw2 := func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;wrappedProvider{\n            ToolProvider: next,\n            beforeFn:     func() { order = append(order, \"mw2-before\") },\n            afterFn:      func() { order = append(order, \"mw2-after\") },\n        }\n    }\n\n    original := &amp;mockProvider{\n        name:    \"test\",\n        enabled: true,\n        handleFn: func(ctx context.Context, args map[string]any) (any, error) {\n            order = append(order, \"handler\")\n            return nil, nil\n        },\n    }\n\n    // Chain: mw1 -&gt; mw2 -&gt; handler\n    chain := NewChain(mw1, mw2)\n    wrapped := chain.Apply(original)\n\n    wrapped.Handle(context.Background(), nil)\n\n    expected := []string{\"mw1-before\", \"mw2-before\", \"handler\", \"mw2-after\", \"mw1-after\"}\n    if len(order) != len(expected) {\n        t.Errorf(\"Order = %v, want %v\", order, expected)\n    }\n    for i, v := range expected {\n        if order[i] != v {\n            t.Errorf(\"Order[%d] = %q, want %q\", i, order[i], v)\n        }\n    }\n}\n\n// wrappedProvider for testing middleware behavior\ntype wrappedProvider struct {\n    provider.ToolProvider\n    beforeFn func()\n    afterFn  func()\n}\n\nfunc (w *wrappedProvider) Handle(ctx context.Context, args map[string]any) (any, error) {\n    if w.beforeFn != nil {\n        w.beforeFn()\n    }\n    result, err := w.ToolProvider.Handle(ctx, args)\n    if w.afterFn != nil {\n        w.afterFn()\n    }\n    return result, err\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/middleware/... -v</code> Expected: FAIL - Middleware types don't exist</p> <p>Step 3: Implement Middleware types</p> <pre><code>// internal/middleware/middleware.go\npackage middleware\n\nimport (\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\n// Middleware wraps a ToolProvider to add cross-cutting concerns.\n// Middleware functions receive the next provider in the chain and return\n// a wrapped provider that adds behavior before/after the next provider.\ntype Middleware func(provider.ToolProvider) provider.ToolProvider\n\n// Chain holds an ordered list of middleware to apply.\ntype Chain struct {\n    middleware []Middleware\n}\n\n// NewChain creates a new middleware chain.\nfunc NewChain(middleware ...Middleware) *Chain {\n    return &amp;Chain{middleware: middleware}\n}\n\n// Use adds middleware to the chain.\nfunc (c *Chain) Use(mw Middleware) *Chain {\n    c.middleware = append(c.middleware, mw)\n    return c\n}\n\n// Apply wraps a provider with all middleware in the chain.\n// Middleware is applied in order: first middleware wraps outermost.\n// Request flow: mw1 -&gt; mw2 -&gt; ... -&gt; provider\n// Response flow: provider -&gt; ... -&gt; mw2 -&gt; mw1\nfunc (c *Chain) Apply(p provider.ToolProvider) provider.ToolProvider {\n    wrapped := p\n    // Apply in reverse order so first middleware is outermost\n    for i := len(c.middleware) - 1; i &gt;= 0; i-- {\n        wrapped = c.middleware[i](wrapped)\n    }\n    return wrapped\n}\n\n// ApplyToRegistry wraps all providers in a registry with the chain.\nfunc (c *Chain) ApplyToRegistry(registry *provider.Registry) {\n    for _, p := range registry.List() {\n        wrapped := c.Apply(p)\n        registry.Unregister(p.Name())\n        registry.Register(wrapped)\n    }\n}\n\n// Len returns the number of middleware in the chain.\nfunc (c *Chain) Len() int {\n    return len(c.middleware)\n}\n\n// Clear removes all middleware from the chain.\nfunc (c *Chain) Clear() {\n    c.middleware = nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/middleware/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/middleware/middleware.go internal/middleware/middleware_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(middleware): define Middleware type and Chain\n\n- Middleware type wraps ToolProvider\n- Chain holds ordered middleware list\n- Apply wraps provider with all middleware\n- ApplyToRegistry for bulk wrapping\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#task-2-implement-middleware-registry","title":"Task 2: Implement Middleware Registry","text":"<p>Files: - Create: <code>internal/middleware/registry.go</code> - Test: <code>internal/middleware/registry_test.go</code></p> <p>Step 1: Write failing test for registry</p> <pre><code>// internal/middleware/registry_test.go\npackage middleware\n\nimport (\n    \"testing\"\n)\n\nfunc TestRegistry_Register(t *testing.T) {\n    registry := NewRegistry()\n\n    factory := func(cfg map[string]any) (Middleware, error) {\n        return func(next provider.ToolProvider) provider.ToolProvider {\n            return next\n        }, nil\n    }\n\n    registry.Register(\"logging\", factory)\n\n    if !registry.Has(\"logging\") {\n        t.Error(\"Has(logging) = false, want true\")\n    }\n}\n\nfunc TestRegistry_Get(t *testing.T) {\n    registry := NewRegistry()\n\n    factory := func(cfg map[string]any) (Middleware, error) {\n        return func(next provider.ToolProvider) provider.ToolProvider {\n            return next\n        }, nil\n    }\n\n    registry.Register(\"test\", factory)\n\n    got, ok := registry.Get(\"test\")\n    if !ok {\n        t.Fatal(\"Get() returned false\")\n    }\n    if got == nil {\n        t.Error(\"Get() returned nil factory\")\n    }\n\n    _, ok = registry.Get(\"nonexistent\")\n    if ok {\n        t.Error(\"Get() should return false for nonexistent middleware\")\n    }\n}\n\nfunc TestRegistry_Create(t *testing.T) {\n    registry := NewRegistry()\n\n    called := false\n    factory := func(cfg map[string]any) (Middleware, error) {\n        called = true\n        return func(next provider.ToolProvider) provider.ToolProvider {\n            return next\n        }, nil\n    }\n\n    registry.Register(\"test\", factory)\n\n    mw, err := registry.Create(\"test\", nil)\n    if err != nil {\n        t.Fatalf(\"Create() error = %v\", err)\n    }\n    if mw == nil {\n        t.Error(\"Create() returned nil middleware\")\n    }\n    if !called {\n        t.Error(\"Factory was not called\")\n    }\n}\n\nfunc TestRegistry_List(t *testing.T) {\n    registry := NewRegistry()\n\n    registry.Register(\"a\", nil)\n    registry.Register(\"b\", nil)\n    registry.Register(\"c\", nil)\n\n    names := registry.List()\n    if len(names) != 3 {\n        t.Errorf(\"List() returned %d names, want 3\", len(names))\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/middleware/... -run TestRegistry -v</code> Expected: FAIL - Registry doesn't exist</p> <p>Step 3: Implement Registry</p> <pre><code>// internal/middleware/registry.go\npackage middleware\n\nimport (\n    \"errors\"\n    \"fmt\"\n    \"sort\"\n    \"sync\"\n)\n\n// ErrMiddlewareNotFound is returned when middleware is not registered.\nvar ErrMiddlewareNotFound = errors.New(\"middleware not found\")\n\n// Factory creates a middleware instance from configuration.\ntype Factory func(cfg map[string]any) (Middleware, error)\n\n// Registry manages middleware factories.\ntype Registry struct {\n    factories map[string]Factory\n    mu        sync.RWMutex\n}\n\n// NewRegistry creates a new middleware registry.\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        factories: make(map[string]Factory),\n    }\n}\n\n// Register adds a middleware factory.\nfunc (r *Registry) Register(name string, factory Factory) {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    r.factories[name] = factory\n}\n\n// Has checks if a middleware is registered.\nfunc (r *Registry) Has(name string) bool {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    _, ok := r.factories[name]\n    return ok\n}\n\n// Get retrieves a middleware factory by name.\nfunc (r *Registry) Get(name string) (Factory, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    f, ok := r.factories[name]\n    return f, ok\n}\n\n// Create instantiates middleware with configuration.\nfunc (r *Registry) Create(name string, cfg map[string]any) (Middleware, error) {\n    factory, ok := r.Get(name)\n    if !ok {\n        return nil, fmt.Errorf(\"%w: %s\", ErrMiddlewareNotFound, name)\n    }\n\n    return factory(cfg)\n}\n\n// List returns all registered middleware names.\nfunc (r *Registry) List() []string {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    names := make([]string, 0, len(r.factories))\n    for name := range r.factories {\n        names = append(names, name)\n    }\n    sort.Strings(names)\n    return names\n}\n\n// Clear removes all registered middleware.\nfunc (r *Registry) Clear() {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    r.factories = make(map[string]Factory)\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/middleware/... -run TestRegistry -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/middleware/registry.go internal/middleware/registry_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(middleware): implement Middleware Registry\n\n- Factory type for middleware creation\n- Register/Get/Has/Create for factory management\n- List returns all registered middleware names\n- Thread-safe with RWMutex\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#task-3-implement-logging-middleware","title":"Task 3: Implement Logging Middleware","text":"<p>Files: - Create: <code>internal/middleware/logging.go</code> - Test: <code>internal/middleware/logging_test.go</code></p> <p>Step 1: Write failing test for LoggingMiddleware</p> <pre><code>// internal/middleware/logging_test.go\npackage middleware\n\nimport (\n    \"bytes\"\n    \"context\"\n    \"log/slog\"\n    \"strings\"\n    \"testing\"\n)\n\nfunc TestLoggingMiddleware(t *testing.T) {\n    var buf bytes.Buffer\n    logger := slog.New(slog.NewTextHandler(&amp;buf, &amp;slog.HandlerOptions{\n        Level: slog.LevelDebug,\n    }))\n\n    mw := NewLoggingMiddleware(LoggingConfig{\n        Logger: logger,\n    })\n\n    original := &amp;mockProvider{\n        name:    \"test_tool\",\n        enabled: true,\n        handleFn: func(ctx context.Context, args map[string]any) (any, error) {\n            return \"result\", nil\n        },\n    }\n\n    wrapped := mw(original)\n\n    _, err := wrapped.Handle(context.Background(), map[string]any{\"key\": \"value\"})\n    if err != nil {\n        t.Fatalf(\"Handle() error = %v\", err)\n    }\n\n    output := buf.String()\n    if !strings.Contains(output, \"test_tool\") {\n        t.Errorf(\"Log output missing tool name: %s\", output)\n    }\n}\n\nfunc TestLoggingMiddleware_Error(t *testing.T) {\n    var buf bytes.Buffer\n    logger := slog.New(slog.NewTextHandler(&amp;buf, &amp;slog.HandlerOptions{\n        Level: slog.LevelDebug,\n    }))\n\n    mw := NewLoggingMiddleware(LoggingConfig{\n        Logger: logger,\n    })\n\n    original := &amp;mockProvider{\n        name:    \"failing_tool\",\n        enabled: true,\n        handleFn: func(ctx context.Context, args map[string]any) (any, error) {\n            return nil, errors.New(\"tool failed\")\n        },\n    }\n\n    wrapped := mw(original)\n\n    _, err := wrapped.Handle(context.Background(), nil)\n    if err == nil {\n        t.Fatal(\"Handle() should return error\")\n    }\n\n    output := buf.String()\n    if !strings.Contains(output, \"error\") || !strings.Contains(output, \"tool failed\") {\n        t.Errorf(\"Log output missing error: %s\", output)\n    }\n}\n\nfunc TestLoggingMiddleware_RequestID(t *testing.T) {\n    var buf bytes.Buffer\n    logger := slog.New(slog.NewTextHandler(&amp;buf, nil))\n\n    mw := NewLoggingMiddleware(LoggingConfig{\n        Logger: logger,\n    })\n\n    original := &amp;mockProvider{name: \"test\", enabled: true}\n    wrapped := mw(original)\n\n    wrapped.Handle(context.Background(), nil)\n\n    output := buf.String()\n    if !strings.Contains(output, \"request_id\") {\n        t.Errorf(\"Log output missing request_id: %s\", output)\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/middleware/... -run TestLoggingMiddleware -v</code> Expected: FAIL - LoggingMiddleware doesn't exist</p> <p>Step 3: Implement LoggingMiddleware</p> <pre><code>// internal/middleware/logging.go\npackage middleware\n\nimport (\n    \"context\"\n    \"log/slog\"\n    \"time\"\n\n    \"github.com/google/uuid\"\n    \"github.com/mark3labs/mcp-go/mcp\"\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\n// LoggingConfig configures the logging middleware.\ntype LoggingConfig struct {\n    Logger              *slog.Logger\n    Level               slog.Level\n    IncludeRequestBody  bool\n    IncludeResponseBody bool\n}\n\n// loggingProvider wraps a provider with logging.\ntype loggingProvider struct {\n    provider.ToolProvider\n    cfg LoggingConfig\n}\n\n// NewLoggingMiddleware creates a middleware that logs requests and responses.\nfunc NewLoggingMiddleware(cfg LoggingConfig) Middleware {\n    if cfg.Logger == nil {\n        cfg.Logger = slog.Default()\n    }\n\n    return func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;loggingProvider{\n            ToolProvider: next,\n            cfg:          cfg,\n        }\n    }\n}\n\n// Handle logs before and after calling the wrapped provider.\nfunc (p *loggingProvider) Handle(ctx context.Context, args map[string]any) (any, error) {\n    requestID := uuid.New().String()\n    start := time.Now()\n\n    // Log request\n    logAttrs := []any{\n        slog.String(\"request_id\", requestID),\n        slog.String(\"tool\", p.ToolProvider.Name()),\n    }\n\n    if p.cfg.IncludeRequestBody {\n        logAttrs = append(logAttrs, slog.Any(\"args\", args))\n    }\n\n    p.cfg.Logger.LogAttrs(ctx, slog.LevelInfo, \"tool request\", logAttrs...)\n\n    // Execute\n    result, err := p.ToolProvider.Handle(ctx, args)\n\n    // Log response\n    duration := time.Since(start)\n    logAttrs = []any{\n        slog.String(\"request_id\", requestID),\n        slog.String(\"tool\", p.ToolProvider.Name()),\n        slog.Duration(\"duration\", duration),\n    }\n\n    if err != nil {\n        logAttrs = append(logAttrs,\n            slog.String(\"error\", err.Error()),\n            slog.Bool(\"success\", false),\n        )\n        p.cfg.Logger.LogAttrs(ctx, slog.LevelError, \"tool error\", logAttrs...)\n    } else {\n        logAttrs = append(logAttrs, slog.Bool(\"success\", true))\n        if p.cfg.IncludeResponseBody {\n            logAttrs = append(logAttrs, slog.Any(\"result\", result))\n        }\n        p.cfg.Logger.LogAttrs(ctx, slog.LevelInfo, \"tool response\", logAttrs...)\n    }\n\n    return result, err\n}\n\n// Name returns the wrapped provider's name.\nfunc (p *loggingProvider) Name() string {\n    return p.ToolProvider.Name()\n}\n\n// Enabled returns the wrapped provider's enabled status.\nfunc (p *loggingProvider) Enabled() bool {\n    return p.ToolProvider.Enabled()\n}\n\n// Tool returns the wrapped provider's tool definition.\nfunc (p *loggingProvider) Tool() mcp.Tool {\n    return p.ToolProvider.Tool()\n}\n\n// LoggingMiddlewareFactory creates a logging middleware from config.\nfunc LoggingMiddlewareFactory(cfg map[string]any) (Middleware, error) {\n    config := LoggingConfig{\n        Logger: slog.Default(),\n    }\n\n    if level, ok := cfg[\"level\"].(string); ok {\n        var lvl slog.Level\n        if err := lvl.UnmarshalText([]byte(level)); err == nil {\n            config.Level = lvl\n        }\n    }\n\n    if includeReq, ok := cfg[\"include_request_body\"].(bool); ok {\n        config.IncludeRequestBody = includeReq\n    }\n\n    if includeResp, ok := cfg[\"include_response_body\"].(bool); ok {\n        config.IncludeResponseBody = includeResp\n    }\n\n    return NewLoggingMiddleware(config), nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/middleware/... -run TestLoggingMiddleware -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/middleware/logging.go internal/middleware/logging_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(middleware): implement LoggingMiddleware\n\n- Logs request start with tool name and request_id\n- Logs response with duration, success, and error\n- Configurable request/response body inclusion\n- Uses slog for structured logging\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#task-4-implement-metrics-middleware","title":"Task 4: Implement Metrics Middleware","text":"<p>Files: - Create: <code>internal/middleware/metrics.go</code> - Test: <code>internal/middleware/metrics_test.go</code></p> <p>Step 1: Write failing test for MetricsMiddleware</p> <pre><code>// internal/middleware/metrics_test.go\npackage middleware\n\nimport (\n    \"context\"\n    \"errors\"\n    \"testing\"\n    \"time\"\n)\n\nfunc TestMetricsMiddleware(t *testing.T) {\n    collector := NewInMemoryMetricsCollector()\n\n    mw := NewMetricsMiddleware(MetricsConfig{\n        Collector: collector,\n    })\n\n    original := &amp;mockProvider{\n        name:    \"test_tool\",\n        enabled: true,\n        handleFn: func(ctx context.Context, args map[string]any) (any, error) {\n            time.Sleep(10 * time.Millisecond) // Simulate work\n            return \"result\", nil\n        },\n    }\n\n    wrapped := mw(original)\n\n    _, err := wrapped.Handle(context.Background(), nil)\n    if err != nil {\n        t.Fatalf(\"Handle() error = %v\", err)\n    }\n\n    // Check metrics\n    metrics := collector.GetMetrics(\"test_tool\")\n    if metrics.TotalRequests != 1 {\n        t.Errorf(\"TotalRequests = %d, want 1\", metrics.TotalRequests)\n    }\n    if metrics.SuccessCount != 1 {\n        t.Errorf(\"SuccessCount = %d, want 1\", metrics.SuccessCount)\n    }\n    if metrics.ErrorCount != 0 {\n        t.Errorf(\"ErrorCount = %d, want 0\", metrics.ErrorCount)\n    }\n    if metrics.LastDuration &lt; 10*time.Millisecond {\n        t.Errorf(\"LastDuration = %v, want &gt;= 10ms\", metrics.LastDuration)\n    }\n}\n\nfunc TestMetricsMiddleware_Error(t *testing.T) {\n    collector := NewInMemoryMetricsCollector()\n\n    mw := NewMetricsMiddleware(MetricsConfig{\n        Collector: collector,\n    })\n\n    original := &amp;mockProvider{\n        name:    \"failing_tool\",\n        enabled: true,\n        handleFn: func(ctx context.Context, args map[string]any) (any, error) {\n            return nil, errors.New(\"failed\")\n        },\n    }\n\n    wrapped := mw(original)\n    wrapped.Handle(context.Background(), nil)\n\n    metrics := collector.GetMetrics(\"failing_tool\")\n    if metrics.ErrorCount != 1 {\n        t.Errorf(\"ErrorCount = %d, want 1\", metrics.ErrorCount)\n    }\n    if metrics.SuccessCount != 0 {\n        t.Errorf(\"SuccessCount = %d, want 0\", metrics.SuccessCount)\n    }\n}\n\nfunc TestMetricsMiddleware_ActiveRequests(t *testing.T) {\n    collector := NewInMemoryMetricsCollector()\n\n    mw := NewMetricsMiddleware(MetricsConfig{\n        Collector: collector,\n    })\n\n    started := make(chan struct{})\n    done := make(chan struct{})\n\n    original := &amp;mockProvider{\n        name:    \"slow_tool\",\n        enabled: true,\n        handleFn: func(ctx context.Context, args map[string]any) (any, error) {\n            close(started)\n            &lt;-done\n            return nil, nil\n        },\n    }\n\n    wrapped := mw(original)\n\n    go wrapped.Handle(context.Background(), nil)\n\n    &lt;-started // Wait for handler to start\n\n    metrics := collector.GetMetrics(\"slow_tool\")\n    if metrics.ActiveRequests != 1 {\n        t.Errorf(\"ActiveRequests = %d, want 1\", metrics.ActiveRequests)\n    }\n\n    close(done) // Allow handler to complete\n    time.Sleep(10 * time.Millisecond) // Let goroutine finish\n\n    metrics = collector.GetMetrics(\"slow_tool\")\n    if metrics.ActiveRequests != 0 {\n        t.Errorf(\"ActiveRequests after completion = %d, want 0\", metrics.ActiveRequests)\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/middleware/... -run TestMetricsMiddleware -v</code> Expected: FAIL - MetricsMiddleware doesn't exist</p> <p>Step 3: Implement MetricsMiddleware</p> <pre><code>// internal/middleware/metrics.go\npackage middleware\n\nimport (\n    \"context\"\n    \"sync\"\n    \"sync/atomic\"\n    \"time\"\n\n    \"github.com/mark3labs/mcp-go/mcp\"\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\n// ToolMetrics holds metrics for a single tool.\ntype ToolMetrics struct {\n    TotalRequests  int64\n    SuccessCount   int64\n    ErrorCount     int64\n    ActiveRequests int64\n    TotalDuration  time.Duration\n    LastDuration   time.Duration\n}\n\n// MetricsCollector defines the interface for collecting metrics.\ntype MetricsCollector interface {\n    RecordRequest(tool string)\n    RecordSuccess(tool string, duration time.Duration)\n    RecordError(tool string, duration time.Duration)\n    RecordActive(tool string, delta int64)\n    GetMetrics(tool string) ToolMetrics\n}\n\n// InMemoryMetricsCollector stores metrics in memory.\ntype InMemoryMetricsCollector struct {\n    metrics map[string]*toolMetricsState\n    mu      sync.RWMutex\n}\n\ntype toolMetricsState struct {\n    totalRequests  atomic.Int64\n    successCount   atomic.Int64\n    errorCount     atomic.Int64\n    activeRequests atomic.Int64\n    totalDuration  atomic.Int64 // nanoseconds\n    lastDuration   atomic.Int64 // nanoseconds\n}\n\n// NewInMemoryMetricsCollector creates an in-memory collector.\nfunc NewInMemoryMetricsCollector() *InMemoryMetricsCollector {\n    return &amp;InMemoryMetricsCollector{\n        metrics: make(map[string]*toolMetricsState),\n    }\n}\n\nfunc (c *InMemoryMetricsCollector) getOrCreate(tool string) *toolMetricsState {\n    c.mu.RLock()\n    state, ok := c.metrics[tool]\n    c.mu.RUnlock()\n\n    if ok {\n        return state\n    }\n\n    c.mu.Lock()\n    defer c.mu.Unlock()\n\n    // Double-check after acquiring write lock\n    if state, ok := c.metrics[tool]; ok {\n        return state\n    }\n\n    state = &amp;toolMetricsState{}\n    c.metrics[tool] = state\n    return state\n}\n\nfunc (c *InMemoryMetricsCollector) RecordRequest(tool string) {\n    state := c.getOrCreate(tool)\n    state.totalRequests.Add(1)\n}\n\nfunc (c *InMemoryMetricsCollector) RecordSuccess(tool string, duration time.Duration) {\n    state := c.getOrCreate(tool)\n    state.successCount.Add(1)\n    state.totalDuration.Add(int64(duration))\n    state.lastDuration.Store(int64(duration))\n}\n\nfunc (c *InMemoryMetricsCollector) RecordError(tool string, duration time.Duration) {\n    state := c.getOrCreate(tool)\n    state.errorCount.Add(1)\n    state.totalDuration.Add(int64(duration))\n    state.lastDuration.Store(int64(duration))\n}\n\nfunc (c *InMemoryMetricsCollector) RecordActive(tool string, delta int64) {\n    state := c.getOrCreate(tool)\n    state.activeRequests.Add(delta)\n}\n\nfunc (c *InMemoryMetricsCollector) GetMetrics(tool string) ToolMetrics {\n    state := c.getOrCreate(tool)\n    return ToolMetrics{\n        TotalRequests:  state.totalRequests.Load(),\n        SuccessCount:   state.successCount.Load(),\n        ErrorCount:     state.errorCount.Load(),\n        ActiveRequests: state.activeRequests.Load(),\n        TotalDuration:  time.Duration(state.totalDuration.Load()),\n        LastDuration:   time.Duration(state.lastDuration.Load()),\n    }\n}\n\n// MetricsConfig configures the metrics middleware.\ntype MetricsConfig struct {\n    Collector MetricsCollector\n    Labels    map[string]string\n}\n\n// metricsProvider wraps a provider with metrics collection.\ntype metricsProvider struct {\n    provider.ToolProvider\n    collector MetricsCollector\n}\n\n// NewMetricsMiddleware creates a middleware that collects metrics.\nfunc NewMetricsMiddleware(cfg MetricsConfig) Middleware {\n    collector := cfg.Collector\n    if collector == nil {\n        collector = NewInMemoryMetricsCollector()\n    }\n\n    return func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;metricsProvider{\n            ToolProvider: next,\n            collector:    collector,\n        }\n    }\n}\n\n// Handle collects metrics around the wrapped provider call.\nfunc (p *metricsProvider) Handle(ctx context.Context, args map[string]any) (any, error) {\n    toolName := p.ToolProvider.Name()\n\n    p.collector.RecordRequest(toolName)\n    p.collector.RecordActive(toolName, 1)\n\n    start := time.Now()\n\n    result, err := p.ToolProvider.Handle(ctx, args)\n\n    duration := time.Since(start)\n    p.collector.RecordActive(toolName, -1)\n\n    if err != nil {\n        p.collector.RecordError(toolName, duration)\n    } else {\n        p.collector.RecordSuccess(toolName, duration)\n    }\n\n    return result, err\n}\n\n// Name returns the wrapped provider's name.\nfunc (p *metricsProvider) Name() string {\n    return p.ToolProvider.Name()\n}\n\n// Enabled returns the wrapped provider's enabled status.\nfunc (p *metricsProvider) Enabled() bool {\n    return p.ToolProvider.Enabled()\n}\n\n// Tool returns the wrapped provider's tool definition.\nfunc (p *metricsProvider) Tool() mcp.Tool {\n    return p.ToolProvider.Tool()\n}\n\n// MetricsMiddlewareFactory creates a metrics middleware from config.\nfunc MetricsMiddlewareFactory(cfg map[string]any) (Middleware, error) {\n    config := MetricsConfig{\n        Collector: NewInMemoryMetricsCollector(),\n    }\n\n    if labels, ok := cfg[\"labels\"].(map[string]any); ok {\n        config.Labels = make(map[string]string)\n        for k, v := range labels {\n            if s, ok := v.(string); ok {\n                config.Labels[k] = s\n            }\n        }\n    }\n\n    return NewMetricsMiddleware(config), nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/middleware/... -run TestMetricsMiddleware -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/middleware/metrics.go internal/middleware/metrics_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(middleware): implement MetricsMiddleware\n\n- MetricsCollector interface for pluggable backends\n- InMemoryMetricsCollector for simple deployments\n- Tracks requests, success/error counts, duration\n- Active requests tracking for concurrency monitoring\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#task-5-add-configuration-support-and-chain-builder","title":"Task 5: Add Configuration Support and Chain Builder","text":"<p>Files: - Create: <code>internal/middleware/config.go</code> - Test: <code>internal/middleware/config_test.go</code></p> <p>Step 1: Write failing test for config-driven chain building</p> <pre><code>// internal/middleware/config_test.go\npackage middleware\n\nimport (\n    \"testing\"\n)\n\nfunc TestMiddlewareConfig_Parse(t *testing.T) {\n    yaml := `\nmiddleware:\n  chain:\n    - logging\n    - metrics\n  logging:\n    enabled: true\n    level: info\n  metrics:\n    enabled: true\n`\n    cfg, err := ParseMiddlewareConfig([]byte(yaml))\n    if err != nil {\n        t.Fatalf(\"ParseMiddlewareConfig() error = %v\", err)\n    }\n\n    if len(cfg.Chain) != 2 {\n        t.Errorf(\"Chain length = %d, want 2\", len(cfg.Chain))\n    }\n\n    if cfg.Chain[0] != \"logging\" || cfg.Chain[1] != \"metrics\" {\n        t.Errorf(\"Chain = %v, want [logging, metrics]\", cfg.Chain)\n    }\n}\n\nfunc TestBuildChainFromConfig(t *testing.T) {\n    registry := NewRegistry()\n    registry.Register(\"logging\", LoggingMiddlewareFactory)\n    registry.Register(\"metrics\", MetricsMiddlewareFactory)\n\n    cfg := &amp;MiddlewareConfig{\n        Chain: []string{\"logging\", \"metrics\"},\n        Configs: map[string]MiddlewareEntry{\n            \"logging\": {Enabled: true, Config: map[string]any{\"level\": \"info\"}},\n            \"metrics\": {Enabled: true, Config: nil},\n        },\n    }\n\n    chain, err := BuildChainFromConfig(registry, cfg)\n    if err != nil {\n        t.Fatalf(\"BuildChainFromConfig() error = %v\", err)\n    }\n\n    if chain.Len() != 2 {\n        t.Errorf(\"Chain length = %d, want 2\", chain.Len())\n    }\n}\n\nfunc TestBuildChainFromConfig_DisabledMiddleware(t *testing.T) {\n    registry := NewRegistry()\n    registry.Register(\"logging\", LoggingMiddlewareFactory)\n    registry.Register(\"metrics\", MetricsMiddlewareFactory)\n\n    cfg := &amp;MiddlewareConfig{\n        Chain: []string{\"logging\", \"metrics\"},\n        Configs: map[string]MiddlewareEntry{\n            \"logging\": {Enabled: true},\n            \"metrics\": {Enabled: false}, // Disabled\n        },\n    }\n\n    chain, err := BuildChainFromConfig(registry, cfg)\n    if err != nil {\n        t.Fatalf(\"BuildChainFromConfig() error = %v\", err)\n    }\n\n    if chain.Len() != 1 {\n        t.Errorf(\"Chain length = %d, want 1 (metrics disabled)\", chain.Len())\n    }\n}\n\nfunc TestBuildChainFromConfig_UnknownMiddleware(t *testing.T) {\n    registry := NewRegistry()\n    // Don't register anything\n\n    cfg := &amp;MiddlewareConfig{\n        Chain: []string{\"unknown\"},\n        Configs: map[string]MiddlewareEntry{\n            \"unknown\": {Enabled: true},\n        },\n    }\n\n    _, err := BuildChainFromConfig(registry, cfg)\n    if err == nil {\n        t.Error(\"BuildChainFromConfig() should fail for unknown middleware\")\n    }\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/middleware/... -run TestMiddlewareConfig -v &amp;&amp; go test ./internal/middleware/... -run TestBuildChain -v</code> Expected: FAIL - Config types don't exist</p> <p>Step 3: Implement config types and chain builder</p> <pre><code>// internal/middleware/config.go\npackage middleware\n\nimport (\n    \"fmt\"\n\n    \"gopkg.in/yaml.v3\"\n)\n\n// MiddlewareConfig is the top-level middleware configuration.\ntype MiddlewareConfig struct {\n    // Chain defines the order of middleware to apply\n    Chain []string `yaml:\"chain\" koanf:\"chain\"`\n\n    // Configs holds per-middleware configuration\n    Configs map[string]MiddlewareEntry `yaml:\",inline\" koanf:\",remain\"`\n}\n\n// MiddlewareEntry configures a single middleware.\ntype MiddlewareEntry struct {\n    Enabled bool           `yaml:\"enabled\" koanf:\"enabled\"`\n    Config  map[string]any `yaml:\"config,omitempty\" koanf:\"config\"`\n}\n\n// ParseMiddlewareConfig parses YAML configuration.\nfunc ParseMiddlewareConfig(data []byte) (*MiddlewareConfig, error) {\n    // First parse the root structure\n    var root struct {\n        Middleware struct {\n            Chain   []string       `yaml:\"chain\"`\n            Configs map[string]any `yaml:\",inline\"`\n        } `yaml:\"middleware\"`\n    }\n\n    if err := yaml.Unmarshal(data, &amp;root); err != nil {\n        return nil, fmt.Errorf(\"parse middleware config: %w\", err)\n    }\n\n    cfg := &amp;MiddlewareConfig{\n        Chain:   root.Middleware.Chain,\n        Configs: make(map[string]MiddlewareEntry),\n    }\n\n    // Parse each middleware config\n    for name, raw := range root.Middleware.Configs {\n        if name == \"chain\" {\n            continue // Skip the chain key\n        }\n\n        entry := MiddlewareEntry{}\n\n        switch v := raw.(type) {\n        case map[string]any:\n            if enabled, ok := v[\"enabled\"].(bool); ok {\n                entry.Enabled = enabled\n            }\n            delete(v, \"enabled\")\n            if len(v) &gt; 0 {\n                entry.Config = v\n            }\n        case bool:\n            entry.Enabled = v\n        }\n\n        cfg.Configs[name] = entry\n    }\n\n    return cfg, nil\n}\n\n// BuildChainFromConfig creates a middleware chain from configuration.\nfunc BuildChainFromConfig(registry *Registry, cfg *MiddlewareConfig) (*Chain, error) {\n    chain := NewChain()\n\n    for _, name := range cfg.Chain {\n        entry, ok := cfg.Configs[name]\n        if !ok {\n            // If not in configs, assume enabled with no config\n            entry = MiddlewareEntry{Enabled: true}\n        }\n\n        if !entry.Enabled {\n            continue\n        }\n\n        mw, err := registry.Create(name, entry.Config)\n        if err != nil {\n            return nil, fmt.Errorf(\"middleware %s: %w\", name, err)\n        }\n\n        chain.Use(mw)\n    }\n\n    return chain, nil\n}\n\n// DefaultRegistry returns a registry with built-in middleware.\nfunc DefaultRegistry() *Registry {\n    registry := NewRegistry()\n    registry.Register(\"logging\", LoggingMiddlewareFactory)\n    registry.Register(\"metrics\", MetricsMiddlewareFactory)\n    return registry\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/middleware/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/middleware/config.go internal/middleware/config_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(middleware): add configuration support and chain builder\n\n- MiddlewareConfig for YAML configuration\n- ParseMiddlewareConfig for parsing\n- BuildChainFromConfig for config-driven chain creation\n- DefaultRegistry with built-in middleware\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#task-6-integrate-with-server","title":"Task 6: Integrate with Server","text":"<p>Files: - Create: <code>internal/server/middleware_adapter.go</code> - Test: <code>internal/server/middleware_adapter_test.go</code></p> <p>Step 1: Write integration test</p> <pre><code>// internal/server/middleware_adapter_test.go\npackage server\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/your-org/metatools-mcp/internal/middleware\"\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\nfunc TestMiddlewareAdapter_ApplyToProviders(t *testing.T) {\n    // Create provider registry\n    providerRegistry := provider.NewRegistry()\n    providerRegistry.MustRegister(&amp;mockProvider{name: \"tool1\", enabled: true})\n    providerRegistry.MustRegister(&amp;mockProvider{name: \"tool2\", enabled: true})\n\n    // Create middleware chain\n    callCount := 0\n    countingMiddleware := func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;wrappedProvider{\n            ToolProvider: next,\n            beforeFn: func() {\n                callCount++\n            },\n        }\n    }\n\n    chain := middleware.NewChain(countingMiddleware)\n\n    adapter := NewMiddlewareAdapter(chain)\n    adapter.ApplyToProviders(providerRegistry)\n\n    // Execute both tools\n    p1, _ := providerRegistry.Get(\"tool1\")\n    p1.Handle(context.Background(), nil)\n\n    p2, _ := providerRegistry.Get(\"tool2\")\n    p2.Handle(context.Background(), nil)\n\n    if callCount != 2 {\n        t.Errorf(\"Middleware called %d times, want 2\", callCount)\n    }\n}\n\nfunc TestMiddlewareAdapter_FromConfig(t *testing.T) {\n    cfg := &amp;middleware.MiddlewareConfig{\n        Chain: []string{\"logging\"},\n        Configs: map[string]middleware.MiddlewareEntry{\n            \"logging\": {Enabled: true},\n        },\n    }\n\n    adapter, err := NewMiddlewareAdapterFromConfig(cfg)\n    if err != nil {\n        t.Fatalf(\"NewMiddlewareAdapterFromConfig() error = %v\", err)\n    }\n\n    if adapter.chain.Len() != 1 {\n        t.Errorf(\"Chain length = %d, want 1\", adapter.chain.Len())\n    }\n}\n\n// mockProvider and wrappedProvider for testing\ntype mockProvider struct {\n    name    string\n    enabled bool\n}\n\nfunc (m *mockProvider) Name() string { return m.name }\nfunc (m *mockProvider) Enabled() bool { return m.enabled }\nfunc (m *mockProvider) Tool() mcp.Tool { return mcp.Tool{Name: m.name} }\nfunc (m *mockProvider) Handle(ctx context.Context, args map[string]any) (any, error) {\n    return nil, nil\n}\n\ntype wrappedProvider struct {\n    provider.ToolProvider\n    beforeFn func()\n}\n\nfunc (w *wrappedProvider) Handle(ctx context.Context, args map[string]any) (any, error) {\n    if w.beforeFn != nil {\n        w.beforeFn()\n    }\n    return w.ToolProvider.Handle(ctx, args)\n}\n</code></pre> <p>Step 2: Implement adapter</p> <pre><code>// internal/server/middleware_adapter.go\npackage server\n\nimport (\n    \"github.com/your-org/metatools-mcp/internal/middleware\"\n    \"github.com/your-org/metatools-mcp/internal/provider\"\n)\n\n// MiddlewareAdapter applies middleware to provider registries.\ntype MiddlewareAdapter struct {\n    chain    *middleware.Chain\n    registry *middleware.Registry\n}\n\n// NewMiddlewareAdapter creates a new adapter with an existing chain.\nfunc NewMiddlewareAdapter(chain *middleware.Chain) *MiddlewareAdapter {\n    return &amp;MiddlewareAdapter{\n        chain:    chain,\n        registry: middleware.DefaultRegistry(),\n    }\n}\n\n// NewMiddlewareAdapterFromConfig creates an adapter from configuration.\nfunc NewMiddlewareAdapterFromConfig(cfg *middleware.MiddlewareConfig) (*MiddlewareAdapter, error) {\n    registry := middleware.DefaultRegistry()\n\n    chain, err := middleware.BuildChainFromConfig(registry, cfg)\n    if err != nil {\n        return nil, err\n    }\n\n    return &amp;MiddlewareAdapter{\n        chain:    chain,\n        registry: registry,\n    }, nil\n}\n\n// ApplyToProviders wraps all providers in a registry with middleware.\nfunc (a *MiddlewareAdapter) ApplyToProviders(providerRegistry *provider.Registry) {\n    providers := providerRegistry.List()\n\n    for _, p := range providers {\n        wrapped := a.chain.Apply(p)\n        providerRegistry.Unregister(p.Name())\n        providerRegistry.Register(wrapped)\n    }\n}\n\n// Chain returns the middleware chain.\nfunc (a *MiddlewareAdapter) Chain() *middleware.Chain {\n    return a.chain\n}\n\n// Registry returns the middleware registry.\nfunc (a *MiddlewareAdapter) Registry() *middleware.Registry {\n    return a.registry\n}\n</code></pre> <p>Step 3: Run test to verify it passes</p> <p>Run: <code>cd /Users/jraymond/Documents/Projects/metatools-mcp &amp;&amp; go test ./internal/server/... -run TestMiddlewareAdapter -v</code> Expected: PASS</p> <p>Step 4: Commit</p> <pre><code>git add internal/server/middleware_adapter.go internal/server/middleware_adapter_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(server): add MiddlewareAdapter for server integration\n\n- ApplyToProviders wraps all providers with middleware\n- NewMiddlewareAdapterFromConfig for config-driven setup\n- Access to chain and registry for customization\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Middleware type defined as function wrapper</li> <li>[ ] Chain for ordered middleware application</li> <li>[ ] Registry for middleware factories</li> <li>[ ] LoggingMiddleware with slog integration</li> <li>[ ] MetricsMiddleware with collector interface</li> <li>[ ] InMemoryMetricsCollector implementation</li> <li>[ ] Config parsing for YAML</li> <li>[ ] BuildChainFromConfig for config-driven chains</li> <li>[ ] MiddlewareAdapter for server integration</li> <li>[ ] All tests pass</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#definition-of-done","title":"Definition of Done","text":"<ol> <li>All tests pass: <code>go test ./internal/middleware/...</code></li> <li>Middleware can wrap providers with logging</li> <li>Metrics collection tracks requests, errors, duration</li> <li>Configuration drives chain construction</li> <li>Server can apply middleware to all providers</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-007-middleware-chain/#next-prd","title":"Next PRD","text":"<p>PRD-008 will implement the tooladapter Library for protocol-agnostic tool definitions.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/","title":"PRD-008: tooladapter Library Implementation","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Create a protocol-agnostic tool abstraction library that enables bidirectional conversion between MCP, OpenAI, Anthropic, LangChain, and OpenAPI tool formats.</p> <p>Architecture: Introduce a canonical tool representation that stores the superset of all schema information, enabling lossless conversion between formats. Protocol adapters implement a common interface for bidirectional conversion.</p> <p>Tech Stack: Go, toolmodel dependency, JSON Schema validation</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/#overview","title":"Overview","text":"<p>The <code>tooladapter</code> library provides protocol-agnostic tool handling, enabling tools from any source to be exposed through multiple transport protocols and consumed by various AI agent frameworks.</p> <p>Reference: protocol-agnostic-tools.md</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/#directory-structure","title":"Directory Structure","text":"<pre><code>tooladapter/\n\u251c\u2500\u2500 canonical.go        # CanonicalTool and JSONSchema types\n\u251c\u2500\u2500 canonical_test.go   # CanonicalTool tests\n\u251c\u2500\u2500 adapter.go          # Adapter interface\n\u251c\u2500\u2500 adapter_test.go     # Adapter interface tests\n\u251c\u2500\u2500 registry.go         # AdapterRegistry implementation\n\u251c\u2500\u2500 registry_test.go    # Registry tests\n\u251c\u2500\u2500 adapters/\n\u2502   \u251c\u2500\u2500 mcp.go          # MCP \u2194 Canonical adapter\n\u2502   \u251c\u2500\u2500 mcp_test.go\n\u2502   \u251c\u2500\u2500 openai.go       # OpenAI \u2194 Canonical adapter\n\u2502   \u251c\u2500\u2500 openai_test.go\n\u2502   \u251c\u2500\u2500 anthropic.go    # Anthropic \u2194 Canonical adapter\n\u2502   \u251c\u2500\u2500 anthropic_test.go\n\u2502   \u251c\u2500\u2500 langchain.go    # LangChain \u2194 Canonical adapter (optional)\n\u2502   \u2514\u2500\u2500 openapi.go      # OpenAPI \u2194 Canonical adapter (import only)\n\u251c\u2500\u2500 schema/\n\u2502   \u251c\u2500\u2500 convert.go      # JSON Schema version conversion\n\u2502   \u251c\u2500\u2500 convert_test.go\n\u2502   \u251c\u2500\u2500 validate.go     # Schema validation\n\u2502   \u2514\u2500\u2500 validate_test.go\n\u251c\u2500\u2500 doc.go              # Package documentation\n\u251c\u2500\u2500 go.mod\n\u2514\u2500\u2500 go.sum\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/#task-1-canonicaltool-and-jsonschema-types","title":"Task 1: CanonicalTool and JSONSchema Types","text":"<p>Files: - Create: <code>tooladapter/canonical.go</code> - Create: <code>tooladapter/canonical_test.go</code> - Create: <code>tooladapter/go.mod</code></p> <p>Step 1: Write failing tests</p> <pre><code>// canonical_test.go\npackage tooladapter_test\n\nimport (\n    \"testing\"\n    \"time\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/tooladapter\"\n)\n\nfunc TestCanonicalTool_ID(t *testing.T) {\n    tool := &amp;tooladapter.CanonicalTool{\n        Namespace: \"mcp\",\n        Name:      \"search\",\n    }\n    assert.Equal(t, \"mcp:search\", tool.ID())\n}\n\nfunc TestCanonicalTool_IDWithEmptyNamespace(t *testing.T) {\n    tool := &amp;tooladapter.CanonicalTool{\n        Name: \"search\",\n    }\n    assert.Equal(t, \"search\", tool.ID())\n}\n\nfunc TestCanonicalTool_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        tool    *tooladapter.CanonicalTool\n        wantErr bool\n    }{\n        {\n            name: \"valid tool\",\n            tool: &amp;tooladapter.CanonicalTool{\n                Name:        \"search\",\n                Description: \"Search for tools\",\n                InputSchema: &amp;tooladapter.JSONSchema{\n                    Type: \"object\",\n                },\n            },\n            wantErr: false,\n        },\n        {\n            name: \"missing name\",\n            tool: &amp;tooladapter.CanonicalTool{\n                Description: \"Search for tools\",\n            },\n            wantErr: true,\n        },\n        {\n            name: \"missing input schema\",\n            tool: &amp;tooladapter.CanonicalTool{\n                Name: \"search\",\n            },\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            err := tt.tool.Validate()\n            if tt.wantErr {\n                require.Error(t, err)\n            } else {\n                require.NoError(t, err)\n            }\n        })\n    }\n}\n\nfunc TestJSONSchema_DeepCopy(t *testing.T) {\n    original := &amp;tooladapter.JSONSchema{\n        Type: \"object\",\n        Properties: map[string]*tooladapter.JSONSchema{\n            \"query\": {\n                Type:        \"string\",\n                Description: \"Search query\",\n            },\n        },\n        Required: []string{\"query\"},\n    }\n\n    copied := original.DeepCopy()\n\n    // Modify original\n    original.Properties[\"query\"].Description = \"Modified\"\n    original.Required = append(original.Required, \"extra\")\n\n    // Verify copy is unchanged\n    assert.Equal(t, \"Search query\", copied.Properties[\"query\"].Description)\n    assert.Equal(t, []string{\"query\"}, copied.Required)\n}\n\nfunc TestJSONSchema_ToMap(t *testing.T) {\n    schema := &amp;tooladapter.JSONSchema{\n        Type: \"object\",\n        Properties: map[string]*tooladapter.JSONSchema{\n            \"query\": {\n                Type: \"string\",\n            },\n        },\n        Required: []string{\"query\"},\n    }\n\n    m := schema.ToMap()\n\n    assert.Equal(t, \"object\", m[\"type\"])\n    props := m[\"properties\"].(map[string]any)\n    query := props[\"query\"].(map[string]any)\n    assert.Equal(t, \"string\", query[\"type\"])\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./... -v</code> Expected: FAIL with \"package tooladapter is not in std\"</p> <p>Step 3: Write minimal implementation</p> <pre><code>// go.mod\nmodule github.com/jrraymond/tooladapter\n\ngo 1.22\n\nrequire github.com/jrraymond/toolmodel v0.1.2\n</code></pre> <pre><code>// canonical.go\npackage tooladapter\n\nimport (\n    \"errors\"\n    \"time\"\n)\n\n// CanonicalTool is the protocol-agnostic tool representation\ntype CanonicalTool struct {\n    // Identity\n    Namespace string // Source namespace (e.g., \"mcp\", \"openai\")\n    Name      string // Tool name within namespace\n    Version   string // Semantic version\n\n    // Metadata\n    Description string   // Human-readable description\n    Category    string   // Tool category for grouping\n    Tags        []string // Searchable tags\n\n    // Schema (superset of all protocol schemas)\n    InputSchema  *JSONSchema // Full JSON Schema for inputs\n    OutputSchema *JSONSchema // Optional output schema\n\n    // Execution\n    Handler ToolHandler   // Execution function\n    Timeout time.Duration // Execution timeout\n\n    // Source tracking\n    SourceFormat string         // Original format (mcp, openai, anthropic, etc.)\n    SourceMeta   map[string]any // Protocol-specific metadata preserved\n\n    // Access control\n    RequiredScopes []string // OAuth scopes or permissions required\n}\n\n// ID returns the fully qualified tool identifier\nfunc (c *CanonicalTool) ID() string {\n    if c.Namespace == \"\" {\n        return c.Name\n    }\n    return c.Namespace + \":\" + c.Name\n}\n\n// Validate checks if the tool is valid\nfunc (c *CanonicalTool) Validate() error {\n    if c.Name == \"\" {\n        return errors.New(\"tool name is required\")\n    }\n    if c.InputSchema == nil {\n        return errors.New(\"input schema is required\")\n    }\n    return nil\n}\n\n// ToolHandler executes the tool\ntype ToolHandler func(ctx context.Context, input map[string]any) (any, error)\n\n// JSONSchema represents a full JSON Schema with all features\ntype JSONSchema struct {\n    Type        string                 `json:\"type\"`\n    Properties  map[string]*JSONSchema `json:\"properties,omitempty\"`\n    Required    []string               `json:\"required,omitempty\"`\n    Items       *JSONSchema            `json:\"items,omitempty\"`\n    Description string                 `json:\"description,omitempty\"`\n\n    // Extended schema features\n    Enum      []any    `json:\"enum,omitempty\"`\n    Const     any      `json:\"const,omitempty\"`\n    Default   any      `json:\"default,omitempty\"`\n    Minimum   *float64 `json:\"minimum,omitempty\"`\n    Maximum   *float64 `json:\"maximum,omitempty\"`\n    MinLength *int     `json:\"minLength,omitempty\"`\n    MaxLength *int     `json:\"maxLength,omitempty\"`\n    Pattern   string   `json:\"pattern,omitempty\"`\n    Format    string   `json:\"format,omitempty\"`\n\n    // JSON Schema draft compatibility\n    Ref  string                 `json:\"$ref,omitempty\"`\n    Defs map[string]*JSONSchema `json:\"$defs,omitempty\"`\n\n    // Additional properties\n    AdditionalProperties *bool `json:\"additionalProperties,omitempty\"`\n}\n\n// DeepCopy creates a deep copy of the schema\nfunc (s *JSONSchema) DeepCopy() *JSONSchema {\n    if s == nil {\n        return nil\n    }\n\n    copied := &amp;JSONSchema{\n        Type:        s.Type,\n        Description: s.Description,\n        Pattern:     s.Pattern,\n        Format:      s.Format,\n        Ref:         s.Ref,\n    }\n\n    // Copy required slice\n    if s.Required != nil {\n        copied.Required = make([]string, len(s.Required))\n        copy(copied.Required, s.Required)\n    }\n\n    // Copy enum slice\n    if s.Enum != nil {\n        copied.Enum = make([]any, len(s.Enum))\n        copy(copied.Enum, s.Enum)\n    }\n\n    // Copy pointer fields\n    if s.Minimum != nil {\n        v := *s.Minimum\n        copied.Minimum = &amp;v\n    }\n    if s.Maximum != nil {\n        v := *s.Maximum\n        copied.Maximum = &amp;v\n    }\n    if s.MinLength != nil {\n        v := *s.MinLength\n        copied.MinLength = &amp;v\n    }\n    if s.MaxLength != nil {\n        v := *s.MaxLength\n        copied.MaxLength = &amp;v\n    }\n    if s.AdditionalProperties != nil {\n        v := *s.AdditionalProperties\n        copied.AdditionalProperties = &amp;v\n    }\n\n    // Deep copy properties\n    if s.Properties != nil {\n        copied.Properties = make(map[string]*JSONSchema)\n        for k, v := range s.Properties {\n            copied.Properties[k] = v.DeepCopy()\n        }\n    }\n\n    // Deep copy items\n    copied.Items = s.Items.DeepCopy()\n\n    // Deep copy defs\n    if s.Defs != nil {\n        copied.Defs = make(map[string]*JSONSchema)\n        for k, v := range s.Defs {\n            copied.Defs[k] = v.DeepCopy()\n        }\n    }\n\n    // Copy Const and Default (shallow copy for primitives)\n    copied.Const = s.Const\n    copied.Default = s.Default\n\n    return copied\n}\n\n// ToMap converts the schema to a map[string]any\nfunc (s *JSONSchema) ToMap() map[string]any {\n    if s == nil {\n        return nil\n    }\n\n    m := make(map[string]any)\n\n    if s.Type != \"\" {\n        m[\"type\"] = s.Type\n    }\n    if s.Description != \"\" {\n        m[\"description\"] = s.Description\n    }\n    if len(s.Required) &gt; 0 {\n        m[\"required\"] = s.Required\n    }\n    if len(s.Enum) &gt; 0 {\n        m[\"enum\"] = s.Enum\n    }\n    if s.Const != nil {\n        m[\"const\"] = s.Const\n    }\n    if s.Default != nil {\n        m[\"default\"] = s.Default\n    }\n    if s.Minimum != nil {\n        m[\"minimum\"] = *s.Minimum\n    }\n    if s.Maximum != nil {\n        m[\"maximum\"] = *s.Maximum\n    }\n    if s.MinLength != nil {\n        m[\"minLength\"] = *s.MinLength\n    }\n    if s.MaxLength != nil {\n        m[\"maxLength\"] = *s.MaxLength\n    }\n    if s.Pattern != \"\" {\n        m[\"pattern\"] = s.Pattern\n    }\n    if s.Format != \"\" {\n        m[\"format\"] = s.Format\n    }\n    if s.Ref != \"\" {\n        m[\"$ref\"] = s.Ref\n    }\n    if s.AdditionalProperties != nil {\n        m[\"additionalProperties\"] = *s.AdditionalProperties\n    }\n\n    // Convert properties\n    if len(s.Properties) &gt; 0 {\n        props := make(map[string]any)\n        for k, v := range s.Properties {\n            props[k] = v.ToMap()\n        }\n        m[\"properties\"] = props\n    }\n\n    // Convert items\n    if s.Items != nil {\n        m[\"items\"] = s.Items.ToMap()\n    }\n\n    // Convert defs\n    if len(s.Defs) &gt; 0 {\n        defs := make(map[string]any)\n        for k, v := range s.Defs {\n            defs[k] = v.ToMap()\n        }\n        m[\"$defs\"] = defs\n    }\n\n    return m\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add tooladapter/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(tooladapter): add CanonicalTool and JSONSchema types\n\n- CanonicalTool provides protocol-agnostic tool representation\n- JSONSchema supports full JSON Schema draft features\n- DeepCopy for immutable schema operations\n- ToMap for serialization to map[string]any\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/#task-2-adapter-interface-and-schemafeature","title":"Task 2: Adapter Interface and SchemaFeature","text":"<p>Files: - Create: <code>tooladapter/adapter.go</code> - Create: <code>tooladapter/adapter_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// adapter_test.go\npackage tooladapter_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/jrraymond/tooladapter\"\n)\n\nfunc TestSchemaFeature_String(t *testing.T) {\n    tests := []struct {\n        feature  tooladapter.SchemaFeature\n        expected string\n    }{\n        {tooladapter.FeatureNestedObjects, \"nested_objects\"},\n        {tooladapter.FeatureArrays, \"arrays\"},\n        {tooladapter.FeatureEnums, \"enums\"},\n        {tooladapter.FeaturePatternValidation, \"pattern_validation\"},\n        {tooladapter.FeatureRefDefinitions, \"ref_definitions\"},\n        {tooladapter.FeatureNullable, \"nullable\"},\n        {tooladapter.FeatureAnyOf, \"any_of\"},\n        {tooladapter.FeatureOneOf, \"one_of\"},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.expected, func(t *testing.T) {\n            assert.Equal(t, tt.expected, tt.feature.String())\n        })\n    }\n}\n\nfunc TestConversionError_Error(t *testing.T) {\n    err := &amp;tooladapter.ConversionError{\n        Adapter:   \"openai\",\n        Direction: \"to_canonical\",\n        Cause:     errors.New(\"invalid schema\"),\n    }\n\n    assert.Contains(t, err.Error(), \"openai\")\n    assert.Contains(t, err.Error(), \"to_canonical\")\n    assert.Contains(t, err.Error(), \"invalid schema\")\n}\n\nfunc TestFeatureLossWarning(t *testing.T) {\n    warning := tooladapter.FeatureLossWarning{\n        Feature:     tooladapter.FeatureRefDefinitions,\n        Adapter:     \"openai\",\n        Description: \"$ref definitions were flattened\",\n    }\n\n    assert.Equal(t, tooladapter.FeatureRefDefinitions, warning.Feature)\n    assert.Contains(t, warning.String(), \"ref_definitions\")\n    assert.Contains(t, warning.String(), \"openai\")\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// adapter.go\npackage tooladapter\n\nimport (\n    \"context\"\n    \"fmt\"\n)\n\n// Adapter converts between canonical and protocol-specific formats\ntype Adapter interface {\n    // Name returns the adapter identifier (e.g., \"mcp\", \"openai\")\n    Name() string\n\n    // ToCanonical converts protocol-specific tool to canonical form\n    ToCanonical(raw any) (*CanonicalTool, error)\n\n    // FromCanonical converts canonical tool to protocol-specific form\n    FromCanonical(tool *CanonicalTool) (any, error)\n\n    // SupportsFeature checks if adapter supports a schema feature\n    SupportsFeature(feature SchemaFeature) bool\n}\n\n// SchemaFeature represents JSON Schema features that may not be universally supported\ntype SchemaFeature int\n\nconst (\n    FeatureNestedObjects SchemaFeature = iota\n    FeatureArrays\n    FeatureEnums\n    FeaturePatternValidation\n    FeatureRefDefinitions\n    FeatureNullable\n    FeatureAnyOf\n    FeatureOneOf\n)\n\n// String returns the string representation of the feature\nfunc (f SchemaFeature) String() string {\n    switch f {\n    case FeatureNestedObjects:\n        return \"nested_objects\"\n    case FeatureArrays:\n        return \"arrays\"\n    case FeatureEnums:\n        return \"enums\"\n    case FeaturePatternValidation:\n        return \"pattern_validation\"\n    case FeatureRefDefinitions:\n        return \"ref_definitions\"\n    case FeatureNullable:\n        return \"nullable\"\n    case FeatureAnyOf:\n        return \"any_of\"\n    case FeatureOneOf:\n        return \"one_of\"\n    default:\n        return \"unknown\"\n    }\n}\n\n// AllFeatures returns all schema features\nfunc AllFeatures() []SchemaFeature {\n    return []SchemaFeature{\n        FeatureNestedObjects,\n        FeatureArrays,\n        FeatureEnums,\n        FeaturePatternValidation,\n        FeatureRefDefinitions,\n        FeatureNullable,\n        FeatureAnyOf,\n        FeatureOneOf,\n    }\n}\n\n// ConversionError represents an error during tool conversion\ntype ConversionError struct {\n    Adapter   string\n    Direction string // \"to_canonical\" or \"from_canonical\"\n    Cause     error\n}\n\nfunc (e *ConversionError) Error() string {\n    return fmt.Sprintf(\"adapter %s %s: %v\", e.Adapter, e.Direction, e.Cause)\n}\n\nfunc (e *ConversionError) Unwrap() error {\n    return e.Cause\n}\n\n// FeatureLossWarning indicates a schema feature was lost during conversion\ntype FeatureLossWarning struct {\n    Feature     SchemaFeature\n    Adapter     string\n    Description string\n}\n\nfunc (w FeatureLossWarning) String() string {\n    return fmt.Sprintf(\"feature %s not supported by %s: %s\",\n        w.Feature.String(), w.Adapter, w.Description)\n}\n\n// ConversionResult contains the conversion result and any warnings\ntype ConversionResult struct {\n    Tool     any\n    Warnings []FeatureLossWarning\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add tooladapter/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(tooladapter): add Adapter interface and SchemaFeature enum\n\n- Adapter interface for bidirectional tool conversion\n- SchemaFeature enum for feature support detection\n- ConversionError for typed error handling\n- FeatureLossWarning for tracking schema degradation\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/#task-3-adapterregistry-implementation","title":"Task 3: AdapterRegistry Implementation","text":"<p>Files: - Create: <code>tooladapter/registry.go</code> - Create: <code>tooladapter/registry_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// registry_test.go\npackage tooladapter_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/tooladapter\"\n)\n\n// mockAdapter for testing\ntype mockAdapter struct {\n    name string\n}\n\nfunc (m *mockAdapter) Name() string { return m.name }\nfunc (m *mockAdapter) ToCanonical(raw any) (*tooladapter.CanonicalTool, error) {\n    return nil, nil\n}\nfunc (m *mockAdapter) FromCanonical(tool *tooladapter.CanonicalTool) (any, error) {\n    return nil, nil\n}\nfunc (m *mockAdapter) SupportsFeature(f tooladapter.SchemaFeature) bool {\n    return true\n}\n\nfunc TestAdapterRegistry_Register(t *testing.T) {\n    reg := tooladapter.NewAdapterRegistry()\n    adapter := &amp;mockAdapter{name: \"test\"}\n\n    err := reg.Register(adapter)\n    require.NoError(t, err)\n\n    got, err := reg.Get(\"test\")\n    require.NoError(t, err)\n    assert.Equal(t, adapter, got)\n}\n\nfunc TestAdapterRegistry_RegisterDuplicate(t *testing.T) {\n    reg := tooladapter.NewAdapterRegistry()\n    adapter1 := &amp;mockAdapter{name: \"test\"}\n    adapter2 := &amp;mockAdapter{name: \"test\"}\n\n    err := reg.Register(adapter1)\n    require.NoError(t, err)\n\n    err = reg.Register(adapter2)\n    require.Error(t, err)\n    assert.Contains(t, err.Error(), \"already registered\")\n}\n\nfunc TestAdapterRegistry_GetNotFound(t *testing.T) {\n    reg := tooladapter.NewAdapterRegistry()\n\n    _, err := reg.Get(\"nonexistent\")\n    require.Error(t, err)\n    assert.Contains(t, err.Error(), \"not found\")\n}\n\nfunc TestAdapterRegistry_List(t *testing.T) {\n    reg := tooladapter.NewAdapterRegistry()\n    reg.Register(&amp;mockAdapter{name: \"mcp\"})\n    reg.Register(&amp;mockAdapter{name: \"openai\"})\n    reg.Register(&amp;mockAdapter{name: \"anthropic\"})\n\n    names := reg.List()\n    assert.Len(t, names, 3)\n    assert.Contains(t, names, \"mcp\")\n    assert.Contains(t, names, \"openai\")\n    assert.Contains(t, names, \"anthropic\")\n}\n\nfunc TestAdapterRegistry_Unregister(t *testing.T) {\n    reg := tooladapter.NewAdapterRegistry()\n    reg.Register(&amp;mockAdapter{name: \"test\"})\n\n    err := reg.Unregister(\"test\")\n    require.NoError(t, err)\n\n    _, err = reg.Get(\"test\")\n    require.Error(t, err)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// registry.go\npackage tooladapter\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\n// AdapterRegistry manages protocol adapters\ntype AdapterRegistry struct {\n    adapters map[string]Adapter\n    mu       sync.RWMutex\n}\n\n// NewAdapterRegistry creates a new adapter registry\nfunc NewAdapterRegistry() *AdapterRegistry {\n    return &amp;AdapterRegistry{\n        adapters: make(map[string]Adapter),\n    }\n}\n\n// Register adds an adapter to the registry\nfunc (r *AdapterRegistry) Register(adapter Adapter) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    name := adapter.Name()\n    if _, exists := r.adapters[name]; exists {\n        return fmt.Errorf(\"adapter %q already registered\", name)\n    }\n\n    r.adapters[name] = adapter\n    return nil\n}\n\n// Get retrieves an adapter by name\nfunc (r *AdapterRegistry) Get(name string) (Adapter, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    adapter, ok := r.adapters[name]\n    if !ok {\n        return nil, fmt.Errorf(\"adapter %q not found\", name)\n    }\n\n    return adapter, nil\n}\n\n// List returns all registered adapter names\nfunc (r *AdapterRegistry) List() []string {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    names := make([]string, 0, len(r.adapters))\n    for name := range r.adapters {\n        names = append(names, name)\n    }\n    return names\n}\n\n// Unregister removes an adapter from the registry\nfunc (r *AdapterRegistry) Unregister(name string) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    if _, exists := r.adapters[name]; !exists {\n        return fmt.Errorf(\"adapter %q not found\", name)\n    }\n\n    delete(r.adapters, name)\n    return nil\n}\n\n// Convert converts a tool between formats using registered adapters\nfunc (r *AdapterRegistry) Convert(tool any, fromFormat, toFormat string) (*ConversionResult, error) {\n    fromAdapter, err := r.Get(fromFormat)\n    if err != nil {\n        return nil, fmt.Errorf(\"source adapter: %w\", err)\n    }\n\n    toAdapter, err := r.Get(toFormat)\n    if err != nil {\n        return nil, fmt.Errorf(\"target adapter: %w\", err)\n    }\n\n    // Convert to canonical\n    canonical, err := fromAdapter.ToCanonical(tool)\n    if err != nil {\n        return nil, &amp;ConversionError{\n            Adapter:   fromFormat,\n            Direction: \"to_canonical\",\n            Cause:     err,\n        }\n    }\n\n    // Track feature loss warnings\n    var warnings []FeatureLossWarning\n    for _, feature := range AllFeatures() {\n        if !toAdapter.SupportsFeature(feature) {\n            warnings = append(warnings, FeatureLossWarning{\n                Feature:     feature,\n                Adapter:     toFormat,\n                Description: fmt.Sprintf(\"feature %s not supported\", feature.String()),\n            })\n        }\n    }\n\n    // Convert from canonical to target format\n    result, err := toAdapter.FromCanonical(canonical)\n    if err != nil {\n        return nil, &amp;ConversionError{\n            Adapter:   toFormat,\n            Direction: \"from_canonical\",\n            Cause:     err,\n        }\n    }\n\n    return &amp;ConversionResult{\n        Tool:     result,\n        Warnings: warnings,\n    }, nil\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add tooladapter/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(tooladapter): add AdapterRegistry for managing adapters\n\n- Thread-safe adapter registration and lookup\n- Convert method for bidirectional tool conversion\n- Feature loss tracking during conversion\n- List and Unregister operations\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/#task-4-mcp-adapter-implementation","title":"Task 4: MCP Adapter Implementation","text":"<p>Files: - Create: <code>tooladapter/adapters/mcp.go</code> - Create: <code>tooladapter/adapters/mcp_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// adapters/mcp_test.go\npackage adapters_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/tooladapter\"\n    \"github.com/jrraymond/tooladapter/adapters\"\n    \"github.com/mark3labs/mcp-go/mcp\"\n)\n\nfunc TestMCPAdapter_Name(t *testing.T) {\n    adapter := adapters.NewMCPAdapter()\n    assert.Equal(t, \"mcp\", adapter.Name())\n}\n\nfunc TestMCPAdapter_ToCanonical(t *testing.T) {\n    adapter := adapters.NewMCPAdapter()\n\n    mcpTool := &amp;mcp.Tool{\n        Name:        \"search_files\",\n        Description: \"Search for files\",\n        InputSchema: mcp.ToolInputSchema{\n            Type: \"object\",\n            Properties: map[string]any{\n                \"query\": map[string]any{\n                    \"type\":        \"string\",\n                    \"description\": \"Search query\",\n                },\n            },\n            Required: []string{\"query\"},\n        },\n    }\n\n    canonical, err := adapter.ToCanonical(mcpTool)\n    require.NoError(t, err)\n\n    assert.Equal(t, \"search_files\", canonical.Name)\n    assert.Equal(t, \"mcp\", canonical.Namespace)\n    assert.Equal(t, \"Search for files\", canonical.Description)\n    assert.Equal(t, \"mcp\", canonical.SourceFormat)\n    assert.NotNil(t, canonical.InputSchema)\n    assert.Equal(t, \"object\", canonical.InputSchema.Type)\n}\n\nfunc TestMCPAdapter_FromCanonical(t *testing.T) {\n    adapter := adapters.NewMCPAdapter()\n\n    canonical := &amp;tooladapter.CanonicalTool{\n        Namespace:   \"test\",\n        Name:        \"my_tool\",\n        Description: \"A test tool\",\n        InputSchema: &amp;tooladapter.JSONSchema{\n            Type: \"object\",\n            Properties: map[string]*tooladapter.JSONSchema{\n                \"input\": {\n                    Type:        \"string\",\n                    Description: \"Input value\",\n                },\n            },\n            Required: []string{\"input\"},\n        },\n    }\n\n    result, err := adapter.FromCanonical(canonical)\n    require.NoError(t, err)\n\n    mcpTool, ok := result.(*mcp.Tool)\n    require.True(t, ok)\n\n    assert.Equal(t, \"my_tool\", mcpTool.Name)\n    assert.Equal(t, \"A test tool\", mcpTool.Description)\n    assert.Equal(t, \"object\", mcpTool.InputSchema.Type)\n}\n\nfunc TestMCPAdapter_SupportsAllFeatures(t *testing.T) {\n    adapter := adapters.NewMCPAdapter()\n\n    for _, feature := range tooladapter.AllFeatures() {\n        assert.True(t, adapter.SupportsFeature(feature),\n            \"MCP should support %s\", feature.String())\n    }\n}\n\nfunc TestMCPAdapter_RoundTrip(t *testing.T) {\n    adapter := adapters.NewMCPAdapter()\n\n    original := &amp;mcp.Tool{\n        Name:        \"roundtrip_tool\",\n        Description: \"Test round trip conversion\",\n        InputSchema: mcp.ToolInputSchema{\n            Type: \"object\",\n            Properties: map[string]any{\n                \"name\": map[string]any{\n                    \"type\": \"string\",\n                },\n                \"count\": map[string]any{\n                    \"type\":    \"integer\",\n                    \"minimum\": 0,\n                },\n            },\n            Required: []string{\"name\"},\n        },\n    }\n\n    canonical, err := adapter.ToCanonical(original)\n    require.NoError(t, err)\n\n    result, err := adapter.FromCanonical(canonical)\n    require.NoError(t, err)\n\n    restored, ok := result.(*mcp.Tool)\n    require.True(t, ok)\n\n    assert.Equal(t, original.Name, restored.Name)\n    assert.Equal(t, original.Description, restored.Description)\n    assert.Equal(t, original.InputSchema.Type, restored.InputSchema.Type)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./adapters/... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// adapters/mcp.go\npackage adapters\n\nimport (\n    \"fmt\"\n\n    \"github.com/jrraymond/tooladapter\"\n    \"github.com/mark3labs/mcp-go/mcp\"\n)\n\n// MCPAdapter converts between MCP and canonical tool formats\ntype MCPAdapter struct{}\n\n// NewMCPAdapter creates a new MCP adapter\nfunc NewMCPAdapter() *MCPAdapter {\n    return &amp;MCPAdapter{}\n}\n\n// Name returns the adapter identifier\nfunc (a *MCPAdapter) Name() string {\n    return \"mcp\"\n}\n\n// ToCanonical converts an MCP tool to canonical form\nfunc (a *MCPAdapter) ToCanonical(raw any) (*tooladapter.CanonicalTool, error) {\n    mcpTool, ok := raw.(*mcp.Tool)\n    if !ok {\n        return nil, fmt.Errorf(\"expected *mcp.Tool, got %T\", raw)\n    }\n\n    inputSchema := convertMCPSchemaToJSONSchema(mcpTool.InputSchema)\n\n    return &amp;tooladapter.CanonicalTool{\n        Namespace:    \"mcp\",\n        Name:         mcpTool.Name,\n        Description:  mcpTool.Description,\n        InputSchema:  inputSchema,\n        SourceFormat: \"mcp\",\n        SourceMeta: map[string]any{\n            \"annotations\": mcpTool.Annotations,\n        },\n    }, nil\n}\n\n// FromCanonical converts a canonical tool to MCP format\nfunc (a *MCPAdapter) FromCanonical(tool *tooladapter.CanonicalTool) (any, error) {\n    if tool == nil {\n        return nil, fmt.Errorf(\"tool cannot be nil\")\n    }\n\n    inputSchema := convertJSONSchemaToMCPSchema(tool.InputSchema)\n\n    return &amp;mcp.Tool{\n        Name:        tool.Name,\n        Description: tool.Description,\n        InputSchema: inputSchema,\n    }, nil\n}\n\n// SupportsFeature returns true for all features (MCP supports full JSON Schema)\nfunc (a *MCPAdapter) SupportsFeature(feature tooladapter.SchemaFeature) bool {\n    return true\n}\n\n// convertMCPSchemaToJSONSchema converts MCP schema to JSONSchema\nfunc convertMCPSchemaToJSONSchema(s mcp.ToolInputSchema) *tooladapter.JSONSchema {\n    schema := &amp;tooladapter.JSONSchema{\n        Type:     s.Type,\n        Required: s.Required,\n    }\n\n    if s.Properties != nil {\n        schema.Properties = make(map[string]*tooladapter.JSONSchema)\n        for k, v := range s.Properties {\n            schema.Properties[k] = convertMapToJSONSchema(v)\n        }\n    }\n\n    return schema\n}\n\n// convertMapToJSONSchema converts a map[string]any to JSONSchema\nfunc convertMapToJSONSchema(m any) *tooladapter.JSONSchema {\n    if m == nil {\n        return nil\n    }\n\n    mMap, ok := m.(map[string]any)\n    if !ok {\n        return nil\n    }\n\n    schema := &amp;tooladapter.JSONSchema{}\n\n    if t, ok := mMap[\"type\"].(string); ok {\n        schema.Type = t\n    }\n    if d, ok := mMap[\"description\"].(string); ok {\n        schema.Description = d\n    }\n    if p, ok := mMap[\"pattern\"].(string); ok {\n        schema.Pattern = p\n    }\n    if f, ok := mMap[\"format\"].(string); ok {\n        schema.Format = f\n    }\n    if min, ok := mMap[\"minimum\"].(float64); ok {\n        schema.Minimum = &amp;min\n    }\n    if max, ok := mMap[\"maximum\"].(float64); ok {\n        schema.Maximum = &amp;max\n    }\n    if e, ok := mMap[\"enum\"].([]any); ok {\n        schema.Enum = e\n    }\n    if d, ok := mMap[\"default\"]; ok {\n        schema.Default = d\n    }\n\n    if props, ok := mMap[\"properties\"].(map[string]any); ok {\n        schema.Properties = make(map[string]*tooladapter.JSONSchema)\n        for k, v := range props {\n            schema.Properties[k] = convertMapToJSONSchema(v)\n        }\n    }\n\n    if items, ok := mMap[\"items\"]; ok {\n        schema.Items = convertMapToJSONSchema(items)\n    }\n\n    if req, ok := mMap[\"required\"].([]any); ok {\n        schema.Required = make([]string, len(req))\n        for i, r := range req {\n            schema.Required[i] = r.(string)\n        }\n    }\n\n    return schema\n}\n\n// convertJSONSchemaToMCPSchema converts JSONSchema to MCP schema\nfunc convertJSONSchemaToMCPSchema(s *tooladapter.JSONSchema) mcp.ToolInputSchema {\n    if s == nil {\n        return mcp.ToolInputSchema{\n            Type: \"object\",\n        }\n    }\n\n    schema := mcp.ToolInputSchema{\n        Type:     s.Type,\n        Required: s.Required,\n    }\n\n    if s.Properties != nil {\n        schema.Properties = make(map[string]any)\n        for k, v := range s.Properties {\n            schema.Properties[k] = convertJSONSchemaToMap(v)\n        }\n    }\n\n    return schema\n}\n\n// convertJSONSchemaToMap converts JSONSchema to map[string]any\nfunc convertJSONSchemaToMap(s *tooladapter.JSONSchema) map[string]any {\n    if s == nil {\n        return nil\n    }\n\n    m := make(map[string]any)\n\n    if s.Type != \"\" {\n        m[\"type\"] = s.Type\n    }\n    if s.Description != \"\" {\n        m[\"description\"] = s.Description\n    }\n    if s.Pattern != \"\" {\n        m[\"pattern\"] = s.Pattern\n    }\n    if s.Format != \"\" {\n        m[\"format\"] = s.Format\n    }\n    if s.Minimum != nil {\n        m[\"minimum\"] = *s.Minimum\n    }\n    if s.Maximum != nil {\n        m[\"maximum\"] = *s.Maximum\n    }\n    if len(s.Enum) &gt; 0 {\n        m[\"enum\"] = s.Enum\n    }\n    if s.Default != nil {\n        m[\"default\"] = s.Default\n    }\n    if len(s.Required) &gt; 0 {\n        m[\"required\"] = s.Required\n    }\n\n    if s.Properties != nil {\n        props := make(map[string]any)\n        for k, v := range s.Properties {\n            props[k] = convertJSONSchemaToMap(v)\n        }\n        m[\"properties\"] = props\n    }\n\n    if s.Items != nil {\n        m[\"items\"] = convertJSONSchemaToMap(s.Items)\n    }\n\n    return m\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./adapters/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add tooladapter/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(tooladapter): add MCP adapter implementation\n\n- Bidirectional MCP \u2194 Canonical conversion\n- Full JSON Schema support\n- Round-trip conversion preserves all data\n- Helper functions for schema conversion\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/#task-5-openai-adapter-implementation","title":"Task 5: OpenAI Adapter Implementation","text":"<p>Files: - Create: <code>tooladapter/adapters/openai.go</code> - Create: <code>tooladapter/adapters/openai_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// adapters/openai_test.go\npackage adapters_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/tooladapter\"\n    \"github.com/jrraymond/tooladapter/adapters\"\n)\n\nfunc TestOpenAIAdapter_Name(t *testing.T) {\n    adapter := adapters.NewOpenAIAdapter(false)\n    assert.Equal(t, \"openai\", adapter.Name())\n}\n\nfunc TestOpenAIAdapter_ToCanonical(t *testing.T) {\n    adapter := adapters.NewOpenAIAdapter(false)\n\n    fn := &amp;adapters.OpenAIFunction{\n        Name:        \"get_weather\",\n        Description: \"Get current weather\",\n        Parameters: map[string]any{\n            \"type\": \"object\",\n            \"properties\": map[string]any{\n                \"location\": map[string]any{\n                    \"type\":        \"string\",\n                    \"description\": \"City name\",\n                },\n            },\n            \"required\": []any{\"location\"},\n        },\n    }\n\n    canonical, err := adapter.ToCanonical(fn)\n    require.NoError(t, err)\n\n    assert.Equal(t, \"get_weather\", canonical.Name)\n    assert.Equal(t, \"openai\", canonical.Namespace)\n    assert.Equal(t, \"Get current weather\", canonical.Description)\n    assert.Equal(t, \"openai\", canonical.SourceFormat)\n}\n\nfunc TestOpenAIAdapter_FromCanonical(t *testing.T) {\n    adapter := adapters.NewOpenAIAdapter(false)\n\n    canonical := &amp;tooladapter.CanonicalTool{\n        Name:        \"my_function\",\n        Description: \"A test function\",\n        InputSchema: &amp;tooladapter.JSONSchema{\n            Type: \"object\",\n            Properties: map[string]*tooladapter.JSONSchema{\n                \"input\": {Type: \"string\"},\n            },\n            Required: []string{\"input\"},\n        },\n    }\n\n    result, err := adapter.FromCanonical(canonical)\n    require.NoError(t, err)\n\n    fn, ok := result.(*adapters.OpenAIFunction)\n    require.True(t, ok)\n\n    assert.Equal(t, \"my_function\", fn.Name)\n    assert.Equal(t, \"A test function\", fn.Description)\n}\n\nfunc TestOpenAIAdapter_StrictMode(t *testing.T) {\n    adapter := adapters.NewOpenAIAdapter(true) // strict mode\n\n    canonical := &amp;tooladapter.CanonicalTool{\n        Name:        \"strict_tool\",\n        Description: \"A strict tool\",\n        InputSchema: &amp;tooladapter.JSONSchema{\n            Type: \"object\",\n        },\n    }\n\n    result, err := adapter.FromCanonical(canonical)\n    require.NoError(t, err)\n\n    fn, ok := result.(*adapters.OpenAIFunction)\n    require.True(t, ok)\n\n    assert.True(t, fn.Strict)\n}\n\nfunc TestOpenAIAdapter_FeatureSupport(t *testing.T) {\n    adapter := adapters.NewOpenAIAdapter(false)\n\n    // OpenAI doesn't support $ref definitions\n    assert.False(t, adapter.SupportsFeature(tooladapter.FeatureRefDefinitions))\n\n    // OpenAI supports basic features\n    assert.True(t, adapter.SupportsFeature(tooladapter.FeatureNestedObjects))\n    assert.True(t, adapter.SupportsFeature(tooladapter.FeatureArrays))\n    assert.True(t, adapter.SupportsFeature(tooladapter.FeatureEnums))\n}\n\nfunc TestOpenAIAdapter_StrictModePatternSupport(t *testing.T) {\n    nonStrict := adapters.NewOpenAIAdapter(false)\n    strict := adapters.NewOpenAIAdapter(true)\n\n    // Pattern validation only in strict mode\n    assert.False(t, nonStrict.SupportsFeature(tooladapter.FeaturePatternValidation))\n    assert.True(t, strict.SupportsFeature(tooladapter.FeaturePatternValidation))\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./adapters/... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// adapters/openai.go\npackage adapters\n\nimport (\n    \"fmt\"\n\n    \"github.com/jrraymond/tooladapter\"\n)\n\n// OpenAIFunction represents an OpenAI function definition\ntype OpenAIFunction struct {\n    Name        string         `json:\"name\"`\n    Description string         `json:\"description,omitempty\"`\n    Parameters  map[string]any `json:\"parameters\"`\n    Strict      bool           `json:\"strict,omitempty\"`\n}\n\n// OpenAIAdapter converts between OpenAI and canonical tool formats\ntype OpenAIAdapter struct {\n    strictMode bool\n}\n\n// NewOpenAIAdapter creates a new OpenAI adapter\nfunc NewOpenAIAdapter(strictMode bool) *OpenAIAdapter {\n    return &amp;OpenAIAdapter{\n        strictMode: strictMode,\n    }\n}\n\n// Name returns the adapter identifier\nfunc (a *OpenAIAdapter) Name() string {\n    return \"openai\"\n}\n\n// ToCanonical converts an OpenAI function to canonical form\nfunc (a *OpenAIAdapter) ToCanonical(raw any) (*tooladapter.CanonicalTool, error) {\n    fn, ok := raw.(*OpenAIFunction)\n    if !ok {\n        return nil, fmt.Errorf(\"expected *OpenAIFunction, got %T\", raw)\n    }\n\n    inputSchema := convertOpenAIParametersToJSONSchema(fn.Parameters)\n\n    return &amp;tooladapter.CanonicalTool{\n        Namespace:    \"openai\",\n        Name:         fn.Name,\n        Description:  fn.Description,\n        InputSchema:  inputSchema,\n        SourceFormat: \"openai\",\n        SourceMeta: map[string]any{\n            \"strict\": fn.Strict,\n        },\n    }, nil\n}\n\n// FromCanonical converts a canonical tool to OpenAI format\nfunc (a *OpenAIAdapter) FromCanonical(tool *tooladapter.CanonicalTool) (any, error) {\n    if tool == nil {\n        return nil, fmt.Errorf(\"tool cannot be nil\")\n    }\n\n    params := convertJSONSchemaToOpenAIParameters(tool.InputSchema, a.strictMode)\n\n    return &amp;OpenAIFunction{\n        Name:        tool.Name,\n        Description: tool.Description,\n        Parameters:  params,\n        Strict:      a.strictMode,\n    }, nil\n}\n\n// SupportsFeature checks if the adapter supports a schema feature\nfunc (a *OpenAIAdapter) SupportsFeature(feature tooladapter.SchemaFeature) bool {\n    switch feature {\n    case tooladapter.FeatureRefDefinitions:\n        return false // OpenAI doesn't support $ref\n    case tooladapter.FeaturePatternValidation:\n        return a.strictMode // Only in strict mode\n    case tooladapter.FeatureAnyOf, tooladapter.FeatureOneOf:\n        return false // Limited support\n    default:\n        return true\n    }\n}\n\n// convertOpenAIParametersToJSONSchema converts OpenAI parameters to JSONSchema\nfunc convertOpenAIParametersToJSONSchema(params map[string]any) *tooladapter.JSONSchema {\n    if params == nil {\n        return &amp;tooladapter.JSONSchema{Type: \"object\"}\n    }\n\n    schema := &amp;tooladapter.JSONSchema{}\n\n    if t, ok := params[\"type\"].(string); ok {\n        schema.Type = t\n    }\n    if d, ok := params[\"description\"].(string); ok {\n        schema.Description = d\n    }\n\n    if props, ok := params[\"properties\"].(map[string]any); ok {\n        schema.Properties = make(map[string]*tooladapter.JSONSchema)\n        for k, v := range props {\n            if vMap, ok := v.(map[string]any); ok {\n                schema.Properties[k] = convertOpenAIParametersToJSONSchema(vMap)\n            }\n        }\n    }\n\n    if req, ok := params[\"required\"].([]any); ok {\n        schema.Required = make([]string, len(req))\n        for i, r := range req {\n            if s, ok := r.(string); ok {\n                schema.Required[i] = s\n            }\n        }\n    }\n\n    if e, ok := params[\"enum\"].([]any); ok {\n        schema.Enum = e\n    }\n\n    return schema\n}\n\n// convertJSONSchemaToOpenAIParameters converts JSONSchema to OpenAI parameters\nfunc convertJSONSchemaToOpenAIParameters(s *tooladapter.JSONSchema, strict bool) map[string]any {\n    if s == nil {\n        return map[string]any{\"type\": \"object\"}\n    }\n\n    params := make(map[string]any)\n\n    if s.Type != \"\" {\n        params[\"type\"] = s.Type\n    }\n    if s.Description != \"\" {\n        params[\"description\"] = s.Description\n    }\n    if len(s.Required) &gt; 0 {\n        params[\"required\"] = s.Required\n    }\n    if len(s.Enum) &gt; 0 {\n        params[\"enum\"] = s.Enum\n    }\n\n    if s.Properties != nil {\n        props := make(map[string]any)\n        for k, v := range s.Properties {\n            props[k] = convertJSONSchemaToOpenAIParameters(v, strict)\n        }\n        params[\"properties\"] = props\n    }\n\n    // OpenAI strict mode requirements\n    if strict {\n        if s.Pattern != \"\" {\n            params[\"pattern\"] = s.Pattern\n        }\n        // additionalProperties must be false in strict mode\n        params[\"additionalProperties\"] = false\n    }\n\n    return params\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./adapters/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add tooladapter/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(tooladapter): add OpenAI adapter implementation\n\n- OpenAI function format conversion\n- Strict mode support with additionalProperties: false\n- Feature support detection for $ref, patterns, anyOf/oneOf\n- Bidirectional conversion with schema preservation\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/#task-6-anthropic-adapter-implementation","title":"Task 6: Anthropic Adapter Implementation","text":"<p>Files: - Create: <code>tooladapter/adapters/anthropic.go</code> - Create: <code>tooladapter/adapters/anthropic_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// adapters/anthropic_test.go\npackage adapters_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/tooladapter\"\n    \"github.com/jrraymond/tooladapter/adapters\"\n)\n\nfunc TestAnthropicAdapter_Name(t *testing.T) {\n    adapter := adapters.NewAnthropicAdapter()\n    assert.Equal(t, \"anthropic\", adapter.Name())\n}\n\nfunc TestAnthropicAdapter_ToCanonical(t *testing.T) {\n    adapter := adapters.NewAnthropicAdapter()\n\n    tool := &amp;adapters.AnthropicTool{\n        Name:        \"search\",\n        Description: \"Search for information\",\n        InputSchema: map[string]any{\n            \"type\": \"object\",\n            \"properties\": map[string]any{\n                \"query\": map[string]any{\n                    \"type\": \"string\",\n                },\n            },\n            \"required\": []any{\"query\"},\n        },\n    }\n\n    canonical, err := adapter.ToCanonical(tool)\n    require.NoError(t, err)\n\n    assert.Equal(t, \"search\", canonical.Name)\n    assert.Equal(t, \"anthropic\", canonical.Namespace)\n    assert.Equal(t, \"Search for information\", canonical.Description)\n    assert.Equal(t, \"anthropic\", canonical.SourceFormat)\n}\n\nfunc TestAnthropicAdapter_FromCanonical(t *testing.T) {\n    adapter := adapters.NewAnthropicAdapter()\n\n    canonical := &amp;tooladapter.CanonicalTool{\n        Name:        \"my_tool\",\n        Description: \"A test tool\",\n        InputSchema: &amp;tooladapter.JSONSchema{\n            Type: \"object\",\n            Properties: map[string]*tooladapter.JSONSchema{\n                \"input\": {Type: \"string\"},\n            },\n        },\n    }\n\n    result, err := adapter.FromCanonical(canonical)\n    require.NoError(t, err)\n\n    tool, ok := result.(*adapters.AnthropicTool)\n    require.True(t, ok)\n\n    assert.Equal(t, \"my_tool\", tool.Name)\n    assert.Equal(t, \"A test tool\", tool.Description)\n\n    // Verify input_schema field (Anthropic uses input_schema, not inputSchema)\n    assert.NotNil(t, tool.InputSchema)\n}\n\nfunc TestAnthropicAdapter_FeatureSupport(t *testing.T) {\n    adapter := adapters.NewAnthropicAdapter()\n\n    // Anthropic supports most features except $ref\n    assert.True(t, adapter.SupportsFeature(tooladapter.FeatureNestedObjects))\n    assert.True(t, adapter.SupportsFeature(tooladapter.FeatureArrays))\n    assert.True(t, adapter.SupportsFeature(tooladapter.FeatureEnums))\n    assert.True(t, adapter.SupportsFeature(tooladapter.FeaturePatternValidation))\n    assert.True(t, adapter.SupportsFeature(tooladapter.FeatureNullable))\n\n    // Anthropic doesn't support $ref\n    assert.False(t, adapter.SupportsFeature(tooladapter.FeatureRefDefinitions))\n}\n\nfunc TestAnthropicAdapter_RoundTrip(t *testing.T) {\n    adapter := adapters.NewAnthropicAdapter()\n\n    original := &amp;adapters.AnthropicTool{\n        Name:        \"roundtrip\",\n        Description: \"Test round trip\",\n        InputSchema: map[string]any{\n            \"type\": \"object\",\n            \"properties\": map[string]any{\n                \"value\": map[string]any{\n                    \"type\":        \"integer\",\n                    \"description\": \"A number\",\n                },\n            },\n            \"required\": []any{\"value\"},\n        },\n    }\n\n    canonical, err := adapter.ToCanonical(original)\n    require.NoError(t, err)\n\n    result, err := adapter.FromCanonical(canonical)\n    require.NoError(t, err)\n\n    restored, ok := result.(*adapters.AnthropicTool)\n    require.True(t, ok)\n\n    assert.Equal(t, original.Name, restored.Name)\n    assert.Equal(t, original.Description, restored.Description)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./adapters/... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// adapters/anthropic.go\npackage adapters\n\nimport (\n    \"fmt\"\n\n    \"github.com/jrraymond/tooladapter\"\n)\n\n// AnthropicTool represents an Anthropic tool definition\ntype AnthropicTool struct {\n    Name        string         `json:\"name\"`\n    Description string         `json:\"description,omitempty\"`\n    InputSchema map[string]any `json:\"input_schema\"` // Note: input_schema, not inputSchema\n}\n\n// AnthropicAdapter converts between Anthropic and canonical tool formats\ntype AnthropicAdapter struct{}\n\n// NewAnthropicAdapter creates a new Anthropic adapter\nfunc NewAnthropicAdapter() *AnthropicAdapter {\n    return &amp;AnthropicAdapter{}\n}\n\n// Name returns the adapter identifier\nfunc (a *AnthropicAdapter) Name() string {\n    return \"anthropic\"\n}\n\n// ToCanonical converts an Anthropic tool to canonical form\nfunc (a *AnthropicAdapter) ToCanonical(raw any) (*tooladapter.CanonicalTool, error) {\n    tool, ok := raw.(*AnthropicTool)\n    if !ok {\n        return nil, fmt.Errorf(\"expected *AnthropicTool, got %T\", raw)\n    }\n\n    inputSchema := convertAnthropicSchemaToJSONSchema(tool.InputSchema)\n\n    return &amp;tooladapter.CanonicalTool{\n        Namespace:    \"anthropic\",\n        Name:         tool.Name,\n        Description:  tool.Description,\n        InputSchema:  inputSchema,\n        SourceFormat: \"anthropic\",\n    }, nil\n}\n\n// FromCanonical converts a canonical tool to Anthropic format\nfunc (a *AnthropicAdapter) FromCanonical(tool *tooladapter.CanonicalTool) (any, error) {\n    if tool == nil {\n        return nil, fmt.Errorf(\"tool cannot be nil\")\n    }\n\n    inputSchema := convertJSONSchemaToAnthropicSchema(tool.InputSchema)\n\n    return &amp;AnthropicTool{\n        Name:        tool.Name,\n        Description: tool.Description,\n        InputSchema: inputSchema,\n    }, nil\n}\n\n// SupportsFeature checks if the adapter supports a schema feature\nfunc (a *AnthropicAdapter) SupportsFeature(feature tooladapter.SchemaFeature) bool {\n    switch feature {\n    case tooladapter.FeatureRefDefinitions:\n        return false // Anthropic doesn't support $ref\n    default:\n        return true\n    }\n}\n\n// convertAnthropicSchemaToJSONSchema converts Anthropic schema to JSONSchema\nfunc convertAnthropicSchemaToJSONSchema(schema map[string]any) *tooladapter.JSONSchema {\n    if schema == nil {\n        return &amp;tooladapter.JSONSchema{Type: \"object\"}\n    }\n\n    result := &amp;tooladapter.JSONSchema{}\n\n    if t, ok := schema[\"type\"].(string); ok {\n        result.Type = t\n    }\n    if d, ok := schema[\"description\"].(string); ok {\n        result.Description = d\n    }\n    if p, ok := schema[\"pattern\"].(string); ok {\n        result.Pattern = p\n    }\n    if f, ok := schema[\"format\"].(string); ok {\n        result.Format = f\n    }\n    if e, ok := schema[\"enum\"].([]any); ok {\n        result.Enum = e\n    }\n    if d, ok := schema[\"default\"]; ok {\n        result.Default = d\n    }\n\n    if props, ok := schema[\"properties\"].(map[string]any); ok {\n        result.Properties = make(map[string]*tooladapter.JSONSchema)\n        for k, v := range props {\n            if vMap, ok := v.(map[string]any); ok {\n                result.Properties[k] = convertAnthropicSchemaToJSONSchema(vMap)\n            }\n        }\n    }\n\n    if items, ok := schema[\"items\"].(map[string]any); ok {\n        result.Items = convertAnthropicSchemaToJSONSchema(items)\n    }\n\n    if req, ok := schema[\"required\"].([]any); ok {\n        result.Required = make([]string, len(req))\n        for i, r := range req {\n            if s, ok := r.(string); ok {\n                result.Required[i] = s\n            }\n        }\n    }\n\n    return result\n}\n\n// convertJSONSchemaToAnthropicSchema converts JSONSchema to Anthropic schema\nfunc convertJSONSchemaToAnthropicSchema(s *tooladapter.JSONSchema) map[string]any {\n    if s == nil {\n        return map[string]any{\"type\": \"object\"}\n    }\n\n    schema := make(map[string]any)\n\n    if s.Type != \"\" {\n        schema[\"type\"] = s.Type\n    }\n    if s.Description != \"\" {\n        schema[\"description\"] = s.Description\n    }\n    if s.Pattern != \"\" {\n        schema[\"pattern\"] = s.Pattern\n    }\n    if s.Format != \"\" {\n        schema[\"format\"] = s.Format\n    }\n    if len(s.Enum) &gt; 0 {\n        schema[\"enum\"] = s.Enum\n    }\n    if s.Default != nil {\n        schema[\"default\"] = s.Default\n    }\n    if len(s.Required) &gt; 0 {\n        schema[\"required\"] = s.Required\n    }\n\n    if s.Properties != nil {\n        props := make(map[string]any)\n        for k, v := range s.Properties {\n            props[k] = convertJSONSchemaToAnthropicSchema(v)\n        }\n        schema[\"properties\"] = props\n    }\n\n    if s.Items != nil {\n        schema[\"items\"] = convertJSONSchemaToAnthropicSchema(s.Items)\n    }\n\n    return schema\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd tooladapter &amp;&amp; go test ./adapters/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add tooladapter/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(tooladapter): add Anthropic adapter implementation\n\n- Anthropic tool format with input_schema field naming\n- Bidirectional conversion with schema preservation\n- Feature support detection ($ref not supported)\n- Round-trip conversion tests\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/#verification-checklist","title":"Verification Checklist","text":"<p>Before marking PRD-008 complete:</p> <ul> <li>[ ] All tests pass: <code>go test ./... -v</code></li> <li>[ ] Code coverage &gt; 80%: <code>go test ./... -cover</code></li> <li>[ ] No linting errors: <code>golangci-lint run</code></li> <li>[ ] Documentation complete:</li> <li>[ ] Package documentation in <code>doc.go</code></li> <li>[ ] README.md with usage examples</li> <li>[ ] GoDoc comments on all exported types</li> <li>[ ] Integration verified:</li> <li>[ ] MCP adapter round-trip works</li> <li>[ ] OpenAI adapter handles strict mode</li> <li>[ ] Anthropic adapter handles input_schema naming</li> <li>[ ] AdapterRegistry manages all adapters</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-008-tooladapter-library/#definition-of-done","title":"Definition of Done","text":"<ol> <li>CanonicalTool type with all fields from proposal</li> <li>JSONSchema type with DeepCopy and ToMap methods</li> <li>Adapter interface with ToCanonical, FromCanonical, SupportsFeature</li> <li>AdapterRegistry with Register, Get, List, Convert</li> <li>MCPAdapter with full JSON Schema support</li> <li>OpenAIAdapter with strict mode support</li> <li>AnthropicAdapter with input_schema field naming</li> <li>All tests passing with &gt;80% coverage</li> <li>Documentation complete</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/","title":"PRD-009: toolset Composition Library Implementation","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Create a composable tool collection library that enables curated, filtered, and access-controlled tool sets from multiple sources.</p> <p>Architecture: Fluent builder pattern for constructing toolsets from registries, with filtering by namespace, tags, categories, and custom policies. Supports multiple exposure formats (MCP, OpenAI, Anthropic).</p> <p>Tech Stack: Go, tooladapter dependency, toolindex dependency</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/#overview","title":"Overview","text":"<p>The <code>toolset</code> library provides composable tool collections for creating curated API surfaces. It enables filtering, access control, and multi-format exposure of tools.</p> <p>Reference: protocol-agnostic-tools.md - Section \"toolset Library\"</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/#directory-structure","title":"Directory Structure","text":"<pre><code>toolset/\n\u251c\u2500\u2500 toolset.go          # Toolset type and methods\n\u251c\u2500\u2500 toolset_test.go     # Toolset tests\n\u251c\u2500\u2500 builder.go          # Builder pattern implementation\n\u251c\u2500\u2500 builder_test.go     # Builder tests\n\u251c\u2500\u2500 filter.go           # Filter functions\n\u251c\u2500\u2500 filter_test.go      # Filter tests\n\u251c\u2500\u2500 policy.go           # Access control policies\n\u251c\u2500\u2500 policy_test.go      # Policy tests\n\u251c\u2500\u2500 exposure.go         # Multi-format exposure\n\u251c\u2500\u2500 exposure_test.go    # Exposure tests\n\u251c\u2500\u2500 doc.go              # Package documentation\n\u251c\u2500\u2500 go.mod\n\u2514\u2500\u2500 go.sum\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/#task-1-toolset-type-and-basic-operations","title":"Task 1: Toolset Type and Basic Operations","text":"<p>Files: - Create: <code>toolset/toolset.go</code> - Create: <code>toolset/toolset_test.go</code> - Create: <code>toolset/go.mod</code></p> <p>Step 1: Write failing tests</p> <pre><code>// toolset_test.go\npackage toolset_test\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolset\"\n    \"github.com/jrraymond/tooladapter\"\n)\n\nfunc makeTool(name, namespace string, tags []string) *tooladapter.CanonicalTool {\n    return &amp;tooladapter.CanonicalTool{\n        Name:      name,\n        Namespace: namespace,\n        Tags:      tags,\n        InputSchema: &amp;tooladapter.JSONSchema{\n            Type: \"object\",\n        },\n    }\n}\n\nfunc TestToolset_New(t *testing.T) {\n    ts := toolset.New(\"test-set\")\n\n    assert.Equal(t, \"test-set\", ts.Name())\n    assert.Empty(t, ts.Tools())\n}\n\nfunc TestToolset_AddTool(t *testing.T) {\n    ts := toolset.New(\"test-set\")\n    tool := makeTool(\"search\", \"mcp\", []string{\"query\"})\n\n    ts.Add(tool)\n\n    tools := ts.Tools()\n    require.Len(t, tools, 1)\n    assert.Equal(t, \"search\", tools[0].Name)\n}\n\nfunc TestToolset_AddMultipleTools(t *testing.T) {\n    ts := toolset.New(\"test-set\")\n\n    ts.Add(makeTool(\"search\", \"mcp\", []string{\"query\"}))\n    ts.Add(makeTool(\"describe\", \"mcp\", []string{\"info\"}))\n    ts.Add(makeTool(\"execute\", \"local\", []string{\"run\"}))\n\n    assert.Len(t, ts.Tools(), 3)\n}\n\nfunc TestToolset_Get(t *testing.T) {\n    ts := toolset.New(\"test-set\")\n    tool := makeTool(\"search\", \"mcp\", []string{\"query\"})\n    ts.Add(tool)\n\n    found, ok := ts.Get(\"mcp:search\")\n    require.True(t, ok)\n    assert.Equal(t, \"search\", found.Name)\n\n    _, ok = ts.Get(\"nonexistent\")\n    assert.False(t, ok)\n}\n\nfunc TestToolset_Remove(t *testing.T) {\n    ts := toolset.New(\"test-set\")\n    ts.Add(makeTool(\"search\", \"mcp\", nil))\n    ts.Add(makeTool(\"describe\", \"mcp\", nil))\n\n    removed := ts.Remove(\"mcp:search\")\n    assert.True(t, removed)\n    assert.Len(t, ts.Tools(), 1)\n\n    removed = ts.Remove(\"nonexistent\")\n    assert.False(t, removed)\n}\n\nfunc TestToolset_Filter(t *testing.T) {\n    ts := toolset.New(\"test-set\")\n    ts.Add(makeTool(\"search\", \"mcp\", []string{\"query\"}))\n    ts.Add(makeTool(\"describe\", \"mcp\", []string{\"info\"}))\n    ts.Add(makeTool(\"execute\", \"local\", []string{\"run\"}))\n\n    filtered := ts.Filter(func(t *tooladapter.CanonicalTool) bool {\n        return t.Namespace == \"mcp\"\n    })\n\n    assert.Equal(t, \"test-set (filtered)\", filtered.Name())\n    assert.Len(t, filtered.Tools(), 2)\n}\n\nfunc TestToolset_Count(t *testing.T) {\n    ts := toolset.New(\"test-set\")\n    assert.Equal(t, 0, ts.Count())\n\n    ts.Add(makeTool(\"search\", \"mcp\", nil))\n    assert.Equal(t, 1, ts.Count())\n\n    ts.Add(makeTool(\"describe\", \"mcp\", nil))\n    assert.Equal(t, 2, ts.Count())\n}\n\nfunc TestToolset_IDs(t *testing.T) {\n    ts := toolset.New(\"test-set\")\n    ts.Add(makeTool(\"search\", \"mcp\", nil))\n    ts.Add(makeTool(\"execute\", \"local\", nil))\n\n    ids := ts.IDs()\n    assert.Len(t, ids, 2)\n    assert.Contains(t, ids, \"mcp:search\")\n    assert.Contains(t, ids, \"local:execute\")\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// go.mod\nmodule github.com/jrraymond/toolset\n\ngo 1.22\n\nrequire github.com/jrraymond/tooladapter v0.1.0\n</code></pre> <pre><code>// toolset.go\npackage toolset\n\nimport (\n    \"sync\"\n\n    \"github.com/jrraymond/tooladapter\"\n)\n\n// Toolset represents a curated collection of tools\ntype Toolset struct {\n    name  string\n    tools map[string]*tooladapter.CanonicalTool\n    mu    sync.RWMutex\n}\n\n// New creates a new empty toolset\nfunc New(name string) *Toolset {\n    return &amp;Toolset{\n        name:  name,\n        tools: make(map[string]*tooladapter.CanonicalTool),\n    }\n}\n\n// Name returns the toolset name\nfunc (ts *Toolset) Name() string {\n    return ts.name\n}\n\n// Add adds a tool to the toolset\nfunc (ts *Toolset) Add(tool *tooladapter.CanonicalTool) {\n    ts.mu.Lock()\n    defer ts.mu.Unlock()\n\n    ts.tools[tool.ID()] = tool\n}\n\n// Get retrieves a tool by ID\nfunc (ts *Toolset) Get(id string) (*tooladapter.CanonicalTool, bool) {\n    ts.mu.RLock()\n    defer ts.mu.RUnlock()\n\n    tool, ok := ts.tools[id]\n    return tool, ok\n}\n\n// Remove removes a tool from the toolset\nfunc (ts *Toolset) Remove(id string) bool {\n    ts.mu.Lock()\n    defer ts.mu.Unlock()\n\n    if _, ok := ts.tools[id]; !ok {\n        return false\n    }\n\n    delete(ts.tools, id)\n    return true\n}\n\n// Tools returns all tools in the toolset\nfunc (ts *Toolset) Tools() []*tooladapter.CanonicalTool {\n    ts.mu.RLock()\n    defer ts.mu.RUnlock()\n\n    result := make([]*tooladapter.CanonicalTool, 0, len(ts.tools))\n    for _, tool := range ts.tools {\n        result = append(result, tool)\n    }\n    return result\n}\n\n// Count returns the number of tools in the toolset\nfunc (ts *Toolset) Count() int {\n    ts.mu.RLock()\n    defer ts.mu.RUnlock()\n\n    return len(ts.tools)\n}\n\n// IDs returns all tool IDs in the toolset\nfunc (ts *Toolset) IDs() []string {\n    ts.mu.RLock()\n    defer ts.mu.RUnlock()\n\n    ids := make([]string, 0, len(ts.tools))\n    for id := range ts.tools {\n        ids = append(ids, id)\n    }\n    return ids\n}\n\n// Filter creates a new toolset with filtered tools\nfunc (ts *Toolset) Filter(fn func(*tooladapter.CanonicalTool) bool) *Toolset {\n    ts.mu.RLock()\n    defer ts.mu.RUnlock()\n\n    filtered := New(ts.name + \" (filtered)\")\n    for _, tool := range ts.tools {\n        if fn(tool) {\n            filtered.Add(tool)\n        }\n    }\n    return filtered\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolset/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolset): add Toolset type with basic operations\n\n- Thread-safe toolset with Add, Get, Remove operations\n- Filter method for creating filtered subsets\n- Tools, Count, IDs accessors\n- Foundation for builder pattern\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/#task-2-builder-pattern-implementation","title":"Task 2: Builder Pattern Implementation","text":"<p>Files: - Create: <code>toolset/builder.go</code> - Create: <code>toolset/builder_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// builder_test.go\npackage toolset_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolset\"\n    \"github.com/jrraymond/tooladapter\"\n)\n\n// MockRegistry for testing\ntype MockRegistry struct {\n    tools []*tooladapter.CanonicalTool\n}\n\nfunc (r *MockRegistry) All() []*tooladapter.CanonicalTool {\n    return r.tools\n}\n\nfunc TestBuilder_New(t *testing.T) {\n    builder := toolset.NewBuilder(\"my-toolset\")\n    assert.NotNil(t, builder)\n}\n\nfunc TestBuilder_FromRegistry(t *testing.T) {\n    registry := &amp;MockRegistry{\n        tools: []*tooladapter.CanonicalTool{\n            makeTool(\"search\", \"mcp\", []string{\"query\"}),\n            makeTool(\"describe\", \"mcp\", []string{\"info\"}),\n        },\n    }\n\n    ts, err := toolset.NewBuilder(\"test\").\n        FromRegistry(registry).\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, 2, ts.Count())\n}\n\nfunc TestBuilder_WithNamespace(t *testing.T) {\n    registry := &amp;MockRegistry{\n        tools: []*tooladapter.CanonicalTool{\n            makeTool(\"search\", \"mcp\", nil),\n            makeTool(\"describe\", \"mcp\", nil),\n            makeTool(\"execute\", \"local\", nil),\n        },\n    }\n\n    ts, err := toolset.NewBuilder(\"mcp-only\").\n        FromRegistry(registry).\n        WithNamespace(\"mcp\").\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, 2, ts.Count())\n    for _, tool := range ts.Tools() {\n        assert.Equal(t, \"mcp\", tool.Namespace)\n    }\n}\n\nfunc TestBuilder_WithNamespaces(t *testing.T) {\n    registry := &amp;MockRegistry{\n        tools: []*tooladapter.CanonicalTool{\n            makeTool(\"search\", \"mcp\", nil),\n            makeTool(\"execute\", \"local\", nil),\n            makeTool(\"call\", \"openai\", nil),\n        },\n    }\n\n    ts, err := toolset.NewBuilder(\"selected\").\n        FromRegistry(registry).\n        WithNamespaces([]string{\"mcp\", \"local\"}).\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, 2, ts.Count())\n}\n\nfunc TestBuilder_WithTags(t *testing.T) {\n    registry := &amp;MockRegistry{\n        tools: []*tooladapter.CanonicalTool{\n            makeTool(\"search\", \"mcp\", []string{\"query\", \"read\"}),\n            makeTool(\"write\", \"mcp\", []string{\"write\", \"modify\"}),\n            makeTool(\"read\", \"mcp\", []string{\"read\"}),\n        },\n    }\n\n    ts, err := toolset.NewBuilder(\"read-only\").\n        FromRegistry(registry).\n        WithTags([]string{\"read\"}).\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, 2, ts.Count())\n}\n\nfunc TestBuilder_WithTools(t *testing.T) {\n    registry := &amp;MockRegistry{\n        tools: []*tooladapter.CanonicalTool{\n            makeTool(\"search\", \"mcp\", nil),\n            makeTool(\"describe\", \"mcp\", nil),\n            makeTool(\"execute\", \"mcp\", nil),\n        },\n    }\n\n    ts, err := toolset.NewBuilder(\"selected\").\n        FromRegistry(registry).\n        WithTools([]string{\"mcp:search\", \"mcp:describe\"}).\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, 2, ts.Count())\n}\n\nfunc TestBuilder_ExcludeTools(t *testing.T) {\n    registry := &amp;MockRegistry{\n        tools: []*tooladapter.CanonicalTool{\n            makeTool(\"search\", \"mcp\", nil),\n            makeTool(\"describe\", \"mcp\", nil),\n            makeTool(\"execute\", \"mcp\", nil),\n        },\n    }\n\n    ts, err := toolset.NewBuilder(\"safe\").\n        FromRegistry(registry).\n        ExcludeTools([]string{\"mcp:execute\"}).\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, 2, ts.Count())\n    _, ok := ts.Get(\"mcp:execute\")\n    assert.False(t, ok)\n}\n\nfunc TestBuilder_ChainedFilters(t *testing.T) {\n    registry := &amp;MockRegistry{\n        tools: []*tooladapter.CanonicalTool{\n            makeTool(\"search\", \"mcp\", []string{\"query\", \"safe\"}),\n            makeTool(\"describe\", \"mcp\", []string{\"info\", \"safe\"}),\n            makeTool(\"execute\", \"mcp\", []string{\"dangerous\"}),\n            makeTool(\"local-search\", \"local\", []string{\"query\", \"safe\"}),\n        },\n    }\n\n    ts, err := toolset.NewBuilder(\"mcp-safe\").\n        FromRegistry(registry).\n        WithNamespace(\"mcp\").\n        WithTags([]string{\"safe\"}).\n        ExcludeTools([]string{\"mcp:execute\"}).\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, 2, ts.Count())\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// builder.go\npackage toolset\n\nimport (\n    \"slices\"\n\n    \"github.com/jrraymond/tooladapter\"\n)\n\n// ToolRegistry is the interface for tool registries\ntype ToolRegistry interface {\n    All() []*tooladapter.CanonicalTool\n}\n\n// Builder constructs toolsets with fluent API\ntype Builder struct {\n    name            string\n    registry        ToolRegistry\n    tools           []*tooladapter.CanonicalTool\n    namespaces      []string\n    tags            []string\n    includeTools    []string\n    excludeTools    []string\n    customFilters   []func(*tooladapter.CanonicalTool) bool\n}\n\n// NewBuilder creates a new toolset builder\nfunc NewBuilder(name string) *Builder {\n    return &amp;Builder{\n        name: name,\n    }\n}\n\n// FromRegistry loads tools from a registry\nfunc (b *Builder) FromRegistry(registry ToolRegistry) *Builder {\n    b.registry = registry\n    return b\n}\n\n// FromTools loads tools from a slice\nfunc (b *Builder) FromTools(tools []*tooladapter.CanonicalTool) *Builder {\n    b.tools = tools\n    return b\n}\n\n// WithNamespace filters to a single namespace\nfunc (b *Builder) WithNamespace(namespace string) *Builder {\n    b.namespaces = []string{namespace}\n    return b\n}\n\n// WithNamespaces filters to multiple namespaces\nfunc (b *Builder) WithNamespaces(namespaces []string) *Builder {\n    b.namespaces = namespaces\n    return b\n}\n\n// WithTags filters to tools with any of the specified tags\nfunc (b *Builder) WithTags(tags []string) *Builder {\n    b.tags = tags\n    return b\n}\n\n// WithTools includes only specified tool IDs\nfunc (b *Builder) WithTools(toolIDs []string) *Builder {\n    b.includeTools = toolIDs\n    return b\n}\n\n// ExcludeTools excludes specified tool IDs\nfunc (b *Builder) ExcludeTools(toolIDs []string) *Builder {\n    b.excludeTools = toolIDs\n    return b\n}\n\n// WithFilter adds a custom filter function\nfunc (b *Builder) WithFilter(fn func(*tooladapter.CanonicalTool) bool) *Builder {\n    b.customFilters = append(b.customFilters, fn)\n    return b\n}\n\n// Build constructs the toolset\nfunc (b *Builder) Build() (*Toolset, error) {\n    ts := New(b.name)\n\n    // Get source tools\n    var source []*tooladapter.CanonicalTool\n    if b.registry != nil {\n        source = b.registry.All()\n    } else if b.tools != nil {\n        source = b.tools\n    }\n\n    // Apply filters\n    for _, tool := range source {\n        if b.shouldInclude(tool) {\n            ts.Add(tool)\n        }\n    }\n\n    return ts, nil\n}\n\n// shouldInclude checks if a tool passes all filters\nfunc (b *Builder) shouldInclude(tool *tooladapter.CanonicalTool) bool {\n    // Namespace filter\n    if len(b.namespaces) &gt; 0 {\n        if !slices.Contains(b.namespaces, tool.Namespace) {\n            return false\n        }\n    }\n\n    // Tag filter (any match)\n    if len(b.tags) &gt; 0 {\n        hasTag := false\n        for _, tag := range b.tags {\n            if slices.Contains(tool.Tags, tag) {\n                hasTag = true\n                break\n            }\n        }\n        if !hasTag {\n            return false\n        }\n    }\n\n    // Include list (if specified)\n    if len(b.includeTools) &gt; 0 {\n        if !slices.Contains(b.includeTools, tool.ID()) {\n            return false\n        }\n    }\n\n    // Exclude list\n    if len(b.excludeTools) &gt; 0 {\n        if slices.Contains(b.excludeTools, tool.ID()) {\n            return false\n        }\n    }\n\n    // Custom filters\n    for _, fn := range b.customFilters {\n        if !fn(tool) {\n            return false\n        }\n    }\n\n    return true\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolset/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolset): add Builder with fluent API\n\n- FromRegistry and FromTools source loading\n- WithNamespace, WithNamespaces namespace filtering\n- WithTags for tag-based filtering\n- WithTools for explicit inclusion\n- ExcludeTools for exclusion\n- WithFilter for custom filter functions\n- Chainable fluent API\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/#task-3-filter-functions-library","title":"Task 3: Filter Functions Library","text":"<p>Files: - Create: <code>toolset/filter.go</code> - Create: <code>toolset/filter_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// filter_test.go\npackage toolset_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/jrraymond/toolset\"\n    \"github.com/jrraymond/tooladapter\"\n)\n\nfunc TestByNamespace(t *testing.T) {\n    filter := toolset.ByNamespace(\"mcp\")\n\n    assert.True(t, filter(makeTool(\"search\", \"mcp\", nil)))\n    assert.False(t, filter(makeTool(\"search\", \"local\", nil)))\n}\n\nfunc TestByNamespaces(t *testing.T) {\n    filter := toolset.ByNamespaces([]string{\"mcp\", \"local\"})\n\n    assert.True(t, filter(makeTool(\"search\", \"mcp\", nil)))\n    assert.True(t, filter(makeTool(\"execute\", \"local\", nil)))\n    assert.False(t, filter(makeTool(\"call\", \"openai\", nil)))\n}\n\nfunc TestByTag(t *testing.T) {\n    filter := toolset.ByTag(\"safe\")\n\n    assert.True(t, filter(makeTool(\"search\", \"mcp\", []string{\"safe\", \"query\"})))\n    assert.False(t, filter(makeTool(\"execute\", \"mcp\", []string{\"dangerous\"})))\n}\n\nfunc TestByAnyTag(t *testing.T) {\n    filter := toolset.ByAnyTag([]string{\"read\", \"query\"})\n\n    assert.True(t, filter(makeTool(\"search\", \"mcp\", []string{\"query\"})))\n    assert.True(t, filter(makeTool(\"get\", \"mcp\", []string{\"read\"})))\n    assert.False(t, filter(makeTool(\"write\", \"mcp\", []string{\"write\"})))\n}\n\nfunc TestByAllTags(t *testing.T) {\n    filter := toolset.ByAllTags([]string{\"safe\", \"read\"})\n\n    assert.True(t, filter(makeTool(\"search\", \"mcp\", []string{\"safe\", \"read\", \"query\"})))\n    assert.False(t, filter(makeTool(\"get\", \"mcp\", []string{\"safe\"}))) // missing \"read\"\n    assert.False(t, filter(makeTool(\"read\", \"mcp\", []string{\"read\"}))) // missing \"safe\"\n}\n\nfunc TestByCategory(t *testing.T) {\n    tool := makeTool(\"search\", \"mcp\", nil)\n    tool.Category = \"retrieval\"\n\n    filter := toolset.ByCategory(\"retrieval\")\n    assert.True(t, filter(tool))\n\n    tool2 := makeTool(\"execute\", \"mcp\", nil)\n    tool2.Category = \"execution\"\n    assert.False(t, filter(tool2))\n}\n\nfunc TestExcludeIDs(t *testing.T) {\n    filter := toolset.ExcludeIDs([]string{\"mcp:execute\", \"mcp:delete\"})\n\n    assert.True(t, filter(makeTool(\"search\", \"mcp\", nil)))\n    assert.False(t, filter(makeTool(\"execute\", \"mcp\", nil)))\n    assert.False(t, filter(makeTool(\"delete\", \"mcp\", nil)))\n}\n\nfunc TestIncludeIDs(t *testing.T) {\n    filter := toolset.IncludeIDs([]string{\"mcp:search\", \"mcp:describe\"})\n\n    assert.True(t, filter(makeTool(\"search\", \"mcp\", nil)))\n    assert.True(t, filter(makeTool(\"describe\", \"mcp\", nil)))\n    assert.False(t, filter(makeTool(\"execute\", \"mcp\", nil)))\n}\n\nfunc TestAnd(t *testing.T) {\n    filter := toolset.And(\n        toolset.ByNamespace(\"mcp\"),\n        toolset.ByTag(\"safe\"),\n    )\n\n    assert.True(t, filter(makeTool(\"search\", \"mcp\", []string{\"safe\"})))\n    assert.False(t, filter(makeTool(\"search\", \"local\", []string{\"safe\"})))\n    assert.False(t, filter(makeTool(\"search\", \"mcp\", []string{\"dangerous\"})))\n}\n\nfunc TestOr(t *testing.T) {\n    filter := toolset.Or(\n        toolset.ByNamespace(\"mcp\"),\n        toolset.ByTag(\"safe\"),\n    )\n\n    assert.True(t, filter(makeTool(\"search\", \"mcp\", []string{\"dangerous\"})))\n    assert.True(t, filter(makeTool(\"search\", \"local\", []string{\"safe\"})))\n    assert.False(t, filter(makeTool(\"search\", \"local\", []string{\"dangerous\"})))\n}\n\nfunc TestNot(t *testing.T) {\n    filter := toolset.Not(toolset.ByNamespace(\"dangerous\"))\n\n    assert.True(t, filter(makeTool(\"search\", \"mcp\", nil)))\n    assert.False(t, filter(makeTool(\"delete\", \"dangerous\", nil)))\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// filter.go\npackage toolset\n\nimport (\n    \"slices\"\n\n    \"github.com/jrraymond/tooladapter\"\n)\n\n// FilterFunc is a function that filters tools\ntype FilterFunc func(*tooladapter.CanonicalTool) bool\n\n// ByNamespace returns a filter for a single namespace\nfunc ByNamespace(namespace string) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        return tool.Namespace == namespace\n    }\n}\n\n// ByNamespaces returns a filter for multiple namespaces\nfunc ByNamespaces(namespaces []string) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        return slices.Contains(namespaces, tool.Namespace)\n    }\n}\n\n// ByTag returns a filter for tools with a specific tag\nfunc ByTag(tag string) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        return slices.Contains(tool.Tags, tag)\n    }\n}\n\n// ByAnyTag returns a filter for tools with any of the specified tags\nfunc ByAnyTag(tags []string) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        for _, tag := range tags {\n            if slices.Contains(tool.Tags, tag) {\n                return true\n            }\n        }\n        return false\n    }\n}\n\n// ByAllTags returns a filter for tools with all specified tags\nfunc ByAllTags(tags []string) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        for _, tag := range tags {\n            if !slices.Contains(tool.Tags, tag) {\n                return false\n            }\n        }\n        return true\n    }\n}\n\n// ByCategory returns a filter for tools in a specific category\nfunc ByCategory(category string) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        return tool.Category == category\n    }\n}\n\n// ExcludeIDs returns a filter that excludes specific tool IDs\nfunc ExcludeIDs(ids []string) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        return !slices.Contains(ids, tool.ID())\n    }\n}\n\n// IncludeIDs returns a filter that includes only specific tool IDs\nfunc IncludeIDs(ids []string) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        return slices.Contains(ids, tool.ID())\n    }\n}\n\n// And combines filters with AND logic\nfunc And(filters ...FilterFunc) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        for _, f := range filters {\n            if !f(tool) {\n                return false\n            }\n        }\n        return true\n    }\n}\n\n// Or combines filters with OR logic\nfunc Or(filters ...FilterFunc) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        for _, f := range filters {\n            if f(tool) {\n                return true\n            }\n        }\n        return false\n    }\n}\n\n// Not negates a filter\nfunc Not(filter FilterFunc) FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        return !filter(tool)\n    }\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolset/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolset): add composable filter functions\n\n- ByNamespace, ByNamespaces for namespace filtering\n- ByTag, ByAnyTag, ByAllTags for tag filtering\n- ByCategory for category filtering\n- ExcludeIDs, IncludeIDs for ID-based filtering\n- And, Or, Not combinators for complex filters\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/#task-4-access-control-policies","title":"Task 4: Access Control Policies","text":"<p>Files: - Create: <code>toolset/policy.go</code> - Create: <code>toolset/policy_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// policy_test.go\npackage toolset_test\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolset\"\n    \"github.com/jrraymond/tooladapter\"\n)\n\nfunc TestAccessPolicy_Allow(t *testing.T) {\n    policy := toolset.NewAccessPolicy().\n        Allow(\"mcp:search\").\n        Allow(\"mcp:describe\")\n\n    assert.True(t, policy.CanAccess(context.Background(), \"mcp:search\"))\n    assert.True(t, policy.CanAccess(context.Background(), \"mcp:describe\"))\n    assert.False(t, policy.CanAccess(context.Background(), \"mcp:execute\"))\n}\n\nfunc TestAccessPolicy_Deny(t *testing.T) {\n    policy := toolset.NewAccessPolicy().\n        AllowAll().\n        Deny(\"mcp:execute\").\n        Deny(\"mcp:delete\")\n\n    assert.True(t, policy.CanAccess(context.Background(), \"mcp:search\"))\n    assert.False(t, policy.CanAccess(context.Background(), \"mcp:execute\"))\n    assert.False(t, policy.CanAccess(context.Background(), \"mcp:delete\"))\n}\n\nfunc TestAccessPolicy_DenyTakesPrecedence(t *testing.T) {\n    policy := toolset.NewAccessPolicy().\n        Allow(\"mcp:execute\").\n        Deny(\"mcp:execute\")\n\n    // Deny takes precedence over allow\n    assert.False(t, policy.CanAccess(context.Background(), \"mcp:execute\"))\n}\n\nfunc TestAccessPolicy_AllowNamespace(t *testing.T) {\n    policy := toolset.NewAccessPolicy().\n        AllowNamespace(\"mcp\")\n\n    assert.True(t, policy.CanAccess(context.Background(), \"mcp:search\"))\n    assert.True(t, policy.CanAccess(context.Background(), \"mcp:describe\"))\n    assert.False(t, policy.CanAccess(context.Background(), \"local:execute\"))\n}\n\nfunc TestAccessPolicy_DenyNamespace(t *testing.T) {\n    policy := toolset.NewAccessPolicy().\n        AllowAll().\n        DenyNamespace(\"dangerous\")\n\n    assert.True(t, policy.CanAccess(context.Background(), \"mcp:search\"))\n    assert.False(t, policy.CanAccess(context.Background(), \"dangerous:delete\"))\n}\n\nfunc TestAccessPolicy_WithRequiredScopes(t *testing.T) {\n    policy := toolset.NewAccessPolicy().\n        AllowAll().\n        RequireScope(\"mcp:execute\", \"admin\")\n\n    ctx := context.Background()\n\n    // Without scope\n    assert.True(t, policy.CanAccess(ctx, \"mcp:search\"))\n    assert.False(t, policy.CanAccess(ctx, \"mcp:execute\"))\n\n    // With scope\n    ctxWithScope := toolset.WithScopes(ctx, []string{\"admin\"})\n    assert.True(t, policy.CanAccess(ctxWithScope, \"mcp:execute\"))\n}\n\nfunc TestAccessPolicy_Validate(t *testing.T) {\n    policy := toolset.NewAccessPolicy().\n        Allow(\"mcp:search\")\n\n    err := policy.Validate(\"mcp:search\")\n    assert.NoError(t, err)\n\n    err = policy.Validate(\"mcp:execute\")\n    assert.Error(t, err)\n    assert.Contains(t, err.Error(), \"access denied\")\n}\n\nfunc TestBuilder_WithPolicy(t *testing.T) {\n    registry := &amp;MockRegistry{\n        tools: []*tooladapter.CanonicalTool{\n            makeTool(\"search\", \"mcp\", nil),\n            makeTool(\"execute\", \"mcp\", nil),\n        },\n    }\n\n    policy := toolset.NewAccessPolicy().\n        Allow(\"mcp:search\")\n\n    ts, err := toolset.NewBuilder(\"safe\").\n        FromRegistry(registry).\n        WithPolicy(policy).\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, 1, ts.Count())\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// policy.go\npackage toolset\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"slices\"\n    \"strings\"\n)\n\ntype contextKey string\n\nconst scopesKey contextKey = \"scopes\"\n\n// WithScopes adds scopes to the context\nfunc WithScopes(ctx context.Context, scopes []string) context.Context {\n    return context.WithValue(ctx, scopesKey, scopes)\n}\n\n// ScopesFromContext retrieves scopes from context\nfunc ScopesFromContext(ctx context.Context) []string {\n    scopes, _ := ctx.Value(scopesKey).([]string)\n    return scopes\n}\n\n// AccessPolicy defines access control for tools\ntype AccessPolicy struct {\n    allowAll         bool\n    allowed          map[string]bool\n    denied           map[string]bool\n    allowedNs        map[string]bool\n    deniedNs         map[string]bool\n    requiredScopes   map[string][]string\n}\n\n// NewAccessPolicy creates a new access policy\nfunc NewAccessPolicy() *AccessPolicy {\n    return &amp;AccessPolicy{\n        allowed:        make(map[string]bool),\n        denied:         make(map[string]bool),\n        allowedNs:      make(map[string]bool),\n        deniedNs:       make(map[string]bool),\n        requiredScopes: make(map[string][]string),\n    }\n}\n\n// AllowAll allows all tools by default\nfunc (p *AccessPolicy) AllowAll() *AccessPolicy {\n    p.allowAll = true\n    return p\n}\n\n// Allow explicitly allows a tool ID\nfunc (p *AccessPolicy) Allow(toolID string) *AccessPolicy {\n    p.allowed[toolID] = true\n    return p\n}\n\n// Deny explicitly denies a tool ID\nfunc (p *AccessPolicy) Deny(toolID string) *AccessPolicy {\n    p.denied[toolID] = true\n    return p\n}\n\n// AllowNamespace allows all tools in a namespace\nfunc (p *AccessPolicy) AllowNamespace(namespace string) *AccessPolicy {\n    p.allowedNs[namespace] = true\n    return p\n}\n\n// DenyNamespace denies all tools in a namespace\nfunc (p *AccessPolicy) DenyNamespace(namespace string) *AccessPolicy {\n    p.deniedNs[namespace] = true\n    return p\n}\n\n// RequireScope requires specific scopes to access a tool\nfunc (p *AccessPolicy) RequireScope(toolID string, scopes ...string) *AccessPolicy {\n    p.requiredScopes[toolID] = scopes\n    return p\n}\n\n// CanAccess checks if access to a tool is allowed\nfunc (p *AccessPolicy) CanAccess(ctx context.Context, toolID string) bool {\n    // Check explicit deny first (takes precedence)\n    if p.denied[toolID] {\n        return false\n    }\n\n    // Check namespace deny\n    namespace := extractNamespace(toolID)\n    if p.deniedNs[namespace] {\n        return false\n    }\n\n    // Check required scopes\n    if required, ok := p.requiredScopes[toolID]; ok {\n        ctxScopes := ScopesFromContext(ctx)\n        for _, scope := range required {\n            if !slices.Contains(ctxScopes, scope) {\n                return false\n            }\n        }\n    }\n\n    // Check explicit allow\n    if p.allowed[toolID] {\n        return true\n    }\n\n    // Check namespace allow\n    if p.allowedNs[namespace] {\n        return true\n    }\n\n    // Check allowAll\n    if p.allowAll {\n        return true\n    }\n\n    return false\n}\n\n// Validate returns an error if access is denied\nfunc (p *AccessPolicy) Validate(toolID string) error {\n    if !p.CanAccess(context.Background(), toolID) {\n        return fmt.Errorf(\"access denied to tool %q\", toolID)\n    }\n    return nil\n}\n\n// AsFilter returns the policy as a filter function\nfunc (p *AccessPolicy) AsFilter() FilterFunc {\n    return func(tool *tooladapter.CanonicalTool) bool {\n        return p.CanAccess(context.Background(), tool.ID())\n    }\n}\n\n// extractNamespace gets namespace from tool ID\nfunc extractNamespace(toolID string) string {\n    if idx := strings.Index(toolID, \":\"); idx &gt; 0 {\n        return toolID[:idx]\n    }\n    return \"\"\n}\n\n// WithPolicy adds access policy filtering to builder\nfunc (b *Builder) WithPolicy(policy *AccessPolicy) *Builder {\n    b.customFilters = append(b.customFilters, policy.AsFilter())\n    return b\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolset/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolset): add AccessPolicy for access control\n\n- Allow/Deny for explicit tool permissions\n- AllowNamespace/DenyNamespace for namespace-level control\n- RequireScope for scope-based access control\n- Deny takes precedence over Allow\n- Context-based scope checking\n- Integration with Builder via WithPolicy\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/#task-5-multi-format-exposure","title":"Task 5: Multi-Format Exposure","text":"<p>Files: - Create: <code>toolset/exposure.go</code> - Create: <code>toolset/exposure_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// exposure_test.go\npackage toolset_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolset\"\n    \"github.com/jrraymond/tooladapter\"\n    \"github.com/jrraymond/tooladapter/adapters\"\n)\n\nfunc TestExposure_AsMCP(t *testing.T) {\n    ts := toolset.New(\"test\")\n    ts.Add(makeTool(\"search\", \"mcp\", nil))\n    ts.Add(makeTool(\"describe\", \"mcp\", nil))\n\n    mcpAdapter := adapters.NewMCPAdapter()\n    exposure := toolset.NewExposure(ts, mcpAdapter)\n\n    tools, err := exposure.Export()\n    require.NoError(t, err)\n    assert.Len(t, tools, 2)\n}\n\nfunc TestExposure_AsOpenAI(t *testing.T) {\n    ts := toolset.New(\"test\")\n    ts.Add(makeTool(\"search\", \"mcp\", nil))\n\n    openaiAdapter := adapters.NewOpenAIAdapter(false)\n    exposure := toolset.NewExposure(ts, openaiAdapter)\n\n    tools, err := exposure.Export()\n    require.NoError(t, err)\n    assert.Len(t, tools, 1)\n\n    fn, ok := tools[0].(*adapters.OpenAIFunction)\n    require.True(t, ok)\n    assert.Equal(t, \"search\", fn.Name)\n}\n\nfunc TestExposure_AsAnthropic(t *testing.T) {\n    ts := toolset.New(\"test\")\n    ts.Add(makeTool(\"search\", \"mcp\", nil))\n\n    anthropicAdapter := adapters.NewAnthropicAdapter()\n    exposure := toolset.NewExposure(ts, anthropicAdapter)\n\n    tools, err := exposure.Export()\n    require.NoError(t, err)\n    assert.Len(t, tools, 1)\n\n    anthropicTool, ok := tools[0].(*adapters.AnthropicTool)\n    require.True(t, ok)\n    assert.Equal(t, \"search\", anthropicTool.Name)\n}\n\nfunc TestExposure_WithWarnings(t *testing.T) {\n    ts := toolset.New(\"test\")\n    tool := makeTool(\"complex\", \"mcp\", nil)\n    tool.InputSchema = &amp;tooladapter.JSONSchema{\n        Type: \"object\",\n        Ref:  \"#/$defs/MyType\", // $ref not supported by OpenAI\n        Defs: map[string]*tooladapter.JSONSchema{\n            \"MyType\": {Type: \"string\"},\n        },\n    }\n    ts.Add(tool)\n\n    openaiAdapter := adapters.NewOpenAIAdapter(false)\n    exposure := toolset.NewExposure(ts, openaiAdapter)\n\n    _, warnings := exposure.ExportWithWarnings()\n    // Should have warning about $ref feature loss\n    assert.NotEmpty(t, warnings)\n}\n\nfunc TestToolsetServer_ListTools(t *testing.T) {\n    ts := toolset.New(\"test\")\n    ts.Add(makeTool(\"search\", \"mcp\", nil))\n    ts.Add(makeTool(\"describe\", \"mcp\", nil))\n\n    server := toolset.NewServer(ts)\n    tools := server.ListTools()\n\n    assert.Len(t, tools, 2)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// exposure.go\npackage toolset\n\nimport (\n    \"github.com/jrraymond/tooladapter\"\n)\n\n// Exposure handles converting toolsets to protocol-specific formats\ntype Exposure struct {\n    toolset *Toolset\n    adapter tooladapter.Adapter\n}\n\n// NewExposure creates a new exposure for a toolset\nfunc NewExposure(ts *Toolset, adapter tooladapter.Adapter) *Exposure {\n    return &amp;Exposure{\n        toolset: ts,\n        adapter: adapter,\n    }\n}\n\n// Export exports the toolset to the target format\nfunc (e *Exposure) Export() ([]any, error) {\n    tools := e.toolset.Tools()\n    result := make([]any, 0, len(tools))\n\n    for _, tool := range tools {\n        converted, err := e.adapter.FromCanonical(tool)\n        if err != nil {\n            return nil, err\n        }\n        result = append(result, converted)\n    }\n\n    return result, nil\n}\n\n// ExportWithWarnings exports with feature loss warnings\nfunc (e *Exposure) ExportWithWarnings() ([]any, []tooladapter.FeatureLossWarning) {\n    tools := e.toolset.Tools()\n    result := make([]any, 0, len(tools))\n    var warnings []tooladapter.FeatureLossWarning\n\n    // Check for feature loss\n    for _, feature := range tooladapter.AllFeatures() {\n        if !e.adapter.SupportsFeature(feature) {\n            warnings = append(warnings, tooladapter.FeatureLossWarning{\n                Feature: feature,\n                Adapter: e.adapter.Name(),\n            })\n        }\n    }\n\n    for _, tool := range tools {\n        converted, err := e.adapter.FromCanonical(tool)\n        if err != nil {\n            continue // Skip tools that fail conversion\n        }\n        result = append(result, converted)\n    }\n\n    return result, warnings\n}\n\n// Server wraps a toolset for serving\ntype Server struct {\n    toolset *Toolset\n}\n\n// NewServer creates a new toolset server\nfunc NewServer(ts *Toolset) *Server {\n    return &amp;Server{\n        toolset: ts,\n    }\n}\n\n// ListTools returns all tools in the toolset\nfunc (s *Server) ListTools() []*tooladapter.CanonicalTool {\n    return s.toolset.Tools()\n}\n\n// GetTool retrieves a tool by ID\nfunc (s *Server) GetTool(id string) (*tooladapter.CanonicalTool, bool) {\n    return s.toolset.Get(id)\n}\n\n// CallTool calls a tool by ID (placeholder - actual implementation would execute)\nfunc (s *Server) CallTool(id string, args map[string]any) (any, error) {\n    tool, ok := s.toolset.Get(id)\n    if !ok {\n        return nil, fmt.Errorf(\"tool %q not found\", id)\n    }\n\n    if tool.Handler == nil {\n        return nil, fmt.Errorf(\"tool %q has no handler\", id)\n    }\n\n    return tool.Handler(context.Background(), args)\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolset/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolset): add multi-format exposure\n\n- Exposure type for protocol conversion\n- Export and ExportWithWarnings methods\n- Server wrapper for serving toolsets\n- ListTools, GetTool, CallTool operations\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/#task-6-integration-with-toolindex","title":"Task 6: Integration with toolindex","text":"<p>Files: - Create: <code>toolset/integration.go</code> - Create: <code>toolset/integration_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// integration_test.go\npackage toolset_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolset\"\n    \"github.com/jrraymond/tooladapter\"\n)\n\n// MockIndex simulates toolindex.Index\ntype MockIndex struct {\n    tools map[string]*tooladapter.CanonicalTool\n}\n\nfunc (m *MockIndex) Get(id string) (*tooladapter.CanonicalTool, bool) {\n    tool, ok := m.tools[id]\n    return tool, ok\n}\n\nfunc (m *MockIndex) Search(query string, limit int) []string {\n    // Simplified search - return all IDs\n    ids := make([]string, 0, len(m.tools))\n    for id := range m.tools {\n        ids = append(ids, id)\n    }\n    return ids\n}\n\nfunc TestBuilder_FromIndex(t *testing.T) {\n    index := &amp;MockIndex{\n        tools: map[string]*tooladapter.CanonicalTool{\n            \"mcp:search\":   makeTool(\"search\", \"mcp\", nil),\n            \"mcp:describe\": makeTool(\"describe\", \"mcp\", nil),\n            \"local:run\":    makeTool(\"run\", \"local\", nil),\n        },\n    }\n\n    ts, err := toolset.NewBuilder(\"from-index\").\n        FromIndex(index).\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, 3, ts.Count())\n}\n\nfunc TestBuilder_FromIndexWithSearch(t *testing.T) {\n    index := &amp;MockIndex{\n        tools: map[string]*tooladapter.CanonicalTool{\n            \"mcp:search\":   makeTool(\"search\", \"mcp\", []string{\"query\"}),\n            \"mcp:describe\": makeTool(\"describe\", \"mcp\", []string{\"info\"}),\n        },\n    }\n\n    ts, err := toolset.NewBuilder(\"search-results\").\n        FromIndexSearch(index, \"query tools\", 10).\n        Build()\n\n    require.NoError(t, err)\n    assert.True(t, ts.Count() &gt; 0)\n}\n\nfunc TestToolset_Merge(t *testing.T) {\n    ts1 := toolset.New(\"first\")\n    ts1.Add(makeTool(\"search\", \"mcp\", nil))\n\n    ts2 := toolset.New(\"second\")\n    ts2.Add(makeTool(\"describe\", \"mcp\", nil))\n\n    merged := toolset.Merge(\"combined\", ts1, ts2)\n\n    assert.Equal(t, 2, merged.Count())\n    _, ok := merged.Get(\"mcp:search\")\n    assert.True(t, ok)\n    _, ok = merged.Get(\"mcp:describe\")\n    assert.True(t, ok)\n}\n\nfunc TestToolset_Subtract(t *testing.T) {\n    ts1 := toolset.New(\"full\")\n    ts1.Add(makeTool(\"search\", \"mcp\", nil))\n    ts1.Add(makeTool(\"describe\", \"mcp\", nil))\n    ts1.Add(makeTool(\"execute\", \"mcp\", nil))\n\n    ts2 := toolset.New(\"dangerous\")\n    ts2.Add(makeTool(\"execute\", \"mcp\", nil))\n\n    safe := toolset.Subtract(\"safe\", ts1, ts2)\n\n    assert.Equal(t, 2, safe.Count())\n    _, ok := safe.Get(\"mcp:execute\")\n    assert.False(t, ok)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// integration.go\npackage toolset\n\nimport (\n    \"github.com/jrraymond/tooladapter\"\n)\n\n// ToolIndex is the interface for tool indexes\ntype ToolIndex interface {\n    Get(id string) (*tooladapter.CanonicalTool, bool)\n    Search(query string, limit int) []string\n}\n\n// FromIndex loads tools from a tool index\nfunc (b *Builder) FromIndex(index ToolIndex) *Builder {\n    // Store index for later use\n    b.index = index\n    return b\n}\n\n// FromIndexSearch loads tools from index search results\nfunc (b *Builder) FromIndexSearch(index ToolIndex, query string, limit int) *Builder {\n    b.index = index\n    b.searchQuery = query\n    b.searchLimit = limit\n    return b\n}\n\n// Update Build to support index loading\nfunc (b *Builder) buildFromIndex() []*tooladapter.CanonicalTool {\n    if b.index == nil {\n        return nil\n    }\n\n    var ids []string\n    if b.searchQuery != \"\" {\n        ids = b.index.Search(b.searchQuery, b.searchLimit)\n    } else {\n        // Get all tools - this requires iteration which isn't in interface\n        // For now, return empty - actual implementation would need All() method\n        return nil\n    }\n\n    tools := make([]*tooladapter.CanonicalTool, 0, len(ids))\n    for _, id := range ids {\n        if tool, ok := b.index.Get(id); ok {\n            tools = append(tools, tool)\n        }\n    }\n    return tools\n}\n\n// Merge combines multiple toolsets\nfunc Merge(name string, toolsets ...*Toolset) *Toolset {\n    merged := New(name)\n    for _, ts := range toolsets {\n        for _, tool := range ts.Tools() {\n            merged.Add(tool)\n        }\n    }\n    return merged\n}\n\n// Subtract removes tools in second toolset from first\nfunc Subtract(name string, base, remove *Toolset) *Toolset {\n    result := New(name)\n    removeIDs := make(map[string]bool)\n\n    for _, tool := range remove.Tools() {\n        removeIDs[tool.ID()] = true\n    }\n\n    for _, tool := range base.Tools() {\n        if !removeIDs[tool.ID()] {\n            result.Add(tool)\n        }\n    }\n\n    return result\n}\n\n// Intersect returns tools present in all toolsets\nfunc Intersect(name string, toolsets ...*Toolset) *Toolset {\n    if len(toolsets) == 0 {\n        return New(name)\n    }\n\n    // Count occurrences\n    counts := make(map[string]int)\n    var firstTools []*tooladapter.CanonicalTool\n\n    for i, ts := range toolsets {\n        for _, tool := range ts.Tools() {\n            counts[tool.ID()]++\n            if i == 0 {\n                firstTools = append(firstTools, tool)\n            }\n        }\n    }\n\n    // Keep only tools in all toolsets\n    result := New(name)\n    for _, tool := range firstTools {\n        if counts[tool.ID()] == len(toolsets) {\n            result.Add(tool)\n        }\n    }\n\n    return result\n}\n</code></pre> <p>Add fields to Builder struct:</p> <pre><code>// Update builder.go Builder struct\ntype Builder struct {\n    name            string\n    registry        ToolRegistry\n    tools           []*tooladapter.CanonicalTool\n    namespaces      []string\n    tags            []string\n    includeTools    []string\n    excludeTools    []string\n    customFilters   []func(*tooladapter.CanonicalTool) bool\n    index           ToolIndex  // NEW\n    searchQuery     string     // NEW\n    searchLimit     int        // NEW\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolset &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolset/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolset): add toolindex integration\n\n- FromIndex for loading from tool index\n- FromIndexSearch for search-based loading\n- Merge for combining toolsets\n- Subtract for removing tools\n- Intersect for common tools\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/#verification-checklist","title":"Verification Checklist","text":"<p>Before marking PRD-009 complete:</p> <ul> <li>[ ] All tests pass: <code>go test ./... -v</code></li> <li>[ ] Code coverage &gt; 80%: <code>go test ./... -cover</code></li> <li>[ ] No linting errors: <code>golangci-lint run</code></li> <li>[ ] Documentation complete:</li> <li>[ ] Package documentation in <code>doc.go</code></li> <li>[ ] README.md with usage examples</li> <li>[ ] GoDoc comments on all exported types</li> <li>[ ] Integration verified:</li> <li>[ ] Builder fluent API works</li> <li>[ ] All filter functions compose correctly</li> <li>[ ] AccessPolicy enforces permissions</li> <li>[ ] Multi-format exposure works</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-009-toolset-composition/#definition-of-done","title":"Definition of Done","text":"<ol> <li>Toolset type with Add, Get, Remove, Filter, Tools, Count, IDs</li> <li>Builder with fluent API for composing toolsets</li> <li>FilterFunc library with composable filter functions</li> <li>AccessPolicy with allow/deny, namespace, and scope control</li> <li>Exposure for multi-format protocol conversion</li> <li>Integration with toolindex (Merge, Subtract, Intersect)</li> <li>All tests passing with &gt;80% coverage</li> <li>Documentation complete</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/","title":"PRD-010: toolobserve Library Implementation","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Create an observability library providing OpenTelemetry-based tracing, metrics, and structured logging for tool execution.</p> <p>Architecture: Observability middleware wrapping tool execution with automatic span creation, metrics collection, and structured log emission. Supports multiple exporters (OTLP, Jaeger, Prometheus, stdout).</p> <p>Tech Stack: Go, OpenTelemetry SDK, OTEL exporters</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/#overview","title":"Overview","text":"<p>The <code>toolobserve</code> library provides comprehensive observability for the metatools ecosystem, enabling distributed tracing, metrics, and structured logging across all tool operations.</p> <p>Reference: architecture-evaluation.md - Observability gap analysis</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/#directory-structure","title":"Directory Structure","text":"<pre><code>toolobserve/\n\u251c\u2500\u2500 observe.go           # Core Observer type\n\u251c\u2500\u2500 observe_test.go\n\u251c\u2500\u2500 tracer.go            # Tracing implementation\n\u251c\u2500\u2500 tracer_test.go\n\u251c\u2500\u2500 metrics.go           # Metrics implementation\n\u251c\u2500\u2500 metrics_test.go\n\u251c\u2500\u2500 logger.go            # Structured logging\n\u251c\u2500\u2500 logger_test.go\n\u251c\u2500\u2500 middleware.go        # Tool execution middleware\n\u251c\u2500\u2500 middleware_test.go\n\u251c\u2500\u2500 exporters/\n\u2502   \u251c\u2500\u2500 otlp.go          # OTLP exporter config\n\u2502   \u251c\u2500\u2500 jaeger.go        # Jaeger exporter config\n\u2502   \u251c\u2500\u2500 prometheus.go    # Prometheus exporter config\n\u2502   \u2514\u2500\u2500 stdout.go        # Stdout exporter (dev)\n\u251c\u2500\u2500 doc.go\n\u251c\u2500\u2500 go.mod\n\u2514\u2500\u2500 go.sum\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/#task-1-core-observer-and-config-types","title":"Task 1: Core Observer and Config Types","text":"<p>Files: - Create: <code>toolobserve/observe.go</code> - Create: <code>toolobserve/observe_test.go</code> - Create: <code>toolobserve/go.mod</code></p> <p>Step 1: Write failing tests</p> <pre><code>// observe_test.go\npackage toolobserve_test\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolobserve\"\n)\n\nfunc TestConfig_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        config  toolobserve.Config\n        wantErr bool\n    }{\n        {\n            name: \"valid config\",\n            config: toolobserve.Config{\n                ServiceName: \"metatools\",\n                Tracing: toolobserve.TracingConfig{\n                    Enabled: true,\n                },\n            },\n            wantErr: false,\n        },\n        {\n            name: \"missing service name\",\n            config: toolobserve.Config{\n                Tracing: toolobserve.TracingConfig{\n                    Enabled: true,\n                },\n            },\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            err := tt.config.Validate()\n            if tt.wantErr {\n                require.Error(t, err)\n            } else {\n                require.NoError(t, err)\n            }\n        })\n    }\n}\n\nfunc TestObserver_New(t *testing.T) {\n    config := toolobserve.Config{\n        ServiceName: \"test-service\",\n        Version:     \"1.0.0\",\n        Tracing: toolobserve.TracingConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n        Metrics: toolobserve.MetricsConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    }\n\n    obs, err := toolobserve.New(config)\n    require.NoError(t, err)\n    assert.NotNil(t, obs)\n\n    defer obs.Shutdown(context.Background())\n}\n\nfunc TestObserver_Tracer(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Tracing: toolobserve.TracingConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    tracer := obs.Tracer()\n    assert.NotNil(t, tracer)\n}\n\nfunc TestObserver_Meter(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Metrics: toolobserve.MetricsConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    meter := obs.Meter()\n    assert.NotNil(t, meter)\n}\n\nfunc TestObserver_Logger(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Logging: toolobserve.LoggingConfig{\n            Level:  \"info\",\n            Format: \"json\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    logger := obs.Logger()\n    assert.NotNil(t, logger)\n}\n\nfunc TestDefaultConfig(t *testing.T) {\n    config := toolobserve.DefaultConfig(\"my-service\")\n\n    assert.Equal(t, \"my-service\", config.ServiceName)\n    assert.True(t, config.Tracing.Enabled)\n    assert.True(t, config.Metrics.Enabled)\n    assert.Equal(t, \"info\", config.Logging.Level)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// go.mod\nmodule github.com/jrraymond/toolobserve\n\ngo 1.22\n\nrequire (\n    go.opentelemetry.io/otel v1.24.0\n    go.opentelemetry.io/otel/trace v1.24.0\n    go.opentelemetry.io/otel/metric v1.24.0\n    go.opentelemetry.io/otel/sdk v1.24.0\n    go.opentelemetry.io/otel/exporters/stdout/stdouttrace v1.24.0\n    go.opentelemetry.io/otel/exporters/stdout/stdoutmetric v1.24.0\n)\n</code></pre> <pre><code>// observe.go\npackage toolobserve\n\nimport (\n    \"context\"\n    \"errors\"\n    \"log/slog\"\n\n    \"go.opentelemetry.io/otel\"\n    \"go.opentelemetry.io/otel/metric\"\n    \"go.opentelemetry.io/otel/trace\"\n)\n\n// Config holds all observability configuration\ntype Config struct {\n    ServiceName    string\n    Version        string\n    Environment    string\n    Tracing        TracingConfig\n    Metrics        MetricsConfig\n    Logging        LoggingConfig\n    ResourceAttrs  map[string]string\n}\n\n// TracingConfig holds tracing configuration\ntype TracingConfig struct {\n    Enabled     bool\n    Exporter    string // otlp, jaeger, stdout\n    Endpoint    string\n    SampleRate  float64\n    Headers     map[string]string\n}\n\n// MetricsConfig holds metrics configuration\ntype MetricsConfig struct {\n    Enabled     bool\n    Exporter    string // otlp, prometheus, stdout\n    Endpoint    string\n    Interval    string // export interval\n    Headers     map[string]string\n}\n\n// LoggingConfig holds logging configuration\ntype LoggingConfig struct {\n    Level   string // debug, info, warn, error\n    Format  string // json, text\n    Output  string // stdout, stderr, file path\n}\n\n// Validate validates the configuration\nfunc (c Config) Validate() error {\n    if c.ServiceName == \"\" {\n        return errors.New(\"service name is required\")\n    }\n    return nil\n}\n\n// DefaultConfig returns a default configuration\nfunc DefaultConfig(serviceName string) Config {\n    return Config{\n        ServiceName: serviceName,\n        Environment: \"development\",\n        Tracing: TracingConfig{\n            Enabled:    true,\n            Exporter:   \"stdout\",\n            SampleRate: 1.0,\n        },\n        Metrics: MetricsConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n            Interval: \"10s\",\n        },\n        Logging: LoggingConfig{\n            Level:  \"info\",\n            Format: \"json\",\n            Output: \"stdout\",\n        },\n    }\n}\n\n// Observer provides observability primitives\ntype Observer struct {\n    config        Config\n    tracerProvider trace.TracerProvider\n    meterProvider  metric.MeterProvider\n    logger        *slog.Logger\n    shutdownFuncs []func(context.Context) error\n}\n\n// New creates a new Observer\nfunc New(config Config) (*Observer, error) {\n    if err := config.Validate(); err != nil {\n        return nil, err\n    }\n\n    obs := &amp;Observer{\n        config: config,\n    }\n\n    // Initialize tracing\n    if config.Tracing.Enabled {\n        tp, shutdown, err := initTracing(config)\n        if err != nil {\n            return nil, err\n        }\n        obs.tracerProvider = tp\n        obs.shutdownFuncs = append(obs.shutdownFuncs, shutdown)\n        otel.SetTracerProvider(tp)\n    }\n\n    // Initialize metrics\n    if config.Metrics.Enabled {\n        mp, shutdown, err := initMetrics(config)\n        if err != nil {\n            return nil, err\n        }\n        obs.meterProvider = mp\n        obs.shutdownFuncs = append(obs.shutdownFuncs, shutdown)\n        otel.SetMeterProvider(mp)\n    }\n\n    // Initialize logging\n    obs.logger = initLogger(config.Logging)\n\n    return obs, nil\n}\n\n// Tracer returns the tracer\nfunc (o *Observer) Tracer() trace.Tracer {\n    if o.tracerProvider == nil {\n        return otel.Tracer(o.config.ServiceName)\n    }\n    return o.tracerProvider.Tracer(o.config.ServiceName)\n}\n\n// Meter returns the meter\nfunc (o *Observer) Meter() metric.Meter {\n    if o.meterProvider == nil {\n        return otel.Meter(o.config.ServiceName)\n    }\n    return o.meterProvider.Meter(o.config.ServiceName)\n}\n\n// Logger returns the logger\nfunc (o *Observer) Logger() *slog.Logger {\n    if o.logger == nil {\n        return slog.Default()\n    }\n    return o.logger\n}\n\n// Shutdown shuts down all observability providers\nfunc (o *Observer) Shutdown(ctx context.Context) error {\n    var errs []error\n    for _, fn := range o.shutdownFuncs {\n        if err := fn(ctx); err != nil {\n            errs = append(errs, err)\n        }\n    }\n    if len(errs) &gt; 0 {\n        return errors.Join(errs...)\n    }\n    return nil\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolobserve/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolobserve): add core Observer and Config types\n\n- Config with Tracing, Metrics, Logging sub-configs\n- Observer with Tracer, Meter, Logger accessors\n- DefaultConfig for development setup\n- Graceful shutdown support\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/#task-2-tracing-implementation","title":"Task 2: Tracing Implementation","text":"<p>Files: - Create: <code>toolobserve/tracer.go</code> - Create: <code>toolobserve/tracer_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// tracer_test.go\npackage toolobserve_test\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolobserve\"\n    \"go.opentelemetry.io/otel/trace\"\n)\n\nfunc TestSpan_ToolExecution(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Tracing: toolobserve.TracingConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    ctx := context.Background()\n    ctx, span := toolobserve.StartToolSpan(ctx, obs.Tracer(), \"test:search\", map[string]any{\n        \"query\": \"test query\",\n    })\n    defer span.End()\n\n    assert.True(t, span.SpanContext().IsValid())\n    assert.True(t, span.SpanContext().IsSampled())\n}\n\nfunc TestSpan_ToolCallAttributes(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Tracing: toolobserve.TracingConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    ctx := context.Background()\n    ctx, span := toolobserve.StartToolSpan(ctx, obs.Tracer(), \"mcp:search\", map[string]any{\n        \"query\": \"find tools\",\n        \"limit\": 10,\n    })\n\n    // Add result\n    toolobserve.RecordToolResult(span, \"success\", 5)\n    span.End()\n\n    // Span should be valid\n    assert.True(t, span.SpanContext().IsValid())\n}\n\nfunc TestSpan_ToolError(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Tracing: toolobserve.TracingConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    ctx := context.Background()\n    ctx, span := toolobserve.StartToolSpan(ctx, obs.Tracer(), \"mcp:execute\", nil)\n\n    toolobserve.RecordToolError(span, errors.New(\"execution failed\"))\n    span.End()\n\n    assert.True(t, span.SpanContext().IsValid())\n}\n\nfunc TestSpan_ChainExecution(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Tracing: toolobserve.TracingConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    ctx := context.Background()\n\n    // Start chain span\n    ctx, chainSpan := toolobserve.StartChainSpan(ctx, obs.Tracer(), \"test-chain\", 3)\n\n    // Start step spans (children of chain)\n    for i := 0; i &lt; 3; i++ {\n        _, stepSpan := toolobserve.StartStepSpan(ctx, obs.Tracer(), i, \"mcp:tool\"+string(rune('A'+i)))\n        stepSpan.End()\n    }\n\n    chainSpan.End()\n    assert.True(t, chainSpan.SpanContext().IsValid())\n}\n\nfunc TestExtractSpanContext(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Tracing: toolobserve.TracingConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    ctx := context.Background()\n    ctx, span := toolobserve.StartToolSpan(ctx, obs.Tracer(), \"test:tool\", nil)\n    defer span.End()\n\n    // Extract context\n    traceID, spanID := toolobserve.ExtractSpanContext(ctx)\n    assert.NotEmpty(t, traceID)\n    assert.NotEmpty(t, spanID)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// tracer.go\npackage toolobserve\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"go.opentelemetry.io/otel\"\n    \"go.opentelemetry.io/otel/attribute\"\n    \"go.opentelemetry.io/otel/codes\"\n    \"go.opentelemetry.io/otel/exporters/stdout/stdouttrace\"\n    sdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n    \"go.opentelemetry.io/otel/trace\"\n)\n\n// Semantic convention attributes for tool execution\nconst (\n    AttrToolID       = \"tool.id\"\n    AttrToolName     = \"tool.name\"\n    AttrToolNs       = \"tool.namespace\"\n    AttrToolStatus   = \"tool.status\"\n    AttrToolResults  = \"tool.results_count\"\n    AttrChainID      = \"chain.id\"\n    AttrChainSteps   = \"chain.steps\"\n    AttrStepIndex    = \"step.index\"\n)\n\n// initTracing initializes the tracer provider\nfunc initTracing(config Config) (trace.TracerProvider, func(context.Context) error, error) {\n    var exporter sdktrace.SpanExporter\n    var err error\n\n    switch config.Tracing.Exporter {\n    case \"stdout\":\n        exporter, err = stdouttrace.New(stdouttrace.WithPrettyPrint())\n    case \"otlp\":\n        exporter, err = initOTLPTraceExporter(config.Tracing)\n    case \"jaeger\":\n        exporter, err = initJaegerExporter(config.Tracing)\n    default:\n        exporter, err = stdouttrace.New()\n    }\n\n    if err != nil {\n        return nil, nil, fmt.Errorf(\"failed to create trace exporter: %w\", err)\n    }\n\n    sampler := sdktrace.AlwaysSample()\n    if config.Tracing.SampleRate &lt; 1.0 {\n        sampler = sdktrace.TraceIDRatioBased(config.Tracing.SampleRate)\n    }\n\n    tp := sdktrace.NewTracerProvider(\n        sdktrace.WithBatcher(exporter),\n        sdktrace.WithSampler(sampler),\n        sdktrace.WithResource(buildResource(config)),\n    )\n\n    return tp, tp.Shutdown, nil\n}\n\n// StartToolSpan starts a span for tool execution\nfunc StartToolSpan(ctx context.Context, tracer trace.Tracer, toolID string, args map[string]any) (context.Context, trace.Span) {\n    attrs := []attribute.KeyValue{\n        attribute.String(AttrToolID, toolID),\n    }\n\n    // Extract namespace and name from tool ID\n    if ns, name := parseToolID(toolID); ns != \"\" {\n        attrs = append(attrs,\n            attribute.String(AttrToolNs, ns),\n            attribute.String(AttrToolName, name),\n        )\n    }\n\n    // Add argument attributes (sanitized)\n    for k, v := range args {\n        attrs = append(attrs, attribute.String(\"tool.arg.\"+k, fmt.Sprintf(\"%v\", v)))\n    }\n\n    ctx, span := tracer.Start(ctx, \"tool.execute\",\n        trace.WithSpanKind(trace.SpanKindInternal),\n        trace.WithAttributes(attrs...),\n    )\n\n    return ctx, span\n}\n\n// RecordToolResult records a successful tool result\nfunc RecordToolResult(span trace.Span, status string, resultCount int) {\n    span.SetAttributes(\n        attribute.String(AttrToolStatus, status),\n        attribute.Int(AttrToolResults, resultCount),\n    )\n    span.SetStatus(codes.Ok, \"success\")\n}\n\n// RecordToolError records a tool execution error\nfunc RecordToolError(span trace.Span, err error) {\n    span.RecordError(err)\n    span.SetStatus(codes.Error, err.Error())\n    span.SetAttributes(attribute.String(AttrToolStatus, \"error\"))\n}\n\n// StartChainSpan starts a span for chain execution\nfunc StartChainSpan(ctx context.Context, tracer trace.Tracer, chainID string, steps int) (context.Context, trace.Span) {\n    ctx, span := tracer.Start(ctx, \"chain.execute\",\n        trace.WithSpanKind(trace.SpanKindInternal),\n        trace.WithAttributes(\n            attribute.String(AttrChainID, chainID),\n            attribute.Int(AttrChainSteps, steps),\n        ),\n    )\n    return ctx, span\n}\n\n// StartStepSpan starts a span for a chain step\nfunc StartStepSpan(ctx context.Context, tracer trace.Tracer, index int, toolID string) (context.Context, trace.Span) {\n    ctx, span := tracer.Start(ctx, \"chain.step\",\n        trace.WithSpanKind(trace.SpanKindInternal),\n        trace.WithAttributes(\n            attribute.Int(AttrStepIndex, index),\n            attribute.String(AttrToolID, toolID),\n        ),\n    )\n    return ctx, span\n}\n\n// ExtractSpanContext extracts trace and span IDs from context\nfunc ExtractSpanContext(ctx context.Context) (traceID, spanID string) {\n    span := trace.SpanFromContext(ctx)\n    if span == nil {\n        return \"\", \"\"\n    }\n    sc := span.SpanContext()\n    return sc.TraceID().String(), sc.SpanID().String()\n}\n\n// parseToolID extracts namespace and name from tool ID\nfunc parseToolID(toolID string) (namespace, name string) {\n    for i, c := range toolID {\n        if c == ':' {\n            return toolID[:i], toolID[i+1:]\n        }\n    }\n    return \"\", toolID\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolobserve/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolobserve): add tracing implementation\n\n- StartToolSpan with semantic attributes\n- RecordToolResult and RecordToolError\n- StartChainSpan and StartStepSpan for chains\n- ExtractSpanContext for context propagation\n- Stdout exporter for development\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/#task-3-metrics-implementation","title":"Task 3: Metrics Implementation","text":"<p>Files: - Create: <code>toolobserve/metrics.go</code> - Create: <code>toolobserve/metrics_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// metrics_test.go\npackage toolobserve_test\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolobserve\"\n)\n\nfunc TestMetrics_ToolCallCounter(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Metrics: toolobserve.MetricsConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    metrics := toolobserve.NewToolMetrics(obs.Meter())\n\n    // Record tool calls\n    metrics.RecordToolCall(\"mcp:search\", \"success\")\n    metrics.RecordToolCall(\"mcp:search\", \"success\")\n    metrics.RecordToolCall(\"mcp:search\", \"error\")\n\n    // Metrics should be recorded (can't easily assert values)\n    assert.NotNil(t, metrics)\n}\n\nfunc TestMetrics_ToolLatency(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Metrics: toolobserve.MetricsConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    metrics := toolobserve.NewToolMetrics(obs.Meter())\n\n    // Record latency\n    metrics.RecordToolLatency(\"mcp:search\", 150*time.Millisecond)\n    metrics.RecordToolLatency(\"mcp:search\", 200*time.Millisecond)\n\n    assert.NotNil(t, metrics)\n}\n\nfunc TestMetrics_ChainMetrics(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Metrics: toolobserve.MetricsConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    metrics := toolobserve.NewToolMetrics(obs.Meter())\n\n    // Record chain execution\n    metrics.RecordChainExecution(\"chain-1\", 3, 500*time.Millisecond, \"success\")\n    metrics.RecordChainExecution(\"chain-2\", 5, 1*time.Second, \"error\")\n\n    assert.NotNil(t, metrics)\n}\n\nfunc TestMetrics_ToolsInFlight(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Metrics: toolobserve.MetricsConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    metrics := toolobserve.NewToolMetrics(obs.Meter())\n\n    // Track in-flight\n    metrics.ToolStarted(\"mcp:search\")\n    metrics.ToolStarted(\"mcp:search\")\n    metrics.ToolCompleted(\"mcp:search\")\n\n    assert.NotNil(t, metrics)\n}\n\nfunc TestMetrics_BackendMetrics(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Metrics: toolobserve.MetricsConfig{\n            Enabled:  true,\n            Exporter: \"stdout\",\n        },\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    metrics := toolobserve.NewToolMetrics(obs.Meter())\n\n    // Record backend calls\n    metrics.RecordBackendCall(\"mcp\", \"github-server\", 100*time.Millisecond, \"success\")\n    metrics.RecordBackendCall(\"local\", \"handler\", 50*time.Millisecond, \"success\")\n    metrics.RecordBackendCall(\"mcp\", \"github-server\", 0, \"error\")\n\n    assert.NotNil(t, metrics)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// metrics.go\npackage toolobserve\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"go.opentelemetry.io/otel/attribute\"\n    \"go.opentelemetry.io/otel/exporters/stdout/stdoutmetric\"\n    \"go.opentelemetry.io/otel/metric\"\n    sdkmetric \"go.opentelemetry.io/otel/sdk/metric\"\n)\n\n// ToolMetrics holds all tool-related metrics\ntype ToolMetrics struct {\n    meter metric.Meter\n\n    // Counters\n    toolCalls    metric.Int64Counter\n    chainCalls   metric.Int64Counter\n    backendCalls metric.Int64Counter\n\n    // Histograms\n    toolLatency    metric.Float64Histogram\n    chainLatency   metric.Float64Histogram\n    backendLatency metric.Float64Histogram\n\n    // Gauges (via UpDownCounter)\n    toolsInFlight metric.Int64UpDownCounter\n}\n\n// NewToolMetrics creates a new ToolMetrics instance\nfunc NewToolMetrics(meter metric.Meter) *ToolMetrics {\n    m := &amp;ToolMetrics{meter: meter}\n    m.init()\n    return m\n}\n\nfunc (m *ToolMetrics) init() {\n    var err error\n\n    // Tool call counter\n    m.toolCalls, err = m.meter.Int64Counter(\n        \"tool.calls.total\",\n        metric.WithDescription(\"Total number of tool calls\"),\n        metric.WithUnit(\"{call}\"),\n    )\n    if err != nil {\n        panic(fmt.Sprintf(\"failed to create tool.calls.total metric: %v\", err))\n    }\n\n    // Chain call counter\n    m.chainCalls, err = m.meter.Int64Counter(\n        \"chain.calls.total\",\n        metric.WithDescription(\"Total number of chain executions\"),\n        metric.WithUnit(\"{call}\"),\n    )\n    if err != nil {\n        panic(fmt.Sprintf(\"failed to create chain.calls.total metric: %v\", err))\n    }\n\n    // Backend call counter\n    m.backendCalls, err = m.meter.Int64Counter(\n        \"backend.calls.total\",\n        metric.WithDescription(\"Total number of backend calls\"),\n        metric.WithUnit(\"{call}\"),\n    )\n    if err != nil {\n        panic(fmt.Sprintf(\"failed to create backend.calls.total metric: %v\", err))\n    }\n\n    // Tool latency histogram\n    m.toolLatency, err = m.meter.Float64Histogram(\n        \"tool.latency\",\n        metric.WithDescription(\"Tool execution latency in milliseconds\"),\n        metric.WithUnit(\"ms\"),\n    )\n    if err != nil {\n        panic(fmt.Sprintf(\"failed to create tool.latency metric: %v\", err))\n    }\n\n    // Chain latency histogram\n    m.chainLatency, err = m.meter.Float64Histogram(\n        \"chain.latency\",\n        metric.WithDescription(\"Chain execution latency in milliseconds\"),\n        metric.WithUnit(\"ms\"),\n    )\n    if err != nil {\n        panic(fmt.Sprintf(\"failed to create chain.latency metric: %v\", err))\n    }\n\n    // Backend latency histogram\n    m.backendLatency, err = m.meter.Float64Histogram(\n        \"backend.latency\",\n        metric.WithDescription(\"Backend call latency in milliseconds\"),\n        metric.WithUnit(\"ms\"),\n    )\n    if err != nil {\n        panic(fmt.Sprintf(\"failed to create backend.latency metric: %v\", err))\n    }\n\n    // Tools in flight gauge\n    m.toolsInFlight, err = m.meter.Int64UpDownCounter(\n        \"tool.in_flight\",\n        metric.WithDescription(\"Number of tools currently executing\"),\n        metric.WithUnit(\"{tool}\"),\n    )\n    if err != nil {\n        panic(fmt.Sprintf(\"failed to create tool.in_flight metric: %v\", err))\n    }\n}\n\n// RecordToolCall records a tool call\nfunc (m *ToolMetrics) RecordToolCall(toolID, status string) {\n    ns, name := parseToolID(toolID)\n    m.toolCalls.Add(context.Background(), 1,\n        metric.WithAttributes(\n            attribute.String(\"tool.id\", toolID),\n            attribute.String(\"tool.namespace\", ns),\n            attribute.String(\"tool.name\", name),\n            attribute.String(\"status\", status),\n        ),\n    )\n}\n\n// RecordToolLatency records tool execution latency\nfunc (m *ToolMetrics) RecordToolLatency(toolID string, duration time.Duration) {\n    ns, name := parseToolID(toolID)\n    m.toolLatency.Record(context.Background(), float64(duration.Milliseconds()),\n        metric.WithAttributes(\n            attribute.String(\"tool.id\", toolID),\n            attribute.String(\"tool.namespace\", ns),\n            attribute.String(\"tool.name\", name),\n        ),\n    )\n}\n\n// RecordChainExecution records a chain execution\nfunc (m *ToolMetrics) RecordChainExecution(chainID string, steps int, duration time.Duration, status string) {\n    m.chainCalls.Add(context.Background(), 1,\n        metric.WithAttributes(\n            attribute.String(\"chain.id\", chainID),\n            attribute.Int(\"chain.steps\", steps),\n            attribute.String(\"status\", status),\n        ),\n    )\n    m.chainLatency.Record(context.Background(), float64(duration.Milliseconds()),\n        metric.WithAttributes(\n            attribute.String(\"chain.id\", chainID),\n        ),\n    )\n}\n\n// ToolStarted increments in-flight counter\nfunc (m *ToolMetrics) ToolStarted(toolID string) {\n    m.toolsInFlight.Add(context.Background(), 1,\n        metric.WithAttributes(attribute.String(\"tool.id\", toolID)),\n    )\n}\n\n// ToolCompleted decrements in-flight counter\nfunc (m *ToolMetrics) ToolCompleted(toolID string) {\n    m.toolsInFlight.Add(context.Background(), -1,\n        metric.WithAttributes(attribute.String(\"tool.id\", toolID)),\n    )\n}\n\n// RecordBackendCall records a backend call\nfunc (m *ToolMetrics) RecordBackendCall(backendType, backendName string, duration time.Duration, status string) {\n    m.backendCalls.Add(context.Background(), 1,\n        metric.WithAttributes(\n            attribute.String(\"backend.type\", backendType),\n            attribute.String(\"backend.name\", backendName),\n            attribute.String(\"status\", status),\n        ),\n    )\n    if duration &gt; 0 {\n        m.backendLatency.Record(context.Background(), float64(duration.Milliseconds()),\n            metric.WithAttributes(\n                attribute.String(\"backend.type\", backendType),\n                attribute.String(\"backend.name\", backendName),\n            ),\n        )\n    }\n}\n\n// initMetrics initializes the meter provider\nfunc initMetrics(config Config) (metric.MeterProvider, func(context.Context) error, error) {\n    var exporter sdkmetric.Exporter\n    var err error\n\n    switch config.Metrics.Exporter {\n    case \"stdout\":\n        exporter, err = stdoutmetric.New()\n    case \"otlp\":\n        exporter, err = initOTLPMetricExporter(config.Metrics)\n    case \"prometheus\":\n        // Prometheus uses a reader, not exporter\n        return initPrometheusMetrics(config)\n    default:\n        exporter, err = stdoutmetric.New()\n    }\n\n    if err != nil {\n        return nil, nil, fmt.Errorf(\"failed to create metric exporter: %w\", err)\n    }\n\n    mp := sdkmetric.NewMeterProvider(\n        sdkmetric.WithReader(sdkmetric.NewPeriodicReader(exporter)),\n        sdkmetric.WithResource(buildResource(config)),\n    )\n\n    return mp, mp.Shutdown, nil\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolobserve/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolobserve): add metrics implementation\n\n- ToolMetrics with counters, histograms, gauges\n- RecordToolCall, RecordToolLatency\n- RecordChainExecution for chain metrics\n- ToolStarted/ToolCompleted for in-flight tracking\n- RecordBackendCall for backend metrics\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/#task-4-observability-middleware","title":"Task 4: Observability Middleware","text":"<p>Files: - Create: <code>toolobserve/middleware.go</code> - Create: <code>toolobserve/middleware_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// middleware_test.go\npackage toolobserve_test\n\nimport (\n    \"context\"\n    \"errors\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolobserve\"\n)\n\n// MockToolProvider for testing\ntype MockToolProvider struct {\n    name    string\n    handler func(ctx context.Context, input map[string]any) (any, error)\n}\n\nfunc (m *MockToolProvider) Name() string { return m.name }\nfunc (m *MockToolProvider) Handle(ctx context.Context, input map[string]any) (any, error) {\n    return m.handler(ctx, input)\n}\n\nfunc TestObserveMiddleware_Success(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Tracing:     toolobserve.TracingConfig{Enabled: true, Exporter: \"stdout\"},\n        Metrics:     toolobserve.MetricsConfig{Enabled: true, Exporter: \"stdout\"},\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    provider := &amp;MockToolProvider{\n        name: \"mcp:search\",\n        handler: func(ctx context.Context, input map[string]any) (any, error) {\n            return map[string]any{\"results\": []string{\"a\", \"b\", \"c\"}}, nil\n        },\n    }\n\n    wrapped := toolobserve.ObserveMiddleware(obs)(provider)\n\n    result, err := wrapped.Handle(context.Background(), map[string]any{\"query\": \"test\"})\n    require.NoError(t, err)\n    assert.NotNil(t, result)\n}\n\nfunc TestObserveMiddleware_Error(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Tracing:     toolobserve.TracingConfig{Enabled: true, Exporter: \"stdout\"},\n        Metrics:     toolobserve.MetricsConfig{Enabled: true, Exporter: \"stdout\"},\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    expectedErr := errors.New(\"tool failed\")\n    provider := &amp;MockToolProvider{\n        name: \"mcp:execute\",\n        handler: func(ctx context.Context, input map[string]any) (any, error) {\n            return nil, expectedErr\n        },\n    }\n\n    wrapped := toolobserve.ObserveMiddleware(obs)(provider)\n\n    _, err = wrapped.Handle(context.Background(), nil)\n    require.Error(t, err)\n    assert.Equal(t, expectedErr, err)\n}\n\nfunc TestObserveMiddleware_TracesContext(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Tracing:     toolobserve.TracingConfig{Enabled: true, Exporter: \"stdout\"},\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    var capturedTraceID string\n    provider := &amp;MockToolProvider{\n        name: \"mcp:tool\",\n        handler: func(ctx context.Context, input map[string]any) (any, error) {\n            traceID, _ := toolobserve.ExtractSpanContext(ctx)\n            capturedTraceID = traceID\n            return nil, nil\n        },\n    }\n\n    wrapped := toolobserve.ObserveMiddleware(obs)(provider)\n    wrapped.Handle(context.Background(), nil)\n\n    assert.NotEmpty(t, capturedTraceID)\n}\n\nfunc TestObserveChainMiddleware(t *testing.T) {\n    obs, err := toolobserve.New(toolobserve.Config{\n        ServiceName: \"test\",\n        Tracing:     toolobserve.TracingConfig{Enabled: true, Exporter: \"stdout\"},\n        Metrics:     toolobserve.MetricsConfig{Enabled: true, Exporter: \"stdout\"},\n    })\n    require.NoError(t, err)\n    defer obs.Shutdown(context.Background())\n\n    steps := []string{\"tool-a\", \"tool-b\", \"tool-c\"}\n    results := make([]any, len(steps))\n\n    err = toolobserve.ObserveChain(context.Background(), obs, \"test-chain\", steps,\n        func(ctx context.Context, stepIndex int, toolID string) (any, error) {\n            time.Sleep(10 * time.Millisecond)\n            return map[string]any{\"step\": stepIndex}, nil\n        },\n        func(stepIndex int, result any) {\n            results[stepIndex] = result\n        },\n    )\n\n    require.NoError(t, err)\n    assert.Len(t, results, 3)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// middleware.go\npackage toolobserve\n\nimport (\n    \"context\"\n    \"time\"\n)\n\n// ToolProvider is the interface for tool providers\ntype ToolProvider interface {\n    Name() string\n    Handle(ctx context.Context, input map[string]any) (any, error)\n}\n\n// Middleware wraps a ToolProvider\ntype Middleware func(ToolProvider) ToolProvider\n\n// observedProvider wraps a provider with observability\ntype observedProvider struct {\n    observer *Observer\n    metrics  *ToolMetrics\n    next     ToolProvider\n}\n\n// ObserveMiddleware creates observability middleware\nfunc ObserveMiddleware(obs *Observer) Middleware {\n    metrics := NewToolMetrics(obs.Meter())\n\n    return func(next ToolProvider) ToolProvider {\n        return &amp;observedProvider{\n            observer: obs,\n            metrics:  metrics,\n            next:     next,\n        }\n    }\n}\n\nfunc (p *observedProvider) Name() string {\n    return p.next.Name()\n}\n\nfunc (p *observedProvider) Handle(ctx context.Context, input map[string]any) (any, error) {\n    toolID := p.next.Name()\n    start := time.Now()\n\n    // Start span\n    ctx, span := StartToolSpan(ctx, p.observer.Tracer(), toolID, input)\n    defer span.End()\n\n    // Track in-flight\n    p.metrics.ToolStarted(toolID)\n    defer p.metrics.ToolCompleted(toolID)\n\n    // Log start\n    p.observer.Logger().Info(\"tool.call.start\",\n        \"tool_id\", toolID,\n        \"trace_id\", span.SpanContext().TraceID().String(),\n    )\n\n    // Execute\n    result, err := p.next.Handle(ctx, input)\n    duration := time.Since(start)\n\n    // Record metrics and spans\n    if err != nil {\n        RecordToolError(span, err)\n        p.metrics.RecordToolCall(toolID, \"error\")\n        p.observer.Logger().Error(\"tool.call.error\",\n            \"tool_id\", toolID,\n            \"duration_ms\", duration.Milliseconds(),\n            \"error\", err.Error(),\n        )\n    } else {\n        RecordToolResult(span, \"success\", countResults(result))\n        p.metrics.RecordToolCall(toolID, \"success\")\n        p.metrics.RecordToolLatency(toolID, duration)\n        p.observer.Logger().Info(\"tool.call.success\",\n            \"tool_id\", toolID,\n            \"duration_ms\", duration.Milliseconds(),\n        )\n    }\n\n    return result, err\n}\n\n// StepExecutor executes a chain step\ntype StepExecutor func(ctx context.Context, stepIndex int, toolID string) (any, error)\n\n// StepCallback is called after each step\ntype StepCallback func(stepIndex int, result any)\n\n// ObserveChain executes a chain with observability\nfunc ObserveChain(\n    ctx context.Context,\n    obs *Observer,\n    chainID string,\n    steps []string,\n    executor StepExecutor,\n    callback StepCallback,\n) error {\n    start := time.Now()\n    metrics := NewToolMetrics(obs.Meter())\n\n    // Start chain span\n    ctx, chainSpan := StartChainSpan(ctx, obs.Tracer(), chainID, len(steps))\n    defer chainSpan.End()\n\n    obs.Logger().Info(\"chain.start\",\n        \"chain_id\", chainID,\n        \"steps\", len(steps),\n        \"trace_id\", chainSpan.SpanContext().TraceID().String(),\n    )\n\n    var lastErr error\n    for i, toolID := range steps {\n        stepCtx, stepSpan := StartStepSpan(ctx, obs.Tracer(), i, toolID)\n\n        result, err := executor(stepCtx, i, toolID)\n\n        if err != nil {\n            RecordToolError(stepSpan, err)\n            stepSpan.End()\n            lastErr = err\n            obs.Logger().Error(\"chain.step.error\",\n                \"chain_id\", chainID,\n                \"step\", i,\n                \"tool_id\", toolID,\n                \"error\", err.Error(),\n            )\n            break\n        }\n\n        RecordToolResult(stepSpan, \"success\", countResults(result))\n        stepSpan.End()\n\n        if callback != nil {\n            callback(i, result)\n        }\n    }\n\n    duration := time.Since(start)\n    status := \"success\"\n    if lastErr != nil {\n        status = \"error\"\n    }\n\n    metrics.RecordChainExecution(chainID, len(steps), duration, status)\n    obs.Logger().Info(\"chain.complete\",\n        \"chain_id\", chainID,\n        \"duration_ms\", duration.Milliseconds(),\n        \"status\", status,\n    )\n\n    return lastErr\n}\n\n// countResults attempts to count results\nfunc countResults(result any) int {\n    if result == nil {\n        return 0\n    }\n    switch v := result.(type) {\n    case []any:\n        return len(v)\n    case map[string]any:\n        if results, ok := v[\"results\"].([]any); ok {\n            return len(results)\n        }\n        return 1\n    default:\n        return 1\n    }\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolobserve/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolobserve): add observability middleware\n\n- ObserveMiddleware wraps ToolProvider with tracing/metrics\n- Automatic span creation and error recording\n- In-flight tracking via metrics\n- Structured logging for all operations\n- ObserveChain for chain execution observability\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/#task-5-structured-logging","title":"Task 5: Structured Logging","text":"<p>Files: - Create: <code>toolobserve/logger.go</code> - Create: <code>toolobserve/logger_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// logger_test.go\npackage toolobserve_test\n\nimport (\n    \"bytes\"\n    \"encoding/json\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolobserve\"\n)\n\nfunc TestLogger_JSONFormat(t *testing.T) {\n    var buf bytes.Buffer\n    logger := toolobserve.NewLogger(toolobserve.LoggingConfig{\n        Level:  \"info\",\n        Format: \"json\",\n    }, &amp;buf)\n\n    logger.Info(\"test message\", \"key\", \"value\")\n\n    var entry map[string]any\n    err := json.Unmarshal(buf.Bytes(), &amp;entry)\n    require.NoError(t, err)\n\n    assert.Equal(t, \"test message\", entry[\"msg\"])\n    assert.Equal(t, \"value\", entry[\"key\"])\n}\n\nfunc TestLogger_LevelFiltering(t *testing.T) {\n    var buf bytes.Buffer\n    logger := toolobserve.NewLogger(toolobserve.LoggingConfig{\n        Level:  \"warn\",\n        Format: \"json\",\n    }, &amp;buf)\n\n    logger.Info(\"should be filtered\")\n    logger.Warn(\"should appear\")\n\n    // Only warn message should appear\n    assert.Contains(t, buf.String(), \"should appear\")\n    assert.NotContains(t, buf.String(), \"should be filtered\")\n}\n\nfunc TestLogger_WithContext(t *testing.T) {\n    var buf bytes.Buffer\n    logger := toolobserve.NewLogger(toolobserve.LoggingConfig{\n        Level:  \"info\",\n        Format: \"json\",\n    }, &amp;buf)\n\n    // Create logger with context\n    ctxLogger := logger.With(\"service\", \"metatools\", \"version\", \"1.0.0\")\n    ctxLogger.Info(\"contextual log\")\n\n    var entry map[string]any\n    err := json.Unmarshal(buf.Bytes(), &amp;entry)\n    require.NoError(t, err)\n\n    assert.Equal(t, \"metatools\", entry[\"service\"])\n    assert.Equal(t, \"1.0.0\", entry[\"version\"])\n}\n\nfunc TestLogger_ToolCallEntry(t *testing.T) {\n    var buf bytes.Buffer\n    logger := toolobserve.NewLogger(toolobserve.LoggingConfig{\n        Level:  \"info\",\n        Format: \"json\",\n    }, &amp;buf)\n\n    toolobserve.LogToolCall(logger, \"mcp:search\", \"query\", \"test\", \"success\", 150)\n\n    var entry map[string]any\n    err := json.Unmarshal(buf.Bytes(), &amp;entry)\n    require.NoError(t, err)\n\n    assert.Equal(t, \"tool.call\", entry[\"msg\"])\n    assert.Equal(t, \"mcp:search\", entry[\"tool_id\"])\n    assert.Equal(t, \"success\", entry[\"status\"])\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// logger.go\npackage toolobserve\n\nimport (\n    \"io\"\n    \"log/slog\"\n    \"os\"\n    \"strings\"\n)\n\n// initLogger initializes the structured logger\nfunc initLogger(config LoggingConfig) *slog.Logger {\n    var output io.Writer\n    switch config.Output {\n    case \"stderr\":\n        output = os.Stderr\n    case \"stdout\", \"\":\n        output = os.Stdout\n    default:\n        // File output\n        f, err := os.OpenFile(config.Output, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)\n        if err != nil {\n            output = os.Stdout\n        } else {\n            output = f\n        }\n    }\n\n    return NewLogger(config, output)\n}\n\n// NewLogger creates a new structured logger\nfunc NewLogger(config LoggingConfig, output io.Writer) *slog.Logger {\n    level := parseLevel(config.Level)\n\n    var handler slog.Handler\n    opts := &amp;slog.HandlerOptions{Level: level}\n\n    switch config.Format {\n    case \"json\":\n        handler = slog.NewJSONHandler(output, opts)\n    case \"text\", \"\":\n        handler = slog.NewTextHandler(output, opts)\n    default:\n        handler = slog.NewJSONHandler(output, opts)\n    }\n\n    return slog.New(handler)\n}\n\n// parseLevel parses log level string\nfunc parseLevel(level string) slog.Level {\n    switch strings.ToLower(level) {\n    case \"debug\":\n        return slog.LevelDebug\n    case \"info\", \"\":\n        return slog.LevelInfo\n    case \"warn\", \"warning\":\n        return slog.LevelWarn\n    case \"error\":\n        return slog.LevelError\n    default:\n        return slog.LevelInfo\n    }\n}\n\n// LogToolCall logs a tool call with standard fields\nfunc LogToolCall(logger *slog.Logger, toolID, query, status string, durationMs int64) {\n    logger.Info(\"tool.call\",\n        \"tool_id\", toolID,\n        \"query\", query,\n        \"status\", status,\n        \"duration_ms\", durationMs,\n    )\n}\n\n// LogChainStart logs chain start\nfunc LogChainStart(logger *slog.Logger, chainID string, steps int, traceID string) {\n    logger.Info(\"chain.start\",\n        \"chain_id\", chainID,\n        \"steps\", steps,\n        \"trace_id\", traceID,\n    )\n}\n\n// LogChainComplete logs chain completion\nfunc LogChainComplete(logger *slog.Logger, chainID, status string, durationMs int64) {\n    logger.Info(\"chain.complete\",\n        \"chain_id\", chainID,\n        \"status\", status,\n        \"duration_ms\", durationMs,\n    )\n}\n\n// LogBackendCall logs a backend call\nfunc LogBackendCall(logger *slog.Logger, backendType, backendName, status string, durationMs int64) {\n    logger.Info(\"backend.call\",\n        \"backend_type\", backendType,\n        \"backend_name\", backendName,\n        \"status\", status,\n        \"duration_ms\", durationMs,\n    )\n}\n\n// LogError logs an error with context\nfunc LogError(logger *slog.Logger, operation string, err error, fields ...any) {\n    args := append([]any{\"operation\", operation, \"error\", err.Error()}, fields...)\n    logger.Error(\"operation.error\", args...)\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolobserve/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolobserve): add structured logging\n\n- NewLogger with JSON and text formats\n- Level filtering (debug, info, warn, error)\n- LogToolCall, LogChainStart, LogChainComplete helpers\n- LogBackendCall for backend operations\n- LogError for error logging with context\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/#task-6-exporter-configurations","title":"Task 6: Exporter Configurations","text":"<p>Files: - Create: <code>toolobserve/exporters/otlp.go</code> - Create: <code>toolobserve/exporters/prometheus.go</code> - Create: <code>toolobserve/exporters/stdout.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// exporters/otlp_test.go\npackage exporters_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/jrraymond/toolobserve/exporters\"\n)\n\nfunc TestOTLPConfig_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        config  exporters.OTLPConfig\n        wantErr bool\n    }{\n        {\n            name: \"valid config\",\n            config: exporters.OTLPConfig{\n                Endpoint: \"localhost:4317\",\n            },\n            wantErr: false,\n        },\n        {\n            name: \"missing endpoint\",\n            config: exporters.OTLPConfig{},\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            err := tt.config.Validate()\n            if tt.wantErr {\n                assert.Error(t, err)\n            } else {\n                assert.NoError(t, err)\n            }\n        })\n    }\n}\n\nfunc TestPrometheusConfig_Endpoint(t *testing.T) {\n    config := exporters.PrometheusConfig{\n        Port: 9090,\n        Path: \"/metrics\",\n    }\n\n    assert.Equal(t, \":9090\", config.Addr())\n    assert.Equal(t, \"/metrics\", config.Path)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./exporters/... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// exporters/otlp.go\npackage exporters\n\nimport (\n    \"context\"\n    \"errors\"\n\n    \"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc\"\n    \"go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc\"\n    sdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n    sdkmetric \"go.opentelemetry.io/otel/sdk/metric\"\n)\n\n// OTLPConfig holds OTLP exporter configuration\ntype OTLPConfig struct {\n    Endpoint    string\n    Insecure    bool\n    Headers     map[string]string\n    Compression string // gzip, none\n}\n\n// Validate validates the OTLP config\nfunc (c OTLPConfig) Validate() error {\n    if c.Endpoint == \"\" {\n        return errors.New(\"OTLP endpoint is required\")\n    }\n    return nil\n}\n\n// NewOTLPTraceExporter creates an OTLP trace exporter\nfunc NewOTLPTraceExporter(ctx context.Context, config OTLPConfig) (sdktrace.SpanExporter, error) {\n    if err := config.Validate(); err != nil {\n        return nil, err\n    }\n\n    opts := []otlptracegrpc.Option{\n        otlptracegrpc.WithEndpoint(config.Endpoint),\n    }\n\n    if config.Insecure {\n        opts = append(opts, otlptracegrpc.WithInsecure())\n    }\n\n    if len(config.Headers) &gt; 0 {\n        opts = append(opts, otlptracegrpc.WithHeaders(config.Headers))\n    }\n\n    return otlptracegrpc.New(ctx, opts...)\n}\n\n// NewOTLPMetricExporter creates an OTLP metric exporter\nfunc NewOTLPMetricExporter(ctx context.Context, config OTLPConfig) (sdkmetric.Exporter, error) {\n    if err := config.Validate(); err != nil {\n        return nil, err\n    }\n\n    opts := []otlpmetricgrpc.Option{\n        otlpmetricgrpc.WithEndpoint(config.Endpoint),\n    }\n\n    if config.Insecure {\n        opts = append(opts, otlpmetricgrpc.WithInsecure())\n    }\n\n    if len(config.Headers) &gt; 0 {\n        opts = append(opts, otlpmetricgrpc.WithHeaders(config.Headers))\n    }\n\n    return otlpmetricgrpc.New(ctx, opts...)\n}\n</code></pre> <pre><code>// exporters/prometheus.go\npackage exporters\n\nimport (\n    \"fmt\"\n    \"net/http\"\n\n    \"go.opentelemetry.io/otel/exporters/prometheus\"\n    \"go.opentelemetry.io/otel/metric\"\n    sdkmetric \"go.opentelemetry.io/otel/sdk/metric\"\n)\n\n// PrometheusConfig holds Prometheus exporter configuration\ntype PrometheusConfig struct {\n    Port int\n    Path string\n}\n\n// Addr returns the address for the Prometheus endpoint\nfunc (c PrometheusConfig) Addr() string {\n    return fmt.Sprintf(\":%d\", c.Port)\n}\n\n// NewPrometheusExporter creates a Prometheus metric exporter\nfunc NewPrometheusExporter(config PrometheusConfig) (metric.MeterProvider, http.Handler, error) {\n    exporter, err := prometheus.New()\n    if err != nil {\n        return nil, nil, err\n    }\n\n    provider := sdkmetric.NewMeterProvider(\n        sdkmetric.WithReader(exporter),\n    )\n\n    return provider, exporter, nil\n}\n</code></pre> <pre><code>// exporters/stdout.go\npackage exporters\n\nimport (\n    \"go.opentelemetry.io/otel/exporters/stdout/stdouttrace\"\n    \"go.opentelemetry.io/otel/exporters/stdout/stdoutmetric\"\n    sdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n    sdkmetric \"go.opentelemetry.io/otel/sdk/metric\"\n)\n\n// StdoutConfig holds stdout exporter configuration\ntype StdoutConfig struct {\n    PrettyPrint bool\n    Timestamps  bool\n}\n\n// NewStdoutTraceExporter creates a stdout trace exporter\nfunc NewStdoutTraceExporter(config StdoutConfig) (sdktrace.SpanExporter, error) {\n    opts := []stdouttrace.Option{}\n\n    if config.PrettyPrint {\n        opts = append(opts, stdouttrace.WithPrettyPrint())\n    }\n\n    return stdouttrace.New(opts...)\n}\n\n// NewStdoutMetricExporter creates a stdout metric exporter\nfunc NewStdoutMetricExporter(config StdoutConfig) (sdkmetric.Exporter, error) {\n    opts := []stdoutmetric.Option{}\n\n    if config.PrettyPrint {\n        opts = append(opts, stdoutmetric.WithPrettyPrint())\n    }\n\n    return stdoutmetric.New(opts...)\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolobserve &amp;&amp; go test ./exporters/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolobserve/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolobserve): add exporter configurations\n\n- OTLPConfig with trace and metric exporter factories\n- PrometheusConfig with HTTP handler\n- StdoutConfig for development\n- Validation and defaults for all configs\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/#verification-checklist","title":"Verification Checklist","text":"<p>Before marking PRD-010 complete:</p> <ul> <li>[ ] All tests pass: <code>go test ./... -v</code></li> <li>[ ] Code coverage &gt; 80%: <code>go test ./... -cover</code></li> <li>[ ] No linting errors: <code>golangci-lint run</code></li> <li>[ ] Documentation complete</li> <li>[ ] Integration verified:</li> <li>[ ] Tracing creates valid spans</li> <li>[ ] Metrics are recorded correctly</li> <li>[ ] Logging outputs structured data</li> <li>[ ] Middleware wraps providers correctly</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-010-toolobserve-library/#definition-of-done","title":"Definition of Done","text":"<ol> <li>Observer type with Tracer, Meter, Logger</li> <li>Tracing with StartToolSpan, StartChainSpan, StartStepSpan</li> <li>Metrics with counters, histograms, and gauges</li> <li>Middleware for automatic observability</li> <li>Structured logging with JSON/text formats</li> <li>Exporters for OTLP, Prometheus, stdout</li> <li>All tests passing with &gt;80% coverage</li> <li>Documentation complete</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-011-toolcache-library/","title":"PRD-011: toolcache Library Implementation","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Create a response caching library with pluggable backends (memory, Redis) supporting TTL, key generation, and cache invalidation for tool execution results.</p> <p>Architecture: Cache middleware wrapping tool providers with configurable key generation, TTL per tool, and layered caching (L1 memory + L2 Redis).</p> <p>Tech Stack: Go, go-redis (optional), hashicorp/golang-lru</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-011-toolcache-library/#overview","title":"Overview","text":"<p>The <code>toolcache</code> library provides response caching for tool execution, reducing latency and backend load for repeated queries with identical inputs.</p> <p>Reference: pluggable-architecture.md - Cache Layer section</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-011-toolcache-library/#directory-structure","title":"Directory Structure","text":"<pre><code>toolcache/\n\u251c\u2500\u2500 cache.go           # Cache interface and types\n\u251c\u2500\u2500 cache_test.go\n\u251c\u2500\u2500 memory.go          # In-memory cache backend\n\u251c\u2500\u2500 memory_test.go\n\u251c\u2500\u2500 redis.go           # Redis cache backend\n\u251c\u2500\u2500 redis_test.go\n\u251c\u2500\u2500 layered.go         # L1 + L2 layered cache\n\u251c\u2500\u2500 layered_test.go\n\u251c\u2500\u2500 key.go             # Key generation strategies\n\u251c\u2500\u2500 key_test.go\n\u251c\u2500\u2500 middleware.go      # Caching middleware\n\u251c\u2500\u2500 middleware_test.go\n\u251c\u2500\u2500 config.go          # Configuration types\n\u251c\u2500\u2500 doc.go\n\u251c\u2500\u2500 go.mod\n\u2514\u2500\u2500 go.sum\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-011-toolcache-library/#task-1-cache-interface-and-types","title":"Task 1: Cache Interface and Types","text":"<p>Files: - Create: <code>toolcache/cache.go</code> - Create: <code>toolcache/cache_test.go</code> - Create: <code>toolcache/go.mod</code></p> <p>Step 1: Write failing tests</p> <pre><code>// cache_test.go\npackage toolcache_test\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolcache\"\n)\n\nfunc TestCacheEntry_IsExpired(t *testing.T) {\n    tests := []struct {\n        name     string\n        entry    toolcache.Entry\n        expected bool\n    }{\n        {\n            name: \"not expired\",\n            entry: toolcache.Entry{\n                ExpiresAt: time.Now().Add(time.Hour),\n            },\n            expected: false,\n        },\n        {\n            name: \"expired\",\n            entry: toolcache.Entry{\n                ExpiresAt: time.Now().Add(-time.Hour),\n            },\n            expected: true,\n        },\n        {\n            name: \"zero expiration (never expires)\",\n            entry: toolcache.Entry{\n                ExpiresAt: time.Time{},\n            },\n            expected: false,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            assert.Equal(t, tt.expected, tt.entry.IsExpired())\n        })\n    }\n}\n\nfunc TestCacheStats(t *testing.T) {\n    stats := &amp;toolcache.Stats{}\n\n    stats.RecordHit()\n    stats.RecordHit()\n    stats.RecordMiss()\n\n    assert.Equal(t, int64(2), stats.Hits)\n    assert.Equal(t, int64(1), stats.Misses)\n    assert.InDelta(t, 0.666, stats.HitRate(), 0.01)\n}\n\nfunc TestCacheConfig_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        config  toolcache.Config\n        wantErr bool\n    }{\n        {\n            name: \"valid config\",\n            config: toolcache.Config{\n                DefaultTTL: time.Minute,\n                MaxSize:    1000,\n            },\n            wantErr: false,\n        },\n        {\n            name: \"negative TTL\",\n            config: toolcache.Config{\n                DefaultTTL: -time.Minute,\n            },\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            err := tt.config.Validate()\n            if tt.wantErr {\n                require.Error(t, err)\n            } else {\n                require.NoError(t, err)\n            }\n        })\n    }\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolcache &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// go.mod\nmodule github.com/jrraymond/toolcache\n\ngo 1.22\n\nrequire (\n    github.com/hashicorp/golang-lru/v2 v2.0.7\n    github.com/redis/go-redis/v9 v9.5.1\n)\n</code></pre> <pre><code>// cache.go\npackage toolcache\n\nimport (\n    \"context\"\n    \"errors\"\n    \"sync/atomic\"\n    \"time\"\n)\n\n// Cache is the interface for cache backends\ntype Cache interface {\n    // Get retrieves a value from cache\n    Get(ctx context.Context, key string) ([]byte, bool, error)\n\n    // Set stores a value in cache with TTL\n    Set(ctx context.Context, key string, value []byte, ttl time.Duration) error\n\n    // Delete removes a value from cache\n    Delete(ctx context.Context, key string) error\n\n    // Clear removes entries matching pattern (empty pattern = all)\n    Clear(ctx context.Context, pattern string) error\n\n    // Stats returns cache statistics\n    Stats() Stats\n\n    // Close closes the cache\n    Close() error\n}\n\n// Entry represents a cached value\ntype Entry struct {\n    Value     []byte\n    CreatedAt time.Time\n    ExpiresAt time.Time\n    ToolID    string\n    InputHash string\n}\n\n// IsExpired checks if the entry is expired\nfunc (e Entry) IsExpired() bool {\n    if e.ExpiresAt.IsZero() {\n        return false // Never expires\n    }\n    return time.Now().After(e.ExpiresAt)\n}\n\n// Stats holds cache statistics\ntype Stats struct {\n    Hits       int64\n    Misses     int64\n    Evictions  int64\n    Size       int64\n    MaxSize    int64\n}\n\n// RecordHit increments hit counter\nfunc (s *Stats) RecordHit() {\n    atomic.AddInt64(&amp;s.Hits, 1)\n}\n\n// RecordMiss increments miss counter\nfunc (s *Stats) RecordMiss() {\n    atomic.AddInt64(&amp;s.Misses, 1)\n}\n\n// RecordEviction increments eviction counter\nfunc (s *Stats) RecordEviction() {\n    atomic.AddInt64(&amp;s.Evictions, 1)\n}\n\n// HitRate returns the cache hit rate\nfunc (s *Stats) HitRate() float64 {\n    total := s.Hits + s.Misses\n    if total == 0 {\n        return 0\n    }\n    return float64(s.Hits) / float64(total)\n}\n\n// Config holds cache configuration\ntype Config struct {\n    // General settings\n    DefaultTTL time.Duration\n    MaxSize    int\n\n    // Per-tool TTL overrides\n    ToolTTLs map[string]time.Duration\n\n    // Memory cache specific\n    Memory MemoryConfig\n\n    // Redis cache specific\n    Redis RedisConfig\n\n    // Layered cache specific\n    Layered LayeredConfig\n}\n\n// MemoryConfig holds in-memory cache settings\ntype MemoryConfig struct {\n    MaxEntries int\n    MaxBytes   int64\n}\n\n// RedisConfig holds Redis cache settings\ntype RedisConfig struct {\n    Addr     string\n    Password string\n    DB       int\n    Prefix   string\n}\n\n// LayeredConfig holds layered cache settings\ntype LayeredConfig struct {\n    L1TTL time.Duration // Short TTL for L1 (memory)\n    L2TTL time.Duration // Longer TTL for L2 (Redis)\n}\n\n// Validate validates the configuration\nfunc (c Config) Validate() error {\n    if c.DefaultTTL &lt; 0 {\n        return errors.New(\"default TTL cannot be negative\")\n    }\n    return nil\n}\n\n// DefaultConfig returns a default configuration\nfunc DefaultConfig() Config {\n    return Config{\n        DefaultTTL: 5 * time.Minute,\n        MaxSize:    10000,\n        Memory: MemoryConfig{\n            MaxEntries: 10000,\n        },\n        Layered: LayeredConfig{\n            L1TTL: time.Minute,\n            L2TTL: 10 * time.Minute,\n        },\n    }\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolcache &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolcache/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolcache): add Cache interface and types\n\n- Cache interface with Get, Set, Delete, Clear, Stats\n- Entry type with expiration checking\n- Stats with atomic counters and hit rate\n- Config with per-tool TTL overrides\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-011-toolcache-library/#task-2-in-memory-cache-backend","title":"Task 2: In-Memory Cache Backend","text":"<p>Files: - Create: <code>toolcache/memory.go</code> - Create: <code>toolcache/memory_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// memory_test.go\npackage toolcache_test\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolcache\"\n)\n\nfunc TestMemoryCache_SetGet(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{\n        MaxEntries: 100,\n    })\n    defer cache.Close()\n\n    ctx := context.Background()\n    key := \"test-key\"\n    value := []byte(`{\"result\": \"test\"}`)\n\n    err := cache.Set(ctx, key, value, time.Minute)\n    require.NoError(t, err)\n\n    got, ok, err := cache.Get(ctx, key)\n    require.NoError(t, err)\n    assert.True(t, ok)\n    assert.Equal(t, value, got)\n}\n\nfunc TestMemoryCache_GetMiss(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{\n        MaxEntries: 100,\n    })\n    defer cache.Close()\n\n    _, ok, err := cache.Get(context.Background(), \"nonexistent\")\n    require.NoError(t, err)\n    assert.False(t, ok)\n}\n\nfunc TestMemoryCache_Expiration(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{\n        MaxEntries: 100,\n    })\n    defer cache.Close()\n\n    ctx := context.Background()\n    key := \"expiring-key\"\n    value := []byte(`test`)\n\n    // Set with very short TTL\n    err := cache.Set(ctx, key, value, 10*time.Millisecond)\n    require.NoError(t, err)\n\n    // Should exist immediately\n    _, ok, _ := cache.Get(ctx, key)\n    assert.True(t, ok)\n\n    // Wait for expiration\n    time.Sleep(20 * time.Millisecond)\n\n    // Should be expired\n    _, ok, _ = cache.Get(ctx, key)\n    assert.False(t, ok)\n}\n\nfunc TestMemoryCache_Delete(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{\n        MaxEntries: 100,\n    })\n    defer cache.Close()\n\n    ctx := context.Background()\n    key := \"delete-key\"\n\n    cache.Set(ctx, key, []byte(`test`), time.Minute)\n    cache.Delete(ctx, key)\n\n    _, ok, _ := cache.Get(ctx, key)\n    assert.False(t, ok)\n}\n\nfunc TestMemoryCache_Clear(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{\n        MaxEntries: 100,\n    })\n    defer cache.Close()\n\n    ctx := context.Background()\n\n    // Add multiple entries\n    cache.Set(ctx, \"key1\", []byte(`1`), time.Minute)\n    cache.Set(ctx, \"key2\", []byte(`2`), time.Minute)\n    cache.Set(ctx, \"key3\", []byte(`3`), time.Minute)\n\n    // Clear all\n    err := cache.Clear(ctx, \"\")\n    require.NoError(t, err)\n\n    // All should be gone\n    _, ok, _ := cache.Get(ctx, \"key1\")\n    assert.False(t, ok)\n}\n\nfunc TestMemoryCache_Eviction(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{\n        MaxEntries: 2,\n    })\n    defer cache.Close()\n\n    ctx := context.Background()\n\n    // Add more entries than max\n    cache.Set(ctx, \"key1\", []byte(`1`), time.Minute)\n    cache.Set(ctx, \"key2\", []byte(`2`), time.Minute)\n    cache.Set(ctx, \"key3\", []byte(`3`), time.Minute)\n\n    // At least one should have been evicted\n    stats := cache.Stats()\n    assert.GreaterOrEqual(t, stats.Evictions, int64(1))\n}\n\nfunc TestMemoryCache_Stats(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{\n        MaxEntries: 100,\n    })\n    defer cache.Close()\n\n    ctx := context.Background()\n\n    cache.Set(ctx, \"key\", []byte(`test`), time.Minute)\n    cache.Get(ctx, \"key\")        // hit\n    cache.Get(ctx, \"nonexistent\") // miss\n\n    stats := cache.Stats()\n    assert.Equal(t, int64(1), stats.Hits)\n    assert.Equal(t, int64(1), stats.Misses)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolcache &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// memory.go\npackage toolcache\n\nimport (\n    \"context\"\n    \"sync\"\n    \"time\"\n\n    lru \"github.com/hashicorp/golang-lru/v2\"\n)\n\n// memoryEntry stores value with metadata\ntype memoryEntry struct {\n    value     []byte\n    expiresAt time.Time\n}\n\n// MemoryCache is an in-memory LRU cache\ntype MemoryCache struct {\n    cache *lru.Cache[string, *memoryEntry]\n    stats Stats\n    mu    sync.RWMutex\n}\n\n// NewMemoryCache creates a new in-memory cache\nfunc NewMemoryCache(config MemoryConfig) *MemoryCache {\n    size := config.MaxEntries\n    if size &lt;= 0 {\n        size = 10000\n    }\n\n    mc := &amp;MemoryCache{}\n\n    cache, _ := lru.NewWithEvict[string, *memoryEntry](size, func(key string, value *memoryEntry) {\n        mc.stats.RecordEviction()\n    })\n\n    mc.cache = cache\n    return mc\n}\n\n// Get retrieves a value from cache\nfunc (c *MemoryCache) Get(ctx context.Context, key string) ([]byte, bool, error) {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n\n    entry, ok := c.cache.Get(key)\n    if !ok {\n        c.stats.RecordMiss()\n        return nil, false, nil\n    }\n\n    // Check expiration\n    if !entry.expiresAt.IsZero() &amp;&amp; time.Now().After(entry.expiresAt) {\n        c.cache.Remove(key)\n        c.stats.RecordMiss()\n        return nil, false, nil\n    }\n\n    c.stats.RecordHit()\n    return entry.value, true, nil\n}\n\n// Set stores a value in cache\nfunc (c *MemoryCache) Set(ctx context.Context, key string, value []byte, ttl time.Duration) error {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n\n    entry := &amp;memoryEntry{\n        value: value,\n    }\n\n    if ttl &gt; 0 {\n        entry.expiresAt = time.Now().Add(ttl)\n    }\n\n    c.cache.Add(key, entry)\n    return nil\n}\n\n// Delete removes a value from cache\nfunc (c *MemoryCache) Delete(ctx context.Context, key string) error {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n\n    c.cache.Remove(key)\n    return nil\n}\n\n// Clear removes all entries (pattern ignored for memory cache)\nfunc (c *MemoryCache) Clear(ctx context.Context, pattern string) error {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n\n    c.cache.Purge()\n    return nil\n}\n\n// Stats returns cache statistics\nfunc (c *MemoryCache) Stats() Stats {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n\n    stats := c.stats\n    stats.Size = int64(c.cache.Len())\n    return stats\n}\n\n// Close closes the cache\nfunc (c *MemoryCache) Close() error {\n    c.cache.Purge()\n    return nil\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolcache &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolcache/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolcache): add in-memory LRU cache backend\n\n- LRU eviction with configurable size\n- TTL-based expiration checking\n- Thread-safe operations\n- Statistics tracking (hits, misses, evictions)\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-011-toolcache-library/#task-3-key-generation-strategies","title":"Task 3: Key Generation Strategies","text":"<p>Files: - Create: <code>toolcache/key.go</code> - Create: <code>toolcache/key_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// key_test.go\npackage toolcache_test\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/jrraymond/toolcache\"\n)\n\nfunc TestKeyGenerator_Default(t *testing.T) {\n    gen := toolcache.DefaultKeyGenerator()\n\n    key1 := gen.Generate(\"mcp:search\", map[string]any{\"query\": \"test\"})\n    key2 := gen.Generate(\"mcp:search\", map[string]any{\"query\": \"test\"})\n    key3 := gen.Generate(\"mcp:search\", map[string]any{\"query\": \"different\"})\n\n    // Same inputs should produce same key\n    assert.Equal(t, key1, key2)\n\n    // Different inputs should produce different key\n    assert.NotEqual(t, key1, key3)\n}\n\nfunc TestKeyGenerator_WithPrefix(t *testing.T) {\n    gen := toolcache.NewKeyGenerator(toolcache.KeyConfig{\n        Prefix: \"cache:\",\n    })\n\n    key := gen.Generate(\"mcp:search\", map[string]any{\"query\": \"test\"})\n    assert.HasPrefix(t, key, \"cache:\")\n}\n\nfunc TestKeyGenerator_WithNamespace(t *testing.T) {\n    gen := toolcache.NewKeyGenerator(toolcache.KeyConfig{\n        Prefix:           \"cache:\",\n        IncludeNamespace: true,\n    })\n\n    key := gen.Generate(\"mcp:search\", map[string]any{\"query\": \"test\"})\n    assert.Contains(t, key, \"mcp\")\n}\n\nfunc TestKeyGenerator_IgnoredArgs(t *testing.T) {\n    gen := toolcache.NewKeyGenerator(toolcache.KeyConfig{\n        IgnoredArgs: []string{\"timestamp\", \"requestId\"},\n    })\n\n    key1 := gen.Generate(\"mcp:search\", map[string]any{\n        \"query\":     \"test\",\n        \"timestamp\": \"2024-01-01\",\n    })\n    key2 := gen.Generate(\"mcp:search\", map[string]any{\n        \"query\":     \"test\",\n        \"timestamp\": \"2024-12-31\", // Different timestamp\n    })\n\n    // Should be same because timestamp is ignored\n    assert.Equal(t, key1, key2)\n}\n\nfunc TestKeyGenerator_SortedArgs(t *testing.T) {\n    gen := toolcache.DefaultKeyGenerator()\n\n    key1 := gen.Generate(\"tool\", map[string]any{\"a\": 1, \"b\": 2, \"c\": 3})\n    key2 := gen.Generate(\"tool\", map[string]any{\"c\": 3, \"a\": 1, \"b\": 2})\n\n    // Order shouldn't matter\n    assert.Equal(t, key1, key2)\n}\n\nfunc TestKeyGenerator_NestedArgs(t *testing.T) {\n    gen := toolcache.DefaultKeyGenerator()\n\n    key1 := gen.Generate(\"tool\", map[string]any{\n        \"nested\": map[string]any{\n            \"value\": \"test\",\n        },\n    })\n    key2 := gen.Generate(\"tool\", map[string]any{\n        \"nested\": map[string]any{\n            \"value\": \"different\",\n        },\n    })\n\n    assert.NotEqual(t, key1, key2)\n}\n\nfunc TestKeyGenerator_EmptyArgs(t *testing.T) {\n    gen := toolcache.DefaultKeyGenerator()\n\n    key := gen.Generate(\"mcp:search\", nil)\n    assert.NotEmpty(t, key)\n\n    key2 := gen.Generate(\"mcp:search\", map[string]any{})\n    assert.Equal(t, key, key2)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolcache &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// key.go\npackage toolcache\n\nimport (\n    \"crypto/sha256\"\n    \"encoding/hex\"\n    \"encoding/json\"\n    \"sort\"\n    \"strings\"\n)\n\n// KeyGenerator generates cache keys\ntype KeyGenerator interface {\n    Generate(toolID string, args map[string]any) string\n}\n\n// KeyConfig holds key generation configuration\ntype KeyConfig struct {\n    Prefix           string\n    IncludeNamespace bool\n    IgnoredArgs      []string\n    HashAlgorithm    string // sha256, md5\n}\n\n// DefaultKeyGenerator returns a default key generator\nfunc DefaultKeyGenerator() KeyGenerator {\n    return NewKeyGenerator(KeyConfig{})\n}\n\n// defaultKeyGenerator implements KeyGenerator\ntype defaultKeyGenerator struct {\n    config KeyConfig\n}\n\n// NewKeyGenerator creates a new key generator\nfunc NewKeyGenerator(config KeyConfig) KeyGenerator {\n    return &amp;defaultKeyGenerator{config: config}\n}\n\n// Generate generates a cache key\nfunc (g *defaultKeyGenerator) Generate(toolID string, args map[string]any) string {\n    var sb strings.Builder\n\n    // Add prefix\n    if g.config.Prefix != \"\" {\n        sb.WriteString(g.config.Prefix)\n    }\n\n    // Add namespace if configured\n    if g.config.IncludeNamespace {\n        if idx := strings.Index(toolID, \":\"); idx &gt; 0 {\n            sb.WriteString(toolID[:idx])\n            sb.WriteString(\":\")\n        }\n    }\n\n    // Add tool ID\n    sb.WriteString(toolID)\n    sb.WriteString(\":\")\n\n    // Hash the arguments\n    argsHash := g.hashArgs(args)\n    sb.WriteString(argsHash)\n\n    return sb.String()\n}\n\n// hashArgs creates a deterministic hash of arguments\nfunc (g *defaultKeyGenerator) hashArgs(args map[string]any) string {\n    if args == nil || len(args) == 0 {\n        return \"empty\"\n    }\n\n    // Filter ignored args\n    filtered := make(map[string]any)\n    for k, v := range args {\n        if !g.isIgnored(k) {\n            filtered[k] = v\n        }\n    }\n\n    if len(filtered) == 0 {\n        return \"empty\"\n    }\n\n    // Sort keys for deterministic output\n    keys := make([]string, 0, len(filtered))\n    for k := range filtered {\n        keys = append(keys, k)\n    }\n    sort.Strings(keys)\n\n    // Build sorted map for JSON encoding\n    sorted := make([]any, 0, len(keys)*2)\n    for _, k := range keys {\n        sorted = append(sorted, k, filtered[k])\n    }\n\n    // JSON encode\n    data, err := json.Marshal(sorted)\n    if err != nil {\n        // Fallback to simple concatenation\n        var sb strings.Builder\n        for _, k := range keys {\n            sb.WriteString(k)\n            sb.WriteString(\"=\")\n            sb.WriteString(stringify(filtered[k]))\n            sb.WriteString(\";\")\n        }\n        data = []byte(sb.String())\n    }\n\n    // Hash\n    hash := sha256.Sum256(data)\n    return hex.EncodeToString(hash[:8]) // Use first 8 bytes\n}\n\n// isIgnored checks if an argument should be ignored\nfunc (g *defaultKeyGenerator) isIgnored(key string) bool {\n    for _, ignored := range g.config.IgnoredArgs {\n        if key == ignored {\n            return true\n        }\n    }\n    return false\n}\n\n// stringify converts a value to string\nfunc stringify(v any) string {\n    switch val := v.(type) {\n    case string:\n        return val\n    case nil:\n        return \"null\"\n    default:\n        data, _ := json.Marshal(val)\n        return string(data)\n    }\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolcache &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolcache/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolcache): add key generation strategies\n\n- DefaultKeyGenerator with SHA256 hashing\n- Configurable prefix and namespace inclusion\n- IgnoredArgs for excluding non-deterministic fields\n- Sorted arguments for deterministic keys\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-011-toolcache-library/#task-4-caching-middleware","title":"Task 4: Caching Middleware","text":"<p>Files: - Create: <code>toolcache/middleware.go</code> - Create: <code>toolcache/middleware_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// middleware_test.go\npackage toolcache_test\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolcache\"\n)\n\ntype MockProvider struct {\n    name       string\n    callCount  int\n    handler    func(ctx context.Context, input map[string]any) (any, error)\n}\n\nfunc (m *MockProvider) Name() string { return m.name }\nfunc (m *MockProvider) Handle(ctx context.Context, input map[string]any) (any, error) {\n    m.callCount++\n    return m.handler(ctx, input)\n}\n\nfunc TestCacheMiddleware_CachesResult(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{MaxEntries: 100})\n    defer cache.Close()\n\n    provider := &amp;MockProvider{\n        name: \"mcp:search\",\n        handler: func(ctx context.Context, input map[string]any) (any, error) {\n            return map[string]any{\"results\": []string{\"a\", \"b\", \"c\"}}, nil\n        },\n    }\n\n    middleware := toolcache.CacheMiddleware(cache, toolcache.CacheMiddlewareConfig{\n        DefaultTTL: time.Minute,\n    })\n\n    wrapped := middleware(provider)\n\n    ctx := context.Background()\n    input := map[string]any{\"query\": \"test\"}\n\n    // First call - should execute provider\n    result1, err := wrapped.Handle(ctx, input)\n    require.NoError(t, err)\n    assert.Equal(t, 1, provider.callCount)\n\n    // Second call - should use cache\n    result2, err := wrapped.Handle(ctx, input)\n    require.NoError(t, err)\n    assert.Equal(t, 1, provider.callCount) // Still 1\n    assert.Equal(t, result1, result2)\n}\n\nfunc TestCacheMiddleware_DifferentInputs(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{MaxEntries: 100})\n    defer cache.Close()\n\n    provider := &amp;MockProvider{\n        name: \"mcp:search\",\n        handler: func(ctx context.Context, input map[string]any) (any, error) {\n            return map[string]any{\"query\": input[\"query\"]}, nil\n        },\n    }\n\n    wrapped := toolcache.CacheMiddleware(cache, toolcache.CacheMiddlewareConfig{\n        DefaultTTL: time.Minute,\n    })(provider)\n\n    ctx := context.Background()\n\n    wrapped.Handle(ctx, map[string]any{\"query\": \"test1\"})\n    wrapped.Handle(ctx, map[string]any{\"query\": \"test2\"})\n\n    assert.Equal(t, 2, provider.callCount)\n}\n\nfunc TestCacheMiddleware_SkipCache(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{MaxEntries: 100})\n    defer cache.Close()\n\n    provider := &amp;MockProvider{\n        name: \"mcp:execute\",\n        handler: func(ctx context.Context, input map[string]any) (any, error) {\n            return map[string]any{\"executed\": true}, nil\n        },\n    }\n\n    wrapped := toolcache.CacheMiddleware(cache, toolcache.CacheMiddlewareConfig{\n        DefaultTTL:    time.Minute,\n        SkippedTools: []string{\"mcp:execute\"},\n    })(provider)\n\n    ctx := context.Background()\n    input := map[string]any{}\n\n    wrapped.Handle(ctx, input)\n    wrapped.Handle(ctx, input)\n\n    // Should not cache - both calls execute\n    assert.Equal(t, 2, provider.callCount)\n}\n\nfunc TestCacheMiddleware_PerToolTTL(t *testing.T) {\n    cache := toolcache.NewMemoryCache(toolcache.MemoryConfig{MaxEntries: 100})\n    defer cache.Close()\n\n    provider := &amp;MockProvider{\n        name: \"mcp:search\",\n        handler: func(ctx context.Context, input map[string]any) (any, error) {\n            return \"result\", nil\n        },\n    }\n\n    wrapped := toolcache.CacheMiddleware(cache, toolcache.CacheMiddlewareConfig{\n        DefaultTTL: time.Hour,\n        ToolTTLs: map[string]time.Duration{\n            \"mcp:search\": 10 * time.Millisecond,\n        },\n    })(provider)\n\n    ctx := context.Background()\n    input := map[string]any{\"query\": \"test\"}\n\n    wrapped.Handle(ctx, input)\n    time.Sleep(20 * time.Millisecond)\n    wrapped.Handle(ctx, input)\n\n    // Should have expired and called twice\n    assert.Equal(t, 2, provider.callCount)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolcache &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// middleware.go\npackage toolcache\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"time\"\n)\n\n// ToolProvider is the interface for tool providers\ntype ToolProvider interface {\n    Name() string\n    Handle(ctx context.Context, input map[string]any) (any, error)\n}\n\n// Middleware wraps a ToolProvider\ntype Middleware func(ToolProvider) ToolProvider\n\n// CacheMiddlewareConfig holds middleware configuration\ntype CacheMiddlewareConfig struct {\n    DefaultTTL   time.Duration\n    ToolTTLs     map[string]time.Duration\n    SkippedTools []string\n    KeyGenerator KeyGenerator\n}\n\n// cachedProvider wraps a provider with caching\ntype cachedProvider struct {\n    cache     Cache\n    config    CacheMiddlewareConfig\n    keyGen    KeyGenerator\n    next      ToolProvider\n}\n\n// CacheMiddleware creates caching middleware\nfunc CacheMiddleware(cache Cache, config CacheMiddlewareConfig) Middleware {\n    keyGen := config.KeyGenerator\n    if keyGen == nil {\n        keyGen = DefaultKeyGenerator()\n    }\n\n    return func(next ToolProvider) ToolProvider {\n        return &amp;cachedProvider{\n            cache:  cache,\n            config: config,\n            keyGen: keyGen,\n            next:   next,\n        }\n    }\n}\n\nfunc (p *cachedProvider) Name() string {\n    return p.next.Name()\n}\n\nfunc (p *cachedProvider) Handle(ctx context.Context, input map[string]any) (any, error) {\n    toolID := p.next.Name()\n\n    // Check if tool should skip cache\n    if p.shouldSkip(toolID) {\n        return p.next.Handle(ctx, input)\n    }\n\n    // Generate cache key\n    key := p.keyGen.Generate(toolID, input)\n\n    // Try to get from cache\n    data, ok, err := p.cache.Get(ctx, key)\n    if err == nil &amp;&amp; ok {\n        var result any\n        if json.Unmarshal(data, &amp;result) == nil {\n            return result, nil\n        }\n    }\n\n    // Execute provider\n    result, err := p.next.Handle(ctx, input)\n    if err != nil {\n        return nil, err\n    }\n\n    // Cache result\n    ttl := p.getTTL(toolID)\n    if ttl &gt; 0 {\n        if data, jsonErr := json.Marshal(result); jsonErr == nil {\n            p.cache.Set(ctx, key, data, ttl)\n        }\n    }\n\n    return result, nil\n}\n\n// shouldSkip checks if tool should skip caching\nfunc (p *cachedProvider) shouldSkip(toolID string) bool {\n    for _, skipped := range p.config.SkippedTools {\n        if toolID == skipped {\n            return true\n        }\n    }\n    return false\n}\n\n// getTTL gets the TTL for a tool\nfunc (p *cachedProvider) getTTL(toolID string) time.Duration {\n    if ttl, ok := p.config.ToolTTLs[toolID]; ok {\n        return ttl\n    }\n    return p.config.DefaultTTL\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolcache &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolcache/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolcache): add caching middleware\n\n- CacheMiddleware wraps ToolProvider with caching\n- Per-tool TTL configuration\n- Skipped tools list for non-cacheable operations\n- Configurable key generator\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-011-toolcache-library/#verification-checklist","title":"Verification Checklist","text":"<p>Before marking PRD-011 complete:</p> <ul> <li>[ ] All tests pass: <code>go test ./... -v</code></li> <li>[ ] Code coverage &gt; 80%: <code>go test ./... -cover</code></li> <li>[ ] No linting errors: <code>golangci-lint run</code></li> <li>[ ] Documentation complete</li> <li>[ ] Integration verified:</li> <li>[ ] Memory cache works correctly</li> <li>[ ] Key generation is deterministic</li> <li>[ ] Middleware caches appropriately</li> <li>[ ] TTL expiration works</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-011-toolcache-library/#definition-of-done","title":"Definition of Done","text":"<ol> <li>Cache interface with Get, Set, Delete, Clear, Stats</li> <li>MemoryCache with LRU eviction and TTL</li> <li>KeyGenerator with deterministic hashing</li> <li>CacheMiddleware for automatic caching</li> <li>Configuration with per-tool TTLs</li> <li>All tests passing with &gt;80% coverage</li> <li>Documentation complete</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-012-multi-tenancy-core/","title":"PRD-012: Multi-Tenancy Core Implementation","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement multi-tenancy support with pluggable tenant resolution, tenant-aware middleware, and tenant-scoped registries.</p> <p>Architecture: Tenant context injection via middleware, with pluggable resolvers (JWT, API Key, Header) and configurable isolation strategies (shared, namespace, process).</p> <p>Tech Stack: Go, JWT validation (golang-jwt), Redis (tenant storage option)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-012-multi-tenancy-core/#overview","title":"Overview","text":"<p>Multi-tenancy enables a single metatools-mcp deployment to serve multiple organizations with isolated tool access, rate limits, and audit trails.</p> <p>Reference: multi-tenancy.md</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-012-multi-tenancy-core/#directory-structure","title":"Directory Structure","text":"<pre><code>internal/tenancy/\n\u251c\u2500\u2500 tenant.go           # Tenant and TenantContext types\n\u251c\u2500\u2500 tenant_test.go\n\u251c\u2500\u2500 resolver.go         # TenantResolver interface\n\u251c\u2500\u2500 resolver_test.go\n\u251c\u2500\u2500 resolvers/\n\u2502   \u251c\u2500\u2500 jwt.go          # JWT-based resolver\n\u2502   \u251c\u2500\u2500 jwt_test.go\n\u2502   \u251c\u2500\u2500 apikey.go       # API key resolver\n\u2502   \u251c\u2500\u2500 apikey_test.go\n\u2502   \u251c\u2500\u2500 header.go       # Header-based resolver\n\u2502   \u251c\u2500\u2500 composite.go    # Composite resolver\n\u2502   \u2514\u2500\u2500 composite_test.go\n\u251c\u2500\u2500 middleware.go       # Tenant middleware\n\u251c\u2500\u2500 middleware_test.go\n\u251c\u2500\u2500 store.go            # TenantStore interface\n\u251c\u2500\u2500 store_test.go\n\u251c\u2500\u2500 stores/\n\u2502   \u251c\u2500\u2500 memory.go       # In-memory store\n\u2502   \u251c\u2500\u2500 memory_test.go\n\u2502   \u251c\u2500\u2500 config.go       # Config-file store\n\u2502   \u2514\u2500\u2500 postgres.go     # PostgreSQL store\n\u251c\u2500\u2500 config.go           # Configuration types\n\u2514\u2500\u2500 doc.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-012-multi-tenancy-core/#task-1-tenant-and-tenantcontext-types","title":"Task 1: Tenant and TenantContext Types","text":"<p>Files: - Create: <code>internal/tenancy/tenant.go</code> - Create: <code>internal/tenancy/tenant_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// tenant_test.go\npackage tenancy_test\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/metatools-mcp/internal/tenancy\"\n)\n\nfunc TestTenant_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        tenant  tenancy.Tenant\n        wantErr bool\n    }{\n        {\n            name: \"valid tenant\",\n            tenant: tenancy.Tenant{\n                ID:   \"acme-corp\",\n                Name: \"Acme Corporation\",\n                Tier: tenancy.TierPro,\n            },\n            wantErr: false,\n        },\n        {\n            name: \"missing ID\",\n            tenant: tenancy.Tenant{\n                Name: \"Acme Corporation\",\n            },\n            wantErr: true,\n        },\n        {\n            name: \"invalid tier\",\n            tenant: tenancy.Tenant{\n                ID:   \"test\",\n                Tier: \"invalid\",\n            },\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            err := tt.tenant.Validate()\n            if tt.wantErr {\n                require.Error(t, err)\n            } else {\n                require.NoError(t, err)\n            }\n        })\n    }\n}\n\nfunc TestTenantContext_FromContext(t *testing.T) {\n    tenant := &amp;tenancy.Tenant{\n        ID:   \"test-tenant\",\n        Name: \"Test\",\n        Tier: tenancy.TierFree,\n    }\n    config := &amp;tenancy.TenantConfig{\n        AllowedTools: []string{\"search\", \"describe\"},\n    }\n\n    tc := &amp;tenancy.TenantContext{\n        Tenant: tenant,\n        Config: config,\n    }\n\n    ctx := tenancy.WithTenantContext(context.Background(), tc)\n\n    // Retrieve from context\n    retrieved := tenancy.TenantFromContext(ctx)\n    require.NotNil(t, retrieved)\n    assert.Equal(t, \"test-tenant\", retrieved.Tenant.ID)\n}\n\nfunc TestTenantContext_FromContextMissing(t *testing.T) {\n    ctx := context.Background()\n\n    retrieved := tenancy.TenantFromContext(ctx)\n    assert.Nil(t, retrieved)\n}\n\nfunc TestTenantID_FromContext(t *testing.T) {\n    tc := &amp;tenancy.TenantContext{\n        Tenant: &amp;tenancy.Tenant{ID: \"my-tenant\"},\n    }\n    ctx := tenancy.WithTenantContext(context.Background(), tc)\n\n    id := tenancy.TenantIDFromContext(ctx)\n    assert.Equal(t, \"my-tenant\", id)\n}\n\nfunc TestTenantConfig_IsToolAllowed(t *testing.T) {\n    tests := []struct {\n        name     string\n        config   tenancy.TenantConfig\n        toolID   string\n        expected bool\n    }{\n        {\n            name:     \"empty config allows all\",\n            config:   tenancy.TenantConfig{},\n            toolID:   \"any-tool\",\n            expected: true,\n        },\n        {\n            name: \"allowed list - tool present\",\n            config: tenancy.TenantConfig{\n                AllowedTools: []string{\"search\", \"describe\"},\n            },\n            toolID:   \"search\",\n            expected: true,\n        },\n        {\n            name: \"allowed list - tool absent\",\n            config: tenancy.TenantConfig{\n                AllowedTools: []string{\"search\", \"describe\"},\n            },\n            toolID:   \"execute\",\n            expected: false,\n        },\n        {\n            name: \"denied list takes precedence\",\n            config: tenancy.TenantConfig{\n                AllowedTools: []string{\"execute\"},\n                DeniedTools:  []string{\"execute\"},\n            },\n            toolID:   \"execute\",\n            expected: false,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            assert.Equal(t, tt.expected, tt.config.IsToolAllowed(tt.toolID))\n        })\n    }\n}\n\nfunc TestTenantTier_Constants(t *testing.T) {\n    assert.Equal(t, tenancy.TenantTier(\"free\"), tenancy.TierFree)\n    assert.Equal(t, tenancy.TenantTier(\"pro\"), tenancy.TierPro)\n    assert.Equal(t, tenancy.TenantTier(\"enterprise\"), tenancy.TierEnterprise)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>go test ./internal/tenancy/... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// tenant.go\npackage tenancy\n\nimport (\n    \"context\"\n    \"errors\"\n    \"slices\"\n    \"time\"\n)\n\ntype contextKey string\n\nconst tenantContextKey contextKey = \"tenant\"\n\n// TenantTier defines service levels\ntype TenantTier string\n\nconst (\n    TierFree       TenantTier = \"free\"\n    TierPro        TenantTier = \"pro\"\n    TierEnterprise TenantTier = \"enterprise\"\n)\n\n// ValidTiers contains all valid tier values\nvar ValidTiers = []TenantTier{TierFree, TierPro, TierEnterprise}\n\n// Tenant represents a tenant in the system\ntype Tenant struct {\n    ID        string            `json:\"id\"`\n    Name      string            `json:\"name\"`\n    Tier      TenantTier        `json:\"tier\"`\n    Metadata  map[string]any    `json:\"metadata,omitempty\"`\n    CreatedAt time.Time         `json:\"created_at\"`\n    UpdatedAt time.Time         `json:\"updated_at\"`\n}\n\n// Validate validates the tenant\nfunc (t *Tenant) Validate() error {\n    if t.ID == \"\" {\n        return errors.New(\"tenant ID is required\")\n    }\n    if t.Tier != \"\" &amp;&amp; !slices.Contains(ValidTiers, t.Tier) {\n        return errors.New(\"invalid tenant tier\")\n    }\n    return nil\n}\n\n// TenantContext holds runtime tenant information\ntype TenantContext struct {\n    Tenant      *Tenant\n    Permissions []string\n    Config      *TenantConfig\n    Quotas      *TenantQuotas\n}\n\n// TenantConfig holds per-tenant configuration overrides\ntype TenantConfig struct {\n    // Tool access control\n    AllowedTools    []string `json:\"allowed_tools,omitempty\"`\n    DeniedTools     []string `json:\"denied_tools,omitempty\"`\n    AllowedBackends []string `json:\"allowed_backends,omitempty\"`\n    DeniedBackends  []string `json:\"denied_backends,omitempty\"`\n\n    // Resource limits\n    RateLimits *RateLimitConfig `json:\"rate_limits,omitempty\"`\n    Quotas     *QuotaConfig     `json:\"quotas,omitempty\"`\n\n    // Feature flags\n    Features map[string]bool `json:\"features,omitempty\"`\n\n    // Execution limits\n    MaxTimeout    time.Duration `json:\"max_timeout,omitempty\"`\n    MaxChainSteps int           `json:\"max_chain_steps,omitempty\"`\n    MaxToolCalls  int           `json:\"max_tool_calls,omitempty\"`\n\n    // Custom middleware config\n    MiddlewareConfig map[string]any `json:\"middleware_config,omitempty\"`\n}\n\n// IsToolAllowed checks if a tool is allowed for this tenant\nfunc (c *TenantConfig) IsToolAllowed(toolID string) bool {\n    // Denied list takes precedence\n    if c.DeniedTools != nil &amp;&amp; slices.Contains(c.DeniedTools, toolID) {\n        return false\n    }\n\n    // If allowed list is specified, tool must be in it\n    if len(c.AllowedTools) &gt; 0 {\n        return slices.Contains(c.AllowedTools, toolID)\n    }\n\n    // No restrictions\n    return true\n}\n\n// IsBackendAllowed checks if a backend is allowed for this tenant\nfunc (c *TenantConfig) IsBackendAllowed(backendName string) bool {\n    if c.DeniedBackends != nil &amp;&amp; slices.Contains(c.DeniedBackends, backendName) {\n        return false\n    }\n    if len(c.AllowedBackends) &gt; 0 {\n        return slices.Contains(c.AllowedBackends, backendName)\n    }\n    return true\n}\n\n// RateLimitConfig defines rate limits\ntype RateLimitConfig struct {\n    RequestsPerMinute int `json:\"requests_per_minute\"`\n    Burst             int `json:\"burst\"`\n}\n\n// QuotaConfig defines usage quotas\ntype QuotaConfig struct {\n    DailyRequests    int64 `json:\"daily_requests\"`\n    DailyToolCalls   int64 `json:\"daily_tool_calls\"`\n    MonthlyRequests  int64 `json:\"monthly_requests\"`\n    MonthlyToolCalls int64 `json:\"monthly_tool_calls\"`\n}\n\n// TenantQuotas holds current quota state\ntype TenantQuotas struct {\n    DailyRequestsUsed    int64\n    DailyToolCallsUsed   int64\n    MonthlyRequestsUsed  int64\n    MonthlyToolCallsUsed int64\n    ResetAt              time.Time\n}\n\n// WithTenantContext adds tenant context to the context\nfunc WithTenantContext(ctx context.Context, tc *TenantContext) context.Context {\n    return context.WithValue(ctx, tenantContextKey, tc)\n}\n\n// TenantFromContext retrieves tenant context from context\nfunc TenantFromContext(ctx context.Context) *TenantContext {\n    tc, _ := ctx.Value(tenantContextKey).(*TenantContext)\n    return tc\n}\n\n// TenantIDFromContext retrieves tenant ID from context\nfunc TenantIDFromContext(ctx context.Context) string {\n    tc := TenantFromContext(ctx)\n    if tc == nil || tc.Tenant == nil {\n        return \"\"\n    }\n    return tc.Tenant.ID\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>go test ./internal/tenancy/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/tenancy/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(tenancy): add Tenant and TenantContext types\n\n- Tenant with ID, Name, Tier, Metadata\n- TenantContext for runtime tenant info\n- TenantConfig with tool/backend access control\n- RateLimitConfig and QuotaConfig\n- Context helpers for tenant propagation\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-012-multi-tenancy-core/#task-2-tenantresolver-interface-and-jwt-resolver","title":"Task 2: TenantResolver Interface and JWT Resolver","text":"<p>Files: - Create: <code>internal/tenancy/resolver.go</code> - Create: <code>internal/tenancy/resolvers/jwt.go</code> - Create: <code>internal/tenancy/resolvers/jwt_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// resolvers/jwt_test.go\npackage resolvers_test\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/golang-jwt/jwt/v5\"\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/metatools-mcp/internal/tenancy\"\n    \"github.com/jrraymond/metatools-mcp/internal/tenancy/resolvers\"\n)\n\nfunc TestJWTResolver_Resolve(t *testing.T) {\n    secret := []byte(\"test-secret\")\n\n    store := &amp;MockTenantStore{\n        tenants: map[string]*tenancy.Tenant{\n            \"acme-corp\": {\n                ID:   \"acme-corp\",\n                Name: \"Acme Corporation\",\n                Tier: tenancy.TierPro,\n            },\n        },\n        configs: map[string]*tenancy.TenantConfig{\n            \"acme-corp\": {\n                AllowedTools: []string{\"search\", \"describe\"},\n            },\n        },\n    }\n\n    resolver := resolvers.NewJWTResolver(resolvers.JWTConfig{\n        ClaimKey: \"tenant_id\",\n        Secret:   secret,\n        Store:    store,\n    })\n\n    // Create valid JWT\n    token := jwt.NewWithClaims(jwt.SigningMethodHS256, jwt.MapClaims{\n        \"tenant_id\": \"acme-corp\",\n        \"exp\":       time.Now().Add(time.Hour).Unix(),\n    })\n    tokenString, _ := token.SignedString(secret)\n\n    req := &amp;tenancy.Request{\n        Headers: map[string]string{\n            \"Authorization\": \"Bearer \" + tokenString,\n        },\n    }\n\n    tc, err := resolver.Resolve(context.Background(), req)\n    require.NoError(t, err)\n    require.NotNil(t, tc)\n    assert.Equal(t, \"acme-corp\", tc.Tenant.ID)\n}\n\nfunc TestJWTResolver_InvalidToken(t *testing.T) {\n    resolver := resolvers.NewJWTResolver(resolvers.JWTConfig{\n        ClaimKey: \"tenant_id\",\n        Secret:   []byte(\"secret\"),\n    })\n\n    req := &amp;tenancy.Request{\n        Headers: map[string]string{\n            \"Authorization\": \"Bearer invalid-token\",\n        },\n    }\n\n    _, err := resolver.Resolve(context.Background(), req)\n    require.Error(t, err)\n}\n\nfunc TestJWTResolver_MissingHeader(t *testing.T) {\n    resolver := resolvers.NewJWTResolver(resolvers.JWTConfig{\n        ClaimKey: \"tenant_id\",\n        Secret:   []byte(\"secret\"),\n    })\n\n    req := &amp;tenancy.Request{\n        Headers: map[string]string{},\n    }\n\n    _, err := resolver.Resolve(context.Background(), req)\n    require.Error(t, err)\n}\n\nfunc TestJWTResolver_MissingClaim(t *testing.T) {\n    secret := []byte(\"secret\")\n    resolver := resolvers.NewJWTResolver(resolvers.JWTConfig{\n        ClaimKey: \"tenant_id\",\n        Secret:   secret,\n    })\n\n    // Token without tenant_id claim\n    token := jwt.NewWithClaims(jwt.SigningMethodHS256, jwt.MapClaims{\n        \"user_id\": \"user-123\",\n        \"exp\":     time.Now().Add(time.Hour).Unix(),\n    })\n    tokenString, _ := token.SignedString(secret)\n\n    req := &amp;tenancy.Request{\n        Headers: map[string]string{\n            \"Authorization\": \"Bearer \" + tokenString,\n        },\n    }\n\n    _, err := resolver.Resolve(context.Background(), req)\n    require.Error(t, err)\n    assert.Contains(t, err.Error(), \"tenant claim\")\n}\n\n// MockTenantStore for testing\ntype MockTenantStore struct {\n    tenants map[string]*tenancy.Tenant\n    configs map[string]*tenancy.TenantConfig\n}\n\nfunc (s *MockTenantStore) Get(ctx context.Context, id string) (*tenancy.Tenant, error) {\n    t, ok := s.tenants[id]\n    if !ok {\n        return nil, tenancy.ErrTenantNotFound\n    }\n    return t, nil\n}\n\nfunc (s *MockTenantStore) GetConfig(ctx context.Context, id string) (*tenancy.TenantConfig, error) {\n    c, ok := s.configs[id]\n    if !ok {\n        return &amp;tenancy.TenantConfig{}, nil\n    }\n    return c, nil\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>go test ./internal/tenancy/resolvers/... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// resolver.go\npackage tenancy\n\nimport (\n    \"context\"\n    \"errors\"\n)\n\n// Errors\nvar (\n    ErrNoTenantResolved = errors.New(\"no tenant could be resolved\")\n    ErrTenantNotFound   = errors.New(\"tenant not found\")\n    ErrNoTenantClaim    = errors.New(\"no tenant claim in token\")\n    ErrInvalidToken     = errors.New(\"invalid or expired token\")\n)\n\n// Request represents an incoming request for tenant resolution\ntype Request struct {\n    Headers map[string]string\n    Query   map[string]string\n    Body    []byte\n}\n\n// TenantResolver identifies the tenant from a request\ntype TenantResolver interface {\n    // Resolve extracts tenant information from the request context\n    // Returns nil tenant for anonymous/default tenant\n    Resolve(ctx context.Context, req *Request) (*TenantContext, error)\n}\n\n// TenantResolverFunc is a convenience type\ntype TenantResolverFunc func(ctx context.Context, req *Request) (*TenantContext, error)\n\nfunc (f TenantResolverFunc) Resolve(ctx context.Context, req *Request) (*TenantContext, error) {\n    return f(ctx, req)\n}\n</code></pre> <pre><code>// resolvers/jwt.go\npackage resolvers\n\nimport (\n    \"context\"\n    \"errors\"\n    \"strings\"\n\n    \"github.com/golang-jwt/jwt/v5\"\n    \"github.com/jrraymond/metatools-mcp/internal/tenancy\"\n)\n\n// JWTConfig holds JWT resolver configuration\ntype JWTConfig struct {\n    ClaimKey string\n    Secret   []byte\n    Issuer   string\n    Audience string\n    Store    TenantStore\n}\n\n// TenantStore interface for JWT resolver\ntype TenantStore interface {\n    Get(ctx context.Context, id string) (*tenancy.Tenant, error)\n    GetConfig(ctx context.Context, id string) (*tenancy.TenantConfig, error)\n}\n\n// JWTResolver extracts tenant from JWT claims\ntype JWTResolver struct {\n    config JWTConfig\n}\n\n// NewJWTResolver creates a new JWT resolver\nfunc NewJWTResolver(config JWTConfig) *JWTResolver {\n    return &amp;JWTResolver{config: config}\n}\n\n// Resolve extracts tenant from JWT token\nfunc (r *JWTResolver) Resolve(ctx context.Context, req *tenancy.Request) (*tenancy.TenantContext, error) {\n    // Extract token from Authorization header\n    authHeader := req.Headers[\"Authorization\"]\n    if authHeader == \"\" {\n        return nil, errors.New(\"missing Authorization header\")\n    }\n\n    tokenString := strings.TrimPrefix(authHeader, \"Bearer \")\n    if tokenString == authHeader {\n        return nil, errors.New(\"invalid Authorization header format\")\n    }\n\n    // Parse and validate token\n    token, err := jwt.Parse(tokenString, func(token *jwt.Token) (any, error) {\n        // Validate signing method\n        if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n            return nil, errors.New(\"unexpected signing method\")\n        }\n        return r.config.Secret, nil\n    })\n\n    if err != nil {\n        return nil, tenancy.ErrInvalidToken\n    }\n\n    if !token.Valid {\n        return nil, tenancy.ErrInvalidToken\n    }\n\n    // Extract claims\n    claims, ok := token.Claims.(jwt.MapClaims)\n    if !ok {\n        return nil, errors.New(\"invalid token claims\")\n    }\n\n    // Get tenant ID from claims\n    tenantID, ok := claims[r.config.ClaimKey].(string)\n    if !ok || tenantID == \"\" {\n        return nil, tenancy.ErrNoTenantClaim\n    }\n\n    // Lookup tenant from store\n    var tenant *tenancy.Tenant\n    var config *tenancy.TenantConfig\n\n    if r.config.Store != nil {\n        tenant, err = r.config.Store.Get(ctx, tenantID)\n        if err != nil {\n            return nil, err\n        }\n        config, _ = r.config.Store.GetConfig(ctx, tenantID)\n    } else {\n        // Minimal tenant without store\n        tenant = &amp;tenancy.Tenant{\n            ID: tenantID,\n        }\n        config = &amp;tenancy.TenantConfig{}\n    }\n\n    // Extract permissions from claims\n    var permissions []string\n    if perms, ok := claims[\"permissions\"].([]any); ok {\n        for _, p := range perms {\n            if s, ok := p.(string); ok {\n                permissions = append(permissions, s)\n            }\n        }\n    }\n\n    return &amp;tenancy.TenantContext{\n        Tenant:      tenant,\n        Permissions: permissions,\n        Config:      config,\n    }, nil\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>go test ./internal/tenancy/resolvers/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/tenancy/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(tenancy): add TenantResolver interface and JWT resolver\n\n- TenantResolver interface for pluggable resolution\n- JWTResolver extracts tenant from JWT claims\n- Token validation with configurable secret\n- Permission extraction from claims\n- Integration with TenantStore\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-012-multi-tenancy-core/#task-3-tenant-middleware","title":"Task 3: Tenant Middleware","text":"<p>Files: - Create: <code>internal/tenancy/middleware.go</code> - Create: <code>internal/tenancy/middleware_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// middleware_test.go\npackage tenancy_test\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/metatools-mcp/internal/tenancy\"\n)\n\n// MockResolver for testing\ntype MockResolver struct {\n    tc  *tenancy.TenantContext\n    err error\n}\n\nfunc (r *MockResolver) Resolve(ctx context.Context, req *tenancy.Request) (*tenancy.TenantContext, error) {\n    return r.tc, r.err\n}\n\n// MockToolProvider for testing\ntype MockToolProvider struct {\n    name      string\n    capturedCtx context.Context\n    result    any\n    err       error\n}\n\nfunc (p *MockToolProvider) Name() string { return p.name }\nfunc (p *MockToolProvider) Handle(ctx context.Context, input map[string]any) (any, error) {\n    p.capturedCtx = ctx\n    return p.result, p.err\n}\n\nfunc TestTenantMiddleware_InjectsContext(t *testing.T) {\n    tc := &amp;tenancy.TenantContext{\n        Tenant: &amp;tenancy.Tenant{ID: \"test-tenant\"},\n        Config: &amp;tenancy.TenantConfig{},\n    }\n\n    resolver := &amp;MockResolver{tc: tc}\n    provider := &amp;MockToolProvider{name: \"test:tool\", result: \"ok\"}\n\n    middleware := tenancy.TenantMiddleware(resolver, nil)\n    wrapped := middleware(provider)\n\n    _, err := wrapped.Handle(context.Background(), nil)\n    require.NoError(t, err)\n\n    // Verify tenant context was injected\n    injected := tenancy.TenantFromContext(provider.capturedCtx)\n    require.NotNil(t, injected)\n    assert.Equal(t, \"test-tenant\", injected.Tenant.ID)\n}\n\nfunc TestTenantToolFilterMiddleware_AllowedTool(t *testing.T) {\n    tc := &amp;tenancy.TenantContext{\n        Tenant: &amp;tenancy.Tenant{ID: \"test\"},\n        Config: &amp;tenancy.TenantConfig{\n            AllowedTools: []string{\"test:tool\"},\n        },\n    }\n\n    ctx := tenancy.WithTenantContext(context.Background(), tc)\n    provider := &amp;MockToolProvider{name: \"test:tool\", result: \"ok\"}\n\n    middleware := tenancy.TenantToolFilterMiddleware()\n    wrapped := middleware(provider)\n\n    result, err := wrapped.Handle(ctx, nil)\n    require.NoError(t, err)\n    assert.Equal(t, \"ok\", result)\n}\n\nfunc TestTenantToolFilterMiddleware_DeniedTool(t *testing.T) {\n    tc := &amp;tenancy.TenantContext{\n        Tenant: &amp;tenancy.Tenant{ID: \"test\"},\n        Config: &amp;tenancy.TenantConfig{\n            DeniedTools: []string{\"test:dangerous\"},\n        },\n    }\n\n    ctx := tenancy.WithTenantContext(context.Background(), tc)\n    provider := &amp;MockToolProvider{name: \"test:dangerous\", result: \"ok\"}\n\n    middleware := tenancy.TenantToolFilterMiddleware()\n    wrapped := middleware(provider)\n\n    _, err := wrapped.Handle(ctx, nil)\n    require.Error(t, err)\n\n    var toolErr *tenancy.ToolDeniedError\n    require.ErrorAs(t, err, &amp;toolErr)\n    assert.Equal(t, \"test:dangerous\", toolErr.Tool)\n}\n\nfunc TestTenantRateLimitMiddleware_AllowsWithinLimit(t *testing.T) {\n    tc := &amp;tenancy.TenantContext{\n        Tenant: &amp;tenancy.Tenant{ID: \"test\"},\n        Config: &amp;tenancy.TenantConfig{\n            RateLimits: &amp;tenancy.RateLimitConfig{\n                RequestsPerMinute: 100,\n                Burst:             10,\n            },\n        },\n    }\n\n    store := tenancy.NewMemoryRateLimitStore()\n    ctx := tenancy.WithTenantContext(context.Background(), tc)\n    provider := &amp;MockToolProvider{name: \"test:tool\", result: \"ok\"}\n\n    middleware := tenancy.TenantRateLimitMiddleware(store, nil)\n    wrapped := middleware(provider)\n\n    // Should allow within limit\n    result, err := wrapped.Handle(ctx, nil)\n    require.NoError(t, err)\n    assert.Equal(t, \"ok\", result)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>go test ./internal/tenancy/... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// middleware.go\npackage tenancy\n\nimport (\n    \"context\"\n    \"fmt\"\n)\n\n// ToolProvider interface for middleware\ntype ToolProvider interface {\n    Name() string\n    Handle(ctx context.Context, input map[string]any) (any, error)\n}\n\n// Middleware wraps a ToolProvider\ntype Middleware func(ToolProvider) ToolProvider\n\n// ToolDeniedError indicates a tool was denied for a tenant\ntype ToolDeniedError struct {\n    TenantID string\n    Tool     string\n    Reason   string\n}\n\nfunc (e *ToolDeniedError) Error() string {\n    return fmt.Sprintf(\"tool %q denied for tenant %q: %s\", e.Tool, e.TenantID, e.Reason)\n}\n\n// RateLimitError indicates rate limit exceeded\ntype RateLimitError struct {\n    TenantID string\n    Limit    int\n}\n\nfunc (e *RateLimitError) Error() string {\n    return fmt.Sprintf(\"rate limit exceeded for tenant %q: limit %d\", e.TenantID, e.Limit)\n}\n\n// tenantMiddleware injects tenant context\ntype tenantMiddleware struct {\n    resolver TenantResolver\n    defaults *TenantContext\n    next     ToolProvider\n}\n\n// TenantMiddleware creates middleware that resolves and injects tenant context\nfunc TenantMiddleware(resolver TenantResolver, defaults *TenantContext) Middleware {\n    return func(next ToolProvider) ToolProvider {\n        return &amp;tenantMiddleware{\n            resolver: resolver,\n            defaults: defaults,\n            next:     next,\n        }\n    }\n}\n\nfunc (m *tenantMiddleware) Name() string {\n    return m.next.Name()\n}\n\nfunc (m *tenantMiddleware) Handle(ctx context.Context, input map[string]any) (any, error) {\n    // Build request from context\n    req := RequestFromContext(ctx)\n\n    // Resolve tenant\n    tc, err := m.resolver.Resolve(ctx, req)\n    if err != nil {\n        if m.defaults != nil {\n            tc = m.defaults\n        } else {\n            return nil, fmt.Errorf(\"tenant resolution failed: %w\", err)\n        }\n    }\n\n    // Inject tenant context\n    ctx = WithTenantContext(ctx, tc)\n\n    return m.next.Handle(ctx, input)\n}\n\n// toolFilterMiddleware filters tools based on tenant permissions\ntype toolFilterMiddleware struct {\n    next ToolProvider\n}\n\n// TenantToolFilterMiddleware creates middleware that filters tools by tenant\nfunc TenantToolFilterMiddleware() Middleware {\n    return func(next ToolProvider) ToolProvider {\n        return &amp;toolFilterMiddleware{next: next}\n    }\n}\n\nfunc (m *toolFilterMiddleware) Name() string {\n    return m.next.Name()\n}\n\nfunc (m *toolFilterMiddleware) Handle(ctx context.Context, input map[string]any) (any, error) {\n    tc := TenantFromContext(ctx)\n    if tc == nil || tc.Config == nil {\n        return m.next.Handle(ctx, input)\n    }\n\n    toolName := m.next.Name()\n    if !tc.Config.IsToolAllowed(toolName) {\n        return nil, &amp;ToolDeniedError{\n            TenantID: tc.Tenant.ID,\n            Tool:     toolName,\n            Reason:   \"tool not allowed for tenant\",\n        }\n    }\n\n    return m.next.Handle(ctx, input)\n}\n\n// RateLimitStore interface for rate limit storage\ntype RateLimitStore interface {\n    Allow(ctx context.Context, key string, limit, burst int) (bool, error)\n}\n\n// rateLimitMiddleware applies per-tenant rate limits\ntype rateLimitMiddleware struct {\n    store    RateLimitStore\n    defaults *RateLimitConfig\n    next     ToolProvider\n}\n\n// TenantRateLimitMiddleware creates middleware that enforces rate limits\nfunc TenantRateLimitMiddleware(store RateLimitStore, defaults *RateLimitConfig) Middleware {\n    return func(next ToolProvider) ToolProvider {\n        return &amp;rateLimitMiddleware{\n            store:    store,\n            defaults: defaults,\n            next:     next,\n        }\n    }\n}\n\nfunc (m *rateLimitMiddleware) Name() string {\n    return m.next.Name()\n}\n\nfunc (m *rateLimitMiddleware) Handle(ctx context.Context, input map[string]any) (any, error) {\n    tc := TenantFromContext(ctx)\n    if tc == nil {\n        return m.next.Handle(ctx, input)\n    }\n\n    // Get rate limit config\n    limits := tc.Config.RateLimits\n    if limits == nil {\n        limits = m.defaults\n    }\n    if limits == nil {\n        return m.next.Handle(ctx, input)\n    }\n\n    // Check rate limit\n    key := fmt.Sprintf(\"tenant:%s:tool:%s\", tc.Tenant.ID, m.next.Name())\n    allowed, err := m.store.Allow(ctx, key, limits.RequestsPerMinute, limits.Burst)\n    if err != nil {\n        return nil, err\n    }\n    if !allowed {\n        return nil, &amp;RateLimitError{\n            TenantID: tc.Tenant.ID,\n            Limit:    limits.RequestsPerMinute,\n        }\n    }\n\n    return m.next.Handle(ctx, input)\n}\n\n// MemoryRateLimitStore is an in-memory rate limit store\ntype MemoryRateLimitStore struct {\n    // Simplified - real implementation would use token bucket\n    counts map[string]int\n}\n\n// NewMemoryRateLimitStore creates a new memory rate limit store\nfunc NewMemoryRateLimitStore() *MemoryRateLimitStore {\n    return &amp;MemoryRateLimitStore{\n        counts: make(map[string]int),\n    }\n}\n\nfunc (s *MemoryRateLimitStore) Allow(ctx context.Context, key string, limit, burst int) (bool, error) {\n    s.counts[key]++\n    return s.counts[key] &lt;= limit, nil\n}\n\n// RequestFromContext builds a Request from context\nfunc RequestFromContext(ctx context.Context) *Request {\n    // Extract headers from context if available\n    // This would be set by the transport layer\n    return &amp;Request{\n        Headers: make(map[string]string),\n    }\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>go test ./internal/tenancy/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add internal/tenancy/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(tenancy): add tenant middleware\n\n- TenantMiddleware for context injection\n- TenantToolFilterMiddleware for access control\n- TenantRateLimitMiddleware for rate limiting\n- ToolDeniedError and RateLimitError types\n- MemoryRateLimitStore for development\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-012-multi-tenancy-core/#verification-checklist","title":"Verification Checklist","text":"<p>Before marking PRD-012 complete:</p> <ul> <li>[ ] All tests pass: <code>go test ./internal/tenancy/... -v</code></li> <li>[ ] Code coverage &gt; 80%</li> <li>[ ] No linting errors: <code>golangci-lint run</code></li> <li>[ ] Documentation complete</li> <li>[ ] Integration verified:</li> <li>[ ] Tenant types validate correctly</li> <li>[ ] JWT resolver extracts tenant</li> <li>[ ] Middleware injects context</li> <li>[ ] Tool filtering works</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-012-multi-tenancy-core/#definition-of-done","title":"Definition of Done","text":"<ol> <li>Tenant and TenantContext types</li> <li>TenantConfig with tool/backend access control</li> <li>TenantResolver interface with JWT resolver</li> <li>TenantMiddleware for context injection</li> <li>TenantToolFilterMiddleware for access control</li> <li>TenantRateLimitMiddleware for rate limiting</li> <li>All tests passing with &gt;80% coverage</li> <li>Documentation complete</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-013-toolsemantic-library/","title":"PRD-013: toolsemantic Library Implementation","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Create a hybrid semantic search library combining BM25 lexical search, vector embeddings, and reranking for intelligent tool discovery.</p> <p>Architecture: Three-stage pipeline: BM25 candidate retrieval, vector embedding similarity, and cross-encoder reranking. Pluggable embedding providers and vector stores.</p> <p>Tech Stack: Go, toolsearch dependency, OpenAI/Anthropic embeddings API, optional pgvector/Qdrant</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-013-toolsemantic-library/#overview","title":"Overview","text":"<p>The <code>toolsemantic</code> library extends toolsearch with semantic understanding, enabling natural language queries like \"find tools for working with git repositories\" to match tools even without exact keyword matches.</p> <p>Reference: ROADMAP.md - toolsemantic specification</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-013-toolsemantic-library/#directory-structure","title":"Directory Structure","text":"<pre><code>toolsemantic/\n\u251c\u2500\u2500 semantic.go          # HybridSearcher type\n\u251c\u2500\u2500 semantic_test.go\n\u251c\u2500\u2500 embedding.go         # Embedding interface\n\u251c\u2500\u2500 embedding_test.go\n\u251c\u2500\u2500 embeddings/\n\u2502   \u251c\u2500\u2500 openai.go        # OpenAI embeddings\n\u2502   \u251c\u2500\u2500 anthropic.go     # Anthropic embeddings\n\u2502   \u2514\u2500\u2500 local.go         # Local embeddings (e.g., all-MiniLM)\n\u251c\u2500\u2500 vector.go            # VectorStore interface\n\u251c\u2500\u2500 vector_test.go\n\u251c\u2500\u2500 stores/\n\u2502   \u251c\u2500\u2500 memory.go        # In-memory vector store\n\u2502   \u251c\u2500\u2500 memory_test.go\n\u2502   \u2514\u2500\u2500 pgvector.go      # PostgreSQL pgvector\n\u251c\u2500\u2500 rerank.go            # Reranker interface\n\u251c\u2500\u2500 rerank_test.go\n\u251c\u2500\u2500 rerankers/\n\u2502   \u251c\u2500\u2500 cross_encoder.go # Cross-encoder reranker\n\u2502   \u2514\u2500\u2500 rrf.go           # Reciprocal Rank Fusion\n\u251c\u2500\u2500 config.go            # Configuration\n\u251c\u2500\u2500 doc.go\n\u251c\u2500\u2500 go.mod\n\u2514\u2500\u2500 go.sum\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-013-toolsemantic-library/#task-1-hybridsearcher-and-configuration","title":"Task 1: HybridSearcher and Configuration","text":"<p>Files: - Create: <code>toolsemantic/semantic.go</code> - Create: <code>toolsemantic/semantic_test.go</code> - Create: <code>toolsemantic/go.mod</code> - Create: <code>toolsemantic/config.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// semantic_test.go\npackage toolsemantic_test\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolsemantic\"\n)\n\nfunc TestHybridSearcher_New(t *testing.T) {\n    config := toolsemantic.Config{\n        BM25Weight:   0.3,\n        VectorWeight: 0.5,\n        RerankWeight: 0.2,\n    }\n\n    searcher, err := toolsemantic.NewHybridSearcher(config, nil, nil, nil)\n    require.NoError(t, err)\n    assert.NotNil(t, searcher)\n}\n\nfunc TestConfig_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        config  toolsemantic.Config\n        wantErr bool\n    }{\n        {\n            name: \"valid config\",\n            config: toolsemantic.Config{\n                BM25Weight:   0.3,\n                VectorWeight: 0.5,\n                RerankWeight: 0.2,\n            },\n            wantErr: false,\n        },\n        {\n            name: \"weights don't sum to 1\",\n            config: toolsemantic.Config{\n                BM25Weight:   0.5,\n                VectorWeight: 0.5,\n                RerankWeight: 0.5,\n            },\n            wantErr: true,\n        },\n        {\n            name: \"negative weight\",\n            config: toolsemantic.Config{\n                BM25Weight:   -0.1,\n                VectorWeight: 0.6,\n                RerankWeight: 0.5,\n            },\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            err := tt.config.Validate()\n            if tt.wantErr {\n                require.Error(t, err)\n            } else {\n                require.NoError(t, err)\n            }\n        })\n    }\n}\n\nfunc TestDefaultConfig(t *testing.T) {\n    config := toolsemantic.DefaultConfig()\n\n    assert.InDelta(t, 1.0, config.BM25Weight+config.VectorWeight+config.RerankWeight, 0.01)\n    assert.Greater(t, config.TopK, 0)\n    assert.Greater(t, config.CandidateMultiplier, 0)\n}\n\nfunc TestHybridSearcher_Search_BM25Only(t *testing.T) {\n    // BM25-only search (no embedder or vector store)\n    config := toolsemantic.Config{\n        BM25Weight:   1.0,\n        VectorWeight: 0.0,\n        RerankWeight: 0.0,\n        TopK:         10,\n    }\n\n    bm25 := &amp;MockBM25Searcher{\n        results: []toolsemantic.SearchResult{\n            {ID: \"tool1\", Score: 0.9},\n            {ID: \"tool2\", Score: 0.8},\n        },\n    }\n\n    searcher, _ := toolsemantic.NewHybridSearcher(config, bm25, nil, nil)\n\n    results, err := searcher.Search(context.Background(), \"test query\", 10)\n    require.NoError(t, err)\n    assert.Len(t, results, 2)\n    assert.Equal(t, \"tool1\", results[0].ID)\n}\n\n// MockBM25Searcher for testing\ntype MockBM25Searcher struct {\n    results []toolsemantic.SearchResult\n}\n\nfunc (m *MockBM25Searcher) Search(query string, limit int) ([]toolsemantic.SearchResult, error) {\n    return m.results, nil\n}\n\nfunc (m *MockBM25Searcher) Close() error { return nil }\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolsemantic &amp;&amp; go test ./... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// go.mod\nmodule github.com/jrraymond/toolsemantic\n\ngo 1.22\n\nrequire (\n    github.com/jrraymond/toolsearch v0.1.9\n)\n</code></pre> <pre><code>// config.go\npackage toolsemantic\n\nimport (\n    \"errors\"\n    \"math\"\n)\n\n// Config holds hybrid search configuration\ntype Config struct {\n    // Weight distribution (must sum to 1.0)\n    BM25Weight   float64 `yaml:\"bm25_weight\"`\n    VectorWeight float64 `yaml:\"vector_weight\"`\n    RerankWeight float64 `yaml:\"rerank_weight\"`\n\n    // Search parameters\n    TopK                int `yaml:\"top_k\"`\n    CandidateMultiplier int `yaml:\"candidate_multiplier\"` // Candidates = TopK * Multiplier\n\n    // Embedding config\n    EmbeddingModel    string `yaml:\"embedding_model\"`\n    EmbeddingProvider string `yaml:\"embedding_provider\"` // openai, anthropic, local\n\n    // Vector store config\n    VectorStore string `yaml:\"vector_store\"` // memory, pgvector, qdrant\n\n    // Reranker config\n    Reranker      string `yaml:\"reranker\"`       // none, cross_encoder, rrf\n    RerankerModel string `yaml:\"reranker_model\"` // For cross-encoder\n}\n\n// Validate validates the configuration\nfunc (c Config) Validate() error {\n    // Check weights\n    if c.BM25Weight &lt; 0 || c.VectorWeight &lt; 0 || c.RerankWeight &lt; 0 {\n        return errors.New(\"weights cannot be negative\")\n    }\n\n    totalWeight := c.BM25Weight + c.VectorWeight + c.RerankWeight\n    if math.Abs(totalWeight-1.0) &gt; 0.01 {\n        return errors.New(\"weights must sum to 1.0\")\n    }\n\n    return nil\n}\n\n// DefaultConfig returns a default configuration\nfunc DefaultConfig() Config {\n    return Config{\n        BM25Weight:          0.3,\n        VectorWeight:        0.5,\n        RerankWeight:        0.2,\n        TopK:                10,\n        CandidateMultiplier: 5,\n        EmbeddingProvider:   \"openai\",\n        EmbeddingModel:      \"text-embedding-3-small\",\n        VectorStore:         \"memory\",\n        Reranker:            \"rrf\",\n    }\n}\n</code></pre> <pre><code>// semantic.go\npackage toolsemantic\n\nimport (\n    \"context\"\n    \"sort\"\n)\n\n// SearchResult represents a search result\ntype SearchResult struct {\n    ID          string\n    Score       float64\n    BM25Score   float64\n    VectorScore float64\n    RerankScore float64\n}\n\n// BM25Searcher interface for lexical search\ntype BM25Searcher interface {\n    Search(query string, limit int) ([]SearchResult, error)\n    Close() error\n}\n\n// Embedder interface for text embedding\ntype Embedder interface {\n    Embed(ctx context.Context, text string) ([]float64, error)\n    EmbedBatch(ctx context.Context, texts []string) ([][]float64, error)\n    Dimensions() int\n}\n\n// VectorStore interface for vector storage\ntype VectorStore interface {\n    Add(ctx context.Context, id string, vector []float64) error\n    Search(ctx context.Context, vector []float64, limit int) ([]SearchResult, error)\n    Delete(ctx context.Context, id string) error\n    Close() error\n}\n\n// Reranker interface for result reranking\ntype Reranker interface {\n    Rerank(ctx context.Context, query string, results []SearchResult) ([]SearchResult, error)\n}\n\n// HybridSearcher combines BM25, vector, and reranking\ntype HybridSearcher struct {\n    config   Config\n    bm25     BM25Searcher\n    embedder Embedder\n    vector   VectorStore\n    reranker Reranker\n}\n\n// NewHybridSearcher creates a new hybrid searcher\nfunc NewHybridSearcher(\n    config Config,\n    bm25 BM25Searcher,\n    embedder Embedder,\n    vector VectorStore,\n) (*HybridSearcher, error) {\n    if err := config.Validate(); err != nil {\n        return nil, err\n    }\n\n    return &amp;HybridSearcher{\n        config:   config,\n        bm25:     bm25,\n        embedder: embedder,\n        vector:   vector,\n    }, nil\n}\n\n// WithReranker adds a reranker to the searcher\nfunc (h *HybridSearcher) WithReranker(reranker Reranker) *HybridSearcher {\n    h.reranker = reranker\n    return h\n}\n\n// Search performs hybrid search\nfunc (h *HybridSearcher) Search(ctx context.Context, query string, limit int) ([]SearchResult, error) {\n    // Calculate candidate count\n    candidateLimit := limit * h.config.CandidateMultiplier\n    if candidateLimit &lt; limit {\n        candidateLimit = limit\n    }\n\n    // Collect results from each source\n    resultMap := make(map[string]*SearchResult)\n\n    // Stage 1: BM25 search\n    if h.bm25 != nil &amp;&amp; h.config.BM25Weight &gt; 0 {\n        bm25Results, err := h.bm25.Search(query, candidateLimit)\n        if err != nil {\n            return nil, err\n        }\n        for _, r := range bm25Results {\n            if existing, ok := resultMap[r.ID]; ok {\n                existing.BM25Score = r.Score\n            } else {\n                resultMap[r.ID] = &amp;SearchResult{\n                    ID:        r.ID,\n                    BM25Score: r.Score,\n                }\n            }\n        }\n    }\n\n    // Stage 2: Vector search\n    if h.embedder != nil &amp;&amp; h.vector != nil &amp;&amp; h.config.VectorWeight &gt; 0 {\n        queryVec, err := h.embedder.Embed(ctx, query)\n        if err != nil {\n            return nil, err\n        }\n\n        vectorResults, err := h.vector.Search(ctx, queryVec, candidateLimit)\n        if err != nil {\n            return nil, err\n        }\n\n        for _, r := range vectorResults {\n            if existing, ok := resultMap[r.ID]; ok {\n                existing.VectorScore = r.Score\n            } else {\n                resultMap[r.ID] = &amp;SearchResult{\n                    ID:          r.ID,\n                    VectorScore: r.Score,\n                }\n            }\n        }\n    }\n\n    // Convert to slice and calculate weighted scores\n    results := make([]SearchResult, 0, len(resultMap))\n    for _, r := range resultMap {\n        r.Score = h.config.BM25Weight*r.BM25Score +\n            h.config.VectorWeight*r.VectorScore +\n            h.config.RerankWeight*r.RerankScore\n        results = append(results, *r)\n    }\n\n    // Sort by score\n    sort.Slice(results, func(i, j int) bool {\n        return results[i].Score &gt; results[j].Score\n    })\n\n    // Stage 3: Rerank top candidates\n    if h.reranker != nil &amp;&amp; h.config.RerankWeight &gt; 0 &amp;&amp; len(results) &gt; 0 {\n        // Rerank top candidates\n        reranked, err := h.reranker.Rerank(ctx, query, results)\n        if err != nil {\n            return nil, err\n        }\n\n        // Update scores with rerank scores\n        for i := range reranked {\n            reranked[i].Score = h.config.BM25Weight*reranked[i].BM25Score +\n                h.config.VectorWeight*reranked[i].VectorScore +\n                h.config.RerankWeight*reranked[i].RerankScore\n        }\n\n        results = reranked\n        sort.Slice(results, func(i, j int) bool {\n            return results[i].Score &gt; results[j].Score\n        })\n    }\n\n    // Limit results\n    if len(results) &gt; limit {\n        results = results[:limit]\n    }\n\n    return results, nil\n}\n\n// Close closes all underlying resources\nfunc (h *HybridSearcher) Close() error {\n    if h.bm25 != nil {\n        h.bm25.Close()\n    }\n    if h.vector != nil {\n        h.vector.Close()\n    }\n    return nil\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolsemantic &amp;&amp; go test ./... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolsemantic/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolsemantic): add HybridSearcher and configuration\n\n- HybridSearcher combining BM25, vector, reranking\n- Config with weight distribution validation\n- Pluggable BM25Searcher, Embedder, VectorStore, Reranker interfaces\n- Three-stage search pipeline\n- Weighted score combination\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-013-toolsemantic-library/#task-2-embedding-interface-and-openai-provider","title":"Task 2: Embedding Interface and OpenAI Provider","text":"<p>Files: - Create: <code>toolsemantic/embedding.go</code> - Create: <code>toolsemantic/embeddings/openai.go</code> - Create: <code>toolsemantic/embeddings/openai_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// embeddings/openai_test.go\npackage embeddings_test\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolsemantic/embeddings\"\n)\n\nfunc TestOpenAIEmbedder_Dimensions(t *testing.T) {\n    embedder := embeddings.NewOpenAIEmbedder(embeddings.OpenAIConfig{\n        APIKey: \"test-key\",\n        Model:  \"text-embedding-3-small\",\n    })\n\n    assert.Equal(t, 1536, embedder.Dimensions())\n}\n\nfunc TestOpenAIEmbedder_DimensionsLarge(t *testing.T) {\n    embedder := embeddings.NewOpenAIEmbedder(embeddings.OpenAIConfig{\n        APIKey: \"test-key\",\n        Model:  \"text-embedding-3-large\",\n    })\n\n    assert.Equal(t, 3072, embedder.Dimensions())\n}\n\n// Note: Actual API tests would require integration testing\nfunc TestOpenAIEmbedder_Config(t *testing.T) {\n    config := embeddings.OpenAIConfig{\n        APIKey:     \"sk-test\",\n        Model:      \"text-embedding-3-small\",\n        Dimensions: 512,\n        BaseURL:    \"https://custom.api.com\",\n    }\n\n    embedder := embeddings.NewOpenAIEmbedder(config)\n    assert.NotNil(t, embedder)\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolsemantic &amp;&amp; go test ./embeddings/... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// embedding.go\npackage toolsemantic\n\nimport \"context\"\n\n// EmbeddingResult holds embedding result\ntype EmbeddingResult struct {\n    Vector     []float64\n    TokenCount int\n}\n\n// EmbedderConfig is the common embedder configuration\ntype EmbedderConfig struct {\n    Provider   string // openai, anthropic, local\n    Model      string\n    Dimensions int\n    APIKey     string\n    BaseURL    string\n}\n</code></pre> <pre><code>// embeddings/openai.go\npackage embeddings\n\nimport (\n    \"bytes\"\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"io\"\n    \"net/http\"\n)\n\n// OpenAIConfig holds OpenAI embeddings configuration\ntype OpenAIConfig struct {\n    APIKey     string\n    Model      string\n    Dimensions int    // Optional: reduce dimensions\n    BaseURL    string // Optional: custom base URL\n}\n\n// OpenAIEmbedder generates embeddings using OpenAI API\ntype OpenAIEmbedder struct {\n    config OpenAIConfig\n    client *http.Client\n}\n\n// NewOpenAIEmbedder creates a new OpenAI embedder\nfunc NewOpenAIEmbedder(config OpenAIConfig) *OpenAIEmbedder {\n    if config.BaseURL == \"\" {\n        config.BaseURL = \"https://api.openai.com/v1\"\n    }\n    if config.Model == \"\" {\n        config.Model = \"text-embedding-3-small\"\n    }\n\n    return &amp;OpenAIEmbedder{\n        config: config,\n        client: &amp;http.Client{},\n    }\n}\n\n// Dimensions returns the embedding dimensions\nfunc (e *OpenAIEmbedder) Dimensions() int {\n    if e.config.Dimensions &gt; 0 {\n        return e.config.Dimensions\n    }\n\n    // Default dimensions per model\n    switch e.config.Model {\n    case \"text-embedding-3-large\":\n        return 3072\n    case \"text-embedding-3-small\":\n        return 1536\n    case \"text-embedding-ada-002\":\n        return 1536\n    default:\n        return 1536\n    }\n}\n\n// Embed generates embedding for a single text\nfunc (e *OpenAIEmbedder) Embed(ctx context.Context, text string) ([]float64, error) {\n    vectors, err := e.EmbedBatch(ctx, []string{text})\n    if err != nil {\n        return nil, err\n    }\n    return vectors[0], nil\n}\n\n// EmbedBatch generates embeddings for multiple texts\nfunc (e *OpenAIEmbedder) EmbedBatch(ctx context.Context, texts []string) ([][]float64, error) {\n    reqBody := map[string]any{\n        \"input\": texts,\n        \"model\": e.config.Model,\n    }\n\n    if e.config.Dimensions &gt; 0 {\n        reqBody[\"dimensions\"] = e.config.Dimensions\n    }\n\n    body, err := json.Marshal(reqBody)\n    if err != nil {\n        return nil, err\n    }\n\n    req, err := http.NewRequestWithContext(ctx, \"POST\",\n        e.config.BaseURL+\"/embeddings\", bytes.NewReader(body))\n    if err != nil {\n        return nil, err\n    }\n\n    req.Header.Set(\"Content-Type\", \"application/json\")\n    req.Header.Set(\"Authorization\", \"Bearer \"+e.config.APIKey)\n\n    resp, err := e.client.Do(req)\n    if err != nil {\n        return nil, err\n    }\n    defer resp.Body.Close()\n\n    if resp.StatusCode != http.StatusOK {\n        respBody, _ := io.ReadAll(resp.Body)\n        return nil, fmt.Errorf(\"OpenAI API error: %s\", string(respBody))\n    }\n\n    var result struct {\n        Data []struct {\n            Embedding []float64 `json:\"embedding\"`\n            Index     int       `json:\"index\"`\n        } `json:\"data\"`\n    }\n\n    if err := json.NewDecoder(resp.Body).Decode(&amp;result); err != nil {\n        return nil, err\n    }\n\n    vectors := make([][]float64, len(texts))\n    for _, item := range result.Data {\n        vectors[item.Index] = item.Embedding\n    }\n\n    return vectors, nil\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolsemantic &amp;&amp; go test ./embeddings/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolsemantic/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolsemantic): add Embedder interface and OpenAI provider\n\n- Embedder interface with Embed and EmbedBatch\n- OpenAIEmbedder with configurable model and dimensions\n- Support for text-embedding-3-small and text-embedding-3-large\n- Custom base URL for Azure OpenAI compatibility\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-013-toolsemantic-library/#task-3-in-memory-vector-store","title":"Task 3: In-Memory Vector Store","text":"<p>Files: - Create: <code>toolsemantic/stores/memory.go</code> - Create: <code>toolsemantic/stores/memory_test.go</code></p> <p>Step 1: Write failing tests</p> <pre><code>// stores/memory_test.go\npackage stores_test\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/jrraymond/toolsemantic/stores\"\n)\n\nfunc TestMemoryVectorStore_AddAndSearch(t *testing.T) {\n    store := stores.NewMemoryVectorStore(3) // 3 dimensions\n    ctx := context.Background()\n\n    // Add vectors\n    store.Add(ctx, \"tool1\", []float64{1.0, 0.0, 0.0})\n    store.Add(ctx, \"tool2\", []float64{0.0, 1.0, 0.0})\n    store.Add(ctx, \"tool3\", []float64{0.0, 0.0, 1.0})\n\n    // Search for vector similar to tool1\n    query := []float64{0.9, 0.1, 0.0}\n    results, err := store.Search(ctx, query, 2)\n    require.NoError(t, err)\n\n    // tool1 should be most similar\n    assert.Equal(t, \"tool1\", results[0].ID)\n    assert.Greater(t, results[0].Score, results[1].Score)\n}\n\nfunc TestMemoryVectorStore_Delete(t *testing.T) {\n    store := stores.NewMemoryVectorStore(3)\n    ctx := context.Background()\n\n    store.Add(ctx, \"tool1\", []float64{1.0, 0.0, 0.0})\n    store.Delete(ctx, \"tool1\")\n\n    results, err := store.Search(ctx, []float64{1.0, 0.0, 0.0}, 10)\n    require.NoError(t, err)\n    assert.Len(t, results, 0)\n}\n\nfunc TestMemoryVectorStore_Update(t *testing.T) {\n    store := stores.NewMemoryVectorStore(3)\n    ctx := context.Background()\n\n    store.Add(ctx, \"tool1\", []float64{1.0, 0.0, 0.0})\n    store.Add(ctx, \"tool1\", []float64{0.0, 1.0, 0.0}) // Update\n\n    results, err := store.Search(ctx, []float64{0.0, 1.0, 0.0}, 1)\n    require.NoError(t, err)\n    assert.Equal(t, \"tool1\", results[0].ID)\n    assert.InDelta(t, 1.0, results[0].Score, 0.01)\n}\n\nfunc TestMemoryVectorStore_EmptySearch(t *testing.T) {\n    store := stores.NewMemoryVectorStore(3)\n    ctx := context.Background()\n\n    results, err := store.Search(ctx, []float64{1.0, 0.0, 0.0}, 10)\n    require.NoError(t, err)\n    assert.Len(t, results, 0)\n}\n\nfunc TestCosineSimilarity(t *testing.T) {\n    tests := []struct {\n        name     string\n        a, b     []float64\n        expected float64\n    }{\n        {\n            name:     \"identical vectors\",\n            a:        []float64{1.0, 0.0, 0.0},\n            b:        []float64{1.0, 0.0, 0.0},\n            expected: 1.0,\n        },\n        {\n            name:     \"orthogonal vectors\",\n            a:        []float64{1.0, 0.0, 0.0},\n            b:        []float64{0.0, 1.0, 0.0},\n            expected: 0.0,\n        },\n        {\n            name:     \"opposite vectors\",\n            a:        []float64{1.0, 0.0, 0.0},\n            b:        []float64{-1.0, 0.0, 0.0},\n            expected: -1.0,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            result := stores.CosineSimilarity(tt.a, tt.b)\n            assert.InDelta(t, tt.expected, result, 0.01)\n        })\n    }\n}\n</code></pre> <p>Step 2: Run tests to verify they fail</p> <p>Run: <code>cd toolsemantic &amp;&amp; go test ./stores/... -v</code> Expected: FAIL</p> <p>Step 3: Write minimal implementation</p> <pre><code>// stores/memory.go\npackage stores\n\nimport (\n    \"context\"\n    \"math\"\n    \"sort\"\n    \"sync\"\n\n    \"github.com/jrraymond/toolsemantic\"\n)\n\n// MemoryVectorStore is an in-memory vector store\ntype MemoryVectorStore struct {\n    dimensions int\n    vectors    map[string][]float64\n    mu         sync.RWMutex\n}\n\n// NewMemoryVectorStore creates a new in-memory vector store\nfunc NewMemoryVectorStore(dimensions int) *MemoryVectorStore {\n    return &amp;MemoryVectorStore{\n        dimensions: dimensions,\n        vectors:    make(map[string][]float64),\n    }\n}\n\n// Add adds or updates a vector\nfunc (s *MemoryVectorStore) Add(ctx context.Context, id string, vector []float64) error {\n    s.mu.Lock()\n    defer s.mu.Unlock()\n\n    // Normalize the vector\n    normalized := normalize(vector)\n    s.vectors[id] = normalized\n    return nil\n}\n\n// Search finds the most similar vectors\nfunc (s *MemoryVectorStore) Search(ctx context.Context, query []float64, limit int) ([]toolsemantic.SearchResult, error) {\n    s.mu.RLock()\n    defer s.mu.RUnlock()\n\n    if len(s.vectors) == 0 {\n        return []toolsemantic.SearchResult{}, nil\n    }\n\n    // Normalize query\n    queryNorm := normalize(query)\n\n    // Calculate similarities\n    type scoredResult struct {\n        id    string\n        score float64\n    }\n\n    results := make([]scoredResult, 0, len(s.vectors))\n    for id, vec := range s.vectors {\n        score := CosineSimilarity(queryNorm, vec)\n        results = append(results, scoredResult{id: id, score: score})\n    }\n\n    // Sort by score descending\n    sort.Slice(results, func(i, j int) bool {\n        return results[i].score &gt; results[j].score\n    })\n\n    // Limit results\n    if len(results) &gt; limit {\n        results = results[:limit]\n    }\n\n    // Convert to SearchResult\n    searchResults := make([]toolsemantic.SearchResult, len(results))\n    for i, r := range results {\n        searchResults[i] = toolsemantic.SearchResult{\n            ID:          r.id,\n            Score:       r.score,\n            VectorScore: r.score,\n        }\n    }\n\n    return searchResults, nil\n}\n\n// Delete removes a vector\nfunc (s *MemoryVectorStore) Delete(ctx context.Context, id string) error {\n    s.mu.Lock()\n    defer s.mu.Unlock()\n\n    delete(s.vectors, id)\n    return nil\n}\n\n// Close closes the store\nfunc (s *MemoryVectorStore) Close() error {\n    return nil\n}\n\n// CosineSimilarity calculates cosine similarity between two vectors\nfunc CosineSimilarity(a, b []float64) float64 {\n    if len(a) != len(b) {\n        return 0\n    }\n\n    var dotProduct, normA, normB float64\n    for i := range a {\n        dotProduct += a[i] * b[i]\n        normA += a[i] * a[i]\n        normB += b[i] * b[i]\n    }\n\n    if normA == 0 || normB == 0 {\n        return 0\n    }\n\n    return dotProduct / (math.Sqrt(normA) * math.Sqrt(normB))\n}\n\n// normalize normalizes a vector to unit length\nfunc normalize(v []float64) []float64 {\n    var sum float64\n    for _, val := range v {\n        sum += val * val\n    }\n\n    if sum == 0 {\n        return v\n    }\n\n    norm := math.Sqrt(sum)\n    result := make([]float64, len(v))\n    for i, val := range v {\n        result[i] = val / norm\n    }\n\n    return result\n}\n</code></pre> <p>Step 4: Run tests to verify they pass</p> <p>Run: <code>cd toolsemantic &amp;&amp; go test ./stores/... -v</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolsemantic/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolsemantic): add in-memory vector store\n\n- MemoryVectorStore with Add, Search, Delete\n- Cosine similarity calculation\n- Vector normalization for accurate similarity\n- Thread-safe operations\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-013-toolsemantic-library/#verification-checklist","title":"Verification Checklist","text":"<p>Before marking PRD-013 complete:</p> <ul> <li>[ ] All tests pass: <code>go test ./... -v</code></li> <li>[ ] Code coverage &gt; 80%</li> <li>[ ] No linting errors: <code>golangci-lint run</code></li> <li>[ ] Documentation complete</li> <li>[ ] Integration verified:</li> <li>[ ] HybridSearcher combines BM25 + vector</li> <li>[ ] OpenAI embeddings work</li> <li>[ ] Memory vector store works</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-013-toolsemantic-library/#definition-of-done","title":"Definition of Done","text":"<ol> <li>HybridSearcher combining BM25, vector, reranking</li> <li>Config with weight validation</li> <li>Embedder interface with OpenAI implementation</li> <li>VectorStore interface with memory implementation</li> <li>Reranker interface (RRF implementation)</li> <li>All tests passing with &gt;80% coverage</li> <li>Documentation complete</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/","title":"PRD-014: toolskill Library Implementation Plan","text":"<p>For Claude: REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.</p> <p>Goal: Implement agent skills support with SKILL.md parsing, skill registry, composition DSL, and runtime execution.</p> <p>Architecture: The toolskill library provides higher-level agent behaviors that compose tools into reusable workflows. Skills sit above tools in the abstraction hierarchy - while tools are atomic operations, skills orchestrate multiple tools with workflow logic (research-and-summarize, debug-and-fix, deploy-with-validation).</p> <p>Tech Stack: Go 1.21+, yaml.v3 (frontmatter), goldmark (markdown), semver</p> <p>Dependencies: toolset (tool access), toolrun (execution), toolobserve (optional tracing)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#task-1-core-types-and-skill-interface","title":"Task 1: Core Types and Skill Interface","text":"<p>Files: - Create: <code>toolskill/skill.go</code> - Create: <code>toolskill/manifest.go</code> - Test: <code>toolskill/skill_test.go</code></p> <p>Step 1: Write the failing test</p> <pre><code>// toolskill/skill_test.go\npackage toolskill\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/Masterminds/semver/v3\"\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc TestSkillManifest_Validate(t *testing.T) {\n    tests := []struct {\n        name    string\n        manifest SkillManifest\n        wantErr bool\n    }{\n        {\n            name: \"valid manifest\",\n            manifest: SkillManifest{\n                ID:          \"research-tool\",\n                Name:        \"research-tool\",\n                Version:     \"1.0.0\",\n                Description: \"Use when researching tools in the codebase\",\n                Tags:        []string{\"research\", \"discovery\"},\n            },\n            wantErr: false,\n        },\n        {\n            name: \"missing ID\",\n            manifest: SkillManifest{\n                Name:        \"research-tool\",\n                Version:     \"1.0.0\",\n                Description: \"Use when researching\",\n            },\n            wantErr: true,\n        },\n        {\n            name: \"missing name\",\n            manifest: SkillManifest{\n                ID:          \"research-tool\",\n                Version:     \"1.0.0\",\n                Description: \"Use when researching\",\n            },\n            wantErr: true,\n        },\n        {\n            name: \"invalid version\",\n            manifest: SkillManifest{\n                ID:          \"research-tool\",\n                Name:        \"research-tool\",\n                Version:     \"not-semver\",\n                Description: \"Use when researching\",\n            },\n            wantErr: true,\n        },\n        {\n            name: \"description must start with Use when\",\n            manifest: SkillManifest{\n                ID:          \"research-tool\",\n                Name:        \"research-tool\",\n                Version:     \"1.0.0\",\n                Description: \"Researches tools\", // Missing \"Use when\"\n            },\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            err := tt.manifest.Validate()\n            if tt.wantErr {\n                assert.Error(t, err)\n            } else {\n                assert.NoError(t, err)\n            }\n        })\n    }\n}\n\nfunc TestSkillInput_Get(t *testing.T) {\n    input := SkillInput{\n        \"topic\":  \"kubernetes\",\n        \"depth\":  3,\n        \"tags\":   []string{\"container\", \"orchestration\"},\n    }\n\n    // String retrieval\n    topic, ok := input.GetString(\"topic\")\n    assert.True(t, ok)\n    assert.Equal(t, \"kubernetes\", topic)\n\n    // Int retrieval\n    depth, ok := input.GetInt(\"depth\")\n    assert.True(t, ok)\n    assert.Equal(t, 3, depth)\n\n    // Missing key\n    _, ok = input.GetString(\"missing\")\n    assert.False(t, ok)\n}\n\nfunc TestSkillOutput_Success(t *testing.T) {\n    output := NewSkillOutput(map[string]any{\n        \"summary\": \"Found 5 tools\",\n        \"tools\":   []string{\"tool1\", \"tool2\"},\n    })\n\n    assert.True(t, output.Success)\n    assert.Nil(t, output.Error)\n    assert.Equal(t, \"Found 5 tools\", output.Result[\"summary\"])\n}\n\nfunc TestSkillOutput_Failure(t *testing.T) {\n    output := NewSkillOutputError(ErrSkillExecutionFailed, \"step 3 timed out\")\n\n    assert.False(t, output.Success)\n    assert.NotNil(t, output.Error)\n    assert.Contains(t, output.ErrorMessage, \"step 3 timed out\")\n}\n\n// Mock skill for testing\ntype mockSkill struct {\n    id       string\n    name     string\n    version  *semver.Version\n    manifest *SkillManifest\n    tools    []string\n    steps    []StepDefinition\n}\n\nfunc (m *mockSkill) ID() string                    { return m.id }\nfunc (m *mockSkill) Name() string                  { return m.name }\nfunc (m *mockSkill) Version() *semver.Version      { return m.version }\nfunc (m *mockSkill) Manifest() *SkillManifest      { return m.manifest }\nfunc (m *mockSkill) RequiredTools() []string       { return m.tools }\nfunc (m *mockSkill) Steps() []StepDefinition       { return m.steps }\nfunc (m *mockSkill) Execute(ctx context.Context, input SkillInput) (*SkillOutput, error) {\n    return NewSkillOutput(map[string]any{\"executed\": true}), nil\n}\n\nfunc TestSkillInterface(t *testing.T) {\n    ver, _ := semver.NewVersion(\"1.0.0\")\n    skill := &amp;mockSkill{\n        id:      \"test-skill\",\n        name:    \"test-skill\",\n        version: ver,\n        manifest: &amp;SkillManifest{\n            ID:          \"test-skill\",\n            Name:        \"test-skill\",\n            Version:     \"1.0.0\",\n            Description: \"Use when testing skill interface\",\n        },\n        tools: []string{\"search_tools\", \"describe_tool\"},\n        steps: []StepDefinition{\n            {ID: \"step1\", Name: \"Search\", Tool: \"search_tools\"},\n        },\n    }\n\n    // Verify interface compliance\n    var _ Skill = skill\n\n    assert.Equal(t, \"test-skill\", skill.ID())\n    assert.Equal(t, \"test-skill\", skill.Name())\n    assert.Equal(t, \"1.0.0\", skill.Version().String())\n    assert.Len(t, skill.RequiredTools(), 2)\n    assert.Len(t, skill.Steps(), 1)\n\n    // Execute\n    output, err := skill.Execute(context.Background(), SkillInput{\"query\": \"test\"})\n    require.NoError(t, err)\n    assert.True(t, output.Success)\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v -run TestSkill</code> Expected: FAIL with \"package toolskill is not in std\"</p> <p>Step 3: Write minimal implementation</p> <pre><code>// toolskill/skill.go\npackage toolskill\n\nimport (\n    \"context\"\n    \"errors\"\n    \"fmt\"\n    \"strings\"\n\n    \"github.com/Masterminds/semver/v3\"\n)\n\n// Errors\nvar (\n    ErrSkillNotFound        = errors.New(\"skill not found\")\n    ErrSkillExecutionFailed = errors.New(\"skill execution failed\")\n    ErrInvalidManifest      = errors.New(\"invalid skill manifest\")\n    ErrMissingTool          = errors.New(\"required tool not available\")\n    ErrStepFailed           = errors.New(\"step execution failed\")\n)\n\n// Skill defines the interface for reusable agent behaviors.\n// Skills orchestrate multiple tools into workflows.\ntype Skill interface {\n    // Identity\n    ID() string\n    Name() string\n    Version() *semver.Version\n\n    // Manifest for discovery/advertisement\n    Manifest() *SkillManifest\n\n    // Execution\n    Execute(ctx context.Context, input SkillInput) (*SkillOutput, error)\n\n    // Introspection\n    RequiredTools() []string\n    Steps() []StepDefinition\n}\n\n// SkillInput represents input parameters for skill execution.\ntype SkillInput map[string]any\n\n// GetString retrieves a string value from input.\nfunc (i SkillInput) GetString(key string) (string, bool) {\n    v, ok := i[key]\n    if !ok {\n        return \"\", false\n    }\n    s, ok := v.(string)\n    return s, ok\n}\n\n// GetInt retrieves an int value from input.\nfunc (i SkillInput) GetInt(key string) (int, bool) {\n    v, ok := i[key]\n    if !ok {\n        return 0, false\n    }\n    switch n := v.(type) {\n    case int:\n        return n, true\n    case int64:\n        return int(n), true\n    case float64:\n        return int(n), true\n    default:\n        return 0, false\n    }\n}\n\n// GetBool retrieves a bool value from input.\nfunc (i SkillInput) GetBool(key string) (bool, bool) {\n    v, ok := i[key]\n    if !ok {\n        return false, false\n    }\n    b, ok := v.(bool)\n    return b, ok\n}\n\n// SkillOutput represents the result of skill execution.\ntype SkillOutput struct {\n    Success      bool           `json:\"success\"`\n    Result       map[string]any `json:\"result,omitempty\"`\n    Error        error          `json:\"-\"`\n    ErrorMessage string         `json:\"error,omitempty\"`\n\n    // Execution metadata\n    StepsCompleted []string `json:\"stepsCompleted,omitempty\"`\n    Duration       int64    `json:\"durationMs,omitempty\"`\n}\n\n// NewSkillOutput creates a successful output.\nfunc NewSkillOutput(result map[string]any) *SkillOutput {\n    return &amp;SkillOutput{\n        Success: true,\n        Result:  result,\n    }\n}\n\n// NewSkillOutputError creates a failed output.\nfunc NewSkillOutputError(err error, message string) *SkillOutput {\n    return &amp;SkillOutput{\n        Success:      false,\n        Error:        err,\n        ErrorMessage: message,\n    }\n}\n\n// StepDefinition defines a single step within a skill.\ntype StepDefinition struct {\n    ID           string                           `json:\"id\"`\n    Name         string                           `json:\"name\"`\n    Tool         string                           `json:\"tool\"`\n    InputMapper  func(SkillContext) any           `json:\"-\"`\n    OutputMapper func(any) any                    `json:\"-\"`\n    Condition    func(SkillContext) bool          `json:\"-\"`\n    OnError      ErrorHandler                     `json:\"-\"`\n    Timeout      int64                            `json:\"timeoutMs,omitempty\"`\n    Optional     bool                             `json:\"optional,omitempty\"`\n}\n\n// ErrorHandler defines how to handle step errors.\ntype ErrorHandler func(ctx SkillContext, err error) error\n\n// SkillContext provides execution context to steps.\ntype SkillContext struct {\n    Input    SkillInput     // Original skill input\n    Results  map[string]any // Results from previous steps\n    Metadata map[string]any // Execution metadata\n    StepID   string         // Current step ID\n}\n\n// Get retrieves a value from results.\nfunc (c *SkillContext) Get(key string) (any, bool) {\n    v, ok := c.Results[key]\n    return v, ok\n}\n\n// Set stores a value in results.\nfunc (c *SkillContext) Set(key string, value any) {\n    if c.Results == nil {\n        c.Results = make(map[string]any)\n    }\n    c.Results[key] = value\n}\n</code></pre> <pre><code>// toolskill/manifest.go\npackage toolskill\n\nimport (\n    \"encoding/json\"\n    \"fmt\"\n    \"strings\"\n\n    \"github.com/Masterminds/semver/v3\"\n)\n\n// SkillManifest describes skill capabilities for discovery.\n// Aligned with A2A (Agent-to-Agent) protocol.\ntype SkillManifest struct {\n    ID          string         `json:\"id\" yaml:\"id\"`\n    Name        string         `json:\"name\" yaml:\"name\"`\n    Version     string         `json:\"version\" yaml:\"version\"`\n    Description string         `json:\"description\" yaml:\"description\"`\n    InputSchema map[string]any `json:\"inputSchema,omitempty\" yaml:\"inputSchema,omitempty\"`\n    OutputSchema map[string]any `json:\"outputSchema,omitempty\" yaml:\"outputSchema,omitempty\"`\n    Tags        []string       `json:\"tags,omitempty\" yaml:\"tags,omitempty\"`\n\n    // Dependencies\n    RequiredTools  []string `json:\"requiredTools,omitempty\" yaml:\"requiredTools,omitempty\"`\n    RequiredSkills []string `json:\"requiredSkills,omitempty\" yaml:\"requiredSkills,omitempty\"`\n\n    // Execution hints\n    EstimatedSteps int  `json:\"estimatedSteps,omitempty\" yaml:\"estimatedSteps,omitempty\"`\n    Idempotent     bool `json:\"idempotent,omitempty\" yaml:\"idempotent,omitempty\"`\n    SupportsPause  bool `json:\"supportsPause,omitempty\" yaml:\"supportsPause,omitempty\"`\n\n    // Metadata\n    Author  string         `json:\"author,omitempty\" yaml:\"author,omitempty\"`\n    License string         `json:\"license,omitempty\" yaml:\"license,omitempty\"`\n    Extra   map[string]any `json:\"metadata,omitempty\" yaml:\"metadata,omitempty\"`\n}\n\n// Validate checks if the manifest is valid.\nfunc (m *SkillManifest) Validate() error {\n    if m.ID == \"\" {\n        return fmt.Errorf(\"%w: ID is required\", ErrInvalidManifest)\n    }\n    if m.Name == \"\" {\n        return fmt.Errorf(\"%w: Name is required\", ErrInvalidManifest)\n    }\n    if m.Version == \"\" {\n        return fmt.Errorf(\"%w: Version is required\", ErrInvalidManifest)\n    }\n    if _, err := semver.NewVersion(m.Version); err != nil {\n        return fmt.Errorf(\"%w: invalid version %q: %v\", ErrInvalidManifest, m.Version, err)\n    }\n    if m.Description == \"\" {\n        return fmt.Errorf(\"%w: Description is required\", ErrInvalidManifest)\n    }\n    // Per SKILL.md standard, description should start with \"Use when\"\n    if !strings.HasPrefix(strings.ToLower(m.Description), \"use when\") {\n        return fmt.Errorf(\"%w: Description must start with 'Use when' per SKILL.md standard\", ErrInvalidManifest)\n    }\n    return nil\n}\n\n// SemVer returns the parsed semantic version.\nfunc (m *SkillManifest) SemVer() (*semver.Version, error) {\n    return semver.NewVersion(m.Version)\n}\n\n// ToJSON serializes the manifest to JSON.\nfunc (m *SkillManifest) ToJSON() ([]byte, error) {\n    return json.MarshalIndent(m, \"\", \"  \")\n}\n\n// ManifestFromJSON deserializes a manifest from JSON.\nfunc ManifestFromJSON(data []byte) (*SkillManifest, error) {\n    var m SkillManifest\n    if err := json.Unmarshal(data, &amp;m); err != nil {\n        return nil, fmt.Errorf(\"failed to parse manifest: %w\", err)\n    }\n    return &amp;m, nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v -run TestSkill</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolskill/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolskill): add core types and Skill interface\n\n- Add Skill interface with ID, Name, Version, Manifest, Execute\n- Add SkillManifest type with A2A-aligned fields\n- Add SkillInput/SkillOutput types with helpers\n- Add StepDefinition for workflow steps\n- Add SkillContext for execution context\n- Validate manifest per SKILL.md standard (description starts with \"Use when\")\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#task-2-skillmd-parser","title":"Task 2: SKILL.md Parser","text":"<p>Files: - Create: <code>toolskill/skillmd/parser.go</code> - Test: <code>toolskill/skillmd/parser_test.go</code></p> <p>Step 1: Write the failing test</p> <pre><code>// toolskill/skillmd/parser_test.go\npackage skillmd\n\nimport (\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc TestParser_Parse(t *testing.T) {\n    content := `---\nname: research-tool\ndescription: Use when researching tools in a codebase\nmetadata:\n  author: metatools\n  version: \"1.0.0\"\n---\n\n# Research Tool\n\n## Overview\n\nDiscovers and analyzes tools in a codebase.\n\n## When to Use\n\n- When exploring unfamiliar codebases\n- When looking for specific tool capabilities\n\n## How It Works\n\n1. Search for tools matching query\n2. Get detailed documentation\n3. Summarize findings\n`\n\n    parser := NewParser()\n    skill, err := parser.ParseBytes([]byte(content))\n    require.NoError(t, err)\n\n    assert.Equal(t, \"research-tool\", skill.Name)\n    assert.Equal(t, \"Use when researching tools in a codebase\", skill.Description)\n    assert.Equal(t, \"metatools\", skill.Metadata[\"author\"])\n    assert.Equal(t, \"1.0.0\", skill.Metadata[\"version\"])\n    assert.Contains(t, skill.Overview, \"Discovers and analyzes\")\n    assert.Contains(t, skill.WhenToUse, \"exploring unfamiliar\")\n    assert.Contains(t, skill.HowItWorks, \"Search for tools\")\n}\n\nfunc TestParser_ParseMinimal(t *testing.T) {\n    content := `---\nname: simple-skill\ndescription: Use when doing simple things\n---\n\n# Simple Skill\n\nBasic skill content.\n`\n\n    parser := NewParser()\n    skill, err := parser.ParseBytes([]byte(content))\n    require.NoError(t, err)\n\n    assert.Equal(t, \"simple-skill\", skill.Name)\n    assert.Equal(t, \"Use when doing simple things\", skill.Description)\n    assert.Empty(t, skill.Metadata)\n}\n\nfunc TestParser_ParseMissingFrontmatter(t *testing.T) {\n    content := `# No Frontmatter\n\nJust markdown content.\n`\n\n    parser := NewParser()\n    _, err := parser.ParseBytes([]byte(content))\n    assert.Error(t, err)\n    assert.Contains(t, err.Error(), \"frontmatter\")\n}\n\nfunc TestParser_ParseMissingName(t *testing.T) {\n    content := `---\ndescription: Use when testing\n---\n\n# Test\n`\n\n    parser := NewParser()\n    _, err := parser.ParseBytes([]byte(content))\n    assert.Error(t, err)\n    assert.Contains(t, err.Error(), \"name\")\n}\n\nfunc TestParser_ParseMissingDescription(t *testing.T) {\n    content := `---\nname: test-skill\n---\n\n# Test\n`\n\n    parser := NewParser()\n    _, err := parser.ParseBytes([]byte(content))\n    assert.Error(t, err)\n    assert.Contains(t, err.Error(), \"description\")\n}\n\nfunc TestParser_Validate(t *testing.T) {\n    parser := NewParser()\n\n    tests := []struct {\n        name    string\n        skill   *SkillMD\n        wantErr bool\n    }{\n        {\n            name: \"valid skill\",\n            skill: &amp;SkillMD{\n                Name:        \"valid-skill\",\n                Description: \"Use when testing validation\",\n            },\n            wantErr: false,\n        },\n        {\n            name: \"invalid name with spaces\",\n            skill: &amp;SkillMD{\n                Name:        \"invalid skill name\",\n                Description: \"Use when testing\",\n            },\n            wantErr: true,\n        },\n        {\n            name: \"description not starting with Use when\",\n            skill: &amp;SkillMD{\n                Name:        \"skill\",\n                Description: \"Does something cool\",\n            },\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            errs := parser.Validate(tt.skill)\n            if tt.wantErr {\n                assert.NotEmpty(t, errs)\n            } else {\n                assert.Empty(t, errs)\n            }\n        })\n    }\n}\n\nfunc TestSkillMD_ToManifest(t *testing.T) {\n    skill := &amp;SkillMD{\n        Name:        \"test-skill\",\n        Description: \"Use when testing manifest conversion\",\n        Metadata: map[string]any{\n            \"version\": \"2.0.0\",\n            \"author\":  \"test\",\n        },\n    }\n\n    manifest := skill.ToManifest()\n    assert.Equal(t, \"test-skill\", manifest.ID)\n    assert.Equal(t, \"test-skill\", manifest.Name)\n    assert.Equal(t, \"2.0.0\", manifest.Version)\n    assert.Equal(t, \"Use when testing manifest conversion\", manifest.Description)\n    assert.Equal(t, \"test\", manifest.Author)\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v ./skillmd/...</code> Expected: FAIL with \"package toolskill/skillmd is not in std\"</p> <p>Step 3: Write minimal implementation</p> <pre><code>// toolskill/skillmd/parser.go\npackage skillmd\n\nimport (\n    \"bytes\"\n    \"errors\"\n    \"fmt\"\n    \"os\"\n    \"regexp\"\n    \"strings\"\n\n    \"gopkg.in/yaml.v3\"\n\n    \"github.com/yourusername/toolskill\"\n)\n\n// SkillMD represents a parsed SKILL.md file.\ntype SkillMD struct {\n    // YAML Frontmatter (required)\n    Name        string         `yaml:\"name\"`\n    Description string         `yaml:\"description\"`\n    License     string         `yaml:\"license,omitempty\"`\n    Metadata    map[string]any `yaml:\"metadata,omitempty\"`\n\n    // Parsed Content\n    Content    string            // Raw markdown content (after frontmatter)\n    Overview   string            // Extracted ## Overview section\n    WhenToUse  string            // Extracted ## When to Use section\n    HowItWorks string            // Extracted ## How It Works section\n    Sections   map[string]string // All other sections\n}\n\n// ToManifest converts SkillMD to a SkillManifest.\nfunc (s *SkillMD) ToManifest() *toolskill.SkillManifest {\n    version := \"1.0.0\"\n    author := \"\"\n\n    if s.Metadata != nil {\n        if v, ok := s.Metadata[\"version\"].(string); ok {\n            version = v\n        }\n        if a, ok := s.Metadata[\"author\"].(string); ok {\n            author = a\n        }\n    }\n\n    return &amp;toolskill.SkillManifest{\n        ID:          s.Name,\n        Name:        s.Name,\n        Version:     version,\n        Description: s.Description,\n        Author:      author,\n        License:     s.License,\n        Extra:       s.Metadata,\n    }\n}\n\n// ValidationError represents a validation issue.\ntype ValidationError struct {\n    Field   string\n    Message string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"%s: %s\", e.Field, e.Message)\n}\n\n// Parser reads and parses SKILL.md files.\ntype Parser struct {\n    // strictMode enforces all validations\n    strictMode bool\n}\n\n// NewParser creates a new SKILL.md parser.\nfunc NewParser() *Parser {\n    return &amp;Parser{strictMode: true}\n}\n\n// NewLenientParser creates a parser that allows some validation failures.\nfunc NewLenientParser() *Parser {\n    return &amp;Parser{strictMode: false}\n}\n\n// Parse reads and parses a SKILL.md file from path.\nfunc (p *Parser) Parse(path string) (*SkillMD, error) {\n    data, err := os.ReadFile(path)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to read skill file: %w\", err)\n    }\n    return p.ParseBytes(data)\n}\n\n// ParseBytes parses SKILL.md content from bytes.\nfunc (p *Parser) ParseBytes(data []byte) (*SkillMD, error) {\n    // Split frontmatter from content\n    frontmatter, content, err := splitFrontmatter(data)\n    if err != nil {\n        return nil, err\n    }\n\n    // Parse YAML frontmatter\n    var skill SkillMD\n    if err := yaml.Unmarshal(frontmatter, &amp;skill); err != nil {\n        return nil, fmt.Errorf(\"failed to parse frontmatter: %w\", err)\n    }\n\n    // Validate required fields\n    if skill.Name == \"\" {\n        return nil, errors.New(\"skill name is required in frontmatter\")\n    }\n    if skill.Description == \"\" {\n        return nil, errors.New(\"skill description is required in frontmatter\")\n    }\n\n    // Store raw content\n    skill.Content = string(content)\n\n    // Extract standard sections\n    skill.Sections = extractSections(content)\n    skill.Overview = skill.Sections[\"overview\"]\n    skill.WhenToUse = skill.Sections[\"when to use\"]\n    skill.HowItWorks = skill.Sections[\"how it works\"]\n\n    return &amp;skill, nil\n}\n\n// Validate checks a SkillMD for issues.\nfunc (p *Parser) Validate(skill *SkillMD) []ValidationError {\n    var errs []ValidationError\n\n    // Name must be lowercase with hyphens only\n    namePattern := regexp.MustCompile(`^[a-z][a-z0-9-]*[a-z0-9]$|^[a-z]$`)\n    if !namePattern.MatchString(skill.Name) {\n        errs = append(errs, ValidationError{\n            Field:   \"name\",\n            Message: \"must be lowercase with hyphens (e.g., 'my-skill')\",\n        })\n    }\n\n    // Description must start with \"Use when\"\n    if !strings.HasPrefix(strings.ToLower(skill.Description), \"use when\") {\n        errs = append(errs, ValidationError{\n            Field:   \"description\",\n            Message: \"must start with 'Use when' per SKILL.md standard\",\n        })\n    }\n\n    return errs\n}\n\n// splitFrontmatter separates YAML frontmatter from markdown content.\nfunc splitFrontmatter(data []byte) ([]byte, []byte, error) {\n    const delimiter = \"---\"\n\n    // Must start with ---\n    if !bytes.HasPrefix(data, []byte(delimiter)) {\n        return nil, nil, errors.New(\"SKILL.md must start with YAML frontmatter (---)\")\n    }\n\n    // Find closing ---\n    rest := data[len(delimiter):]\n    idx := bytes.Index(rest, []byte(\"\\n\"+delimiter))\n    if idx == -1 {\n        return nil, nil, errors.New(\"SKILL.md frontmatter not closed (missing ---)\")\n    }\n\n    frontmatter := rest[:idx]\n    content := rest[idx+len(delimiter)+1:] // Skip newline + ---\n\n    // Skip leading newlines from content\n    content = bytes.TrimLeft(content, \"\\n\")\n\n    return frontmatter, content, nil\n}\n\n// extractSections parses markdown content into named sections.\nfunc extractSections(content []byte) map[string]string {\n    sections := make(map[string]string)\n    lines := strings.Split(string(content), \"\\n\")\n\n    var currentSection string\n    var currentContent strings.Builder\n\n    for _, line := range lines {\n        // Check for ## heading\n        if strings.HasPrefix(line, \"## \") {\n            // Save previous section\n            if currentSection != \"\" {\n                sections[strings.ToLower(currentSection)] = strings.TrimSpace(currentContent.String())\n            }\n\n            // Start new section\n            currentSection = strings.TrimPrefix(line, \"## \")\n            currentContent.Reset()\n        } else if currentSection != \"\" {\n            currentContent.WriteString(line)\n            currentContent.WriteString(\"\\n\")\n        }\n    }\n\n    // Save last section\n    if currentSection != \"\" {\n        sections[strings.ToLower(currentSection)] = strings.TrimSpace(currentContent.String())\n    }\n\n    return sections\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v ./skillmd/...</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolskill/skillmd/\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolskill): add SKILL.md parser\n\n- Add SkillMD type representing parsed SKILL.md files\n- Add Parser with Parse and ParseBytes methods\n- Extract YAML frontmatter (name, description, metadata)\n- Extract standard sections (Overview, When to Use, How It Works)\n- Add validation for SKILL.md standard compliance\n- Add ToManifest conversion helper\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#task-3-skill-registry","title":"Task 3: Skill Registry","text":"<p>Files: - Create: <code>toolskill/registry.go</code> - Test: <code>toolskill/registry_test.go</code></p> <p>Step 1: Write the failing test</p> <pre><code>// toolskill/registry_test.go\npackage toolskill\n\nimport (\n    \"testing\"\n\n    \"github.com/Masterminds/semver/v3\"\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc newTestSkill(id, name, version string, tags []string) *mockSkill {\n    ver, _ := semver.NewVersion(version)\n    return &amp;mockSkill{\n        id:      id,\n        name:    name,\n        version: ver,\n        manifest: &amp;SkillManifest{\n            ID:          id,\n            Name:        name,\n            Version:     version,\n            Description: \"Use when testing \" + name,\n            Tags:        tags,\n        },\n    }\n}\n\nfunc TestRegistry_Register(t *testing.T) {\n    reg := NewRegistry()\n\n    skill := newTestSkill(\"research-v1\", \"research\", \"1.0.0\", []string{\"discovery\"})\n\n    err := reg.Register(skill)\n    require.NoError(t, err)\n\n    // Verify registration\n    got, err := reg.Get(\"research-v1\")\n    require.NoError(t, err)\n    assert.Equal(t, \"research-v1\", got.ID())\n}\n\nfunc TestRegistry_RegisterDuplicate(t *testing.T) {\n    reg := NewRegistry()\n\n    skill := newTestSkill(\"research-v1\", \"research\", \"1.0.0\", nil)\n\n    err := reg.Register(skill)\n    require.NoError(t, err)\n\n    // Duplicate registration should fail\n    err = reg.Register(skill)\n    assert.Error(t, err)\n    assert.ErrorIs(t, err, ErrSkillAlreadyRegistered)\n}\n\nfunc TestRegistry_Get(t *testing.T) {\n    reg := NewRegistry()\n    skill := newTestSkill(\"my-skill\", \"my-skill\", \"1.0.0\", nil)\n    _ = reg.Register(skill)\n\n    got, err := reg.Get(\"my-skill\")\n    require.NoError(t, err)\n    assert.Equal(t, \"my-skill\", got.ID())\n}\n\nfunc TestRegistry_GetNotFound(t *testing.T) {\n    reg := NewRegistry()\n\n    _, err := reg.Get(\"nonexistent\")\n    assert.Error(t, err)\n    assert.ErrorIs(t, err, ErrSkillNotFound)\n}\n\nfunc TestRegistry_GetByName(t *testing.T) {\n    reg := NewRegistry()\n\n    // Register multiple versions\n    v1 := newTestSkill(\"research-v1\", \"research\", \"1.0.0\", nil)\n    v2 := newTestSkill(\"research-v2\", \"research\", \"2.0.0\", nil)\n    v3 := newTestSkill(\"research-v3\", \"research\", \"3.0.0\", nil)\n\n    _ = reg.Register(v1)\n    _ = reg.Register(v2)\n    _ = reg.Register(v3)\n\n    // Get latest (no constraint)\n    got, err := reg.GetByName(\"research\", \"\")\n    require.NoError(t, err)\n    assert.Equal(t, \"3.0.0\", got.Version().String())\n\n    // Get with constraint\n    got, err = reg.GetByName(\"research\", \"&gt;=1.0.0 &lt;2.0.0\")\n    require.NoError(t, err)\n    assert.Equal(t, \"1.0.0\", got.Version().String())\n\n    // Get with ^2 constraint\n    got, err = reg.GetByName(\"research\", \"^2.0.0\")\n    require.NoError(t, err)\n    assert.Equal(t, \"2.0.0\", got.Version().String())\n}\n\nfunc TestRegistry_GetByNameNotFound(t *testing.T) {\n    reg := NewRegistry()\n\n    _, err := reg.GetByName(\"nonexistent\", \"\")\n    assert.Error(t, err)\n    assert.ErrorIs(t, err, ErrSkillNotFound)\n}\n\nfunc TestRegistry_List(t *testing.T) {\n    reg := NewRegistry()\n\n    s1 := newTestSkill(\"skill-a\", \"skill-a\", \"1.0.0\", nil)\n    s2 := newTestSkill(\"skill-b\", \"skill-b\", \"1.0.0\", nil)\n\n    _ = reg.Register(s1)\n    _ = reg.Register(s2)\n\n    manifests := reg.List()\n    assert.Len(t, manifests, 2)\n\n    ids := make([]string, len(manifests))\n    for i, m := range manifests {\n        ids[i] = m.ID\n    }\n    assert.Contains(t, ids, \"skill-a\")\n    assert.Contains(t, ids, \"skill-b\")\n}\n\nfunc TestRegistry_ListByTag(t *testing.T) {\n    reg := NewRegistry()\n\n    s1 := newTestSkill(\"search-skill\", \"search-skill\", \"1.0.0\", []string{\"discovery\", \"search\"})\n    s2 := newTestSkill(\"code-skill\", \"code-skill\", \"1.0.0\", []string{\"code\", \"execution\"})\n    s3 := newTestSkill(\"explore-skill\", \"explore-skill\", \"1.0.0\", []string{\"discovery\", \"exploration\"})\n\n    _ = reg.Register(s1)\n    _ = reg.Register(s2)\n    _ = reg.Register(s3)\n\n    // Filter by tag\n    results := reg.ListByTag(\"discovery\")\n    assert.Len(t, results, 2)\n\n    results = reg.ListByTag(\"code\")\n    assert.Len(t, results, 1)\n    assert.Equal(t, \"code-skill\", results[0].ID)\n\n    results = reg.ListByTag(\"nonexistent\")\n    assert.Len(t, results, 0)\n}\n\nfunc TestRegistry_Unregister(t *testing.T) {\n    reg := NewRegistry()\n\n    skill := newTestSkill(\"to-remove\", \"to-remove\", \"1.0.0\", nil)\n    _ = reg.Register(skill)\n\n    err := reg.Unregister(\"to-remove\")\n    require.NoError(t, err)\n\n    _, err = reg.Get(\"to-remove\")\n    assert.ErrorIs(t, err, ErrSkillNotFound)\n}\n\nfunc TestRegistry_UnregisterNotFound(t *testing.T) {\n    reg := NewRegistry()\n\n    err := reg.Unregister(\"nonexistent\")\n    assert.ErrorIs(t, err, ErrSkillNotFound)\n}\n\nfunc TestRegistry_Advertise(t *testing.T) {\n    reg := NewRegistry()\n\n    s1 := newTestSkill(\"public-skill\", \"public-skill\", \"1.0.0\", nil)\n    _ = reg.Register(s1)\n\n    manifests := reg.Advertise()\n    assert.Len(t, manifests, 1)\n    assert.Equal(t, \"public-skill\", manifests[0].ID)\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v -run TestRegistry</code> Expected: FAIL with \"undefined: NewRegistry\"</p> <p>Step 3: Write minimal implementation</p> <pre><code>// toolskill/registry.go\npackage toolskill\n\nimport (\n    \"errors\"\n    \"fmt\"\n    \"sort\"\n    \"sync\"\n\n    \"github.com/Masterminds/semver/v3\"\n)\n\nvar (\n    ErrSkillAlreadyRegistered = errors.New(\"skill already registered\")\n)\n\n// SkillRegistry manages skill discovery and lookup.\ntype SkillRegistry interface {\n    Register(skill Skill) error\n    Get(id string) (Skill, error)\n    GetByName(name string, versionConstraint string) (Skill, error)\n    List() []SkillManifest\n    ListByTag(tag string) []SkillManifest\n    Unregister(id string) error\n\n    // Discovery for A2A\n    Advertise() []SkillManifest\n}\n\n// Registry is the default implementation of SkillRegistry.\ntype Registry struct {\n    mu     sync.RWMutex\n    skills map[string]Skill // id -&gt; skill\n    byName map[string][]Skill // name -&gt; skills (multiple versions)\n}\n\n// NewRegistry creates a new skill registry.\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        skills: make(map[string]Skill),\n        byName: make(map[string][]Skill),\n    }\n}\n\n// Register adds a skill to the registry.\nfunc (r *Registry) Register(skill Skill) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    id := skill.ID()\n    if _, exists := r.skills[id]; exists {\n        return fmt.Errorf(\"%w: %s\", ErrSkillAlreadyRegistered, id)\n    }\n\n    r.skills[id] = skill\n    r.byName[skill.Name()] = append(r.byName[skill.Name()], skill)\n\n    return nil\n}\n\n// Get retrieves a skill by ID.\nfunc (r *Registry) Get(id string) (Skill, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    skill, ok := r.skills[id]\n    if !ok {\n        return nil, fmt.Errorf(\"%w: %s\", ErrSkillNotFound, id)\n    }\n    return skill, nil\n}\n\n// GetByName retrieves a skill by name with optional version constraint.\n// If constraint is empty, returns the latest version.\nfunc (r *Registry) GetByName(name string, versionConstraint string) (Skill, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    skills, ok := r.byName[name]\n    if !ok || len(skills) == 0 {\n        return nil, fmt.Errorf(\"%w: no skill named %q\", ErrSkillNotFound, name)\n    }\n\n    // No constraint - return latest\n    if versionConstraint == \"\" {\n        return r.latestVersion(skills), nil\n    }\n\n    // Parse constraint\n    constraint, err := semver.NewConstraint(versionConstraint)\n    if err != nil {\n        return nil, fmt.Errorf(\"invalid version constraint: %w\", err)\n    }\n\n    // Find matching versions\n    var matching []Skill\n    for _, s := range skills {\n        if constraint.Check(s.Version()) {\n            matching = append(matching, s)\n        }\n    }\n\n    if len(matching) == 0 {\n        return nil, fmt.Errorf(\"%w: no skill %q matching constraint %q\", ErrSkillNotFound, name, versionConstraint)\n    }\n\n    return r.latestVersion(matching), nil\n}\n\n// latestVersion returns the skill with highest version.\nfunc (r *Registry) latestVersion(skills []Skill) Skill {\n    if len(skills) == 1 {\n        return skills[0]\n    }\n\n    sorted := make([]Skill, len(skills))\n    copy(sorted, skills)\n\n    sort.Slice(sorted, func(i, j int) bool {\n        return sorted[i].Version().GreaterThan(sorted[j].Version())\n    })\n\n    return sorted[0]\n}\n\n// List returns all registered skill manifests.\nfunc (r *Registry) List() []SkillManifest {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    manifests := make([]SkillManifest, 0, len(r.skills))\n    for _, skill := range r.skills {\n        manifests = append(manifests, *skill.Manifest())\n    }\n\n    // Sort by ID for deterministic order\n    sort.Slice(manifests, func(i, j int) bool {\n        return manifests[i].ID &lt; manifests[j].ID\n    })\n\n    return manifests\n}\n\n// ListByTag returns skills that have the specified tag.\nfunc (r *Registry) ListByTag(tag string) []SkillManifest {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    var manifests []SkillManifest\n    for _, skill := range r.skills {\n        m := skill.Manifest()\n        for _, t := range m.Tags {\n            if t == tag {\n                manifests = append(manifests, *m)\n                break\n            }\n        }\n    }\n\n    sort.Slice(manifests, func(i, j int) bool {\n        return manifests[i].ID &lt; manifests[j].ID\n    })\n\n    return manifests\n}\n\n// Unregister removes a skill from the registry.\nfunc (r *Registry) Unregister(id string) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    skill, ok := r.skills[id]\n    if !ok {\n        return fmt.Errorf(\"%w: %s\", ErrSkillNotFound, id)\n    }\n\n    delete(r.skills, id)\n\n    // Remove from byName\n    name := skill.Name()\n    skills := r.byName[name]\n    for i, s := range skills {\n        if s.ID() == id {\n            r.byName[name] = append(skills[:i], skills[i+1:]...)\n            break\n        }\n    }\n    if len(r.byName[name]) == 0 {\n        delete(r.byName, name)\n    }\n\n    return nil\n}\n\n// Advertise returns manifests for A2A discovery.\nfunc (r *Registry) Advertise() []SkillManifest {\n    return r.List()\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v -run TestRegistry</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolskill/registry.go toolskill/registry_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolskill): add skill registry with version resolution\n\n- Add SkillRegistry interface for skill management\n- Add Registry implementation with thread-safe operations\n- Support version constraints via semver\n- Add GetByName with constraint resolution (^2.0.0, &gt;=1.0.0 &lt;2.0.0)\n- Add ListByTag for tag-based filtering\n- Add Advertise for A2A protocol discovery\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#task-4-skill-builder-and-composition","title":"Task 4: Skill Builder and Composition","text":"<p>Files: - Create: <code>toolskill/builder.go</code> - Test: <code>toolskill/builder_test.go</code></p> <p>Step 1: Write the failing test</p> <pre><code>// toolskill/builder_test.go\npackage toolskill\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc TestBuilder_Basic(t *testing.T) {\n    skill, err := NewBuilder(\"research-skill\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when researching topics\").\n        WithTags(\"research\", \"discovery\").\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, \"research-skill\", skill.ID())\n    assert.Equal(t, \"research-skill\", skill.Name())\n    assert.Equal(t, \"1.0.0\", skill.Version().String())\n    assert.Equal(t, \"Use when researching topics\", skill.Manifest().Description)\n    assert.Contains(t, skill.Manifest().Tags, \"research\")\n}\n\nfunc TestBuilder_WithSteps(t *testing.T) {\n    skill, err := NewBuilder(\"multi-step\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when doing multi-step work\").\n        Step(\"search\", \"search_tools\").\n            WithInputMapper(func(ctx SkillContext) any {\n                query, _ := ctx.Input.GetString(\"query\")\n                return map[string]any{\"query\": query}\n            }).\n            Done().\n        Step(\"describe\", \"describe_tool\").\n            WithInputMapper(func(ctx SkillContext) any {\n                // Get first result from search\n                return map[string]any{\"tool\": \"result\"}\n            }).\n            Done().\n        Build()\n\n    require.NoError(t, err)\n    assert.Len(t, skill.Steps(), 2)\n    assert.Equal(t, \"search\", skill.Steps()[0].ID)\n    assert.Equal(t, \"describe\", skill.Steps()[1].ID)\n}\n\nfunc TestBuilder_RequiredTools(t *testing.T) {\n    skill, err := NewBuilder(\"tool-user\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when using tools\").\n        RequireTools(\"search_tools\", \"describe_tool\", \"run_tool\").\n        Build()\n\n    require.NoError(t, err)\n    tools := skill.RequiredTools()\n    assert.Len(t, tools, 3)\n    assert.Contains(t, tools, \"search_tools\")\n}\n\nfunc TestBuilder_Conditional(t *testing.T) {\n    skill, err := NewBuilder(\"conditional-skill\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing conditions\").\n        Step(\"maybe-run\", \"some_tool\").\n            WithCondition(func(ctx SkillContext) bool {\n                enabled, _ := ctx.Input.GetBool(\"enabled\")\n                return enabled\n            }).\n            Done().\n        Build()\n\n    require.NoError(t, err)\n    assert.Len(t, skill.Steps(), 1)\n    assert.NotNil(t, skill.Steps()[0].Condition)\n}\n\nfunc TestBuilder_ValidationFailure(t *testing.T) {\n    _, err := NewBuilder(\"\").\n        WithVersion(\"1.0.0\").\n        Build()\n\n    assert.Error(t, err)\n    assert.Contains(t, err.Error(), \"name\")\n}\n\nfunc TestBuilder_MissingVersion(t *testing.T) {\n    _, err := NewBuilder(\"test-skill\").\n        WithDescription(\"Use when testing\").\n        Build()\n\n    assert.Error(t, err)\n    assert.Contains(t, err.Error(), \"version\")\n}\n\nfunc TestBuilder_MissingDescription(t *testing.T) {\n    _, err := NewBuilder(\"test-skill\").\n        WithVersion(\"1.0.0\").\n        Build()\n\n    assert.Error(t, err)\n    assert.Contains(t, err.Error(), \"description\")\n}\n\nfunc TestBuilder_InputOutputSchema(t *testing.T) {\n    inputSchema := map[string]any{\n        \"type\": \"object\",\n        \"properties\": map[string]any{\n            \"query\": map[string]any{\"type\": \"string\"},\n        },\n        \"required\": []string{\"query\"},\n    }\n\n    skill, err := NewBuilder(\"schema-skill\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing schemas\").\n        WithInputSchema(inputSchema).\n        Build()\n\n    require.NoError(t, err)\n    assert.Equal(t, inputSchema, skill.Manifest().InputSchema)\n}\n\nfunc TestCompositeSkill_Execute(t *testing.T) {\n    // Create a simple skill with two steps\n    skill, err := NewBuilder(\"test-execution\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing execution\").\n        Step(\"step1\", \"tool1\").\n            WithInputMapper(func(ctx SkillContext) any {\n                return map[string]any{\"from\": \"step1\"}\n            }).\n            Done().\n        Build()\n\n    require.NoError(t, err)\n\n    // Execute - will fail because no runtime, but structure should be valid\n    output, err := skill.Execute(context.Background(), SkillInput{\"test\": true})\n\n    // Without a configured runtime, execution returns error\n    assert.Error(t, err)\n    assert.Nil(t, output)\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v -run TestBuilder</code> Expected: FAIL with \"undefined: NewBuilder\"</p> <p>Step 3: Write minimal implementation</p> <pre><code>// toolskill/builder.go\npackage toolskill\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/Masterminds/semver/v3\"\n)\n\n// Builder provides a fluent API for building skills.\ntype Builder struct {\n    name          string\n    version       string\n    description   string\n    tags          []string\n    requiredTools []string\n    inputSchema   map[string]any\n    outputSchema  map[string]any\n    steps         []StepDefinition\n    idempotent    bool\n    supportsPause bool\n    author        string\n}\n\n// NewBuilder creates a new skill builder.\nfunc NewBuilder(name string) *Builder {\n    return &amp;Builder{\n        name:          name,\n        tags:          []string{},\n        requiredTools: []string{},\n        steps:         []StepDefinition{},\n    }\n}\n\n// WithVersion sets the skill version.\nfunc (b *Builder) WithVersion(version string) *Builder {\n    b.version = version\n    return b\n}\n\n// WithDescription sets the skill description.\nfunc (b *Builder) WithDescription(desc string) *Builder {\n    b.description = desc\n    return b\n}\n\n// WithTags adds tags to the skill.\nfunc (b *Builder) WithTags(tags ...string) *Builder {\n    b.tags = append(b.tags, tags...)\n    return b\n}\n\n// RequireTools specifies tools this skill depends on.\nfunc (b *Builder) RequireTools(tools ...string) *Builder {\n    b.requiredTools = append(b.requiredTools, tools...)\n    return b\n}\n\n// WithInputSchema sets the input JSON schema.\nfunc (b *Builder) WithInputSchema(schema map[string]any) *Builder {\n    b.inputSchema = schema\n    return b\n}\n\n// WithOutputSchema sets the output JSON schema.\nfunc (b *Builder) WithOutputSchema(schema map[string]any) *Builder {\n    b.outputSchema = schema\n    return b\n}\n\n// WithAuthor sets the skill author.\nfunc (b *Builder) WithAuthor(author string) *Builder {\n    b.author = author\n    return b\n}\n\n// Idempotent marks the skill as idempotent.\nfunc (b *Builder) Idempotent() *Builder {\n    b.idempotent = true\n    return b\n}\n\n// SupportsPause marks the skill as supporting pause/resume.\nfunc (b *Builder) SupportsPause() *Builder {\n    b.supportsPause = true\n    return b\n}\n\n// Step begins defining a new step.\nfunc (b *Builder) Step(id, tool string) *StepBuilder {\n    return &amp;StepBuilder{\n        parent: b,\n        step: StepDefinition{\n            ID:   id,\n            Name: id,\n            Tool: tool,\n        },\n    }\n}\n\n// Build creates the skill from the builder configuration.\nfunc (b *Builder) Build() (Skill, error) {\n    // Validation\n    if b.name == \"\" {\n        return nil, fmt.Errorf(\"skill name is required\")\n    }\n    if b.version == \"\" {\n        return nil, fmt.Errorf(\"skill version is required\")\n    }\n    if b.description == \"\" {\n        return nil, fmt.Errorf(\"skill description is required\")\n    }\n\n    ver, err := semver.NewVersion(b.version)\n    if err != nil {\n        return nil, fmt.Errorf(\"invalid version: %w\", err)\n    }\n\n    // Collect tool names from steps\n    toolSet := make(map[string]bool)\n    for _, tool := range b.requiredTools {\n        toolSet[tool] = true\n    }\n    for _, step := range b.steps {\n        if step.Tool != \"\" {\n            toolSet[step.Tool] = true\n        }\n    }\n    tools := make([]string, 0, len(toolSet))\n    for tool := range toolSet {\n        tools = append(tools, tool)\n    }\n\n    manifest := &amp;SkillManifest{\n        ID:             b.name,\n        Name:           b.name,\n        Version:        b.version,\n        Description:    b.description,\n        Tags:           b.tags,\n        RequiredTools:  tools,\n        InputSchema:    b.inputSchema,\n        OutputSchema:   b.outputSchema,\n        EstimatedSteps: len(b.steps),\n        Idempotent:     b.idempotent,\n        SupportsPause:  b.supportsPause,\n        Author:         b.author,\n    }\n\n    return &amp;CompositeSkill{\n        id:       b.name,\n        name:     b.name,\n        version:  ver,\n        manifest: manifest,\n        steps:    b.steps,\n        tools:    tools,\n    }, nil\n}\n\n// StepBuilder builds individual steps.\ntype StepBuilder struct {\n    parent *Builder\n    step   StepDefinition\n}\n\n// WithName sets the step display name.\nfunc (sb *StepBuilder) WithName(name string) *StepBuilder {\n    sb.step.Name = name\n    return sb\n}\n\n// WithInputMapper sets how to transform skill context to tool input.\nfunc (sb *StepBuilder) WithInputMapper(mapper func(SkillContext) any) *StepBuilder {\n    sb.step.InputMapper = mapper\n    return sb\n}\n\n// WithOutputMapper sets how to transform tool output.\nfunc (sb *StepBuilder) WithOutputMapper(mapper func(any) any) *StepBuilder {\n    sb.step.OutputMapper = mapper\n    return sb\n}\n\n// WithCondition sets a condition for step execution.\nfunc (sb *StepBuilder) WithCondition(cond func(SkillContext) bool) *StepBuilder {\n    sb.step.Condition = cond\n    return sb\n}\n\n// WithTimeout sets step timeout in milliseconds.\nfunc (sb *StepBuilder) WithTimeout(ms int64) *StepBuilder {\n    sb.step.Timeout = ms\n    return sb\n}\n\n// Optional marks the step as optional (continue on failure).\nfunc (sb *StepBuilder) Optional() *StepBuilder {\n    sb.step.Optional = true\n    return sb\n}\n\n// OnError sets the error handler.\nfunc (sb *StepBuilder) OnError(handler ErrorHandler) *StepBuilder {\n    sb.step.OnError = handler\n    return sb\n}\n\n// Done finishes step configuration and returns to the builder.\nfunc (sb *StepBuilder) Done() *Builder {\n    sb.parent.steps = append(sb.parent.steps, sb.step)\n    return sb.parent\n}\n\n// CompositeSkill is a skill built from steps.\ntype CompositeSkill struct {\n    id       string\n    name     string\n    version  *semver.Version\n    manifest *SkillManifest\n    steps    []StepDefinition\n    tools    []string\n    runtime  SkillRuntime\n}\n\nfunc (s *CompositeSkill) ID() string               { return s.id }\nfunc (s *CompositeSkill) Name() string             { return s.name }\nfunc (s *CompositeSkill) Version() *semver.Version { return s.version }\nfunc (s *CompositeSkill) Manifest() *SkillManifest { return s.manifest }\nfunc (s *CompositeSkill) RequiredTools() []string  { return s.tools }\nfunc (s *CompositeSkill) Steps() []StepDefinition  { return s.steps }\n\n// SetRuntime configures the runtime for execution.\nfunc (s *CompositeSkill) SetRuntime(rt SkillRuntime) {\n    s.runtime = rt\n}\n\n// Execute runs the skill with the given input.\nfunc (s *CompositeSkill) Execute(ctx context.Context, input SkillInput) (*SkillOutput, error) {\n    if s.runtime == nil {\n        return nil, fmt.Errorf(\"skill runtime not configured\")\n    }\n    return s.runtime.Execute(ctx, s, input)\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v -run TestBuilder</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolskill/builder.go toolskill/builder_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolskill): add fluent builder for skill composition\n\n- Add Builder with fluent API for skill creation\n- Add StepBuilder for defining workflow steps\n- Support input/output mappers for data transformation\n- Support conditional step execution\n- Support step timeouts and optional steps\n- Add CompositeSkill implementation\n- Extract required tools from steps automatically\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#task-5-skill-runtime","title":"Task 5: Skill Runtime","text":"<p>Files: - Create: <code>toolskill/runtime.go</code> - Test: <code>toolskill/runtime_test.go</code></p> <p>Step 1: Write the failing test</p> <pre><code>// toolskill/runtime_test.go\npackage toolskill\n\nimport (\n    \"context\"\n    \"errors\"\n    \"testing\"\n    \"time\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\n// mockToolExecutor simulates tool execution\ntype mockToolExecutor struct {\n    results map[string]any\n    errors  map[string]error\n    calls   []string\n}\n\nfunc (m *mockToolExecutor) Execute(ctx context.Context, tool string, input any) (any, error) {\n    m.calls = append(m.calls, tool)\n    if err, ok := m.errors[tool]; ok {\n        return nil, err\n    }\n    if result, ok := m.results[tool]; ok {\n        return result, nil\n    }\n    return map[string]any{\"tool\": tool, \"executed\": true}, nil\n}\n\nfunc TestRuntime_Execute(t *testing.T) {\n    executor := &amp;mockToolExecutor{\n        results: map[string]any{\n            \"search_tools\":  map[string]any{\"tools\": []string{\"tool1\", \"tool2\"}},\n            \"describe_tool\": map[string]any{\"description\": \"A test tool\"},\n        },\n    }\n\n    runtime := NewRuntime(RuntimeConfig{\n        ToolExecutor: executor,\n    })\n\n    skill, _ := NewBuilder(\"test-skill\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing runtime\").\n        Step(\"search\", \"search_tools\").\n            WithInputMapper(func(ctx SkillContext) any {\n                return map[string]any{\"query\": ctx.Input[\"query\"]}\n            }).\n            Done().\n        Step(\"describe\", \"describe_tool\").\n            WithInputMapper(func(ctx SkillContext) any {\n                return map[string]any{\"tool\": \"tool1\"}\n            }).\n            Done().\n        Build()\n\n    output, err := runtime.Execute(context.Background(), skill, SkillInput{\"query\": \"test\"})\n    require.NoError(t, err)\n    assert.True(t, output.Success)\n    assert.Len(t, output.StepsCompleted, 2)\n    assert.Contains(t, output.StepsCompleted, \"search\")\n    assert.Contains(t, output.StepsCompleted, \"describe\")\n\n    // Verify tools were called in order\n    assert.Equal(t, []string{\"search_tools\", \"describe_tool\"}, executor.calls)\n}\n\nfunc TestRuntime_ConditionalStep(t *testing.T) {\n    executor := &amp;mockToolExecutor{}\n\n    runtime := NewRuntime(RuntimeConfig{\n        ToolExecutor: executor,\n    })\n\n    skill, _ := NewBuilder(\"conditional\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing conditions\").\n        Step(\"always\", \"tool1\").Done().\n        Step(\"maybe\", \"tool2\").\n            WithCondition(func(ctx SkillContext) bool {\n                return ctx.Input[\"enabled\"] == true\n            }).\n            Done().\n        Step(\"final\", \"tool3\").Done().\n        Build()\n\n    // With condition false\n    output, err := runtime.Execute(context.Background(), skill, SkillInput{\"enabled\": false})\n    require.NoError(t, err)\n    assert.True(t, output.Success)\n    assert.Equal(t, []string{\"tool1\", \"tool3\"}, executor.calls) // tool2 skipped\n\n    // With condition true\n    executor.calls = nil\n    output, err = runtime.Execute(context.Background(), skill, SkillInput{\"enabled\": true})\n    require.NoError(t, err)\n    assert.Equal(t, []string{\"tool1\", \"tool2\", \"tool3\"}, executor.calls)\n}\n\nfunc TestRuntime_StepFailure(t *testing.T) {\n    executor := &amp;mockToolExecutor{\n        errors: map[string]error{\n            \"failing_tool\": errors.New(\"tool failed\"),\n        },\n    }\n\n    runtime := NewRuntime(RuntimeConfig{\n        ToolExecutor: executor,\n    })\n\n    skill, _ := NewBuilder(\"failing-skill\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing failures\").\n        Step(\"step1\", \"good_tool\").Done().\n        Step(\"step2\", \"failing_tool\").Done().\n        Step(\"step3\", \"another_tool\").Done().\n        Build()\n\n    output, err := runtime.Execute(context.Background(), skill, SkillInput{})\n    assert.Error(t, err)\n    assert.False(t, output.Success)\n    assert.Len(t, output.StepsCompleted, 1) // Only step1 completed\n    assert.Contains(t, output.ErrorMessage, \"failing_tool\")\n}\n\nfunc TestRuntime_OptionalStep(t *testing.T) {\n    executor := &amp;mockToolExecutor{\n        errors: map[string]error{\n            \"optional_tool\": errors.New(\"optional failed\"),\n        },\n    }\n\n    runtime := NewRuntime(RuntimeConfig{\n        ToolExecutor: executor,\n    })\n\n    skill, _ := NewBuilder(\"optional-skill\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing optional steps\").\n        Step(\"step1\", \"tool1\").Done().\n        Step(\"step2\", \"optional_tool\").Optional().Done().\n        Step(\"step3\", \"tool3\").Done().\n        Build()\n\n    output, err := runtime.Execute(context.Background(), skill, SkillInput{})\n    require.NoError(t, err) // Should succeed despite optional step failure\n    assert.True(t, output.Success)\n    assert.Contains(t, output.StepsCompleted, \"step1\")\n    assert.Contains(t, output.StepsCompleted, \"step3\")\n}\n\nfunc TestRuntime_Timeout(t *testing.T) {\n    executor := &amp;mockToolExecutor{}\n\n    runtime := NewRuntime(RuntimeConfig{\n        ToolExecutor:   executor,\n        DefaultTimeout: 50 * time.Millisecond,\n    })\n\n    // Create context that will timeout\n    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Millisecond)\n    defer cancel()\n\n    skill, _ := NewBuilder(\"timeout-skill\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing timeouts\").\n        Step(\"step1\", \"tool1\").Done().\n        Build()\n\n    // Simulate slow execution by waiting\n    time.Sleep(20 * time.Millisecond)\n\n    _, err := runtime.Execute(ctx, skill, SkillInput{})\n    assert.Error(t, err)\n    assert.True(t, errors.Is(err, context.DeadlineExceeded) || errors.Is(err, context.Canceled))\n}\n\nfunc TestRuntime_GetStatus(t *testing.T) {\n    executor := &amp;mockToolExecutor{}\n    runtime := NewRuntime(RuntimeConfig{ToolExecutor: executor})\n\n    skill, _ := NewBuilder(\"status-skill\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing status\").\n        Step(\"step1\", \"tool1\").Done().\n        Build()\n\n    // Start async execution\n    execID, err := runtime.ExecuteAsync(context.Background(), skill, SkillInput{})\n    require.NoError(t, err)\n\n    // Check status (may be running or completed)\n    status, err := runtime.GetStatus(execID)\n    require.NoError(t, err)\n    assert.Equal(t, execID, status.ID)\n    assert.Equal(t, \"status-skill\", status.SkillID)\n}\n\nfunc TestRuntime_Cancel(t *testing.T) {\n    executor := &amp;mockToolExecutor{}\n    runtime := NewRuntime(RuntimeConfig{ToolExecutor: executor})\n\n    skill, _ := NewBuilder(\"cancel-skill\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing cancellation\").\n        Step(\"step1\", \"tool1\").Done().\n        Build()\n\n    execID, _ := runtime.ExecuteAsync(context.Background(), skill, SkillInput{})\n\n    err := runtime.Cancel(execID)\n    assert.NoError(t, err)\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v -run TestRuntime</code> Expected: FAIL with \"undefined: NewRuntime\"</p> <p>Step 3: Write minimal implementation</p> <pre><code>// toolskill/runtime.go\npackage toolskill\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n    \"sync/atomic\"\n    \"time\"\n)\n\n// ExecutionID uniquely identifies a skill execution.\ntype ExecutionID string\n\n// ExecutionState represents the state of skill execution.\ntype ExecutionState string\n\nconst (\n    StatePending   ExecutionState = \"pending\"\n    StateRunning   ExecutionState = \"running\"\n    StatePaused    ExecutionState = \"paused\"\n    StateCompleted ExecutionState = \"completed\"\n    StateFailed    ExecutionState = \"failed\"\n    StateCancelled ExecutionState = \"cancelled\"\n)\n\n// ToolExecutor executes individual tools.\ntype ToolExecutor interface {\n    Execute(ctx context.Context, tool string, input any) (any, error)\n}\n\n// SkillRuntime executes skills.\ntype SkillRuntime interface {\n    Execute(ctx context.Context, skill Skill, input SkillInput) (*SkillOutput, error)\n    ExecuteAsync(ctx context.Context, skill Skill, input SkillInput) (ExecutionID, error)\n    GetStatus(execID ExecutionID) (*ExecutionStatus, error)\n    Pause(execID ExecutionID) error\n    Resume(execID ExecutionID) error\n    Cancel(execID ExecutionID) error\n}\n\n// ExecutionStatus tracks skill execution progress.\ntype ExecutionStatus struct {\n    ID             ExecutionID\n    SkillID        string\n    State          ExecutionState\n    CurrentStep    string\n    CompletedSteps []string\n    Progress       float64\n    StartedAt      time.Time\n    CompletedAt    *time.Time\n    Error          error\n}\n\n// RuntimeConfig configures the skill runtime.\ntype RuntimeConfig struct {\n    ToolExecutor   ToolExecutor\n    DefaultTimeout time.Duration\n    MaxConcurrent  int\n}\n\n// Runtime is the default SkillRuntime implementation.\ntype Runtime struct {\n    executor       ToolExecutor\n    defaultTimeout time.Duration\n    maxConcurrent  int\n\n    mu         sync.RWMutex\n    executions map[ExecutionID]*execution\n    nextID     atomic.Uint64\n}\n\ntype execution struct {\n    id        ExecutionID\n    skill     Skill\n    input     SkillInput\n    status    *ExecutionStatus\n    cancel    context.CancelFunc\n    done      chan struct{}\n    output    *SkillOutput\n    err       error\n}\n\n// NewRuntime creates a new skill runtime.\nfunc NewRuntime(cfg RuntimeConfig) *Runtime {\n    if cfg.DefaultTimeout == 0 {\n        cfg.DefaultTimeout = 30 * time.Second\n    }\n    if cfg.MaxConcurrent == 0 {\n        cfg.MaxConcurrent = 10\n    }\n\n    return &amp;Runtime{\n        executor:       cfg.ToolExecutor,\n        defaultTimeout: cfg.DefaultTimeout,\n        maxConcurrent:  cfg.MaxConcurrent,\n        executions:     make(map[ExecutionID]*execution),\n    }\n}\n\n// Execute runs a skill synchronously.\nfunc (r *Runtime) Execute(ctx context.Context, skill Skill, input SkillInput) (*SkillOutput, error) {\n    // Check context before starting\n    select {\n    case &lt;-ctx.Done():\n        return nil, ctx.Err()\n    default:\n    }\n\n    execCtx := &amp;SkillContext{\n        Input:    input,\n        Results:  make(map[string]any),\n        Metadata: make(map[string]any),\n    }\n\n    steps := skill.Steps()\n    completed := make([]string, 0, len(steps))\n    startTime := time.Now()\n\n    for _, step := range steps {\n        // Check context\n        select {\n        case &lt;-ctx.Done():\n            return &amp;SkillOutput{\n                Success:        false,\n                Error:          ctx.Err(),\n                ErrorMessage:   ctx.Err().Error(),\n                StepsCompleted: completed,\n                Duration:       time.Since(startTime).Milliseconds(),\n            }, ctx.Err()\n        default:\n        }\n\n        execCtx.StepID = step.ID\n\n        // Check condition\n        if step.Condition != nil &amp;&amp; !step.Condition(*execCtx) {\n            continue // Skip this step\n        }\n\n        // Prepare input\n        var toolInput any\n        if step.InputMapper != nil {\n            toolInput = step.InputMapper(*execCtx)\n        } else {\n            toolInput = input\n        }\n\n        // Execute tool\n        result, err := r.executor.Execute(ctx, step.Tool, toolInput)\n        if err != nil {\n            if step.Optional {\n                // Continue on optional step failure\n                continue\n            }\n\n            // Handle error\n            if step.OnError != nil {\n                if handlerErr := step.OnError(*execCtx, err); handlerErr != nil {\n                    return &amp;SkillOutput{\n                        Success:        false,\n                        Error:          handlerErr,\n                        ErrorMessage:   fmt.Sprintf(\"step %s failed: %v\", step.ID, err),\n                        StepsCompleted: completed,\n                        Duration:       time.Since(startTime).Milliseconds(),\n                    }, handlerErr\n                }\n            } else {\n                return &amp;SkillOutput{\n                    Success:        false,\n                    Error:          err,\n                    ErrorMessage:   fmt.Sprintf(\"step %s (%s) failed: %v\", step.ID, step.Tool, err),\n                    StepsCompleted: completed,\n                    Duration:       time.Since(startTime).Milliseconds(),\n                }, fmt.Errorf(\"%w: %v\", ErrStepFailed, err)\n            }\n        }\n\n        // Transform output if mapper provided\n        if step.OutputMapper != nil {\n            result = step.OutputMapper(result)\n        }\n\n        // Store result\n        execCtx.Results[step.ID] = result\n        completed = append(completed, step.ID)\n    }\n\n    return &amp;SkillOutput{\n        Success:        true,\n        Result:         execCtx.Results,\n        StepsCompleted: completed,\n        Duration:       time.Since(startTime).Milliseconds(),\n    }, nil\n}\n\n// ExecuteAsync runs a skill asynchronously.\nfunc (r *Runtime) ExecuteAsync(ctx context.Context, skill Skill, input SkillInput) (ExecutionID, error) {\n    id := ExecutionID(fmt.Sprintf(\"exec-%d\", r.nextID.Add(1)))\n\n    execCtx, cancel := context.WithCancel(ctx)\n\n    exec := &amp;execution{\n        id:     id,\n        skill:  skill,\n        input:  input,\n        cancel: cancel,\n        done:   make(chan struct{}),\n        status: &amp;ExecutionStatus{\n            ID:        id,\n            SkillID:   skill.ID(),\n            State:     StatePending,\n            StartedAt: time.Now(),\n        },\n    }\n\n    r.mu.Lock()\n    r.executions[id] = exec\n    r.mu.Unlock()\n\n    go func() {\n        defer close(exec.done)\n\n        exec.status.State = StateRunning\n        output, err := r.Execute(execCtx, skill, input)\n\n        exec.output = output\n        exec.err = err\n\n        now := time.Now()\n        exec.status.CompletedAt = &amp;now\n\n        if err != nil {\n            exec.status.State = StateFailed\n            exec.status.Error = err\n        } else {\n            exec.status.State = StateCompleted\n            exec.status.CompletedSteps = output.StepsCompleted\n            exec.status.Progress = 1.0\n        }\n    }()\n\n    return id, nil\n}\n\n// GetStatus retrieves execution status.\nfunc (r *Runtime) GetStatus(execID ExecutionID) (*ExecutionStatus, error) {\n    r.mu.RLock()\n    exec, ok := r.executions[execID]\n    r.mu.RUnlock()\n\n    if !ok {\n        return nil, fmt.Errorf(\"execution not found: %s\", execID)\n    }\n\n    return exec.status, nil\n}\n\n// Pause pauses execution (not yet implemented).\nfunc (r *Runtime) Pause(execID ExecutionID) error {\n    return fmt.Errorf(\"pause not yet implemented\")\n}\n\n// Resume resumes execution (not yet implemented).\nfunc (r *Runtime) Resume(execID ExecutionID) error {\n    return fmt.Errorf(\"resume not yet implemented\")\n}\n\n// Cancel cancels an execution.\nfunc (r *Runtime) Cancel(execID ExecutionID) error {\n    r.mu.RLock()\n    exec, ok := r.executions[execID]\n    r.mu.RUnlock()\n\n    if !ok {\n        return fmt.Errorf(\"execution not found: %s\", execID)\n    }\n\n    exec.cancel()\n    exec.status.State = StateCancelled\n    return nil\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v -run TestRuntime</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolskill/runtime.go toolskill/runtime_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolskill): add skill runtime with step execution\n\n- Add SkillRuntime interface for skill execution\n- Add Runtime implementation with sync/async execution\n- Execute steps sequentially with context propagation\n- Support conditional steps via Condition function\n- Support optional steps that continue on failure\n- Add input/output mappers for data transformation\n- Track execution status with progress updates\n- Support cancellation via context\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#task-6-discovery-and-integration","title":"Task 6: Discovery and Integration","text":"<p>Files: - Create: <code>toolskill/discovery.go</code> - Create: <code>toolskill/provider.go</code> - Test: <code>toolskill/discovery_test.go</code></p> <p>Step 1: Write the failing test</p> <pre><code>// toolskill/discovery_test.go\npackage toolskill\n\nimport (\n    \"os\"\n    \"path/filepath\"\n    \"testing\"\n\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc TestDiscovery_ScanDirectory(t *testing.T) {\n    // Create temp directory with skill files\n    tmpDir, err := os.MkdirTemp(\"\", \"skills-test\")\n    require.NoError(t, err)\n    defer os.RemoveAll(tmpDir)\n\n    // Create skill directory structure\n    skill1Dir := filepath.Join(tmpDir, \"research-skill\")\n    require.NoError(t, os.MkdirAll(skill1Dir, 0755))\n\n    skill1Content := `---\nname: research-skill\ndescription: Use when researching topics\nmetadata:\n  version: \"1.0.0\"\n---\n\n# Research Skill\n\n## Overview\nHelps research topics.\n`\n    require.NoError(t, os.WriteFile(filepath.Join(skill1Dir, \"SKILL.md\"), []byte(skill1Content), 0644))\n\n    skill2Dir := filepath.Join(tmpDir, \"debug-skill\")\n    require.NoError(t, os.MkdirAll(skill2Dir, 0755))\n\n    skill2Content := `---\nname: debug-skill\ndescription: Use when debugging issues\nmetadata:\n  version: \"2.0.0\"\n---\n\n# Debug Skill\n\n## Overview\nHelps debug code.\n`\n    require.NoError(t, os.WriteFile(filepath.Join(skill2Dir, \"SKILL.md\"), []byte(skill2Content), 0644))\n\n    // Scan directory\n    discovery := NewDiscovery()\n    skills, err := discovery.ScanDirectory(tmpDir)\n    require.NoError(t, err)\n\n    assert.Len(t, skills, 2)\n\n    // Verify skills were found\n    names := make([]string, len(skills))\n    for i, s := range skills {\n        names[i] = s.Name\n    }\n    assert.Contains(t, names, \"research-skill\")\n    assert.Contains(t, names, \"debug-skill\")\n}\n\nfunc TestDiscovery_ScanDirectoryNested(t *testing.T) {\n    tmpDir, err := os.MkdirTemp(\"\", \"skills-nested\")\n    require.NoError(t, err)\n    defer os.RemoveAll(tmpDir)\n\n    // Create nested structure\n    nestedDir := filepath.Join(tmpDir, \"category\", \"subcategory\", \"my-skill\")\n    require.NoError(t, os.MkdirAll(nestedDir, 0755))\n\n    content := `---\nname: nested-skill\ndescription: Use when testing nested discovery\n---\n\n# Nested Skill\n`\n    require.NoError(t, os.WriteFile(filepath.Join(nestedDir, \"SKILL.md\"), []byte(content), 0644))\n\n    discovery := NewDiscovery()\n    skills, err := discovery.ScanDirectory(tmpDir)\n    require.NoError(t, err)\n\n    assert.Len(t, skills, 1)\n    assert.Equal(t, \"nested-skill\", skills[0].Name)\n}\n\nfunc TestDiscovery_ScanEmptyDirectory(t *testing.T) {\n    tmpDir, err := os.MkdirTemp(\"\", \"skills-empty\")\n    require.NoError(t, err)\n    defer os.RemoveAll(tmpDir)\n\n    discovery := NewDiscovery()\n    skills, err := discovery.ScanDirectory(tmpDir)\n    require.NoError(t, err)\n    assert.Len(t, skills, 0)\n}\n\nfunc TestDiscovery_ScanNonexistentDirectory(t *testing.T) {\n    discovery := NewDiscovery()\n    _, err := discovery.ScanDirectory(\"/nonexistent/path\")\n    assert.Error(t, err)\n}\n\nfunc TestSkillToolProvider_Tools(t *testing.T) {\n    registry := NewRegistry()\n\n    skill1, _ := NewBuilder(\"research\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when researching\").\n        WithInputSchema(map[string]any{\n            \"type\": \"object\",\n            \"properties\": map[string]any{\n                \"query\": map[string]any{\"type\": \"string\"},\n            },\n        }).\n        Build()\n\n    skill2, _ := NewBuilder(\"debug\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when debugging\").\n        Build()\n\n    _ = registry.Register(skill1)\n    _ = registry.Register(skill2)\n\n    provider := NewSkillToolProvider(registry, nil)\n    tools := provider.Tools()\n\n    assert.Len(t, tools, 2)\n\n    // Verify tool naming convention\n    names := make([]string, len(tools))\n    for i, tool := range tools {\n        names[i] = tool.Name\n    }\n    assert.Contains(t, names, \"skill:research\")\n    assert.Contains(t, names, \"skill:debug\")\n\n    // Verify description prefix\n    for _, tool := range tools {\n        assert.Contains(t, tool.Description, \"[SKILL]\")\n    }\n}\n\nfunc TestSkillToolProvider_Handle(t *testing.T) {\n    registry := NewRegistry()\n    executor := &amp;mockToolExecutor{}\n    runtime := NewRuntime(RuntimeConfig{ToolExecutor: executor})\n\n    skill, _ := NewBuilder(\"test-handle\").\n        WithVersion(\"1.0.0\").\n        WithDescription(\"Use when testing handle\").\n        Step(\"step1\", \"tool1\").Done().\n        Build()\n    skill.(*CompositeSkill).SetRuntime(runtime)\n\n    _ = registry.Register(skill)\n\n    provider := NewSkillToolProvider(registry, runtime)\n\n    // Handle skill execution\n    result, err := provider.Handle(\"skill:test-handle\", map[string]any{\"input\": \"value\"})\n    require.NoError(t, err)\n\n    output, ok := result.(*SkillOutput)\n    require.True(t, ok)\n    assert.True(t, output.Success)\n}\n</code></pre> <p>Step 2: Run test to verify it fails</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v -run \"TestDiscovery|TestSkillToolProvider\"</code> Expected: FAIL with \"undefined: NewDiscovery\"</p> <p>Step 3: Write minimal implementation</p> <pre><code>// toolskill/discovery.go\npackage toolskill\n\nimport (\n    \"os\"\n    \"path/filepath\"\n\n    \"github.com/yourusername/toolskill/skillmd\"\n)\n\n// Discovery finds skills in standard locations.\ntype Discovery struct {\n    parser *skillmd.Parser\n}\n\n// NewDiscovery creates a new skill discovery instance.\nfunc NewDiscovery() *Discovery {\n    return &amp;Discovery{\n        parser: skillmd.NewParser(),\n    }\n}\n\n// ScanDirectory finds all SKILL.md files in a directory tree.\nfunc (d *Discovery) ScanDirectory(root string) ([]*skillmd.SkillMD, error) {\n    var skills []*skillmd.SkillMD\n\n    err := filepath.WalkDir(root, func(path string, entry os.DirEntry, err error) error {\n        if err != nil {\n            return err\n        }\n\n        if entry.IsDir() {\n            return nil\n        }\n\n        if entry.Name() == \"SKILL.md\" {\n            skill, err := d.parser.Parse(path)\n            if err != nil {\n                // Log warning but continue scanning\n                return nil\n            }\n            skills = append(skills, skill)\n        }\n\n        return nil\n    })\n\n    if err != nil {\n        return nil, err\n    }\n\n    return skills, nil\n}\n\n// ScanUserSkills scans ~/.claude/skills/ for user-defined skills.\nfunc (d *Discovery) ScanUserSkills() ([]*skillmd.SkillMD, error) {\n    homeDir, err := os.UserHomeDir()\n    if err != nil {\n        return nil, err\n    }\n\n    // Check both possible locations\n    paths := []string{\n        filepath.Join(homeDir, \".claude\", \"skills\"),\n        filepath.Join(homeDir, \".config\", \"claude\", \"skills\"),\n    }\n\n    var allSkills []*skillmd.SkillMD\n    for _, path := range paths {\n        if _, err := os.Stat(path); os.IsNotExist(err) {\n            continue\n        }\n        skills, err := d.ScanDirectory(path)\n        if err != nil {\n            continue\n        }\n        allSkills = append(allSkills, skills...)\n    }\n\n    return allSkills, nil\n}\n\n// ScanProjectSkills scans .claude/skills/ in a project root.\nfunc (d *Discovery) ScanProjectSkills(projectRoot string) ([]*skillmd.SkillMD, error) {\n    skillsDir := filepath.Join(projectRoot, \".claude\", \"skills\")\n    if _, err := os.Stat(skillsDir); os.IsNotExist(err) {\n        return nil, nil\n    }\n    return d.ScanDirectory(skillsDir)\n}\n\n// ScanPluginSkills scans a plugin directory for skills.\nfunc (d *Discovery) ScanPluginSkills(pluginDir string) ([]*skillmd.SkillMD, error) {\n    skillsDir := filepath.Join(pluginDir, \"skills\")\n    if _, err := os.Stat(skillsDir); os.IsNotExist(err) {\n        return nil, nil\n    }\n    return d.ScanDirectory(skillsDir)\n}\n</code></pre> <pre><code>// toolskill/provider.go\npackage toolskill\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n)\n\n// Tool represents an MCP tool definition.\ntype Tool struct {\n    Name        string         `json:\"name\"`\n    Description string         `json:\"description\"`\n    InputSchema map[string]any `json:\"inputSchema,omitempty\"`\n}\n\n// SkillToolProvider exposes skills as MCP tools.\ntype SkillToolProvider struct {\n    registry SkillRegistry\n    runtime  SkillRuntime\n}\n\n// NewSkillToolProvider creates a provider that exposes skills as tools.\nfunc NewSkillToolProvider(registry SkillRegistry, runtime SkillRuntime) *SkillToolProvider {\n    return &amp;SkillToolProvider{\n        registry: registry,\n        runtime:  runtime,\n    }\n}\n\n// Tools returns all skills as MCP tool definitions.\nfunc (p *SkillToolProvider) Tools() []*Tool {\n    manifests := p.registry.List()\n    tools := make([]*Tool, 0, len(manifests))\n\n    for _, m := range manifests {\n        tool := &amp;Tool{\n            Name:        \"skill:\" + m.Name,\n            Description: fmt.Sprintf(\"[SKILL] %s\", m.Description),\n            InputSchema: m.InputSchema,\n        }\n        tools = append(tools, tool)\n    }\n\n    return tools\n}\n\n// Handle executes a skill via its tool name.\nfunc (p *SkillToolProvider) Handle(toolName string, input any) (any, error) {\n    // Extract skill name from tool name (remove \"skill:\" prefix)\n    if len(toolName) &lt;= 6 || toolName[:6] != \"skill:\" {\n        return nil, fmt.Errorf(\"invalid skill tool name: %s\", toolName)\n    }\n    skillName := toolName[6:]\n\n    // Get skill from registry\n    skill, err := p.registry.GetByName(skillName, \"\")\n    if err != nil {\n        return nil, fmt.Errorf(\"skill not found: %s\", skillName)\n    }\n\n    // Convert input to SkillInput\n    var skillInput SkillInput\n    switch v := input.(type) {\n    case SkillInput:\n        skillInput = v\n    case map[string]any:\n        skillInput = SkillInput(v)\n    case json.RawMessage:\n        if err := json.Unmarshal(v, &amp;skillInput); err != nil {\n            return nil, fmt.Errorf(\"invalid input: %w\", err)\n        }\n    default:\n        return nil, fmt.Errorf(\"unsupported input type: %T\", input)\n    }\n\n    // Execute skill\n    if p.runtime == nil {\n        return nil, fmt.Errorf(\"runtime not configured\")\n    }\n\n    return p.runtime.Execute(context.Background(), skill, skillInput)\n}\n\n// Name returns the provider name.\nfunc (p *SkillToolProvider) Name() string {\n    return \"skills\"\n}\n</code></pre> <p>Step 4: Run test to verify it passes</p> <p>Run: <code>cd toolskill &amp;&amp; go test -v -run \"TestDiscovery|TestSkillToolProvider\"</code> Expected: PASS</p> <p>Step 5: Commit</p> <pre><code>git add toolskill/discovery.go toolskill/provider.go toolskill/discovery_test.go\ngit commit -m \"$(cat &lt;&lt;'EOF'\nfeat(toolskill): add discovery and MCP tool provider\n\n- Add Discovery for finding SKILL.md files in directories\n- Support user skills (~/.claude/skills/)\n- Support project skills (.claude/skills/)\n- Support plugin skills (plugins/*/skills/)\n- Add SkillToolProvider exposing skills as MCP tools\n- Use skill: prefix for tool naming convention\n- Add [SKILL] prefix to descriptions for visibility\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\nEOF\n)\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#verification-checklist","title":"Verification Checklist","text":"<p>Before marking this PRD complete, verify:</p> <ul> <li>[ ] All tests pass: <code>go test ./toolskill/...</code></li> <li>[ ] Code coverage &gt; 80%: <code>go test -cover ./toolskill/...</code></li> <li>[ ] No lint errors: <code>golangci-lint run ./toolskill/...</code></li> <li>[ ] Examples compile: <code>go build ./toolskill/examples/...</code></li> <li>[ ] Integration with toolset works</li> <li>[ ] SKILL.md parsing handles edge cases</li> <li>[ ] Registry thread-safety verified</li> <li>[ ] Runtime handles cancellation properly</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#definition-of-done","title":"Definition of Done","text":"<ol> <li>Core Types - Skill interface, SkillManifest, SkillInput/Output defined</li> <li>SKILL.md Parser - Parses standard format with frontmatter extraction</li> <li>Registry - Thread-safe registration with version constraint resolution</li> <li>Builder - Fluent API for skill composition with steps</li> <li>Runtime - Executes skills with conditional steps and error handling</li> <li>Discovery - Scans standard locations for SKILL.md files</li> <li>Provider - Exposes skills as MCP tools with skill: prefix</li> <li>Documentation - README.md with examples</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#architecture-notes","title":"Architecture Notes","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#abstraction-hierarchy","title":"Abstraction Hierarchy","text":"<pre><code>Agents \u2192 Skills \u2192 Toolsets \u2192 Tools\n</code></pre> <p>Skills orchestrate multiple tools into higher-level behaviors. The <code>skill:</code> prefix distinguishes skill tools from regular tools in MCP listings.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#skillmd-standard","title":"SKILL.md Standard","text":"<p>The toolskill library implements the Agent Skills Open Standard: - YAML frontmatter with name and description (required) - Description must start with \"Use when\" for discovery optimization - Markdown body with Overview, When to Use, How It Works sections</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-014-toolskill-library/#integration-points","title":"Integration Points","text":"<ul> <li>toolset: Skills use toolsets for filtered tool access</li> <li>toolrun: Runtime delegates to toolrun for execution</li> <li>toolobserve: Optional tracing integration via middleware</li> <li>toolversion: Manifest includes version for compatibility</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/","title":"PRD-015: MCP Spec Alignment (Tools)","text":"<p>Status: Ready Priority: P1 Owner: metatools-mcp Date: 2026-01-28</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#objective","title":"Objective","text":"<p>Align <code>metatools-mcp</code> with the MCP 2025-11-25 tool semantics by adding dynamic tool list change notifications, consistent pagination/cursor behavior, and explicit cancellation/progress propagation for long-running calls.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#non-goals","title":"Non-Goals","text":"<ul> <li>Adding MCP resources or prompts (separate PRD).</li> <li>Introducing new execution backends.</li> <li>Changing toolmodel schemas.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#requirements","title":"Requirements","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#r1-tool-list-change-notifications","title":"R1 \u2014 Tool list change notifications","text":"<ul> <li>Emit <code>notifications/tools/list_changed</code> when tools are added, removed, or updated.</li> <li>Wire to <code>toolindex</code> change hooks (OnChange/Refresh).</li> <li>Provide a config flag to disable notifications.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#r2-pagination-cursor-consistency","title":"R2 \u2014 Pagination &amp; cursor consistency","text":"<ul> <li>Enforce consistent <code>limit</code> caps for <code>search_tools</code> and <code>list_namespaces</code>.</li> <li>Use opaque cursor tokens for stable pagination (even if in-memory).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#r3-cancellation-propagation","title":"R3 \u2014 Cancellation propagation","text":"<ul> <li>Ensure <code>ctx</code> cancellation aborts <code>run_tool</code>, <code>run_chain</code>, and <code>execute_code</code>.</li> <li>Document behavior for backends that do not support cancellation.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#r4-progress-wiring-optional-v1","title":"R4 \u2014 Progress wiring (optional v1)","text":"<ul> <li>If <code>toolrun</code> or <code>toolruntime</code> exposes progress events, surface them as MCP progress notifications.</li> <li>If not available, document that progress is unsupported.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#tdd-plan","title":"TDD Plan","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#task-1-tool-list-change-notifications","title":"Task 1 \u2014 Tool list change notifications","text":"<ol> <li>Write failing test for <code>tools/list_changed</code> emission when toolindex changes.</li> <li>Run test and confirm failure.</li> <li>Implement hook wiring and notification emission.</li> <li>Run test and confirm pass.</li> <li>Commit <code>feat(metatools): emit tool list change notifications</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#task-2-pagination-and-cursor-consistency","title":"Task 2 \u2014 Pagination and cursor consistency","text":"<ol> <li>Write failing tests for limit caps and cursor semantics.</li> <li>Run tests and confirm failure.</li> <li>Implement cursor helper and caps.</li> <li>Run tests and confirm pass.</li> <li>Commit <code>feat(metatools): normalize search pagination</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#task-3-cancellation-propagation","title":"Task 3 \u2014 Cancellation propagation","text":"<ol> <li>Write failing tests that cancel context mid-call.</li> <li>Run tests and confirm failure.</li> <li>Implement cancellation handling in handlers.</li> <li>Run tests and confirm pass.</li> <li>Commit <code>feat(metatools): propagate cancellation</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#task-4-progress-wiring-optional","title":"Task 4 \u2014 Progress wiring (optional)","text":"<ol> <li>Write failing test for progress event forwarding (if supported by runner).</li> <li>Implement forwarding or explicitly skip with documented limitation.</li> <li>Commit <code>feat(metatools): progress forwarding (optional)</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Tools change notifications are emitted when toolindex changes.</li> <li>Search/list pagination behaves consistently and caps are enforced.</li> <li>Cancellation of context stops tool execution where possible.</li> <li>Documentation updated to reflect any limitations.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#dependencies","title":"Dependencies","text":"<ul> <li><code>toolindex</code> OnChange/Refresh hooks.</li> <li><code>toolrun</code> cancellation semantics.</li> <li>MCP Go SDK notification APIs.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-28-prd-015-mcp-spec-alignment/#notes","title":"Notes","text":"<ul> <li>Keep feature gated by config to preserve static deployments.</li> <li>Debounce notifications to avoid client spam.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/","title":"Architecture Review: Comprehensive Proposal Analysis","text":"<p>Date: 2026-01-28 Status: Review Complete Reviewer: Architecture Review Agent</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#executive-summary","title":"Executive Summary","text":"<p>After thorough review of all 7 proposal documents against the current metatools-mcp codebase, the architecture is well-designed and internally consistent, with some notable areas requiring attention before implementation.</p> <p>Overall Score: 8.5/10</p> Category Score Status Interface Consistency 9/10 \u2705 Minor variations to fix Dependency Graph 8/10 \u26a0\ufe0f Some implicit deps Timeline Feasibility 6/10 \ud83d\udd34 Major discrepancy Coverage 8/10 \u26a0\ufe0f Some gaps Architectural Smells 7/10 \u26a0\ufe0f Complexity concerns"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#1-critical-issues-must-fix-before-implementation","title":"1. Critical Issues (Must Fix Before Implementation)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#11-timeline-discrepancy","title":"1.1 Timeline Discrepancy \ud83d\udd34","text":"<p>Finding: Three documents give different timeline estimates for the same work:</p> Document Total Timeline MVP Timeline ROADMAP.md 21 weeks 7 weeks implementation-phases.md 6-7 weeks 3-4 weeks architecture-evaluation.md 13 weeks (implied) Not specified <p>Root Cause: Each document measures a different scope: - implementation-phases.md: Core pluggable architecture only - architecture-evaluation.md: Core + key enterprise features - ROADMAP.md: Full ecosystem including agent skills</p> <p>Impact: Teams could plan with wrong expectations, resource allocation issues.</p> <p>Recommendation: <pre><code># Add to ROADMAP.md Executive Summary:\n\n## Scope Clarification\n\n| Milestone | Scope | Timeline |\n|-----------|-------|----------|\n| **MVP** | CLI, Config, Transport, Provider Registry | 7 weeks |\n| **Protocol** | + tooladapter, toolset | 14 weeks |\n| **Enterprise** | + toolsemantic, toolgateway, multi-tenancy | 17 weeks |\n| **Full** | + toolskill (Agent Skills) | 21 weeks |\n\nNote: implementation-phases.md covers MVP scope only.\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#12-transport-interface-signature-mismatch","title":"1.2 Transport Interface Signature Mismatch \ud83d\udd34","text":"<p>Finding: The <code>Transport</code> interface has inconsistent signatures across documents:</p> <pre><code>// pluggable-architecture.md (lines 274-288)\ntype Transport interface {\n    Name() string           // \u2705 Present\n    Serve(ctx context.Context, handler RequestHandler) error\n    Close() error\n    Info() TransportInfo    // Uses \"TransportInfo\"\n}\n\n// ROADMAP.md (lines 277-284)\ntype Transport interface {\n    // Name() - MISSING \u274c\n    Serve(ctx context.Context, handler RequestHandler) error\n    Close() error\n    Info() TransportInfo\n}\n\n// implementation-phases.md (lines 341-353)\ntype Transport interface {\n    Name() string\n    Serve(ctx context.Context, handler RequestHandler) error\n    Close() error\n    Info() Info             // Uses \"Info\" not \"TransportInfo\" \u274c\n}\n</code></pre> <p>Impact: Implementation confusion, potential compile errors.</p> <p>Recommendation: Standardize on pluggable-architecture.md version with <code>Name()</code> method and <code>TransportInfo</code> type. Update ROADMAP.md and implementation-phases.md.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#2-medium-priority-issues","title":"2. Medium Priority Issues","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#21-missing-dependencies-in-toolskill","title":"2.1 Missing Dependencies in toolskill","text":"<p>Finding: ROADMAP.md line 97 lists toolskill dependencies as <code>toolset, toolrun</code>.</p> <p>However, the SkillRuntime specification (lines 1329-1344) shows it also requires: - <code>toolobserve</code> for tracing (SkillContext has <code>Tracer trace.Tracer</code>) - <code>toolversion</code> for skill versioning (mentioned in Edge Cases)</p> <p>Impact: Incomplete dependency graph could cause integration issues.</p> <p>Recommendation: Update ROADMAP.md: <pre><code>| **toolskill** | Skills | ... | toolset, toolrun, toolobserve (optional), toolversion |\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#22-missing-toolprompt-library","title":"2.2 Missing toolprompt Library","text":"<p>Finding: architecture-evaluation.md (lines 371-394) identifies MCP Prompts as a gap. ROADMAP.md includes <code>toolresource</code> but not <code>toolprompt</code>.</p> <p>MCP Prompts are a core feature for standardized agent interactions.</p> <p>Impact: Incomplete MCP feature coverage.</p> <p>Recommendation: Either: 1. Add <code>toolprompt</code> to Stream D: Enterprise, OR 2. Document explicit exclusion rationale in ROADMAP.md</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#23-session-management-not-addressed","title":"2.3 Session Management Not Addressed","text":"<p>Finding: architecture-evaluation.md (line 173) notes MCP SDK has session management that metatools lacks. This gap is not addressed in any proposal.</p> <p>Impact: Multi-tenant stateful connections may need session tracking.</p> <p>Recommendation: Add session management consideration to multi-tenancy.md: <pre><code>### Session Management Integration\n\nFor stateful tenant connections, integrate with MCP SDK session:\n- Session ID \u2192 Tenant resolution\n- Session lifecycle \u2192 Tenant quota tracking\n- Session data \u2192 Tenant-scoped storage\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#24-index-interface-missing-onchangerefresh","title":"2.4 Index Interface Missing OnChange/Refresh","text":"<p>Finding: component-library-analysis.md (line 218) proposes adding <code>OnChange</code> callback and <code>Refresh()</code> to Index interface for hot reload. This is not reflected in ROADMAP.md's interface contracts.</p> <p>Impact: Hot reload capability won't be standardized.</p> <p>Recommendation: Add to ROADMAP.md Section 5 Interface Contracts: <pre><code>type Index interface {\n    // ... existing methods ...\n    OnChange(callback func(event RegistryEvent)) func()  // Returns unsubscribe function\n    Refresh() error                                       // Force refresh from backends\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#25-upstreamdownstream-impact-matrix-incomplete","title":"2.5 Upstream/Downstream Impact Matrix Incomplete","text":"<p>Finding: ROADMAP.md (lines 165-176) provides an impact matrix but is missing entries for new libraries.</p> <p>Missing Entries:</p> Change In Affects Upstream Affects Downstream toolsemantic None toolgateway (search routing) toolskill toolset, toolrun metatools (skill exposure), toolgateway toolaudit None All tenant-aware middleware toolresilience None All middleware, toolgateway"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#3-architectural-smells","title":"3. Architectural Smells","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#31-toolsemantic-complexity-explosion","title":"3.1 toolsemantic Complexity Explosion \u26a0\ufe0f","text":"<p>Finding: ROADMAP.md specifies 8 major interfaces for semantic search:</p> Interface Complexity Necessity for MVP Embedder Low \u2705 Required VectorIndex Medium \u2705 Required HybridSearcher Medium \u2705 Required Reranker Medium \u26a0\ufe0f Nice-to-have KnowledgeGraph High \u274c Experimental HierarchicalChunker High \u274c Experimental AgenticRetriever High \u274c Experimental ColBERTIndex High \u274c Specialized <p>Accuracy Benchmarks (from ROADMAP.md): - BM25 only: 78% - Hybrid (BM25+Vector): 94%  \u2190 16% improvement - Hybrid + Reranker: 97%    \u2190 3% more - Full stack: 98%           \u2190 1% more for 5 extra interfaces</p> <p>Impact: Over-engineering risk, delayed delivery.</p> <p>Recommendation: Phase the implementation: <pre><code>## toolsemantic Phased Delivery\n\n| Phase | Version | Interfaces | Accuracy |\n|-------|---------|------------|----------|\n| 1 | v0.1 | Embedder, VectorIndex, HybridSearcher | 94% |\n| 2 | v0.2 | + Reranker | 97% |\n| 3 | v0.3 | + KnowledgeGraph | 98% |\n| 4 | v1.0 | + AgenticRetriever, ColBERT | 98%+ |\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#32-middleware-proliferation","title":"3.2 Middleware Proliferation \u26a0\ufe0f","text":"<p>Finding: Combined proposals define 10+ middleware types: - Logging, Auth, RateLimit, Cache, Metrics, Tracing, Validation (7 from pluggable-architecture.md) - Tenant, TenantRateLimit, TenantToolFilter, TenantAudit (4 from multi-tenancy.md)</p> <p>Impact: - Latency accumulation (each middleware adds ~1-5ms) - Debugging complexity - Order dependency issues (rate limit before auth? after?)</p> <p>Recommendation: Document middleware ordering with production preset:</p> <pre><code>// DefaultProductionMiddleware provides recommended ordering\nvar DefaultProductionMiddleware = []Middleware{\n    LoggingMiddleware,     // 1st: Log all requests for observability\n    TracingMiddleware,     // 2nd: Start trace span\n    TenantMiddleware,      // 3rd: Resolve tenant early\n    RateLimitMiddleware,   // 4th: Fail fast if limited\n    AuthMiddleware,        // 5th: Authenticate\n    ValidationMiddleware,  // 6th: Validate input\n    CachingMiddleware,     // 7th: Check cache\n    // Handler executes here\n    // Middleware unwind in reverse order\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#33-skillbuilder-tight-coupling","title":"3.3 SkillBuilder Tight Coupling \u26a0\ufe0f","text":"<p>Finding: ROADMAP.md SkillBuilder (lines 1548-1567) uses hard-coded tool names:</p> <pre><code>Step(\"discover\", \"search_tools\")\nStep(\"docs-1\", \"describe_tool\")\n</code></pre> <p>Impact: If tool names change, all skills break.</p> <p>Recommendation: Use capability-based or versioned references:</p> <pre><code>// Option 1: Capability enum\nStep(\"discover\", capability.Search)\n\n// Option 2: Versioned tool ID\nStep(\"discover\", toolID(\"metatools:search_tools@v1\"))\n\n// Option 3: Interface-based\nStep(\"discover\", toolThat(func(t Tool) bool {\n    return t.HasCapability(\"search\")\n}))\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#4-verification-against-current-codebase","title":"4. Verification Against Current Codebase","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#41-current-implementation-analysis","title":"4.1 Current Implementation Analysis","text":"<p>File: <code>internal/handlers/interfaces.go</code></p> <p>Current interfaces are internal abstractions, not the external tool* library interfaces:</p> <pre><code>type Index interface {\n    Search(ctx context.Context, query string, limit int) ([]ToolSummary, error)\n    ListNamespaces(ctx context.Context) ([]string, error)\n}\n\ntype Store interface {\n    DescribeTool(ctx context.Context, id string, level string) (ToolDoc, error)\n    ListExamples(ctx context.Context, id string, maxExamples int) ([]ToolExample, error)\n}\n\ntype Runner interface {\n    Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)\n    RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error)\n}\n</code></pre> <p>Observation: The proposals correctly identify these as internal interfaces that wrap external libraries via adapters (<code>internal/adapters/</code>).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#42-transport-layer-verification","title":"4.2 Transport Layer Verification","text":"<p>File: <code>cmd/metatools/main.go</code></p> <pre><code>transport := &amp;mcp.StdioTransport{}\nif err := srv.Run(ctx, transport); err != nil &amp;&amp; ctx.Err() == nil {\n    log.Fatalf(\"Server error: %v\", err)\n}\n</code></pre> <p>Observation: Current implementation uses <code>mcp.StdioTransport</code> directly. The proposals correctly identify that Transport abstraction is new work to enable multiple transport types.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#43-configuration-verification","title":"4.3 Configuration Verification","text":"<p>File: <code>internal/config/config.go</code></p> <pre><code>type Config struct {\n    Index    handlers.Index\n    Docs     handlers.Store\n    Runner   handlers.Runner\n    Executor handlers.Executor // optional\n}\n</code></pre> <p>Observation: Current config is minimal (4 fields). Proposals expand this significantly with ServerConfig, TransportConfig, SearchConfig, etc. This is additive and backward compatible.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#5-cross-reference-audit","title":"5. Cross-Reference Audit","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#51-document-references","title":"5.1 Document References","text":"From To Status pluggable-architecture.md component-library-analysis.md \u2705 Valid pluggable-architecture.md implementation-phases.md \u2705 Valid implementation-phases.md pluggable-architecture.md \u2705 Valid multi-tenancy.md pluggable-architecture.md \u2705 Valid architecture-evaluation.md component-library-analysis.md \u2705 Valid ROADMAP.md All proposals \u2705 Valid protocol-agnostic-tools.md ROADMAP.md \u274c Missing <p>Recommendation: Add to protocol-agnostic-tools.md: <pre><code>**Related:** [Master Roadmap](./ROADMAP.md) - Stream B: Protocol Layer\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#6-summary-of-recommendations","title":"6. Summary of Recommendations","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#high-priority-block-implementation","title":"High Priority (Block Implementation)","text":"<ol> <li>Reconcile timeline discrepancies - Add scope clarification table to ROADMAP.md</li> <li>Standardize Transport interface - Use pluggable-architecture.md version everywhere</li> <li>Document parallel stream constraints - Add resource requirements and critical path</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#medium-priority-quality-improvements","title":"Medium Priority (Quality Improvements)","text":"<ol> <li>Update toolskill dependencies - Add toolobserve, toolversion</li> <li>Add toolprompt - Or document exclusion rationale</li> <li>Add session management - To multi-tenancy proposal</li> <li>Add Index.OnChange/Refresh - To interface contracts</li> <li>Complete impact matrix - Add all new libraries</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#low-priority-future-considerations","title":"Low Priority (Future Considerations)","text":"<ol> <li>Phase toolsemantic - Deliver in 4 incremental versions</li> <li>Document middleware ordering - With production preset</li> <li>Use capability-based tool references - In SkillBuilder</li> <li>Add cross-reference - protocol-agnostic-tools.md \u2192 ROADMAP.md</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#7-conclusion","title":"7. Conclusion","text":"<p>The metatools architecture proposals are comprehensive and well-designed. The modular approach with 22 libraries provides excellent separation of concerns. The main risks are:</p> <ol> <li>Timeline confusion - Different documents suggest wildly different timelines</li> <li>Complexity creep - toolsemantic and middleware could become unwieldy</li> <li>Interface drift - Minor inconsistencies need cleanup before implementation</li> </ol> <p>With the recommended fixes, this architecture will achieve the stated goal of 95%+ championship-level capabilities.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#appendix-files-reviewed","title":"Appendix: Files Reviewed","text":"Document Lines Last Modified ROADMAP.md ~2100 2026-01-28 pluggable-architecture.md ~4900 2026-01-28 implementation-phases.md ~900 2026-01-28 component-library-analysis.md - 2026-01-27 architecture-evaluation.md ~450 2026-01-28 multi-tenancy.md - 2026-01-28 protocol-agnostic-tools.md - 2026-01-28 Source File Purpose internal/handlers/interfaces.go Current internal interfaces internal/config/config.go Current config structure internal/server/server.go Current server implementation cmd/metatools/main.go Current entry point internal/adapters/*.go Library adapters"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/","title":"Metatools Architecture Roadmap","text":"<p>Status: Master Plan Version: 1.0.0 Last Updated: 2026-01-28</p> <p>Guiding Principle: Simple and elegant at the core, extensible through modular, pluggable architecture. The existing 7 libraries represent a mature, well-designed foundation. New work focuses on exposure, configuration, and enterprise capabilities\u2014not redesign.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#executive-summary","title":"Executive Summary","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#current-state","title":"Current State","text":"<ul> <li>7 production libraries with clean interfaces</li> <li>13 extension points already implemented as Go interfaces</li> <li>85% championship-level architecture</li> <li>Primary gap: Exposure and configuration, not architecture</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#target-state","title":"Target State","text":"<ul> <li>22 total libraries (7 existing + 15 new)</li> <li>95%+ championship-level with full enterprise capabilities</li> <li>Protocol-agnostic tool platform</li> <li>Multi-tenant with pluggable isolation strategies</li> <li>Agent skills for higher-level capability composition</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#scope-clarification","title":"Scope Clarification","text":"Milestone Scope Timeline Document Reference MVP CLI, Config, Transport, Provider Registry 7 weeks implementation-phases.md Protocol + tooladapter, toolset, multi-transport 14 weeks protocol-agnostic-tools.md Enterprise + toolsemantic, toolgateway, multi-tenancy 17 weeks multi-tenancy.md Full + toolskill (Agent Skills) 21 weeks This document <p>Note: implementation-phases.md covers MVP scope only (6-7 weeks). This master roadmap covers the full 21-week timeline.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#timeline-overview","title":"Timeline Overview","text":"<pre><code>                    CORE EXPOSURE          ENTERPRISE FEATURES         AGENT SKILLS\n                    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500         \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nWeek 1-2   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 CLI + Config\nWeek 3-4   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Transport Layer\nWeek 5     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Provider Registry\nWeek 6-7   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Backend Registry\nWeek 8-9              \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Protocol Adapters\nWeek 10-11            \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Observability + Caching\nWeek 12-13            \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Multi-Tenancy\nWeek 14-15            \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Versioning + Resilience\nWeek 16-17            \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Semantic Search + Gateway\nWeek 18-19                                                    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Skill Core\nWeek 20-21                                                    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Orchestration\n                    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                    MVP: 7 weeks | Full: 17 weeks | Skills: 21 weeks\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Library Inventory</li> <li>Dependency Map</li> <li>Work Streams</li> <li>Stream A: Core Exposure</li> <li>Stream B: Protocol Layer</li> <li>Stream C: Cross-Cutting</li> <li>Stream D: Enterprise</li> <li>Stream E: Agent Skills</li> <li>Phase Breakdown</li> <li>Interface Contracts</li> <li>Edge Cases &amp; Considerations</li> <li>Rollout Strategy</li> <li>Multi-Language Extensibility</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#1-library-inventory","title":"1. Library Inventory","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#existing-libraries-production","title":"Existing Libraries (Production)","text":"Library Version Purpose Extension Points Changes Needed toolmodel v0.1.3 Core data models, schemas SchemaValidator Add Version field toolindex v0.1.9 Tool registry, discovery Searcher, BackendSelector Multi-backend events tooldocs v0.1.11 Progressive disclosure docs Store, ToolResolver Bulk registration toolsearch v0.1.10 BM25 search implementation (via Searcher) None toolrun v0.1.10 Execution orchestration Runner, MCPExecutor, ProviderExecutor, LocalRegistry HTTP/gRPC executors toolcode v0.1.11 Code execution Engine, Logger Engine registry toolruntime v0.1.11 Sandbox isolation (10 backends) Backend, ToolGateway None"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#proposed-libraries-new","title":"Proposed Libraries (New)","text":"Library Stream Purpose Priority Effort Dependencies tooladapter Protocol Protocol-agnostic tool abstraction High 2w toolmodel toolset Protocol Composable tool collections High 2w tooladapter, toolindex toolversion Cross-Cut Semantic versioning, negotiation High 2w toolmodel toolcache Cross-Cut Pluggable caching (Redis/Memory) High 2w None toolobserve Cross-Cut OpenTelemetry tracing + metrics High 2w None toolresilience Cross-Cut Circuit breaker, retry, bulkhead Medium 2w None toolhealth Cross-Cut Health checks, readiness probes Medium 1w None toolsecrets Cross-Cut Vault/AWS secrets management Medium 2w None toolflags Cross-Cut Feature flags (LaunchDarkly) Low 1w None toolaudit Cross-Cut Immutable audit logging Medium 2w None toolpressure Cross-Cut Backpressure, load shedding Low 1w None toolsemantic Enterprise Hybrid search (BM25+vector), GraphRAG, reranking, ColBERT High 3w toolindex, toolsearch toolresource Enterprise MCP Resources support Medium 2w toolindex toolgateway Enterprise Auth, rate limit, analytics proxy Medium 3w All toolskill Skills SKILL.md-compatible agent skills, workflows Medium 4w toolset, toolrun, toolobserve (opt), toolversion"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#2-dependency-map","title":"2. Dependency Map","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#library-dependencies-dag","title":"Library Dependencies (DAG)","text":"<pre><code>                            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                            \u2502    toolskill    \u2502 (L5)\n                            \u2502  Agent Skills   \u2502\n                            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502                                                      \u2502\n          \u25bc                                                      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   toolgateway   \u2502 (L4)                              \u2502    toolrun      \u2502\n\u2502  Auth + Proxy   \u2502                                   \u2502   (execution)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502                          \u2502                          \u2502\n          \u25bc                          \u25bc                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   toolobserve   \u2502      \u2502  toolresilience \u2502      \u2502    toolaudit    \u2502 (L3)\n\u2502   OpenTelemetry \u2502      \u2502 Circuit Breaker \u2502      \u2502  Audit Logging  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                        \u2502                        \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502                       \u2502                       \u2502\n          \u25bc                       \u25bc                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    toolset      \u2502      \u2502   toolversion   \u2502      \u2502    toolcache    \u2502 (L2)\n\u2502  Composable     \u2502      \u2502   Versioning    \u2502      \u2502    Caching      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                        \u2502                        \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502   tooladapter   \u2502 (L1)\n                        \u2502 Protocol Adapt  \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                            \u2502                            \u2502\n    \u25bc                            \u25bc                            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502toolmodel\u2502  \u2502toolindex\u2502  \u2502tooldocs \u2502  \u2502 toolrun \u2502  \u2502toolcode \u2502 (L0)\n\u2502  v0.1.2 \u2502  \u2502  v0.1.8 \u2502  \u2502 v0.1.10 \u2502  \u2502  v0.1.9 \u2502  \u2502 v0.1.10 \u2502\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n     \u2502            \u2502            \u2502            \u2502            \u2502\n     \u2502            \u2502            \u2502            \u2502            \u25bc\n     \u2502            \u2502            \u2502            \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502            \u2502            \u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 toolruntime \u2502\n     \u2502            \u2502            \u2502                   \u2502   v0.1.10   \u2502\n     \u2502            \u2502            \u25bc                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502            \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u25ba\u2502toolsearch\u2502\n     \u2502                   \u2502  v0.1.9  \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#upstreamdownstream-impact-matrix","title":"Upstream/Downstream Impact Matrix","text":"Change In Affects Upstream Affects Downstream toolmodel None All libraries toolindex None tooldocs, toolrun, toolset tooladapter toolmodel toolset, toolgateway toolversion toolmodel tooladapter, toolrun toolcache None toolindex, tooldocs, toolrun toolobserve None All libraries (optional) toolskill toolset, toolrun metatools (skill exposure)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#3-work-streams","title":"3. Work Streams","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#stream-a-core-exposure","title":"Stream A: Core Exposure","text":"<p>Goal: Expose existing 13 extension points via configuration and CLI.</p> Phase Work Package Duration Deliverables A1 CLI Framework 2 weeks Cobra CLI, subcommands A2 Configuration 1 week Koanf loader, YAML schema A3 Transport Layer 2 weeks Transport interface, stdio/SSE/HTTP A4 Provider Registry 1 week ToolProvider interface, registry A5 Backend Registry 2 weeks Backend interface, aggregator <p>Total: 8 weeks | MVP: Phases A1-A4 (6 weeks)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#a1-cli-framework-2-weeks","title":"A1: CLI Framework (2 weeks)","text":"<pre><code>Week 1:\n\u251c\u2500\u2500 Day 1-2: Cobra setup, root command\n\u251c\u2500\u2500 Day 3-4: `stdio` subcommand (existing behavior)\n\u251c\u2500\u2500 Day 5: `serve` subcommand (HTTP server)\n\nWeek 2:\n\u251c\u2500\u2500 Day 1-2: `version`, `validate` commands\n\u251c\u2500\u2500 Day 3-4: Signal handling, graceful shutdown\n\u251c\u2500\u2500 Day 5: Documentation, examples\n</code></pre> <p>Interface Contract: <pre><code>// cmd/metatools/main.go\nfunc main() {\n    rootCmd := &amp;cobra.Command{Use: \"metatools\"}\n    rootCmd.AddCommand(\n        newStdioCmd(),   // MCP over stdio (default)\n        newServeCmd(),   // HTTP/SSE server\n        newVersionCmd(), // Print version\n        newValidateCmd(), // Validate config\n    )\n    rootCmd.Execute()\n}\n</code></pre></p> <p>Edge Cases: - [ ] Backward compatibility: <code>metatools</code> alone = <code>metatools stdio</code> - [ ] Environment variables override YAML config - [ ] Invalid config: fail fast with clear error messages - [ ] Missing optional config: sensible defaults</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#a2-configuration-1-week","title":"A2: Configuration (1 week)","text":"<pre><code>Week 3:\n\u251c\u2500\u2500 Day 1-2: Koanf setup, YAML parser\n\u251c\u2500\u2500 Day 3: Environment variable binding\n\u251c\u2500\u2500 Day 4: Config validation schema\n\u251c\u2500\u2500 Day 5: Default values, documentation\n</code></pre> <p>Interface Contract: <pre><code>// internal/config/config.go\ntype Config struct {\n    Server     ServerConfig     `koanf:\"server\"`\n    Transport  TransportConfig  `koanf:\"transport\"`\n    Search     SearchConfig     `koanf:\"search\"`\n    Execution  ExecutionConfig  `koanf:\"execution\"`\n    Backends   BackendsConfig   `koanf:\"backends\"`\n    Middleware MiddlewareConfig `koanf:\"middleware\"`\n}\n\nfunc Load(path string) (*Config, error)\nfunc LoadWithEnv(path string, prefix string) (*Config, error)\n</code></pre></p> <p>Edge Cases: - [ ] Config file not found: use defaults - [ ] Partial config: merge with defaults - [ ] Invalid values: return typed validation errors - [ ] Hot reload: optional, via <code>toolconfig</code> watcher</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#a3-transport-layer-2-weeks","title":"A3: Transport Layer (2 weeks)","text":"<pre><code>Week 4:\n\u251c\u2500\u2500 Day 1-2: Transport interface definition\n\u251c\u2500\u2500 Day 3-4: Stdio transport (wrap existing)\n\u251c\u2500\u2500 Day 5: Transport registry\n\nWeek 5:\n\u251c\u2500\u2500 Day 1-2: SSE transport implementation\n\u251c\u2500\u2500 Day 3-4: HTTP transport implementation\n\u251c\u2500\u2500 Day 5: TLS support, health endpoints\n</code></pre> <p>Interface Contract: <pre><code>// internal/transport/transport.go\ntype Transport interface {\n    Name() string  // Transport identifier (e.g., \"stdio\", \"sse\", \"http\")\n    Serve(ctx context.Context, handler RequestHandler) error\n    Close() error\n    Info() TransportInfo\n}\n\ntype TransportInfo struct {\n    Name     string\n    Protocol string // \"stdio\", \"http\", \"sse\", \"grpc\"\n    Address  string // \"\" for stdio, \"localhost:8080\" for HTTP\n}\n\ntype TransportRegistry interface {\n    Register(name string, factory TransportFactory)\n    Get(name string) (Transport, error)\n    List() []string\n}\n</code></pre></p> <p>Edge Cases: - [ ] Stdio: handle broken pipe gracefully - [ ] HTTP: CORS headers for browser clients - [ ] SSE: reconnection with event ID - [ ] TLS: certificate rotation without restart - [ ] Health: <code>/health</code> (liveness), <code>/ready</code> (readiness)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#a4-provider-registry-1-week","title":"A4: Provider Registry (1 week)","text":"<pre><code>Week 6:\n\u251c\u2500\u2500 Day 1-2: ToolProvider interface\n\u251c\u2500\u2500 Day 3: Provider registry\n\u251c\u2500\u2500 Day 4: Refactor existing tools as providers\n\u251c\u2500\u2500 Day 5: Custom provider registration docs\n</code></pre> <p>Interface Contract: <pre><code>// internal/provider/provider.go\ntype ToolProvider interface {\n    Name() string\n    Tool() *mcp.Tool\n    Handle(ctx context.Context, input json.RawMessage) (any, error)\n}\n\ntype ProviderRegistry interface {\n    Register(provider ToolProvider) error\n    Get(name string) (ToolProvider, error)\n    List() []ToolProvider\n    Unregister(name string) error\n}\n</code></pre></p> <p>Edge Cases: - [ ] Duplicate registration: return error, don't overwrite - [ ] Dynamic registration: emit events for discovery - [ ] Provider panic: recover, log, return error - [ ] Slow provider: context deadline enforced</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#a5-backend-registry-2-weeks","title":"A5: Backend Registry (2 weeks)","text":"<pre><code>Week 7:\n\u251c\u2500\u2500 Day 1-2: Backend interface definition\n\u251c\u2500\u2500 Day 3-4: Local backend (existing behavior)\n\u251c\u2500\u2500 Day 5: Backend registry\n\nWeek 8:\n\u251c\u2500\u2500 Day 1-2: MCP backend (connect to MCP servers)\n\u251c\u2500\u2500 Day 3-4: HTTP backend (REST API tools)\n\u251c\u2500\u2500 Day 5: Aggregator (merge tools from all backends)\n</code></pre> <p>Interface Contract: <pre><code>// internal/backend/backend.go\ntype Backend interface {\n    Kind() string              // \"local\", \"mcp\", \"http\"\n    Name() string              // Instance name\n    Start(ctx context.Context) error\n    Stop(ctx context.Context) error\n    ListTools(ctx context.Context) ([]*toolmodel.Tool, error)\n    Execute(ctx context.Context, tool string, input any) (any, error)\n    Health(ctx context.Context) HealthStatus\n}\n\ntype BackendRegistry interface {\n    Register(backend Backend) error\n    Get(name string) (Backend, error)\n    ListByKind(kind string) []Backend\n    Aggregate() AggregatedBackend\n}\n</code></pre></p> <p>Edge Cases: - [ ] Backend offline: mark unhealthy, exclude from routing - [ ] Tool name collision: namespace with backend name - [ ] Slow backend: per-backend timeout - [ ] Backend restart: re-register tools, emit events</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#stream-b-protocol-layer","title":"Stream B: Protocol Layer","text":"<p>Goal: Protocol-agnostic tool exposure with composable toolsets.</p> Phase Work Package Duration Deliverables B1 tooladapter Core 2 weeks Adapter interface, MCP adapter B2 Additional Adapters 1 week OpenAI, Anthropic, LangChain B3 toolset Core 2 weeks Toolset builder, filtering B4 Multi-Transport 1 week Expose via MCP, REST, direct <p>Total: 6 weeks</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#b1-tooladapter-core-2-weeks","title":"B1: tooladapter Core (2 weeks)","text":"<pre><code>Week 9:\n\u251c\u2500\u2500 Day 1-2: CanonicalTool type definition\n\u251c\u2500\u2500 Day 3-4: Adapter interface\n\u251c\u2500\u2500 Day 5: MCP adapter (bidirectional)\n\nWeek 10:\n\u251c\u2500\u2500 Day 1-2: Schema conversion utilities\n\u251c\u2500\u2500 Day 3-4: Adapter registry\n\u251c\u2500\u2500 Day 5: Unit tests, documentation\n</code></pre> <p>Interface Contract: <pre><code>// tooladapter/canonical.go\ntype CanonicalTool struct {\n    ID          string\n    Namespace   string\n    Name        string\n    Version     semver.Version\n    Description string\n    InputSchema *JSONSchema\n    OutputSchema *JSONSchema\n    Handler     ToolHandler\n    SourceFormat string\n    SourceMeta   map[string]any\n}\n\n// tooladapter/adapter.go\ntype Adapter interface {\n    Name() string\n    ToCanonical(raw any) (*CanonicalTool, error)\n    FromCanonical(tool *CanonicalTool) (any, error)\n    SupportsFeature(feature SchemaFeature) bool\n}\n</code></pre></p> <p>Edge Cases: - [ ] Schema feature not supported: strip with warning - [ ] Conversion loss: preserve original in SourceMeta - [ ] Bidirectional round-trip: verify no data loss - [ ] Nil handling: optional fields default to nil/zero</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#b2-additional-adapters-1-week","title":"B2: Additional Adapters (1 week)","text":"<pre><code>Week 11:\n\u251c\u2500\u2500 Day 1-2: OpenAI adapter (strict mode support)\n\u251c\u2500\u2500 Day 3: Anthropic adapter\n\u251c\u2500\u2500 Day 4: LangChain adapter\n\u251c\u2500\u2500 Day 5: OpenAPI adapter (import only)\n</code></pre> <p>Edge Cases: - [ ] OpenAI strict mode: reject unsupported features - [ ] Anthropic input_schema vs inputSchema naming - [ ] LangChain Zod schemas: convert to JSON Schema - [ ] OpenAPI discriminators: flatten to anyOf</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#b3-toolset-core-2-weeks","title":"B3: toolset Core (2 weeks)","text":"<pre><code>Week 12:\n\u251c\u2500\u2500 Day 1-2: Toolset type definition\n\u251c\u2500\u2500 Day 3-4: Builder pattern with fluent API\n\u251c\u2500\u2500 Day 5: Filter predicates\n\nWeek 13:\n\u251c\u2500\u2500 Day 1-2: Access control policies\n\u251c\u2500\u2500 Day 3-4: Integration with toolindex\n\u251c\u2500\u2500 Day 5: Integration with toolrun\n</code></pre> <p>Interface Contract: <pre><code>// toolset/builder.go\ntype Builder struct { ... }\n\nfunc NewBuilder(name string) *Builder\nfunc (b *Builder) FromRegistry(reg *Registry) *Builder\nfunc (b *Builder) WithNamespace(ns string) *Builder\nfunc (b *Builder) WithTags(tags ...string) *Builder\nfunc (b *Builder) WithTools(ids ...string) *Builder\nfunc (b *Builder) ExcludeTools(ids ...string) *Builder\nfunc (b *Builder) WithPolicy(p *AccessPolicy) *Builder\nfunc (b *Builder) Build() (*Toolset, error)\n</code></pre></p> <p>Edge Cases: - [ ] Empty toolset: valid, return empty list - [ ] Conflicting filters: AND logic (all must match) - [ ] Tool removed after build: refresh on demand - [ ] Circular exclude: no-op, tool already excluded</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#b4-multi-transport-1-week","title":"B4: Multi-Transport (1 week)","text":"<pre><code>Week 14:\n\u251c\u2500\u2500 Day 1-2: MCP exposure (enhanced)\n\u251c\u2500\u2500 Day 3: REST API exposure\n\u251c\u2500\u2500 Day 4: Direct Go client\n\u251c\u2500\u2500 Day 5: Documentation, examples\n</code></pre> <p>Edge Cases: - [ ] MCP version mismatch: negotiate or reject - [ ] REST pagination: cursor-based for large toolsets - [ ] Go client: context cancellation propagation</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#stream-c-cross-cutting","title":"Stream C: Cross-Cutting","text":"<p>Goal: Production-ready cross-cutting concerns.</p> Phase Work Package Duration Deliverables C1 toolcache 2 weeks Cache interface, Redis/Memory C2 toolobserve 2 weeks OpenTelemetry integration C3 toolversion 2 weeks Semantic versioning, negotiation C4 toolresilience 2 weeks Circuit breaker, retry C5 toolhealth 1 week Health checks C6 toolaudit 2 weeks Audit logging C7 toolsecrets 2 weeks Secrets management C8 toolflags + toolpressure 2 weeks Feature flags, backpressure <p>Total: 15 weeks (can parallelize C1-C3 and C4-C8)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#c1-toolcache-2-weeks","title":"C1: toolcache (2 weeks)","text":"<p>Interface Contract: <pre><code>// toolcache/cache.go\ntype Cache interface {\n    Get(ctx context.Context, key string) ([]byte, bool, error)\n    Set(ctx context.Context, key string, value []byte, ttl time.Duration) error\n    Delete(ctx context.Context, key string) error\n    Clear(ctx context.Context, pattern string) error\n    Stats() CacheStats\n    Close() error\n}\n</code></pre></p> <p>Implementations: - <code>MemoryCache</code> - LRU eviction, process-local - <code>RedisCache</code> - Distributed, TTL-based - <code>LayeredCache</code> - L1 memory + L2 Redis</p> <p>Integration Points: - <code>toolindex</code>: Cache tool lookups (<code>index:tool:{id}</code>) - <code>tooldocs</code>: Cache documentation (<code>docs:{id}:{level}</code>) - <code>toolsearch</code>: Cache search results (<code>search:{hash}</code>) - <code>tooladapter</code>: Cache schema conversions (<code>schema:{format}:{id}</code>)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#c2-toolobserve-2-weeks","title":"C2: toolobserve (2 weeks)","text":"<p>Interface Contract: <pre><code>// toolobserve/observe.go\ntype Observer interface {\n    StartSpan(ctx context.Context, name string) (context.Context, Span)\n    RecordMetric(name string, value float64, labels map[string]string)\n    RecordError(ctx context.Context, err error)\n}\n\ntype Span interface {\n    SetAttribute(key string, value any)\n    AddEvent(name string, attrs map[string]any)\n    RecordError(err error)\n    End()\n}\n</code></pre></p> <p>Integration Points: - Middleware: auto-instrument all tool calls - Per-backend: trace backend latency - Per-tool: trace individual tool execution</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#c3-toolversion-2-weeks","title":"C3: toolversion (2 weeks)","text":"<p>Interface Contract: <pre><code>// toolversion/registry.go\ntype VersionedToolRegistry interface {\n    Register(tool *VersionedTool) error\n    Resolve(name string, constraint string) (*VersionedTool, error)\n    ListVersions(name string) []VersionInfo\n    Deprecate(name string, version string, message string, sunset time.Time) error\n}\n</code></pre></p> <p>Edge Cases: - [ ] No matching version: return ErrNoCompatibleVersion - [ ] Deprecated tool used: log warning, emit metric - [ ] Sunset reached: remove from registry - [ ] Version constraint invalid: return parse error</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#c4-toolresilience-2-weeks","title":"C4: toolresilience (2 weeks)","text":"<p>Interface Contract: <pre><code>// toolresilience/resilience.go\ntype CircuitBreaker interface {\n    Execute(ctx context.Context, fn func() error) error\n    State() CircuitState\n    Reset()\n}\n\ntype RetryPolicy interface {\n    Execute(ctx context.Context, fn func() error) error\n    ShouldRetry(err error, attempt int) bool\n}\n\ntype Bulkhead interface {\n    Acquire(ctx context.Context) error\n    Release()\n    Available() int\n}\n</code></pre></p> <p>Edge Cases: - [ ] Circuit open: fail fast without calling backend - [ ] Retry on non-idempotent: disabled by default - [ ] Bulkhead full: reject with 503 - [ ] Jitter calculation: prevent thundering herd</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#stream-d-enterprise","title":"Stream D: Enterprise","text":"<p>Goal: Enterprise-grade features for production deployments.</p> Phase Work Package Duration Deliverables D1 Multi-Tenancy Core 2 weeks Tenant model, resolvers D2 Tenant Middleware 1 week Rate limit, filtering, audit D3 Tenant Storage 1 week Redis/Postgres store D4 toolsemantic 3 weeks Vector search, hybrid D5 toolresource 2 weeks MCP Resources support D6 toolgateway 3 weeks Auth proxy, analytics <p>Total: 12 weeks (can parallelize D1-D3 and D4-D6)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#d1-multi-tenancy-core-2-weeks","title":"D1: Multi-Tenancy Core (2 weeks)","text":"<p>Interface Contract: <pre><code>// multi-tenancy\ntype Tenant struct {\n    ID       string\n    Name     string\n    Tier     TenantTier // free, pro, enterprise\n    Metadata map[string]any\n}\n\ntype TenantResolver interface {\n    Resolve(ctx context.Context, req *Request) (*TenantContext, error)\n}\n\ntype TenantContext struct {\n    Tenant      *Tenant\n    Permissions []string\n    Config      *TenantConfig\n    Quotas      *TenantQuotas\n}\n</code></pre></p> <p>Isolation Strategies: 1. Shared: Logical isolation via middleware (default) 2. Namespace: Tool namespace per tenant 3. Process: Dedicated process per tenant</p> <p>Edge Cases: - [ ] No tenant header: use default tenant or reject - [ ] Tenant not found: return 401/403 - [ ] Quota exceeded: return 429 with retry-after - [ ] Tenant config change: propagate to active sessions</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#d4-toolsemantic-advanced-semantic-search-3-weeks","title":"D4: toolsemantic - Advanced Semantic Search (3 weeks)","text":"<p>Research-Driven Design: This specification is based on 2025 industry best practices for production RAG systems, including hybrid search, knowledge graphs, hierarchical chunking, agentic retrieval, and late interaction models.</p> <pre><code>Week 16:\n\u251c\u2500\u2500 Day 1-2: Core embedding and vector interfaces\n\u251c\u2500\u2500 Day 3-4: Hybrid search (BM25 + vector fusion)\n\u251c\u2500\u2500 Day 5: Reranker integration\n\nWeek 17:\n\u251c\u2500\u2500 Day 1-2: GraphRAG knowledge graph layer\n\u251c\u2500\u2500 Day 3-4: Hierarchical/tree chunking\n\u251c\u2500\u2500 Day 5: Context tree traversal\n\nWeek 18:\n\u251c\u2500\u2500 Day 1-2: Agentic RAG (query expansion, multi-query)\n\u251c\u2500\u2500 Day 3-4: ColBERT/late interaction support\n\u251c\u2500\u2500 Day 5: Integration tests, benchmarks\n</code></pre> <p>Architecture Overview:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          AGENTIC RAG LAYER                                  \u2502\n\u2502  Query Expansion \u2192 Multi-Query \u2192 Self-Reasoning \u2192 Adaptive Retrieval       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           HYBRID SEARCH                                     \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502\n\u2502  \u2502  BM25/TF-IDF\u2502    \u2502   Vector    \u2502    \u2502   GraphRAG  \u2502                     \u2502\n\u2502  \u2502  (toolsearch)\u2502   \u2502  (Dense)    \u2502    \u2502 (Knowledge) \u2502                     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502         \u2502                  \u2502                  \u2502                             \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502                            \u2502                                                \u2502\n\u2502                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                       \u2502\n\u2502                   \u2502  Rank Fusion    \u2502                                       \u2502\n\u2502                   \u2502 (RRF / Weighted)\u2502                                       \u2502\n\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                       \u2502\n\u2502                            \u2502                                                \u2502\n\u2502                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                       \u2502\n\u2502                   \u2502   Reranker      \u2502                                       \u2502\n\u2502                   \u2502 (Cross-Encoder) \u2502                                       \u2502\n\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        INDEX LAYER                                          \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  BM25 Index \u2502    \u2502 HNSW/IVF    \u2502    \u2502  Knowledge  \u2502    \u2502 Hierarchical\u2502  \u2502\n\u2502  \u2502(toolsearch) \u2502    \u2502Vector Index \u2502    \u2502   Graph     \u2502    \u2502    Tree     \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Core Interface Contracts:</p> <pre><code>// toolsemantic/embedding.go\n\n// Embedder generates vector embeddings from text\ntype Embedder interface {\n    // Embed generates embedding for a single text\n    Embed(ctx context.Context, text string) ([]float32, error)\n\n    // EmbedBatch generates embeddings for multiple texts (more efficient)\n    EmbedBatch(ctx context.Context, texts []string) ([][]float32, error)\n\n    // Dimensions returns the embedding vector size\n    Dimensions() int\n\n    // Model returns the model identifier\n    Model() string\n}\n\n// EmbedderFactory creates embedders from configuration\ntype EmbedderFactory interface {\n    Create(config EmbedderConfig) (Embedder, error)\n}\n\n// EmbedderConfig configures an embedding provider\ntype EmbedderConfig struct {\n    Provider   string            // \"openai\", \"cohere\", \"local\", \"ollama\"\n    Model      string            // \"text-embedding-3-small\", \"embed-english-v3.0\"\n    Dimensions int               // Override dimensions (for some models)\n    Options    map[string]any    // Provider-specific options\n}\n</code></pre> <pre><code>// toolsemantic/vector.go\n\n// VectorIndex provides vector similarity search\ntype VectorIndex interface {\n    // Index adds vectors to the index\n    Index(ctx context.Context, docs []VectorDocument) error\n\n    // Search finds similar vectors\n    Search(ctx context.Context, query []float32, opts SearchOptions) ([]VectorResult, error)\n\n    // Delete removes documents from index\n    Delete(ctx context.Context, ids []string) error\n\n    // Stats returns index statistics\n    Stats() IndexStats\n}\n\ntype VectorDocument struct {\n    ID        string\n    Vector    []float32\n    Metadata  map[string]any\n    Content   string  // Optional, for hybrid storage\n}\n\ntype VectorResult struct {\n    ID       string\n    Score    float32  // Similarity score (higher = more similar)\n    Distance float32  // Distance (lower = more similar)\n    Metadata map[string]any\n    Content  string\n}\n\ntype SearchOptions struct {\n    TopK     int               // Number of results\n    MinScore float32           // Minimum similarity threshold\n    Filter   map[string]any    // Metadata filters\n}\n\n// VectorIndexFactory creates vector indices\ntype VectorIndexFactory interface {\n    Create(config VectorIndexConfig) (VectorIndex, error)\n}\n\ntype VectorIndexConfig struct {\n    Backend     string  // \"memory\", \"faiss\", \"qdrant\", \"pinecone\", \"chromadb\"\n    Dimensions  int\n    Metric      string  // \"cosine\", \"euclidean\", \"dot\"\n    IndexType   string  // \"flat\", \"hnsw\", \"ivf\"\n\n    // HNSW-specific\n    M               int  // Max connections per layer\n    EfConstruction  int  // Construction time quality/speed tradeoff\n    EfSearch        int  // Search time quality/speed tradeoff\n}\n</code></pre> <pre><code>// toolsemantic/hybrid.go\n\n// HybridSearcher combines multiple retrieval methods\ntype HybridSearcher interface {\n    // Search performs hybrid search across all configured retrievers\n    Search(ctx context.Context, query string, opts HybridOptions) ([]SearchResult, error)\n\n    // Explain returns detailed scoring breakdown\n    Explain(ctx context.Context, query string, docID string) (*ScoreExplanation, error)\n}\n\ntype HybridOptions struct {\n    TopK            int\n\n    // Retrieval weights (must sum to 1.0)\n    BM25Weight      float32  // Weight for BM25/keyword results\n    VectorWeight    float32  // Weight for vector similarity results\n    GraphWeight     float32  // Weight for knowledge graph results\n\n    // Fusion strategy\n    FusionMethod    FusionMethod  // RRF, WeightedSum, Borda\n\n    // Reranking\n    EnableReranker  bool\n    RerankerTopK    int  // Rerank top N results\n\n    // Filters\n    Namespaces      []string\n    Tags            []string\n    MetadataFilters map[string]any\n}\n\ntype FusionMethod string\n\nconst (\n    FusionRRF         FusionMethod = \"rrf\"          // Reciprocal Rank Fusion\n    FusionWeightedSum FusionMethod = \"weighted_sum\" // Weighted score combination\n    FusionBorda       FusionMethod = \"borda\"        // Borda count ranking\n)\n\ntype SearchResult struct {\n    ID          string\n    Score       float32\n    Content     string\n    Metadata    map[string]any\n\n    // Detailed scores\n    BM25Score   float32\n    VectorScore float32\n    GraphScore  float32\n    RerankerScore float32\n\n    // Source tracking\n    Sources     []string  // Which retrievers contributed\n}\n\ntype ScoreExplanation struct {\n    FinalScore    float32\n    FusionMethod  FusionMethod\n    Components    []ScoreComponent\n    RerankerBoost float32\n}\n\ntype ScoreComponent struct {\n    Source      string   // \"bm25\", \"vector\", \"graph\"\n    RawScore    float32\n    Weight      float32\n    WeightedScore float32\n    Rank        int\n}\n</code></pre> <pre><code>// toolsemantic/reranker.go\n\n// Reranker performs cross-encoder reranking on retrieved results\ntype Reranker interface {\n    // Rerank scores query-document pairs using cross-encoder\n    Rerank(ctx context.Context, query string, docs []RerankerInput) ([]RerankerResult, error)\n\n    // Model returns the reranker model identifier\n    Model() string\n}\n\ntype RerankerInput struct {\n    ID      string\n    Content string\n}\n\ntype RerankerResult struct {\n    ID    string\n    Score float32  // Cross-encoder relevance score\n}\n\n// RerankerConfig configures a reranker\ntype RerankerConfig struct {\n    Provider  string  // \"cohere\", \"jina\", \"local\", \"colbert\"\n    Model     string  // \"rerank-english-v3.0\", \"ms-marco-MiniLM\"\n    MaxTokens int     // Max input tokens\n    BatchSize int     // Batch size for efficiency\n}\n</code></pre> <pre><code>// toolsemantic/graph.go\n\n// KnowledgeGraph provides graph-based retrieval (GraphRAG)\ntype KnowledgeGraph interface {\n    // Build extracts entities and relationships from documents\n    Build(ctx context.Context, docs []GraphDocument) error\n\n    // Query retrieves relevant subgraph for a query\n    Query(ctx context.Context, query string, opts GraphQueryOptions) (*GraphResult, error)\n\n    // GetEntity retrieves a specific entity\n    GetEntity(ctx context.Context, id string) (*Entity, error)\n\n    // TraverseRelations walks relationships from an entity\n    TraverseRelations(ctx context.Context, entityID string, depth int) ([]Relationship, error)\n}\n\ntype GraphDocument struct {\n    ID      string\n    Content string\n    Metadata map[string]any\n}\n\ntype GraphQueryOptions struct {\n    MaxEntities     int\n    MaxRelationships int\n    TraversalDepth  int\n    IncludeCommunities bool  // Include community summaries\n}\n\ntype GraphResult struct {\n    Entities      []Entity\n    Relationships []Relationship\n    Communities   []Community     // High-level community summaries\n    Summary       string          // Graph-generated summary\n    Score         float32\n}\n\ntype Entity struct {\n    ID          string\n    Name        string\n    Type        string            // \"tool\", \"namespace\", \"concept\"\n    Description string\n    Attributes  map[string]any\n    Embedding   []float32\n}\n\ntype Relationship struct {\n    ID       string\n    Source   string  // Entity ID\n    Target   string  // Entity ID\n    Type     string  // \"uses\", \"depends_on\", \"similar_to\"\n    Weight   float32\n    Metadata map[string]any\n}\n\ntype Community struct {\n    ID       string\n    Name     string\n    Summary  string\n    Entities []string  // Entity IDs in this community\n    Level    int       // Hierarchy level (0 = most granular)\n}\n</code></pre> <pre><code>// toolsemantic/hierarchical.go\n\n// HierarchicalChunker implements tree-structured document chunking\ntype HierarchicalChunker interface {\n    // Chunk splits document into hierarchical tree structure\n    Chunk(ctx context.Context, doc *Document) (*ChunkTree, error)\n\n    // Retrieve navigates tree to find relevant chunks\n    Retrieve(ctx context.Context, tree *ChunkTree, query string, opts TreeOptions) ([]Chunk, error)\n}\n\ntype Document struct {\n    ID       string\n    Content  string\n    Metadata map[string]any\n}\n\ntype ChunkTree struct {\n    Root     *ChunkNode\n    Depth    int\n    NumNodes int\n}\n\ntype ChunkNode struct {\n    ID        string\n    Level     int           // 0 = leaf, higher = more abstract\n    Content   string        // Text content or summary\n    Embedding []float32\n    Children  []*ChunkNode\n    Parent    *ChunkNode\n\n    // For RAPTOR-style summarization\n    Summary   string        // LLM-generated summary at this level\n}\n\ntype Chunk struct {\n    ID        string\n    Content   string\n    Level     int\n    Score     float32\n    Path      []string  // Path from root to this chunk\n}\n\ntype TreeOptions struct {\n    MaxChunks     int\n    MinLevel      int  // Minimum abstraction level to consider\n    MaxLevel      int  // Maximum abstraction level\n\n    // Traversal strategy\n    Strategy      TraversalStrategy\n}\n\ntype TraversalStrategy string\n\nconst (\n    TraversalTopDown    TraversalStrategy = \"top_down\"    // Start from summaries\n    TraversalBottomUp   TraversalStrategy = \"bottom_up\"   // Start from leaves\n    TraversalCollapsed  TraversalStrategy = \"collapsed\"   // RAPTOR-style collapsed tree\n)\n</code></pre> <pre><code>// toolsemantic/agentic.go\n\n// AgenticRetriever implements LLM-enhanced retrieval strategies\ntype AgenticRetriever interface {\n    // Retrieve performs agentic retrieval with optional query expansion\n    Retrieve(ctx context.Context, query string, opts AgenticOptions) (*AgenticResult, error)\n}\n\ntype AgenticOptions struct {\n    // Query expansion\n    EnableQueryExpansion  bool\n    MaxExpandedQueries    int\n\n    // Multi-query\n    EnableMultiQuery      bool\n    QueryVariations       int\n\n    // Self-reasoning (Step-Back, Chain-of-Thought)\n    EnableSelfReasoning   bool\n    ReasoningDepth        int\n\n    // Iterative retrieval\n    EnableIterative       bool\n    MaxIterations         int\n    StopCondition         func(results []SearchResult) bool\n\n    // Base retriever to use\n    BaseRetriever         HybridSearcher\n}\n\ntype AgenticResult struct {\n    Results          []SearchResult\n\n    // Agentic metadata\n    ExpandedQueries  []string\n    ReasoningChain   []ReasoningStep\n    Iterations       int\n\n    // Quality signals\n    Confidence       float32\n    CoverageScore    float32\n}\n\ntype ReasoningStep struct {\n    Step        int\n    Query       string\n    Reasoning   string   // LLM explanation\n    ResultCount int\n    TopScore    float32\n}\n</code></pre> <pre><code>// toolsemantic/colbert.go\n\n// ColBERTIndex implements late interaction retrieval\ntype ColBERTIndex interface {\n    // Index adds documents with token-level embeddings\n    Index(ctx context.Context, docs []ColBERTDocument) error\n\n    // Search performs MaxSim-based late interaction search\n    Search(ctx context.Context, query string, opts ColBERTOptions) ([]ColBERTResult, error)\n}\n\ntype ColBERTDocument struct {\n    ID           string\n    Content      string\n    TokenEmbeddings [][]float32  // Per-token embeddings\n}\n\ntype ColBERTOptions struct {\n    TopK         int\n    NCells       int   // For PLAID centroid-based search\n    NDocs        int   // Candidate docs before rescoring\n}\n\ntype ColBERTResult struct {\n    ID           string\n    Score        float32  // MaxSim score\n    TokenScores  []TokenMatch  // Token-level matching details\n}\n\ntype TokenMatch struct {\n    QueryToken  string\n    DocToken    string\n    Score       float32\n}\n</code></pre> <p>Integration with Existing Libraries:</p> <pre><code>// toolsemantic/integration.go\n\n// SemanticSearcher wraps toolsearch.Searcher with semantic capabilities\ntype SemanticSearcher struct {\n    // Existing BM25 searcher\n    bm25     toolsearch.Searcher\n\n    // New semantic components\n    embedder     Embedder\n    vectorIndex  VectorIndex\n    reranker     Reranker\n    graph        KnowledgeGraph\n\n    // Configuration\n    config       SemanticConfig\n}\n\n// Search implements toolindex.Searcher interface\nfunc (s *SemanticSearcher) Search(ctx context.Context, query string, opts toolsearch.Options) ([]toolsearch.Result, error) {\n    // Perform hybrid search internally\n    hybridResults, err := s.hybridSearch(ctx, query, HybridOptions{\n        TopK:         opts.Limit,\n        BM25Weight:   s.config.BM25Weight,\n        VectorWeight: s.config.VectorWeight,\n        GraphWeight:  s.config.GraphWeight,\n        EnableReranker: s.config.EnableReranker,\n    })\n    if err != nil {\n        return nil, err\n    }\n\n    // Convert to toolsearch.Result format\n    return convertResults(hybridResults), nil\n}\n\n// NewSemanticSearcher creates a semantic searcher that wraps BM25\nfunc NewSemanticSearcher(bm25 toolsearch.Searcher, opts ...SemanticOption) (*SemanticSearcher, error) {\n    // ...\n}\n</code></pre> <p>Configuration Example:</p> <pre><code># metatools.yaml\nsemantic:\n  enabled: true\n\n  embedder:\n    provider: openai\n    model: text-embedding-3-small\n    dimensions: 1536\n\n  vector_index:\n    backend: memory  # memory, faiss, qdrant, chromadb\n    metric: cosine\n    index_type: hnsw\n    hnsw:\n      m: 16\n      ef_construction: 200\n      ef_search: 100\n\n  hybrid:\n    bm25_weight: 0.4\n    vector_weight: 0.5\n    graph_weight: 0.1\n    fusion_method: rrf\n\n  reranker:\n    enabled: true\n    provider: cohere\n    model: rerank-english-v3.0\n    top_k: 20\n\n  graph:\n    enabled: false  # Experimental\n    entity_types: [\"tool\", \"namespace\", \"concept\"]\n\n  agentic:\n    enabled: false  # Experimental\n    query_expansion: true\n    max_iterations: 3\n</code></pre> <p>Performance Characteristics:</p> Component Latency Memory Accuracy Impact BM25 (baseline) ~8ms Low Baseline (78%) Vector (HNSW) ~12ms Medium +8% (86%) Hybrid (BM25+Vector) ~25ms Medium +16% (94%) + Reranker +50-100ms Low +3% (97%) + GraphRAG +100-200ms High +2% (context) + Agentic +500-2000ms Low Variable <p>Research-Based Accuracy Benchmarks (Tool Discovery):</p> Method Accuracy @ 50 tools @ 200 tools @ 500 tools BM25 only 78% 71% 63% Vector only 82% 76% 69% Hybrid (BM25+Vector) 94% 89% 84% Hybrid + Reranker 97% 94% 91% Hybrid + Reranker + Graph 98% 96% 93% <p>Edge Cases:</p> <ul> <li>[ ] Empty embedding: reject with ErrEmptyInput</li> <li>[ ] Dimension mismatch: validate at index time</li> <li>[ ] Reranker timeout: fall back to hybrid-only results</li> <li>[ ] Graph disconnected: handle isolated entities</li> <li>[ ] Query expansion loop: max iteration limit</li> <li>[ ] OOM on large indices: streaming/pagination support</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#stream-e-agent-skills","title":"Stream E: Agent Skills","text":"<p>Goal: Higher-level agent capabilities that compose tools into reusable workflows and behaviors.</p> <p>Design Insight: Skills sit above tools in the abstraction hierarchy. While tools are atomic operations (search, execute, describe), skills are reusable agent behaviors that orchestrate multiple tools (research-and-summarize, debug-and-fix, deploy-with-validation).</p> Phase Work Package Duration Deliverables E1 Skill Core 2 weeks Skill interface, registry, manifest E2 Skill Composition 1 week Workflow DSL, step orchestration E3 Skill Execution 1 week Runtime, context propagation, rollback <p>Total: 4 weeks (can start after Stream B Protocol Layer)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#abstraction-hierarchy","title":"Abstraction Hierarchy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        AGENTS                                \u2502\n\u2502  (Autonomous decision makers: Claude, GPT, custom agents)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502 use\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        SKILLS (NEW)                          \u2502\n\u2502  Higher-level behaviors: research, debug, deploy, review    \u2502\n\u2502  Composed from multiple tools with workflow logic           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502 orchestrate\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        TOOLSETS                              \u2502\n\u2502  Curated tool collections: dev-tools, search-tools          \u2502\n\u2502  Filtered by namespace, tags, access policy                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502 contain\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         TOOLS                                \u2502\n\u2502  Atomic operations: search_tools, run_tool, describe_tool   \u2502\n\u2502  Single-purpose, composable primitives                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#e1-skill-core-2-weeks","title":"E1: Skill Core (2 weeks)","text":"<pre><code>Week 18:\n\u251c\u2500\u2500 Day 1-2: Skill interface definition\n\u251c\u2500\u2500 Day 3-4: SkillManifest type (A2A-aligned)\n\u251c\u2500\u2500 Day 5: SkillRegistry implementation\n\nWeek 19:\n\u251c\u2500\u2500 Day 1-2: Skill discovery and advertisement\n\u251c\u2500\u2500 Day 3-4: Skill versioning integration\n\u251c\u2500\u2500 Day 5: Unit tests, documentation\n</code></pre> <p>Interface Contract: <pre><code>// toolskill/skill.go\ntype Skill interface {\n    // Identity\n    ID() string\n    Name() string\n    Version() semver.Version\n\n    // Manifest for discovery/advertisement\n    Manifest() *SkillManifest\n\n    // Execution\n    Execute(ctx context.Context, input SkillInput) (*SkillOutput, error)\n\n    // Introspection\n    RequiredTools() []string\n    Steps() []StepDefinition\n}\n\n// SkillManifest describes skill capabilities (A2A-aligned)\ntype SkillManifest struct {\n    ID          string            `json:\"id\"`\n    Name        string            `json:\"name\"`\n    Version     string            `json:\"version\"`\n    Description string            `json:\"description\"`\n    InputSchema *jsonschema.Schema `json:\"inputSchema\"`\n    OutputSchema *jsonschema.Schema `json:\"outputSchema,omitempty\"`\n    Tags        []string          `json:\"tags\"`\n\n    // Dependencies\n    RequiredTools []string        `json:\"requiredTools\"`\n    RequiredSkills []string       `json:\"requiredSkills,omitempty\"`\n\n    // Execution hints\n    EstimatedSteps int            `json:\"estimatedSteps\"`\n    Idempotent     bool           `json:\"idempotent\"`\n    SupportsPause  bool           `json:\"supportsPause\"`\n}\n\n// SkillRegistry manages skill discovery and lookup\ntype SkillRegistry interface {\n    Register(skill Skill) error\n    Get(id string) (Skill, error)\n    GetByName(name string, versionConstraint string) (Skill, error)\n    List() []SkillManifest\n    ListByTag(tag string) []SkillManifest\n    Unregister(id string) error\n\n    // Discovery for A2A\n    Advertise() []SkillManifest\n}\n</code></pre></p> <p>Design Patterns from Research:</p> Framework Pattern Adaptation for toolskill LangChain Chains (sequential) <code>SequentialSkill</code> with steps LangChain Agents (decision) <code>AdaptiveSkill</code> with branching CrewAI Crews (role-based) <code>CompositeSkill</code> with sub-skills CrewAI Flows (control) <code>WorkflowSkill</code> with explicit flow AutoGen Conversation <code>ConversationalSkill</code> with memory"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#skillmd-standard-format-support","title":"SKILL.md Standard Format Support","text":"<p>The toolskill library will implement the Agent Skills Open Standard (adopted by Claude Code, OpenAI Codex CLI, ChatGPT, and Google Antigravity) to ensure cross-platform compatibility.</p> <p>Standard SKILL.md Structure: <pre><code>---\nname: skill-name-with-hyphens\ndescription: Use when [specific triggering conditions and symptoms]\nmetadata:\n  author: optional-author\n  version: \"1.0.0\"\n  argument-hint: optional-hint\n---\n\n# Skill Name\n\n## Overview\nWhat is this? Core principle in 1-2 sentences.\n\n## When to Use\nSymptoms and use cases.\n\n## How It Works\nStep-by-step process.\n\n[Additional sections as needed]\n</code></pre></p> <p>Standard Directory Structure: <pre><code>skills/\n  skill-name/\n    SKILL.md              # Main entry point (required)\n    references/           # Optional supporting files\n      summary.md\n      files.md\n    scripts/              # Optional executable tools\n      validate.sh\n</code></pre></p> <p>Discovery Locations (Claude Code compatible): - User settings: <code>~/.claude/skills/</code> or <code>~/.config/claude/skills/</code> - Project settings: <code>.claude/skills/</code> - Plugin-provided: <code>plugins/*/skills/</code> - Nested directories: Automatic discovery in subdirectories</p> <p>Interface Contract for SKILL.md Parsing: <pre><code>// toolskill/skillmd/parser.go\n\n// SkillMD represents a parsed SKILL.md file\ntype SkillMD struct {\n    // YAML Frontmatter\n    Name        string            `yaml:\"name\"`\n    Description string            `yaml:\"description\"`\n    License     string            `yaml:\"license,omitempty\"`\n    Metadata    map[string]any    `yaml:\"metadata,omitempty\"`\n\n    // Parsed Content\n    Content     string            // Raw markdown content\n    Overview    string            // Extracted ## Overview section\n    WhenToUse   string            // Extracted ## When to Use section\n    HowItWorks  string            // Extracted ## How It Works section\n    Sections    map[string]string // All other sections\n}\n\n// Parser reads and parses SKILL.md files\ntype Parser interface {\n    Parse(path string) (*SkillMD, error)\n    ParseBytes(data []byte) (*SkillMD, error)\n    Validate(skill *SkillMD) []ValidationError\n}\n\n// Generator creates SKILL.md files from skills\ntype Generator interface {\n    Generate(skill Skill) ([]byte, error)\n    GenerateWithTemplate(skill Skill, template string) ([]byte, error)\n}\n\n// Discovery finds skills in standard locations\ntype Discovery interface {\n    // Scan standard locations for skills\n    ScanUserSkills() ([]SkillMD, error)           // ~/.claude/skills/\n    ScanProjectSkills(root string) ([]SkillMD, error) // .claude/skills/\n    ScanPluginSkills(pluginDir string) ([]SkillMD, error)\n\n    // Watch for changes\n    Watch(ctx context.Context, locations []string) (&lt;-chan SkillEvent, error)\n}\n</code></pre></p> <p>Cross-Platform Export: <pre><code>// toolskill/export/exporter.go\n\ntype Exporter interface {\n    // Export to standard SKILL.md format (Claude, Codex, ChatGPT)\n    ToSkillMD(skill Skill) (*SkillMD, error)\n\n    // Export to platform-specific formats\n    ToZIP(skill Skill) ([]byte, error)          // Claude/OpenAI upload\n    ToTarGz(skill Skill) ([]byte, error)        // Gemini upload\n\n    // Batch export\n    ExportDirectory(skills []Skill, path string) error\n}\n\n// Import from SKILL.md files\ntype Importer interface {\n    // Import single skill\n    FromSkillMD(md *SkillMD) (Skill, error)\n\n    // Batch import from directory\n    FromDirectory(path string) ([]Skill, error)\n\n    // Import from skill repository URL\n    FromRepository(url string) ([]Skill, error)\n}\n</code></pre></p> <p>Key Design Decisions:</p> <ol> <li> <p>Frontmatter Limited to name + description: Per standard, only these fields are guaranteed. Additional metadata is optional.</p> </li> <li> <p>Description Format: Must start with \"Use when...\" to optimize for Claude's skill discovery algorithm.</p> </li> <li> <p>Progressive Disclosure: Skills loaded on-demand based on description matching, not pre-loaded (reduces context window usage).</p> </li> <li> <p>Flat Namespace: All skills in searchable namespace for discovery. No nested hierarchies.</p> </li> <li> <p>Token Efficiency: Frequently-loaded skills should be &lt;200 words. Reference material in separate files.</p> </li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#e2-skill-composition-1-week","title":"E2: Skill Composition (1 week)","text":"<pre><code>Week 20:\n\u251c\u2500\u2500 Day 1-2: Step definition DSL\n\u251c\u2500\u2500 Day 3: Sequential composition\n\u251c\u2500\u2500 Day 4: Parallel composition\n\u251c\u2500\u2500 Day 5: Conditional branching\n</code></pre> <p>Interface Contract: <pre><code>// toolskill/step.go\ntype StepDefinition struct {\n    ID          string\n    Name        string\n    Tool        string              // Tool to execute\n    InputMapper func(SkillContext) any  // Map skill input to tool input\n    OutputMapper func(any) any      // Transform tool output\n    Condition   func(SkillContext) bool // Skip if returns false\n    OnError     ErrorHandler\n}\n\n// toolskill/builder.go\ntype SkillBuilder struct { ... }\n\nfunc NewSkillBuilder(name string) *SkillBuilder\n\n// Sequential steps\nfunc (b *SkillBuilder) Step(name string, tool string) *StepBuilder\n\n// Parallel execution\nfunc (b *SkillBuilder) Parallel(steps ...*StepBuilder) *SkillBuilder\n\n// Conditional branching\nfunc (b *SkillBuilder) Branch(condition func(SkillContext) bool,\n                              ifTrue *SkillBuilder,\n                              ifFalse *SkillBuilder) *SkillBuilder\n\n// Sub-skill composition\nfunc (b *SkillBuilder) UseSkill(skillID string) *SkillBuilder\n\n// Build final skill\nfunc (b *SkillBuilder) Build() (Skill, error)\n</code></pre></p> <p>Example: Research-and-Summarize Skill <pre><code>researchSkill := NewSkillBuilder(\"research-and-summarize\").\n    WithDescription(\"Research a topic and provide a summary\").\n    WithInputSchema(researchInputSchema).\n\n    // Step 1: Search for relevant tools\n    Step(\"discover\", \"search_tools\").\n        WithInput(func(ctx SkillContext) any {\n            return map[string]any{\"query\": ctx.Input[\"topic\"]}\n        }).\n\n    // Step 2: Get documentation for top results\n    Parallel(\n        Step(\"docs-1\", \"describe_tool\").WithInput(fromResult(0)),\n        Step(\"docs-2\", \"describe_tool\").WithInput(fromResult(1)),\n        Step(\"docs-3\", \"describe_tool\").WithInput(fromResult(2)),\n    ).\n\n    // Step 3: Synthesize findings\n    Step(\"synthesize\", \"run_tool\").\n        WithInput(func(ctx SkillContext) any {\n            return synthesizeInputs(ctx)\n        }).\n\n    Build()\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#e3-skill-execution-1-week","title":"E3: Skill Execution (1 week)","text":"<pre><code>Week 21:\n\u251c\u2500\u2500 Day 1-2: Skill runtime with context\n\u251c\u2500\u2500 Day 3: Progress tracking, checkpoints\n\u251c\u2500\u2500 Day 4: Rollback on failure\n\u251c\u2500\u2500 Day 5: Integration with toolobserve\n</code></pre> <p>Interface Contract: <pre><code>// toolskill/runtime.go\ntype SkillRuntime interface {\n    Execute(ctx context.Context, skill Skill, input SkillInput) (*SkillOutput, error)\n    ExecuteAsync(ctx context.Context, skill Skill, input SkillInput) (ExecutionID, error)\n\n    // Progress and control\n    GetStatus(execID ExecutionID) (*ExecutionStatus, error)\n    Pause(execID ExecutionID) error\n    Resume(execID ExecutionID) error\n    Cancel(execID ExecutionID) error\n\n    // Checkpoints for long-running skills\n    Checkpoint(execID ExecutionID) (*Checkpoint, error)\n    RestoreFromCheckpoint(checkpoint *Checkpoint) (ExecutionID, error)\n}\n\n// SkillContext provides execution context to steps\ntype SkillContext struct {\n    Input      map[string]any      // Original skill input\n    Results    map[string]any      // Results from previous steps\n    Metadata   map[string]any      // Execution metadata\n    Toolset    *toolset.Toolset    // Available tools\n    Logger     Logger              // Structured logging\n    Tracer     trace.Tracer        // OpenTelemetry tracing\n}\n\n// ExecutionStatus tracks skill progress\ntype ExecutionStatus struct {\n    ID            ExecutionID\n    SkillID       string\n    State         ExecutionState  // pending, running, paused, completed, failed\n    CurrentStep   string\n    CompletedSteps []string\n    Progress      float64         // 0.0 to 1.0\n    StartedAt     time.Time\n    Error         error\n}\n</code></pre></p> <p>Edge Cases: - [ ] Step timeout: configurable per-step, fail or skip - [ ] Tool not found: fail skill with ErrMissingTool - [ ] Parallel step failure: configurable (fail-fast or continue) - [ ] Checkpoint restore: validate skill version compatibility - [ ] Circular skill dependencies: detect and reject at registration</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#skill-tool-integration","title":"Skill-Tool Integration","text":"<pre><code>// Expose skills via MCP as special tools\ntype SkillToolProvider struct {\n    registry SkillRegistry\n    runtime  SkillRuntime\n}\n\nfunc (p *SkillToolProvider) Tools() []*mcp.Tool {\n    var tools []*mcp.Tool\n    for _, manifest := range p.registry.List() {\n        tools = append(tools, &amp;mcp.Tool{\n            Name: \"skill:\" + manifest.Name,\n            Description: \"[SKILL] \" + manifest.Description,\n            InputSchema: manifest.InputSchema,\n        })\n    }\n    return tools\n}\n</code></pre> <p>MCP Tool Naming Convention: - Regular tools: <code>search_tools</code>, <code>run_tool</code> - Skills: <code>skill:research</code>, <code>skill:debug</code>, <code>skill:deploy</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#4-phase-breakdown","title":"4. Phase Breakdown","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#phase-1-mvp-core-weeks-1-7","title":"Phase 1: MVP Core (Weeks 1-7)","text":"<p>Deliverables: - [x] Cobra CLI framework - [x] Koanf configuration - [x] Transport abstraction (stdio, SSE, HTTP) - [x] Provider registry - [x] Basic backend registry</p> <p>Success Criteria: - <code>metatools serve --config config.yaml</code> starts HTTP server - All 13 extension points configurable via YAML - Backward compatible with existing <code>metatools</code> usage</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#phase-2-protocol-layer-weeks-8-14","title":"Phase 2: Protocol Layer (Weeks 8-14)","text":"<p>Deliverables: - [ ] tooladapter library - [ ] toolset library - [ ] Multi-transport exposure</p> <p>Success Criteria: - Tools convertible between MCP \u2194 OpenAI \u2194 Anthropic - Composable toolsets via builder pattern - Same tools exposed via MCP and REST</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#phase-3-cross-cutting-weeks-8-17-parallel","title":"Phase 3: Cross-Cutting (Weeks 8-17, parallel)","text":"<p>Deliverables: - [ ] toolcache (memory, Redis, layered) - [ ] toolobserve (OpenTelemetry) - [ ] toolversion (semantic versioning) - [ ] toolresilience (circuit breaker, retry) - [ ] toolhealth, toolaudit, toolsecrets</p> <p>Success Criteria: - All tool calls traced via OpenTelemetry - Circuit breaker protects against cascade failures - Comprehensive audit log for compliance</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#phase-4-enterprise-weeks-12-17-parallel","title":"Phase 4: Enterprise (Weeks 12-17, parallel)","text":"<p>Deliverables: - [ ] Multi-tenancy (resolvers, middleware, storage) - [ ] toolsemantic (vector search) - [ ] toolresource (MCP Resources) - [ ] toolgateway (auth proxy)</p> <p>Success Criteria: - Multiple tenants isolated by configuration - Semantic search improves tool discovery accuracy - OAuth 2.1 authentication via gateway</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#phase-5-agent-skills-weeks-18-21","title":"Phase 5: Agent Skills (Weeks 18-21)","text":"<p>Deliverables: - [ ] toolskill library (skill interface, registry, manifest) - [ ] Skill composition DSL (sequential, parallel, branching) - [ ] Skill runtime (execution, checkpoints, rollback) - [ ] A2A skill advertisement integration</p> <p>Success Criteria: - Skills discoverable via SkillRegistry.Advertise() - Multi-step skills execute with progress tracking - Skills exposed as MCP tools with <code>skill:</code> prefix - Checkpoint/restore enables long-running skill recovery</p> <p>Dependencies: - Requires Stream B completion (toolset for tool access) - Benefits from Stream C (toolobserve for tracing)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#5-interface-contracts","title":"5. Interface Contracts","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#core-interfaces-must-be-stable","title":"Core Interfaces (Must Be Stable)","text":"Interface Library Breaking Change Policy <code>Tool</code> toolmodel MAJOR version bump <code>Index</code> toolindex MAJOR version bump <code>Searcher</code> toolindex MINOR (additive only) <code>Store</code> tooldocs MINOR (additive only) <code>Runner</code> toolrun MAJOR version bump <code>Backend</code> toolruntime MINOR (additive only)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#new-interfaces-design-phase","title":"New Interfaces (Design Phase)","text":"Interface Library Status Review Required <code>Transport</code> metatools Draft Architecture <code>ToolProvider</code> metatools Draft Architecture <code>BackendRegistry</code> metatools Draft Architecture <code>Adapter</code> tooladapter Draft Protocol Team <code>Cache</code> toolcache Draft Infrastructure <code>Observer</code> toolobserve Draft SRE Team <code>Skill</code> toolskill Draft Agent Team <code>SkillRegistry</code> toolskill Draft Agent Team <code>SkillRuntime</code> toolskill Draft Agent Team <code>Embedder</code> toolsemantic Draft ML/Search Team <code>VectorIndex</code> toolsemantic Draft ML/Search Team <code>HybridSearcher</code> toolsemantic Draft ML/Search Team <code>Reranker</code> toolsemantic Draft ML/Search Team <code>KnowledgeGraph</code> toolsemantic Draft ML/Search Team <code>AgenticRetriever</code> toolsemantic Draft ML/Search Team"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#6-edge-cases-considerations","title":"6. Edge Cases &amp; Considerations","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#interface-evolution","title":"Interface Evolution","text":"Scenario Strategy Add optional field MINOR bump, backward compatible Add required field MAJOR bump, migration guide Remove field Deprecate \u2192 2 releases \u2192 remove Change field type Never (create new field)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#error-handling","title":"Error Handling","text":"Error Type HTTP Code MCP Error Code Retry? Tool not found 404 -32601 No Invalid input 400 -32602 No Backend timeout 504 -32603 Yes Rate limited 429 -32603 Yes (with backoff) Circuit open 503 -32603 Yes (after reset) Internal error 500 -32603 Maybe"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#concurrency","title":"Concurrency","text":"Component Concurrency Model Lock Granularity Provider Registry RWMutex Per-registry Backend Registry RWMutex Per-registry Cache Per-key locking Key-level Circuit Breaker Atomic counters Per-breaker Tenant Store RWMutex Per-tenant Skill Registry RWMutex Per-registry Skill Runtime Per-execution Execution-level"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#resource-limits","title":"Resource Limits","text":"Resource Default Configurable Enforcement Max tools per backend 1000 Yes Registration fails Max concurrent requests 100 Yes 503 response Max request size 10MB Yes 413 response Tool execution timeout 30s Per-tool Context cancellation Cache entry size 1MB Yes Reject large entries"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#7-rollout-strategy","title":"7. Rollout Strategy","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#version-compatibility-matrix","title":"Version Compatibility Matrix","text":"metatools toolmodel toolindex toolrun tooladapter toolskill v0.2.x v0.1.2+ v0.1.8+ v0.1.9+ - - v0.3.x v0.2.0+ v0.2.0+ v0.2.0+ v1.0.0+ - v1.0.x v0.2.0+ v0.2.0+ v0.2.0+ v1.0.0+ - v1.1.x v0.2.0+ v0.2.0+ v0.2.0+ v1.0.0+ v1.0.0+"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#release-cadence","title":"Release Cadence","text":"Track Frequency Stability Use Case stable Monthly Production Enterprise beta Bi-weekly Testing Early adopters nightly Daily Development Contributors"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#migration-guides","title":"Migration Guides","text":"<p>Each MAJOR version bump requires: 1. Migration guide with step-by-step instructions 2. Codemods where possible (automated refactoring) 3. Deprecation period (minimum 2 minor versions) 4. Backward compatibility layer (optional, time-limited)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#feature-flags-for-rollout","title":"Feature Flags for Rollout","text":"<pre><code>feature_flags:\n  new_transport_layer: true      # Phase 2\n  protocol_adapters: false       # Phase 3 (beta)\n  semantic_search: false         # Phase 4 (alpha)\n  multi_tenancy: false           # Phase 4 (alpha)\n  agent_skills: false            # Phase 5 (alpha)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#8-multi-language-extensibility","title":"8. Multi-Language Extensibility","text":"<p>Design Principle: The pluggable architecture is not limited to Go implementations. Any component can be replaced by implementations written in any programming language through standardized interface contracts.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#why-multi-language-matters","title":"Why Multi-Language Matters","text":"Use Case Language Rationale ML/Embedding Models Python Rich ML ecosystem (PyTorch, transformers, sentence-transformers) High-Performance Retrieval Rust Memory safety + near-C performance for vector operations Enterprise Integrations Java Existing corporate libraries, Spring ecosystem Rapid Prototyping TypeScript Fast iteration, existing MCP server implementations Edge Deployment WASM Sandboxed, portable, language-agnostic runtime"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#interface-contract-technologies","title":"Interface Contract Technologies","text":"<p>The architecture supports three proven approaches for multi-language interoperability:</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#option-1-grpc-protocol-buffers-recommended","title":"Option 1: gRPC + Protocol Buffers (Recommended)","text":"<p>Battle-tested approach used by HashiCorp (Terraform, Vault, Consul, Packer).</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            METATOOLS CORE (Go)                                   \u2502\n\u2502                                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                     Plugin Host (go-plugin style)                        \u2502   \u2502\n\u2502   \u2502   - Launches plugins as subprocesses                                     \u2502   \u2502\n\u2502   \u2502   - Communicates via gRPC over local socket                             \u2502   \u2502\n\u2502   \u2502   - Health monitoring and automatic restart                              \u2502   \u2502\n\u2502   \u2502   - Graceful shutdown and resource cleanup                               \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                   \u2502                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502 gRPC (protobuf)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                           \u2502                           \u2502\n        \u25bc                           \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Python Embedder   \u2502   \u2502 Rust Vector Index \u2502   \u2502 TypeScript Adapter\u2502\n\u2502 (sentence-bert)   \u2502   \u2502 (HNSW + SIMD)     \u2502   \u2502 (OpenAI format)   \u2502\n\u2502                   \u2502   \u2502                   \u2502   \u2502                   \u2502\n\u2502 pip install       \u2502   \u2502 cargo build       \u2502   \u2502 npm run build     \u2502\n\u2502 metatools-embed   \u2502   \u2502 --release         \u2502   \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Protocol Buffer Interface Definitions:</p> <pre><code>// api/proto/embedder.proto\nsyntax = \"proto3\";\npackage metatools.v1;\n\nservice Embedder {\n  rpc Embed(EmbedRequest) returns (EmbedResponse);\n  rpc EmbedBatch(EmbedBatchRequest) returns (EmbedBatchResponse);\n  rpc Info(InfoRequest) returns (EmbedderInfo);\n}\n\nmessage EmbedRequest {\n  string text = 1;\n}\n\nmessage EmbedResponse {\n  repeated float embedding = 1;\n}\n\nmessage EmbedderInfo {\n  string model = 1;\n  int32 dimensions = 2;\n}\n</code></pre> <pre><code>// api/proto/searcher.proto\nsyntax = \"proto3\";\npackage metatools.v1;\n\nservice Searcher {\n  rpc Search(SearchRequest) returns (SearchResponse);\n  rpc Index(IndexRequest) returns (IndexResponse);\n  rpc Delete(DeleteRequest) returns (DeleteResponse);\n}\n\nmessage SearchRequest {\n  string query = 1;\n  int32 top_k = 2;\n  map&lt;string, string&gt; filters = 3;\n}\n\nmessage SearchResult {\n  string id = 1;\n  float score = 2;\n  string content = 3;\n  map&lt;string, string&gt; metadata = 4;\n}\n</code></pre> <p>Benefits: - Language-agnostic: Generate client/server stubs for 10+ languages via <code>protoc</code> - Schema evolution: Add fields without breaking backward compatibility - High performance: Binary serialization, HTTP/2 multiplexing - Proven at scale: Used by Kubernetes, gRPC-web, many microservices</p> <p>Real-World Example (HashiCorp go-plugin): <pre><code>// Go host code (metatools)\ntype EmbedderPlugin struct {\n    plugin.Plugin\n    Impl Embedder\n}\n\nfunc (p *EmbedderPlugin) GRPCServer(broker *plugin.GRPCBroker, s *grpc.Server) error {\n    RegisterEmbedderServer(s, &amp;GRPCServer{Impl: p.Impl})\n    return nil\n}\n\nfunc (p *EmbedderPlugin) GRPCClient(ctx context.Context, broker *plugin.GRPCBroker, c *grpc.ClientConn) (interface{}, error) {\n    return &amp;GRPCClient{client: NewEmbedderClient(c)}, nil\n}\n</code></pre></p> <pre><code># Python plugin implementation\nclass PythonEmbedder(metatools_pb2_grpc.EmbedderServicer):\n    def __init__(self):\n        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n\n    def Embed(self, request, context):\n        embedding = self.model.encode(request.text)\n        return metatools_pb2.EmbedResponse(embedding=embedding.tolist())\n\n    def Info(self, request, context):\n        return metatools_pb2.EmbedderInfo(\n            model='all-MiniLM-L6-v2',\n            dimensions=384\n        )\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#option-2-webassembly-component-model-emerging","title":"Option 2: WebAssembly Component Model (Emerging)","text":"<p>Sandboxed, portable, no network overhead.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            METATOOLS CORE (Go)                                   \u2502\n\u2502                                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                     WASM Runtime (wasmtime/wasmer)                       \u2502   \u2502\n\u2502   \u2502   - Load .wasm modules as plugins                                        \u2502   \u2502\n\u2502   \u2502   - WebAssembly Interface Types (WIT) for type-safe boundaries          \u2502   \u2502\n\u2502   \u2502   - WASI for system access (filesystem, network)                         \u2502   \u2502\n\u2502   \u2502   - Strong sandbox: memory isolation, capability-based security          \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                   \u2502                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502 WebAssembly Interface Types (WIT)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                           \u2502                           \u2502\n        \u25bc                           \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Rust \u2192 WASM       \u2502   \u2502 Go \u2192 WASM         \u2502   \u2502 Python \u2192 WASM     \u2502\n\u2502 (vector_index.wasm\u2502   \u2502 (adapter.wasm)    \u2502   \u2502 (embedder.wasm)   \u2502\n\u2502  via wasm32-wasi) \u2502   \u2502  via TinyGo       \u2502   \u2502  via Pyodide      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>WebAssembly Interface Types (WIT) Definition:</p> <pre><code>// api/wit/embedder.wit\npackage metatools:embedder@1.0.0;\n\ninterface embedder {\n    record embed-request {\n        text: string,\n    }\n\n    record embed-response {\n        embedding: list&lt;f32&gt;,\n    }\n\n    record embedder-info {\n        model: string,\n        dimensions: u32,\n    }\n\n    embed: func(request: embed-request) -&gt; result&lt;embed-response, string&gt;;\n    info: func() -&gt; embedder-info;\n}\n\nworld embedder-plugin {\n    export embedder;\n}\n</code></pre> <p>Benefits: - Sandboxed: Strong isolation, no access beyond granted capabilities - Portable: Same .wasm binary runs on any platform - No network overhead: Direct function calls, not RPC - Multi-language: Rust, Go (TinyGo), C/C++, AssemblyScript compile to WASM</p> <p>Limitations: - Ecosystem still maturing (WASI Preview 2 released 2024) - Some languages have limited WASM support - Performance overhead for complex data marshaling</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#option-3-json-rpc-over-stdio-simple","title":"Option 3: JSON-RPC over stdio (Simple)","text":"<p>Lightweight approach for simple plugins.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            METATOOLS CORE (Go)                                   \u2502\n\u2502                                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                     JSON-RPC Dispatcher                                  \u2502   \u2502\n\u2502   \u2502   - Spawn plugin process                                                 \u2502   \u2502\n\u2502   \u2502   - Send JSON-RPC requests via stdin                                     \u2502   \u2502\n\u2502   \u2502   - Receive JSON-RPC responses via stdout                                \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                   \u2502                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502 JSON-RPC 2.0 over stdin/stdout\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                           \u2502                           \u2502\n        \u25bc                           \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Any executable    \u2502   \u2502 Shell script      \u2502   \u2502 Node.js script    \u2502\n\u2502 (simple wrapper)  \u2502   \u2502 (bash/zsh)        \u2502   \u2502 (quick prototype) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits: - Trivial to implement: Any language that reads stdin and writes stdout - No dependencies: No gRPC libraries, no WASM runtime - Debugging friendly: Human-readable JSON messages</p> <p>Limitations: - Performance: Text serialization slower than binary - No streaming: Request-response only - Less type safety: JSON schema validation required</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#recommended-approach-by-component","title":"Recommended Approach by Component","text":"Component Recommended Rationale Embedder gRPC (Python) ML ecosystem, batch processing, GPU support VectorIndex gRPC (Rust) or WASM Performance-critical, SIMD optimization Reranker gRPC (Python) Hugging Face transformers, cross-encoders KnowledgeGraph gRPC (Python/Java) Neo4j, NetworkX, JanusGraph bindings Adapter Go native or WASM Simple logic, low latency Cache Go native Redis/memory clients well-supported in Go"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#plugin-sdk-generation","title":"Plugin SDK Generation","text":"<p>The architecture supports automatic SDK generation from Protocol Buffer definitions:</p> <pre><code># Generate SDKs for all supported languages\nmake generate-sdks\n\n# Outputs:\n# - sdk/go/       (native Go interfaces)\n# - sdk/python/   (gRPC stubs + helper classes)\n# - sdk/rust/     (gRPC stubs + traits)\n# - sdk/typescript/ (gRPC-web stubs)\n</code></pre> <p>Python SDK Example:</p> <pre><code># sdk/python/metatools/embedder.py\nfrom abc import ABC, abstractmethod\nfrom metatools.proto import embedder_pb2, embedder_pb2_grpc\n\nclass BaseEmbedder(embedder_pb2_grpc.EmbedderServicer, ABC):\n    \"\"\"Base class for implementing Embedder plugins in Python.\"\"\"\n\n    @abstractmethod\n    def embed(self, text: str) -&gt; list[float]:\n        \"\"\"Generate embedding for text.\"\"\"\n        pass\n\n    @abstractmethod\n    def dimensions(self) -&gt; int:\n        \"\"\"Return embedding dimensions.\"\"\"\n        pass\n\n    @abstractmethod\n    def model_name(self) -&gt; str:\n        \"\"\"Return model identifier.\"\"\"\n        pass\n\n    # gRPC method implementations\n    def Embed(self, request, context):\n        embedding = self.embed(request.text)\n        return embedder_pb2.EmbedResponse(embedding=embedding)\n\n    def Info(self, request, context):\n        return embedder_pb2.EmbedderInfo(\n            model=self.model_name(),\n            dimensions=self.dimensions()\n        )\n\ndef serve(embedder: BaseEmbedder, port: int = 50051):\n    \"\"\"Start the gRPC server for the embedder plugin.\"\"\"\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n    embedder_pb2_grpc.add_EmbedderServicer_to_server(embedder, server)\n    server.add_insecure_port(f'[::]:{port}')\n    server.start()\n    server.wait_for_termination()\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#configuration-for-multi-language-plugins","title":"Configuration for Multi-Language Plugins","text":"<pre><code># metatools.yaml\nplugins:\n  # gRPC plugin (Python embedder)\n  embedder:\n    type: grpc\n    command: \"python -m metatools_embedder\"\n    address: \"localhost:50051\"\n    health_check_interval: 10s\n    restart_on_failure: true\n\n  # WASM plugin (Rust vector index)\n  vector_index:\n    type: wasm\n    module: \"plugins/vector_index.wasm\"\n    memory_limit: 256MB\n    capabilities:\n      - filesystem:read:/data/indices\n\n  # JSON-RPC plugin (quick prototype)\n  custom_adapter:\n    type: jsonrpc\n    command: \"node plugins/adapter.js\"\n    timeout: 5s\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#research-references","title":"Research References","text":"<p>This multi-language architecture is informed by:</p> <ol> <li>HashiCorp go-plugin: Battle-tested gRPC plugin system used by Terraform, Vault, Consul, and Packer for 10+ years</li> <li>gRPC + Protocol Buffers: Industry standard for polyglot microservices, supports 10+ languages</li> <li>WebAssembly Component Model (WCM): Emerging standard for sandboxed, portable plugin systems</li> <li>WASI Preview 2: Standardized system interfaces for WASM (filesystem, network, clocks)</li> <li>Interface Definition Languages (IDL): Contract-first development enabling language-agnostic interoperability</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#summary-roadmap-at-a-glance","title":"Summary: Roadmap at a Glance","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           METATOOLS ROADMAP 2026                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                    \u2502\n\u2502  EXISTING (7 libs)        NEW CORE (2 libs)       CROSS-CUTTING (7 libs)          \u2502\n\u2502  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550      \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550       \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550          \u2502\n\u2502  \u2705 toolmodel             \ud83d\udd32 tooladapter          \ud83d\udd32 toolcache                     \u2502\n\u2502  \u2705 toolindex             \ud83d\udd32 toolset              \ud83d\udd32 toolobserve                   \u2502\n\u2502  \u2705 tooldocs                                      \ud83d\udd32 toolversion                   \u2502\n\u2502  \u2705 toolsearch            ENTERPRISE (5 libs)     \ud83d\udd32 toolresilience                \u2502\n\u2502  \u2705 toolrun               \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550     \ud83d\udd32 toolhealth                    \u2502\n\u2502  \u2705 toolcode              \ud83d\udd32 toolsemantic         \ud83d\udd32 toolaudit                     \u2502\n\u2502  \u2705 toolruntime           \ud83d\udd32 toolresource         \ud83d\udd32 toolsecrets                   \u2502\n\u2502                           \ud83d\udd32 toolgateway          \ud83d\udd32 toolflags                     \u2502\n\u2502                           \ud83d\udd32 toola2a (future)     \ud83d\udd32 toolpressure                  \u2502\n\u2502                           \ud83d\udd32 toolprompt (future)                                   \u2502\n\u2502                                                                                    \u2502\n\u2502  AGENT SKILLS (1 lib)                                                             \u2502\n\u2502  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                                             \u2502\n\u2502  \ud83d\udd32 toolskill             Skill composition, workflows, A2A advertisement         \u2502\n\u2502                                                                                    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502\n\u2502                                                                                    \u2502\n\u2502  TIMELINE                                                                         \u2502\n\u2502  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                                                        \u2502\n\u2502                                                                                    \u2502\n\u2502  Weeks 1-7   [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] MVP Core     \u2502\n\u2502  Weeks 8-14  [\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] Protocol     \u2502\n\u2502  Weeks 8-17  [\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591] Cross-Cut    \u2502\n\u2502  Weeks 12-17 [\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591] Enterprise   \u2502\n\u2502  Weeks 18-21 [\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2588\u2588\u2588\u2588] Agent Skills \u2502\n\u2502                                                                                    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502\n\u2502                                                                                    \u2502\n\u2502  MILESTONES                                                                       \u2502\n\u2502  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                                                       \u2502\n\u2502                                                                                    \u2502\n\u2502  Week 7:  MVP Release (v0.2.0) - CLI, Config, Transport, Providers               \u2502\n\u2502  Week 14: Protocol Release (v0.3.0) - Adapters, Toolsets, Multi-Transport        \u2502\n\u2502  Week 17: Enterprise Release (v1.0.0) - Full feature set                         \u2502\n\u2502  Week 21: Agent Skills Release (v1.1.0) - Skills, Workflows, A2A                 \u2502\n\u2502                                                                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#appendix-document-cross-references","title":"Appendix: Document Cross-References","text":"Document Purpose Status pluggable-architecture.md Core architecture design Active implementation-phases.md Phase details Active component-library-analysis.md Library analysis Complete architecture-evaluation.md Championship comparison Complete protocol-agnostic-tools.md Protocol layer design Active multi-tenancy.md Multi-tenant design Active ROADMAP.md (this document) Master roadmap Active"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/#changelog","title":"Changelog","text":"Date Change 2026-01-28 Architecture Review: Added scope clarification table, fixed Transport interface (added Name()), updated toolskill dependencies 2026-01-28 Added Section 8: Multi-Language Extensibility - gRPC, WASM, JSON-RPC plugin architectures with SDK generation 2026-01-28 Added comprehensive D4 toolsemantic specification: hybrid search, GraphRAG, hierarchical chunking, agentic RAG, ColBERT, cross-encoder reranking 2026-01-28 Added SKILL.md Open Standard support to toolskill (Claude Code, Codex, ChatGPT compatible) 2026-01-28 Added Stream E: Agent Skills with toolskill library proposal 2026-01-28 Initial roadmap created from all proposal documents"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/","title":"Architecture Evaluation: Championship-Level Analysis","text":"<p>Status: Draft Date: 2026-01-28 Related: Pluggable Architecture Proposal, Component Library Analysis</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#executive-summary","title":"Executive Summary","text":"<p>This document evaluates the metatools ecosystem against championship-level implementations and industry best practices. The analysis reveals that your architecture is already at 85-90% of championship-level in core areas, with specific opportunities for advancement in emerging patterns.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Research Methodology</li> <li>Championship Implementations Analyzed</li> <li>Pattern Comparison Matrix</li> <li>What You Already Have (Championship Features)</li> <li>Gaps and Opportunities</li> <li>Recommended Extensions</li> <li>New Libraries to Consider</li> <li>Protocol Evolution (A2A + MCP)</li> <li>Implementation Roadmap</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#research-methodology","title":"Research Methodology","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#sources-analyzed","title":"Sources Analyzed","text":"Source Type Examples Key Insights Production Go Projects Tencent WeKnora (12.5k stars), go-kratos/blades (700 stars) Multi-tenant, agent orchestration patterns MCP Ecosystem Official Go SDK, fastmcp (22k stars), mcp-agent (8k stars) Protocol implementation patterns Industry Standards MCP Spec 2025-11-25, A2A Protocol, Google ADK Protocol interoperability Academic/Industry Research Anthropic context engineering, LangChain patterns Progressive disclosure, semantic discovery"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#key-references","title":"Key References","text":"<ul> <li>MCP Best Practices - Single-purpose servers, transport options</li> <li>Effective Context Engineering - Progressive disclosure</li> <li>A2A Protocol - Agent-to-agent communication</li> <li>Google ADK for Go - Multi-agent patterns</li> <li>Semantic Tool Discovery - Vector-based tool selection</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#championship-implementations-analyzed","title":"Championship Implementations Analyzed","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#1-tencent-weknora-12566-stars","title":"1. Tencent WeKnora (12,566 stars)","text":"<p>What it is: LLM-powered RAG framework with multi-tenant support</p> <p>Architecture Highlights: <pre><code>internal/\n\u251c\u2500\u2500 agent/          # Agent orchestration\n\u2502   \u2514\u2500\u2500 tools/      # Agent-specific tools\n\u251c\u2500\u2500 application/    # Business logic\n\u2502   \u251c\u2500\u2500 repository/ # Data access\n\u2502   \u2514\u2500\u2500 service/    # Service layer\n\u251c\u2500\u2500 handler/        # HTTP handlers\n\u251c\u2500\u2500 middleware/     # Cross-cutting concerns\n\u251c\u2500\u2500 models/         # LLM integrations\n\u2502   \u251c\u2500\u2500 chat/\n\u2502   \u251c\u2500\u2500 embedding/\n\u2502   \u2514\u2500\u2500 rerank/\n\u251c\u2500\u2500 runtime/        # Execution environment\n\u2514\u2500\u2500 types/\n    \u2514\u2500\u2500 interfaces/ # Contract definitions\n</code></pre></p> <p>Key Patterns: - Clean layered architecture (handler \u2192 service \u2192 repository) - Multi-tenant via middleware - Model provider abstraction (chat, embedding, rerank) - Event-driven architecture with adapters</p> <p>Comparison to metatools: | Feature | WeKnora | metatools | Gap | |---------|---------|-----------|-----| | Layered architecture | \u2705 | \u2705 | None | | Multi-tenant | \u2705 Built-in | \ud83d\udccb Proposed | Implement | | Embedding models | \u2705 | \u274c | Extension opportunity | | Reranking | \u2705 | \u274c | Extension opportunity |</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#2-go-kratosblades-700-stars","title":"2. go-kratos/blades (700 stars)","text":"<p>What it is: Multi-agent AI framework from the Kratos team</p> <p>Architecture Highlights: <pre><code>// Tool interface - remarkably similar to toolmodel.Tool\ntype Tool interface {\n    Name() string\n    Description() string\n    InputSchema() *jsonschema.Schema\n    OutputSchema() *jsonschema.Schema\n    Handler\n}\n\n// Middleware chain - identical pattern to your proposal\ntype Handler interface {\n    Handle(context.Context, *Invocation) Generator[*Message, error]\n}\ntype Middleware func(Handler) Handler\n\nfunc ChainMiddlewares(mws ...Middleware) Middleware {\n    return func(next Handler) Handler {\n        h := next\n        for i := len(mws) - 1; i &gt;= 0; i-- {\n            h = mws[i](h)\n        }\n        return h\n    }\n}\n</code></pre></p> <p>Key Patterns: - Generic tool creation with type inference (<code>NewFunc[I, O any]</code>) - Middleware chain (confirm, conversation, retry) - Agent-as-tool pattern (agents can be tools for other agents) - Streaming via Go iterators</p> <p>Comparison to metatools: | Feature | blades | metatools | Gap | |---------|--------|-----------|-----| | Tool interface | \u2705 | \u2705 toolmodel.Tool | None | | Middleware chain | \u2705 | \ud83d\udccb Proposed | Implement | | Generic tool creation | \u2705 | \u274c | Enhancement | | Agent-as-tool | \u2705 | \u274c | Extension | | Streaming | \u2705 Iterators | \u2705 Channels | Different approach |</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#3-official-mcp-go-sdk-modelcontextprotocolgo-sdk","title":"3. Official MCP Go SDK (modelcontextprotocol/go-sdk)","text":"<p>What it is: Reference implementation for MCP in Go</p> <p>Architecture Highlights: <pre><code>type Server struct {\n    impl    *Implementation\n    opts    ServerOptions\n    prompts *featureSet[*serverPrompt]\n    tools   *featureSet[*serverTool]\n    resources *featureSet[*serverResource]\n    sessions []*ServerSession\n    // ...\n}\n\ntype ServerOptions struct {\n    Instructions string\n    Logger *slog.Logger\n    InitializedHandler func(context.Context, *InitializedRequest)\n    PageSize int\n    KeepAlive time.Duration\n    // ...\n}\n</code></pre></p> <p>Key Patterns: - Feature sets for prompts, tools, resources - Session management - Handler-based configuration (functional options) - Built-in SSE support</p> <p>Comparison to metatools: | Feature | MCP SDK | metatools | Gap | |---------|---------|-----------|-----| | Tools registration | \u2705 | \u2705 toolindex | None | | Resources | \u2705 | \u274c | Extension | | Prompts | \u2705 | \u274c | Extension | | SSE transport | \u2705 | \ud83d\udccb Proposed | Implement | | Session management | \u2705 | \u274c | Enhancement |</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#4-fastmcp-22398-stars-python","title":"4. fastmcp (22,398 stars - Python)","text":"<p>What it is: Fastest way to build MCP servers</p> <p>Key Insight: Despite being Python, the architecture patterns are transferable: - Decorator-based tool registration - Context manager patterns for resources - Progressive tool loading for large toolsets</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#5-google-adk-for-go","title":"5. Google ADK for Go","text":"<p>What it is: Agent Development Kit with A2A support</p> <p>Key Features: - MCP integration out of the box - A2A protocol support for multi-agent systems - 30+ database connectors via MCP Toolbox - Built-in observability</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#pattern-comparison-matrix","title":"Pattern Comparison Matrix","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#core-architecture-patterns","title":"Core Architecture Patterns","text":"Pattern Industry Best metatools Status Priority Progressive Disclosure 3-tier (index/details/full) \u2705 tooldocs (summary/schema/full) Done Interface-Based Pluggability All components as interfaces \u2705 13 extension points Done Multi-Backend Per Tool Runtime backend selection \u2705 toolindex BackendSelector Done Middleware Chain Decorator pattern \ud83d\udccb Proposed High Security Profiles dev/standard/hardened \u2705 toolruntime Done Contract Testing Interface compliance tests \u2705 toolruntime Gateway tests Done"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#advanced-patterns","title":"Advanced Patterns","text":"Pattern Industry Best metatools Status Priority Semantic Tool Discovery Vector embeddings + BM25 \u26a0\ufe0f BM25 only (toolsearch) Medium A2A Protocol Agent-to-agent communication \u274c Not implemented Low MCP Resources File/data exposure to LLMs \u274c Not implemented Medium MCP Prompts Reusable prompt templates \u274c Not implemented Low Observability OpenTelemetry tracing \u274c Not implemented High Hot Reload Dynamic tool registration \u26a0\ufe0f Partial (UnregisterBackend) Medium"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#what-you-already-have-championship-features","title":"What You Already Have (Championship Features)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#1-progressive-disclosure-tooldocs","title":"1. Progressive Disclosure (tooldocs)","text":"<p>Your 3-tier documentation system matches industry best practice exactly:</p> <pre><code>// Your implementation matches Anthropic's recommendation\ntype DetailLevel string\nconst (\n    DetailLevelSummary DetailLevel = \"summary\"  // Layer 1: Metadata\n    DetailLevelSchema  DetailLevel = \"schema\"   // Layer 2: Structure\n    DetailLevelFull    DetailLevel = \"full\"     // Layer 3: Complete\n)\n</code></pre> <p>Industry validation: Anthropic's context engineering guide recommends exactly this pattern for token optimization.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#2-multi-backend-tool-registry-toolindex","title":"2. Multi-Backend Tool Registry (toolindex)","text":"<p>Your architecture supports what few frameworks do - multiple backends for the same tool:</p> <pre><code>// Tools can have MCP, Provider, AND Local backends simultaneously\ntype ToolBackend struct {\n    Kind     BackendKind      // mcp, provider, local\n    MCP      *MCPBackend\n    Provider *ProviderBackend\n    Local    *LocalBackend\n}\n\n// Runtime selection via pluggable BackendSelector\ntype BackendSelector func(tool Tool, backends []ToolBackend) ToolBackend\n</code></pre> <p>Industry validation: This matches Google ADK's multi-source pattern.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#3-10-sandbox-backends-toolruntime","title":"3. 10 Sandbox Backends (toolruntime)","text":"<p>Your runtime isolation options exceed most frameworks:</p> Backend Use Case Isolation Level unsafe Development None docker Standard production Container containerd Kubernetes environments Container kubernetes Multi-tenant production Pod + Namespace firecracker High security microVM kata Strong isolation VM gvisor Kernel isolation Sandboxed kernel wasm Portable execution Sandbox temporal Workflow orchestration Durable execution remote Distributed execution Network <p>Industry validation: No other open-source MCP framework offers this breadth.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#4-interface-based-extension-13-points","title":"4. Interface-Based Extension (13 Points)","text":"<p>Your 13 extension points match the Go best practice of interface-based composition:</p> # Interface Purpose 1 SchemaValidator JSON Schema validation 2 Searcher Tool search (BM25, semantic) 3 BackendSelector Multi-backend selection 4 Store Documentation storage 5 ToolResolver Tool resolution 6 Runner Execution orchestration 7 MCPExecutor MCP backend calls 8 ProviderExecutor Provider backend calls 9 LocalRegistry Local handler lookup 10 Backend Sandbox isolation 11 ToolGateway Sandboxed tool access 12 Logger Execution logging 13 Engine Code execution <p>Industry validation: Matches go-kratos/blades interface design philosophy.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#gaps-and-opportunities","title":"Gaps and Opportunities","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#high-priority","title":"High Priority","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#1-observability-tracing-metrics","title":"1. Observability (Tracing + Metrics)","text":"<p>Gap: No built-in OpenTelemetry integration.</p> <p>Why it matters: Production deployments need distributed tracing and metrics.</p> <p>Solution: <pre><code>// New package: toolobserve\ntype Tracer interface {\n    StartSpan(ctx context.Context, name string) (context.Context, Span)\n}\n\ntype MetricsRecorder interface {\n    RecordToolCall(toolID string, duration time.Duration, err error)\n    RecordSearchLatency(query string, duration time.Duration)\n}\n\n// Integration via middleware\nfunc TracingMiddleware(tracer Tracer) toolrun.ExecutionHook {\n    return &amp;tracingHook{tracer: tracer}\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#2-mcp-gateway-auth-analytics","title":"2. MCP Gateway (Auth + Analytics)","text":"<p>Gap: No proxy layer for authentication, rate limiting, analytics.</p> <p>Why it matters: Enterprise deployments need centralized auth and monitoring.</p> <p>Reference: hyprmcp/jetski - OAuth2.1, DCR, real-time logs</p> <p>Solution: <pre><code>// New package: toolgateway\ntype Gateway struct {\n    Auth       AuthProvider\n    RateLimit  RateLimiter\n    Analytics  AnalyticsRecorder\n    Upstream   MCPServer\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#medium-priority","title":"Medium Priority","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#3-semantic-tool-discovery","title":"3. Semantic Tool Discovery","text":"<p>Gap: Only BM25 lexical search, no vector/embedding search.</p> <p>Why it matters: With 50+ tools, semantic search dramatically improves accuracy.</p> <p>Reference: Semantic Tool Discovery</p> <p>Solution: <pre><code>// New package: toolsemantic (implements toolindex.Searcher)\ntype SemanticSearcher struct {\n    embedder   Embedder\n    vectorDB   VectorStore\n    bm25       toolsearch.BM25Searcher // Hybrid: semantic + lexical\n}\n\ntype Embedder interface {\n    Embed(ctx context.Context, text string) ([]float32, error)\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#4-mcp-resources-support","title":"4. MCP Resources Support","text":"<p>Gap: No file/data resource exposure to LLMs.</p> <p>Why it matters: MCP Resources allow LLMs to read files, databases, APIs.</p> <p>Solution: <pre><code>// New extension to toolindex or new package: toolresource\ntype Resource struct {\n    URI         string\n    Name        string\n    Description string\n    MimeType    string\n}\n\ntype ResourceProvider interface {\n    List(ctx context.Context) ([]Resource, error)\n    Read(ctx context.Context, uri string) (io.Reader, error)\n    Subscribe(ctx context.Context, uri string) (&lt;-chan ResourceUpdate, error)\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#low-priority-future","title":"Low Priority (Future)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#5-a2a-protocol-support","title":"5. A2A Protocol Support","text":"<p>Gap: No agent-to-agent communication.</p> <p>Why it matters: Multi-agent systems need standardized communication.</p> <p>Reference: A2A Protocol</p> <p>Solution: <pre><code>// New package: toola2a\ntype AgentCard struct {\n    Name         string\n    Description  string\n    Capabilities []Capability\n    Endpoint     string\n}\n\ntype A2AClient interface {\n    Discover(ctx context.Context, endpoint string) (*AgentCard, error)\n    Invoke(ctx context.Context, agent string, task *Task) (*TaskResult, error)\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#6-mcp-prompts-support","title":"6. MCP Prompts Support","text":"<p>Gap: No reusable prompt template system.</p> <p>Why it matters: Prompts are a core MCP feature for standardized interactions.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#recommended-extensions","title":"Recommended Extensions","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#new-libraries-to-consider","title":"New Libraries to Consider","text":"<p>Based on the analysis, here are potential new libraries that could enhance the ecosystem:</p> Library Purpose Priority Effort toolobserve OpenTelemetry tracing + metrics High 2 weeks toolsemantic Vector-based semantic search Medium 3 weeks toolresource MCP Resources support Medium 2 weeks toolgateway Auth, rate limit, analytics proxy Medium 3 weeks toola2a A2A protocol support Low 4 weeks toolprompt MCP Prompts support Low 1 week"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#updated-dependency-graph","title":"Updated Dependency Graph","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     EXPANDED METATOOLS ECOSYSTEM                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                               \u2502\n\u2502                           \u2502  metatools-mcp  \u2502                               \u2502\n\u2502                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                               \u2502\n\u2502                                    \u2502                                         \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2534\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502    \u2502                              \u2502 \u2502                              \u2502         \u2502\n\u2502    \u25bc                              \u25bc \u25bc                              \u25bc         \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502 \u2502toolgateway\u2502 NEW          \u2502 toolcode \u2502                    \u2502toolobserve\u2502 NEW\u2502\n\u2502 \u2502(auth/proxy)\u2502             \u2502          \u2502                    \u2502(tracing)  \u2502    \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                 \u2502                                            \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502         \u2502                       \u2502                           \u2502               \u2502\n\u2502         \u25bc                       \u25bc                           \u25bc               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502  \u2502  toolrun    \u2502         \u2502  tooldocs   \u2502            \u2502toolresource \u2502 NEW    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502(MCP Resources)\u2502       \u2502\n\u2502         \u2502                       \u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502         \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502         \u2502    \u2502                  \u2502                        \u2502                  \u2502\n\u2502         \u25bc    \u25bc                  \u25bc                        \u25bc                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502  \u2502 toolruntime \u2502         \u2502  toolindex  \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502toolsemantic \u2502 NEW       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502(vector search)\u2502          \u2502\n\u2502         \u2502                       \u2502                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502         \u2502                       \u2502                        \u25b2                  \u2502\n\u2502         \u2502                       \u25bc                        \u2502                  \u2502\n\u2502         \u2502                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  toolmodel  \u2502          \u2502 toolsearch  \u2502           \u2502\n\u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502 (BM25)      \u2502           \u2502\n\u2502                                 \u2502                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502                                 \u25bc                                           \u2502\n\u2502                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2502\n\u2502                   \u2502 modelcontextprotocol/   \u2502                              \u2502\n\u2502                   \u2502       go-sdk            \u2502                              \u2502\n\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502\n\u2502                                                                              \u2502\n\u2502    Future:  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                   \u2502\n\u2502             \u2502 toola2a  \u2502    \u2502toolprompt\u2502                                   \u2502\n\u2502             \u2502(A2A proto)\u2502   \u2502(MCP prompts)\u2502                                 \u2502\n\u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#protocol-evolution","title":"Protocol Evolution","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#mcp-a2a-complementary-protocols","title":"MCP + A2A Complementary Protocols","text":"<p>The industry is converging on two complementary protocols:</p> Protocol Purpose Direction Your Status MCP Agent-to-tool Vertical (depth) \u2705 Implemented A2A Agent-to-agent Horizontal (breadth) \u274c Future <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PROTOCOL LANDSCAPE                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u2502\n\u2502                         \u2502  User   \u2502                             \u2502\n\u2502                         \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502                              \u2502                                   \u2502\n\u2502                         \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510                             \u2502\n\u2502                         \u2502  Host   \u2502                             \u2502\n\u2502                         \u2502  Agent  \u2502                             \u2502\n\u2502                         \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502                              \u2502                                   \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502         \u2502                    \u2502                    \u2502             \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502    \u2502 Remote  \u2502\u25c4\u2500\u2500 A2A \u2500\u2500\u25b6\u2502 Remote \u2502\u25c4\u2500\u2500 A2A \u2500\u2500\u25b6\u2502 Remote \u2502       \u2502\n\u2502    \u2502 Agent 1 \u2502           \u2502 Agent 2\u2502           \u2502 Agent 3\u2502       \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518       \u2502\n\u2502         \u2502                     \u2502                    \u2502            \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510       \u2502\n\u2502    \u2502  MCP    \u2502           \u2502  MCP   \u2502           \u2502  MCP   \u2502       \u2502\n\u2502    \u2502 Server  \u2502           \u2502 Server \u2502           \u2502 Server \u2502       \u2502\n\u2502    \u2502 (tools) \u2502           \u2502 (tools)\u2502           \u2502 (tools)\u2502       \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                                                  \u2502\n\u2502    Legend: A2A = Agent-to-Agent (horizontal)                    \u2502\n\u2502            MCP = Agent-to-Tool (vertical)                       \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#scaling-recommendation-from-anthropic-nov-2025","title":"Scaling Recommendation (from Anthropic Nov 2025)","text":"<p>For 50+ tools, present MCP servers as code APIs instead of direct tool calls:</p> <p>\"This pattern becomes essential when scaling to many tools. You're essentially giving agents a programming environment rather than a function-calling interface.\"</p> <p>Your <code>toolcode</code> package already enables this pattern!</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#updated-timeline-with-extensions","title":"Updated Timeline with Extensions","text":"Phase Focus Duration Libraries Phase 1 CLI + Config 2 weeks metatools-mcp Phase 2 Transport + Observability 2 weeks metatools-mcp, toolobserve (new) Phase 3 Public APIs 1 week All existing Phase 4 Backend Integration 2 weeks toolruntime Phase 5 Semantic Search 2 weeks toolsemantic (new) Phase 6 MCP Resources 2 weeks toolresource (new) Phase 7 Gateway/Proxy 2 weeks toolgateway (new) Total 13 weeks 4 new libraries"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#mvp-phases-1-4-7-weeks","title":"MVP (Phases 1-4): 7 weeks","text":"<p>Core pluggable architecture with observability.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#extended-phases-5-7-6-weeks","title":"Extended (Phases 5-7): +6 weeks","text":"<p>Advanced features for enterprise/production deployments.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#summary-your-position","title":"Summary: Your Position","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#championship-scorecard","title":"Championship Scorecard","text":"Category Score Notes Core Architecture 95% Excellent layering, interfaces, patterns Pluggability 90% 13 extension points, multi-backend Security 95% 10 isolation backends, 3 security profiles Documentation 85% Progressive disclosure implemented Observability 40% Gap - needs OpenTelemetry Semantic Search 60% BM25 good, vectors needed Protocol Coverage 70% MCP tools, missing resources/prompts Overall 85% Championship-adjacent"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#key-takeaway","title":"Key Takeaway","text":"<p>Your architecture is not a framework to be built\u2014it's a mature ecosystem to be exposed and extended. The 7 tool* libraries represent years of thoughtful design that matches or exceeds most open-source alternatives.</p> <p>The path to championship level requires: 1. Exposure (CLI + config) - 2 weeks 2. Observability (toolobserve) - 2 weeks 3. Semantic search (toolsemantic) - 2 weeks 4. MCP completeness (toolresource) - 2 weeks</p> <p>Total to championship: ~8 weeks of focused work.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#changelog","title":"Changelog","text":"Date Change 2026-01-28 Initial comprehensive architecture evaluation 2026-01-28 Analyzed 5 championship-level implementations 2026-01-28 Identified 4 new potential libraries 2026-01-28 Created extended implementation roadmap"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/","title":"Component Library Analysis for Pluggable Architecture","text":"<p>Status: Draft Date: 2026-01-27 Related: Pluggable Architecture Proposal, Implementation Phases</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#overview","title":"Overview","text":"<p>This document analyzes the metatools component library ecosystem and identifies changes needed to support the pluggable architecture. The analysis follows Go Architect principles: layered architecture, clean interfaces, dependency injection, and proper error handling.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#component-library-ecosystem","title":"Component Library Ecosystem","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#dependency-graph","title":"Dependency Graph","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         METATOOLS COMPONENT ECOSYSTEM                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                \u2502\n\u2502                           \u2502  metatools-mcp  \u2502                                \u2502\n\u2502                           \u2502    (v0.1.x)     \u2502                                \u2502\n\u2502                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                \u2502\n\u2502                                    \u2502                                          \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502         \u2502                          \u2502                          \u2502              \u2502\n\u2502         \u25bc                          \u25bc                          \u25bc              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502  \u2502  toolcode   \u2502           \u2502  tooldocs   \u2502           \u2502  toolrun    \u2502        \u2502\n\u2502  \u2502  (v0.1.10)  \u2502           \u2502  (v0.1.10)  \u2502           \u2502  (v0.1.9)   \u2502        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502         \u2502                         \u2502                         \u2502                \u2502\n\u2502         \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2502         \u2502    \u2502                    \u2502                                          \u2502\n\u2502         \u25bc    \u25bc                    \u25bc                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502  \u2502 toolruntime \u2502           \u2502  toolindex  \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502  \u2502  (v0.1.10)  \u2502           \u2502  (v0.1.8)   \u2502                          \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502         \u2502                         \u2502                          \u2502 toolsearch \u2502 \u2502\n\u2502         \u2502                         \u2502                          \u2502  (v0.1.9)  \u2502 \u2502\n\u2502         \u2502                         \u25bc                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502         \u2502                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  toolmodel  \u2502                                  \u2502\n\u2502                            \u2502  (v0.1.2)   \u2502                                  \u2502\n\u2502                            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                  \u2502\n\u2502                                   \u2502                                          \u2502\n\u2502                                   \u25bc                                          \u2502\n\u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u2502\n\u2502                     \u2502 modelcontextprotocol/   \u2502                             \u2502\n\u2502                     \u2502       go-sdk            \u2502                             \u2502\n\u2502                     \u2502       (v1.2.0)          \u2502                             \u2502\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#library-summary-matrix","title":"Library Summary Matrix","text":"Library Version Purpose Key Interfaces Dependencies toolmodel v0.1.2 Core data models <code>Tool</code>, <code>ToolBackend</code>, <code>SchemaValidator</code> mcp go-sdk toolindex v0.1.8 Tool registry <code>Index</code>, <code>Searcher</code>, <code>BackendSelector</code> toolmodel tooldocs v0.1.10 Documentation <code>Store</code>, <code>DetailLevel</code> toolindex, toolmodel toolrun v0.1.9 Execution <code>Runner</code>, <code>MCPExecutor</code>, <code>ProviderExecutor</code>, <code>LocalRegistry</code> toolindex, toolmodel toolcode v0.1.10 Code execution <code>Executor</code>, <code>Engine</code>, <code>Tools</code> toolrun, tooldocs, toolindex toolsearch v0.1.9 BM25 search <code>BM25Searcher</code> (implements <code>Searcher</code>) toolindex, bleve toolruntime v0.1.10 Sandbox runtime <code>Runtime</code>, <code>Backend</code>, <code>ToolGateway</code> toolcode, toolrun, tooldocs"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-1-toolmodel-foundation","title":"Layer 1: toolmodel (Foundation)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state","title":"Current State","text":"<p>The foundational library defining what a \"tool\" is. Zero networking dependencies, safe for embedding.</p> <p>Exported Types: - <code>Tool</code> - Embeds <code>mcp.Tool</code> with extensions (Namespace, Version, Tags) - <code>ToolBackend</code> - Backend binding (Kind, MCP/Provider/Local configs) - <code>BackendKind</code> - Enum: <code>mcp</code>, <code>provider</code>, <code>local</code> - <code>MCPBackend</code>, <code>ProviderBackend</code>, <code>LocalBackend</code> - Backend configs - <code>SchemaValidator</code> - Interface for JSON Schema validation - <code>DefaultValidator</code> - Default implementation using jsonschema-go</p> <p>Key Functions: - <code>Tool.ToolID()</code> - Returns canonical ID (<code>namespace:name</code>) - <code>ParseToolID()</code> - Parses ID string into components - <code>Tool.Validate()</code> - Validates tool invariants - <code>NormalizeTags()</code> - Tag normalization for indexing</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-low-mostly-stable","title":"Priority: LOW (mostly stable)","text":"Change Rationale Impact Add <code>ToolMetadata</code> field Support arbitrary metadata for middleware/backends Minor - additive Add <code>BackendKindHTTP</code> Support HTTP backend type for remote APIs Minor - additive Add <code>BackendKindGRPC</code> Support gRPC backend type Minor - additive Add <code>HTTPBackend</code> struct Config for HTTP backends Minor - additive"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#proposed-additions","title":"Proposed Additions","text":"<pre><code>// New backend kinds for multi-backend architecture\nconst (\n    BackendKindMCP      BackendKind = \"mcp\"\n    BackendKindProvider BackendKind = \"provider\"\n    BackendKindLocal    BackendKind = \"local\"\n    BackendKindHTTP     BackendKind = \"http\"      // NEW\n    BackendKindGRPC     BackendKind = \"grpc\"      // NEW\n)\n\n// HTTPBackend metadata for HTTP API backends\ntype HTTPBackend struct {\n    BaseURL   string            `json:\"baseUrl\"`\n    AuthType  string            `json:\"authType,omitempty\"`  // bearer, oauth2, apikey\n    Headers   map[string]string `json:\"headers,omitempty\"`\n    Timeout   time.Duration     `json:\"timeout,omitempty\"`\n}\n\n// GRPCBackend metadata for gRPC backends\ntype GRPCBackend struct {\n    Address   string `json:\"address\"`\n    TLS       bool   `json:\"tls,omitempty\"`\n    CACert    string `json:\"caCert,omitempty\"`\n}\n\n// ToolBackend - add HTTP and GRPC fields\ntype ToolBackend struct {\n    Kind     BackendKind      `json:\"kind\"`\n    MCP      *MCPBackend      `json:\"mcp,omitempty\"`\n    Provider *ProviderBackend `json:\"provider,omitempty\"`\n    Local    *LocalBackend    `json:\"local,omitempty\"`\n    HTTP     *HTTPBackend     `json:\"http,omitempty\"`      // NEW\n    GRPC     *GRPCBackend     `json:\"grpc,omitempty\"`      // NEW\n}\n\n// Tool - add metadata field\ntype Tool struct {\n    mcp.Tool\n    Namespace string         `json:\"namespace,omitempty\"`\n    Version   string         `json:\"version,omitempty\"`\n    Tags      []string       `json:\"tags,omitempty\"`\n    Metadata  map[string]any `json:\"metadata,omitempty\"`   // NEW\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-2-toolindex-registry","title":"Layer 2: toolindex (Registry)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_1","title":"Current State","text":"<p>Global registry and discovery layer for tools. Thread-safe, supports pluggable search.</p> <p>Exported Types: - <code>Index</code> - Interface for tool registry - <code>InMemoryIndex</code> - Default implementation - <code>Summary</code> - Lightweight search result - <code>SearchDoc</code> - Document for search indexing - <code>Searcher</code> - Interface for search implementations - <code>BackendSelector</code> - Function type for backend selection - <code>ToolRegistration</code> - Tool + Backend pair</p> <p>Key Methods: - <code>RegisterTool()</code>, <code>RegisterTools()</code>, <code>RegisterToolsFromMCP()</code> - <code>GetTool()</code>, <code>GetAllBackends()</code> - <code>Search()</code>, <code>ListNamespaces()</code> - <code>UnregisterBackend()</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_1","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-medium","title":"Priority: MEDIUM","text":"Change Rationale Impact Add <code>ListTools()</code> method Backend aggregation needs full tool list Minor - additive Add <code>BackendSource</code> tracking Track which backend registered a tool Medium - structural Add <code>Refresh()</code> capability Support hot-reload from config changes Medium - additive Add <code>OnChange</code> callback Notify listeners of registry changes Minor - additive"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#proposed-interface-extensions","title":"Proposed Interface Extensions","text":"<pre><code>// Index interface additions\ntype Index interface {\n    // Existing methods...\n    RegisterTool(tool toolmodel.Tool, backend toolmodel.ToolBackend) error\n    RegisterTools(regs []ToolRegistration) error\n    RegisterToolsFromMCP(serverName string, tools []toolmodel.Tool) error\n    UnregisterBackend(toolID string, kind toolmodel.BackendKind, backendID string) error\n    GetTool(id string) (toolmodel.Tool, toolmodel.ToolBackend, error)\n    GetAllBackends(id string) ([]toolmodel.ToolBackend, error)\n    Search(query string, limit int) ([]Summary, error)\n    ListNamespaces() ([]string, error)\n\n    // NEW: Support for multi-backend architecture\n    ListTools() ([]toolmodel.Tool, error)                    // List all registered tools\n    ListToolsFromBackend(backendName string) ([]Summary, error) // Filter by source\n\n    // NEW: Support for dynamic updates\n    OnChange(callback func(event RegistryEvent)) func()      // Subscribe to changes\n    Refresh() error                                          // Trigger refresh from sources\n}\n\n// RegistryEvent for change notifications\ntype RegistryEvent struct {\n    Type    RegistryEventType  // added, updated, removed\n    ToolID  string\n    Backend *toolmodel.ToolBackend\n}\n\ntype RegistryEventType string\n\nconst (\n    RegistryEventAdded   RegistryEventType = \"added\"\n    RegistryEventUpdated RegistryEventType = \"updated\"\n    RegistryEventRemoved RegistryEventType = \"removed\"\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#backendselector-enhancement","title":"BackendSelector Enhancement","text":"<pre><code>// Enhanced backend selection with context\ntype BackendSelectorFunc func(\n    tool toolmodel.Tool,\n    backends []toolmodel.ToolBackend,\n    hints *SelectionHints,\n) toolmodel.ToolBackend\n\n// SelectionHints provides context for backend selection\ntype SelectionHints struct {\n    PreferredKind    toolmodel.BackendKind // Caller preference\n    PreferredBackend string                 // Specific backend name\n    LatencyBudget    time.Duration          // Latency requirement\n    CostSensitive    bool                   // Prefer cheaper backends\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-3-tooldocs-documentation","title":"Layer 3: tooldocs (Documentation)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_2","title":"Current State","text":"<p>Progressive disclosure documentation layer. Three detail levels: summary, schema, full.</p> <p>Exported Types: - <code>Store</code> - Interface for documentation storage - <code>InMemoryStore</code> - Default implementation - <code>DetailLevel</code> - Enum: summary, schema, full - <code>ToolDoc</code> - Documentation at various levels - <code>ToolExample</code> - Usage example - <code>SchemaInfo</code> - Derived schema information - <code>DocEntry</code> - Input for registration</p> <p>Key Methods: - <code>DescribeTool(id, level)</code> - Get documentation at level - <code>ListExamples(id, max)</code> - Get examples - <code>RegisterDoc()</code>, <code>RegisterExamples()</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_2","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-low-minimal-changes-needed","title":"Priority: LOW (minimal changes needed)","text":"Change Rationale Impact Add <code>BulkRegister()</code> method Backend aggregation may load many docs Minor - additive Add source tracking Track which backend provided docs Minor - structural"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#proposed-additions_1","title":"Proposed Additions","text":"<pre><code>// Store interface additions\ntype Store interface {\n    // Existing methods...\n    DescribeTool(id string, level DetailLevel) (ToolDoc, error)\n    ListExamples(id string, maxExamples int) ([]ToolExample, error)\n\n    // NEW: Bulk operations for backend aggregation\n    BulkRegisterDocs(entries map[string]DocEntry) error\n\n    // NEW: Source tracking\n    GetDocSource(id string) (string, error)  // Returns backend name\n}\n\n// DocEntry - add source field\ntype DocEntry struct {\n    Summary      string\n    Notes        string\n    Examples     []ToolExample\n    ExternalRefs []string\n    Source       string  // NEW: Backend that provided this doc\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-4-toolrun-execution","title":"Layer 4: toolrun (Execution)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_3","title":"Current State","text":"<p>Tool execution layer supporting MCP, Provider, and Local backends.</p> <p>Exported Types: - <code>Runner</code> - Interface for tool execution - <code>DefaultRunner</code> - Default implementation - <code>MCPExecutor</code> - Interface for MCP backend calls - <code>ProviderExecutor</code> - Interface for provider backend calls - <code>LocalRegistry</code> - Interface for local handler lookup - <code>RunResult</code>, <code>StepResult</code>, <code>ChainStep</code> - Execution results - <code>StreamEvent</code> - Streaming event type - <code>ToolError</code> - Contextual error wrapper</p> <p>Key Methods: - <code>Run()</code> - Execute single tool - <code>RunStream()</code> - Execute with streaming - <code>RunChain()</code> - Execute tool sequence</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_3","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-high-core-execution-layer","title":"Priority: HIGH (core execution layer)","text":"Change Rationale Impact Add <code>HTTPExecutor</code> interface Support HTTP backend execution Medium - additive Add <code>GRPCExecutor</code> interface Support gRPC backend execution Medium - additive Add <code>ExecutorRegistry</code> Dynamic executor registration Medium - structural Add execution hooks Middleware integration point Medium - additive Add <code>BackendRouter</code> Route execution to correct executor Medium - structural"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#proposed-interface-additions","title":"Proposed Interface Additions","text":"<pre><code>// HTTPExecutor for HTTP backend execution\ntype HTTPExecutor interface {\n    CallTool(ctx context.Context, baseURL string, tool string, args map[string]any) (any, error)\n    CallToolStream(ctx context.Context, baseURL string, tool string, args map[string]any) (&lt;-chan StreamEvent, error)\n}\n\n// GRPCExecutor for gRPC backend execution\ntype GRPCExecutor interface {\n    CallTool(ctx context.Context, address string, tool string, args map[string]any) (any, error)\n    CallToolStream(ctx context.Context, address string, tool string, args map[string]any) (&lt;-chan StreamEvent, error)\n}\n\n// ExecutorRegistry manages execution backends\ntype ExecutorRegistry interface {\n    Register(kind toolmodel.BackendKind, executor any) error\n    Get(kind toolmodel.BackendKind) (any, bool)\n    List() []toolmodel.BackendKind\n}\n\n// ExecutionHook for middleware integration\ntype ExecutionHook interface {\n    BeforeExecution(ctx context.Context, toolID string, args map[string]any) (context.Context, error)\n    AfterExecution(ctx context.Context, toolID string, result RunResult, err error) error\n}\n\n// Config additions\ntype Config struct {\n    // Existing fields...\n    Index            toolindex.Index\n    ToolResolver     func(id string) (*toolmodel.Tool, error)\n    BackendsResolver func(id string) ([]toolmodel.ToolBackend, error)\n    BackendSelector  toolindex.BackendSelector\n    Validator        toolmodel.SchemaValidator\n    ValidateInput    bool\n    ValidateOutput   bool\n    MCP              MCPExecutor\n    Provider         ProviderExecutor\n    Local            LocalRegistry\n\n    // NEW: Additional executors\n    HTTP             HTTPExecutor        // NEW\n    GRPC             GRPCExecutor        // NEW\n    ExecutorRegistry ExecutorRegistry    // NEW: Dynamic registration\n    Hooks            []ExecutionHook     // NEW: Middleware hooks\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#enhanced-runner-interface","title":"Enhanced Runner Interface","text":"<pre><code>// Runner interface with execution options\ntype Runner interface {\n    Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)\n    RunStream(ctx context.Context, toolID string, args map[string]any) (&lt;-chan StreamEvent, error)\n    RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error)\n\n    // NEW: Execution with options\n    RunWithOptions(ctx context.Context, toolID string, args map[string]any, opts RunOptions) (RunResult, error)\n}\n\n// RunOptions for execution customization\ntype RunOptions struct {\n    PreferredBackend string                 // Override backend selection\n    Timeout          time.Duration          // Per-call timeout\n    Metadata         map[string]any         // Pass-through metadata\n    SkipValidation   bool                   // Skip input/output validation\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-5-toolcode-code-execution","title":"Layer 5: toolcode (Code Execution)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_4","title":"Current State","text":"<p>Code execution orchestration layer with pluggable engines.</p> <p>Exported Types: - <code>Executor</code> - Interface for code execution - <code>DefaultExecutor</code> - Default implementation - <code>Engine</code> - Interface for language-specific execution - <code>Tools</code> - Metatool environment exposed to code - <code>Config</code>, <code>ExecuteParams</code>, <code>ExecuteResult</code> - <code>ToolCallRecord</code>, <code>CodeError</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_4","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-low-mostly-stable_1","title":"Priority: LOW (mostly stable)","text":"Change Rationale Impact Add engine registry Support multiple language engines Minor - structural Add execution context Pass middleware context through Minor - additive"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#proposed-additions_2","title":"Proposed Additions","text":"<pre><code>// EngineRegistry for multiple language support\ntype EngineRegistry interface {\n    Register(language string, engine Engine) error\n    Get(language string) (Engine, bool)\n    List() []string\n}\n\n// Config additions\ntype Config struct {\n    // Existing fields...\n    Index           toolindex.Index\n    Docs            tooldocs.Store\n    Run             toolrun.Runner\n    Engine          Engine\n    DefaultTimeout  time.Duration\n    DefaultLanguage string\n    MaxToolCalls    int\n    MaxChainSteps   int\n    Logger          Logger\n\n    // NEW: Multiple engine support\n    EngineRegistry  EngineRegistry  // NEW\n}\n\n// ExecuteParams additions\ntype ExecuteParams struct {\n    Language     string\n    Code         string\n    Timeout      time.Duration\n    MaxToolCalls int\n\n    // NEW: Execution context\n    Metadata     map[string]any  // NEW: Pass-through metadata\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-6-toolsearch-bm25-search","title":"Layer 6: toolsearch (BM25 Search)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_5","title":"Current State","text":"<p>BM25 search implementation using Bleve. Implements <code>toolindex.Searcher</code>.</p> <p>Exported Types: - <code>BM25Config</code> - Configuration (boosts, limits) - <code>BM25Searcher</code> - Searcher implementation</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_5","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-none-stable-well-designed","title":"Priority: NONE (stable, well-designed)","text":"<p>The library already implements the pluggable pattern correctly via <code>toolindex.Searcher</code> interface. No changes needed for the pluggable architecture.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-7-toolruntime-sandbox","title":"Layer 7: toolruntime (Sandbox)","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#current-state_6","title":"Current State","text":"<p>Runtime and trust boundary layer with multiple isolation backends.</p> <p>Exported Types: - <code>Runtime</code> - Interface for code execution runtime - <code>DefaultRuntime</code> - Default implementation - <code>Backend</code> - Interface for isolation backends - <code>ToolGateway</code> - Tool access interface for sandboxed code - <code>SecurityProfile</code> - dev, standard, hardened - <code>BackendKind</code> - Isolation mechanism (Docker, K8s, gVisor, etc.) - <code>ExecuteRequest</code>, <code>ExecuteResult</code>, <code>Limits</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changes-needed-for-pluggable-architecture_6","title":"Changes Needed for Pluggable Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#priority-low-mostly-independent","title":"Priority: LOW (mostly independent)","text":"Change Rationale Impact Add security profile config Configure profiles via YAML Minor - additive Add backend discovery Auto-discover available backends Minor - additive"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#cross-cutting-concerns","title":"Cross-Cutting Concerns","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#error-handling-improvements","title":"Error Handling Improvements","text":"<p>All libraries should adopt a consistent error taxonomy:</p> <pre><code>// Proposed: pkg/errors/errors.go (new shared package)\n\n// ToolError is the base error type for all tool operations\ntype ToolError struct {\n    Code       ErrorCode\n    Message    string\n    ToolID     string\n    Backend    string\n    Op         string\n    Cause      error\n    Retryable  bool\n    Metadata   map[string]any\n}\n\ntype ErrorCode string\n\nconst (\n    ErrCodeNotFound       ErrorCode = \"not_found\"\n    ErrCodeValidation     ErrorCode = \"validation\"\n    ErrCodeExecution      ErrorCode = \"execution\"\n    ErrCodeTimeout        ErrorCode = \"timeout\"\n    ErrCodeBackendFailure ErrorCode = \"backend_failure\"\n    ErrCodeRateLimit      ErrorCode = \"rate_limit\"\n    ErrCodeAuth           ErrorCode = \"auth\"\n)\n\nfunc (e *ToolError) Error() string\nfunc (e *ToolError) Unwrap() error\nfunc (e *ToolError) Is(target error) bool\nfunc (e *ToolError) IsRetryable() bool\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#context-propagation","title":"Context Propagation","text":"<p>All libraries should propagate context consistently:</p> <pre><code>// Proposed: Context keys for cross-cutting concerns\ntype contextKey string\n\nconst (\n    ContextKeyRequestID  contextKey = \"request_id\"\n    ContextKeyUserID     contextKey = \"user_id\"\n    ContextKeyTraceID    contextKey = \"trace_id\"\n    ContextKeyBackend    contextKey = \"backend\"\n    ContextKeyMetadata   contextKey = \"metadata\"\n)\n\n// Helper functions\nfunc WithRequestID(ctx context.Context, id string) context.Context\nfunc RequestIDFromContext(ctx context.Context) string\n// ... etc\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#implementation-priority","title":"Implementation Priority","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#phase-1-foundation-with-metatools-mcp-phase-1","title":"Phase 1: Foundation (with metatools-mcp Phase 1)","text":"<ol> <li>toolmodel: Add HTTP/GRPC backend kinds (1 day)</li> <li>toolrun: Add HTTPExecutor, GRPCExecutor interfaces (2 days)</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#phase-2-registry-enhancements-with-metatools-mcp-phase-4","title":"Phase 2: Registry Enhancements (with metatools-mcp Phase 4)","text":"<ol> <li>toolindex: Add ListTools, OnChange, source tracking (2 days)</li> <li>toolrun: Add ExecutorRegistry, BackendRouter (2 days)</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#phase-3-middleware-integration-with-metatools-mcp-phase-5","title":"Phase 3: Middleware Integration (with metatools-mcp Phase 5)","text":"<ol> <li>toolrun: Add ExecutionHook interface (1 day)</li> <li>All libraries: Consistent error taxonomy (2 days)</li> <li>All libraries: Context propagation (1 day)</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#version-compatibility-matrix","title":"Version Compatibility Matrix","text":"<p>Current ecosystem versions:</p> Library Current After Phase 1 After Phase 2 After Phase 3 toolmodel v0.1.2 v0.2.0 v0.2.0 v0.2.0 toolindex v0.1.8 v0.1.8 v0.2.0 v0.2.0 tooldocs v0.1.10 v0.1.10 v0.1.11 v0.1.11 toolrun v0.1.9 v0.2.0 v0.2.0 v0.3.0 toolcode v0.1.10 v0.1.10 v0.1.10 v0.1.11 toolsearch v0.1.9 v0.1.9 v0.1.9 v0.1.9 toolruntime v0.1.10 v0.1.10 v0.1.10 v0.1.11"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#summary-required-library-changes","title":"Summary: Required Library Changes","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#breaking-changes-none","title":"Breaking Changes: NONE","text":"<p>All proposed changes are additive and backward-compatible.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#high-priority-changes","title":"High Priority Changes","text":"Library Change Files Affected toolmodel Add BackendKindHTTP, BackendKindGRPC types.go toolmodel Add HTTPBackend, GRPCBackend structs types.go toolrun Add HTTPExecutor interface executor.go (new) toolrun Add GRPCExecutor interface executor.go (new) toolrun Add ExecutorRegistry registry.go (new)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#medium-priority-changes","title":"Medium Priority Changes","text":"Library Change Files Affected toolindex Add ListTools method index.go toolindex Add OnChange callback index.go toolrun Add ExecutionHook interface hooks.go (new) toolrun Add RunOptions, RunWithOptions runner.go"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#low-priority-changes","title":"Low Priority Changes","text":"Library Change Files Affected tooldocs Add BulkRegisterDocs store.go toolcode Add EngineRegistry engine.go (new) All Consistent error taxonomy errors.go (new per lib)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#key-discovery-architecture-already-pluggable","title":"Key Discovery: Architecture Already Pluggable","text":"<p>Comprehensive analysis of all 8 component libraries (40+ source files, 12,000+ lines) revealed:</p> <p>The metatools ecosystem is NOT a monolith to be refactored. It is a mature, layered, pluggable architecture with 13 extension points already implemented as Go interfaces.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#13-extension-points-catalogued","title":"13 Extension Points Catalogued","text":"# Interface Library Status 1 <code>SchemaValidator</code> toolmodel \u2705 Interface-based 2 <code>Searcher</code> toolindex \u2705 Interface-based 3 <code>BackendSelector</code> toolindex \u2705 Function-based 4 <code>Store</code> tooldocs \u2705 Interface-based 5 <code>ToolResolver</code> tooldocs \u2705 Function-based 6 <code>Runner</code> toolrun \u2705 Interface-based 7 <code>MCPExecutor</code> toolrun \u2705 Interface-based 8 <code>ProviderExecutor</code> toolrun \u2705 Interface-based 9 <code>LocalRegistry</code> toolrun \u2705 Interface-based 10 <code>Backend</code> toolruntime \u2705 Interface-based (10 implementations!) 11 <code>ToolGateway</code> toolruntime \u2705 Interface-based 12 <code>Logger</code> toolcode \u2705 Interface-based 13 <code>Engine</code> toolcode \u2705 Interface-based"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#implications-for-implementation","title":"Implications for Implementation","text":"<p>The \"pluggable architecture\" work is primarily: 1. Exposure - Make internal extension points accessible via configuration 2. Configuration - Add CLI + config layer (Cobra + Koanf) 3. Documentation - Catalog the 13 extension points with examples</p> <p>This reduces the implementation timeline from 9 weeks to 6-7 weeks (25% reduction).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#changelog","title":"Changelog","text":"Date Change 2026-01-27 Initial analysis of all 7 component libraries 2026-01-28 Added Key Discovery section documenting 13 existing extension points 2026-01-28 Updated analysis to reflect that architecture is already pluggable"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/","title":"Pluggable Architecture Implementation Phases","text":"<p>Status: Draft (Revised) Date: 2026-01-28 Related: Pluggable Architecture Proposal, Component Library Analysis</p> <p>Revised Timeline: Architecture discovery revealed that 13 extension points already exist as Go interfaces. The work is primarily configuration and exposure, not architecture redesign. Timeline reduced from 9 weeks to 6-7 weeks (25% reduction).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#overview","title":"Overview","text":"<p>This document breaks the pluggable architecture proposal into manageable implementation phases, following Go best practices and layered architecture principles. Each phase is designed to be:</p> <ul> <li>Independently deliverable - Can be merged and deployed after completion</li> <li>Backward compatible - Existing functionality continues to work</li> <li>Testable - Includes clear verification criteria</li> <li>Incremental - Builds on previous phases</li> </ul> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    REVISED IMPLEMENTATION ROADMAP (6-7 weeks)               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Phase 1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Phase 2 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Phase 3 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Phase 4          \u2502\n\u2502   CLI + Config       Transport          Public APIs        Backend           \u2502\n\u2502   (Expose 13 pts)    Abstraction        &amp; Documentation    Integration       \u2502\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502   2 weeks    \u2502   \u2502  1-2 weeks   \u2502   \u2502   1 week     \u2502   \u2502   2 weeks    \u2502 \u2502\n\u2502   \u2502              \u2502   \u2502              \u2502   \u2502              \u2502   \u2502              \u2502 \u2502\n\u2502   \u2502 Cobra CLI    \u2502   \u2502 Transport    \u2502   \u2502 Export       \u2502   \u2502 Docker/WASM  \u2502 \u2502\n\u2502   \u2502 Koanf config \u2502   \u2502 Interface    \u2502   \u2502 internal pkg \u2502   \u2502 integration  \u2502 \u2502\n\u2502   \u2502 13 ext points\u2502   \u2502 Stdio + SSE  \u2502   \u2502 13 ext docs  \u2502   \u2502 Backend reg  \u2502 \u2502\n\u2502   \u2502 config schema\u2502   \u2502              \u2502   \u2502 Examples     \u2502   \u2502 config       \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502   MVP \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502                                    \u2502\n\u2502   (Phases 1-2: ~3-4 weeks)              \u2502                                    \u2502\n\u2502                                                                               \u2502\n\u2502   Note: Original Phase 5 (Middleware) deferred - 13 extension points        \u2502\n\u2502         already provide middleware integration via ExecutionHook             \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phase-1-cli-framework-configuration-foundation","title":"Phase 1: CLI Framework &amp; Configuration (Foundation)","text":"<p>Duration: ~2 weeks Priority: Critical (foundation for all other phases) Risk: Low (additive changes, no breaking changes)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#objective","title":"Objective","text":"<p>Introduce Cobra CLI framework and Koanf configuration library while maintaining backward compatibility with current environment variable configuration.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#directory-structure-changes","title":"Directory Structure Changes","text":"<pre><code>cmd/metatools/\n\u251c\u2500\u2500 main.go              # Entry point (simplified)\n\u251c\u2500\u2500 root.go              # Root command\n\u251c\u2500\u2500 stdio.go             # `metatools stdio` (current behavior)\n\u251c\u2500\u2500 serve.go             # `metatools serve` (HTTP/SSE) - placeholder\n\u251c\u2500\u2500 version.go           # `metatools version`\n\u251c\u2500\u2500 validate.go          # `metatools validate` (config validation)\n\u251c\u2500\u2500 executor_toolruntime.go  # (unchanged)\n\u2514\u2500\u2500 executor_stub.go         # (unchanged)\n\ninternal/\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 env.go           # (unchanged - backward compat)\n\u2502   \u251c\u2500\u2500 loader.go        # NEW: Koanf-based config loader\n\u2502   \u251c\u2500\u2500 schema.go        # NEW: Config struct definitions\n\u2502   \u2514\u2500\u2500 defaults.go      # NEW: Default values\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#implementation-tasks","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#11-add-dependencies","title":"1.1 Add Dependencies","text":"<pre><code>// go.mod additions\nrequire (\n    github.com/spf13/cobra v1.8.1\n    github.com/knadh/koanf/v2 v2.1.2\n    github.com/knadh/koanf/parsers/yaml v0.1.0\n    github.com/knadh/koanf/providers/env v1.0.0\n    github.com/knadh/koanf/providers/file v1.1.0\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#12-configuration-schema-internalconfigschemago","title":"1.2 Configuration Schema (<code>internal/config/schema.go</code>)","text":"<pre><code>package config\n\n// ServerConfig is the root configuration structure\ntype ServerConfig struct {\n    Server    ServerSettings    `koanf:\"server\"`\n    Transport TransportConfig   `koanf:\"transport\"`\n    Search    SearchConfig      `koanf:\"search\"`\n    Execution ExecutionConfig   `koanf:\"execution\"`\n    Providers ProvidersConfig   `koanf:\"providers\"`\n    Backends  BackendsConfig    `koanf:\"backends\"`\n    Middleware MiddlewareConfig `koanf:\"middleware\"`\n}\n\ntype ServerSettings struct {\n    Name    string `koanf:\"name\"`\n    Version string `koanf:\"version\"`\n}\n\ntype TransportConfig struct {\n    Type string       `koanf:\"type\"` // stdio, sse, http\n    HTTP HTTPConfig   `koanf:\"http\"`\n}\n\ntype HTTPConfig struct {\n    Host     string        `koanf:\"host\"`\n    Port     int           `koanf:\"port\"`\n    TLS      TLSConfig     `koanf:\"tls\"`\n    Timeouts TimeoutConfig `koanf:\"timeouts\"`\n    CORS     CORSConfig    `koanf:\"cors\"`\n    Health   HealthConfig  `koanf:\"health\"`\n}\n\n// SearchConfig matches current EnvConfig.SearchConfig\ntype SearchConfig struct {\n    Strategy       string `koanf:\"strategy\"`\n    NameBoost      int    `koanf:\"name_boost\"`\n    NamespaceBoost int    `koanf:\"namespace_boost\"`\n    TagsBoost      int    `koanf:\"tags_boost\"`\n    MaxDocs        int    `koanf:\"max_docs\"`\n    MaxDocTextLen  int    `koanf:\"max_doctext_len\"`\n}\n\n// ... (additional config types)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#13-configuration-loader-internalconfigloadergo","title":"1.3 Configuration Loader (<code>internal/config/loader.go</code>)","text":"<pre><code>package config\n\nimport (\n    \"github.com/knadh/koanf/v2\"\n    \"github.com/knadh/koanf/parsers/yaml\"\n    \"github.com/knadh/koanf/providers/env\"\n    \"github.com/knadh/koanf/providers/file\"\n)\n\ntype Loader struct {\n    k *koanf.Koanf\n}\n\n// Load loads configuration with precedence:\n// CLI flags &gt; Environment variables &gt; Config file &gt; Defaults\nfunc (l *Loader) Load(configPath string) (*ServerConfig, error) {\n    l.k = koanf.New(\".\")\n\n    // 1. Load defaults\n    if err := l.loadDefaults(); err != nil {\n        return nil, err\n    }\n\n    // 2. Load config file (if exists)\n    if configPath != \"\" {\n        if err := l.k.Load(file.Provider(configPath), yaml.Parser()); err != nil {\n            return nil, fmt.Errorf(\"loading config file: %w\", err)\n        }\n    }\n\n    // 3. Load environment variables (METATOOLS_ prefix)\n    if err := l.k.Load(env.Provider(\"METATOOLS_\", \".\", func(s string) string {\n        return strings.Replace(strings.ToLower(\n            strings.TrimPrefix(s, \"METATOOLS_\")), \"_\", \".\", -1)\n    }), nil); err != nil {\n        return nil, fmt.Errorf(\"loading env vars: %w\", err)\n    }\n\n    var cfg ServerConfig\n    if err := l.k.Unmarshal(\"\", &amp;cfg); err != nil {\n        return nil, fmt.Errorf(\"unmarshaling config: %w\", err)\n    }\n\n    return &amp;cfg, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#14-cli-root-command-cmdmetatoolsrootgo","title":"1.4 CLI Root Command (<code>cmd/metatools/root.go</code>)","text":"<pre><code>package main\n\nimport (\n    \"os\"\n\n    \"github.com/spf13/cobra\"\n)\n\nvar (\n    cfgFile string\n    verbose bool\n)\n\nvar rootCmd = &amp;cobra.Command{\n    Use:   \"metatools\",\n    Short: \"MCP server for tool discovery and execution\",\n    Long: `metatools-mcp is a Model Context Protocol server that provides\nunified tool discovery, documentation, and execution capabilities.`,\n}\n\nfunc init() {\n    rootCmd.PersistentFlags().StringVarP(&amp;cfgFile, \"config\", \"c\", \"\",\n        \"config file (default: metatools.yaml)\")\n    rootCmd.PersistentFlags().BoolVarP(&amp;verbose, \"verbose\", \"v\", false,\n        \"verbose output\")\n\n    rootCmd.AddCommand(stdioCmd)\n    rootCmd.AddCommand(serveCmd)\n    rootCmd.AddCommand(versionCmd)\n    rootCmd.AddCommand(validateCmd)\n}\n\nfunc Execute() {\n    if err := rootCmd.Execute(); err != nil {\n        os.Exit(1)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#15-stdio-command-cmdmetatoolsstdiogo","title":"1.5 Stdio Command (<code>cmd/metatools/stdio.go</code>)","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"log\"\n    \"os/signal\"\n    \"syscall\"\n\n    \"github.com/spf13/cobra\"\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\nvar stdioCmd = &amp;cobra.Command{\n    Use:   \"stdio\",\n    Short: \"Run as stdio MCP server (default mode)\",\n    Long:  `Runs the MCP server using stdin/stdout transport for MCP clients like Claude Desktop.`,\n    RunE:  runStdio,\n}\n\nfunc init() {\n    // Set as default command when no subcommand provided\n    rootCmd.Run = stdioCmd.Run\n}\n\nfunc runStdio(cmd *cobra.Command, args []string) error {\n    ctx, cancel := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)\n    defer cancel()\n\n    srv, err := createServer()\n    if err != nil {\n        return fmt.Errorf(\"failed to create server: %w\", err)\n    }\n\n    tools := srv.ListTools()\n    log.Printf(\"metatools-mcp server starting with %d tools\", len(tools))\n\n    transport := &amp;mcp.StdioTransport{}\n    if err := srv.Run(ctx, transport); err != nil &amp;&amp; ctx.Err() == nil {\n        return fmt.Errorf(\"server error: %w\", err)\n    }\n\n    log.Println(\"Server stopped\")\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#verification-criteria","title":"Verification Criteria","text":"<ul> <li>[ ] <code>metatools stdio</code> works identically to current behavior</li> <li>[ ] <code>metatools version</code> prints version info</li> <li>[ ] <code>metatools validate -c config.yaml</code> validates configuration files</li> <li>[ ] Existing environment variables (<code>METATOOLS_SEARCH_*</code>) continue to work</li> <li>[ ] New YAML config file loading works</li> <li>[ ] Config precedence: CLI &gt; Env &gt; File &gt; Defaults</li> <li>[ ] All existing tests pass</li> <li>[ ] New unit tests for config loader (&gt;80% coverage)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#migration-notes","title":"Migration Notes","text":"<ul> <li>No breaking changes</li> <li><code>metatools</code> (no args) defaults to <code>metatools stdio</code></li> <li>Environment variable prefix remains <code>METATOOLS_</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phase-2-transport-layer-abstraction","title":"Phase 2: Transport Layer Abstraction","text":"<p>Duration: ~2 weeks Priority: High (enables multi-modal deployment) Risk: Medium (touches core server logic) Depends on: Phase 1</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#objective_1","title":"Objective","text":"<p>Abstract the transport layer so the same server logic can run over stdio, SSE, or HTTP.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#directory-structure-changes_1","title":"Directory Structure Changes","text":"<pre><code>internal/\n\u251c\u2500\u2500 transport/\n\u2502   \u251c\u2500\u2500 transport.go     # NEW: Transport interface\n\u2502   \u251c\u2500\u2500 registry.go      # NEW: Transport registry\n\u2502   \u251c\u2500\u2500 stdio.go         # NEW: Stdio transport wrapper\n\u2502   \u251c\u2500\u2500 sse.go           # NEW: SSE transport\n\u2502   \u2514\u2500\u2500 http.go          # NEW: HTTP transport (optional)\n\u251c\u2500\u2500 server/\n\u2502   \u251c\u2500\u2500 server.go        # MODIFIED: Use Transport interface\n\u2502   \u2514\u2500\u2500 handler.go       # NEW: Shared request handler\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#implementation-tasks_1","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#21-transport-interface-internaltransporttransportgo","title":"2.1 Transport Interface (<code>internal/transport/transport.go</code>)","text":"<pre><code>package transport\n\nimport (\n    \"context\"\n)\n\n// Transport defines how MCP clients connect to the server\ntype Transport interface {\n    // Name returns the transport identifier\n    Name() string\n\n    // Serve starts the transport and blocks until ctx is cancelled\n    Serve(ctx context.Context, handler RequestHandler) error\n\n    // Close gracefully shuts down the transport\n    Close() error\n\n    // Info returns runtime information about the transport\n    Info() TransportInfo\n}\n\n// RequestHandler processes incoming MCP requests\ntype RequestHandler interface {\n    HandleRequest(ctx context.Context, req *Request) (*Response, error)\n}\n\n// TransportInfo provides runtime details about a transport\ntype TransportInfo struct {\n    Name      string\n    Protocol  string            // \"stdio\", \"http\", \"sse\", \"grpc\"\n    Address   string            // \"\" for stdio, \"localhost:8080\" for HTTP\n    Listening bool\n    Metadata  map[string]string\n}\n\n// Config holds transport-specific configuration\ntype Config struct {\n    Type      string\n    HTTP      HTTPConfig\n    WebSocket WebSocketConfig\n    GRPC      GRPCConfig\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#22-transport-registry-internaltransportregistrygo","title":"2.2 Transport Registry (<code>internal/transport/registry.go</code>)","text":"<pre><code>package transport\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\n// Factory creates a configured transport instance\ntype Factory func(cfg Config) (Transport, error)\n\n// Registry manages available transports\ntype Registry struct {\n    mu         sync.RWMutex\n    transports map[string]Factory\n}\n\n// NewRegistry creates a new transport registry with built-in transports\nfunc NewRegistry() *Registry {\n    r := &amp;Registry{\n        transports: make(map[string]Factory),\n    }\n\n    // Register built-in transports\n    r.Register(\"stdio\", NewStdioTransport)\n    r.Register(\"sse\", NewSSETransport)\n    r.Register(\"http\", NewHTTPTransport)\n\n    return r\n}\n\n// Register adds a transport factory\nfunc (r *Registry) Register(name string, factory Factory) {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n    r.transports[name] = factory\n}\n\n// Create instantiates a transport from config\nfunc (r *Registry) Create(cfg Config) (Transport, error) {\n    r.mu.RLock()\n    factory, ok := r.transports[cfg.Type]\n    r.mu.RUnlock()\n\n    if !ok {\n        return nil, fmt.Errorf(\"unknown transport type: %s\", cfg.Type)\n    }\n\n    return factory(cfg)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#23-stdio-transport-internaltransportstdiogo","title":"2.3 Stdio Transport (<code>internal/transport/stdio.go</code>)","text":"<pre><code>package transport\n\nimport (\n    \"context\"\n\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// StdioTransport wraps the MCP SDK's stdio transport\ntype StdioTransport struct {\n    sdk *mcp.StdioTransport\n}\n\n// NewStdioTransport creates a stdio transport\nfunc NewStdioTransport(cfg Config) (Transport, error) {\n    return &amp;StdioTransport{\n        sdk: &amp;mcp.StdioTransport{},\n    }, nil\n}\n\nfunc (t *StdioTransport) Name() string { return \"stdio\" }\n\nfunc (t *StdioTransport) Serve(ctx context.Context, handler RequestHandler) error {\n    // Adapt to MCP SDK's transport interface\n    return t.sdk.Run(ctx, adaptHandler(handler))\n}\n\nfunc (t *StdioTransport) Close() error { return nil }\n\nfunc (t *StdioTransport) Info() TransportInfo {\n    return TransportInfo{\n        Name:      \"stdio\",\n        Protocol:  \"stdio\",\n        Address:   \"stdin/stdout\",\n        Listening: true,\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#24-sse-transport-internaltransportssego","title":"2.4 SSE Transport (<code>internal/transport/sse.go</code>)","text":"<pre><code>package transport\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"net/http\"\n    \"sync\"\n    \"time\"\n)\n\n// SSETransport implements Server-Sent Events transport\ntype SSETransport struct {\n    cfg      HTTPConfig\n    server   *http.Server\n    handler  RequestHandler\n    mu       sync.RWMutex\n    clients  map[string]chan []byte\n}\n\n// NewSSETransport creates an SSE transport\nfunc NewSSETransport(cfg Config) (Transport, error) {\n    return &amp;SSETransport{\n        cfg:     cfg.HTTP,\n        clients: make(map[string]chan []byte),\n    }, nil\n}\n\nfunc (t *SSETransport) Name() string { return \"sse\" }\n\nfunc (t *SSETransport) Serve(ctx context.Context, handler RequestHandler) error {\n    t.handler = handler\n\n    mux := http.NewServeMux()\n    mux.HandleFunc(\"/mcp\", t.handleMCP)\n    mux.HandleFunc(\"/health\", t.handleHealth)\n    mux.HandleFunc(\"/ready\", t.handleReady)\n\n    addr := fmt.Sprintf(\"%s:%d\", t.cfg.Host, t.cfg.Port)\n    t.server = &amp;http.Server{\n        Addr:         addr,\n        Handler:      t.applyCORS(mux),\n        ReadTimeout:  t.cfg.Timeouts.Read,\n        WriteTimeout: t.cfg.Timeouts.Write,\n        IdleTimeout:  t.cfg.Timeouts.Idle,\n    }\n\n    // Start server in goroutine\n    errCh := make(chan error, 1)\n    go func() {\n        if t.cfg.TLS.Enabled {\n            errCh &lt;- t.server.ListenAndServeTLS(t.cfg.TLS.Cert, t.cfg.TLS.Key)\n        } else {\n            errCh &lt;- t.server.ListenAndServe()\n        }\n    }()\n\n    // Wait for context cancellation or error\n    select {\n    case &lt;-ctx.Done():\n        shutdownCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n        defer cancel()\n        return t.server.Shutdown(shutdownCtx)\n    case err := &lt;-errCh:\n        return err\n    }\n}\n\nfunc (t *SSETransport) handleMCP(w http.ResponseWriter, r *http.Request) {\n    if r.Method != http.MethodPost {\n        http.Error(w, \"Method not allowed\", http.StatusMethodNotAllowed)\n        return\n    }\n\n    // Set SSE headers\n    w.Header().Set(\"Content-Type\", \"text/event-stream\")\n    w.Header().Set(\"Cache-Control\", \"no-cache\")\n    w.Header().Set(\"Connection\", \"keep-alive\")\n\n    // Parse request\n    var req Request\n    if err := json.NewDecoder(r.Body).Decode(&amp;req); err != nil {\n        t.sendError(w, \"Invalid request\", http.StatusBadRequest)\n        return\n    }\n\n    // Handle request\n    resp, err := t.handler.HandleRequest(r.Context(), &amp;req)\n    if err != nil {\n        t.sendError(w, err.Error(), http.StatusInternalServerError)\n        return\n    }\n\n    // Send response as SSE event\n    t.sendEvent(w, \"message\", resp)\n    t.sendEvent(w, \"done\", struct{}{})\n}\n\nfunc (t *SSETransport) sendEvent(w http.ResponseWriter, event string, data any) {\n    jsonData, _ := json.Marshal(data)\n    fmt.Fprintf(w, \"event: %s\\ndata: %s\\n\\n\", event, jsonData)\n    if f, ok := w.(http.Flusher); ok {\n        f.Flush()\n    }\n}\n\n// ... additional helper methods\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#25-server-modifications-internalserverservergo","title":"2.5 Server Modifications (<code>internal/server/server.go</code>)","text":"<pre><code>// Run now accepts our Transport interface\nfunc (s *Server) Run(ctx context.Context, t transport.Transport) error {\n    log.Printf(\"Starting server with %s transport\", t.Name())\n    return t.Serve(ctx, s)\n}\n\n// HandleRequest implements transport.RequestHandler\nfunc (s *Server) HandleRequest(ctx context.Context, req *transport.Request) (*transport.Response, error) {\n    // Delegate to MCP SDK's request handling\n    return s.mcp.HandleRequest(ctx, req)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#verification-criteria_1","title":"Verification Criteria","text":"<ul> <li>[ ] <code>metatools stdio</code> works identically to Phase 1</li> <li>[ ] <code>metatools serve --port 8080</code> starts SSE server</li> <li>[ ] SSE endpoint accepts POST requests at <code>/mcp</code></li> <li>[ ] Health check endpoints work (<code>/health</code>, <code>/ready</code>)</li> <li>[ ] CORS headers applied correctly</li> <li>[ ] Graceful shutdown on SIGTERM</li> <li>[ ] TLS works when configured</li> <li>[ ] Integration tests for SSE transport</li> <li>[ ] Load test: 100 concurrent SSE connections</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#cli-changes","title":"CLI Changes","text":"<pre><code># New serve command\nmetatools serve [flags]\n\nFlags:\n  --port int          HTTP port (default 8080)\n  --host string       Bind address (default \"0.0.0.0\")\n  --tls               Enable TLS\n  --cert string       TLS certificate path\n  --key string        TLS key path\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phase-3-tool-provider-registry","title":"Phase 3: Tool Provider Registry","text":"<p>Duration: ~1 week Priority: High (enables plug-and-play tools) Risk: Medium (refactors core registration logic) Depends on: Phase 1</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#objective_2","title":"Objective","text":"<p>Replace hardcoded tool registration with a registry pattern that allows dynamic tool registration.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#directory-structure-changes_2","title":"Directory Structure Changes","text":"<pre><code>internal/\n\u251c\u2500\u2500 provider/\n\u2502   \u251c\u2500\u2500 provider.go      # NEW: ToolProvider interface\n\u2502   \u251c\u2500\u2500 registry.go      # NEW: Tool registry\n\u2502   \u251c\u2500\u2500 search.go        # NEW: search_tools provider\n\u2502   \u251c\u2500\u2500 describe.go      # NEW: describe_tool provider\n\u2502   \u251c\u2500\u2500 run.go           # NEW: run_tool provider\n\u2502   \u251c\u2500\u2500 chain.go         # NEW: run_chain provider\n\u2502   \u251c\u2500\u2500 namespaces.go    # NEW: list_namespaces provider\n\u2502   \u251c\u2500\u2500 examples.go      # NEW: list_tool_examples provider\n\u2502   \u2514\u2500\u2500 code.go          # NEW: execute_code provider (optional)\n\u251c\u2500\u2500 server/\n\u2502   \u2514\u2500\u2500 server.go        # MODIFIED: Use provider registry\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#implementation-tasks_2","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#31-tool-provider-interface-internalproviderprovidergo","title":"3.1 Tool Provider Interface (<code>internal/provider/provider.go</code>)","text":"<pre><code>package provider\n\nimport (\n    \"context\"\n\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// ToolProvider defines a pluggable MCP tool\ntype ToolProvider interface {\n    // Name returns the tool name (e.g., \"search_tools\")\n    Name() string\n\n    // Tool returns the MCP tool definition with JSON schema\n    Tool() *mcp.Tool\n\n    // Handle executes the tool with the given input\n    Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error)\n}\n\n// Option configures a tool provider\ntype Option func(ToolProvider)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#32-tool-registry-internalproviderregistrygo","title":"3.2 Tool Registry (<code>internal/provider/registry.go</code>)","text":"<pre><code>package provider\n\nimport (\n    \"fmt\"\n    \"sync\"\n\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// Registry manages registered tool providers\ntype Registry struct {\n    mu        sync.RWMutex\n    providers map[string]ToolProvider\n    order     []string // Maintains registration order\n}\n\n// NewRegistry creates a new tool provider registry\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        providers: make(map[string]ToolProvider),\n        order:     make([]string, 0),\n    }\n}\n\n// Register adds a tool provider\nfunc (r *Registry) Register(p ToolProvider) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    name := p.Name()\n    if _, exists := r.providers[name]; exists {\n        return fmt.Errorf(\"provider already registered: %s\", name)\n    }\n\n    r.providers[name] = p\n    r.order = append(r.order, name)\n    return nil\n}\n\n// Get retrieves a provider by name\nfunc (r *Registry) Get(name string) (ToolProvider, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    p, ok := r.providers[name]\n    return p, ok\n}\n\n// All returns all registered providers in registration order\nfunc (r *Registry) All() []ToolProvider {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    result := make([]ToolProvider, 0, len(r.order))\n    for _, name := range r.order {\n        result = append(result, r.providers[name])\n    }\n    return result\n}\n\n// Tools returns MCP tool definitions for all providers\nfunc (r *Registry) Tools() []*mcp.Tool {\n    providers := r.All()\n    tools := make([]*mcp.Tool, 0, len(providers))\n    for _, p := range providers {\n        tools = append(tools, p.Tool())\n    }\n    return tools\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#33-example-provider-internalprovidersearchgo","title":"3.3 Example Provider (<code>internal/provider/search.go</code>)","text":"<pre><code>package provider\n\nimport (\n    \"context\"\n\n    \"github.com/jonwraymond/metatools-mcp/internal/handlers\"\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// SearchProvider implements the search_tools tool\ntype SearchProvider struct {\n    handler *handlers.SearchHandler\n}\n\n// NewSearchProvider creates a search_tools provider\nfunc NewSearchProvider(h *handlers.SearchHandler) *SearchProvider {\n    return &amp;SearchProvider{handler: h}\n}\n\nfunc (p *SearchProvider) Name() string { return \"search_tools\" }\n\nfunc (p *SearchProvider) Tool() *mcp.Tool {\n    return &amp;mcp.Tool{\n        Name:        \"search_tools\",\n        Description: \"Search for tools by query string. Returns ranked list of matching tools.\",\n        InputSchema: mcp.ToolInputSchema{\n            Type: \"object\",\n            Properties: map[string]any{\n                \"query\": map[string]any{\n                    \"type\":        \"string\",\n                    \"description\": \"Search query to find relevant tools\",\n                },\n                \"limit\": map[string]any{\n                    \"type\":        \"integer\",\n                    \"description\": \"Maximum number of results (default 10)\",\n                    \"default\":     10,\n                },\n            },\n            Required: []string{\"query\"},\n        },\n    }\n}\n\nfunc (p *SearchProvider) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    query, _ := input[\"query\"].(string)\n    limit := 10\n    if l, ok := input[\"limit\"].(float64); ok {\n        limit = int(l)\n    }\n\n    return p.handler.Handle(ctx, query, limit)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#34-server-integration","title":"3.4 Server Integration","text":"<pre><code>// internal/server/server.go\n\nfunc New(cfg config.Config, registry *provider.Registry) (*Server, error) {\n    // ... existing validation\n\n    mcpServer := mcp.NewServer(&amp;mcp.Implementation{\n        Name:    implementationName,\n        Version: implementationVersion,\n    }, &amp;mcp.ServerOptions{\n        PageSize: defaultPageSize,\n    })\n\n    srv := &amp;Server{\n        config:   cfg,\n        mcp:      mcpServer,\n        registry: registry,\n    }\n\n    // Register tools from provider registry\n    for _, p := range registry.All() {\n        srv.registerProvider(p)\n    }\n\n    return srv, nil\n}\n\nfunc (s *Server) registerProvider(p provider.ToolProvider) {\n    tool := p.Tool()\n    s.tools = append(s.tools, tool)\n\n    s.mcp.AddTool(tool, func(ctx context.Context, req *mcp.CallToolRequest) (*mcp.CallToolResult, error) {\n        return p.Handle(ctx, req.Params.Arguments)\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#verification-criteria_2","title":"Verification Criteria","text":"<ul> <li>[ ] All existing tools work via provider registry</li> <li>[ ] Provider registration order matches tool list order</li> <li>[ ] Custom providers can be registered programmatically</li> <li>[ ] Unit tests for registry (&gt;90% coverage)</li> <li>[ ] Benchmark: Registration of 100 providers &lt; 1ms</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phase-4-backend-registry","title":"Phase 4: Backend Registry","text":"<p>Duration: ~2 weeks Priority: Medium (enables multi-source tool aggregation) Risk: Medium (new subsystem) Depends on: Phase 3</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#objective_3","title":"Objective","text":"<p>Implement a backend registry that aggregates tools from multiple sources (local, MCP servers, HTTP APIs).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#directory-structure-changes_3","title":"Directory Structure Changes","text":"<pre><code>internal/\n\u251c\u2500\u2500 backend/\n\u2502   \u251c\u2500\u2500 backend.go       # NEW: Backend interface\n\u2502   \u251c\u2500\u2500 registry.go      # NEW: Backend registry\n\u2502   \u251c\u2500\u2500 local.go         # NEW: Local file backend\n\u2502   \u251c\u2500\u2500 mcp.go           # NEW: MCP subprocess backend\n\u2502   \u251c\u2500\u2500 http.go          # NEW: HTTP API backend\n\u2502   \u251c\u2500\u2500 aggregator.go    # NEW: Tool aggregation logic\n\u2502   \u2514\u2500\u2500 errors.go        # NEW: Backend-specific errors\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#implementation-tasks_3","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#41-backend-interface-internalbackendbackendgo","title":"4.1 Backend Interface (<code>internal/backend/backend.go</code>)","text":"<pre><code>package backend\n\nimport (\n    \"context\"\n\n    \"github.com/jonwraymond/toolmodel\"\n)\n\n// Backend defines a source of tools\ntype Backend interface {\n    // Identity\n    Kind() string  // e.g., \"local\", \"mcp\", \"http\"\n    Name() string  // Instance name\n\n    // Lifecycle\n    Start(ctx context.Context) error\n    Stop() error\n\n    // Discovery\n    ListTools(ctx context.Context) ([]toolmodel.Tool, error)\n\n    // Execution\n    Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n}\n\n// Configurable backends support dynamic configuration\ntype Configurable interface {\n    Configure(raw []byte) error\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#42-backend-registry-internalbackendregistrygo","title":"4.2 Backend Registry (<code>internal/backend/registry.go</code>)","text":"<pre><code>package backend\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n)\n\n// Registry manages backend instances\ntype Registry struct {\n    mu       sync.RWMutex\n    backends map[string]Backend\n    order    []string\n}\n\n// NewRegistry creates a backend registry\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        backends: make(map[string]Backend),\n        order:    make([]string, 0),\n    }\n}\n\n// Register adds a backend\nfunc (r *Registry) Register(name string, b Backend) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    if _, exists := r.backends[name]; exists {\n        return fmt.Errorf(\"backend already registered: %s\", name)\n    }\n\n    r.backends[name] = b\n    r.order = append(r.order, name)\n    return nil\n}\n\n// StartAll starts all registered backends\nfunc (r *Registry) StartAll(ctx context.Context) error {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    for name, b := range r.backends {\n        if err := b.Start(ctx); err != nil {\n            return fmt.Errorf(\"starting backend %s: %w\", name, err)\n        }\n    }\n    return nil\n}\n\n// StopAll stops all registered backends\nfunc (r *Registry) StopAll() error {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    var errs []error\n    for name, b := range r.backends {\n        if err := b.Stop(); err != nil {\n            errs = append(errs, fmt.Errorf(\"stopping backend %s: %w\", name, err))\n        }\n    }\n\n    if len(errs) &gt; 0 {\n        return fmt.Errorf(\"errors stopping backends: %v\", errs)\n    }\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#43-mcp-backend-internalbackendmcpgo","title":"4.3 MCP Backend (<code>internal/backend/mcp.go</code>)","text":"<pre><code>package backend\n\nimport (\n    \"context\"\n    \"os/exec\"\n\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// MCPBackend connects to an MCP subprocess\ntype MCPBackend struct {\n    name    string\n    command string\n    args    []string\n    env     map[string]string\n\n    cmd    *exec.Cmd\n    client *mcp.Client\n}\n\n// NewMCPBackend creates an MCP subprocess backend\nfunc NewMCPBackend(name, command string, args []string, env map[string]string) *MCPBackend {\n    return &amp;MCPBackend{\n        name:    name,\n        command: command,\n        args:    args,\n        env:     env,\n    }\n}\n\nfunc (b *MCPBackend) Kind() string { return \"mcp\" }\nfunc (b *MCPBackend) Name() string { return b.name }\n\nfunc (b *MCPBackend) Start(ctx context.Context) error {\n    // Start subprocess and establish MCP connection\n    // ... implementation\n}\n\nfunc (b *MCPBackend) ListTools(ctx context.Context) ([]toolmodel.Tool, error) {\n    resp, err := b.client.ListTools(ctx)\n    if err != nil {\n        return nil, err\n    }\n\n    // Convert MCP tools to toolmodel.Tool\n    tools := make([]toolmodel.Tool, 0, len(resp.Tools))\n    for _, t := range resp.Tools {\n        tools = append(tools, convertMCPTool(t, b.name))\n    }\n    return tools, nil\n}\n\nfunc (b *MCPBackend) Execute(ctx context.Context, tool string, args map[string]any) (any, error) {\n    return b.client.CallTool(ctx, tool, args)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#verification-criteria_3","title":"Verification Criteria","text":"<ul> <li>[ ] Local backend loads tools from file paths</li> <li>[ ] MCP backend spawns subprocess and communicates via stdio</li> <li>[ ] HTTP backend calls remote API endpoints</li> <li>[ ] Tool aggregation merges tools from all backends</li> <li>[ ] Backend failures don't crash the server (graceful degradation)</li> <li>[ ] Integration tests for each backend type</li> <li>[ ] E2E test: GitHub MCP server integration</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phase-5-middleware-chain","title":"Phase 5: Middleware Chain","text":"<p>Duration: ~2 weeks Priority: Low (nice-to-have for MVP) Risk: Low (additive feature) Depends on: Phase 3</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#objective_4","title":"Objective","text":"<p>Implement a middleware chain for cross-cutting concerns (logging, auth, rate limiting, metrics).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#directory-structure-changes_4","title":"Directory Structure Changes","text":"<pre><code>internal/\n\u251c\u2500\u2500 middleware/\n\u2502   \u251c\u2500\u2500 middleware.go    # NEW: Middleware interface\n\u2502   \u251c\u2500\u2500 chain.go         # NEW: Middleware chain builder\n\u2502   \u251c\u2500\u2500 registry.go      # NEW: Middleware registry\n\u2502   \u251c\u2500\u2500 logging.go       # NEW: Logging middleware\n\u2502   \u251c\u2500\u2500 auth.go          # NEW: Auth middleware\n\u2502   \u251c\u2500\u2500 ratelimit.go     # NEW: Rate limiting middleware\n\u2502   \u251c\u2500\u2500 metrics.go       # NEW: Metrics middleware\n\u2502   \u251c\u2500\u2500 cache.go         # NEW: Caching middleware\n\u2502   \u2514\u2500\u2500 validation.go    # NEW: Input validation middleware\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#implementation-tasks_4","title":"Implementation Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#51-middleware-interface-internalmiddlewaremiddlewarego","title":"5.1 Middleware Interface (<code>internal/middleware/middleware.go</code>)","text":"<pre><code>package middleware\n\nimport (\n    \"context\"\n\n    \"github.com/jonwraymond/metatools-mcp/internal/provider\"\n)\n\n// Middleware wraps a ToolProvider with additional behavior\ntype Middleware func(provider.ToolProvider) provider.ToolProvider\n\n// Factory creates a configured middleware instance\ntype Factory func(cfg Config) (Middleware, error)\n\n// Config holds middleware-specific configuration\ntype Config struct {\n    Name    string\n    Enabled bool\n    Raw     map[string]any\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#52-middleware-chain-internalmiddlewarechaingo","title":"5.2 Middleware Chain (<code>internal/middleware/chain.go</code>)","text":"<pre><code>package middleware\n\nimport (\n    \"github.com/jonwraymond/metatools-mcp/internal/provider\"\n)\n\n// Chain applies middleware to providers in order\nfunc Chain(middlewares []Middleware, p provider.ToolProvider) provider.ToolProvider {\n    if len(middlewares) == 0 {\n        return p\n    }\n\n    // Apply in reverse order so first middleware wraps outermost\n    wrapped := p\n    for i := len(middlewares) - 1; i &gt;= 0; i-- {\n        wrapped = middlewares[i](wrapped)\n    }\n    return wrapped\n}\n\n// ApplyToRegistry wraps all providers in a registry with middleware\nfunc ApplyToRegistry(registry *provider.Registry, middlewares []Middleware) {\n    for _, p := range registry.All() {\n        wrapped := Chain(middlewares, p)\n        // Replace in registry\n        // ...\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#53-logging-middleware-internalmiddlewarelogginggo","title":"5.3 Logging Middleware (<code>internal/middleware/logging.go</code>)","text":"<pre><code>package middleware\n\nimport (\n    \"context\"\n    \"log/slog\"\n    \"time\"\n\n    \"github.com/jonwraymond/metatools-mcp/internal/provider\"\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\ntype loggingMiddleware struct {\n    next   provider.ToolProvider\n    logger *slog.Logger\n    level  slog.Level\n}\n\n// NewLoggingMiddleware creates a logging middleware\nfunc NewLoggingMiddleware(logger *slog.Logger, level slog.Level) Middleware {\n    return func(next provider.ToolProvider) provider.ToolProvider {\n        return &amp;loggingMiddleware{\n            next:   next,\n            logger: logger,\n            level:  level,\n        }\n    }\n}\n\nfunc (m *loggingMiddleware) Name() string        { return m.next.Name() }\nfunc (m *loggingMiddleware) Tool() *mcp.Tool     { return m.next.Tool() }\n\nfunc (m *loggingMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    start := time.Now()\n\n    m.logger.Log(ctx, m.level, \"tool call started\",\n        \"tool\", m.next.Name(),\n        \"input\", input,\n    )\n\n    result, err := m.next.Handle(ctx, input)\n\n    m.logger.Log(ctx, m.level, \"tool call completed\",\n        \"tool\", m.next.Name(),\n        \"duration\", time.Since(start),\n        \"error\", err,\n    )\n\n    return result, err\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#verification-criteria_4","title":"Verification Criteria","text":"<ul> <li>[ ] Logging middleware logs all tool calls</li> <li>[ ] Auth middleware validates tokens when configured</li> <li>[ ] Rate limiting middleware enforces limits</li> <li>[ ] Metrics middleware exposes Prometheus metrics</li> <li>[ ] Middleware chain order matches config order</li> <li>[ ] Unit tests for each middleware type</li> <li>[ ] Integration test: Full middleware chain</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#summary-implementation-priority-matrix","title":"Summary: Implementation Priority Matrix","text":"Phase Priority Risk Duration MVP? Phase 1: CLI + Config Critical Low 2 weeks \u2713 Phase 2: Transport High Medium 2 weeks \u2713 Phase 3: Tool Provider Registry High Medium 1 week \u2713 Phase 4: Backend Registry Medium Medium 2 weeks Phase 5: Middleware Chain Low Low 2 weeks <p>MVP Timeline: ~5 weeks (Phases 1-3) Full Implementation: ~9 weeks (All phases)</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#appendix-architectural-decisions","title":"Appendix: Architectural Decisions","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#decision-1-koanf-over-viper","title":"Decision 1: Koanf over Viper","text":"<p>Decision: Use Koanf for configuration loading instead of Viper.</p> <p>Rationale: - Lighter dependency footprint - Modular provider architecture - Cleaner API for layered configuration - Better suited for our use case</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#decision-2-interface-based-transports-over-mcp-sdk-extension","title":"Decision 2: Interface-based Transports over MCP SDK Extension","text":"<p>Decision: Define our own Transport interface that wraps MCP SDK transports.</p> <p>Rationale: - Decouples from MCP SDK implementation details - Enables custom transports (Unix socket, gRPC) - Allows consistent lifecycle management - Facilitates testing with mock transports</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#decision-3-provider-pattern-over-direct-handler-registration","title":"Decision 3: Provider Pattern over Direct Handler Registration","text":"<p>Decision: Use ToolProvider interface instead of direct MCP tool registration.</p> <p>Rationale: - Enables middleware wrapping - Supports dynamic registration - Cleaner separation of concerns - Facilitates testing</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#decision-4-decorator-pattern-for-middleware","title":"Decision 4: Decorator Pattern for Middleware","text":"<p>Decision: Use decorator pattern (wrapping) for middleware chain.</p> <p>Rationale: - Matches go-chi's proven approach - Simple mental model - Easy to compose and test - Preserves ToolProvider interface</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#changelog","title":"Changelog","text":"Date Change 2026-01-27 Initial draft with 5 phases"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/","title":"MCP Spec Alignment Proposal","text":"<p>Status: Draft Date: 2026-01-28 Related: pluggable-architecture, architecture-evaluation, ROADMAP</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#summary","title":"Summary","text":"<p><code>metatools-mcp</code> already exposes a clean MCP-native tool surface, but several MCP-spec features are only partially covered or are not yet surfaced at the server boundary. This proposal defines a focused alignment path with the latest MCP spec (2025-11-25) and the official Go SDK, while keeping the current tool-first architecture stable.</p> <p>The goal is to improve protocol completeness and operational correctness without redesigning the existing libraries.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#goals","title":"Goals","text":"<ol> <li>Spec compliance at the server edge: align handler behavior with MCP method contracts (tools list, tool calls, tool error semantics, pagination).</li> <li>Dynamic tool updates: support <code>tools/list_changed</code> notifications tied to toolindex change events.</li> <li>Operational robustness: ensure cancellation/progress signals propagate through toolrun and toolruntime where supported.</li> <li>Clear expansion path for MCP resources and prompts without blocking current tool-focused roadmap.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#observations-current-state","title":"Observations (Current State)","text":"<ul> <li><code>metatools-mcp</code> exposes MCP tools via the official Go SDK and maps errors into MCP tool error payloads.</li> <li>Tool schemas are derived from <code>toolmodel</code> and remain MCP-native, preserving compatibility end-to-end.</li> <li>Tool registration is static at startup; runtime updates do not emit <code>tools/list_changed</code> yet.</li> <li>Resources and prompts are not yet part of the metatools surface.</li> <li>Cancellation/progress behavior depends on downstream runner behavior; it is not yet surfaced as a first-class contract.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#mcp-spec-alignment-targets","title":"MCP Spec Alignment Targets","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#1-tool-list-change-notifications","title":"1) Tool list change notifications","text":"<p>When tool availability changes (new tools, removed tools, updated schemas), the MCP server should notify connected clients via <code>notifications/tools/list_changed</code>. This can be wired to <code>toolindex</code> change callbacks.</p> <p>Implementation idea: - Subscribe to toolindex OnChange/Refresh hooks. - Emit <code>tools/list_changed</code> to all MCP sessions. - Expose a config flag to disable notifications for static deployments.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#2-pagination-and-list-contracts","title":"2) Pagination and list contracts","text":"<p>The MCP spec defines <code>tools/list</code> pagination and page sizes. <code>metatools-mcp</code> already sets a default page size in the Go SDK; align <code>search_tools</code> and <code>list_namespaces</code> with consistent paging semantics and cursor shapes.</p> <p>Implementation idea: - Cap and validate list size consistently. - Use stable cursor generation (e.g., opaque tokens) for pagination of search results.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#3-cancellation-and-progress-signals","title":"3) Cancellation and progress signals","text":"<p>MCP supports cancellation and progress notifications for long-running operations. For <code>run_tool</code>, <code>run_chain</code>, and <code>execute_code</code>, cancellation should be propagated to toolrun/toolruntime if supported.</p> <p>Implementation idea: - Use <code>ctx</code> cancellation to interrupt tool execution. - Surface progress events from toolruntime or toolrun (where available). - Document supported behavior per tool type (local, provider, MCP).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#4-resources-and-prompts-expansion-future-prd","title":"4) Resources and prompts expansion (future PRD)","text":"<p>MCP defines resources and prompts alongside tools. The architecture should leave a clear integration path (e.g., new <code>toolresource</code> and <code>toolprompt</code> libraries or adapters in metatools-mcp).</p> <p>Implementation idea: - Draft a separate PRD to introduce a resources/prompt provider interface. - Keep current tool-only server behavior stable and backwards compatible.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#corrected-assumptions","title":"Corrected Assumptions","text":"<ul> <li>MCP versioning: target 2025-11-25 as the default protocol version in metatools-mcp and toolmodel. Back-compat shims should be explicit rather than implicit.</li> <li>Go SDK alignment: the official MCP Go SDK should be pinned to a version that explicitly supports the 2025-11-25 spec and its tool schema fields (icons, outputSchema, etc.).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#risks","title":"Risks","text":"<ul> <li>Notification spam: emitting list change notifications on every small index update could overwhelm clients. Mitigate with debouncing.</li> <li>Partial cancellation support: some backends may not support cancellation; document and expose that limitation.</li> <li>Scope creep: adding resources/prompts too early could delay core tool stability; keep those as a later PRD.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#recommended-next-steps","title":"Recommended Next Steps","text":"<ol> <li>Implement tool list change notifications tied to toolindex changes.</li> <li>Ensure pagination and cursor semantics are consistent across tool listing and search.</li> <li>Add cancellation/progress wiring and document limitations.</li> <li>Create a dedicated PRD for resources/prompts support.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#appendix-related-prd","title":"Appendix: Related PRD","text":"<p>See <code>docs/plans/2026-01-28-prd-015-mcp-spec-alignment.md</code> for an incremental implementation plan.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/","title":"Multi-Tenancy Extension for Pluggable Architecture","text":"<p>Status: Draft Date: 2026-01-28 Related: Pluggable Architecture Proposal</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#overview","title":"Overview","text":"<p>This document extends the pluggable architecture to support multi-tenancy in a flexible, pluggable way. The design allows different tenant isolation strategies without hardcoding any specific approach.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#multi-tenancy-architecture","title":"Multi-Tenancy Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#design-principles","title":"Design Principles","text":"<ol> <li>Pluggable Tenant Resolution - How tenants are identified (JWT, API key, header, etc.)</li> <li>Pluggable Isolation Strategy - Level of isolation between tenants</li> <li>Tenant-Aware Middleware - All middleware can access tenant context</li> <li>Tenant-Specific Configuration - Override any config per tenant</li> <li>Backward Compatible - Single-tenant mode works without changes</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       MULTI-TENANT MCP SERVER                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Incoming Request                                                           \u2502\n\u2502         \u2502                                                                     \u2502\n\u2502         \u25bc                                                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    TENANT RESOLUTION MIDDLEWARE                      \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502   \u2502    JWT      \u2502 \u2502   API Key   \u2502 \u2502   Header    \u2502 \u2502   Custom    \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502  Resolver   \u2502 \u2502  Resolver   \u2502 \u2502  Resolver   \u2502 \u2502  Resolver   \u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Output: Tenant Context injected into request context               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                             \u2502                                                \u2502\n\u2502                             \u25bc                                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    TENANT-AWARE MIDDLEWARE CHAIN                     \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502   \u2502\n\u2502   \u2502   \u2502 Tenant   \u2502\u2192\u2502 Tenant   \u2502\u2192\u2502 Tenant   \u2502\u2192\u2502 Tenant   \u2502               \u2502   \u2502\n\u2502   \u2502   \u2502 Scoped   \u2502 \u2502 Rate     \u2502 \u2502 Audit    \u2502 \u2502 Tool     \u2502               \u2502   \u2502\n\u2502   \u2502   \u2502 Config   \u2502 \u2502 Limits   \u2502 \u2502 Logging  \u2502 \u2502 Filter   \u2502               \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                             \u2502                                                \u2502\n\u2502                             \u25bc                                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    TENANT-SCOPED REGISTRIES                          \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502   \u2502\n\u2502   \u2502   \u2502  Shared Registry \u2502    \u2502  Tenant Registry \u2502                      \u2502   \u2502\n\u2502   \u2502   \u2502  (all tenants)   \u2502    \u2502  (tenant-only)   \u2502                      \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Tool visibility = Shared \u222a Tenant-specific - Denied               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#core-interfaces","title":"Core Interfaces","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-model","title":"Tenant Model","text":"<pre><code>// Tenant represents a tenant in the system\ntype Tenant struct {\n    ID          string            // Unique tenant identifier\n    Name        string            // Human-readable name\n    Tier        TenantTier        // free, pro, enterprise\n    Metadata    map[string]any    // Arbitrary tenant metadata\n    CreatedAt   time.Time\n    UpdatedAt   time.Time\n}\n\n// TenantTier defines service levels\ntype TenantTier string\n\nconst (\n    TenantTierFree       TenantTier = \"free\"\n    TenantTierPro        TenantTier = \"pro\"\n    TenantTierEnterprise TenantTier = \"enterprise\"\n)\n\n// TenantContext holds runtime tenant information\ntype TenantContext struct {\n    Tenant      *Tenant\n    Permissions []string          // Resolved permissions\n    Config      *TenantConfig     // Tenant-specific config overrides\n    Quotas      *TenantQuotas     // Current quota state\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-resolver-interface","title":"Tenant Resolver Interface","text":"<pre><code>// TenantResolver identifies the tenant from a request\ntype TenantResolver interface {\n    // Resolve extracts tenant information from the request context\n    // Returns nil tenant for anonymous/default tenant\n    Resolve(ctx context.Context, req *Request) (*TenantContext, error)\n}\n\n// TenantResolverFunc is a convenience type\ntype TenantResolverFunc func(ctx context.Context, req *Request) (*TenantContext, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#built-in-resolvers","title":"Built-in Resolvers","text":"<pre><code>// JWTTenantResolver extracts tenant from JWT claims\ntype JWTTenantResolver struct {\n    ClaimKey    string                    // JWT claim containing tenant ID\n    TenantStore TenantStore               // Lookup tenant details\n    Validator   JWTValidator              // Validate JWT\n}\n\nfunc (r *JWTTenantResolver) Resolve(ctx context.Context, req *Request) (*TenantContext, error) {\n    token := extractBearerToken(req)\n    claims, err := r.Validator.Validate(token)\n    if err != nil {\n        return nil, err\n    }\n\n    tenantID, ok := claims[r.ClaimKey].(string)\n    if !ok {\n        return nil, ErrNoTenantClaim\n    }\n\n    tenant, err := r.TenantStore.Get(ctx, tenantID)\n    if err != nil {\n        return nil, err\n    }\n\n    return &amp;TenantContext{\n        Tenant:      tenant,\n        Permissions: extractPermissions(claims),\n        Config:      r.TenantStore.GetConfig(ctx, tenantID),\n    }, nil\n}\n\n// APIKeyTenantResolver extracts tenant from API key\ntype APIKeyTenantResolver struct {\n    HeaderName  string       // Header containing API key\n    KeyStore    APIKeyStore  // Lookup key -&gt; tenant mapping\n}\n\n// HeaderTenantResolver extracts tenant from a header\ntype HeaderTenantResolver struct {\n    HeaderName  string\n    TenantStore TenantStore\n}\n\n// CompositeTenantResolver tries multiple resolvers in order\ntype CompositeTenantResolver struct {\n    Resolvers []TenantResolver\n}\n\nfunc (r *CompositeTenantResolver) Resolve(ctx context.Context, req *Request) (*TenantContext, error) {\n    for _, resolver := range r.Resolvers {\n        tc, err := resolver.Resolve(ctx, req)\n        if err == nil &amp;&amp; tc != nil {\n            return tc, nil\n        }\n    }\n    return nil, ErrNoTenantResolved\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-configuration","title":"Tenant Configuration","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-specific-config-overrides","title":"Tenant-Specific Config Overrides","text":"<pre><code>// TenantConfig holds per-tenant configuration overrides\ntype TenantConfig struct {\n    // Tool access control\n    AllowedTools     []string          // Whitelist (empty = all allowed)\n    DeniedTools      []string          // Blacklist (takes precedence)\n    AllowedBackends  []string          // Which backends tenant can use\n    DeniedBackends   []string          // Blacklisted backends\n\n    // Resource limits\n    RateLimits       *RateLimitConfig  // Override rate limits\n    Quotas           *QuotaConfig      // Usage quotas\n\n    // Feature flags\n    Features         map[string]bool   // Feature toggles\n\n    // Execution\n    MaxTimeout       time.Duration     // Max allowed timeout\n    MaxChainSteps    int               // Max chain steps\n    MaxToolCalls     int               // Max tool calls per request\n\n    // Custom middleware config\n    MiddlewareConfig map[string]any    // Per-middleware overrides\n}\n\n// QuotaConfig defines usage quotas\ntype QuotaConfig struct {\n    DailyRequests    int64             // Requests per day\n    DailyToolCalls   int64             // Tool calls per day\n    MonthlyRequests  int64             // Requests per month\n    MonthlyToolCalls int64             // Tool calls per month\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<pre><code># metatools.yaml - Multi-tenant configuration\n\ntenancy:\n  enabled: true\n\n  # Tenant resolution strategy\n  resolver:\n    type: composite\n    resolvers:\n      - type: jwt\n        claim_key: tenant_id\n        issuer: https://auth.example.com\n      - type: api_key\n        header: X-API-Key\n      - type: header\n        header: X-Tenant-ID\n\n  # Default tenant (anonymous requests)\n  default_tenant:\n    id: default\n    tier: free\n    config:\n      rate_limits:\n        requests_per_minute: 10\n      allowed_tools:\n        - search_tools\n        - describe_tool\n      denied_tools:\n        - execute_code\n\n  # Tier-based defaults\n  tiers:\n    free:\n      rate_limits:\n        requests_per_minute: 60\n        burst: 10\n      quotas:\n        daily_requests: 1000\n        monthly_requests: 10000\n      denied_tools:\n        - execute_code\n      max_chain_steps: 3\n\n    pro:\n      rate_limits:\n        requests_per_minute: 300\n        burst: 50\n      quotas:\n        daily_requests: 10000\n        monthly_requests: 100000\n      max_chain_steps: 10\n\n    enterprise:\n      rate_limits:\n        requests_per_minute: 1000\n        burst: 200\n      quotas:\n        daily_requests: -1  # unlimited\n        monthly_requests: -1\n      max_chain_steps: 50\n      features:\n        custom_backends: true\n        audit_logging: true\n\n# Per-tenant overrides (loaded from store or config)\ntenants:\n  acme-corp:\n    tier: enterprise\n    config:\n      allowed_backends:\n        - local\n        - github\n        - jira\n      features:\n        execute_code: true\n      middleware_config:\n        audit:\n          destination: elasticsearch\n          index: acme-audit\n\n  startup-xyz:\n    tier: pro\n    config:\n      rate_limits:\n        requests_per_minute: 500  # Override pro default\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-aware-middleware","title":"Tenant-Aware Middleware","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-context-middleware","title":"Tenant Context Middleware","text":"<pre><code>// TenantMiddleware resolves and injects tenant context\nfunc TenantMiddleware(resolver TenantResolver) Middleware {\n    return func(next ToolProvider) ToolProvider {\n        return &amp;tenantMiddleware{\n            resolver: resolver,\n            next:     next,\n        }\n    }\n}\n\ntype tenantMiddleware struct {\n    resolver TenantResolver\n    next     ToolProvider\n}\n\nfunc (m *tenantMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    // Resolve tenant from context (set by transport layer)\n    req := RequestFromContext(ctx)\n    tc, err := m.resolver.Resolve(ctx, req)\n    if err != nil {\n        return nil, &amp;TenantError{Op: \"resolve\", Err: err}\n    }\n\n    // Inject tenant context\n    ctx = WithTenantContext(ctx, tc)\n\n    return m.next.Handle(ctx, input)\n}\n\n// Context helpers\nfunc WithTenantContext(ctx context.Context, tc *TenantContext) context.Context\nfunc TenantFromContext(ctx context.Context) *TenantContext\nfunc TenantIDFromContext(ctx context.Context) string\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-aware-rate-limiting","title":"Tenant-Aware Rate Limiting","text":"<pre><code>// TenantRateLimitMiddleware applies per-tenant rate limits\ntype TenantRateLimitMiddleware struct {\n    store    RateLimitStore\n    defaults RateLimitConfig\n    next     ToolProvider\n}\n\nfunc (m *TenantRateLimitMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    tc := TenantFromContext(ctx)\n\n    // Get tenant-specific limits or tier defaults\n    limits := m.resolveLimits(tc)\n\n    // Check rate limit\n    key := fmt.Sprintf(\"tenant:%s:tool:%s\", tc.Tenant.ID, m.next.Name())\n    allowed, err := m.store.Allow(ctx, key, limits)\n    if err != nil {\n        return nil, err\n    }\n    if !allowed {\n        return nil, &amp;RateLimitError{\n            TenantID: tc.Tenant.ID,\n            Limit:    limits.RequestsPerMinute,\n        }\n    }\n\n    return m.next.Handle(ctx, input)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-tool-filter","title":"Tenant Tool Filter","text":"<pre><code>// TenantToolFilterMiddleware filters tools based on tenant permissions\ntype TenantToolFilterMiddleware struct {\n    next ToolProvider\n}\n\nfunc (m *TenantToolFilterMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    tc := TenantFromContext(ctx)\n    toolName := m.next.Name()\n\n    // Check denied tools first (takes precedence)\n    if slices.Contains(tc.Config.DeniedTools, toolName) {\n        return nil, &amp;ToolDeniedError{\n            TenantID: tc.Tenant.ID,\n            Tool:     toolName,\n            Reason:   \"tool denied for tenant\",\n        }\n    }\n\n    // Check allowed tools (if whitelist is non-empty)\n    if len(tc.Config.AllowedTools) &gt; 0 {\n        if !slices.Contains(tc.Config.AllowedTools, toolName) {\n            return nil, &amp;ToolDeniedError{\n                TenantID: tc.Tenant.ID,\n                Tool:     toolName,\n                Reason:   \"tool not in allowed list\",\n            }\n        }\n    }\n\n    return m.next.Handle(ctx, input)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-audit-middleware","title":"Tenant Audit Middleware","text":"<pre><code>// TenantAuditMiddleware logs all actions with tenant context\ntype TenantAuditMiddleware struct {\n    logger AuditLogger\n    next   ToolProvider\n}\n\nfunc (m *TenantAuditMiddleware) Handle(ctx context.Context, input map[string]any) (*mcp.CallToolResult, error) {\n    tc := TenantFromContext(ctx)\n    start := time.Now()\n\n    result, err := m.next.Handle(ctx, input)\n\n    m.logger.Log(AuditEntry{\n        Timestamp:  time.Now(),\n        TenantID:   tc.Tenant.ID,\n        TenantTier: string(tc.Tenant.Tier),\n        Tool:       m.next.Name(),\n        Input:      input,\n        Success:    err == nil,\n        Duration:   time.Since(start),\n        RequestID:  RequestIDFromContext(ctx),\n        UserID:     UserIDFromContext(ctx),\n    })\n\n    return result, err\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-scoped-registries","title":"Tenant-Scoped Registries","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#multi-tenant-tool-registry","title":"Multi-Tenant Tool Registry","text":"<pre><code>// MultiTenantRegistry wraps a base registry with tenant scoping\ntype MultiTenantRegistry struct {\n    shared        *provider.Registry  // Shared tools (all tenants)\n    tenantTools   map[string]*provider.Registry  // Tenant-specific tools\n    tenantStore   TenantStore\n    mu            sync.RWMutex\n}\n\n// GetForTenant returns a tenant-scoped view of the registry\nfunc (r *MultiTenantRegistry) GetForTenant(tenantID string) *TenantScopedRegistry {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    tenant, _ := r.tenantStore.Get(context.Background(), tenantID)\n    tenantReg := r.tenantTools[tenantID]\n\n    return &amp;TenantScopedRegistry{\n        tenant:   tenant,\n        shared:   r.shared,\n        specific: tenantReg,\n    }\n}\n\n// TenantScopedRegistry provides a tenant's view of available tools\ntype TenantScopedRegistry struct {\n    tenant   *Tenant\n    shared   *provider.Registry\n    specific *provider.Registry\n}\n\n// All returns all tools visible to the tenant\nfunc (r *TenantScopedRegistry) All() []provider.ToolProvider {\n    var result []provider.ToolProvider\n\n    // Add shared tools (filtered by tenant config)\n    for _, p := range r.shared.All() {\n        if r.isToolAllowed(p.Name()) {\n            result = append(result, p)\n        }\n    }\n\n    // Add tenant-specific tools\n    if r.specific != nil {\n        result = append(result, r.specific.All()...)\n    }\n\n    return result\n}\n\nfunc (r *TenantScopedRegistry) isToolAllowed(name string) bool {\n    if r.tenant == nil || r.tenant.Config == nil {\n        return true\n    }\n\n    cfg := r.tenant.Config\n\n    // Check denied list first\n    if slices.Contains(cfg.DeniedTools, name) {\n        return false\n    }\n\n    // Check allowed list (if specified)\n    if len(cfg.AllowedTools) &gt; 0 {\n        return slices.Contains(cfg.AllowedTools, name)\n    }\n\n    return true\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#multi-tenant-backend-registry","title":"Multi-Tenant Backend Registry","text":"<pre><code>// MultiTenantBackendRegistry manages tenant-scoped backends\ntype MultiTenantBackendRegistry struct {\n    shared        *backend.Registry\n    tenantBackends map[string]*backend.Registry\n    mu            sync.RWMutex\n}\n\n// GetForTenant returns backends available to a tenant\nfunc (r *MultiTenantBackendRegistry) GetForTenant(ctx context.Context, tenantID string) *TenantScopedBackendRegistry {\n    tc := TenantFromContext(ctx)\n\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    return &amp;TenantScopedBackendRegistry{\n        tenant:   tc,\n        shared:   r.shared,\n        specific: r.tenantBackends[tenantID],\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#isolation-strategies","title":"Isolation Strategies","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#strategy-1-shared-infrastructure-default","title":"Strategy 1: Shared Infrastructure (Default)","text":"<p>All tenants share the same server instance with logical isolation via middleware.</p> <pre><code>tenancy:\n  isolation: shared\n  # All tenants use same tool/backend registries\n  # Isolation via rate limits, tool filtering, audit logging\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    SHARED INFRASTRUCTURE                          \u2502\n\u2502                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n\u2502   \u2502Tenant A \u2502 \u2502Tenant B \u2502 \u2502Tenant C \u2502                           \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                           \u2502\n\u2502        \u2502           \u2502           \u2502                                 \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                 \u2502\n\u2502                    \u2502                                              \u2502\n\u2502                    \u25bc                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502              SHARED MCP SERVER INSTANCE                  \u2502   \u2502\n\u2502   \u2502                                                           \u2502   \u2502\n\u2502   \u2502   Tenant Middleware \u2192 Tool Filter \u2192 Rate Limit \u2192 Audit   \u2502   \u2502\n\u2502   \u2502                                                           \u2502   \u2502\n\u2502   \u2502   Shared Tool Registry + Tenant Configs                  \u2502   \u2502\n\u2502   \u2502                                                           \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#strategy-2-namespace-isolation","title":"Strategy 2: Namespace Isolation","text":"<p>Tenants have isolated namespaces within shared infrastructure.</p> <pre><code>tenancy:\n  isolation: namespace\n  # Each tenant gets own tool namespace prefix\n  # Tenant A sees: tenant-a:*, shared:*\n  # Tenant B sees: tenant-b:*, shared:*\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    NAMESPACE ISOLATION                            \u2502\n\u2502                                                                   \u2502\n\u2502   Tenant A View:              Tenant B View:                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502   \u2502 shared:*        \u2502        \u2502 shared:*        \u2502                \u2502\n\u2502   \u2502 tenant-a:*      \u2502        \u2502 tenant-b:*      \u2502                \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2502                                                                   \u2502\n\u2502   Backend Routing:                                               \u2502\n\u2502   shared:* \u2192 Shared backends                                     \u2502\n\u2502   tenant-a:* \u2192 Tenant A's backends                              \u2502\n\u2502   tenant-b:* \u2192 Tenant B's backends                              \u2502\n\u2502                                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#strategy-3-process-isolation","title":"Strategy 3: Process Isolation","text":"<p>Each tenant gets a dedicated server process.</p> <pre><code>tenancy:\n  isolation: process\n  # Tenant requests routed to dedicated processes\n  # Maximum isolation, higher resource usage\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PROCESS ISOLATION                              \u2502\n\u2502                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502  Tenant A   \u2502        \u2502  Tenant B   \u2502        \u2502  Tenant C   \u2502 \u2502\n\u2502   \u2502   Process   \u2502        \u2502   Process   \u2502        \u2502   Process   \u2502 \u2502\n\u2502   \u2502             \u2502        \u2502             \u2502        \u2502             \u2502 \u2502\n\u2502   \u2502 Own config  \u2502        \u2502 Own config  \u2502        \u2502 Own config  \u2502 \u2502\n\u2502   \u2502 Own tools   \u2502        \u2502 Own tools   \u2502        \u2502 Own tools   \u2502 \u2502\n\u2502   \u2502 Own backends\u2502        \u2502 Own backends\u2502        \u2502 Own backends\u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502          \u2502                      \u2502                      \u2502         \u2502\n\u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                              \u2502                                    \u2502\n\u2502                              \u25bc                                    \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    TENANT ROUTER                         \u2502   \u2502\n\u2502   \u2502          (Load balancer / API Gateway)                   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenant-storage","title":"Tenant Storage","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#tenantstore-interface","title":"TenantStore Interface","text":"<pre><code>// TenantStore manages tenant data\ntype TenantStore interface {\n    // CRUD\n    Get(ctx context.Context, id string) (*Tenant, error)\n    Create(ctx context.Context, tenant *Tenant) error\n    Update(ctx context.Context, tenant *Tenant) error\n    Delete(ctx context.Context, id string) error\n    List(ctx context.Context, opts ListOptions) ([]*Tenant, error)\n\n    // Config\n    GetConfig(ctx context.Context, id string) (*TenantConfig, error)\n    UpdateConfig(ctx context.Context, id string, cfg *TenantConfig) error\n\n    // Quotas\n    GetQuotaUsage(ctx context.Context, id string) (*QuotaUsage, error)\n    IncrementUsage(ctx context.Context, id string, metric string, delta int64) error\n}\n\n// Built-in implementations\ntype MemoryTenantStore struct { ... }      // For testing/development\ntype RedisTenantStore struct { ... }       // For distributed deployments\ntype PostgresTenantStore struct { ... }    // For persistent storage\ntype ConfigFileTenantStore struct { ... }  // For static configuration\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#end-to-end-example","title":"End-to-End Example","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#enterprise-saas-configuration","title":"Enterprise SaaS Configuration","text":"<pre><code># metatools-saas.yaml\n\nserver:\n  name: \"metatools-saas\"\n  version: \"1.0.0\"\n\ntransport:\n  type: sse\n  http:\n    port: 8080\n\ntenancy:\n  enabled: true\n\n  resolver:\n    type: composite\n    resolvers:\n      - type: jwt\n        issuer: https://auth.saas.example.com\n        claim_key: org_id\n      - type: api_key\n        header: X-API-Key\n\n  store:\n    type: postgres\n    postgres:\n      connection_string: ${DATABASE_URL}\n\n  isolation: shared\n\n  tiers:\n    free:\n      rate_limits:\n        requests_per_minute: 30\n      quotas:\n        daily_requests: 500\n      denied_tools:\n        - execute_code\n        - run_chain\n\n    startup:\n      rate_limits:\n        requests_per_minute: 120\n      quotas:\n        daily_requests: 5000\n      max_chain_steps: 5\n\n    enterprise:\n      rate_limits:\n        requests_per_minute: 1000\n      quotas:\n        daily_requests: -1\n      features:\n        custom_backends: true\n        dedicated_support: true\n\nmiddleware:\n  chain:\n    - tenant          # Resolve tenant first\n    - tenant_config   # Load tenant-specific config\n    - tenant_filter   # Filter tools by tenant permissions\n    - tenant_rate_limit\n    - tenant_quota\n    - tenant_audit\n    - logging\n    - metrics\n\nbackends:\n  shared:\n    github:\n      enabled: true\n      kind: mcp\n      config:\n        command: npx\n        args: [\"-y\", \"@modelcontextprotocol/server-github\"]\n\n    filesystem:\n      enabled: true\n      kind: mcp\n      config:\n        command: npx\n        args: [\"-y\", \"@modelcontextprotocol/server-filesystem\"]\n\n  # Enterprise tenants can have custom backends\n  # Loaded from tenant config in database\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#request-flow","title":"Request Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    MULTI-TENANT REQUEST FLOW                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   1. INCOMING REQUEST                                                        \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  POST /mcp HTTP/1.1                                                 \u2502   \u2502\n\u2502   \u2502  Authorization: Bearer eyJhbGc...                                  \u2502   \u2502\n\u2502   \u2502  X-API-Key: key_abc123 (fallback)                                  \u2502   \u2502\n\u2502   \u2502                                                                     \u2502   \u2502\n\u2502   \u2502  { \"method\": \"tools/call\", \"params\": { \"name\": \"github/...\" } }   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502   2. TENANT RESOLUTION                                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  JWT Resolver:                                                      \u2502   \u2502\n\u2502   \u2502  - Validate token                                                   \u2502   \u2502\n\u2502   \u2502  - Extract org_id: \"acme-corp\"                                     \u2502   \u2502\n\u2502   \u2502  - Load tenant from store                                          \u2502   \u2502\n\u2502   \u2502  - Inject TenantContext into ctx                                   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502   TenantContext:                     \u2502                                       \u2502\n\u2502   - ID: \"acme-corp\"                  \u2502                                       \u2502\n\u2502   - Tier: \"enterprise\"               \u2502                                       \u2502\n\u2502   - Config: { allowed_backends: [...], features: {...} }                    \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502   3. TENANT TOOL FILTER                                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  Check: Is \"github/create_issue\" allowed for acme-corp?            \u2502   \u2502\n\u2502   \u2502  - Not in denied_tools \u2713                                           \u2502   \u2502\n\u2502   \u2502  - github backend is in allowed_backends \u2713                         \u2502   \u2502\n\u2502   \u2502  \u2192 ALLOWED                                                          \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502   4. TENANT RATE LIMIT                                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  Key: \"tenant:acme-corp:tool:github/create_issue\"                  \u2502   \u2502\n\u2502   \u2502  Limit: 1000 req/min (enterprise tier)                             \u2502   \u2502\n\u2502   \u2502  Current: 42 \u2192 ALLOWED                                             \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502   5. EXECUTION (with tenant context)                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  Route to: github backend                                          \u2502   \u2502\n\u2502   \u2502  Execute: create_issue                                             \u2502   \u2502\n\u2502   \u2502  Tenant-scoped audit log written                                   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                      \u2502                                       \u2502\n\u2502                                      \u25bc                                       \u2502\n\u2502   6. RESPONSE                                                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  { \"result\": { \"issue_number\": 456 }, \"id\": \"req-123\" }           \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#implementation-priority","title":"Implementation Priority","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#phase-1-core-multi-tenancy-2-weeks","title":"Phase 1: Core Multi-Tenancy (2 weeks)","text":"<ol> <li>Define <code>Tenant</code>, <code>TenantContext</code>, <code>TenantConfig</code> types</li> <li>Implement <code>TenantResolver</code> interface + JWT/API Key resolvers</li> <li>Implement <code>TenantMiddleware</code> for context injection</li> <li>Add <code>TenantFromContext()</code> helper</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#phase-2-tenant-aware-middleware-1-week","title":"Phase 2: Tenant-Aware Middleware (1 week)","text":"<ol> <li>Implement <code>TenantRateLimitMiddleware</code></li> <li>Implement <code>TenantToolFilterMiddleware</code></li> <li>Implement <code>TenantAuditMiddleware</code></li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#phase-3-tenant-storage-1-week","title":"Phase 3: Tenant Storage (1 week)","text":"<ol> <li>Define <code>TenantStore</code> interface</li> <li>Implement <code>MemoryTenantStore</code> for development</li> <li>Implement <code>PostgresTenantStore</code> for production</li> <li>Add quota tracking</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#phase-4-advanced-features-2-weeks","title":"Phase 4: Advanced Features (2 weeks)","text":"<ol> <li>Multi-tenant tool registry</li> <li>Multi-tenant backend registry</li> <li>Namespace isolation strategy</li> <li>Process isolation strategy (optional)</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#changes-to-component-libraries","title":"Changes to Component Libraries","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#toolrun-changes","title":"toolrun Changes","text":"<pre><code>// Add tenant context propagation\ntype RunOptions struct {\n    // Existing...\n    TenantID string  // NEW: Tenant context for execution\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#toolindex-changes","title":"toolindex Changes","text":"<pre><code>// Add tenant-scoped search\ntype Index interface {\n    // Existing...\n    SearchForTenant(tenantID string, query string, limit int) ([]Summary, error)  // NEW\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#summary","title":"Summary","text":"<p>Multi-tenancy integrates cleanly into the pluggable architecture via:</p> <ol> <li>Pluggable TenantResolver - Any identification strategy</li> <li>Tenant-Aware Middleware - Transparent isolation via middleware chain</li> <li>Tenant-Scoped Registries - Logical isolation of tools/backends</li> <li>Configuration Hierarchy - Defaults \u2192 Tier \u2192 Tenant overrides</li> <li>Multiple Isolation Strategies - Shared, namespace, or process isolation</li> </ol> <p>All components remain pluggable and can be replaced or extended.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#changelog","title":"Changelog","text":"Date Change 2026-01-28 Initial multi-tenancy extension proposal"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/","title":"Pluggable Architecture Proposal","text":"<p>Status: Draft Date: 2026-01-27 Author: Jon Raymond</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#executive-summary","title":"Executive Summary","text":"<p>This proposal outlines a pluggable, modular architecture for metatools-mcp that enables: - Multiple transport protocols (stdio, HTTP/SSE, WebSocket) - Plug-and-play tool providers - Configurable search strategies - Extensible backend registries - Cross-cutting middleware</p> <p>The design leverages Go's interface-based composition, build-tag gating, and configuration-driven initialization to create a flexible framework while maintaining the clean, canonical core.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Motivation</li> <li>Current Architecture Analysis</li> <li>Proposed Architecture</li> <li>Extension Points</li> <li>Transport Layer</li> <li>Search Strategy</li> <li>Tool Provider Registry</li> <li>Backend Registry</li> <li>Middleware Chain</li> <li>Cache Layer</li> <li>Additional Cross-Cutting Concerns</li> <li>Multi-Backend Architecture</li> <li>Configuration Design</li> <li>Implementation Approach</li> <li>End-to-End Examples</li> <li>Enterprise AI Assistant</li> <li>Local Development Setup</li> <li>Multi-LLM Tool Router</li> <li>Microservices Tool Mesh</li> <li>Request Flow Diagram</li> <li>Comparative Analysis</li> <li>References</li> <li>Architecture Validation</li> <li>Implementation Phases</li> <li>Component Library Analysis</li> <li>Multi-Tenancy Extension</li> <li>Extension Point Catalog</li> <li>Revised Implementation Timeline</li> <li>Architecture Evaluation</li> <li>Protocol-Agnostic Tools</li> <li>Versioning Strategy</li> <li>Multi-Language Extensibility</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#motivation","title":"Motivation","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#goals","title":"Goals","text":"<ol> <li>Multi-transport support - Run as stdio MCP server (current) or HTTP/SSE server (high availability)</li> <li>Plug-and-play extensibility - Add new tools, backends, and search strategies without modifying core</li> <li>Configuration-driven - YAML/JSON config files with environment variable overrides</li> <li>Framework potential - Enable metatools-mcp as a reusable framework for building MCP servers</li> <li>Multi-language support - Enable components in Python, Rust, TypeScript via standardized interface contracts</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#non-goals","title":"Non-Goals","text":"<ul> <li>Go's native plugin package (platform limitations; use gRPC/WASM instead)</li> <li>Breaking changes to existing tool* library interfaces</li> <li>Over-engineering for hypothetical future requirements</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#current-architecture-analysis","title":"Current Architecture Analysis","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#strengths-85-pluggable","title":"Strengths (85% Pluggable)","text":"<p>The existing architecture demonstrates excellent patterns:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      MCP Server (SDK)                           \u2502\n\u2502           metatools-mcp/internal/server/server.go               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Adapter Layer                                 \u2502\n\u2502  - IndexAdapter (toolindex \u2192 handlers.Index)                    \u2502\n\u2502  - DocsAdapter (tooldocs \u2192 handlers.Store)                      \u2502\n\u2502  - RunnerAdapter (toolrun \u2192 handlers.Runner)                    \u2502\n\u2502  - ExecutorAdapter (toolcode \u2192 handlers.Executor)               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Handlers Layer                                 \u2502\n\u2502  - SearchHandler, DescribeHandler, RunHandler, ChainHandler    \u2502\n\u2502  - CodeHandler (optional), ExamplesHandler, NamespacesHandler  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Core Tool Libraries                                 \u2502\n\u2502  toolindex, tooldocs, toolrun, toolcode, toolruntime, toolsearch\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>What works well: - Clean interface contracts (<code>handlers/interfaces.go</code>) - Adapter pattern prevents library leakage - Build-tag gating for optional features (<code>toolsearch</code>, <code>toolruntime</code>) - Configuration-driven bootstrap (<code>internal/config/env.go</code>) - Stateless handlers with dependency injection</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#gap-monolithic-tool-registration","title":"Gap: Monolithic Tool Registration","text":"<p>The primary gap is in <code>server.registerTools()</code> (~200 lines):</p> <pre><code>// Current: Hard-coded tool list\nfunc (s *Server) registerTools() {\n    s.addTool(\"search_tools\", ...)    // inline schema\n    s.addTool(\"describe_tool\", ...)   // inline schema\n    s.addTool(\"run_tool\", ...)        // inline schema\n    // ... 7 tools total\n}\n</code></pre> <p>This requires code changes to add new tools.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#proposed-architecture","title":"Proposed Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#five-layer-design","title":"Five-Layer Design","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    METATOOLS-MCP FRAMEWORK                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                 TRANSPORT LAYER                              \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502 \u2502\n\u2502  \u2502  \u2502  stdio  \u2502  \u2502  SSE    \u2502  \u2502  HTTP   \u2502  \u2502  gRPC   \u2502        \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518        \u2502 \u2502\n\u2502  \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502 \u2502\n\u2502  \u2502                        \u2193                                     \u2502 \u2502\n\u2502  \u2502               transport.Transport interface                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                             \u2193                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                  MIDDLEWARE CHAIN                            \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502 \u2502\n\u2502  \u2502  \u2502 Logging  \u2502\u2192\u2502  Auth    \u2502\u2192\u2502  Rate    \u2502\u2192\u2502  Cache   \u2502       \u2502 \u2502\n\u2502  \u2502  \u2502          \u2502 \u2502          \u2502 \u2502  Limit   \u2502 \u2502          \u2502       \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                             \u2193                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502               TOOL PROVIDER REGISTRY                         \u2502 \u2502\n\u2502  \u2502                                                               \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502 \u2502\n\u2502  \u2502  \u2502 search_tools \u2502 \u2502 describe_    \u2502 \u2502 run_tool     \u2502         \u2502 \u2502\n\u2502  \u2502  \u2502              \u2502 \u2502 tool         \u2502 \u2502              \u2502         \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502 \u2502\n\u2502  \u2502  \u2502 run_chain    \u2502 \u2502 execute_code \u2502 \u2502 [custom...]  \u2502         \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                             \u2193                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502              CORE SERVICES (Tool Libraries)                  \u2502 \u2502\n\u2502  \u2502                                                               \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502 \u2502\n\u2502  \u2502  \u2502   toolindex    \u2502  \u2502   tooldocs     \u2502                     \u2502 \u2502\n\u2502  \u2502  \u2502  (Registry)    \u2502  \u2502  (Disclosure)  \u2502                     \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502 \u2502\n\u2502  \u2502  \u2502   toolrun      \u2502  \u2502   toolcode     \u2502                     \u2502 \u2502\n\u2502  \u2502  \u2502  (Execution)   \u2502  \u2502 (Orchestration)\u2502                     \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                             \u2193                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502               BACKEND REGISTRY                               \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502 \u2502\n\u2502  \u2502  \u2502  local  \u2502  \u2502 openai  \u2502  \u2502  azure  \u2502  \u2502  mcp    \u2502        \u2502 \u2502\n\u2502  \u2502  \u2502handlers \u2502  \u2502   api   \u2502  \u2502   api   \u2502  \u2502 servers \u2502        \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#core-interfaces","title":"Core Interfaces","text":"<pre><code>// Transport abstraction (enables stdio/SSE/HTTP)\ntype Transport interface {\n    Serve(ctx context.Context, handler RequestHandler) error\n}\n\n// Tool provider (enables plug-and-play tools)\ntype ToolProvider interface {\n    Name() string\n    Tool() *mcp.Tool\n    Handle(ctx context.Context, input []byte) (any, error)\n}\n\n// Middleware (enables cross-cutting concerns)\ntype Middleware func(ToolProvider) ToolProvider\n\n// Backend registry (enables tool sources)\ntype BackendRegistry interface {\n    Register(kind string, backend Backend)\n    Get(kind string) (Backend, bool)\n    List() []string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#extension-points","title":"Extension Points","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#1-transport-layer","title":"1. Transport Layer","text":"<p>The transport layer abstracts how MCP clients connect to the server. This enables the same tool logic to be exposed via multiple protocols.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         TRANSPORT LAYER                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502                              MCP CLIENTS                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502   \u2502   Claude    \u2502  \u2502   Cursor    \u2502  \u2502  Web App    \u2502  \u2502   Custom    \u2502        \u2502\n\u2502   \u2502   Desktop   \u2502  \u2502    IDE      \u2502  \u2502  Frontend   \u2502  \u2502   Client    \u2502        \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502          \u2502                \u2502                \u2502                \u2502                \u2502\n\u2502          \u2502 stdio          \u2502 stdio          \u2502 HTTP/SSE       \u2502 gRPC          \u2502\n\u2502          \u2502                \u2502                \u2502                \u2502                \u2502\n\u2502          \u25bc                \u25bc                \u25bc                \u25bc                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                     TRANSPORT REGISTRY                               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502   \u2502\n\u2502   \u2502   \u2502   STDIO   \u2502  \u2502    SSE    \u2502  \u2502   HTTP    \u2502  \u2502   gRPC    \u2502        \u2502   \u2502\n\u2502   \u2502   \u2502 Transport \u2502  \u2502 Transport \u2502  \u2502 Transport \u2502  \u2502 Transport \u2502        \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518        \u2502   \u2502\n\u2502   \u2502         \u2502              \u2502              \u2502              \u2502               \u2502   \u2502\n\u2502   \u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502                              \u25bc                                        \u2502   \u2502\n\u2502   \u2502                    transport.Transport                                \u2502   \u2502\n\u2502   \u2502                       interface                                       \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                   \u2502                                          \u2502\n\u2502                                   \u25bc                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    MCP REQUEST HANDLER                               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Unified handler processes all requests regardless of transport    \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#the-transport-interface","title":"The Transport Interface","text":"<pre><code>// Transport defines how MCP clients connect to the server\ntype Transport interface {\n    // Name returns the transport identifier (e.g., \"stdio\", \"sse\")\n    Name() string\n\n    // Serve starts the transport and blocks until ctx is cancelled\n    Serve(ctx context.Context, handler RequestHandler) error\n\n    // Close gracefully shuts down the transport\n    Close() error\n\n    // Info returns runtime information about the transport\n    Info() TransportInfo\n}\n\n// RequestHandler processes incoming MCP requests\ntype RequestHandler interface {\n    HandleRequest(ctx context.Context, req *mcp.Request) (*mcp.Response, error)\n}\n\n// TransportInfo provides runtime details\ntype TransportInfo struct {\n    Name      string            // Transport name\n    Listening bool              // Is it accepting connections?\n    Address   string            // Listening address (for network transports)\n    Metadata  map[string]string // Additional info\n}\n\n// TransportFactory creates configured transport instances\ntype TransportFactory func(cfg TransportConfig) (Transport, error)\n\n// TransportRegistry manages available transports\ntype TransportRegistry struct {\n    transports map[string]TransportFactory\n}\n\nfunc (r *TransportRegistry) Register(name string, factory TransportFactory) {\n    r.transports[name] = factory\n}\n\nfunc (r *TransportRegistry) Create(cfg TransportConfig) (Transport, error) {\n    factory, ok := r.transports[cfg.Type]\n    if !ok {\n        return nil, fmt.Errorf(\"unknown transport: %s\", cfg.Type)\n    }\n    return factory(cfg)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#transport-types","title":"Transport Types","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#1-stdio-transport-current-default","title":"1. Stdio Transport (Current Default)","text":"<p>For MCP clients that spawn the server as a subprocess.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          STDIO TRANSPORT                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502      MCP Client       \u2502         \u2502    metatools-mcp      \u2502               \u2502\n\u2502   \u2502   (Claude, Cursor)    \u2502         \u2502       server          \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   Spawns process \u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Started as child    \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   stdin  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Reads JSON-RPC      \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   stdout \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502   Writes JSON-RPC     \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                               \u2502\n\u2502   Characteristics:                                                           \u2502\n\u2502   - Single client per process                                               \u2502\n\u2502   - Process lifecycle tied to client                                        \u2502\n\u2502   - No network configuration needed                                         \u2502\n\u2502   - Ideal for desktop MCP clients                                           \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Implementation:                                                             \u2502\n\u2502                                                                               \u2502\n\u2502  type StdioTransport struct {                                               \u2502\n\u2502      reader  io.Reader  // os.Stdin                                         \u2502\n\u2502      writer  io.Writer  // os.Stdout                                        \u2502\n\u2502      decoder *json.Decoder                                                  \u2502\n\u2502      encoder *json.Encoder                                                  \u2502\n\u2502  }                                                                           \u2502\n\u2502                                                                               \u2502\n\u2502  func (t *StdioTransport) Serve(ctx context.Context, h RequestHandler)      \u2502\n\u2502      error {                                                                \u2502\n\u2502      for {                                                                  \u2502\n\u2502          select {                                                           \u2502\n\u2502          case &lt;-ctx.Done():                                                 \u2502\n\u2502              return ctx.Err()                                               \u2502\n\u2502          default:                                                           \u2502\n\u2502              var req mcp.Request                                            \u2502\n\u2502              if err := t.decoder.Decode(&amp;req); err != nil {                 \u2502\n\u2502                  return err                                                 \u2502\n\u2502              }                                                              \u2502\n\u2502              resp, err := h.HandleRequest(ctx, &amp;req)                        \u2502\n\u2502              if err := t.encoder.Encode(resp); err != nil {                 \u2502\n\u2502                  return err                                                 \u2502\n\u2502              }                                                              \u2502\n\u2502          }                                                                  \u2502\n\u2502      }                                                                      \u2502\n\u2502  }                                                                           \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                                                     \u2502\n\u2502    transport:                                                               \u2502\n\u2502      type: stdio                                                            \u2502\n\u2502      # No additional config needed                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#2-sse-transport-server-sent-events","title":"2. SSE Transport (Server-Sent Events)","text":"<p>For web-based MCP clients using the Streamable HTTP protocol.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           SSE TRANSPORT                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502     Web Browser       \u2502         \u2502    metatools-mcp      \u2502               \u2502\n\u2502   \u2502    or HTTP Client     \u2502         \u2502       server          \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   POST /mcp \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Handle request      \u2502               \u2502\n\u2502   \u2502   (JSON-RPC request)  \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   SSE stream \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502   Stream response     \u2502               \u2502\n\u2502   \u2502   (chunked events)    \u2502         \u2502   via SSE             \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                               \u2502\n\u2502   HTTP Endpoints:                                                            \u2502\n\u2502   - POST /mcp           \u2192 Submit MCP request, receive SSE stream            \u2502\n\u2502   - GET  /mcp/sse       \u2192 Establish SSE connection for server push          \u2502\n\u2502   - GET  /health        \u2192 Health check endpoint                              \u2502\n\u2502   - GET  /ready         \u2192 Readiness probe                                   \u2502\n\u2502                                                                               \u2502\n\u2502   Characteristics:                                                           \u2502\n\u2502   - Multiple concurrent clients                                             \u2502\n\u2502   - Stateless (each request independent)                                    \u2502\n\u2502   - Web-friendly (works through firewalls/proxies)                          \u2502\n\u2502   - Supports streaming responses                                            \u2502\n\u2502   - Can be load balanced                                                    \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Request/Response Flow:                                                      \u2502\n\u2502                                                                               \u2502\n\u2502  Client                              Server                                  \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502    \u2502  POST /mcp                        \u2502                                     \u2502\n\u2502    \u2502  Content-Type: application/json   \u2502                                     \u2502\n\u2502    \u2502  Accept: text/event-stream        \u2502                                     \u2502\n\u2502    \u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   \u2502                                     \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502    \u2502  HTTP/1.1 200 OK                  \u2502                                     \u2502\n\u2502    \u2502  Content-Type: text/event-stream  \u2502                                     \u2502\n\u2502    \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502                                     \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502    \u2502  event: message                   \u2502                                     \u2502\n\u2502    \u2502  data: {\"jsonrpc\":\"2.0\",...}      \u2502                                     \u2502\n\u2502    \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502                                     \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502    \u2502  event: message                   \u2502                                     \u2502\n\u2502    \u2502  data: {\"jsonrpc\":\"2.0\",...}      \u2502  (streaming)                       \u2502\n\u2502    \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502                                     \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502    \u2502  event: done                      \u2502                                     \u2502\n\u2502    \u2502  data: {}                         \u2502                                     \u2502\n\u2502    \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502                                     \u2502\n\u2502    \u2502                                   \u2502                                     \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                                                     \u2502\n\u2502    transport:                                                               \u2502\n\u2502      type: sse                                                              \u2502\n\u2502      http:                                                                  \u2502\n\u2502        host: \"0.0.0.0\"                                                     \u2502\n\u2502        port: 8080                                                          \u2502\n\u2502        base_path: /mcp                                                     \u2502\n\u2502        cors:                                                               \u2502\n\u2502          enabled: true                                                     \u2502\n\u2502          origins: [\"https://app.example.com\"]                             \u2502\n\u2502        tls:                                                                \u2502\n\u2502          enabled: true                                                     \u2502\n\u2502          cert: /etc/ssl/cert.pem                                          \u2502\n\u2502          key: /etc/ssl/key.pem                                            \u2502\n\u2502        timeouts:                                                           \u2502\n\u2502          read: 30s                                                         \u2502\n\u2502          write: 60s                                                        \u2502\n\u2502          idle: 120s                                                        \u2502\n\u2502        keepalive: 30s                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#3-http-transport-rest-style","title":"3. HTTP Transport (REST-style)","text":"<p>For simple request/response without streaming.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          HTTP TRANSPORT                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Endpoints:                                                                 \u2502\n\u2502                                                                               \u2502\n\u2502   POST /mcp/tools/list                                                       \u2502\n\u2502   \u251c\u2500 Request:  {}                                                            \u2502\n\u2502   \u2514\u2500 Response: { \"tools\": [...] }                                           \u2502\n\u2502                                                                               \u2502\n\u2502   POST /mcp/tools/call                                                       \u2502\n\u2502   \u251c\u2500 Request:  { \"name\": \"search_tools\", \"arguments\": {...} }               \u2502\n\u2502   \u2514\u2500 Response: { \"content\": [...] }                                         \u2502\n\u2502                                                                               \u2502\n\u2502   GET /mcp/tools/:name                                                       \u2502\n\u2502   \u2514\u2500 Response: { \"name\": \"...\", \"description\": \"...\", \"inputSchema\": {...}} \u2502\n\u2502                                                                               \u2502\n\u2502   Characteristics:                                                           \u2502\n\u2502   - Simple request/response                                                  \u2502\n\u2502   - No streaming support                                                    \u2502\n\u2502   - Easy to debug with curl                                                 \u2502\n\u2502   - Good for simple integrations                                            \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                                                     \u2502\n\u2502    transport:                                                               \u2502\n\u2502      type: http                                                             \u2502\n\u2502      http:                                                                  \u2502\n\u2502        host: \"0.0.0.0\"                                                     \u2502\n\u2502        port: 8080                                                          \u2502\n\u2502        base_path: /mcp                                                     \u2502\n\u2502        # Same TLS/timeout options as SSE                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#4-websocket-transport","title":"4. WebSocket Transport","text":"<p>For bidirectional real-time communication.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        WEBSOCKET TRANSPORT                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502       Client          \u2502         \u2502    metatools-mcp      \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502       server          \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   WS Connect \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Accept connection   \u2502               \u2502\n\u2502   \u2502   ws://host/mcp/ws    \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2502   \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   \u2502               \u2502\n\u2502   \u2502      Bidirectional    \u2502         \u2502   Full duplex         \u2502               \u2502\n\u2502   \u2502      JSON-RPC         \u2502         \u2502   messaging           \u2502               \u2502\n\u2502   \u2502                       \u2502         \u2502                       \u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                               \u2502\n\u2502   Characteristics:                                                           \u2502\n\u2502   - Full duplex communication                                               \u2502\n\u2502   - Server can push notifications                                           \u2502\n\u2502   - Lower latency than HTTP                                                 \u2502\n\u2502   - Persistent connection                                                   \u2502\n\u2502   - Good for real-time applications                                         \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                                                     \u2502\n\u2502    transport:                                                               \u2502\n\u2502      type: websocket                                                        \u2502\n\u2502      websocket:                                                             \u2502\n\u2502        host: \"0.0.0.0\"                                                     \u2502\n\u2502        port: 8080                                                          \u2502\n\u2502        path: /mcp/ws                                                       \u2502\n\u2502        ping_interval: 30s                                                  \u2502\n\u2502        pong_timeout: 10s                                                   \u2502\n\u2502        max_message_size: 1MB                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#5-grpc-transport","title":"5. gRPC Transport","text":"<p>For high-performance, strongly-typed RPC.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          gRPC TRANSPORT                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Protocol Buffer Definition:                                                \u2502\n\u2502                                                                               \u2502\n\u2502   service MCPService {                                                       \u2502\n\u2502     rpc ListTools(ListToolsRequest) returns (ListToolsResponse);            \u2502\n\u2502     rpc CallTool(CallToolRequest) returns (CallToolResponse);               \u2502\n\u2502     rpc CallToolStream(CallToolRequest) returns (stream ToolEvent);         \u2502\n\u2502   }                                                                          \u2502\n\u2502                                                                               \u2502\n\u2502   Characteristics:                                                           \u2502\n\u2502   - High performance (binary protocol)                                       \u2502\n\u2502   - Strong typing via protobuf                                              \u2502\n\u2502   - Bidirectional streaming                                                 \u2502\n\u2502   - Built-in load balancing                                                 \u2502\n\u2502   - Good for service-to-service communication                               \u2502\n\u2502                                                                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                                                     \u2502\n\u2502    transport:                                                               \u2502\n\u2502      type: grpc                                                             \u2502\n\u2502      grpc:                                                                  \u2502\n\u2502        host: \"0.0.0.0\"                                                     \u2502\n\u2502        port: 9090                                                          \u2502\n\u2502        tls:                                                                \u2502\n\u2502          enabled: true                                                     \u2502\n\u2502          cert: /etc/ssl/cert.pem                                          \u2502\n\u2502          key: /etc/ssl/key.pem                                            \u2502\n\u2502          client_ca: /etc/ssl/ca.pem  # For mTLS                           \u2502\n\u2502        reflection: true  # Enable gRPC reflection                          \u2502\n\u2502        max_recv_msg_size: 4MB                                              \u2502\n\u2502        max_send_msg_size: 4MB                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#multi-transport-support","title":"Multi-Transport Support","text":"<p>Run multiple transports simultaneously:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      MULTI-TRANSPORT ARCHITECTURE                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    METATOOLS-MCP SERVER                              \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502   \u2502\n\u2502   \u2502   \u2502   STDIO     \u2502 \u2502    SSE      \u2502 \u2502    gRPC     \u2502                   \u2502   \u2502\n\u2502   \u2502   \u2502  Transport  \u2502 \u2502  Transport  \u2502 \u2502  Transport  \u2502                   \u2502   \u2502\n\u2502   \u2502   \u2502             \u2502 \u2502  :8080      \u2502 \u2502  :9090      \u2502                   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502   \u2502\n\u2502   \u2502          \u2502               \u2502               \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502   \u2502\n\u2502   \u2502                          \u2502                                            \u2502   \u2502\n\u2502   \u2502                          \u25bc                                            \u2502   \u2502\n\u2502   \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502   \u2502\n\u2502   \u2502          \u2502     SHARED REQUEST HANDLER    \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2502                               \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2502   All transports share the    \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2502   same middleware, tools,     \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2502   and backend registries      \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2502                               \u2502                           \u2502   \u2502\n\u2502   \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2502   Config:                                                                    \u2502\n\u2502     transports:                                                             \u2502\n\u2502       - type: stdio                                                         \u2502\n\u2502         enabled: true                                                       \u2502\n\u2502                                                                               \u2502\n\u2502       - type: sse                                                           \u2502\n\u2502         enabled: true                                                       \u2502\n\u2502         http:                                                               \u2502\n\u2502           port: 8080                                                        \u2502\n\u2502                                                                               \u2502\n\u2502       - type: grpc                                                          \u2502\n\u2502         enabled: true                                                       \u2502\n\u2502         grpc:                                                               \u2502\n\u2502           port: 9090                                                        \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementing-custom-transports","title":"Implementing Custom Transports","text":"<pre><code>// Example: Unix socket transport for local high-performance IPC\ntype UnixSocketTransport struct {\n    path     string\n    listener net.Listener\n    handler  RequestHandler\n}\n\nfunc NewUnixSocketTransport(cfg TransportConfig) (Transport, error) {\n    return &amp;UnixSocketTransport{\n        path: cfg.UnixSocket.Path,\n    }, nil\n}\n\nfunc (t *UnixSocketTransport) Name() string {\n    return \"unix\"\n}\n\nfunc (t *UnixSocketTransport) Serve(ctx context.Context, h RequestHandler) error {\n    t.handler = h\n\n    var err error\n    t.listener, err = net.Listen(\"unix\", t.path)\n    if err != nil {\n        return err\n    }\n\n    go func() {\n        &lt;-ctx.Done()\n        t.listener.Close()\n    }()\n\n    for {\n        conn, err := t.listener.Accept()\n        if err != nil {\n            if ctx.Err() != nil {\n                return nil // Graceful shutdown\n            }\n            return err\n        }\n        go t.handleConnection(ctx, conn)\n    }\n}\n\nfunc (t *UnixSocketTransport) handleConnection(ctx context.Context, conn net.Conn) {\n    defer conn.Close()\n    decoder := json.NewDecoder(conn)\n    encoder := json.NewEncoder(conn)\n\n    for {\n        var req mcp.Request\n        if err := decoder.Decode(&amp;req); err != nil {\n            return\n        }\n        resp, _ := t.handler.HandleRequest(ctx, &amp;req)\n        if err := encoder.Encode(resp); err != nil {\n            return\n        }\n    }\n}\n\nfunc (t *UnixSocketTransport) Close() error {\n    if t.listener != nil {\n        return t.listener.Close()\n    }\n    return nil\n}\n\nfunc (t *UnixSocketTransport) Info() TransportInfo {\n    return TransportInfo{\n        Name:      \"unix\",\n        Listening: t.listener != nil,\n        Address:   t.path,\n    }\n}\n\n// Register the custom transport\nfunc init() {\n    transport.Register(\"unix\", NewUnixSocketTransport)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#high-availability-configuration","title":"High Availability Configuration","text":"<p>For production deployments with HTTP/SSE transport:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    HIGH AVAILABILITY DEPLOYMENT                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                       LOAD BALANCER                                  \u2502   \u2502\n\u2502   \u2502                    (nginx, HAProxy, ALB)                             \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   - TLS termination                                                  \u2502   \u2502\n\u2502   \u2502   - Health checks                                                    \u2502   \u2502\n\u2502   \u2502   - Round-robin / least-connections                                 \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                    \u2502                \u2502                \u2502                       \u2502\n\u2502                    \u25bc                \u25bc                \u25bc                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502   \u2502   metatools-mcp    \u2502 \u2502   metatools-mcp    \u2502 \u2502   metatools-mcp    \u2502     \u2502\n\u2502   \u2502    instance 1      \u2502 \u2502    instance 2      \u2502 \u2502    instance 3      \u2502     \u2502\n\u2502   \u2502                    \u2502 \u2502                    \u2502 \u2502                    \u2502     \u2502\n\u2502   \u2502  SSE :8080         \u2502 \u2502  SSE :8080         \u2502 \u2502  SSE :8080         \u2502     \u2502\n\u2502   \u2502  gRPC :9090        \u2502 \u2502  gRPC :9090        \u2502 \u2502  gRPC :9090        \u2502     \u2502\n\u2502   \u2502                    \u2502 \u2502                    \u2502 \u2502                    \u2502     \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502             \u2502                      \u2502                      \u2502                 \u2502\n\u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                                    \u2502                                         \u2502\n\u2502                                    \u25bc                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      SHARED STATE (Optional)                         \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   - Redis for rate limiting                                          \u2502   \u2502\n\u2502   \u2502   - Redis for caching                                                \u2502   \u2502\n\u2502   \u2502   - Shared tool registry (if dynamic)                               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code># Kubernetes-ready configuration\ntransport:\n  type: sse\n  http:\n    host: \"0.0.0.0\"\n    port: 8080\n\n    # Health endpoints for k8s probes\n    health:\n      enabled: true\n      liveness_path: /healthz\n      readiness_path: /ready\n\n    # Graceful shutdown\n    shutdown:\n      timeout: 30s\n      drain_connections: true\n\n    # TLS (or terminate at ingress)\n    tls:\n      enabled: false  # Terminated at ingress\n\nmiddleware:\n  rate_limit:\n    enabled: true\n    storage: redis\n    redis:\n      address: redis:6379\n\n  cache:\n    enabled: true\n    backend: redis\n    redis:\n      address: redis:6379\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cli-integration","title":"CLI Integration","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          CLI SUBCOMMANDS                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502  metatools stdio                                                             \u2502\n\u2502  \u2514\u2500 Run as stdio server (default, for MCP clients)                          \u2502\n\u2502                                                                               \u2502\n\u2502  metatools serve                                                             \u2502\n\u2502  \u2514\u2500 Run as HTTP/SSE server                                                  \u2502\n\u2502  \u2514\u2500 Options:                                                                \u2502\n\u2502       --port 8080          HTTP port                                        \u2502\n\u2502       --grpc-port 9090     gRPC port (optional)                            \u2502\n\u2502       --tls                Enable TLS                                       \u2502\n\u2502       --cert FILE          TLS certificate                                  \u2502\n\u2502       --key FILE           TLS key                                          \u2502\n\u2502                                                                               \u2502\n\u2502  metatools serve --multi                                                     \u2502\n\u2502  \u2514\u2500 Run all enabled transports from config                                  \u2502\n\u2502                                                                               \u2502\n\u2502  metatools version                                                           \u2502\n\u2502  \u2514\u2500 Print version and exit                                                  \u2502\n\u2502                                                                               \u2502\n\u2502  metatools validate                                                          \u2502\n\u2502  \u2514\u2500 Validate configuration file                                             \u2502\n\u2502                                                                               \u2502\n\u2502  metatools tools list                                                        \u2502\n\u2502  \u2514\u2500 List all registered tools (from all backends)                          \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#transport-configuration-summary","title":"Transport Configuration Summary","text":"<pre><code># Complete transport configuration example\ntransports:\n  # Stdio for MCP desktop clients\n  - type: stdio\n    enabled: true\n\n  # SSE for web clients\n  - type: sse\n    enabled: true\n    http:\n      host: \"0.0.0.0\"\n      port: 8080\n      base_path: /mcp\n      cors:\n        enabled: true\n        origins: [\"*\"]\n        methods: [\"GET\", \"POST\", \"OPTIONS\"]\n        headers: [\"Content-Type\", \"Authorization\"]\n      tls:\n        enabled: true\n        cert: /etc/ssl/certs/server.crt\n        key: /etc/ssl/private/server.key\n      timeouts:\n        read: 30s\n        write: 60s\n        idle: 120s\n      health:\n        enabled: true\n        liveness_path: /healthz\n        readiness_path: /ready\n\n  # WebSocket for real-time apps\n  - type: websocket\n    enabled: false\n    websocket:\n      host: \"0.0.0.0\"\n      port: 8081\n      path: /ws\n\n  # gRPC for service-to-service\n  - type: grpc\n    enabled: false\n    grpc:\n      host: \"0.0.0.0\"\n      port: 9090\n      reflection: true\n\n  # Unix socket for local IPC\n  - type: unix\n    enabled: false\n    unix:\n      path: /var/run/metatools.sock\n      permissions: \"0660\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#2-search-strategy","title":"2. Search Strategy","text":"<p>Already implemented via build tags + interface:</p> <pre><code>// toolindex.Searcher interface\ntype Searcher interface {\n    Search(query string, limit int) ([]Summary, error)\n}\n\n// Implementations:\n// - Default lexical (built into toolindex)\n// - BM25 (toolsearch package, requires build tag)\n// - Semantic/vector (future, could use embeddings)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#3-tool-provider-registry","title":"3. Tool Provider Registry","text":"<p>New pattern to enable plug-and-play tools:</p> <pre><code>// ToolProvider interface\ntype ToolProvider interface {\n    Name() string\n    Tool() *mcp.Tool  // MCP tool definition with schema\n    Handle(ctx context.Context, input []byte) (any, error)\n}\n\n// Registry\ntype ToolRegistry struct {\n    providers map[string]ToolProvider\n}\n\nfunc (r *ToolRegistry) Register(p ToolProvider) {\n    r.providers[p.Name()] = p\n}\n\nfunc (r *ToolRegistry) All() []ToolProvider {\n    // Returns all registered providers\n}\n</code></pre> <p>Migration path: Convert existing handlers to ToolProvider implementations.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#4-backend-registry","title":"4. Backend Registry","text":"<p>For tool execution sources (local, API, MCP servers):</p> <pre><code>// Backend interface (already in toolmodel conceptually)\ntype Backend interface {\n    Kind() string\n    Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n}\n\n// Registry with configuration\ntype BackendRegistry struct {\n    backends map[string]Backend\n}\n\nfunc (r *BackendRegistry) RegisterFromConfig(cfg BackendConfig) error {\n    switch cfg.Kind {\n    case \"local\":\n        r.backends[\"local\"] = NewLocalBackend(cfg.Local)\n    case \"openai\":\n        r.backends[\"openai\"] = NewOpenAIBackend(cfg.OpenAI)\n    // ...\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#5-middleware-chain","title":"5. Middleware Chain","text":"<p>The middleware layer provides pluggable cross-cutting concerns using the decorator pattern.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-overview_1","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         MIDDLEWARE CHAIN                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   Incoming Request                                                           \u2502\n\u2502         \u2502                                                                     \u2502\n\u2502         \u25bc                                                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502   \u2502  Logging  \u2502 \u2192 \u2502   Auth    \u2502 \u2192 \u2502   Rate    \u2502 \u2192 \u2502  Caching  \u2502            \u2502\n\u2502   \u2502           \u2502   \u2502           \u2502   \u2502  Limiter  \u2502   \u2502           \u2502            \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502         \u2502               \u2502               \u2502               \u2502                    \u2502\n\u2502         \u2502   on error:   \u2502   on error:   \u2502   on error:   \u2502                    \u2502\n\u2502         \u2502   log &amp; pass  \u2502   reject 401  \u2502   reject 429  \u2502                    \u2502\n\u2502         \u2502               \u2502               \u2502               \u2502                    \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                                         \u2502                                     \u2502\n\u2502                                         \u25bc                                     \u2502\n\u2502                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2502\n\u2502                               \u2502  Tool Handler \u2502                              \u2502\n\u2502                               \u2502   (actual)    \u2502                              \u2502\n\u2502                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502\n\u2502                                         \u2502                                     \u2502\n\u2502                                         \u25bc                                     \u2502\n\u2502   Response flows back through chain (for metrics, logging, caching)         \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#the-middleware-interface","title":"The Middleware Interface","text":"<pre><code>// Middleware wraps a ToolProvider with additional behavior\ntype Middleware func(ToolProvider) ToolProvider\n\n// MiddlewareFunc is a convenience type for stateless middleware\ntype MiddlewareFunc func(ctx context.Context, input []byte, next NextFunc) (any, error)\n\ntype NextFunc func(ctx context.Context, input []byte) (any, error)\n\n// MiddlewareRegistry manages available middleware\ntype MiddlewareRegistry struct {\n    available map[string]MiddlewareFactory\n    active    []Middleware\n}\n\n// MiddlewareFactory creates configured middleware instances\ntype MiddlewareFactory func(cfg MiddlewareConfig) (Middleware, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#built-in-middleware","title":"Built-in Middleware","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        AVAILABLE MIDDLEWARE                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 LOGGING                                                                  \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Request/response logging                                              \u2502 \u2502\n\u2502  \u2502 - Configurable log levels (debug, info, warn, error)                   \u2502 \u2502\n\u2502  \u2502 - Structured JSON output                                                \u2502 \u2502\n\u2502  \u2502 - Request ID tracking                                                   \u2502 \u2502\n\u2502  \u2502 - Duration metrics                                                      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 AUTHENTICATION                                                           \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Bearer token validation                                               \u2502 \u2502\n\u2502  \u2502 - API key authentication                                                \u2502 \u2502\n\u2502  \u2502 - OAuth2/OIDC integration                                               \u2502 \u2502\n\u2502  \u2502 - mTLS client certificates                                              \u2502 \u2502\n\u2502  \u2502 - Configurable bypass for specific tools                               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 RATE LIMITING                                                            \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Per-client rate limits                                                \u2502 \u2502\n\u2502  \u2502 - Per-tool rate limits                                                  \u2502 \u2502\n\u2502  \u2502 - Token bucket algorithm                                                \u2502 \u2502\n\u2502  \u2502 - Sliding window counters                                               \u2502 \u2502\n\u2502  \u2502 - Redis-backed for distributed deployments                             \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 CACHING                                                                  \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Response caching for idempotent tools                                \u2502 \u2502\n\u2502  \u2502 - Configurable TTL per tool                                            \u2502 \u2502\n\u2502  \u2502 - Cache key customization                                               \u2502 \u2502\n\u2502  \u2502 - In-memory or Redis backend                                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 METRICS                                                                  \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Prometheus-compatible metrics                                         \u2502 \u2502\n\u2502  \u2502 - Request counts, latencies, error rates                               \u2502 \u2502\n\u2502  \u2502 - Per-tool and per-backend breakdowns                                  \u2502 \u2502\n\u2502  \u2502 - Custom metric labels                                                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 TRACING                                                                  \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - OpenTelemetry integration                                             \u2502 \u2502\n\u2502  \u2502 - Distributed trace propagation                                         \u2502 \u2502\n\u2502  \u2502 - Span creation for each tool call                                     \u2502 \u2502\n\u2502  \u2502 - Backend call tracing                                                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 VALIDATION                                                               \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - JSON Schema validation on inputs                                      \u2502 \u2502\n\u2502  \u2502 - Output validation                                                     \u2502 \u2502\n\u2502  \u2502 - Custom validators per tool                                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementing-custom-middleware","title":"Implementing Custom Middleware","text":"<pre><code>// Example: Custom audit logging middleware\ntype AuditMiddleware struct {\n    logger AuditLogger\n    next   ToolProvider\n}\n\nfunc NewAuditMiddleware(logger AuditLogger) Middleware {\n    return func(next ToolProvider) ToolProvider {\n        return &amp;AuditMiddleware{\n            logger: logger,\n            next:   next,\n        }\n    }\n}\n\nfunc (m *AuditMiddleware) Name() string { return m.next.Name() }\nfunc (m *AuditMiddleware) Tool() *mcp.Tool { return m.next.Tool() }\n\nfunc (m *AuditMiddleware) Handle(ctx context.Context, input []byte) (any, error) {\n    // Pre-execution: Log the request\n    requestID := uuid.New().String()\n    user := auth.UserFromContext(ctx)\n\n    m.logger.LogRequest(AuditEntry{\n        RequestID: requestID,\n        User:      user,\n        Tool:      m.next.Name(),\n        Input:     input,\n        Timestamp: time.Now(),\n    })\n\n    // Execute the actual tool\n    result, err := m.next.Handle(ctx, input)\n\n    // Post-execution: Log the result\n    m.logger.LogResponse(AuditEntry{\n        RequestID: requestID,\n        User:      user,\n        Tool:      m.next.Name(),\n        Success:   err == nil,\n        Duration:  time.Since(start),\n        Timestamp: time.Now(),\n    })\n\n    return result, err\n}\n\n// Register custom middleware\nfunc init() {\n    middleware.Register(\"audit\", func(cfg MiddlewareConfig) (Middleware, error) {\n        logger := newAuditLogger(cfg)\n        return NewAuditMiddleware(logger), nil\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-driven-middleware","title":"Configuration-Driven Middleware","text":"<pre><code># metatools.yaml\nmiddleware:\n  # Order matters - first in config = first in chain\n  chain:\n    - logging\n    - auth\n    - rate_limit\n    - metrics\n    - audit  # Custom middleware\n\n  # Per-middleware configuration\n  logging:\n    enabled: true\n    level: info\n    format: json\n    include_request_body: false\n    include_response_body: false\n\n  auth:\n    enabled: true\n    type: bearer\n    token_validation:\n      issuer: https://auth.example.com\n      audience: metatools-api\n    bypass_tools:\n      - search_tools  # Allow anonymous search\n      - list_namespaces\n\n  rate_limit:\n    enabled: true\n    default:\n      requests_per_minute: 100\n      burst: 20\n    per_tool:\n      execute_code:\n        requests_per_minute: 10\n        burst: 2\n    storage: memory  # or redis\n\n  metrics:\n    enabled: true\n    endpoint: /metrics\n    labels:\n      environment: production\n      service: metatools\n\n  cache:\n    enabled: true\n    backend: memory  # or redis\n    default_ttl: 5m\n    per_tool:\n      describe_tool:\n        ttl: 1h\n      search_tools:\n        ttl: 30s\n\n  audit:\n    enabled: true\n    destination: file\n    path: /var/log/metatools/audit.log\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#middleware-chain-construction","title":"Middleware Chain Construction","text":"<pre><code>// Chain construction from config\nfunc BuildMiddlewareChain(cfg MiddlewareConfig) ([]Middleware, error) {\n    var chain []Middleware\n\n    for _, name := range cfg.Chain {\n        mwCfg, ok := cfg.Middlewares[name]\n        if !ok || !mwCfg.Enabled {\n            continue\n        }\n\n        // Look up factory in registry\n        factory, ok := middleware.Get(name)\n        if !ok {\n            return nil, fmt.Errorf(\"unknown middleware: %s\", name)\n        }\n\n        // Create middleware instance\n        mw, err := factory(mwCfg)\n        if err != nil {\n            return nil, fmt.Errorf(\"middleware %s: %w\", name, err)\n        }\n\n        chain = append(chain, mw)\n    }\n\n    return chain, nil\n}\n\n// Apply chain to all providers\nfunc ApplyToRegistry(registry *ToolRegistry, chain []Middleware) {\n    for name, provider := range registry.providers {\n        wrapped := provider\n        for i := len(chain) - 1; i &gt;= 0; i-- {\n            wrapped = chain[i](wrapped)\n        }\n        registry.providers[name] = wrapped\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#request-flow-through-middleware","title":"Request Flow Through Middleware","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    REQUEST FLOW EXAMPLE                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   Client Request: run_tool(\"github/create_issue\", {...})                    \u2502\n\u2502                                                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 1. LOGGING MIDDLEWARE                                                 \u2502  \u2502\n\u2502   \u2502    - Generate request ID: \"req-abc123\"                               \u2502  \u2502\n\u2502   \u2502    - Log: \"Incoming request for github/create_issue\"                 \u2502  \u2502\n\u2502   \u2502    - Start timer                                                      \u2502  \u2502\n\u2502   \u2502    \u2192 Pass to next                                                     \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                               \u2502\n\u2502                              \u25bc                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 2. AUTH MIDDLEWARE                                                    \u2502  \u2502\n\u2502   \u2502    - Extract token from Authorization header                         \u2502  \u2502\n\u2502   \u2502    - Validate JWT signature                                          \u2502  \u2502\n\u2502   \u2502    - Check claims (issuer, audience, expiry)                        \u2502  \u2502\n\u2502   \u2502    - Inject user into context                                        \u2502  \u2502\n\u2502   \u2502    \u2192 Pass to next (or reject with 401)                               \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                               \u2502\n\u2502                              \u25bc                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 3. RATE LIMIT MIDDLEWARE                                              \u2502  \u2502\n\u2502   \u2502    - Identify client (by user, IP, or API key)                       \u2502  \u2502\n\u2502   \u2502    - Check token bucket for \"github/create_issue\"                    \u2502  \u2502\n\u2502   \u2502    - Consume token                                                    \u2502  \u2502\n\u2502   \u2502    \u2192 Pass to next (or reject with 429)                               \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                               \u2502\n\u2502                              \u25bc                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 4. METRICS MIDDLEWARE                                                 \u2502  \u2502\n\u2502   \u2502    - Increment request counter                                        \u2502  \u2502\n\u2502   \u2502    - Start latency timer                                              \u2502  \u2502\n\u2502   \u2502    \u2192 Pass to next                                                     \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                               \u2502\n\u2502                              \u25bc                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 5. ACTUAL TOOL HANDLER                                                \u2502  \u2502\n\u2502   \u2502    - Route to GitHub backend                                         \u2502  \u2502\n\u2502   \u2502    - Execute create_issue                                            \u2502  \u2502\n\u2502   \u2502    - Return result                                                    \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                              \u2502                                               \u2502\n\u2502                              \u25bc                                               \u2502\n\u2502   Response bubbles back through chain:                                      \u2502\n\u2502   - Metrics: Record latency, success/failure                                \u2502\n\u2502   - Rate limit: (no action on response)                                     \u2502\n\u2502   - Auth: (no action on response)                                           \u2502\n\u2502   - Logging: Log response, duration, status                                 \u2502\n\u2502                                                                              \u2502\n\u2502   Final Response \u2192 Client                                                   \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#registering-custom-middleware","title":"Registering Custom Middleware","text":"<pre><code>// Register at init time (compile-time pluggability)\nfunc init() {\n    middleware.Register(\"my-custom\", NewMyCustomMiddleware)\n}\n\n// Or register at runtime (config-driven)\nfunc setupMiddleware(registry *MiddlewareRegistry) {\n    // Built-in middleware (always available)\n    registry.Register(\"logging\", NewLoggingMiddleware)\n    registry.Register(\"auth\", NewAuthMiddleware)\n    registry.Register(\"rate_limit\", NewRateLimitMiddleware)\n    registry.Register(\"metrics\", NewMetricsMiddleware)\n    registry.Register(\"cache\", NewCacheMiddleware)\n\n    // Custom middleware (loaded from config or plugins)\n    registry.Register(\"audit\", NewAuditMiddleware)\n    registry.Register(\"pii-filter\", NewPIIFilterMiddleware)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#middleware-composition-patterns","title":"Middleware Composition Patterns","text":"<pre><code>// Conditional middleware (only apply to certain tools)\nfunc OnlyForTools(tools []string, mw Middleware) Middleware {\n    return func(next ToolProvider) ToolProvider {\n        if slices.Contains(tools, next.Name()) {\n            return mw(next)\n        }\n        return next\n    }\n}\n\n// Except middleware (skip for certain tools)\nfunc ExceptForTools(tools []string, mw Middleware) Middleware {\n    return func(next ToolProvider) ToolProvider {\n        if slices.Contains(tools, next.Name()) {\n            return next\n        }\n        return mw(next)\n    }\n}\n\n// Usage\nchain := []Middleware{\n    LoggingMiddleware,\n    ExceptForTools([]string{\"search_tools\"}, AuthMiddleware),\n    OnlyForTools([]string{\"execute_code\"}, StrictRateLimitMiddleware),\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#6-cache-layer","title":"6. Cache Layer","text":"<p>The cache layer provides pluggable caching across multiple components with support for different backends and layered caching strategies.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-overview_2","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           CACHE LAYER                                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                      CACHE CONSUMERS                                     \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\u2502\n\u2502   \u2502  \u2502toolindex \u2502  \u2502tooldocs  \u2502  \u2502toolsearch\u2502  \u2502tooladapter\u2502  \u2502 toolrun  \u2502 \u2502\u2502\n\u2502   \u2502  \u2502 (lookup) \u2502  \u2502 (docs)   \u2502  \u2502 (search) \u2502  \u2502 (convert) \u2502  \u2502 (result) \u2502 \u2502\u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\u2502\n\u2502   \u2502       \u2502             \u2502             \u2502             \u2502             \u2502        \u2502\u2502\n\u2502   \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\u2502\n\u2502   \u2502                            \u2502                                            \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                \u2502                                              \u2502\n\u2502                                \u25bc                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                      toolcache.Cache INTERFACE                           \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2502   Get(ctx, key) \u2192 (value, bool, error)                                  \u2502\u2502\n\u2502   \u2502   Set(ctx, key, value, ttl) \u2192 error                                     \u2502\u2502\n\u2502   \u2502   Delete(ctx, key) \u2192 error                                               \u2502\u2502\n\u2502   \u2502   Clear(ctx, pattern) \u2192 error                                            \u2502\u2502\n\u2502   \u2502   Stats() \u2192 CacheStats                                                   \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                \u2502                                              \u2502\n\u2502                                \u25bc                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                      LAYERED CACHE (L1 + L2)                             \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\u2502\n\u2502   \u2502   \u2502 L1: In-Memory (hot data, microsecond access)                    \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - LRU eviction                                               \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - Size-bounded                                               \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - Process-local                                              \u2502   \u2502\u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\u2502\n\u2502   \u2502                            \u2502 miss                                        \u2502\u2502\n\u2502   \u2502                            \u25bc                                             \u2502\u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\u2502\n\u2502   \u2502   \u2502 L2: Distributed (warm data, millisecond access)                 \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - Redis, Memcached, DynamoDB                                \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - Shared across instances                                    \u2502   \u2502\u2502\n\u2502   \u2502   \u2502     - TTL-based expiration                                       \u2502   \u2502\u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                      CACHE BACKENDS                                      \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\u2502\n\u2502   \u2502   \u2502In-Memory\u2502  \u2502  Redis  \u2502  \u2502Memcached\u2502  \u2502 SQLite  \u2502  \u2502 Custom  \u2502      \u2502\u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\u2502\n\u2502   \u2502                                                                          \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cache-interface","title":"Cache Interface","text":"<pre><code>// toolcache/cache.go\n\n// Cache defines the pluggable cache interface\ntype Cache interface {\n    // Get retrieves a value, returns (value, found, error)\n    Get(ctx context.Context, key string) ([]byte, bool, error)\n\n    // Set stores a value with TTL (0 = no expiration)\n    Set(ctx context.Context, key string, value []byte, ttl time.Duration) error\n\n    // Delete removes a key\n    Delete(ctx context.Context, key string) error\n\n    // Clear removes keys matching pattern (e.g., \"toolindex:*\")\n    Clear(ctx context.Context, pattern string) error\n\n    // Stats returns cache statistics\n    Stats() CacheStats\n\n    // Close releases resources\n    Close() error\n}\n\n// CacheStats provides observability\ntype CacheStats struct {\n    Hits       int64\n    Misses     int64\n    Size       int64\n    Evictions  int64\n    HitRate    float64\n}\n\n// TypedCache provides type-safe caching with serialization\ntype TypedCache[T any] interface {\n    Get(ctx context.Context, key string) (T, bool, error)\n    Set(ctx context.Context, key string, value T, ttl time.Duration) error\n    GetOrCompute(ctx context.Context, key string, compute func() (T, error), ttl time.Duration) (T, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cache-backends","title":"Cache Backends","text":"<pre><code>// toolcache/memory.go - In-memory LRU cache\ntype MemoryCache struct {\n    maxSize    int64\n    lru        *lru.Cache[string, []byte]\n    stats      CacheStats\n    mu         sync.RWMutex\n}\n\nfunc NewMemoryCache(opts MemoryCacheOptions) *MemoryCache {\n    return &amp;MemoryCache{\n        maxSize: opts.MaxSize,\n        lru:     lru.New[string, []byte](opts.MaxItems),\n    }\n}\n\n// toolcache/redis.go - Redis-backed cache\ntype RedisCache struct {\n    client  *redis.Client\n    prefix  string\n    stats   CacheStats\n}\n\nfunc NewRedisCache(opts RedisCacheOptions) (*RedisCache, error) {\n    client := redis.NewClient(&amp;redis.Options{\n        Addr:     opts.Addr,\n        Password: opts.Password,\n        DB:       opts.DB,\n    })\n    return &amp;RedisCache{\n        client: client,\n        prefix: opts.Prefix,\n    }, nil\n}\n\n// toolcache/sqlite.go - SQLite-backed persistent cache\ntype SQLiteCache struct {\n    db     *sql.DB\n    stats  CacheStats\n}\n\n// toolcache/layered.go - L1 + L2 layered cache\ntype LayeredCache struct {\n    l1      Cache  // Fast, local (memory)\n    l2      Cache  // Slower, shared (Redis)\n    l1TTL   time.Duration\n}\n\nfunc NewLayeredCache(l1, l2 Cache, l1TTL time.Duration) *LayeredCache {\n    return &amp;LayeredCache{l1: l1, l2: l2, l1TTL: l1TTL}\n}\n\nfunc (c *LayeredCache) Get(ctx context.Context, key string) ([]byte, bool, error) {\n    // Try L1 first\n    if val, ok, _ := c.l1.Get(ctx, key); ok {\n        return val, true, nil\n    }\n\n    // Fall back to L2\n    val, ok, err := c.l2.Get(ctx, key)\n    if err != nil || !ok {\n        return nil, false, err\n    }\n\n    // Promote to L1\n    _ = c.l1.Set(ctx, key, val, c.l1TTL)\n    return val, true, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cache-points-in-the-architecture","title":"Cache Points in the Architecture","text":"Component Cache Key Pattern TTL Purpose toolindex <code>index:tool:{id}</code> 1h Tool metadata lookups toolindex <code>index:namespace:{ns}</code> 30m Namespace listings tooldocs <code>docs:{id}:{level}</code> 1h Documentation at each detail level toolsearch <code>search:{hash(query)}</code> 5m Search result caching toolsearch <code>search:index</code> 10m BM25 index caching tooladapter <code>schema:{format}:{id}</code> 24h Schema conversion results toolrun <code>result:{tool}:{hash(input)}</code> varies Idempotent tool results toolsemantic <code>embed:{hash(text)}</code> 24h Vector embeddings"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#integration-with-existing-libraries","title":"Integration with Existing Libraries","text":"<pre><code>// toolindex integration\ntype CachedIndex struct {\n    inner toolindex.Index\n    cache toolcache.Cache\n    ttl   time.Duration\n}\n\nfunc (c *CachedIndex) Get(ctx context.Context, id string) (*toolmodel.Tool, error) {\n    key := fmt.Sprintf(\"index:tool:%s\", id)\n\n    // Try cache first\n    if data, ok, _ := c.cache.Get(ctx, key); ok {\n        var tool toolmodel.Tool\n        if err := json.Unmarshal(data, &amp;tool); err == nil {\n            return &amp;tool, nil\n        }\n    }\n\n    // Cache miss - fetch from index\n    tool, err := c.inner.Get(ctx, id)\n    if err != nil {\n        return nil, err\n    }\n\n    // Store in cache\n    if data, err := json.Marshal(tool); err == nil {\n        _ = c.cache.Set(ctx, key, data, c.ttl)\n    }\n\n    return tool, nil\n}\n\n// toolsearch integration\ntype CachedSearcher struct {\n    inner toolsearch.Searcher\n    cache toolcache.Cache\n    ttl   time.Duration\n}\n\nfunc (c *CachedSearcher) Search(ctx context.Context, query string, limit int) ([]toolsearch.Result, error) {\n    key := fmt.Sprintf(\"search:%x\", sha256.Sum256([]byte(query)))\n\n    // Try cache\n    if data, ok, _ := c.cache.Get(ctx, key); ok {\n        var results []toolsearch.Result\n        if err := json.Unmarshal(data, &amp;results); err == nil {\n            return results, nil\n        }\n    }\n\n    // Execute search\n    results, err := c.inner.Search(ctx, query, limit)\n    if err != nil {\n        return nil, err\n    }\n\n    // Cache results\n    if data, err := json.Marshal(results); err == nil {\n        _ = c.cache.Set(ctx, key, data, c.ttl)\n    }\n\n    return results, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cache-configuration","title":"Cache Configuration","text":"<pre><code># metatools.yaml\ncache:\n  # Default backend for all caches\n  backend: layered\n\n  # Backend configurations\n  backends:\n    memory:\n      max_size: 100MB\n      max_items: 10000\n\n    redis:\n      addr: localhost:6379\n      password: ${REDIS_PASSWORD}\n      db: 0\n      prefix: metatools\n\n    sqlite:\n      path: /var/cache/metatools/cache.db\n\n    layered:\n      l1: memory\n      l2: redis\n      l1_ttl: 1m\n\n  # Per-component cache settings\n  components:\n    toolindex:\n      enabled: true\n      ttl: 1h\n      backend: layered\n\n    tooldocs:\n      enabled: true\n      ttl: 1h\n      backend: memory  # Docs are static, memory is fine\n\n    toolsearch:\n      enabled: true\n      ttl: 5m\n      backend: redis  # Shared across instances\n\n    tooladapter:\n      enabled: true\n      ttl: 24h\n      backend: sqlite  # Persistent, conversions are expensive\n\n    toolrun:\n      enabled: true\n      ttl: 0  # Per-tool configuration\n      backend: redis\n      # Only cache idempotent tools\n      tools:\n        - describe_tool\n        - list_namespaces\n        - search_tools\n\n  # Cache invalidation\n  invalidation:\n    on_tool_register: true    # Clear index caches\n    on_doc_update: true       # Clear docs caches\n    webhook_endpoint: /cache/invalidate\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#cache-invalidation-strategies","title":"Cache Invalidation Strategies","text":"<pre><code>// toolcache/invalidation.go\n\n// InvalidationStrategy defines how cache entries are invalidated\ntype InvalidationStrategy interface {\n    OnToolRegistered(ctx context.Context, tool *toolmodel.Tool) error\n    OnToolUnregistered(ctx context.Context, toolID string) error\n    OnDocUpdated(ctx context.Context, toolID string) error\n}\n\n// PatternInvalidation clears by key patterns\ntype PatternInvalidation struct {\n    cache Cache\n}\n\nfunc (p *PatternInvalidation) OnToolRegistered(ctx context.Context, tool *toolmodel.Tool) error {\n    patterns := []string{\n        fmt.Sprintf(\"index:tool:%s\", tool.ID()),\n        fmt.Sprintf(\"index:namespace:%s\", tool.Namespace),\n        \"search:*\",  // All search results potentially affected\n    }\n    for _, pattern := range patterns {\n        if err := p.cache.Clear(ctx, pattern); err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\n// TTLInvalidation relies on TTL expiration (simpler, eventually consistent)\ntype TTLInvalidation struct{}\n\nfunc (t *TTLInvalidation) OnToolRegistered(ctx context.Context, tool *toolmodel.Tool) error {\n    // No-op: cache will expire naturally\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#proposed-library-toolcache","title":"Proposed Library: <code>toolcache</code>","text":"<pre><code>toolcache/\n\u251c\u2500\u2500 cache.go           # Cache interface\n\u251c\u2500\u2500 memory.go          # In-memory LRU implementation\n\u251c\u2500\u2500 redis.go           # Redis implementation\n\u251c\u2500\u2500 sqlite.go          # SQLite implementation\n\u251c\u2500\u2500 layered.go         # L1+L2 layered cache\n\u251c\u2500\u2500 stats.go           # Statistics and metrics\n\u251c\u2500\u2500 invalidation.go    # Invalidation strategies\n\u251c\u2500\u2500 typed.go           # Type-safe generic wrapper\n\u251c\u2500\u2500 config.go          # Configuration parsing\n\u2514\u2500\u2500 wrappers/\n    \u251c\u2500\u2500 index.go       # toolindex.Index wrapper\n    \u251c\u2500\u2500 docs.go        # tooldocs.Store wrapper\n    \u251c\u2500\u2500 search.go      # toolsearch.Searcher wrapper\n    \u2514\u2500\u2500 adapter.go     # tooladapter.Adapter wrapper\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#7-additional-cross-cutting-concerns","title":"7. Additional Cross-Cutting Concerns","text":"<p>Beyond the core extension points, production deployments require additional pluggable concerns for resilience, security, and operations.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#71-resilience-patterns","title":"7.1 Resilience Patterns","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       RESILIENCE LAYER                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 CIRCUIT BREAKER                                                          \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 States: CLOSED \u2192 OPEN \u2192 HALF-OPEN \u2192 CLOSED                              \u2502 \u2502\n\u2502  \u2502 - Monitors failure rate per backend/tool                                 \u2502 \u2502\n\u2502  \u2502 - Opens circuit after threshold (e.g., 50% failures in 10s window)      \u2502 \u2502\n\u2502  \u2502 - Allows probe requests in half-open state                               \u2502 \u2502\n\u2502  \u2502 - Prevents cascading failures across backends                            \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 RETRY POLICY                                                             \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Exponential backoff with jitter (prevents retry storms)               \u2502 \u2502\n\u2502  \u2502 - Per-tool retry configuration (idempotent ops only)                    \u2502 \u2502\n\u2502  \u2502 - Retry budgets (max retries per time window)                           \u2502 \u2502\n\u2502  \u2502 - Non-retryable error classification                                     \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 BULKHEAD                                                                 \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Isolated resource pools per backend                                    \u2502 \u2502\n\u2502  \u2502 - Semaphore-based concurrency limits                                     \u2502 \u2502\n\u2502  \u2502 - Prevents resource exhaustion from single backend                      \u2502 \u2502\n\u2502  \u2502 - Configurable queue depth and timeout                                   \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 TIMEOUT MANAGEMENT                                                       \u2502 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502  \u2502 - Per-tool timeout configuration                                         \u2502 \u2502\n\u2502  \u2502 - Cascading timeouts (request \u2192 backend \u2192 tool)                         \u2502 \u2502\n\u2502  \u2502 - Context deadline propagation                                           \u2502 \u2502\n\u2502  \u2502 - Graceful timeout handling with partial results                        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>// toolresilience/circuit_breaker.go\n\ntype CircuitBreaker interface {\n    Execute(ctx context.Context, fn func() error) error\n    State() CircuitState\n    Reset()\n}\n\ntype CircuitState int\n\nconst (\n    StateClosed CircuitState = iota\n    StateOpen\n    StateHalfOpen\n)\n\ntype CircuitBreakerConfig struct {\n    FailureThreshold    int           // failures before opening\n    SuccessThreshold    int           // successes in half-open before closing\n    Timeout             time.Duration // time in open state before half-open\n    WindowSize          time.Duration // sliding window for failure counting\n}\n\n// toolresilience/retry.go\n\ntype RetryPolicy interface {\n    Execute(ctx context.Context, fn func() error) error\n    ShouldRetry(err error, attempt int) bool\n}\n\ntype RetryConfig struct {\n    MaxAttempts     int\n    InitialBackoff  time.Duration\n    MaxBackoff      time.Duration\n    BackoffFactor   float64\n    Jitter          float64       // 0-1, randomization factor\n    RetryBudget     *RetryBudget  // optional rate limiting\n    NonRetryable    []error       // errors that should not be retried\n}\n\n// toolresilience/bulkhead.go\n\ntype Bulkhead interface {\n    Acquire(ctx context.Context) error\n    Release()\n    Available() int\n}\n\ntype BulkheadConfig struct {\n    MaxConcurrent int\n    MaxWait       time.Duration\n    QueueDepth    int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#72-health-checks","title":"7.2 Health Checks","text":"<pre><code>// toolhealth/health.go\n\ntype HealthChecker interface {\n    Check(ctx context.Context) HealthStatus\n    Name() string\n}\n\ntype HealthStatus struct {\n    Status    Status            // healthy, degraded, unhealthy\n    Details   map[string]any\n    Timestamp time.Time\n}\n\ntype Status string\n\nconst (\n    StatusHealthy   Status = \"healthy\"\n    StatusDegraded  Status = \"degraded\"\n    StatusUnhealthy Status = \"unhealthy\"\n)\n\n// Composite health aggregates multiple checkers\ntype CompositeHealth struct {\n    checkers []HealthChecker\n}\n\nfunc (c *CompositeHealth) Check(ctx context.Context) HealthStatus {\n    results := make(map[string]HealthStatus)\n    overall := StatusHealthy\n\n    for _, checker := range c.checkers {\n        status := checker.Check(ctx)\n        results[checker.Name()] = status\n\n        if status.Status == StatusUnhealthy {\n            overall = StatusUnhealthy\n        } else if status.Status == StatusDegraded &amp;&amp; overall != StatusUnhealthy {\n            overall = StatusDegraded\n        }\n    }\n\n    return HealthStatus{\n        Status:    overall,\n        Details:   map[string]any{\"components\": results},\n        Timestamp: time.Now(),\n    }\n}\n\n// Built-in health checkers\ntype BackendHealthChecker struct{ registry BackendRegistry }\ntype CacheHealthChecker struct{ cache Cache }\ntype SearchHealthChecker struct{ index Index }\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#73-secrets-management","title":"7.3 Secrets Management","text":"<pre><code>// toolsecrets/secrets.go\n\ntype SecretsManager interface {\n    Get(ctx context.Context, key string) (string, error)\n    GetWithMetadata(ctx context.Context, key string) (*Secret, error)\n    Watch(ctx context.Context, key string, callback func(*Secret)) error\n    Close() error\n}\n\ntype Secret struct {\n    Value     string\n    Version   int\n    ExpiresAt time.Time\n    Metadata  map[string]string\n}\n\n// Implementations\ntype VaultSecretsManager struct {\n    client       *vault.Client\n    secretPath   string\n    cacheTTL     time.Duration\n    rotationChan chan string\n}\n\ntype AWSSecretsManager struct {\n    client *secretsmanager.Client\n    region string\n}\n\ntype EnvSecretsManager struct {\n    prefix string  // e.g., \"METATOOLS_SECRET_\"\n}\n</code></pre> <pre><code># metatools.yaml\nsecrets:\n  provider: vault  # vault, aws, env, file\n\n  vault:\n    addr: ${VAULT_ADDR}\n    auth_method: kubernetes  # token, kubernetes, approle\n    secret_path: secret/data/metatools\n    cache_ttl: 5m\n\n  # Backend credentials resolved from secrets\n  backends:\n    openai:\n      api_key: \"{{ secrets.openai_api_key }}\"\n    github:\n      token: \"{{ secrets.github_token }}\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#74-configuration-hot-reload","title":"7.4 Configuration Hot-Reload","text":"<pre><code>// toolconfig/watcher.go\n\ntype ConfigWatcher interface {\n    Watch(ctx context.Context, path string, callback func(Config)) error\n    Stop() error\n}\n\ntype FSConfigWatcher struct {\n    watcher *fsnotify.Watcher\n    parser  ConfigParser\n}\n\nfunc (w *FSConfigWatcher) Watch(ctx context.Context, path string, callback func(Config)) error {\n    if err := w.watcher.Add(path); err != nil {\n        return err\n    }\n\n    go func() {\n        for {\n            select {\n            case event := &lt;-w.watcher.Events:\n                if event.Op&amp;fsnotify.Write == fsnotify.Write {\n                    if cfg, err := w.parser.Parse(path); err == nil {\n                        callback(cfg)\n                    }\n                }\n            case &lt;-ctx.Done():\n                return\n            }\n        }\n    }()\n\n    return nil\n}\n\n// Hot-reloadable components\ntype HotReloadable interface {\n    Reload(cfg Config) error\n}\n\n// Registry tracks reloadable components\ntype ReloadRegistry struct {\n    components map[string]HotReloadable\n}\n\nfunc (r *ReloadRegistry) ReloadAll(cfg Config) error {\n    for name, component := range r.components {\n        if err := component.Reload(cfg); err != nil {\n            return fmt.Errorf(\"reload %s: %w\", name, err)\n        }\n    }\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#75-feature-flags","title":"7.5 Feature Flags","text":"<pre><code>// toolflags/flags.go\n\ntype FeatureFlags interface {\n    IsEnabled(ctx context.Context, flag string) bool\n    GetVariant(ctx context.Context, flag string) string\n    AllFlags(ctx context.Context) map[string]bool\n}\n\n// Local file-based flags (simple deployments)\ntype LocalFeatureFlags struct {\n    flags map[string]bool\n    mu    sync.RWMutex\n}\n\n// LaunchDarkly integration (enterprise)\ntype LaunchDarklyFlags struct {\n    client *ld.LDClient\n    user   func(ctx context.Context) ld.User\n}\n\n// Use case: Gradual tool rollout\nfunc (h *Handler) RunTool(ctx context.Context, req Request) (Response, error) {\n    if h.flags.IsEnabled(ctx, \"new_execution_engine\") {\n        return h.newRunner.Run(ctx, req)\n    }\n    return h.legacyRunner.Run(ctx, req)\n}\n</code></pre> <pre><code># metatools.yaml\nfeature_flags:\n  provider: local  # local, launchdarkly, unleash\n\n  local:\n    path: /etc/metatools/flags.yaml\n    reload_interval: 30s\n\n  flags:\n    new_execution_engine: false\n    semantic_search: true\n    multi_tenant_mode: false\n    streaming_responses: true\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#76-audit-trail-event-sourcing","title":"7.6 Audit Trail / Event Sourcing","text":"<pre><code>// toolaudit/audit.go\n\ntype AuditLogger interface {\n    Log(ctx context.Context, event AuditEvent) error\n    Query(ctx context.Context, filter AuditFilter) ([]AuditEvent, error)\n}\n\ntype AuditEvent struct {\n    ID          string\n    Timestamp   time.Time\n    EventType   EventType\n    Actor       Actor\n    Resource    Resource\n    Action      string\n    Outcome     Outcome\n    Details     map[string]any\n    RequestID   string\n    SessionID   string\n}\n\ntype EventType string\n\nconst (\n    EventToolExecution   EventType = \"tool.execution\"\n    EventToolDiscovery   EventType = \"tool.discovery\"\n    EventConfigChange    EventType = \"config.change\"\n    EventAuthAttempt     EventType = \"auth.attempt\"\n    EventBackendError    EventType = \"backend.error\"\n)\n\n// Implementations\ntype FileAuditLogger struct{ path string }\ntype DatabaseAuditLogger struct{ db *sql.DB }\ntype CloudWatchAuditLogger struct{ client *cloudwatchlogs.Client }\n\n// Compliance-ready: immutable append-only log\ntype ImmutableAuditLogger struct {\n    inner  AuditLogger\n    signer crypto.Signer  // Signs each entry\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#77-backpressure-load-shedding","title":"7.7 Backpressure / Load Shedding","text":"<pre><code>// toolpressure/backpressure.go\n\ntype LoadShedder interface {\n    ShouldShed(ctx context.Context) bool\n    CurrentLoad() float64\n}\n\ntype AdaptiveLoadShedder struct {\n    targetLatency time.Duration\n    maxLoad       float64\n\n    // Metrics\n    currentLatency atomic.Value\n    activeRequests atomic.Int64\n}\n\nfunc (s *AdaptiveLoadShedder) ShouldShed(ctx context.Context) bool {\n    // Little's Law: if latency &gt; target and load &gt; threshold, shed\n    latency := s.currentLatency.Load().(time.Duration)\n    load := float64(s.activeRequests.Load()) / s.maxLoad\n\n    return latency &gt; s.targetLatency &amp;&amp; load &gt; 0.8\n}\n\n// Priority-based shedding\ntype PriorityLoadShedder struct {\n    inner      LoadShedder\n    priorities map[string]int  // tool -&gt; priority (higher = more important)\n}\n\nfunc (s *PriorityLoadShedder) ShouldShed(ctx context.Context, tool string) bool {\n    if !s.inner.ShouldShed(ctx) {\n        return false\n    }\n\n    // Don't shed high-priority tools\n    priority := s.priorities[tool]\n    return priority &lt; 5  // Only shed low-priority requests\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-for-all-concerns","title":"Configuration for All Concerns","text":"<pre><code># metatools.yaml - Cross-Cutting Concerns\nresilience:\n  circuit_breaker:\n    enabled: true\n    failure_threshold: 5\n    success_threshold: 2\n    timeout: 30s\n    window_size: 10s\n\n  retry:\n    enabled: true\n    max_attempts: 3\n    initial_backoff: 100ms\n    max_backoff: 5s\n    jitter: 0.2\n\n  bulkhead:\n    enabled: true\n    default_concurrent: 100\n    per_backend:\n      openai: 50    # Rate-limited API\n      github: 200\n      local: 500\n\n  timeout:\n    default: 30s\n    per_tool:\n      execute_code: 120s\n      search_tools: 5s\n\nhealth:\n  endpoint: /health\n  detailed_endpoint: /health/detailed\n  check_interval: 10s\n  components:\n    - backends\n    - cache\n    - search_index\n\nbackpressure:\n  enabled: true\n  target_latency: 500ms\n  max_concurrent: 1000\n  shed_priority_below: 5\n\naudit:\n  enabled: true\n  provider: file  # file, database, cloudwatch\n  path: /var/log/metatools/audit.log\n  events:\n    - tool.execution\n    - auth.attempt\n    - config.change\n  retention_days: 90\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#summary-cross-cutting-concerns-catalog","title":"Summary: Cross-Cutting Concerns Catalog","text":"Concern Purpose Priority Proposed Library Cache Response/metadata caching High <code>toolcache</code> Circuit Breaker Prevent cascading failures High <code>toolresilience</code> Retry Handle transient failures High <code>toolresilience</code> Bulkhead Resource isolation Medium <code>toolresilience</code> Health Checks Monitoring/orchestration High <code>toolhealth</code> Secrets Credential management High <code>toolsecrets</code> Config Reload Zero-downtime updates Medium <code>toolconfig</code> Feature Flags Gradual rollout Medium <code>toolflags</code> Audit Trail Compliance/debugging High <code>toolaudit</code> Backpressure Overload protection Medium <code>toolpressure</code> Timeout Deadline management High Built-in (context) Tracing Distributed observability High <code>toolobserve</code>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#multi-backend-architecture","title":"Multi-Backend Architecture","text":"<p>The backend layer is the foundation for tool discovery and execution. It enables metatools-mcp to aggregate tools from multiple sources while presenting a unified interface to MCP clients.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-overview_3","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           MCP CLIENT                                         \u2502\n\u2502                    (Claude, Cursor, Custom)                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502 MCP Protocol\n                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         METATOOLS-MCP SERVER                                 \u2502\n\u2502                                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                      UNIFIED TOOL INTERFACE                              \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502   search_tools    describe_tool    run_tool    run_chain    execute_code \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                    \u2502                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                       BACKEND REGISTRY                                   \u2502 \u2502\n\u2502  \u2502                                                                           \u2502 \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502 \u2502\n\u2502  \u2502   \u2502   LOCAL     \u2502 \u2502   OPENAI    \u2502 \u2502    MCP      \u2502 \u2502   CUSTOM    \u2502       \u2502 \u2502\n\u2502  \u2502   \u2502  Backend    \u2502 \u2502  Backend    \u2502 \u2502  Backend    \u2502 \u2502  Backend    \u2502       \u2502 \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502 \u2502\n\u2502  \u2502          \u2502               \u2502               \u2502               \u2502               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502               \u2502               \u2502               \u2502\n              \u25bc               \u25bc               \u25bc               \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  Local   \u2502   \u2502  OpenAI  \u2502   \u2502  Other   \u2502   \u2502  Custom  \u2502\n        \u2502  Files   \u2502   \u2502   API    \u2502   \u2502   MCP    \u2502   \u2502   API    \u2502\n        \u2502          \u2502   \u2502          \u2502   \u2502 Servers  \u2502   \u2502          \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#the-backend-interface","title":"The Backend Interface","text":"<p>Each backend implements a common interface, allowing uniform handling regardless of the tool source:</p> <pre><code>// Backend defines a source of tools\ntype Backend interface {\n    // Identity\n    Kind() string                                    // e.g., \"local\", \"openai\", \"mcp\"\n    Name() string                                    // Instance name for disambiguation\n\n    // Configuration\n    Configure(raw []byte) error                      // Parse backend-specific config\n\n    // Discovery\n    ListTools(ctx context.Context) ([]toolmodel.Tool, error)\n\n    // Execution\n    Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n\n    // Lifecycle\n    Start(ctx context.Context) error\n    Stop() error\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#backend-types","title":"Backend Types","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#1-local-backend","title":"1. Local Backend","text":"<p>Tools defined as files on disk (YAML, JSON, or Go handlers).</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   LOCAL BACKEND                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                       \u2502\n\u2502   ~/.config/metatools/tools/                         \u2502\n\u2502   \u251c\u2500\u2500 calculator.yaml      \u2192 Tool definition         \u2502\n\u2502   \u251c\u2500\u2500 file-ops.yaml        \u2192 Tool definition         \u2502\n\u2502   \u2514\u2500\u2500 custom/                                        \u2502\n\u2502       \u2514\u2500\u2500 my-tool.yaml     \u2192 Tool definition         \u2502\n\u2502                                                       \u2502\n\u2502   /usr/share/metatools/tools/                        \u2502\n\u2502   \u2514\u2500\u2500 system-tools.yaml    \u2192 System-wide tools       \u2502\n\u2502                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                             \u2502\n\u2502    paths:                                            \u2502\n\u2502      - ~/.config/metatools/tools                    \u2502\n\u2502      - /usr/share/metatools/tools                   \u2502\n\u2502    watch: true  # Hot reload on changes             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#2-api-backends-openai-azure-anthropic","title":"2. API Backends (OpenAI, Azure, Anthropic)","text":"<p>Tools exposed via LLM provider APIs.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   OPENAI BACKEND                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502   \u2502 metatools   \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  OpenAI API         \u2502    \u2502\n\u2502   \u2502   run_tool  \u2502        \u2502  /chat/completions  \u2502    \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502  (function calling) \u2502    \u2502\n\u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                             \u2502\n\u2502    api_key: ${OPENAI_API_KEY}                       \u2502\n\u2502    organization: ${OPENAI_ORG}                      \u2502\n\u2502    models:                                           \u2502\n\u2502      - gpt-4                                        \u2502\n\u2502      - gpt-4-turbo                                  \u2502\n\u2502    timeout: 30s                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#3-mcp-backend","title":"3. MCP Backend","text":"<p>Connect to other MCP servers as tool sources.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    MCP BACKEND                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                       \u2502\n\u2502   metatools-mcp                                      \u2502\n\u2502        \u2502                                             \u2502\n\u2502        \u2502 stdio                                       \u2502\n\u2502        \u25bc                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                   \u2502\n\u2502   \u2502  GitHub     \u2502  \u2190 npx @modelcontextprotocol/     \u2502\n\u2502   \u2502  MCP Server \u2502       server-github               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2502\n\u2502        \u2502                                             \u2502\n\u2502        \u25bc                                             \u2502\n\u2502   GitHub API tools:                                  \u2502\n\u2502   - create_issue                                    \u2502\n\u2502   - list_pull_requests                              \u2502\n\u2502   - search_code                                     \u2502\n\u2502                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                             \u2502\n\u2502    kind: mcp                                        \u2502\n\u2502    command: npx                                     \u2502\n\u2502    args:                                            \u2502\n\u2502      - \"-y\"                                         \u2502\n\u2502      - \"@modelcontextprotocol/server-github\"        \u2502\n\u2502    env:                                             \u2502\n\u2502      GITHUB_TOKEN: ${GITHUB_TOKEN}                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#4-http-backend","title":"4. HTTP Backend","text":"<p>Tools exposed via REST APIs.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   HTTP BACKEND                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                       \u2502\n\u2502   metatools-mcp                                      \u2502\n\u2502        \u2502                                             \u2502\n\u2502        \u2502 HTTPS                                       \u2502\n\u2502        \u25bc                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502   \u2502  Internal Tool Server   \u2502                       \u2502\n\u2502   \u2502  tools.company.internal \u2502                       \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502        \u2502                                             \u2502\n\u2502        \u25bc                                             \u2502\n\u2502   Endpoints:                                         \u2502\n\u2502   - POST /tools/list                                \u2502\n\u2502   - POST /tools/{name}/execute                      \u2502\n\u2502                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config:                                             \u2502\n\u2502    base_url: https://tools.company.internal         \u2502\n\u2502    auth:                                            \u2502\n\u2502      type: oauth2                                   \u2502\n\u2502      client_id: ${OAUTH_CLIENT_ID}                  \u2502\n\u2502      client_secret: ${OAUTH_CLIENT_SECRET}          \u2502\n\u2502    headers:                                         \u2502\n\u2502      X-Custom-Header: value                         \u2502\n\u2502    timeout: 30s                                     \u2502\n\u2502    retry:                                           \u2502\n\u2502      max_attempts: 3                                \u2502\n\u2502      backoff: exponential                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#5-custom-backend","title":"5. Custom Backend","text":"<p>For specialized integrations that don't fit standard patterns.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  CUSTOM BACKEND                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                       \u2502\n\u2502   Implement the Backend interface in Go:             \u2502\n\u2502                                                       \u2502\n\u2502   type MyCustomBackend struct {                     \u2502\n\u2502       // Your fields                                \u2502\n\u2502   }                                                  \u2502\n\u2502                                                       \u2502\n\u2502   func (b *MyCustomBackend) Kind() string {         \u2502\n\u2502       return \"my-custom\"                            \u2502\n\u2502   }                                                  \u2502\n\u2502                                                       \u2502\n\u2502   func (b *MyCustomBackend) Configure(raw []byte)   \u2502\n\u2502       error {                                       \u2502\n\u2502       // Parse your custom config                   \u2502\n\u2502       return yaml.Unmarshal(raw, &amp;b.config)         \u2502\n\u2502   }                                                  \u2502\n\u2502                                                       \u2502\n\u2502   func (b *MyCustomBackend) Execute(ctx, tool,      \u2502\n\u2502       args) (any, error) {                          \u2502\n\u2502       // Your execution logic                       \u2502\n\u2502   }                                                  \u2502\n\u2502                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Config (passed as raw bytes):                      \u2502\n\u2502    kind: custom                                     \u2502\n\u2502    handler: my-custom                               \u2502\n\u2502    config:                                          \u2502\n\u2502      whatever_you_need: value                       \u2502\n\u2502      nested:                                        \u2502\n\u2502        custom: structure                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-examples","title":"Configuration Examples","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#comprehensive-multi-backend-setup","title":"Comprehensive Multi-Backend Setup","text":"<pre><code># metatools.yaml\nbackends:\n  # Local file-based tools\n  local:\n    enabled: true\n    paths:\n      - ~/.config/metatools/tools\n      - /usr/share/metatools/tools\n    watch: true  # Hot reload\n\n  # OpenAI function calling\n  openai:\n    enabled: true\n    api_key: ${OPENAI_API_KEY}\n    organization: ${OPENAI_ORG}\n    models:\n      - gpt-4\n      - gpt-4-turbo\n    timeout: 30s\n\n  # Azure OpenAI\n  azure-openai:\n    enabled: true\n    kind: azure\n    config:\n      endpoint: https://my-resource.openai.azure.com\n      api_key: ${AZURE_OPENAI_KEY}\n      api_version: \"2024-02-15-preview\"\n      deployment: gpt-4\n\n  # GitHub MCP server\n  github:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-github\"]\n      env:\n        GITHUB_TOKEN: ${GITHUB_TOKEN}\n\n  # Filesystem MCP server\n  filesystem:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/home/user/projects\"]\n\n  # Internal company tool server\n  internal-tools:\n    enabled: true\n    kind: http\n    config:\n      base_url: https://tools.internal.company.com/api/v1\n      auth:\n        type: oauth2\n        token_url: https://auth.company.com/oauth/token\n        client_id: ${INTERNAL_CLIENT_ID}\n        client_secret: ${INTERNAL_CLIENT_SECRET}\n        scopes: [\"tools:read\", \"tools:execute\"]\n      timeout: 60s\n\n  # LangChain tools\n  langchain:\n    enabled: false\n    kind: custom\n    config:\n      toolkit: serpapi\n      api_key: ${SERPAPI_KEY}\n\n  # Database tools\n  database:\n    enabled: true\n    kind: custom\n    config:\n      driver: postgres\n      connection_string: ${DATABASE_URL}\n      read_only: true\n      allowed_schemas: [\"public\", \"analytics\"]\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#tool-aggregation-flow","title":"Tool Aggregation Flow","text":"<p>When a client searches for or executes tools, metatools-mcp aggregates across all backends:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         TOOL SEARCH FLOW                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   Client: search_tools(\"file operations\")                                   \u2502\n\u2502                           \u2502                                                  \u2502\n\u2502                           \u25bc                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    BACKEND REGISTRY                                  \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502   \u2502\n\u2502   \u2502   \u2502  local  \u2502   \u2502 github  \u2502   \u2502  azure  \u2502   \u2502  http   \u2502            \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518            \u2502   \u2502\n\u2502   \u2502        \u2502             \u2502             \u2502             \u2502                  \u2502   \u2502\n\u2502   \u2502        \u25bc             \u25bc             \u25bc             \u25bc                  \u2502   \u2502\n\u2502   \u2502   ListTools()   ListTools()   ListTools()   ListTools()            \u2502   \u2502\n\u2502   \u2502        \u2502             \u2502             \u2502             \u2502                  \u2502   \u2502\n\u2502   \u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502   \u2502\n\u2502   \u2502                             \u2502                                        \u2502   \u2502\n\u2502   \u2502                             \u25bc                                        \u2502   \u2502\n\u2502   \u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2502   \u2502\n\u2502   \u2502                    \u2502   AGGREGATOR    \u2502                              \u2502   \u2502\n\u2502   \u2502                    \u2502  - Merge tools  \u2502                              \u2502   \u2502\n\u2502   \u2502                    \u2502  - Deduplicate  \u2502                              \u2502   \u2502\n\u2502   \u2502                    \u2502  - Apply search \u2502                              \u2502   \u2502\n\u2502   \u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502   \u2502\n\u2502   \u2502                             \u2502                                        \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                 \u25bc                                            \u2502\n\u2502   Results:                                                                   \u2502\n\u2502   [                                                                          \u2502\n\u2502     { id: \"local/file-read\",      backend: \"local\",    score: 0.95 },       \u2502\n\u2502     { id: \"github/get-file\",      backend: \"github\",   score: 0.87 },       \u2502\n\u2502     { id: \"filesystem/read_file\", backend: \"mcp\",      score: 0.82 },       \u2502\n\u2502   ]                                                                          \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#tool-execution-flow","title":"Tool Execution Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        TOOL EXECUTION FLOW                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   Client: run_tool(\"github/create_issue\", { title: \"Bug\", body: \"...\" })   \u2502\n\u2502                           \u2502                                                  \u2502\n\u2502                           \u25bc                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      TOOL ROUTER                                     \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   1. Parse tool ID: \"github/create_issue\"                           \u2502   \u2502\n\u2502   \u2502      \u2514\u2500 backend: \"github\"                                           \u2502   \u2502\n\u2502   \u2502      \u2514\u2500 tool: \"create_issue\"                                        \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   2. Lookup backend in registry                                     \u2502   \u2502\n\u2502   \u2502      \u2514\u2500 Found: GitHubMCPBackend                                     \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   3. Delegate execution                                              \u2502   \u2502\n\u2502   \u2502      \u2514\u2500 backend.Execute(ctx, \"create_issue\", args)                  \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                           \u2502                                                  \u2502\n\u2502                           \u25bc                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                   GITHUB MCP BACKEND                                 \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   1. Forward to MCP subprocess                                      \u2502   \u2502\n\u2502   \u2502      \u2514\u2500 npx @modelcontextprotocol/server-github                     \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   2. MCP call: tools/call { name: \"create_issue\", arguments: ... }  \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   3. Receive result                                                  \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                           \u2502                                                  \u2502\n\u2502                           \u25bc                                                  \u2502\n\u2502   Result:                                                                    \u2502\n\u2502   {                                                                          \u2502\n\u2502     result: { issue_number: 123, url: \"https://github.com/...\" },          \u2502\n\u2502     backend: { kind: \"mcp\", name: \"github\" },                              \u2502\n\u2502     duration_ms: 1250                                                       \u2502\n\u2502   }                                                                          \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#registration-patterns","title":"Registration Patterns","text":"<p>Backends can be registered via YAML configuration or programmatically:</p> <pre><code>// YAML-driven registration (config file)\nfunc (r *BackendRegistry) LoadFromConfig(cfg BackendsConfig) error {\n    for name, backendCfg := range cfg.Backends {\n        if !backendCfg.Enabled {\n            continue\n        }\n\n        // Create backend based on kind\n        backend, err := r.createBackend(backendCfg.Kind)\n        if err != nil {\n            return fmt.Errorf(\"backend %s: %w\", name, err)\n        }\n\n        // Configure with raw config (backend parses itself)\n        if err := backend.Configure(backendCfg.RawConfig); err != nil {\n            return fmt.Errorf(\"backend %s config: %w\", name, err)\n        }\n\n        r.backends[name] = backend\n    }\n    return nil\n}\n\n// Programmatic registration (code-driven)\nfunc main() {\n    registry := NewBackendRegistry()\n\n    // Register a custom backend programmatically\n    myBackend := &amp;MyCustomBackend{\n        // ... configuration\n    }\n    registry.Register(\"my-backend\", myBackend)\n\n    // Or use the builder pattern\n    registry.\n        WithLocal(\"~/.config/metatools/tools\").\n        WithOpenAI(os.Getenv(\"OPENAI_API_KEY\")).\n        WithMCP(\"github\", \"npx\", \"-y\", \"@modelcontextprotocol/server-github\")\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#hybrid-configuration","title":"Hybrid Configuration","text":"<p>For maximum flexibility, backends support both YAML and code:</p> <pre><code>// Backend interface with hybrid config support\ntype Backend interface {\n    Kind() string\n    Name() string\n\n    // Option 1: YAML-driven config\n    Configure(raw []byte) error\n\n    // Option 2: Programmatic config (for complex backends)\n    ConfigureWith(opts ...BackendOption) error\n\n    // Operations\n    ListTools(ctx context.Context) ([]toolmodel.Tool, error)\n    Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n}\n\n// Usage: Some config in YAML, some in code\nfunc setupBackends(registry *BackendRegistry, cfg Config) error {\n    // Load standard backends from YAML\n    if err := registry.LoadFromConfig(cfg.Backends); err != nil {\n        return err\n    }\n\n    // Add a complex custom backend programmatically\n    customBackend := NewDatabaseBackend(\n        WithConnectionPool(pool),\n        WithQueryValidator(validator),\n        WithAuditLogger(auditLog),\n    )\n    registry.Register(\"database\", customBackend)\n\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#error-handling-across-backends","title":"Error Handling Across Backends","text":"<pre><code>// Backend errors include source information\ntype BackendError struct {\n    Backend   string    // Which backend failed\n    Operation string    // What operation failed\n    Tool      string    // Which tool (if applicable)\n    Cause     error     // Underlying error\n    Retryable bool      // Can this be retried?\n}\n\n// Aggregated errors for multi-backend operations\ntype AggregatedError struct {\n    Errors []BackendError\n}\n\nfunc (e *AggregatedError) Error() string {\n    // Format: \"3 backends failed: local: connection refused, openai: rate limited, ...\"\n}\n\n// Partial success handling\ntype AggregatedResult struct {\n    Tools   []toolmodel.Tool  // Successfully retrieved tools\n    Errors  []BackendError    // Backends that failed\n    Partial bool              // True if some backends failed\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#summary-what-this-enables","title":"Summary: What This Enables","text":"Capability Description Tool Aggregation Single search across all backends Unified Execution Consistent interface regardless of backend Hot Plugging Add/remove backends via config without code changes Custom Backends Write Go code for specialized integrations MCP Composition Chain multiple MCP servers together Hybrid Config YAML for standard backends, code for complex ones Graceful Degradation Continue working if some backends fail"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-design","title":"Configuration Design","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#recommended-koanf-cobra","title":"Recommended: Koanf + Cobra","text":"Component Library Rationale CLI framework Cobra Subcommands (<code>stdio</code>, <code>serve</code>, <code>version</code>) Config loading Koanf Lighter than Viper, modular providers"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-structure","title":"Configuration Structure","text":"<pre><code># metatools.yaml\nserver:\n  name: \"metatools-mcp\"\n  version: \"0.2.0\"\n\ntransport:\n  type: sse           # stdio | sse | http\n  http:\n    host: \"0.0.0.0\"\n    port: 8080\n    tls:\n      enabled: true\n      cert: /etc/ssl/cert.pem\n      key: /etc/ssl/key.pem\n    timeouts:\n      read: 30s\n      write: 30s\n      idle: 120s\n\nsearch:\n  strategy: bm25      # lexical | bm25 | semantic\n  bm25:\n    name_boost: 3\n    namespace_boost: 2\n    tags_boost: 2\n    max_docs: 0\n    max_doctext_len: 0\n\nexecution:\n  timeout: 10s\n  max_tool_calls: 64\n  max_chain_steps: 8\n\n# Tool providers (each gets own config section)\nproviders:\n  search_tools:\n    enabled: true\n  describe_tool:\n    enabled: true\n    default_level: summary\n  run_tool:\n    enabled: true\n  run_chain:\n    enabled: true\n  execute_code:\n    enabled: true      # Requires toolruntime build tag\n    sandbox: dev\n\n# Backend sources for tools\nbackends:\n  local:\n    enabled: true\n    paths:\n      - ~/.config/metatools/tools\n      - /usr/share/metatools/tools\n  openai:\n    enabled: false\n    api_key: ${OPENAI_API_KEY}\n  azure:\n    enabled: false\n    tenant_id: ${AZURE_TENANT_ID}\n\n# Middleware chain\nmiddleware:\n  logging:\n    enabled: true\n    level: info\n  auth:\n    enabled: false\n    type: bearer\n  rate_limit:\n    enabled: false\n    requests_per_minute: 100\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-precedence","title":"Configuration Precedence","text":"<pre><code>CLI flags &gt; Environment variables &gt; Config file &gt; Defaults\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#plugin-configuration-pattern","title":"Plugin Configuration Pattern","text":"<p>Plugins receive raw config and parse themselves:</p> <pre><code>type Plugin interface {\n    Name() string\n    Configure(raw []byte) error  // Plugin parses its own config\n    Start(ctx context.Context) error\n    Stop() error\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementation-approach","title":"Implementation Approach","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-1-cli-framework-cobra-koanf","title":"Phase 1: CLI Framework (Cobra + Koanf)","text":"<ol> <li>Add Cobra for subcommands (<code>metatools stdio</code>, <code>metatools serve</code>)</li> <li>Add Koanf for config file loading</li> <li>Maintain backward compatibility (env vars still work)</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-2-transport-abstraction","title":"Phase 2: Transport Abstraction","text":"<ol> <li>Define <code>Transport</code> interface</li> <li>Extract current stdio logic into <code>StdioTransport</code></li> <li>Add <code>SSETransport</code> for HTTP/SSE mode</li> <li>Wire transport selection to config/CLI</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-3-tool-provider-registry","title":"Phase 3: Tool Provider Registry","text":"<ol> <li>Define <code>ToolProvider</code> interface</li> <li>Convert existing handlers to providers</li> <li>Replace <code>registerTools()</code> with registry iteration</li> <li>Enable external provider registration</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-4-backend-registry","title":"Phase 4: Backend Registry","text":"<ol> <li>Define <code>BackendRegistry</code> interface</li> <li>Implement config-driven backend loading</li> <li>Support local, API, and MCP server backends</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-5-middleware-chain","title":"Phase 5: Middleware Chain","text":"<ol> <li>Define <code>Middleware</code> type</li> <li>Implement logging, auth, rate limiting</li> <li>Apply middleware via config</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#end-to-end-examples","title":"End-to-End Examples","text":"<p>This section demonstrates how the pluggable architecture works in practice with complete examples.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#example-1-enterprise-ai-assistant","title":"Example 1: Enterprise AI Assistant","text":"<p>An internal AI assistant that aggregates tools from multiple sources.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    ENTERPRISE AI ASSISTANT                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      FRONTEND / CLIENTS                              \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502   \u2502\n\u2502   \u2502   \u2502  Slack    \u2502  \u2502  Teams    \u2502  \u2502   Web     \u2502  \u2502  VS Code  \u2502        \u2502   \u2502\n\u2502   \u2502   \u2502   Bot     \u2502  \u2502   Bot     \u2502  \u2502   App     \u2502  \u2502 Extension \u2502        \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518        \u2502   \u2502\n\u2502   \u2502         \u2502              \u2502              \u2502              \u2502               \u2502   \u2502\n\u2502   \u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502   \u2502\n\u2502   \u2502                              \u2502 HTTPS/SSE                             \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                  \u25bc                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      METATOOLS-MCP SERVER                            \u2502   \u2502\n\u2502   \u2502                         (HA Cluster)                                 \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Transport: SSE on :8080                                           \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Middleware Chain:                                                  \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502   \u2502\n\u2502   \u2502   \u2502  Log   \u2502\u2192\u2502 OAuth  \u2502\u2192\u2502 Rate   \u2502\u2192\u2502 Audit  \u2502\u2192\u2502 Cache  \u2502           \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Tool Providers:                                                    \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502   \u2502\n\u2502   \u2502   \u2502 search_tools \u2502 \u2502 describe    \u2502 \u2502 run_tool    \u2502               \u2502   \u2502\n\u2502   \u2502   \u2502              \u2502 \u2502 _tool       \u2502 \u2502             \u2502               \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Backends:                                                          \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502   \u2502\n\u2502   \u2502   \u2502  Jira    \u2502 \u2502Confluence\u2502 \u2502  GitHub  \u2502 \u2502 Internal \u2502              \u2502   \u2502\n\u2502   \u2502   \u2502   MCP    \u2502 \u2502   MCP    \u2502 \u2502   MCP    \u2502 \u2502   API    \u2502              \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518              \u2502   \u2502\n\u2502   \u2502        \u2502            \u2502            \u2502            \u2502                     \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502            \u25bc            \u25bc            \u25bc            \u25bc                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502   \u2502    Jira      \u2502 \u2502  Confluence  \u2502 \u2502    GitHub    \u2502 \u2502   Company    \u2502       \u2502\n\u2502   \u2502    Cloud     \u2502 \u2502    Cloud     \u2502 \u2502              \u2502 \u2502     API      \u2502       \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Configuration:</p> <pre><code># metatools-enterprise.yaml\nserver:\n  name: \"enterprise-ai-assistant\"\n  version: \"1.0.0\"\n\ntransport:\n  type: sse\n  http:\n    host: \"0.0.0.0\"\n    port: 8080\n    tls:\n      enabled: true\n      cert: /etc/ssl/certs/server.crt\n      key: /etc/ssl/private/server.key\n    cors:\n      enabled: true\n      origins:\n        - \"https://chat.company.com\"\n        - \"https://slack-bot.company.internal\"\n    health:\n      enabled: true\n\nmiddleware:\n  chain: [logging, auth, rate_limit, audit, cache]\n\n  logging:\n    enabled: true\n    level: info\n    format: json\n\n  auth:\n    enabled: true\n    type: oauth2\n    issuer: https://auth.company.com\n    audience: metatools-api\n    jwks_uri: https://auth.company.com/.well-known/jwks.json\n\n  rate_limit:\n    enabled: true\n    storage: redis\n    redis:\n      address: redis.company.internal:6379\n    default:\n      requests_per_minute: 60\n    per_user: true\n\n  audit:\n    enabled: true\n    destination: elasticsearch\n    elasticsearch:\n      addresses: [\"https://es.company.internal:9200\"]\n      index: metatools-audit\n\n  cache:\n    enabled: true\n    backend: redis\n    redis:\n      address: redis.company.internal:6379\n    per_tool:\n      search_tools:\n        ttl: 1m\n      describe_tool:\n        ttl: 10m\n\nbackends:\n  jira:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@anthropic/mcp-server-jira\"]\n      env:\n        JIRA_URL: https://company.atlassian.net\n        JIRA_EMAIL: ${JIRA_EMAIL}\n        JIRA_API_TOKEN: ${JIRA_API_TOKEN}\n\n  confluence:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@anthropic/mcp-server-confluence\"]\n      env:\n        CONFLUENCE_URL: https://company.atlassian.net/wiki\n        CONFLUENCE_EMAIL: ${CONFLUENCE_EMAIL}\n        CONFLUENCE_API_TOKEN: ${CONFLUENCE_API_TOKEN}\n\n  github:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-github\"]\n      env:\n        GITHUB_TOKEN: ${GITHUB_TOKEN}\n\n  internal-api:\n    enabled: true\n    kind: http\n    config:\n      base_url: https://api.company.internal/tools/v1\n      auth:\n        type: oauth2\n        token_url: https://auth.company.com/oauth/token\n        client_id: ${INTERNAL_CLIENT_ID}\n        client_secret: ${INTERNAL_CLIENT_SECRET}\n        scopes: [\"tools:read\", \"tools:execute\"]\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#example-2-local-development-setup","title":"Example 2: Local Development Setup","text":"<p>A developer workstation with file system access and code execution.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    LOCAL DEVELOPMENT SETUP                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                       DEVELOPER MACHINE                              \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                             \u2502   \u2502\n\u2502   \u2502   \u2502   Claude Desktop  \u2502 \u2190\u2500\u2500 stdio \u2500\u2500\u2510                               \u2502   \u2502\n\u2502   \u2502   \u2502   or Cursor IDE   \u2502             \u2502                               \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502                               \u2502   \u2502\n\u2502   \u2502                                      \u2502                               \u2502   \u2502\n\u2502   \u2502                                      \u25bc                               \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502   \u2502              METATOOLS-MCP (stdio mode)                      \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   Build: go build -tags \"toolsearch,toolruntime\"            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   Features:                                                  \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - BM25 search (toolsearch tag)                            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - Code execution (toolruntime tag)                        \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   Backends:                                                  \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502   Local    \u2502 \u2502 Filesystem \u2502 \u2502   Git      \u2502              \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2502   Tools    \u2502 \u2502    MCP     \u2502 \u2502   MCP      \u2502              \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502         \u2502              \u2502              \u2502                      \u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502             \u2502              \u2502              \u2502                          \u2502   \u2502\n\u2502   \u2502             \u25bc              \u25bc              \u25bc                          \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502   \u2502\n\u2502   \u2502   \u2502 ~/.config/ \u2502   \u2502 ~/Projects \u2502   \u2502 .git repos \u2502                  \u2502   \u2502\n\u2502   \u2502   \u2502 metatools/ \u2502   \u2502            \u2502   \u2502            \u2502                  \u2502   \u2502\n\u2502   \u2502   \u2502 tools/     \u2502   \u2502            \u2502   \u2502            \u2502                  \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Configuration:</p> <pre><code># ~/.config/metatools/config.yaml\nserver:\n  name: \"dev-metatools\"\n  version: \"local\"\n\ntransport:\n  type: stdio\n\nsearch:\n  strategy: bm25\n  bm25:\n    name_boost: 3\n    namespace_boost: 2\n\nexecution:\n  timeout: 30s\n  max_tool_calls: 100\n\nmiddleware:\n  chain: [logging]\n  logging:\n    enabled: true\n    level: debug\n    output: /tmp/metatools.log\n\nbackends:\n  local:\n    enabled: true\n    paths:\n      - ~/.config/metatools/tools\n    watch: true\n\n  filesystem:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args:\n        - \"-y\"\n        - \"@modelcontextprotocol/server-filesystem\"\n        - \"~/Projects\"\n        - \"~/Documents\"\n\n  git:\n    enabled: true\n    kind: mcp\n    config:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-git\"]\n</code></pre> <p>Custom Local Tool Definition:</p> <pre><code># ~/.config/metatools/tools/project-tools.yaml\ntools:\n  - name: run_tests\n    namespace: dev\n    description: Run project tests with optional coverage\n    inputSchema:\n      type: object\n      properties:\n        path:\n          type: string\n          description: Project path\n        coverage:\n          type: boolean\n          default: false\n      required: [path]\n\n    backend:\n      kind: local\n      handler: run_tests\n\n  - name: lint_code\n    namespace: dev\n    description: Run linter on project\n    inputSchema:\n      type: object\n      properties:\n        path:\n          type: string\n        fix:\n          type: boolean\n          default: false\n      required: [path]\n\n    backend:\n      kind: local\n      handler: lint_code\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#example-3-multi-llm-tool-router","title":"Example 3: Multi-LLM Tool Router","text":"<p>A gateway that routes tool calls to different LLM providers.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      MULTI-LLM TOOL ROUTER                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                  \u2502\n\u2502                         \u2502   Application   \u2502                                  \u2502\n\u2502                         \u2502   (Your App)    \u2502                                  \u2502\n\u2502                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                  \u2502\n\u2502                                  \u2502 MCP                                       \u2502\n\u2502                                  \u25bc                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      METATOOLS-MCP ROUTER                            \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502   \u2502                    TOOL AGGREGATOR                           \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   All tools from all backends visible as one unified set    \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   search_tools(\"weather\") \u2192                                  \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   [                                                          \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502     { id: \"openai/get_weather\", backend: \"openai\" },        \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502     { id: \"anthropic/weather_lookup\", backend: \"anthropic\" },\u2502   \u2502   \u2502\n\u2502   \u2502   \u2502     { id: \"local/weather_api\", backend: \"local\" }           \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   ]                                                          \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502                              \u25bc                                        \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502   \u2502                    SMART ROUTER                              \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   Routes based on:                                           \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - Tool prefix (openai/*, anthropic/*, local/*)            \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - Cost optimization                                        \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - Latency requirements                                     \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502   - Fallback on failure                                     \u2502   \u2502   \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502   \u2502\n\u2502   \u2502          \u2502                   \u2502                   \u2502                   \u2502   \u2502\n\u2502   \u2502          \u25bc                   \u25bc                   \u25bc                   \u2502   \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502   \u2502\n\u2502   \u2502   \u2502   OpenAI   \u2502     \u2502 Anthropic  \u2502     \u2502   Local    \u2502              \u2502   \u2502\n\u2502   \u2502   \u2502  Backend   \u2502     \u2502  Backend   \u2502     \u2502  Backend   \u2502              \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502   \u2502\n\u2502   \u2502         \u2502                   \u2502                 \u2502                      \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502             \u2502                   \u2502                 \u2502                          \u2502\n\u2502             \u25bc                   \u25bc                 \u25bc                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502   \u2502    OpenAI API    \u2502 \u2502  Anthropic API   \u2502 \u2502   Local Tools    \u2502            \u2502\n\u2502   \u2502                  \u2502 \u2502                  \u2502 \u2502                  \u2502            \u2502\n\u2502   \u2502  - GPT-4 tools   \u2502 \u2502  - Claude tools  \u2502 \u2502  - Custom tools  \u2502            \u2502\n\u2502   \u2502  - DALL-E        \u2502 \u2502  - Computer use  \u2502 \u2502  - File ops      \u2502            \u2502\n\u2502   \u2502  - Whisper       \u2502 \u2502                  \u2502 \u2502  - Scripts       \u2502            \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Configuration:</p> <pre><code># multi-llm-router.yaml\nserver:\n  name: \"llm-tool-router\"\n  version: \"1.0.0\"\n\ntransport:\n  type: sse\n  http:\n    port: 8080\n\nmiddleware:\n  chain: [logging, metrics, cost_tracking]\n\n  cost_tracking:\n    enabled: true\n    storage: postgres\n    postgres:\n      connection_string: ${DATABASE_URL}\n\nbackends:\n  openai:\n    enabled: true\n    kind: openai\n    config:\n      api_key: ${OPENAI_API_KEY}\n      organization: ${OPENAI_ORG}\n      models:\n        - gpt-4\n        - gpt-4-turbo\n        - dall-e-3\n      default_model: gpt-4-turbo\n      timeout: 60s\n\n  anthropic:\n    enabled: true\n    kind: anthropic\n    config:\n      api_key: ${ANTHROPIC_API_KEY}\n      models:\n        - claude-3-opus\n        - claude-3-sonnet\n      default_model: claude-3-sonnet\n      timeout: 60s\n\n  local:\n    enabled: true\n    paths:\n      - /opt/metatools/tools\n\nrouting:\n  # Route by prefix\n  prefix_routing:\n    \"openai/*\": openai\n    \"anthropic/*\": anthropic\n    \"local/*\": local\n\n  # Fallback chain\n  fallback:\n    - openai\n    - anthropic\n    - local\n\n  # Cost optimization\n  cost_aware:\n    enabled: true\n    prefer_cheaper: true\n    budget_per_hour: 10.00\n    currency: USD\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#example-4-microservices-tool-mesh","title":"Example 4: Microservices Tool Mesh","text":"<p>A distributed architecture where each service exposes tools via MCP.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     MICROSERVICES TOOL MESH                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                        API GATEWAY                                   \u2502   \u2502\n\u2502   \u2502                    (Kong / Envoy / etc)                             \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                \u2502                                             \u2502\n\u2502                                \u25bc                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                   METATOOLS-MCP AGGREGATOR                           \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Transport: gRPC (internal), SSE (external)                        \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Service Discovery: Kubernetes / Consul                            \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502   Aggregates tools from all registered MCP services                 \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                \u2502                                             \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502\n\u2502         \u2502                      \u2502                      \u2502                     \u2502\n\u2502         \u25bc                      \u25bc                      \u25bc                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502  Orders    \u2502        \u2502  Users     \u2502        \u2502  Inventory \u2502               \u2502\n\u2502   \u2502  Service   \u2502        \u2502  Service   \u2502        \u2502  Service   \u2502               \u2502\n\u2502   \u2502            \u2502        \u2502            \u2502        \u2502            \u2502               \u2502\n\u2502   \u2502  MCP Tools:\u2502        \u2502  MCP Tools:\u2502        \u2502  MCP Tools:\u2502               \u2502\n\u2502   \u2502  - create  \u2502        \u2502  - lookup  \u2502        \u2502  - check   \u2502               \u2502\n\u2502   \u2502    _order  \u2502        \u2502    _user   \u2502        \u2502    _stock  \u2502               \u2502\n\u2502   \u2502  - cancel  \u2502        \u2502  - update  \u2502        \u2502  - reserve \u2502               \u2502\n\u2502   \u2502    _order  \u2502        \u2502    _prefs  \u2502        \u2502    _item   \u2502               \u2502\n\u2502   \u2502  - track   \u2502        \u2502  - auth    \u2502        \u2502  - release \u2502               \u2502\n\u2502   \u2502    _order  \u2502        \u2502            \u2502        \u2502    _item   \u2502               \u2502\n\u2502   \u2502            \u2502        \u2502            \u2502        \u2502            \u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502         \u2502                      \u2502                      \u2502                     \u2502\n\u2502         \u25bc                      \u25bc                      \u25bc                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502   \u2502 Orders DB  \u2502        \u2502 Users DB   \u2502        \u2502Inventory DB\u2502               \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Aggregator Configuration:</p> <pre><code># aggregator.yaml\nserver:\n  name: \"tool-mesh-aggregator\"\n  version: \"1.0.0\"\n\ntransports:\n  - type: sse\n    enabled: true\n    http:\n      port: 8080\n      # External-facing\n\n  - type: grpc\n    enabled: true\n    grpc:\n      port: 9090\n      # Internal service mesh\n\nservice_discovery:\n  type: kubernetes\n  kubernetes:\n    namespace: production\n    label_selector: \"mcp.enabled=true\"\n    port_name: mcp-grpc\n\nbackends:\n  # Auto-discovered from Kubernetes\n  auto_discover:\n    enabled: true\n    refresh_interval: 30s\n\n  # Or explicit configuration\n  orders:\n    enabled: true\n    kind: grpc\n    config:\n      address: orders-service.production.svc:9090\n      tls:\n        enabled: true\n        ca_cert: /etc/ssl/ca.crt\n\n  users:\n    enabled: true\n    kind: grpc\n    config:\n      address: users-service.production.svc:9090\n\n  inventory:\n    enabled: true\n    kind: grpc\n    config:\n      address: inventory-service.production.svc:9090\n</code></pre> <p>Service Configuration (e.g., Orders Service):</p> <pre><code># orders-service/mcp-config.yaml\nserver:\n  name: \"orders-service-mcp\"\n  version: \"2.1.0\"\n\ntransport:\n  type: grpc\n  grpc:\n    port: 9090\n\nproviders:\n  create_order:\n    enabled: true\n  cancel_order:\n    enabled: true\n  track_order:\n    enabled: true\n\nbackends:\n  local:\n    enabled: true\n    # Orders service tools implemented in Go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#example-5-request-flow-diagram","title":"Example 5: Request Flow Diagram","text":"<p>A complete request flow through all layers:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    COMPLETE REQUEST FLOW                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502   1. CLIENT REQUEST                                                          \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  POST /mcp HTTP/1.1                                                  \u2502   \u2502\n\u2502   \u2502  Content-Type: application/json                                      \u2502   \u2502\n\u2502   \u2502  Authorization: Bearer eyJhbGc...                                   \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502  {                                                                   \u2502   \u2502\n\u2502   \u2502    \"jsonrpc\": \"2.0\",                                                \u2502   \u2502\n\u2502   \u2502    \"method\": \"tools/call\",                                          \u2502   \u2502\n\u2502   \u2502    \"params\": {                                                      \u2502   \u2502\n\u2502   \u2502      \"name\": \"github/create_issue\",                                 \u2502   \u2502\n\u2502   \u2502      \"arguments\": {                                                 \u2502   \u2502\n\u2502   \u2502        \"repo\": \"company/project\",                                   \u2502   \u2502\n\u2502   \u2502        \"title\": \"Bug: Login fails\",                                 \u2502   \u2502\n\u2502   \u2502        \"body\": \"Steps to reproduce...\"                              \u2502   \u2502\n\u2502   \u2502      }                                                              \u2502   \u2502\n\u2502   \u2502    },                                                               \u2502   \u2502\n\u2502   \u2502    \"id\": \"req-123\"                                                  \u2502   \u2502\n\u2502   \u2502  }                                                                   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   2. TRANSPORT LAYER (SSE)                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  - Accept HTTP connection                                           \u2502   \u2502\n\u2502   \u2502  - Parse JSON-RPC request                                           \u2502   \u2502\n\u2502   \u2502  - Create context with request ID                                   \u2502   \u2502\n\u2502   \u2502  - Pass to handler chain                                            \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   3. MIDDLEWARE CHAIN                                                        \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502 LOGGING                                                       \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Log: \"Incoming request req-123 for github/create_issue\"    \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Start timer                                                 \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502                              \u25bc                                        \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502 AUTH                                                          \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Validate JWT token                                          \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Extract user: \"alice@company.com\"                          \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Inject user into context                                    \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502                              \u25bc                                        \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502 RATE LIMIT                                                    \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Check: alice@company.com has 45/60 requests remaining      \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Consume 1 token                                             \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Pass through                                                \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                              \u2502                                        \u2502   \u2502\n\u2502   \u2502                              \u25bc                                        \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502 AUDIT                                                         \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 - Log to audit trail:                                        \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502   { user: \"alice\", tool: \"github/create_issue\", time: ... }  \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   4. TOOL ROUTER                                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  - Parse tool ID: \"github/create_issue\"                             \u2502   \u2502\n\u2502   \u2502  - Extract backend: \"github\"                                         \u2502   \u2502\n\u2502   \u2502  - Extract tool name: \"create_issue\"                                \u2502   \u2502\n\u2502   \u2502  - Lookup backend in registry                                        \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   5. BACKEND (GitHub MCP)                                                    \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  - Backend type: MCP subprocess                                      \u2502   \u2502\n\u2502   \u2502  - Command: npx @modelcontextprotocol/server-github                 \u2502   \u2502\n\u2502   \u2502  - Forward MCP call to subprocess                                    \u2502   \u2502\n\u2502   \u2502  - Wait for response                                                 \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   6. EXTERNAL SERVICE (GitHub API)                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  - GitHub MCP server calls GitHub API                               \u2502   \u2502\n\u2502   \u2502  - POST https://api.github.com/repos/company/project/issues        \u2502   \u2502\n\u2502   \u2502  - Response: { \"number\": 456, \"url\": \"...\" }                        \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   7. RESPONSE FLOW (reverse through middleware)                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  - Audit: Log success                                                \u2502   \u2502\n\u2502   \u2502  - Rate limit: (no action)                                          \u2502   \u2502\n\u2502   \u2502  - Auth: (no action)                                                \u2502   \u2502\n\u2502   \u2502  - Logging: Log \"Completed req-123 in 1.2s, status: success\"        \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                     \u2502                                        \u2502\n\u2502                                     \u25bc                                        \u2502\n\u2502   8. CLIENT RESPONSE                                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  HTTP/1.1 200 OK                                                     \u2502   \u2502\n\u2502   \u2502  Content-Type: text/event-stream                                    \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502  event: message                                                      \u2502   \u2502\n\u2502   \u2502  data: {                                                             \u2502   \u2502\n\u2502   \u2502    \"jsonrpc\": \"2.0\",                                                \u2502   \u2502\n\u2502   \u2502    \"result\": {                                                      \u2502   \u2502\n\u2502   \u2502      \"content\": [{                                                  \u2502   \u2502\n\u2502   \u2502        \"type\": \"text\",                                              \u2502   \u2502\n\u2502   \u2502        \"text\": \"Created issue #456\"                                 \u2502   \u2502\n\u2502   \u2502      }],                                                            \u2502   \u2502\n\u2502   \u2502      \"metadata\": {                                                  \u2502   \u2502\n\u2502   \u2502        \"issue_number\": 456,                                         \u2502   \u2502\n\u2502   \u2502        \"url\": \"https://github.com/company/project/issues/456\"      \u2502   \u2502\n\u2502   \u2502      }                                                              \u2502   \u2502\n\u2502   \u2502    },                                                               \u2502   \u2502\n\u2502   \u2502    \"id\": \"req-123\"                                                  \u2502   \u2502\n\u2502   \u2502  }                                                                   \u2502   \u2502\n\u2502   \u2502                                                                       \u2502   \u2502\n\u2502   \u2502  event: done                                                         \u2502   \u2502\n\u2502   \u2502  data: {}                                                            \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#comparative-analysis","title":"Comparative Analysis","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#your-tool-libraries-vs-industry-patterns","title":"Your Tool Libraries vs. Industry Patterns","text":"Your Pattern Industry Standard Alignment toolindex.Searcher interface Register-on-init pattern Excellent Build-tag gating HashiCorp conditional compilation Same approach Adapter layer Clean Architecture boundaries Textbook Progressive disclosure Apple API design principles Ahead of most"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#comparison-with-other-go-mcp-servers","title":"Comparison with Other Go MCP Servers","text":"Project Transport Plugin System Your Advantage Official go-sdk stdio, SSE None Your tool* libraries mark3labs/mcp-go stdio, SSE Basic Your progressive disclosure viant/mcp stdio None Your modular architecture metatools-mcp stdio (SSE planned) Build-tag + interfaces Full stack orchestration <p>Unique value: No other Go MCP server has layered tool libraries with progressive disclosure, BM25 search, and code execution.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#references","title":"References","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#go-plugin-patterns","title":"Go Plugin Patterns","text":"<ul> <li>HashiCorp go-plugin - RPC-based plugin system</li> <li>Register-on-Init Pattern</li> <li>Interface Extension Pattern</li> <li>Clean Architecture with Plugins</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#mcp-implementations","title":"MCP Implementations","text":"<ul> <li>Official MCP Go SDK</li> <li>mark3labs/mcp-go</li> <li>viant/mcp</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-libraries","title":"Configuration Libraries","text":"<ul> <li>Koanf - Lighter Viper alternative</li> <li>Cobra - CLI framework</li> <li>Dependency Injection Patterns</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#api-design","title":"API Design","text":"<ul> <li>Progressive Disclosure</li> <li>Apple WWDC22: API Design</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-validation","title":"Architecture Validation","text":"<p>This section documents validation of the proposed architecture against industry best practices and real-world implementations, gathered from multiple research sources (Exa, Firecrawl, GitHub, Context7).</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#plugin-architecture-validation","title":"Plugin Architecture Validation \u2713","text":"<p>Sources: cekrem.github.io, blog.devcoffee.me, skoredin.pro, caffeinatedcoder.medium.com, reintech.io</p> <p>Our proposed architecture aligns with established Go plugin patterns:</p> Pattern Our Implementation Industry Validation Dependency Inversion ToolProvider interface abstracts concrete implementations \"High-level modules depend only on abstractions (interfaces)\" - Clean Architecture Interface-Driven Design <code>handlers/interfaces.go</code> defines stable contracts \"Define stable, simple core interfaces\" - Go best practices Plugin Registry ToolProviderRegistry with Register/Get methods \"Central hub for registering plugins with unique names\" - Plugin Registry pattern Plugin Factories Factory functions for backend creation \"A function that returns a new instance of a plugin\" - Factory pattern Graceful Shutdown Context-based cancellation propagation \"Critical feature for supporting context cancellation\" - Production patterns <p>RPC-Based Plugin Pattern (HashiCorp): Our Backend interface supports both in-process and RPC-based plugins, aligning with the industry-recommended approach for fault tolerance.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#middleware-chain-validation","title":"Middleware Chain Validation \u2713","text":"<p>Sources: go-chi/chi (21.7k\u2b50), grpc-ecosystem/go-grpc-middleware (6.7k\u2b50)</p> <p>The chi router's <code>chain.go</code> demonstrates the exact pattern we're proposing:</p> <pre><code>// From go-chi/chi - validates our decorator pattern\nfunc chain(middlewares []func(http.Handler) http.Handler, endpoint http.Handler) http.Handler {\n    if len(middlewares) == 0 {\n        return endpoint\n    }\n    h := middlewares[len(middlewares)-1](endpoint)\n    for i := len(middlewares) - 2; i &gt;= 0; i-- {\n        h = middlewares[i](h)\n    }\n    return h\n}\n</code></pre> <p>grpc-ecosystem interceptor categories match our proposed middleware types: - <code>auth/</code> \u2192 Our Auth middleware - <code>logging/</code> \u2192 Our Logging middleware - <code>ratelimit/</code> \u2192 Our RateLimit middleware - <code>recovery/</code> \u2192 Our Recovery/error handling - <code>retry/</code> \u2192 Our Circuit breaker patterns - <code>timeout/</code> \u2192 Our Timeout middleware</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#transport-layer-validation","title":"Transport Layer Validation \u2713","text":"<p>Sources: FreeCodeCamp, go-zero.dev, goa.design, Centrifugo</p> <p>SSE Implementation Requirements (validated): <pre><code>// Required headers for SSE - confirmed across all sources\nw.Header().Set(\"Content-Type\", \"text/event-stream\")\nw.Header().Set(\"Cache-Control\", \"no-cache\")\nw.Header().Set(\"Connection\", \"keep-alive\")\n</code></pre></p> <p>Multi-Transport Architecture Patterns: | Transport | Use Case | Our Support | |-----------|----------|-------------| | HTTP/REST | Request-response APIs | \u2713 Proposed | | SSE | Server-to-client streaming | \u2713 Proposed | | WebSocket | Bidirectional real-time | \u2713 Proposed | | gRPC | High-performance RPC | \u2713 Proposed | | stdio | Local MCP clients | \u2713 Current |</p> <p>Centrifugo WebSocket Scaling Patterns: Validates our approach of using shared state (Redis) for HA deployments with multiple transport instances.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#mcp-server-ecosystem-validation","title":"MCP Server Ecosystem Validation \u2713","text":"<p>Sources: viant/mcp, mcp-golang, go-mcp (Reddit), bytesizego.com, dev.to</p> <p>Active Go MCP implementations confirm the viability of our approach:</p> Project Stars Approach Notes viant/mcp Active Interface-based Validates our pattern mcp-golang Active Framework approach Similar extensibility goals mark3labs/mcp-go Popular Simple MCP Basic implementation <p>Key insight: No existing Go MCP server offers the combination of: - Multi-transport support (stdio + HTTP/SSE) - Pluggable tool providers - Configurable search strategies - Multi-backend aggregation - Middleware chain</p> <p>This confirms metatools-mcp's unique positioning in the ecosystem.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#configuration-library-validation","title":"Configuration Library Validation \u2713","text":"<p>Sources: Context7 library research, GitHub documentation</p> Library Reputation Code Snippets Recommendation Koanf High 23 \u2713 \"Cleaner, lighter alternative to Viper\" Cobra High 1,126+ \u2713 \"Powerful CLI with subcommands\" <p>This validates our choice of Koanf + Cobra over Viper for configuration management.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#validation-summary","title":"Validation Summary","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  ARCHITECTURE VALIDATION MATRIX                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Component              \u2502 Pattern Validated  \u2502 Source Quality    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Plugin Registry        \u2502 \u2713 Industry standard\u2502 High (multiple)   \u2502\n\u2502 Middleware Chain       \u2502 \u2713 go-chi pattern   \u2502 High (21.7k\u2b50)    \u2502\n\u2502 Transport Abstraction  \u2502 \u2713 Multi-impl refs  \u2502 High (docs + OSS) \u2502\n\u2502 SSE Implementation     \u2502 \u2713 Standard headers \u2502 High (RFC 6455)   \u2502\n\u2502 Backend Interface      \u2502 \u2713 DIP/Clean Arch   \u2502 High (canonical)  \u2502\n\u2502 Config Framework       \u2502 \u2713 Koanf + Cobra    \u2502 High (Context7)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Conclusion: The proposed architecture follows established best practices and patterns validated across multiple high-quality sources. The design is sustainable, maintainable, and aligned with the Go ecosystem's conventions.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementation-phases","title":"Implementation Phases","text":"<p>A detailed phased implementation plan has been created to break this proposal into manageable chunks. See implementation-phases.md for:</p> <ul> <li>Phase 1: CLI Framework &amp; Configuration (~2 weeks) - Cobra + Koanf foundation</li> <li>Phase 2: Transport Layer Abstraction (~2 weeks) - Stdio + SSE transports</li> <li>Phase 3: Tool Provider Registry (~1 week) - Plug-and-play tool registration</li> <li>Phase 4: Backend Registry (~2 weeks) - Multi-source tool aggregation</li> <li>Phase 5: Middleware Chain (~2 weeks) - Cross-cutting concerns</li> </ul> <p>MVP (Phases 1-3): ~5 weeks Full Implementation: ~9 weeks</p> <p>Each phase includes: - Detailed directory structure changes - Interface definitions with Go code - Implementation tasks with code examples - Verification criteria checklist - Migration notes for backward compatibility</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#component-library-analysis","title":"Component Library Analysis","text":"<p>A comprehensive analysis of the metatools component library ecosystem has been performed. See component-library-analysis.md for:</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#library-ecosystem-7-libraries","title":"Library Ecosystem (7 libraries)","text":"Library Version Purpose Changes Needed toolmodel v0.1.2 Core data models Add HTTP/gRPC backend kinds toolindex v0.1.8 Tool registry Add ListTools, OnChange tooldocs v0.1.10 Documentation Add BulkRegisterDocs toolrun v0.1.9 Execution Add HTTPExecutor, GRPCExecutor, ExecutionHook toolcode v0.1.10 Code execution Add EngineRegistry toolsearch v0.1.9 BM25 search No changes (already pluggable) toolruntime v0.1.10 Sandbox runtime Minor config additions"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#key-findings","title":"Key Findings","text":"<ol> <li>All changes are additive - No breaking changes to existing interfaces</li> <li>toolsearch is exemplary - Already implements pluggable pattern via <code>Searcher</code> interface</li> <li>toolrun needs most work - Core execution layer requires new executor interfaces</li> <li>Error taxonomy needed - Consistent error types across all libraries</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#dependency-graph","title":"Dependency Graph","text":"<pre><code>metatools-mcp\n    \u251c\u2500\u2500 toolcode \u2500\u2500\u252c\u2500\u2500 toolrun \u2500\u2500\u252c\u2500\u2500 toolindex \u2500\u2500 toolmodel \u2500\u2500 mcp-go-sdk\n    \u2502              \u2502             \u2502\n    \u2502              \u251c\u2500\u2500 tooldocs \u2500\u2524\n    \u2502              \u2502             \u2502\n    \u2514\u2500\u2500 toolruntime \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                   toolsearch (optional, implements toolindex.Searcher)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#multi-tenancy-extension","title":"Multi-Tenancy Extension","text":"<p>A comprehensive multi-tenancy design has been created as an extension to this architecture. See multi-tenancy.md for:</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#core-concepts","title":"Core Concepts","text":"Concept Description Pluggable Tenant Resolution JWT, API Key, Header, or custom resolvers Tenant-Aware Middleware Rate limiting, tool filtering, audit per tenant Tenant-Scoped Registries Isolated tool/backend views per tenant Configuration Hierarchy Defaults \u2192 Tier \u2192 Tenant overrides Isolation Strategies Shared, Namespace, or Process isolation"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture","title":"Architecture","text":"<pre><code>Request \u2192 Tenant Resolver \u2192 Tenant Middleware Chain \u2192 Tenant-Scoped Registry \u2192 Execution\n              \u2502                     \u2502                        \u2502\n              \u25bc                     \u25bc                        \u25bc\n         TenantContext      Rate Limit + Filter     Filtered Tools/Backends\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#key-interfaces","title":"Key Interfaces","text":"<pre><code>// Pluggable tenant identification\ntype TenantResolver interface {\n    Resolve(ctx context.Context, req *Request) (*TenantContext, error)\n}\n\n// Tenant configuration overrides\ntype TenantConfig struct {\n    AllowedTools    []string\n    DeniedTools     []string\n    AllowedBackends []string\n    RateLimits      *RateLimitConfig\n    Quotas          *QuotaConfig\n    Features        map[string]bool\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementation-priority","title":"Implementation Priority","text":"Phase Focus Duration Phase 1 Core multi-tenancy (Tenant, TenantContext, resolvers) 2 weeks Phase 2 Tenant-aware middleware (rate limit, filter, audit) 1 week Phase 3 Tenant storage (memory, Postgres implementations) 1 week Phase 4 Advanced features (scoped registries, isolation strategies) 2 weeks"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#extension-point-catalog","title":"Extension Point Catalog","text":"<p>Comprehensive architecture analysis has revealed that the metatools ecosystem is already 85%+ pluggable. The following 13 extension points exist across the component libraries, ready for configuration and exposure.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#critical-finding","title":"Critical Finding","text":"<p>The architecture is NOT a monolith to be refactored. It is a mature, layered, pluggable architecture that needs: - Exposure - Make internal extension points accessible via configuration - Configuration - Add CLI + config layer (Cobra + Koanf) - Documentation - Catalog the 13 extension points with examples - Examples - Show how to extend each interface</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#extension-points-by-library","title":"Extension Points by Library","text":"# Interface Library Purpose Pluggability 1 <code>SchemaValidator</code> toolmodel JSON Schema validation \u2705 Interface-based 2 <code>Searcher</code> toolindex Tool search strategy \u2705 Interface-based 3 <code>BackendSelector</code> toolindex Multi-backend selection \u2705 Function-based 4 <code>Store</code> tooldocs Documentation storage \u2705 Interface-based 5 <code>ToolResolver</code> tooldocs Tool resolution for docs \u2705 Function-based 6 <code>Runner</code> toolrun Tool execution \u2705 Interface-based 7 <code>MCPExecutor</code> toolrun MCP backend executor \u2705 Interface-based 8 <code>ProviderExecutor</code> toolrun Provider backend executor \u2705 Interface-based 9 <code>LocalRegistry</code> toolrun Local handler lookup \u2705 Interface-based 10 <code>Backend</code> toolruntime Sandbox isolation backend \u2705 Interface-based 11 <code>ToolGateway</code> toolruntime Sandbox tool access \u2705 Interface-based 12 <code>Logger</code> toolcode Execution logging \u2705 Interface-based 13 <code>Engine</code> toolcode Language-specific execution \u2705 Interface-based"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#interface-definitions","title":"Interface Definitions","text":"<pre><code>// 1. SchemaValidator - JSON Schema validation strategy\ntype SchemaValidator interface {\n    ValidateSchema(schema map[string]any) error\n    ValidateInput(schema map[string]any, input map[string]any) error\n}\n\n// 2. Searcher - Tool search strategy (toolsearch.BM25Searcher implements this)\ntype Searcher interface {\n    Search(query string, limit int) ([]SearchResult, error)\n    Close() error\n}\n\n// 3. BackendSelector - Multi-backend selection policy\ntype BackendSelector func(tool Tool, backends []ToolBackend) ToolBackend\n\n// 4. Store - Documentation storage\ntype Store interface {\n    DescribeTool(id string, level DetailLevel) (ToolDoc, error)\n    ListExamples(id string, max int) ([]ToolExample, error)\n    RegisterDoc(id string, entry DocEntry) error\n}\n\n// 5. ToolResolver - Tool resolution for documentation\ntype ToolResolver func(id string) (*toolmodel.Tool, error)\n\n// 6. Runner - Tool execution orchestration\ntype Runner interface {\n    Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)\n    RunStream(ctx context.Context, toolID string, args map[string]any) (&lt;-chan StreamEvent, error)\n    RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error)\n}\n\n// 7. MCPExecutor - MCP backend execution\ntype MCPExecutor interface {\n    CallTool(ctx context.Context, server, tool string, args map[string]any) (any, error)\n    CallToolStream(ctx context.Context, server, tool string, args map[string]any) (&lt;-chan StreamEvent, error)\n}\n\n// 8. ProviderExecutor - Provider backend execution\ntype ProviderExecutor interface {\n    CallTool(ctx context.Context, provider, tool string, args map[string]any) (any, error)\n    CallToolStream(ctx context.Context, provider, tool string, args map[string]any) (&lt;-chan StreamEvent, error)\n}\n\n// 9. LocalRegistry - Local handler lookup\ntype LocalRegistry interface {\n    Get(name string) (LocalHandler, bool)\n}\n\n// 10. Backend - Sandbox isolation backend (10 implementations exist)\ntype Backend interface {\n    Name() string\n    Execute(ctx context.Context, req ExecuteRequest) (ExecuteResult, error)\n    Capabilities() BackendCapabilities\n    Close() error\n}\n\n// 11. ToolGateway - Tool access from sandboxed code\ntype ToolGateway interface {\n    SearchTools(ctx context.Context, query string, limit int) ([]SearchResult, error)\n    ListNamespaces(ctx context.Context) ([]string, error)\n    DescribeTool(ctx context.Context, id string, level DetailLevel) (ToolDoc, error)\n    ListToolExamples(ctx context.Context, id string, max int) ([]ToolExample, error)\n    RunTool(ctx context.Context, toolID string, args map[string]any) (any, error)\n    RunChain(ctx context.Context, steps []ChainStep) (any, []StepResult, error)\n}\n\n// 12. Logger - Execution logging\ntype Logger interface {\n    Info(msg string, fields ...any)\n    Error(msg string, fields ...any)\n    Debug(msg string, fields ...any)\n}\n\n// 13. Engine - Language-specific code execution\ntype Engine interface {\n    Name() string\n    Execute(ctx context.Context, code string, gateway ToolGateway) (any, error)\n    Capabilities() EngineCapabilities\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#existing-implementations","title":"Existing Implementations","text":"Interface Built-in Implementations <code>SchemaValidator</code> <code>DefaultValidator</code> (jsonschema-go) <code>Searcher</code> <code>BM25Searcher</code> (toolsearch, uses Bleve) <code>BackendSelector</code> <code>DefaultBackendSelector</code> (local &gt; provider &gt; mcp) <code>Store</code> <code>InMemoryStore</code> <code>Runner</code> <code>DefaultRunner</code> <code>Backend</code> 10 implementations: unsafe, docker, containerd, kubernetes, firecracker, kata, gvisor, wasm, temporal, remote <code>ToolGateway</code> <code>toolcodeengine.WrapTools()</code> adapter <code>Engine</code> Language-specific engines (JS, Python, etc.)"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         METATOOLS PLUGGABLE ARCHITECTURE                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                         MCP Protocol Layer                                  \u2502 \u2502\n\u2502  \u2502              Transport: Stdio (current) | SSE | WebSocket                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                     \u2502                                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                         metatools-mcp Server                                \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 \u2502\n\u2502  \u2502  \u2502  Handlers   \u2502  \u2502  Adapters   \u2502  \u2502   Config    \u2502  \u2502    Middleware       \u2502\u2502 \u2502\n\u2502  \u2502  \u2502  (MCP ops)  \u2502  \u2502  (bridge)   \u2502  \u2502  (YAML/env) \u2502  \u2502  (auth/rate/log)   \u2502\u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502            \u2502                \u2502                                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                    Component Library Layer                                   \u2502 \u2502\n\u2502  \u2502                                                                              \u2502 \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502 \u2502\n\u2502  \u2502   \u2502  toolcode    \u2502\u2500\u2500\u2500\u25b6\u2502   toolrun    \u2502\u2500\u2500\u2500\u25b6\u2502  toolindex   \u2502                  \u2502 \u2502\n\u2502  \u2502   \u2502  [13:Engine] \u2502    \u2502  [6-9:Exec]  \u2502    \u2502  [2-3:Search]\u2502                  \u2502 \u2502\n\u2502  \u2502   \u2502  [12:Logger] \u2502    \u2502              \u2502    \u2502              \u2502                  \u2502 \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502 \u2502\n\u2502  \u2502          \u2502                                       \u2502                          \u2502 \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502 \u2502\n\u2502  \u2502   \u2502 toolruntime  \u2502    \u2502   tooldocs   \u2502    \u2502  toolmodel   \u2502                  \u2502 \u2502\n\u2502  \u2502   \u2502 [10:Backend] \u2502    \u2502  [4-5:Store] \u2502    \u2502 [1:Validator]\u2502                  \u2502 \u2502\n\u2502  \u2502   \u2502 [11:Gateway] \u2502    \u2502              \u2502    \u2502              \u2502                  \u2502 \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502 \u2502\n\u2502  \u2502                                                                              \u2502 \u2502\n\u2502  \u2502              toolsearch (optional, implements Searcher #2)                  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                    Sandbox/Runtime Layer (10 backends)                      \u2502 \u2502\n\u2502  \u2502   unsafe | docker | containerd | k8s | firecracker | kata | gvisor | wasm  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#revised-implementation-timeline","title":"Revised Implementation Timeline","text":"<p>Based on the architecture discovery, the implementation timeline has been reduced from 9 weeks to 6-7 weeks because the core pluggable architecture already exists.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#updated-phase-summary","title":"Updated Phase Summary","text":"Phase Focus Duration Rationale Phase 1 CLI + Config 2 weeks Add Cobra CLI and Koanf configuration to expose existing extension points Phase 2 Transport Layer 1-2 weeks Transport interface exists conceptually, needs explicit abstraction Phase 3 Public APIs 1 week Export internal packages, document extension points, provide examples Phase 4 Backend Integration 2 weeks Complete Docker/WASM integration, backend registry configuration Total 6-7 weeks 25% reduction from original 9-week estimate"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#key-insight","title":"Key Insight","text":"<p>The original proposal assumed significant refactoring work. The architecture discovery revealed:</p> <ol> <li>13 extension points already exist as Go interfaces</li> <li>10 sandbox backends already implemented (docker, k8s, wasm, etc.)</li> <li>Multi-backend per tool already supported with <code>BackendSelector</code></li> <li>Progressive disclosure already implemented (summary/schema/full)</li> <li>Security profiles already exist (dev/standard/hardened)</li> </ol> <p>The work is primarily configuration and exposure, not architecture redesign.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#phase-1-detailed-plan-cli-config","title":"Phase 1 Detailed Plan (CLI + Config)","text":"<p>Goal: Make the 13 extension points configurable via YAML and CLI flags.</p> <pre><code># config.yaml - Complete configuration schema\nserver:\n  transport: stdio  # stdio | sse | websocket\n  port: 8080        # For HTTP transports\n\n# Extension Point #2: Searcher\nsearch:\n  strategy: bm25    # bm25 | simple | semantic\n  config:\n    name_boost: 3.0\n    tags_boost: 2.0\n\n# Extension Point #3: BackendSelector\nbackends:\n  selector: default  # default | latency | cost | custom\n  priority: [local, provider, mcp]\n\n# Extension Point #10: Runtime Backend\nruntime:\n  backend: docker    # unsafe | docker | k8s | wasm | gvisor\n  profile: standard  # dev | standard | hardened\n\n# Extension Point #12: Logger\nlogging:\n  level: info\n  format: json\n</code></pre> <p>CLI Commands: <pre><code>metatools serve --transport=stdio                    # Default MCP mode\nmetatools serve --transport=sse --port=8080          # HTTP/SSE mode\nmetatools serve --config=/path/to/config.yaml        # Full configuration\nmetatools list-tools                                 # List registered tools\nmetatools describe &lt;tool-id&gt;                         # Show tool documentation\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-evaluation","title":"Architecture Evaluation","text":"<p>A comprehensive evaluation against championship-level implementations has been performed. See architecture-evaluation.md for:</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#championship-implementations-analyzed","title":"Championship Implementations Analyzed","text":"Project Stars Key Patterns Tencent WeKnora 12,566 Multi-tenant RAG, layered architecture go-kratos/blades 700 Tool interfaces, middleware chain Official MCP Go SDK - Reference implementation patterns Google ADK for Go - A2A protocol, multi-agent fastmcp 22,398 Rapid MCP server development"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#current-position-85-championship-level","title":"Current Position: 85% Championship Level","text":"Category Score Status Core Architecture 95% \u2705 Excellent Pluggability 90% \u2705 13 extension points Security 95% \u2705 10 backends, 3 profiles Observability 40% \u26a0\ufe0f Needs OpenTelemetry Semantic Search 60% \u26a0\ufe0f BM25 only Protocol Coverage 70% \u26a0\ufe0f Missing resources/prompts"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#recommended-new-libraries","title":"Recommended New Libraries","text":"Library Purpose Priority toolobserve OpenTelemetry tracing + metrics High toolsemantic Vector-based semantic search Medium toolresource MCP Resources support Medium toolgateway Auth, rate limit, analytics proxy Medium"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#path-to-championship","title":"Path to Championship","text":"<ol> <li>Observability (toolobserve) - 2 weeks</li> <li>Semantic search (toolsemantic) - 2 weeks</li> <li>MCP Resources (toolresource) - 2 weeks</li> <li>Gateway/Proxy (toolgateway) - 2 weeks</li> </ol> <p>Total to 95%+ championship level: ~8 weeks</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#protocol-agnostic-tools","title":"Protocol-Agnostic Tools","text":"<p>A comprehensive proposal for protocol-agnostic tool exposure and composable toolsets has been created. See protocol-agnostic-tools.md for:</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#key-capabilities","title":"Key Capabilities","text":"Capability Description Protocol-agnostic interface Canonical tool representation independent of source or destination protocol Bidirectional adapters Convert tools between MCP, OpenAI, Anthropic, LangChain formats Toolset composition Create curated tool collections from multiple sources Multi-transport exposure Serve toolsets via MCP, direct client interfaces, REST, or A2A"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#proposed-new-libraries","title":"Proposed New Libraries","text":"Library Purpose tooladapter Canonical tool abstraction with protocol adapters toolset Composable tool collections with access control"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#adapter-support-matrix","title":"Adapter Support Matrix","text":"Protocol Import Export Notes MCP \u2705 \u2705 Full JSON Schema support OpenAI \u2705 \u2705 Includes strict mode Anthropic \u2705 \u2705 input_schema mapping LangChain \u2705 \u2705 Zod schema conversion OpenAPI \u2705 - Operation extraction"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#toolset-composition-pattern","title":"Toolset Composition Pattern","text":"<pre><code>// Create customer-specific toolset from multiple sources\ncustomerSet, _ := toolset.NewBuilder(\"customer-acme\").\n    FromRegistry(registry).\n    WithTools(\n        \"mcp.support.create_ticket\",\n        \"mcp.docs.search\",\n        \"openai.functions.analyze\",\n    ).\n    WithPolicy(&amp;toolset.AccessPolicy{\n        AllowedTenants: []string{\"acme-corp\"},\n    }).\n    Build()\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#implementation-timeline","title":"Implementation Timeline","text":"<ul> <li>Phase 1: Core adapter library (2 weeks)</li> <li>Phase 2: Toolset composition (2 weeks)</li> <li>Phase 3: Multi-transport exposure (2 weeks)</li> </ul> <p>Total: ~6 weeks</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#versioning-strategy","title":"Versioning Strategy","text":"<p>Critical Finding: Tool versioning causes 60% of production agent failures. Backward compatibility is the foundation of agent ecosystem stability.</p> <p>A comprehensive versioning strategy is essential for fast rollforward, safe rollback, and multi-version coexistence.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#versioning-layers","title":"Versioning Layers","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        VERSIONING ARCHITECTURE                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                               \u2502\n\u2502  Layer 1: MCP PROTOCOL VERSION                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Version negotiation during initialization                                \u2502 \u2502\n\u2502  \u2502 Current: 2025-11-25 | Supported: [2024-11-05, 2025-03-26, 2025-06-18]  \u2502 \u2502\n\u2502  \u2502 \u2192 Server advertises supported versions                                   \u2502 \u2502\n\u2502  \u2502 \u2192 Client selects compatible version                                      \u2502 \u2502\n\u2502  \u2502 \u2192 Single version used for session                                        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  Layer 2: TOOL SCHEMA VERSION                                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Per-tool semantic versioning (MAJOR.MINOR.PATCH)                        \u2502 \u2502\n\u2502  \u2502 \u2192 MAJOR: Breaking input/output schema changes                           \u2502 \u2502\n\u2502  \u2502 \u2192 MINOR: New optional parameters, backward-compatible                   \u2502 \u2502\n\u2502  \u2502 \u2192 PATCH: Bug fixes, documentation updates                                \u2502 \u2502\n\u2502  \u2502 Multiple versions can be active simultaneously                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  Layer 3: BACKEND VERSION                                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 External API versions (OpenAI v1/v2, GitHub REST/GraphQL)               \u2502 \u2502\n\u2502  \u2502 \u2192 Version-specific adapters                                              \u2502 \u2502\n\u2502  \u2502 \u2192 Automatic version detection                                            \u2502 \u2502\n\u2502  \u2502 \u2192 Graceful degradation                                                   \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  Layer 4: CONFIGURATION VERSION                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Config file schema versioning                                            \u2502 \u2502\n\u2502  \u2502 \u2192 Version field at config root                                           \u2502 \u2502\n\u2502  \u2502 \u2192 Migration scripts for version upgrades                                 \u2502 \u2502\n\u2502  \u2502 \u2192 Validation against versioned schema                                    \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2502  Layer 5: DEPLOYMENT VERSION                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Blue/green, canary deployment support                                    \u2502 \u2502\n\u2502  \u2502 \u2192 Multiple server versions running simultaneously                       \u2502 \u2502\n\u2502  \u2502 \u2192 Traffic splitting by version                                          \u2502 \u2502\n\u2502  \u2502 \u2192 Instant rollback capability                                           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#mcp-protocol-version-negotiation","title":"MCP Protocol Version Negotiation","text":"<pre><code>// toolversion/protocol.go\n\n// ProtocolVersions lists supported MCP specification versions\nvar ProtocolVersions = []string{\n    \"2025-11-25\",  // Latest (default)\n    \"2025-06-18\",  // OAuth 2.1 authorization\n    \"2025-03-26\",  // Batching (later removed)\n    \"2024-11-05\",  // Initial stable release\n}\n\n// VersionNegotiator handles protocol version selection\ntype VersionNegotiator struct {\n    supported []string\n    preferred string\n}\n\nfunc (n *VersionNegotiator) Negotiate(clientVersions []string) (string, error) {\n    // Find best matching version\n    for _, preferred := range n.supported {\n        for _, client := range clientVersions {\n            if preferred == client {\n                return preferred, nil\n            }\n        }\n    }\n    return \"\", ErrNoCompatibleVersion\n}\n\n// Server initialization with version negotiation\nfunc (s *Server) Initialize(ctx context.Context, req *mcp.InitializeRequest) (*mcp.InitializeResult, error) {\n    version, err := s.negotiator.Negotiate(req.ProtocolVersions)\n    if err != nil {\n        return nil, err\n    }\n\n    s.activeVersion = version\n\n    return &amp;mcp.InitializeResult{\n        ProtocolVersion: version,\n        ServerInfo: mcp.ServerInfo{\n            Name:    \"metatools-mcp\",\n            Version: s.serverVersion,\n        },\n        Capabilities: s.capabilitiesForVersion(version),\n    }, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#tool-schema-versioning","title":"Tool Schema Versioning","text":"<pre><code>// toolversion/tool.go\n\n// VersionedTool represents a tool with semantic versioning\ntype VersionedTool struct {\n    toolmodel.Tool\n\n    Version       semver.Version    // e.g., 2.1.0\n    MinVersion    semver.Version    // Minimum compatible version\n    Deprecated    bool\n    DeprecatedMsg string\n    Sunset        time.Time         // When this version will be removed\n}\n\n// ToolVersionRegistry manages multiple versions of tools\ntype ToolVersionRegistry struct {\n    tools map[string]map[semver.Version]*VersionedTool  // name -&gt; version -&gt; tool\n    mu    sync.RWMutex\n}\n\n// Register adds a versioned tool\nfunc (r *ToolVersionRegistry) Register(tool *VersionedTool) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    name := tool.Name()\n    if r.tools[name] == nil {\n        r.tools[name] = make(map[semver.Version]*VersionedTool)\n    }\n\n    r.tools[name][tool.Version] = tool\n    return nil\n}\n\n// Resolve finds the best matching tool version\nfunc (r *ToolVersionRegistry) Resolve(name string, constraint string) (*VersionedTool, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    versions, ok := r.tools[name]\n    if !ok {\n        return nil, ErrToolNotFound\n    }\n\n    // Parse constraint (e.g., \"&gt;=1.0.0 &lt;2.0.0\", \"^1.2.3\", \"~1.2.0\")\n    c, err := semver.NewConstraint(constraint)\n    if err != nil {\n        // No constraint = latest stable\n        return r.latestStable(name)\n    }\n\n    // Find best matching version\n    var best *VersionedTool\n    for ver, tool := range versions {\n        if c.Check(&amp;ver) &amp;&amp; !tool.Deprecated {\n            if best == nil || ver.GreaterThan(&amp;best.Version) {\n                best = tool\n            }\n        }\n    }\n\n    if best == nil {\n        return nil, ErrNoCompatibleVersion\n    }\n    return best, nil\n}\n\n// ListVersions returns all versions of a tool\nfunc (r *ToolVersionRegistry) ListVersions(name string) []VersionInfo {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    var versions []VersionInfo\n    for ver, tool := range r.tools[name] {\n        versions = append(versions, VersionInfo{\n            Version:    ver,\n            Deprecated: tool.Deprecated,\n            Sunset:     tool.Sunset,\n        })\n    }\n\n    sort.Slice(versions, func(i, j int) bool {\n        return versions[i].Version.GreaterThan(&amp;versions[j].Version)\n    })\n\n    return versions\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#schema-evolution-compatibility","title":"Schema Evolution &amp; Compatibility","text":"<pre><code>// toolversion/schema.go\n\n// CompatibilityMode defines schema evolution rules\ntype CompatibilityMode string\n\nconst (\n    // BACKWARD: New schema can read old data\n    CompatibilityBackward CompatibilityMode = \"BACKWARD\"\n    // FORWARD: Old schema can read new data\n    CompatibilityForward CompatibilityMode = \"FORWARD\"\n    // FULL: Both backward and forward compatible\n    CompatibilityFull CompatibilityMode = \"FULL\"\n    // NONE: No compatibility guarantees\n    CompatibilityNone CompatibilityMode = \"NONE\"\n)\n\n// SchemaEvolutionRules defines allowed changes per compatibility mode\nvar SchemaEvolutionRules = map[CompatibilityMode]EvolutionRules{\n    CompatibilityBackward: {\n        AllowAddOptionalField:    true,\n        AllowRemoveOptionalField: false,\n        AllowAddRequiredField:    false,  // Breaks old clients\n        AllowRemoveRequiredField: true,   // Old clients still work\n        AllowFieldTypeWidening:   true,   // int \u2192 long\n        AllowFieldTypeNarrowing:  false,\n    },\n    CompatibilityForward: {\n        AllowAddOptionalField:    false,  // Old readers can't handle\n        AllowRemoveOptionalField: true,\n        AllowAddRequiredField:    true,\n        AllowRemoveRequiredField: false,\n        AllowFieldTypeWidening:   false,\n        AllowFieldTypeNarrowing:  true,\n    },\n    CompatibilityFull: {\n        AllowAddOptionalField:    true,   // Only safe change\n        AllowRemoveOptionalField: false,\n        AllowAddRequiredField:    false,\n        AllowRemoveRequiredField: false,\n        AllowFieldTypeWidening:   false,\n        AllowFieldTypeNarrowing:  false,\n    },\n}\n\n// SchemaValidator checks if schema change is compatible\ntype SchemaValidator struct {\n    mode CompatibilityMode\n}\n\nfunc (v *SchemaValidator) ValidateChange(old, new *jsonschema.Schema) error {\n    rules := SchemaEvolutionRules[v.mode]\n    changes := v.detectChanges(old, new)\n\n    for _, change := range changes {\n        if !rules.IsAllowed(change) {\n            return &amp;CompatibilityError{\n                Change: change,\n                Mode:   v.mode,\n            }\n        }\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#version-aware-tool-resolution","title":"Version-Aware Tool Resolution","text":"<pre><code>// toolversion/resolver.go\n\n// VersionedToolRequest specifies version constraints\ntype VersionedToolRequest struct {\n    Name           string\n    VersionSpec    string  // Semver constraint: \"^1.0.0\", \"&gt;=2.0.0\", \"latest\"\n    PreferStable   bool\n    AllowPrerelease bool\n}\n\n// Resolver determines which tool version to use\ntype Resolver struct {\n    registry *ToolVersionRegistry\n    cache    Cache\n    metrics  VersionMetrics\n}\n\nfunc (r *Resolver) Resolve(ctx context.Context, req VersionedToolRequest) (*VersionedTool, error) {\n    // Check cache first\n    cacheKey := fmt.Sprintf(\"resolve:%s:%s\", req.Name, req.VersionSpec)\n    if cached, ok := r.cache.Get(ctx, cacheKey); ok {\n        return cached.(*VersionedTool), nil\n    }\n\n    var tool *VersionedTool\n    var err error\n\n    switch req.VersionSpec {\n    case \"\", \"latest\":\n        tool, err = r.registry.Resolve(req.Name, \"*\")\n    default:\n        tool, err = r.registry.Resolve(req.Name, req.VersionSpec)\n    }\n\n    if err != nil {\n        return nil, err\n    }\n\n    // Warn if using deprecated version\n    if tool.Deprecated {\n        r.metrics.DeprecatedToolUsage.Inc(labels{\n            \"tool\":    req.Name,\n            \"version\": tool.Version.String(),\n        })\n        log.Warn(\"Using deprecated tool version\",\n            \"tool\", req.Name,\n            \"version\", tool.Version,\n            \"message\", tool.DeprecatedMsg,\n            \"sunset\", tool.Sunset,\n        )\n    }\n\n    r.cache.Set(ctx, cacheKey, tool, 5*time.Minute)\n    return tool, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#multi-version-deployment","title":"Multi-Version Deployment","text":"<pre><code>// toolversion/deployment.go\n\n// DeploymentVersion represents a running server version\ntype DeploymentVersion struct {\n    ServerVersion string\n    GitCommit     string\n    BuildTime     time.Time\n    Features      []string\n}\n\n// VersionRouter routes requests to appropriate server versions\ntype VersionRouter struct {\n    versions map[string]*ServerInstance\n    weights  map[string]int  // Traffic percentage\n}\n\n// Route selects server version based on routing rules\nfunc (r *VersionRouter) Route(ctx context.Context, req *Request) (*ServerInstance, error) {\n    // Check for explicit version header\n    if ver := req.Header.Get(\"X-Tool-Version\"); ver != \"\" {\n        if instance, ok := r.versions[ver]; ok {\n            return instance, nil\n        }\n    }\n\n    // Check for client-specified version preference\n    if pref := ctx.Value(versionPreferenceKey); pref != nil {\n        if instance, ok := r.versions[pref.(string)]; ok {\n            return instance, nil\n        }\n    }\n\n    // Weighted random selection (for canary deployments)\n    return r.weightedSelect(), nil\n}\n\n// DeploymentManager handles version lifecycle\ntype DeploymentManager struct {\n    router   *VersionRouter\n    registry *ToolVersionRegistry\n}\n\n// Canary starts a canary deployment\nfunc (m *DeploymentManager) Canary(newVersion string, percentage int) error {\n    m.router.weights[newVersion] = percentage\n    m.router.weights[\"stable\"] = 100 - percentage\n    return nil\n}\n\n// Promote makes a version the new stable\nfunc (m *DeploymentManager) Promote(version string) error {\n    m.router.weights = map[string]int{version: 100}\n    return nil\n}\n\n// Rollback reverts to previous stable version\nfunc (m *DeploymentManager) Rollback() error {\n    // Instant traffic shift to previous stable\n    return m.Promote(m.previousStable)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#version-configuration","title":"Version Configuration","text":"<pre><code># metatools.yaml\nversion: \"1.0.0\"  # Config schema version\n\nserver:\n  version: \"2.3.1\"\n\nprotocol:\n  supported_versions:\n    - \"2025-11-25\"\n    - \"2025-06-18\"\n    - \"2024-11-05\"\n  default_version: \"2025-11-25\"\n\ntools:\n  versioning:\n    enabled: true\n    compatibility_mode: BACKWARD  # BACKWARD, FORWARD, FULL, NONE\n\n    # Per-tool version configuration\n    versions:\n      github/create_issue:\n        - version: \"2.0.0\"\n          status: stable\n        - version: \"1.5.0\"\n          status: deprecated\n          sunset: \"2026-06-01\"\n          message: \"Use v2.0.0 - improved error handling\"\n        - version: \"1.0.0\"\n          status: sunset  # Will be removed\n\n    # Version resolution rules\n    resolution:\n      prefer_stable: true\n      allow_prerelease: false\n      default_constraint: \"^\"  # Caret = compatible with major version\n\ndeployment:\n  strategy: canary  # blue_green, canary, rolling\n\n  canary:\n    initial_percentage: 5\n    increment: 10\n    interval: 5m\n    rollback_threshold:\n      error_rate: 0.05\n      latency_p99: 2s\n\n  versions:\n    stable: \"2.3.0\"\n    canary: \"2.3.1\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#mcp-tool-registration-with-versioning","title":"MCP Tool Registration with Versioning","text":"<pre><code>// Expose versioned tools via MCP\nfunc (s *Server) listTools(ctx context.Context) ([]mcp.Tool, error) {\n    var tools []mcp.Tool\n\n    for _, vt := range s.versionRegistry.AllLatestStable() {\n        tool := vt.Tool.ToMCP()\n\n        // Add version metadata as annotations\n        tool.Annotations = map[string]any{\n            \"version\":      vt.Version.String(),\n            \"min_version\":  vt.MinVersion.String(),\n            \"deprecated\":   vt.Deprecated,\n            \"sunset\":       vt.Sunset,\n        }\n\n        // Version in description for AI visibility\n        if vt.Deprecated {\n            tool.Description = fmt.Sprintf(\"[DEPRECATED: %s] %s\",\n                vt.DeprecatedMsg, tool.Description)\n        }\n\n        tools = append(tools, tool)\n    }\n\n    return tools, nil\n}\n\n// Handle tool calls with version resolution\nfunc (s *Server) callTool(ctx context.Context, req *mcp.CallToolRequest) (*mcp.CallToolResult, error) {\n    // Extract version from request (if specified)\n    versionSpec := \"latest\"\n    if v, ok := req.Arguments[\"_version\"].(string); ok {\n        versionSpec = v\n        delete(req.Arguments, \"_version\")  // Remove meta-argument\n    }\n\n    // Resolve tool version\n    tool, err := s.resolver.Resolve(ctx, VersionedToolRequest{\n        Name:        req.Name,\n        VersionSpec: versionSpec,\n    })\n    if err != nil {\n        return nil, err\n    }\n\n    // Execute with resolved version\n    return tool.Execute(ctx, req.Arguments)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#versioning-best-practices","title":"Versioning Best Practices","text":"Rule Rationale Never break existing function signatures Old clients must continue working Add optional parameters, never remove required ones Backward compatibility Don't delete safety rules or constraints Maintain security guarantees Deprecate before removing Give users migration time Version from day one Adding versioning later is exponentially harder Announce breaking changes in MAJOR Clear semantic meaning Maintain audit trails for version changes Compliance and debugging"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#proposed-library-toolversion","title":"Proposed Library: <code>toolversion</code>","text":"<pre><code>toolversion/\n\u251c\u2500\u2500 protocol.go        # MCP protocol version negotiation\n\u251c\u2500\u2500 semver.go          # Semantic version parsing and comparison\n\u251c\u2500\u2500 registry.go        # Multi-version tool registry\n\u251c\u2500\u2500 resolver.go        # Version constraint resolution\n\u251c\u2500\u2500 schema.go          # Schema evolution validation\n\u251c\u2500\u2500 compatibility.go   # Compatibility mode enforcement\n\u251c\u2500\u2500 deployment.go      # Blue/green, canary deployment support\n\u251c\u2500\u2500 migration.go       # Version migration helpers\n\u2514\u2500\u2500 metrics.go         # Version usage metrics\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#multi-language-extensibility","title":"Multi-Language Extensibility","text":"<p>Key Insight: The pluggable architecture is not limited to Go implementations. Any component defined by an interface can be implemented in any programming language through standardized interface contracts.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#architecture-principle","title":"Architecture Principle","text":"<p>All extension points in this architecture (Transport, Searcher, Cache, Backend, etc.) are defined as Go interfaces. These interfaces can be implemented in any language using:</p> <ol> <li>gRPC + Protocol Buffers (recommended) - Battle-tested, used by HashiCorp Terraform/Vault</li> <li>WebAssembly Component Model - Sandboxed, portable, no network overhead</li> <li>JSON-RPC over stdio - Simple, any executable works</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#use-cases","title":"Use Cases","text":"Component Preferred Language Rationale Embedder Python Rich ML ecosystem (PyTorch, sentence-transformers) VectorIndex Rust SIMD performance, memory safety Reranker Python Hugging Face cross-encoders KnowledgeGraph Python/Java Neo4j, NetworkX bindings Custom Adapter TypeScript Existing MCP servers, quick prototypes"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#interface-contracts-via-protocol-buffers","title":"Interface Contracts via Protocol Buffers","text":"<p>All Go interfaces are documented as Protocol Buffer service definitions, enabling automatic SDK generation for Python, Rust, TypeScript, Java, and more.</p> <pre><code>// Example: Embedder interface as protobuf\nservice Embedder {\n  rpc Embed(EmbedRequest) returns (EmbedResponse);\n  rpc EmbedBatch(EmbedBatchRequest) returns (EmbedBatchResponse);\n  rpc Info(InfoRequest) returns (EmbedderInfo);\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#full-specification","title":"Full Specification","text":"<p>See ROADMAP.md Section 8: Multi-Language Extensibility for: - Complete gRPC plugin architecture with HashiCorp go-plugin patterns - WebAssembly Interface Types (WIT) definitions - JSON-RPC fallback for simple plugins - SDK generation for Python, Rust, TypeScript - Configuration examples for multi-language plugins</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#open-questions","title":"Open Questions","text":"<ol> <li>ToolProvider interface - Does the proposed interface feel right for plug-and-play tools?</li> <li>Middleware chain - Useful now, or defer until needed?</li> <li>Backend configuration - YAML-driven or code-only for now?</li> <li>Semantic search - Priority for vector/embedding-based search strategy?</li> <li>Multi-tenancy - Which isolation strategy (shared, namespace, process) is primary target?</li> <li>Versioning compatibility mode - Should BACKWARD be the default, or FULL for maximum safety?</li> <li>MCP protocol versions - How far back should we support? (2024-11-05 is the oldest stable)</li> <li>Tool version in tool names - Should version be part of tool name (<code>github/create_issue@2</code>) or metadata?</li> <li>Breaking change policy - What's the minimum deprecation window before sunset?</li> <li>Multi-language plugins - Should gRPC be the primary contract mechanism, or prioritize WASM for sandboxing?</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#changelog","title":"Changelog","text":"Date Change 2026-01-27 Initial draft 2026-01-27 Added Multi-Backend Architecture section with diagrams 2026-01-27 Expanded Middleware Chain section with pluggable design 2026-01-27 Added comprehensive Transport Layer section with all protocols 2026-01-27 Added End-to-End Examples section with 5 real-world scenarios 2026-01-27 Added Architecture Validation section with industry pattern verification 2026-01-27 Created detailed Implementation Phases document (see implementation-phases.md) 2026-01-27 Added Component Library Analysis for all 7 tool* libraries (see component-library-analysis.md) 2026-01-28 Added Multi-Tenancy Extension for pluggable tenant isolation (see multi-tenancy.md) 2026-01-28 Added Extension Point Catalog documenting 13 existing pluggable interfaces across all component libraries 2026-01-28 Added Revised Implementation Timeline (6-7 weeks, 25% reduction from original 9-week estimate) 2026-01-28 Key finding: Architecture is already 85%+ pluggable - needs exposure and configuration, not redesign 2026-01-28 Added Architecture Evaluation comparing against 5 championship-level implementations 2026-01-28 Identified 4 potential new libraries: toolobserve, toolsemantic, toolresource, toolgateway 2026-01-28 Added Protocol-Agnostic Tools section with 2 new proposed libraries: tooladapter, toolset 2026-01-28 Created comprehensive proposal for composable toolsets and protocol adapters (see protocol-agnostic-tools.md) 2026-01-28 Added Cache Layer as extension point #6 with pluggable backends (memory, Redis, SQLite, layered) 2026-01-28 Proposed new library: <code>toolcache</code> for cross-component caching with invalidation strategies 2026-01-28 Added section 7: Additional Cross-Cutting Concerns with comprehensive enterprise patterns 2026-01-28 Documented 12 cross-cutting concerns: cache, circuit breaker, retry, bulkhead, health checks, secrets, config reload, feature flags, audit trail, backpressure, timeout, tracing 2026-01-28 Proposed 6 new libraries for cross-cutting concerns: toolresilience, toolhealth, toolsecrets, toolflags, toolaudit, toolpressure 2026-01-28 Added comprehensive Versioning Strategy section (section 19) 2026-01-28 Documented 5 versioning layers: MCP protocol, tool schema, backend, configuration, deployment 2026-01-28 Added schema evolution with BACKWARD/FORWARD/FULL compatibility modes 2026-01-28 Added blue/green and canary deployment support for multi-version coexistence 2026-01-28 Proposed new library: <code>toolversion</code> for semantic versioning and version negotiation 2026-01-28 Created master ROADMAP.md consolidating all proposals into 4 work streams and 17-week timeline 2026-01-28 Total library inventory: 7 existing + 14 proposed = 21 libraries for enterprise-ready platform 2026-01-28 Added Section 20: Multi-Language Extensibility - gRPC/WASM/JSON-RPC plugin contracts for Python, Rust, TypeScript"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/","title":"Protocol-Agnostic Tools and Composable Toolsets","text":"<p>Status: Draft Last Updated: 2026-01-28 Authors: Architecture Team Related: Master Roadmap (Stream B: Protocol Layer), Pluggable Architecture</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Executive Summary</li> <li>Problem Statement</li> <li>Goals and Non-Goals</li> <li>Research Findings</li> <li>Proposed Architecture</li> <li>Tool Abstraction Layer</li> <li>Protocol Adapters</li> <li>Composable Toolsets</li> <li>Integration with Existing Libraries</li> <li>Implementation Roadmap</li> <li>Appendix: Industry Patterns</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#executive-summary","title":"Executive Summary","text":"<p>This proposal extends metatools-mcp's pluggable architecture to support protocol-agnostic tool exposure and composable toolsets. Rather than limiting tool consumption to the MCP protocol, we introduce an adaptability layer that enables tools from any source (MCP backends, custom providers, local implementations) to be exposed through multiple transport protocols and consumed by various AI agent frameworks.</p> <p>Key capabilities: - Protocol-agnostic tool interface - Canonical tool representation independent of source or destination protocol - Bidirectional adapters - Convert tools between MCP, OpenAI, Anthropic, LangChain, and other formats - Toolset composition - Create curated tool collections from multiple sources - Multi-transport exposure - Serve toolsets via MCP, direct client interfaces, REST, or A2A</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#problem-statement","title":"Problem Statement","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#current-limitations","title":"Current Limitations","text":"<ol> <li> <p>MCP-Only Exposure: metatools-mcp currently exposes tools exclusively through the MCP protocol. Organizations with mature AI environments using different tool calling conventions (OpenAI function calling, Anthropic tool use, LangChain tools) cannot directly consume metatools without MCP integration.</p> </li> <li> <p>Fixed Tool Collections: All registered tools are exposed as a single collection. There's no mechanism to create curated toolsets for different use cases (development vs production, team A vs team B, customer-specific).</p> </li> <li> <p>One-Way Conversion: Tools flow from backends \u2192 MCP \u2192 clients. There's no standardized way to import tools from external sources (OpenAPI specs, LangChain tools, OpenAI functions) into the metatools ecosystem.</p> </li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#industry-context","title":"Industry Context","text":"<p>Research reveals a fragmented landscape of tool formats:</p> Provider Format Key Differences MCP <code>Tool</code> with <code>inputSchema</code> Rich JSON Schema, supports resources/prompts OpenAI <code>function</code> with <code>parameters</code> Strict mode available, simpler schema Anthropic <code>tool</code> with <code>input_schema</code> Similar to MCP but different field names LangChain <code>StructuredTool</code> Python/JS-centric, Zod schemas A2A Agent-defined Inter-agent tool delegation <p>The Mastra framework demonstrated that proper tool format conversion reduces error rates from 15% to 3% across providers.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#goals-and-non-goals","title":"Goals and Non-Goals","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#goals","title":"Goals","text":"<ol> <li>Protocol Independence: Tools can be consumed without MCP protocol dependency</li> <li>Format Preservation: Tool semantics survive conversion without information loss</li> <li>Bidirectional Flow: Import tools from external sources, export to any format</li> <li>Composability: Create, manage, and expose custom tool collections</li> <li>Backward Compatibility: Existing MCP-based workflows remain unchanged</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#non-goals","title":"Non-Goals","text":"<ol> <li>Runtime Protocol Bridging: We're not building a universal protocol translator</li> <li>Tool Implementation: Adapters convert metadata, not execution logic</li> <li>Full A2A Implementation: Agent orchestration is out of scope</li> <li>Schema Validation Engine: We rely on existing validation libraries</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#research-findings","title":"Research Findings","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#pattern-1-unified-tool-abstraction-toolregistry-paper","title":"Pattern 1: Unified Tool Abstraction (ToolRegistry Paper)","text":"<p>The ArXiv paper \"Unified Tool Integration for LLMs\" establishes a three-layer architecture:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 Layer 3: API Compatibility              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502 OpenAI  \u2502  \u2502Anthropic\u2502  \u2502LangChain\u2502  \u2502   MCP   \u2502   \u2502\n\u2502   \u2502 Format  \u2502  \u2502 Format  \u2502  \u2502 Format  \u2502  \u2502 Format  \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502        \u2502            \u2502            \u2502            \u2502         \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                           \u2502                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                 Layer 2: Protocol Adapters              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  MCP    \u2502  \u2502 OpenAPI \u2502  \u2502LangChain\u2502  \u2502 Custom  \u2502   \u2502\n\u2502   \u2502 Adapter \u2502  \u2502 Adapter \u2502  \u2502 Adapter \u2502  \u2502 Adapter \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502        \u2502            \u2502            \u2502            \u2502         \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                           \u2502                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                 Layer 1: Unified Abstraction            \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n\u2502                    \u2502 Canonical Tool\u2502                    \u2502\n\u2502                    \u2502  Abstraction  \u2502                    \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key Insight: The canonical tool representation stores the superset of all schema information, enabling lossless conversion between formats.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#pattern-2-langchain-mcp-adapter","title":"Pattern 2: LangChain MCP Adapter","text":"<p>LangChain's <code>langchainjs-mcp-adapters</code> demonstrates practical conversion:</p> <pre><code>// MCP Tool \u2192 LangChain DynamicStructuredTool\nexport async function loadMcpTools(\n  serverName: string,\n  client: Client,\n): Promise&lt;StructuredToolInterface[]&gt; {\n  const toolsResponse = await client.listTools();\n  return toolsResponse.tools.map((tool: MCPTool) =&gt; {\n    return new DynamicStructuredTool({\n      name: `${serverName}_${tool.name}`,\n      description: tool.description || \"\",\n      schema: tool.inputSchema,  // Direct schema pass-through\n      func: callTool.bind(null, serverName, tool.name, client)\n    });\n  });\n}\n</code></pre> <p>Key Insight: Namespacing (<code>serverName_toolName</code>) prevents collisions when aggregating tools from multiple sources.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#pattern-3-multi-language-tool-declaration-llm-functions","title":"Pattern 3: Multi-Language Tool Declaration (llm-functions)","text":"<p>The <code>llm-functions</code> library shows format-agnostic tool declaration:</p> <pre><code># Bash: Comment annotations\n# @describe Search the web\n# @option --query! The search query\n# @option --num_results=10 Number of results\nsearch_web() { ... }\n</code></pre> <pre><code>// JavaScript: JSDoc\n/**\n * @typedef {Object} Args\n * @property {string} query - The search query\n * @property {number} [num_results=10] - Number of results\n */\n</code></pre> <pre><code># Python: Type hints + docstrings\ndef search_web(query: str, num_results: int = 10):\n    \"\"\"Search the web.\n\n    Args:\n        query: The search query\n        num_results: Number of results (default: 10)\n    \"\"\"\n</code></pre> <p>Key Insight: All three declarations compile to identical JSON Schema, proving format-agnostic tool definitions are achievable.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#pattern-4-tool-rag-for-large-registries","title":"Pattern 4: Tool RAG for Large Registries","text":"<p>For registries with 50+ tools, semantic search dramatically improves tool selection:</p> Approach Accuracy (50 tools) Accuracy (500 tools) Keyword matching 65% 23% BM25 (current) 78% 45% Vector embeddings 89% 72% Hybrid (BM25 + vector) 94% 81% <p>Anthropic's RAG-MCP implementation showed 13% \u2192 43% accuracy improvement using Tool RAG.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#proposed-architecture","title":"Proposed Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#new-library-tooladapter","title":"New Library: <code>tooladapter</code>","text":"<p>A dedicated library for protocol-agnostic tool handling:</p> <pre><code>tooladapter/\n\u251c\u2500\u2500 canonical.go      # Canonical tool representation\n\u251c\u2500\u2500 adapter.go        # Adapter interface\n\u251c\u2500\u2500 adapters/\n\u2502   \u251c\u2500\u2500 mcp.go        # MCP \u2194 Canonical\n\u2502   \u251c\u2500\u2500 openai.go     # OpenAI \u2194 Canonical\n\u2502   \u251c\u2500\u2500 anthropic.go  # Anthropic \u2194 Canonical\n\u2502   \u251c\u2500\u2500 langchain.go  # LangChain \u2194 Canonical\n\u2502   \u2514\u2500\u2500 openapi.go    # OpenAPI \u2194 Canonical\n\u251c\u2500\u2500 schema/\n\u2502   \u251c\u2500\u2500 convert.go    # JSON Schema version conversion\n\u2502   \u2514\u2500\u2500 validate.go   # Schema validation\n\u2514\u2500\u2500 registry.go       # Adapter registry\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#new-library-toolset","title":"New Library: <code>toolset</code>","text":"<p>Composable tool collections:</p> <pre><code>toolset/\n\u251c\u2500\u2500 set.go            # Toolset definition\n\u251c\u2500\u2500 builder.go        # Fluent toolset construction\n\u251c\u2500\u2500 filter.go         # Tool filtering predicates\n\u251c\u2500\u2500 policy.go         # Access control policies\n\u2514\u2500\u2500 expose.go         # Multi-protocol exposure\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        metatools-mcp Server                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502    MCP      \u2502  \u2502   Direct    \u2502  \u2502    REST     \u2502  \u2502    A2A     \u2502  \u2502\n\u2502  \u2502  Transport  \u2502  \u2502   Client    \u2502  \u2502     API     \u2502  \u2502  Protocol  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502         \u2502                \u2502                \u2502               \u2502          \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                                   \u2502                                  \u2502\n\u2502                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502                          \u2502    toolset      \u2502                         \u2502\n\u2502                          \u2502   Composer      \u2502                         \u2502\n\u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502                                   \u2502                                  \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502         \u2502                         \u2502                         \u2502        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   Toolset   \u2502  \u2502        Toolset              \u2502  \u2502   Toolset    \u2502 \u2502\n\u2502  \u2502  \"dev-ops\"  \u2502  \u2502      \"customer-x\"           \u2502  \u2502    \"prod\"    \u2502 \u2502\n\u2502  \u2502 [A,C,E,F]   \u2502  \u2502       [B,D,F]               \u2502  \u2502   [A,B,D]    \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502         \u2502                         \u2502                         \u2502        \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502                                   \u2502                                  \u2502\n\u2502                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502                          \u2502   tooladapter   \u2502                         \u2502\n\u2502                          \u2502   (Canonical)   \u2502                         \u2502\n\u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502                                   \u2502                                  \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502    \u2502              \u2502               \u2502               \u2502              \u2502   \u2502\n\u2502 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2510 \u2502\n\u2502 \u2502 MCP  \u2502    \u2502  OpenAI  \u2502   \u2502  Anthropic \u2502  \u2502LangChain \u2502  \u2502 OpenAPI\u2502 \u2502\n\u2502 \u2502Adapter\u2502   \u2502  Adapter \u2502   \u2502   Adapter  \u2502  \u2502 Adapter  \u2502  \u2502 Adapter\u2502 \u2502\n\u2502 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2518 \u2502\n\u2502    \u2502              \u2502               \u2502               \u2502              \u2502   \u2502\n\u251c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2524\n\u2502    \u2502              \u2502               \u2502               \u2502              \u2502   \u2502\n\u2502 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2510 \u2502\n\u2502 \u2502 MCP  \u2502    \u2502 External \u2502   \u2502  External  \u2502  \u2502 External \u2502  \u2502  REST  \u2502 \u2502\n\u2502 \u2502Server\u2502    \u2502  OpenAI  \u2502   \u2502  Anthropic \u2502  \u2502LangChain \u2502  \u2502  APIs  \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  Tools   \u2502   \u2502   Tools    \u2502  \u2502  Tools   \u2502  \u2502        \u2502 \u2502\n\u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#tool-abstraction-layer","title":"Tool Abstraction Layer","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#canonical-tool-interface","title":"Canonical Tool Interface","text":"<pre><code>// tooladapter/canonical.go\n\n// CanonicalTool is the protocol-agnostic tool representation\ntype CanonicalTool struct {\n    // Identity\n    ID          string            // Globally unique identifier\n    Namespace   string            // Source namespace (e.g., \"mcp.github\", \"openai.functions\")\n    Name        string            // Tool name within namespace\n    Version     string            // Semantic version\n\n    // Metadata\n    Description string            // Human-readable description\n    Category    string            // Tool category for grouping\n    Tags        []string          // Searchable tags\n\n    // Schema (superset of all protocol schemas)\n    InputSchema  *JSONSchema      // Full JSON Schema for inputs\n    OutputSchema *JSONSchema      // Optional output schema\n\n    // Execution\n    Handler     ToolHandler       // Execution function\n    Timeout     time.Duration     // Execution timeout\n\n    // Source tracking\n    SourceFormat string           // Original format (mcp, openai, anthropic, etc.)\n    SourceMeta   map[string]any   // Protocol-specific metadata preserved\n\n    // Access control\n    RequiredScopes []string       // OAuth scopes or permissions required\n}\n\n// JSONSchema represents a full JSON Schema with all features\ntype JSONSchema struct {\n    Type        string                 `json:\"type\"`\n    Properties  map[string]*JSONSchema `json:\"properties,omitempty\"`\n    Required    []string               `json:\"required,omitempty\"`\n    Items       *JSONSchema            `json:\"items,omitempty\"`\n    Description string                 `json:\"description,omitempty\"`\n\n    // Extended schema features (preserved during conversion)\n    Enum        []any                  `json:\"enum,omitempty\"`\n    Const       any                    `json:\"const,omitempty\"`\n    Default     any                    `json:\"default,omitempty\"`\n    Minimum     *float64               `json:\"minimum,omitempty\"`\n    Maximum     *float64               `json:\"maximum,omitempty\"`\n    MinLength   *int                   `json:\"minLength,omitempty\"`\n    MaxLength   *int                   `json:\"maxLength,omitempty\"`\n    Pattern     string                 `json:\"pattern,omitempty\"`\n    Format      string                 `json:\"format,omitempty\"`\n\n    // JSON Schema draft compatibility\n    Ref         string                 `json:\"$ref,omitempty\"`\n    Defs        map[string]*JSONSchema `json:\"$defs,omitempty\"`\n}\n\n// ToolHandler executes the tool\ntype ToolHandler func(ctx context.Context, input map[string]any) (any, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#adapter-interface","title":"Adapter Interface","text":"<pre><code>// tooladapter/adapter.go\n\n// Adapter converts between canonical and protocol-specific formats\ntype Adapter interface {\n    // Name returns the adapter identifier (e.g., \"mcp\", \"openai\")\n    Name() string\n\n    // ToCanonical converts protocol-specific tool to canonical form\n    ToCanonical(raw any) (*CanonicalTool, error)\n\n    // FromCanonical converts canonical tool to protocol-specific form\n    FromCanonical(tool *CanonicalTool) (any, error)\n\n    // SupportsFeature checks if adapter supports a schema feature\n    SupportsFeature(feature SchemaFeature) bool\n}\n\n// SchemaFeature represents JSON Schema features that may not be universally supported\ntype SchemaFeature int\n\nconst (\n    FeatureNestedObjects SchemaFeature = iota\n    FeatureArrays\n    FeatureEnums\n    FeaturePatternValidation\n    FeatureRefDefinitions\n    FeatureNullable\n    FeatureAnyOf\n    FeatureOneOf\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#protocol-adapters","title":"Protocol Adapters","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#mcp-adapter","title":"MCP Adapter","text":"<pre><code>// tooladapter/adapters/mcp.go\n\ntype MCPAdapter struct{}\n\nfunc (a *MCPAdapter) Name() string { return \"mcp\" }\n\nfunc (a *MCPAdapter) ToCanonical(raw any) (*CanonicalTool, error) {\n    mcpTool, ok := raw.(*mcp.Tool)\n    if !ok {\n        return nil, fmt.Errorf(\"expected *mcp.Tool, got %T\", raw)\n    }\n\n    return &amp;CanonicalTool{\n        ID:          fmt.Sprintf(\"mcp.%s\", mcpTool.Name),\n        Namespace:   \"mcp\",\n        Name:        mcpTool.Name,\n        Description: mcpTool.Description,\n        InputSchema: convertMCPSchema(mcpTool.InputSchema),\n        SourceFormat: \"mcp\",\n        SourceMeta: map[string]any{\n            \"annotations\": mcpTool.Annotations,\n        },\n    }, nil\n}\n\nfunc (a *MCPAdapter) FromCanonical(tool *CanonicalTool) (any, error) {\n    return &amp;mcp.Tool{\n        Name:        tool.Name,\n        Description: tool.Description,\n        InputSchema: convertToMCPSchema(tool.InputSchema),\n    }, nil\n}\n\nfunc (a *MCPAdapter) SupportsFeature(f SchemaFeature) bool {\n    // MCP supports full JSON Schema\n    return true\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#openai-adapter","title":"OpenAI Adapter","text":"<pre><code>// tooladapter/adapters/openai.go\n\ntype OpenAIAdapter struct {\n    StrictMode bool // Enable OpenAI's strict schema mode\n}\n\nfunc (a *OpenAIAdapter) Name() string { return \"openai\" }\n\nfunc (a *OpenAIAdapter) ToCanonical(raw any) (*CanonicalTool, error) {\n    fn, ok := raw.(*OpenAIFunction)\n    if !ok {\n        return nil, fmt.Errorf(\"expected *OpenAIFunction, got %T\", raw)\n    }\n\n    return &amp;CanonicalTool{\n        ID:          fmt.Sprintf(\"openai.%s\", fn.Name),\n        Namespace:   \"openai\",\n        Name:        fn.Name,\n        Description: fn.Description,\n        InputSchema: convertOpenAIParameters(fn.Parameters),\n        SourceFormat: \"openai\",\n        SourceMeta: map[string]any{\n            \"strict\": fn.Strict,\n        },\n    }, nil\n}\n\nfunc (a *OpenAIAdapter) FromCanonical(tool *CanonicalTool) (any, error) {\n    params := convertToOpenAIParameters(tool.InputSchema, a.StrictMode)\n\n    return &amp;OpenAIFunction{\n        Name:        tool.Name,\n        Description: tool.Description,\n        Parameters:  params,\n        Strict:      a.StrictMode,\n    }, nil\n}\n\nfunc (a *OpenAIAdapter) SupportsFeature(f SchemaFeature) bool {\n    switch f {\n    case FeatureRefDefinitions:\n        return false // OpenAI doesn't support $ref\n    case FeaturePatternValidation:\n        return a.StrictMode // Only in strict mode\n    default:\n        return true\n    }\n}\n\n// OpenAI function format\ntype OpenAIFunction struct {\n    Name        string         `json:\"name\"`\n    Description string         `json:\"description,omitempty\"`\n    Parameters  map[string]any `json:\"parameters\"`\n    Strict      bool           `json:\"strict,omitempty\"`\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#anthropic-adapter","title":"Anthropic Adapter","text":"<pre><code>// tooladapter/adapters/anthropic.go\n\ntype AnthropicAdapter struct{}\n\nfunc (a *AnthropicAdapter) Name() string { return \"anthropic\" }\n\nfunc (a *AnthropicAdapter) ToCanonical(raw any) (*CanonicalTool, error) {\n    tool, ok := raw.(*AnthropicTool)\n    if !ok {\n        return nil, fmt.Errorf(\"expected *AnthropicTool, got %T\", raw)\n    }\n\n    return &amp;CanonicalTool{\n        ID:          fmt.Sprintf(\"anthropic.%s\", tool.Name),\n        Namespace:   \"anthropic\",\n        Name:        tool.Name,\n        Description: tool.Description,\n        InputSchema: convertAnthropicSchema(tool.InputSchema),\n        SourceFormat: \"anthropic\",\n    }, nil\n}\n\nfunc (a *AnthropicAdapter) FromCanonical(tool *CanonicalTool) (any, error) {\n    return &amp;AnthropicTool{\n        Name:        tool.Name,\n        Description: tool.Description,\n        InputSchema: convertToAnthropicSchema(tool.InputSchema),\n    }, nil\n}\n\n// AnthropicTool matches Anthropic's tool format\ntype AnthropicTool struct {\n    Name        string         `json:\"name\"`\n    Description string         `json:\"description,omitempty\"`\n    InputSchema map[string]any `json:\"input_schema\"`\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#schema-conversion-utilities","title":"Schema Conversion Utilities","text":"<pre><code>// tooladapter/schema/convert.go\n\n// StripUnsupportedFeatures removes schema features not supported by target\nfunc StripUnsupportedFeatures(schema *JSONSchema, adapter Adapter) *JSONSchema {\n    result := schema.DeepCopy()\n\n    if !adapter.SupportsFeature(FeatureRefDefinitions) {\n        result = resolveRefs(result)\n    }\n\n    if !adapter.SupportsFeature(FeaturePatternValidation) {\n        clearPatterns(result)\n    }\n\n    if !adapter.SupportsFeature(FeatureAnyOf) {\n        result = flattenAnyOf(result)\n    }\n\n    return result\n}\n\n// PreserveSemantics records stripped features for potential restoration\nfunc PreserveSemantics(original, stripped *JSONSchema) map[string]any {\n    return map[string]any{\n        \"original_features\": detectFeatures(original),\n        \"stripped_features\": detectStrippedFeatures(original, stripped),\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#composable-toolsets","title":"Composable Toolsets","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#toolset-definition","title":"Toolset Definition","text":"<pre><code>// toolset/set.go\n\n// Toolset represents a curated collection of tools\ntype Toolset struct {\n    ID          string                 // Unique identifier\n    Name        string                 // Human-readable name\n    Description string                 // Purpose description\n\n    // Tool selection\n    Tools       []*tooladapter.CanonicalTool\n\n    // Metadata\n    Tags        []string               // Searchable tags\n    Owner       string                 // Owner/tenant ID\n    CreatedAt   time.Time\n    UpdatedAt   time.Time\n\n    // Access control\n    Policy      *AccessPolicy\n}\n\n// AccessPolicy controls who can use the toolset\ntype AccessPolicy struct {\n    AllowedTenants []string           // Tenant IDs that can access\n    AllowedRoles   []string           // Role-based access\n    RateLimit      *RateLimitConfig   // Optional rate limiting\n    AuditLog       bool               // Enable audit logging\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#fluent-builder","title":"Fluent Builder","text":"<pre><code>// toolset/builder.go\n\n// Builder provides fluent toolset construction\ntype Builder struct {\n    set      *Toolset\n    registry *tooladapter.Registry\n    filters  []FilterFunc\n}\n\n// NewBuilder creates a new toolset builder\nfunc NewBuilder(name string) *Builder {\n    return &amp;Builder{\n        set: &amp;Toolset{\n            ID:   uuid.New().String(),\n            Name: name,\n        },\n    }\n}\n\n// FromRegistry loads tools from an adapter registry\nfunc (b *Builder) FromRegistry(reg *tooladapter.Registry) *Builder {\n    b.registry = reg\n    return b\n}\n\n// WithNamespace includes tools from a specific namespace\nfunc (b *Builder) WithNamespace(ns string) *Builder {\n    b.filters = append(b.filters, func(t *tooladapter.CanonicalTool) bool {\n        return t.Namespace == ns\n    })\n    return b\n}\n\n// WithTags includes tools with any of the specified tags\nfunc (b *Builder) WithTags(tags ...string) *Builder {\n    tagSet := make(map[string]bool)\n    for _, t := range tags {\n        tagSet[t] = true\n    }\n    b.filters = append(b.filters, func(t *tooladapter.CanonicalTool) bool {\n        for _, tag := range t.Tags {\n            if tagSet[tag] {\n                return true\n            }\n        }\n        return false\n    })\n    return b\n}\n\n// WithTools includes specific tools by ID\nfunc (b *Builder) WithTools(ids ...string) *Builder {\n    idSet := make(map[string]bool)\n    for _, id := range ids {\n        idSet[id] = true\n    }\n    b.filters = append(b.filters, func(t *tooladapter.CanonicalTool) bool {\n        return idSet[t.ID]\n    })\n    return b\n}\n\n// WithCategory includes tools from a category\nfunc (b *Builder) WithCategory(cat string) *Builder {\n    b.filters = append(b.filters, func(t *tooladapter.CanonicalTool) bool {\n        return t.Category == cat\n    })\n    return b\n}\n\n// ExcludeTools removes specific tools by ID\nfunc (b *Builder) ExcludeTools(ids ...string) *Builder {\n    idSet := make(map[string]bool)\n    for _, id := range ids {\n        idSet[id] = true\n    }\n    b.filters = append(b.filters, func(t *tooladapter.CanonicalTool) bool {\n        return !idSet[t.ID]\n    })\n    return b\n}\n\n// WithPolicy sets access control policy\nfunc (b *Builder) WithPolicy(p *AccessPolicy) *Builder {\n    b.set.Policy = p\n    return b\n}\n\n// Build creates the toolset\nfunc (b *Builder) Build() (*Toolset, error) {\n    if b.registry == nil {\n        return nil, errors.New(\"registry required\")\n    }\n\n    allTools := b.registry.All()\n    for _, tool := range allTools {\n        include := true\n        for _, filter := range b.filters {\n            if !filter(tool) {\n                include = false\n                break\n            }\n        }\n        if include {\n            b.set.Tools = append(b.set.Tools, tool)\n        }\n    }\n\n    b.set.CreatedAt = time.Now()\n    b.set.UpdatedAt = time.Now()\n\n    return b.set, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#usage-examples","title":"Usage Examples","text":"<pre><code>// Example: Creating a DevOps toolset\ndevOpsSet, _ := toolset.NewBuilder(\"devops-tools\").\n    FromRegistry(registry).\n    WithNamespace(\"mcp.github\").\n    WithNamespace(\"mcp.kubernetes\").\n    WithTags(\"ci-cd\", \"deployment\", \"monitoring\").\n    ExcludeTools(\"mcp.github.delete_repo\"). // Too dangerous\n    WithPolicy(&amp;toolset.AccessPolicy{\n        AllowedRoles: []string{\"devops\", \"sre\"},\n        AuditLog:     true,\n    }).\n    Build()\n\n// Example: Customer-specific toolset\ncustomerSet, _ := toolset.NewBuilder(\"customer-acme\").\n    FromRegistry(registry).\n    WithTools(\n        \"mcp.support.create_ticket\",\n        \"mcp.docs.search\",\n        \"mcp.billing.get_invoice\",\n    ).\n    WithPolicy(&amp;toolset.AccessPolicy{\n        AllowedTenants: []string{\"acme-corp\"},\n        RateLimit: &amp;toolset.RateLimitConfig{\n            RequestsPerMinute: 60,\n        },\n    }).\n    Build()\n\n// Example: Production-safe toolset (no destructive operations)\nprodSet, _ := toolset.NewBuilder(\"production\").\n    FromRegistry(registry).\n    WithCategory(\"read-only\").\n    WithTags(\"safe\", \"idempotent\").\n    Build()\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#integration-with-existing-libraries","title":"Integration with Existing Libraries","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#toolindex-integration","title":"toolindex Integration","text":"<p>The tooladapter library integrates with toolindex for tool discovery:</p> <pre><code>// tooladapter/registry.go\n\n// Registry manages tools from multiple sources\ntype Registry struct {\n    index    toolindex.Index\n    adapters map[string]Adapter\n    tools    map[string]*CanonicalTool\n}\n\n// RegisterAdapter adds a protocol adapter\nfunc (r *Registry) RegisterAdapter(adapter Adapter) {\n    r.adapters[adapter.Name()] = adapter\n}\n\n// Import loads tools from an external source\nfunc (r *Registry) Import(format string, tools []any) error {\n    adapter, ok := r.adapters[format]\n    if !ok {\n        return fmt.Errorf(\"unknown format: %s\", format)\n    }\n\n    for _, raw := range tools {\n        canonical, err := adapter.ToCanonical(raw)\n        if err != nil {\n            return err\n        }\n\n        r.tools[canonical.ID] = canonical\n\n        // Register with toolindex for discovery\n        r.index.Register(convertToIndexTool(canonical))\n    }\n\n    return nil\n}\n\n// Export converts tools to a specific format\nfunc (r *Registry) Export(format string, toolIDs []string) ([]any, error) {\n    adapter, ok := r.adapters[format]\n    if !ok {\n        return nil, fmt.Errorf(\"unknown format: %s\", format)\n    }\n\n    var result []any\n    for _, id := range toolIDs {\n        tool, ok := r.tools[id]\n        if !ok {\n            continue\n        }\n\n        exported, err := adapter.FromCanonical(tool)\n        if err != nil {\n            return nil, err\n        }\n        result = append(result, exported)\n    }\n\n    return result, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#toolmodel-integration","title":"toolmodel Integration","text":"<p>CanonicalTool embeds and extends toolmodel.Tool:</p> <pre><code>// tooladapter/canonical.go\n\n// CanonicalTool extends toolmodel.Tool with adapter metadata\ntype CanonicalTool struct {\n    toolmodel.Tool // Embed base tool\n\n    // Adapter-specific extensions\n    SourceFormat string\n    SourceMeta   map[string]any\n    OutputSchema *JSONSchema\n}\n\n// ToToolModel converts to base toolmodel.Tool\nfunc (c *CanonicalTool) ToToolModel() *toolmodel.Tool {\n    return &amp;c.Tool\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#toolrun-integration","title":"toolrun Integration","text":"<p>Toolsets can be exposed through toolrun for execution:</p> <pre><code>// toolset/expose.go\n\n// ExposeViaMCP creates an MCP-compatible tool list from a toolset\nfunc (ts *Toolset) ExposeViaMCP(adapter *adapters.MCPAdapter) ([]*mcp.Tool, error) {\n    var result []*mcp.Tool\n    for _, tool := range ts.Tools {\n        mcpTool, err := adapter.FromCanonical(tool)\n        if err != nil {\n            return nil, err\n        }\n        result = append(result, mcpTool.(*mcp.Tool))\n    }\n    return result, nil\n}\n\n// ExposeViaOpenAI creates OpenAI function definitions from a toolset\nfunc (ts *Toolset) ExposeViaOpenAI(adapter *adapters.OpenAIAdapter) ([]*OpenAIFunction, error) {\n    var result []*OpenAIFunction\n    for _, tool := range ts.Tools {\n        fn, err := adapter.FromCanonical(tool)\n        if err != nil {\n            return nil, err\n        }\n        result = append(result, fn.(*OpenAIFunction))\n    }\n    return result, nil\n}\n\n// CreateRunner creates a toolrun.Runner scoped to the toolset\nfunc (ts *Toolset) CreateRunner(baseRunner *toolrun.Runner) *toolrun.Runner {\n    // Create a filtered view of the runner that only exposes toolset tools\n    toolIDs := make(map[string]bool)\n    for _, t := range ts.Tools {\n        toolIDs[t.ID] = true\n    }\n\n    return baseRunner.WithFilter(func(tool *toolmodel.Tool) bool {\n        return toolIDs[tool.ID()]\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#phase-1-core-adapter-library-2-weeks","title":"Phase 1: Core Adapter Library (2 weeks)","text":"<p>Week 1: Foundation - [ ] Create <code>tooladapter</code> module structure - [ ] Implement <code>CanonicalTool</code> and <code>JSONSchema</code> types - [ ] Implement <code>Adapter</code> interface - [ ] Create MCP adapter (bidirectional)</p> <p>Week 2: Additional Adapters - [ ] OpenAI adapter with strict mode support - [ ] Anthropic adapter - [ ] Schema conversion utilities - [ ] Unit tests for all adapters</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#phase-2-toolset-composition-2-weeks","title":"Phase 2: Toolset Composition (2 weeks)","text":"<p>Week 3: Toolset Core - [ ] Create <code>toolset</code> module structure - [ ] Implement <code>Toolset</code> type with metadata - [ ] Implement fluent <code>Builder</code> pattern - [ ] Implement filter predicates</p> <p>Week 4: Integration - [ ] Integrate with <code>toolindex</code> for discovery - [ ] Integrate with <code>toolrun</code> for execution - [ ] Add access control policies - [ ] Integration tests</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#phase-3-multi-transport-exposure-2-weeks","title":"Phase 3: Multi-Transport Exposure (2 weeks)","text":"<p>Week 5: Transport Adapters - [ ] MCP transport (existing, enhanced) - [ ] Direct client interface (Go library) - [ ] REST API transport</p> <p>Week 6: Production Readiness - [ ] Rate limiting integration - [ ] Audit logging - [ ] Documentation - [ ] Example applications</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#dependency-graph","title":"Dependency Graph","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Phase 3: Transports                    \u2502\n\u2502            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502            \u2502   MCP   \u2502  REST   \u2502 Direct  \u2502                \u2502\n\u2502            \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2502                 \u2502         \u2502         \u2502                     \u2502\n\u2502                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502                                \u2502                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                    Phase 2: Toolsets                      \u2502\n\u2502                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502\n\u2502                       \u2502     toolset     \u2502                 \u2502\n\u2502                       \u2502   (composer)    \u2502                 \u2502\n\u2502                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                                \u2502                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                    Phase 1: Adapters                      \u2502\n\u2502                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502\n\u2502                       \u2502   tooladapter   \u2502                 \u2502\n\u2502                       \u2502   (canonical)   \u2502                 \u2502\n\u2502                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                                \u2502                          \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502    \u2502           \u2502               \u2502               \u2502       \u2502  \u2502\n\u2502 \u250c\u2500\u2500\u2534\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502 \u2502 MCP \u2502  \u2502 OpenAI   \u2502  \u2502 Anthropic  \u2502  \u2502 OpenAPI  \u2502   \u2502  \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#appendix-industry-patterns","title":"Appendix: Industry Patterns","text":""},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#a-tool-format-comparison","title":"A. Tool Format Comparison","text":"Field MCP OpenAI Anthropic LangChain Name <code>name</code> <code>name</code> <code>name</code> <code>name</code> Description <code>description</code> <code>description</code> <code>description</code> <code>description</code> Parameters <code>inputSchema</code> <code>parameters</code> <code>input_schema</code> <code>schema</code> Schema Type JSON Schema JSON Schema JSON Schema Zod/JSON Schema Strict Mode N/A <code>strict: true</code> N/A N/A Return Type Content array String/Object Content array Any"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#b-schema-feature-support-matrix","title":"B. Schema Feature Support Matrix","text":"Feature MCP OpenAI OpenAI Strict Anthropic Nested objects \u2705 \u2705 \u2705 \u2705 Arrays \u2705 \u2705 \u2705 \u2705 Enums \u2705 \u2705 \u2705 \u2705 Pattern validation \u2705 \u26a0\ufe0f \u2705 \u2705 $ref definitions \u2705 \u274c \u274c \u274c anyOf/oneOf \u2705 \u26a0\ufe0f \u26a0\ufe0f \u2705 Nullable \u2705 \u2705 \u2705 \u2705 Default values \u2705 \u2705 \u274c \u2705"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#c-error-rate-comparison-mastra-research","title":"C. Error Rate Comparison (Mastra Research)","text":"Scenario No Adapter With Adapter Improvement Simple tools 8% 1% 87.5% Complex schemas 23% 4% 82.6% Cross-provider 31% 5% 83.9% Overall 15% 3% 80%"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#d-related-projects","title":"D. Related Projects","text":"Project Stars Approach Limitations LangChain MCP Adapters ~2k MCP \u2192 LangChain One-way, JS only llm-functions 704 Multi-language declaration No runtime registry kani 598 Python @ai_function Python only Mastra ~500 Compatibility layer TypeScript only"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#changelog","title":"Changelog","text":"Date Change 2026-01-28 Initial draft based on architecture research"}]}