{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Tools Stack","text":"<p>Welcome to the unified documentation for the AI Tools Stack. This site brings all tool libraries together in one place and shows how they compose into a progressive-disclosure MCP surface.</p> <p>Simple and elegant at the core, extensible through modular, pluggable architecture.</p> <p></p>"},{"location":"#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes Index</li> <li>User Journeys Index</li> <li>Stack Changelog</li> </ul>"},{"location":"#what-this-stack-provides","title":"What this stack provides","text":"Layer Components Purpose Foundation toolfoundation (model, adapter, version) Canonical schemas + protocol adapters Discovery tooldiscovery (index, tooldoc, search, semantic) Registry, docs, search strategies Execution toolexec (run, code, runtime, backend) Execution, chaining, sandboxing Execution (Integrations) toolexec-integrations (kubernetes, proxmox, remotehttp) Concrete runtime clients Composition toolcompose (set, skill) Filtered collections, skill workflows Operations toolops (observe, cache, auth, resilience, health) Observability + production controls Protocol toolprotocol (transport, wire, content, stream, task, session, resource, prompt, elicit) Protocol primitives Surface metatools-mcp, metatools-a2a MCP + A2A servers wiring"},{"location":"#high-level-flow","title":"High-level Flow","text":"<p>Diagram controls</p> <p>Click any diagram to open a zoomable, pannable view. Scroll/pinch to zoom and drag to pan.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0', 'primaryTextColor': '#fff', 'lineColor': '#4a5568'}}}%%\nflowchart TB\n    subgraph client[\"Client\"]\n        Agent[\"\ud83e\udd16 AI Agent\"]\n    end\n\n    subgraph surface[\"Protocol Surfaces\"]\n        MCP[\"\ud83d\udd37 metatools-mcp&lt;br/&gt;&lt;small&gt;JSON-RPC / SSE&lt;/small&gt;\"]\n        A2A[\"\ud83d\udd37 metatools-a2a&lt;br/&gt;&lt;small&gt;A2A JSON-RPC / REST / SSE&lt;/small&gt;\"]\n    end\n\n    subgraph operations[\"Operations\"]\n        Observe[\"\ud83d\udc41\ufe0f toolops/observe\"]\n        Cache[\"\ud83d\udcbe toolops/cache\"]\n        Auth[\"\ud83d\udd10 toolops/auth\"]\n        Resilience[\"\ud83e\uddef toolops/resilience\"]\n        Health[\"\ud83d\udc9a toolops/health\"]\n    end\n\n    subgraph composition[\"Composition\"]\n        Toolset[\"\ud83d\udce6 toolcompose/set\"]\n        Skill[\"\ud83c\udfaf toolcompose/skill\"]\n    end\n\n    subgraph protocol[\"Protocol\"]\n        Wire[\"\ud83d\udd04 toolprotocol/wire\"]\n        Transport[\"\ud83d\udce1 toolprotocol/transport\"]\n        Content[\"\ud83e\udde9 toolprotocol/content\"]\n    end\n\n    subgraph execution[\"Execution\"]\n        Run[\"\u25b6\ufe0f toolexec/run\"]\n        Code[\"\ud83d\udcbb toolexec/code\"]\n        Runtime[\"\ud83c\udfc3 toolexec/runtime\"]\n    end\n\n    subgraph discovery[\"Discovery\"]\n        Index[\"\ud83d\udcc7 tooldiscovery/index\"]\n        Docs[\"\ud83d\udcda tooldiscovery/tooldoc\"]\n        Search[\"\ud83d\udd0d tooldiscovery/search\"]\n        Semantic[\"\ud83e\udde0 tooldiscovery/semantic\"]\n    end\n\n    subgraph foundation[\"Foundation\"]\n        Model[\"\ud83e\uddf1 toolfoundation/model\"]\n        Adapter[\"\ud83e\udde9 toolfoundation/adapter\"]\n        Version[\"\ud83c\udff7\ufe0f toolfoundation/version\"]\n    end\n\n    subgraph backends[\"Backends\"]\n        Local[\"\ud83c\udfe0 Local\"]\n        Provider[\"\ud83d\udd0c Provider\"]\n        MCPBackend[\"\ud83d\udce1 MCP Server\"]\n        Docker[\"\ud83d\udc33 Docker\"]\n    end\n\n    Agent &lt;--&gt;|\"MCP Protocol\"| MCP\n    Agent &lt;--&gt;|\"A2A Protocol\"| A2A\n\n    MCP --&gt; Observe\n    MCP --&gt; Cache\n    MCP --&gt; Auth\n    MCP --&gt; Resilience\n    MCP --&gt; Health\n\n    MCP --&gt; Toolset\n    MCP --&gt; Skill\n\n    MCP --&gt; Wire\n    MCP --&gt; Transport\n    MCP --&gt; Content\n\n    MCP --&gt; Index\n    MCP --&gt; Docs\n    Index --&gt; Search\n    Index --&gt; Semantic\n\n    MCP --&gt; Run\n    Run --&gt; Code\n    Code --&gt; Runtime\n\n    Toolset --&gt; Index\n    Toolset --&gt; Model\n    Skill --&gt; Run\n\n    Index --&gt; Model\n    Docs --&gt; Model\n    Adapter --&gt; Model\n    Version --&gt; Model\n\n    Run --&gt; Local\n    Run --&gt; Provider\n    Run --&gt; MCPBackend\n    Runtime --&gt; Docker\n\n    style client fill:#4a5568,stroke:#2d3748,stroke-width:2px\n    style surface fill:#2b6cb0,stroke:#2c5282,stroke-width:3px\n    style operations fill:#e53e3e,stroke:#c53030\n    style composition fill:#6b46c1,stroke:#553c9a\n    style protocol fill:#d69e2e,stroke:#b7791f\n    style execution fill:#38a169,stroke:#276749\n    style discovery fill:#3182ce,stroke:#2c5282\n    style foundation fill:#718096,stroke:#4a5568\n    style backends fill:#2d3748,stroke:#1a202c</code></pre>"},{"location":"#progressive-disclosure","title":"Progressive Disclosure","text":"<p>The core usability pattern: discover \u2192 describe \u2192 execute</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'actorBkg': '#2b6cb0', 'actorTextColor': '#fff'}}}%%\nsequenceDiagram\n    autonumber\n    participant Agent as \ud83e\udd16 Agent\n    participant MCP as \ud83d\udd37 metatools-mcp\n\n    rect rgb(43, 108, 176, 0.1)\n        Note over Agent,MCP: 1. Discovery (Token-Cheap)\n        Agent-&gt;&gt;MCP: search_tools(\"create issue\")\n        MCP--&gt;&gt;Agent: Summary[] (no schemas)\n    end\n\n    rect rgb(214, 158, 46, 0.1)\n        Note over Agent,MCP: 2. Description (On-Demand)\n        Agent-&gt;&gt;MCP: describe_tool(id, \"schema\")\n        MCP--&gt;&gt;Agent: Full tool schema\n    end\n\n    rect rgb(56, 161, 105, 0.1)\n        Note over Agent,MCP: 3. Execution (Validated)\n        Agent-&gt;&gt;MCP: run_tool(id, args)\n        MCP--&gt;&gt;Agent: Execution result\n    end</code></pre>"},{"location":"#quickstart","title":"Quickstart","text":"<ol> <li>Start with <code>toolfoundation/model</code> for your canonical schemas</li> <li>Register tools in <code>tooldiscovery/index</code> for discovery</li> <li>Add docs/examples in <code>tooldiscovery/tooldoc</code></li> <li>Execute tools via <code>toolexec/run</code></li> <li>Expose the MCP surface using <code>metatools-mcp</code></li> <li>Expose the A2A surface using <code>metatools-a2a</code> (optional)</li> </ol> <p>See the Components section for per-library examples and diagrams.</p>"},{"location":"#design-notes-and-user-journeys","title":"Design Notes and User Journeys","text":"<p>For deeper context, see the aggregated indexes:</p> <ul> <li>Design Notes Index \u2014 per\u2011repo tradeoffs and error semantics</li> <li>User Journeys Index \u2014 end\u2011to\u2011end agent workflows</li> </ul>"},{"location":"#docs-from-each-repo","title":"Docs from each repo","text":"<p>Under Library Docs (from repos) you will find the docs imported directly from each repository at build time.</p>"},{"location":"roadmap/","title":"ApertureStack Roadmap","text":"<p>Date: 2026-02-02 Scope: Consolidated multi-repo stack (toolfoundation, tooldiscovery, toolexec, toolexec-integrations, toolcompose, toolops, toolprotocol, metatools-mcp, metatools-a2a)</p> <p>This is the single source of truth roadmap for the stack. <code>metatools-mcp</code> is a reference MCP server built from the components below.</p>"},{"location":"roadmap/#current-state","title":"Current State","text":"<ul> <li>Consolidation complete: the original tool* repos have been merged into the 8 core repos.</li> <li>MCP alignment: toolfoundation embeds the official MCP Go SDK and targets MCP 2025-11-25.</li> <li>Progressive discovery: tooldiscovery provides search + progressive tool docs.</li> <li>Execution + sandboxing: toolexec provides run, code execution, and runtime backends (some backends are stubbed).</li> <li>Protocol primitives: toolprotocol contains transport/wire/content/task/stream/session/resource/prompt/elicit/discover.</li> <li>A2A reference server: metatools-a2a exposes AgentCard + task flow alongside metatools-mcp.</li> </ul>"},{"location":"roadmap/#now-0-3-months","title":"Now (0-3 months)","text":"<ul> <li>Protocol crosswalk + adapters: add canonical mappings and adapters for A2A, OpenAI Agents, Anthropic, and Google Gemini.</li> <li>Tool schema normalization: extend <code>CanonicalTool</code> to cover OpenAPI schema subsets and feature-loss reporting across adapters.</li> <li>Progressive discovery UX: align discovery outputs with MCP <code>search_tools</code>/<code>describe_tool</code> semantics and add deterministic paging + stable tool IDs across sources.</li> <li>Runtime truth table: document and test which toolexec runtime backends are production-ready vs scaffolded.</li> <li>Doc cleanup: archive historical consolidation PRDs and move all live roadmap content here.</li> </ul>"},{"location":"roadmap/#next-3-6-months","title":"Next (3-6 months)","text":"<ul> <li>Runtime backend parity: implement real execution for Kubernetes, gVisor, Kata, Firecracker, remote HTTP, and Temporal backends.</li> <li>Multi-tenant execution: enforce tenancy boundaries (authn/authz + per-tenant toolsets + runtime isolation).</li> <li>Protocol bindings: add A2A bindings (JSON-RPC + HTTP/REST; gRPC if needed) using toolprotocol/wire/transport primitives.</li> <li>Observable execution: ensure toolops observe/cache/health/resilience are wired end-to-end in metatools-mcp.</li> </ul>"},{"location":"roadmap/#later-6-months","title":"Later (6+ months)","text":"<ul> <li>Proxmox/LXC runtime backend (enterprise isolation).</li> <li>Policy-driven tool routing across heterogeneous backends (cost, latency, data locality).</li> <li>Tool registry federation across MCP + A2A + vendor agent frameworks.</li> </ul>"},{"location":"roadmap/#definition-of-done-per-deliverable","title":"Definition of Done (Per Deliverable)","text":"<ul> <li>Adapter: round-trip conversions with feature-loss warnings and tests per protocol.</li> <li>Runtime backend: a runnable integration test + error semantics + docs page.</li> <li>Protocol binding: end-to-end interoperability test with a reference client.</li> <li>Docs: a single canonical doc + 1 example + 1 diagram per new capability.</li> </ul>"},{"location":"architecture/design-notes/","title":"Design Notes Index","text":"<p>This page aggregates the per\u2011repo Design Notes pages that document tradeoffs and error semantics for each component. Use these when you want to understand why a design decision was made or how to handle specific failure modes.</p>"},{"location":"architecture/design-notes/#perrepo-design-notes","title":"Per\u2011repo Design Notes","text":"<ul> <li>toolfoundation \u2014 design-notes</li> <li>tooldiscovery \u2014 design-notes</li> <li>toolexec \u2014 design-notes</li> <li>toolcompose \u2014 design-notes</li> <li>toolops \u2014 design-notes</li> <li>toolprotocol \u2014 design-notes</li> <li>metatools-mcp \u2014 design-notes</li> </ul>"},{"location":"architecture/design-notes/#when-to-read-these","title":"When to read these","text":"<ul> <li>You\u2019re debugging failure modes or error propagation.</li> <li>You want to compare tradeoffs (latency vs safety, flexibility vs simplicity).</li> <li>You\u2019re deciding where to plug in a custom implementation.</li> </ul>"},{"location":"architecture/end-to-end-example/","title":"End-to-End Example","text":"<p>This example shows the full flow:</p> <ol> <li>Define a tool</li> <li>Register it + docs</li> <li>Discover and describe it</li> <li>Execute it</li> </ol> <p>It is intentionally small but exercises the core layers.</p> <pre><code>package main\n\nimport (\n  \"context\"\n  \"fmt\"\n\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n\n  \"github.com/jonwraymond/toolfoundation/model\"\n  \"github.com/jonwraymond/tooldiscovery/index\"\n  \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n  \"github.com/jonwraymond/toolexec/exec\"\n)\n\nfunc main() {\n  ctx := context.Background()\n\n  // 1) Define a tool\n  tool := model.Tool{\n    Tool: mcp.Tool{\n      Name:        \"add\",\n      Description: \"Add two numbers\",\n      InputSchema: map[string]any{\n        \"type\": \"object\",\n        \"properties\": map[string]any{\n          \"a\": map[string]any{\"type\": \"number\"},\n          \"b\": map[string]any{\"type\": \"number\"},\n        },\n        \"required\": []string{\"a\", \"b\"},\n      },\n    },\n    Namespace: \"math\",\n    Tags:      []string{\"math\", \"add\"},\n  }\n\n  // 2) Create registry + docs\n  idx := index.NewInMemoryIndex()\n  docs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n  // 3) Register tool + docs\n  _ = idx.RegisterTool(tool, model.ToolBackend{Kind: model.BackendKindLocal, Local: &amp;model.LocalBackend{Name: \"math-add\"}})\n  _ = docs.RegisterDoc(tool.ToolID(), tooldoc.DocEntry{Summary: \"Adds two numbers\"})\n\n  // 4) Create executor with local handler\n  executor, _ := exec.New(exec.Options{\n    Index: idx,\n    Docs:  docs,\n    LocalHandlers: map[string]exec.Handler{\n      \"math-add\": func(_ context.Context, args map[string]any) (any, error) {\n        return args[\"a\"].(float64) + args[\"b\"].(float64), nil\n      },\n    },\n  })\n\n  // 5) Discover\n  summaries, _ := idx.Search(\"add\", 3)\n  fmt.Println(\"summaries\", summaries)\n\n  // 6) Describe\n  doc, _ := docs.DescribeTool(tool.ToolID(), tooldoc.DetailSchema)\n  fmt.Println(\"doc\", doc.Summary)\n\n  // 7) Execute\n  result, _ := executor.RunTool(ctx, tool.ToolID(), map[string]any{\"a\": 2.0, \"b\": 3.0})\n  fmt.Println(\"result\", result.Value)\n}\n</code></pre> <p>Notes: - In real use, the registry often sits behind <code>metatools-mcp</code> or <code>metatools-a2a</code>. - For server wiring, see <code>metatools-mcp/examples</code> and <code>metatools-a2a</code> docs.</p>"},{"location":"architecture/entrypoints/","title":"Entrypoints","text":"<p>This page summarizes the recommended entrypoints for each layer of the stack. Use the facade packages unless you need lower-level control.</p> Use case Recommended entrypoint Why If you need more control Define tools + schemas <code>toolfoundation/model</code> Canonical MCP-aligned types + validation <code>toolfoundation/adapter</code>, <code>toolfoundation/version</code> Convert between tool protocols <code>toolfoundation/adapter</code> Bidirectional MCP/A2A/OpenAI/Anthropic/Gemini conversion Implement a custom <code>adapter.Adapter</code> Register + discover tools <code>tooldiscovery/index</code> Registry + search orchestration Implement a custom <code>index.Searcher</code> Progressive tool docs <code>tooldiscovery/tooldoc</code> Summary/schema/full detail levels Custom <code>tooldoc.Store</code> Search (lexical/BM25) <code>tooldiscovery/search</code> BM25 production search Custom <code>index.Searcher</code> Semantic/hybrid search <code>tooldiscovery/semantic</code> or <code>tooldiscovery/discovery</code> Embeddings + hybrid scoring Custom <code>semantic.Embedder</code> Unified discovery API <code>tooldiscovery/discovery</code> Convenience facade Mix <code>index</code> + <code>tooldoc</code> directly Execute tools + chains <code>toolexec/run</code> Validation + backend dispatch + chaining <code>toolexec/backend</code>, custom executors Unified exec + discovery <code>toolexec/exec</code> Single facade for index/docs/run Compose <code>index</code> + <code>tooldoc</code> + <code>run</code> yourself Code orchestration <code>toolexec/code</code> Execute code with tool access Custom <code>code.Engine</code> Runtime isolation <code>toolexec/runtime</code> Security profiles + sandbox backends Backend-specific packages Runtime integrations <code>toolexec-integrations/*</code> Concrete runtime clients Provide your own SDK client Compose toolsets <code>toolcompose/set</code> Filtered collections + exposure Custom <code>set.Policy</code> Skills/workflows <code>toolcompose/skill</code> Declarative multi-step skills Custom <code>skill.Guard</code> or <code>skill.Runner</code> Observability <code>toolops/observe</code> Tracing/metrics/logging Custom exporters/logger AuthN/AuthZ <code>toolops/auth</code> Authenticator + authorizer primitives Custom <code>auth.Authenticator</code> Caching <code>toolops/cache</code> Deterministic cache keys + cache API Custom <code>cache.Cache</code> Protocol + transport <code>toolprotocol</code> Wire/transport/session/resources Implement <code>transport.Transport</code> MCP server <code>metatools-mcp</code> Opinionated MCP surface Build your own server with toolprotocol A2A server <code>metatools-a2a</code> Opinionated A2A surface Build your own server with toolprotocol"},{"location":"architecture/entrypoints/#quick-decisions","title":"Quick decisions","text":"<ul> <li>If you need basic discovery + execution, start with <code>toolexec/exec</code>.</li> <li>If you need server wiring, use <code>metatools-mcp</code> or <code>metatools-a2a</code> (or <code>toolprotocol</code> for custom servers).</li> <li>If you need progressive disclosure, use <code>tooldiscovery/tooldoc</code> with <code>tooldiscovery/index</code>.</li> <li>If you need sandboxed code execution, pair <code>toolexec/code</code> with <code>toolexec/runtime</code>.</li> </ul>"},{"location":"architecture/overview/","title":"Stack Architecture","text":"<p>This stack is built around progressive disclosure and a clean separation of schema, discovery, docs, execution, and transport.</p> <p>See also: <code>architecture/stack-map.md</code> and <code>architecture/protocol-crosswalk.md</code>.</p>"},{"location":"architecture/overview/#system-context-c4-level-1","title":"System Context (C4 Level 1)","text":"<p>High-level view showing the ApertureStack and its external actors.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#1a365d', 'primaryTextColor': '#fff', 'primaryBorderColor': '#2c5282', 'lineColor': '#4a5568', 'secondaryColor': '#2d3748', 'tertiaryColor': '#e2e8f0'}}}%%\nflowchart TB\n    subgraph external[\"External Systems\"]\n        Agent[\"\ud83e\udd16 AI Agent&lt;br/&gt;&lt;small&gt;Claude, GPT, etc.&lt;/small&gt;\"]\n        ExtMCP[\"\ud83d\udce1 External MCP Servers&lt;br/&gt;&lt;small&gt;GitHub, Filesystem, etc.&lt;/small&gt;\"]\n        Backends[\"\u2699\ufe0f Execution Backends&lt;br/&gt;&lt;small&gt;Docker, K8s, WASM&lt;/small&gt;\"]\n    end\n\n    subgraph aperture[\"ApertureStack\"]\n        direction TB\n        MCP[\"\ud83d\udd37 metatools-mcp&lt;br/&gt;&lt;small&gt;MCP Server Surface&lt;/small&gt;\"]\n        A2A[\"\ud83e\udde9 metatools-a2a&lt;br/&gt;&lt;small&gt;A2A Server Surface&lt;/small&gt;\"]\n    end\n\n    subgraph observability[\"Observability\"]\n        OTLP[\"\ud83d\udcca OTLP Collector\"]\n        Prometheus[\"\ud83d\udcc8 Prometheus\"]\n        Jaeger[\"\ud83d\udd0d Jaeger\"]\n    end\n\n    Agent --&gt;|\"MCP Protocol&lt;br/&gt;JSON-RPC\"| MCP\n    Agent --&gt;|\"A2A Protocol&lt;br/&gt;JSON-RPC/REST\"| A2A\n    MCP --&gt;|\"Tool Calls\"| ExtMCP\n    MCP --&gt;|\"Code Execution\"| Backends\n    A2A --&gt;|\"Tool Calls\"| ExtMCP\n    A2A --&gt;|\"Code Execution\"| Backends\n    MCP -.-&gt;|\"Traces\"| OTLP\n    MCP -.-&gt;|\"Metrics\"| Prometheus\n    A2A -.-&gt;|\"Traces\"| OTLP\n    A2A -.-&gt;|\"Metrics\"| Prometheus\n    OTLP --&gt; Jaeger\n\n    style aperture fill:#1a365d,stroke:#2c5282,stroke-width:3px\n    style external fill:#2d3748,stroke:#4a5568,stroke-width:2px\n    style observability fill:#2f855a,stroke:#276749,stroke-width:2px</code></pre>"},{"location":"architecture/overview/#layering-model-consolidated-stack","title":"Layering Model (Consolidated Stack)","text":"<p>Complete view of the consolidated repositories organized by layer.</p> <p></p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0', 'primaryTextColor': '#fff', 'lineColor': '#4a5568'}}}%%\nflowchart TB\n    subgraph surface[\"Protocol Surface Layer\"]\n        direction LR\n        metatools[\"\ud83d\udd37 metatools-mcp&lt;br/&gt;&lt;small&gt;v0.5.2 \u2022 MCP Server&lt;/small&gt;\"]\n        metatoolsA2A[\"\ud83e\udde9 metatools-a2a&lt;br/&gt;&lt;small&gt;v0.1.0 \u2022 A2A Server&lt;/small&gt;\"]\n    end\n\n    subgraph protocol[\"Protocol Layer\"]\n        direction LR\n        toolprotocol[\"\ud83d\udce1 toolprotocol&lt;br/&gt;&lt;small&gt;v0.1.5 \u2022 Transports + Wire&lt;/small&gt;\"]\n    end\n\n    subgraph operations[\"Operations Layer\"]\n        direction LR\n        toolops[\"\ud83d\udc41\ufe0f toolops&lt;br/&gt;&lt;small&gt;v0.1.4 \u2022 Observe/Cache/Auth&lt;/small&gt;\"]\n    end\n\n    subgraph composition[\"Composition Layer\"]\n        direction LR\n        toolcompose[\"\ud83d\udce6 toolcompose&lt;br/&gt;&lt;small&gt;v0.1.2 \u2022 Set + Skill&lt;/small&gt;\"]\n    end\n\n    subgraph execution[\"Execution Layer\"]\n        direction LR\n        toolexec[\"\u25b6\ufe0f toolexec&lt;br/&gt;&lt;small&gt;v0.2.0 \u2022 Run/Code/Runtime&lt;/small&gt;\"]\n    end\n\n    subgraph discovery[\"Discovery Layer\"]\n        direction LR\n        tooldiscovery[\"\ud83d\udcc7 tooldiscovery&lt;br/&gt;&lt;small&gt;v0.2.2 \u2022 Index/Search/Docs&lt;/small&gt;\"]\n    end\n\n    subgraph foundation[\"Foundation Layer\"]\n        direction LR\n        toolfoundation[\"\ud83e\uddf1 toolfoundation&lt;br/&gt;&lt;small&gt;v0.2.0 \u2022 Model/Adapter/Version&lt;/small&gt;\"]\n    end\n\n    toolfoundation --&gt; tooldiscovery\n    toolfoundation --&gt; toolexec\n    toolfoundation --&gt; toolprotocol\n    toolfoundation --&gt; toolops\n    toolfoundation --&gt; toolcompose\n\n    tooldiscovery --&gt; toolcompose\n    toolexec --&gt; toolcompose\n\n    toolprotocol --&gt; metatools\n    toolops --&gt; metatools\n    toolcompose --&gt; metatools\n    toolexec --&gt; metatools\n    tooldiscovery --&gt; metatools\n    toolfoundation --&gt; metatools\n\n    toolprotocol --&gt; metatoolsA2A\n    toolops --&gt; metatoolsA2A\n    toolcompose --&gt; metatoolsA2A\n    toolexec --&gt; metatoolsA2A\n    tooldiscovery --&gt; metatoolsA2A\n    toolfoundation --&gt; metatoolsA2A\n\n    style surface fill:#2b6cb0,stroke:#2c5282,stroke-width:2px\n    style protocol fill:#d69e2e,stroke:#b7791f,stroke-width:2px\n    style operations fill:#e53e3e,stroke:#c53030,stroke-width:2px\n    style composition fill:#6b46c1,stroke:#553c9a,stroke-width:2px\n    style execution fill:#38a169,stroke:#276749,stroke-width:2px\n    style discovery fill:#3182ce,stroke:#2c5282,stroke-width:2px\n    style foundation fill:#718096,stroke:#4a5568,stroke-width:2px</code></pre>"},{"location":"architecture/overview/#progressive-disclosure-pipeline","title":"Progressive Disclosure Pipeline","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'actorBkg': '#2b6cb0', 'actorTextColor': '#fff', 'actorBorder': '#2c5282'}}}%%\nsequenceDiagram\n    autonumber\n\n    participant Agent as \ud83e\udd16 AI Agent\n    participant MCP as \ud83d\udd37 metatools-mcp\n    participant Index as \ud83d\udcc7 tooldiscovery/index\n    participant Search as \ud83d\udd0d tooldiscovery/search\n    participant Docs as \ud83d\udcda tooldiscovery/tooldoc\n    participant Run as \u25b6\ufe0f toolexec/run\n\n    rect rgb(43, 108, 176, 0.1)\n        Note over Agent,Search: Phase 1: Discovery (Token-Cheap)\n        Agent-&gt;&gt;+MCP: search_tools(\"create issue\", limit=5)\n        MCP-&gt;&gt;+Index: Search(query, limit)\n        Index-&gt;&gt;+Search: Search(docs, query, limit)\n        Search--&gt;&gt;-Index: scored results\n        Index--&gt;&gt;-MCP: Summary[] (no schemas)\n        MCP--&gt;&gt;-Agent: summaries\n    end\n\n    rect rgb(214, 158, 46, 0.1)\n        Note over Agent,Docs: Phase 2: Description (On-Demand)\n        Agent-&gt;&gt;+MCP: describe_tool(\"github:create_issue\", \"schema\")\n        MCP-&gt;&gt;+Docs: DescribeTool(id, DetailSchema)\n        Docs-&gt;&gt;Index: GetTool(id)\n        Index--&gt;&gt;Docs: Tool definition\n        Docs--&gt;&gt;-MCP: ToolDoc with schema\n        MCP--&gt;&gt;-Agent: full tool schema\n    end\n\n    rect rgb(56, 161, 105, 0.1)\n        Note over Agent,Run: Phase 3: Execution (Validated)\n        Agent-&gt;&gt;+MCP: run_tool(\"github:create_issue\", args)\n        MCP-&gt;&gt;+Run: Run(ctx, id, args)\n        Run-&gt;&gt;Run: ValidateInput(args)\n        Run-&gt;&gt;Run: ResolveBackend()\n        Run-&gt;&gt;Run: Execute via backend\n        Run-&gt;&gt;Run: ValidateOutput(result)\n        Run--&gt;&gt;-MCP: RunResult\n        MCP--&gt;&gt;-Agent: execution result\n    end</code></pre>"},{"location":"architecture/overview/#tool-execution-and-runtime-isolation","title":"Tool Execution and Runtime Isolation","text":"<p>Concrete runtime clients (Kubernetes, Proxmox, remote HTTP) live in <code>toolexec-integrations</code>. <code>toolexec</code> core stays interface-only for runtime backends and consumes these integrations via injection.</p> <p></p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#38a169'}}}%%\nflowchart LR\n    subgraph input[\"Input Phase\"]\n        A[\"\ud83d\udce5 Receive&lt;br/&gt;ToolID + Args\"]\n    end\n\n    subgraph validation1[\"Validation Phase 1\"]\n        B[\"\u2705 Validate&lt;br/&gt;Tool ID Format\"]\n        C[\"\u2705 Validate&lt;br/&gt;Input Schema\"]\n    end\n\n    subgraph resolution[\"Resolution Phase\"]\n        D[\"\ud83d\udd0d Resolve&lt;br/&gt;Tool Definition\"]\n        E[\"\ud83c\udfaf Select&lt;br/&gt;Backend\"]\n    end\n\n    subgraph execution[\"Execution Phase\"]\n        F{\"Backend&lt;br/&gt;Type?\"}\n        G[\"\ud83c\udfe0 Local&lt;br/&gt;Handler\"]\n        H[\"\ud83d\udd0c Provider&lt;br/&gt;Executor\"]\n        I[\"\ud83d\udce1 MCP&lt;br/&gt;Server Call\"]\n    end\n\n    subgraph normalization[\"Normalization Phase\"]\n        J[\"\ud83d\udce4 Normalize&lt;br/&gt;Result\"]\n    end\n\n    subgraph validation2[\"Validation Phase 2\"]\n        K[\"\u2705 Validate&lt;br/&gt;Output Schema\"]\n    end\n\n    subgraph output[\"Output Phase\"]\n        L[\"\ud83d\udce6 Return&lt;br/&gt;RunResult\"]\n    end\n\n    A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F\n    F --&gt;|local| G\n    F --&gt;|provider| H\n    F --&gt;|mcp| I\n    G --&gt; J\n    H --&gt; J\n    I --&gt; J\n    J --&gt; K --&gt; L\n\n    style input fill:#3182ce,stroke:#2c5282\n    style validation1 fill:#38a169,stroke:#276749\n    style resolution fill:#d69e2e,stroke:#b7791f\n    style execution fill:#6b46c1,stroke:#553c9a\n    style normalization fill:#e53e3e,stroke:#c53030\n    style validation2 fill:#38a169,stroke:#276749\n    style output fill:#3182ce,stroke:#2c5282</code></pre>"},{"location":"architecture/overview/#end-to-end-example","title":"End-to-End Example","text":"<p>See the short, runnable walkthrough: End-to-End Example.</p>"},{"location":"architecture/overview/#search-strategy-layering","title":"Search Strategy Layering","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#3182ce'}}}%%\nflowchart TB\n    subgraph query[\"Search Query\"]\n        Input[\"\ud83d\udd0d 'create github issue'\"]\n    end\n\n    subgraph index[\"tooldiscovery/index\"]\n        Search[\"Index.Search(query, limit)\"]\n        Docs[\"SearchDoc[]&lt;br/&gt;&lt;small&gt;ID, Name, Namespace,&lt;br/&gt;Description, Tags&lt;/small&gt;\"]\n    end\n\n    subgraph strategies[\"Search Strategies\"]\n        direction TB\n\n        subgraph lexical[\"Lexical (Default)\"]\n            Simple[\"Simple substring&lt;br/&gt;matching\"]\n        end\n\n        subgraph bm25[\"BM25 (tooldiscovery/search)\"]\n            BM[\"BM25Searcher\"]\n            Boosts[\"Field Boosts:&lt;br/&gt;&lt;small&gt;name: 4x&lt;br/&gt;namespace: 2x&lt;br/&gt;tags: 1x&lt;/small&gt;\"]\n            Bleve[\"Bleve Index\"]\n        end\n\n        subgraph semantic[\"Semantic (tooldiscovery/semantic)\"]\n            Embed[\"Embedder\"]\n            Vector[\"Vector Store\"]\n            Similarity[\"Cosine Similarity\"]\n        end\n    end\n\n    subgraph ranking[\"Ranking\"]\n        Score[\"\ud83d\udcca Score + Rank\"]\n        Dedup[\"\ud83d\udd04 Deduplicate\"]\n        Limit[\"\u2702\ufe0f Apply Limit\"]\n    end\n\n    subgraph output[\"Results\"]\n        Results[\"Summary[]&lt;br/&gt;&lt;small&gt;No schemas (token-cheap)&lt;/small&gt;\"]\n    end\n\n    Input --&gt; Search\n    Search --&gt; Docs\n\n    Docs --&gt; Simple\n    Docs --&gt; BM --&gt; Boosts --&gt; Bleve\n    Docs --&gt; Embed --&gt; Vector --&gt; Similarity\n\n    Simple --&gt; Score\n    Bleve --&gt; Score\n    Similarity --&gt; Score\n\n    Score --&gt; Dedup --&gt; Limit --&gt; Results\n\n    style strategies fill:#3182ce,stroke:#2c5282,stroke-width:2px\n    style bm25 fill:#38a169,stroke:#276749\n    style semantic fill:#6b46c1,stroke:#553c9a\n    style ranking fill:#d69e2e,stroke:#b7791f</code></pre>"},{"location":"architecture/overview/#component-dependency-graph","title":"Component Dependency Graph","text":"<p>Directed acyclic graph showing module dependencies and bump order.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#4a5568'}}}%%\nflowchart TD\n    subgraph order1[\"Bump Order 1\"]\n        toolfoundation[\"\ud83e\uddf1 toolfoundation\"]\n    end\n\n    subgraph order2[\"Bump Order 2\"]\n        tooldiscovery[\"\ud83d\udcc7 tooldiscovery\"]\n        toolexec[\"\u25b6\ufe0f toolexec\"]\n        toolprotocol[\"\ud83d\udce1 toolprotocol\"]\n        toolops[\"\ud83d\udc41\ufe0f toolops\"]\n    end\n\n    subgraph order3[\"Bump Order 3\"]\n        toolcompose[\"\ud83d\udce6 toolcompose\"]\n    end\n\n    subgraph order4[\"Bump Order 4\"]\n        metatools[\"\ud83d\udd37 metatools-mcp\"]\n    end\n\n    toolfoundation --&gt; tooldiscovery\n    toolfoundation --&gt; toolexec\n    toolfoundation --&gt; toolprotocol\n    toolfoundation --&gt; toolops\n    toolfoundation --&gt; toolcompose\n\n    tooldiscovery --&gt; toolcompose\n    toolexec --&gt; toolcompose\n\n    toolprotocol --&gt; metatools\n    toolops --&gt; metatools\n    toolcompose --&gt; metatools\n    toolexec --&gt; metatools\n    tooldiscovery --&gt; metatools\n    toolfoundation --&gt; metatools\n\n    style order1 fill:#718096,stroke:#4a5568\n    style order2 fill:#3182ce,stroke:#2c5282\n    style order3 fill:#38a169,stroke:#276749\n    style order4 fill:#6b46c1,stroke:#553c9a</code></pre>"},{"location":"architecture/overview/#observability-integration","title":"Observability Integration","text":"<p>How toolops/observe wraps around tool execution with traces, metrics, and logs.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e53e3e'}}}%%\nflowchart TB\n    subgraph client[\"Client Layer\"]\n        Request[\"\ud83d\udce5 Tool Request\"]\n    end\n\n    subgraph middleware[\"toolops/observe Middleware\"]\n        direction TB\n        MW[\"\ud83d\udd00 Middleware.Wrap()\"]\n\n        subgraph tracing[\"Tracing\"]\n            SpanStart[\"StartSpan&lt;br/&gt;&lt;small&gt;tool.exec.{namespace}.{name}&lt;/small&gt;\"]\n            SpanEnd[\"EndSpan\"]\n            SpanAttrs[\"Span Attributes&lt;br/&gt;&lt;small&gt;tool.id, tool.namespace, tool.name&lt;br/&gt;tool.version, tool.category, tool.tags&lt;/small&gt;\"]\n        end\n\n        subgraph metrics[\"Metrics\"]\n            Counter[\"tool.exec.total&lt;br/&gt;&lt;small&gt;{call} counter&lt;/small&gt;\"]\n            Histogram[\"tool.exec.duration&lt;br/&gt;&lt;small&gt;ms histogram&lt;/small&gt;\"]\n        end\n\n        subgraph logging[\"Structured Logging\"]\n            LogFields[\"Fields: tool.id, args (redacted)&lt;br/&gt;duration, error\"]\n        end\n    end\n\n    subgraph execution[\"Actual Execution\"]\n        Runner[\"\u25b6\ufe0f toolexec/run.Runner\"]\n    end\n\n    subgraph exporters[\"Exporters\"]\n        direction LR\n        OTLP[\"\ud83d\udce1 OTLP\"]\n        Jaeger[\"\ud83d\udd0d Jaeger\"]\n        Prometheus[\"\ud83d\udcca Prometheus\"]\n        Stdout[\"\ud83d\udda5\ufe0f Stdout\"]\n    end\n\n    Request --&gt; MW\n    MW --&gt; SpanStart --&gt; SpanAttrs\n    MW --&gt; Counter\n    SpanAttrs --&gt; Runner\n    Runner --&gt; SpanEnd\n    Runner --&gt; Histogram\n\n    SpanEnd --&gt; OTLP\n    SpanEnd --&gt; Jaeger\n    Histogram --&gt; Prometheus\n    Histogram --&gt; OTLP\n\n    style middleware fill:#e53e3e,stroke:#c53030,stroke-width:2px\n    style tracing fill:#6b46c1,stroke:#553c9a\n    style metrics fill:#38a169,stroke:#276749\n    style logging fill:#3182ce,stroke:#2c5282\n    style exporters fill:#d69e2e,stroke:#b7791f</code></pre>"},{"location":"architecture/pluggable-architecture/","title":"Pluggable Architecture","text":"<p>The stack is designed so each layer is replaceable without changing the others. This keeps the core stable while allowing experimentation and integration.</p>"},{"location":"architecture/pluggable-architecture/#extension-points","title":"Extension points","text":""},{"location":"architecture/pluggable-architecture/#what-you-can-plug-in","title":"What you can plug in","text":"<ul> <li>Search: swap lexical for BM25 or semantic ranking</li> <li>Execution: add MCP servers, local handlers, or provider adapters</li> <li>Code execution: change engines or language runtimes</li> <li>Runtime isolation: choose the sandbox backend per environment</li> </ul>"},{"location":"architecture/pluggable-architecture/#design-goal","title":"Design goal","text":"<p>The default implementations are intentionally simple and safe. Advanced capabilities are injected rather than baked into the core.</p>"},{"location":"architecture/progressive-disclosure/","title":"Progressive Disclosure","text":"<p>Progressive disclosure is the core usability strategy of this stack. It lets agents discover just enough information to choose the right tool, then retrieve deeper details only when needed.</p>"},{"location":"architecture/progressive-disclosure/#why-it-matters","title":"Why it matters","text":"<ul> <li>Lower token cost: most tools are never fully expanded</li> <li>Faster decisions: summary-level signals are enough to pick candidates</li> <li>Safer execution: schema and examples are fetched only after a tool is chosen</li> </ul>"},{"location":"architecture/progressive-disclosure/#flow","title":"Flow","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'actorBkg': '#2b6cb0', 'actorTextColor': '#fff', 'actorBorder': '#2c5282'}}}%%\nsequenceDiagram\n    autonumber\n\n    participant Agent as \ud83e\udd16 AI Agent\n    participant MCP as \ud83d\udd37 metatools-mcp\n    participant Index as \ud83d\udcc7 tooldiscovery/index\n    participant Search as \ud83d\udd0d tooldiscovery/search\n    participant Docs as \ud83d\udcda tooldiscovery/tooldoc\n    participant Run as \u25b6\ufe0f toolexec/run\n    participant Cache as \ud83d\udcbe toolops/cache\n    participant Observe as \ud83d\udc41\ufe0f toolops/observe\n\n    rect rgb(43, 108, 176, 0.1)\n        Note over Agent,Search: Phase 1: Discovery (Token-Cheap)\n        Agent-&gt;&gt;+MCP: search_tools(\"create issue\", limit=5)\n        MCP-&gt;&gt;+Index: Search(query, limit)\n        Index-&gt;&gt;+Search: Search(docs, query, limit)\n        Search--&gt;&gt;-Index: scored results\n        Index--&gt;&gt;-MCP: Summary[] (no schemas)\n        MCP--&gt;&gt;-Agent: summaries\n    end\n\n    rect rgb(214, 158, 46, 0.1)\n        Note over Agent,Docs: Phase 2: Description (On-Demand)\n        Agent-&gt;&gt;+MCP: describe_tool(\"github:create_issue\", \"schema\")\n        MCP-&gt;&gt;+Docs: DescribeTool(id, DetailSchema)\n        Docs-&gt;&gt;Index: GetTool(id)\n        Index--&gt;&gt;Docs: Tool definition\n        Docs--&gt;&gt;-MCP: ToolDoc with schema\n        MCP--&gt;&gt;-Agent: full tool schema\n    end\n\n    rect rgb(56, 161, 105, 0.1)\n        Note over Agent,Observe: Phase 3: Execution (Validated)\n        Agent-&gt;&gt;+MCP: run_tool(\"github:create_issue\", args)\n        MCP-&gt;&gt;Observe: StartSpan(\"tool.exec.github.create_issue\")\n        MCP-&gt;&gt;+Cache: Get(toolID, argsHash)\n        alt Cache Hit\n            Cache--&gt;&gt;MCP: cached result\n        else Cache Miss\n            MCP-&gt;&gt;+Run: Run(ctx, id, args)\n            Run-&gt;&gt;Run: ValidateInput(args)\n            Run-&gt;&gt;Run: ResolveBackend()\n            Run-&gt;&gt;Run: Execute via backend\n            Run-&gt;&gt;Run: ValidateOutput(result)\n            Run--&gt;&gt;-MCP: RunResult\n            MCP-&gt;&gt;Cache: Set(toolID, argsHash, result)\n        end\n        Cache--&gt;&gt;-MCP: result\n        MCP-&gt;&gt;Observe: EndSpan(result)\n        MCP--&gt;&gt;-Agent: execution result\n    end</code></pre>"},{"location":"architecture/progressive-disclosure/#detail-levels","title":"Detail Levels","text":"<p>The three progressive detail levels minimize token consumption:</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#3182ce'}}}%%\nflowchart LR\n    subgraph level1[\"DetailSummary\"]\n        S1[\"\ud83d\udccb 1-2 line description\"]\n        S2[\"\ud83c\udff7\ufe0f Tags\"]\n        S3[\"\ud83d\udcc1 Namespace\"]\n    end\n\n    subgraph level2[\"DetailSchema\"]\n        SS1[\"\ud83d\udccb Full description\"]\n        SS2[\"\ud83d\udcd0 Input schema\"]\n        SS3[\"\ud83d\udce4 Output schema\"]\n    end\n\n    subgraph level3[\"DetailFull\"]\n        F1[\"\ud83d\udccb Everything from Schema\"]\n        F2[\"\ud83d\udcdd Human-authored notes\"]\n        F3[\"\ud83d\udca1 1-3 examples\"]\n        F4[\"\ud83d\udd17 External references\"]\n    end\n\n    level1 --&gt;|\"Agent selects tool\"| level2\n    level2 --&gt;|\"Needs examples\"| level3\n\n    style level1 fill:#38a169,stroke:#276749\n    style level2 fill:#d69e2e,stroke:#b7791f\n    style level3 fill:#6b46c1,stroke:#553c9a</code></pre>"},{"location":"architecture/progressive-disclosure/#component-roles","title":"Component Roles","text":"Component Role in Progressive Disclosure <code>tooldiscovery/index</code> Fast, summary-only discovery <code>tooldiscovery/search</code> Pluggable ranking strategy (BM25, semantic) <code>tooldiscovery/semantic</code> Vector-based intent matching <code>tooldiscovery/tooldoc</code> Structured detail (summary/schema/full/examples) <code>toolexec/run</code> Execution with validation + consistent errors <code>toolexec/code</code> Optional code-mode orchestration <code>toolops/cache</code> Cache results to avoid re-execution <code>toolops/observe</code> Trace execution for debugging"},{"location":"architecture/progressive-disclosure/#token-economics","title":"Token Economics","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#38a169'}}}%%\npie showData\n    title Token Distribution by Phase\n    \"Discovery (Summary)\" : 15\n    \"Description (Schema)\" : 35\n    \"Execution (Args/Result)\" : 50</code></pre> <p>Most tools are never fully expanded \u2014 progressive disclosure means you only pay for the detail level you actually need.</p>"},{"location":"architecture/protocol-crosswalk/","title":"Protocol Crosswalk (MCP \u21c4 A2A \u21c4 OpenAI \u21c4 Anthropic \u21c4 Google)","text":"<p>This page maps the canonical tool model to the dominant agent/tool protocols as of 2026-02-02. It exists to keep adapter work grounded in the latest specs and to clarify how we normalize divergent schemas.</p>"},{"location":"architecture/protocol-crosswalk/#canonical-model-toolfoundationadapter","title":"Canonical Model (toolfoundation/adapter)","text":"<p>The stack uses <code>CanonicalTool</code> as the hub for adapter conversions. It captures: - Tool identity (namespace, name, version) - Display metadata (display name, summary, tags, category) - Input/Output schemas (JSON Schema superset) - Execution traits (deterministic, idempotent, streaming, input/output modes) - Security schemes + requirements - Source metadata for round-tripping</p> <p></p>"},{"location":"architecture/protocol-crosswalk/#protocol-snapshot-key-spec-facts","title":"Protocol Snapshot (Key Spec Facts)","text":"<ul> <li>MCP 2025-11-25: JSON-RPC 2.0 base protocol; servers expose resources, prompts, tools; clients may offer sampling, roots, elicitation; explicit user consent is required for data access and tool execution.</li> <li>A2A (Agent2Agent): layered model with canonical data types, abstract operations, and protocol bindings (JSON-RPC, gRPC, HTTP/REST). The AgentCard advertises capabilities, security schemes, and skills.</li> <li>OpenAI Agents SDK: tools can be hosted, local runtime, function tools, or agents-as-tools; function tools derive JSON schema from function signatures.</li> <li>Anthropic tool use: tools are defined by <code>name</code>, <code>description</code>, <code>input_schema</code>; tool calls return <code>tool_use</code> and <code>tool_result</code> content blocks; MCP tools can be used by renaming <code>inputSchema</code> to <code>input_schema</code>.</li> <li>Google Gemini function calling: tool definitions are function declarations with <code>name</code>, <code>description</code>, and <code>parameters</code> defined using a subset of the OpenAPI schema.</li> </ul>"},{"location":"architecture/protocol-crosswalk/#crosswalk-table-concept-mapping","title":"Crosswalk Table (Concept Mapping)","text":"Concept MCP A2A OpenAI Agents Anthropic Google Gemini Tool identity <code>name</code> (+ optional annotations) <code>AgentSkill</code> + Task routing Tool <code>name</code> Tool <code>name</code> Function <code>name</code> Description <code>description</code> Skill description Tool description / docstring <code>description</code> <code>description</code> Input schema <code>inputSchema</code> (JSON Schema) Skill/task inputs (proto \u2192 binding) JSON Schema from function signature <code>input_schema</code> (JSON Schema) <code>parameters</code> (OpenAPI subset) Output schema <code>outputSchema</code> (optional) Task/Artifact outputs Tool output (string/structured) <code>tool_result</code> payload Function response payload Discovery <code>search_tools</code>, <code>describe_tool</code> AgentCard + task listing Tool lists within Agents SDK Tools array in request Tools in request Streaming MCP streaming responses Task/Artifact streaming (SSE/stream) Model streaming events Streaming tool use Streaming responses Security User consent + transport auth Security schemes + requirements API key / tool scopes API key + tool permissions API key / IAM"},{"location":"architecture/protocol-crosswalk/#adapter-guidance","title":"Adapter Guidance","text":"<ul> <li>Use <code>CanonicalTool</code> as the source of truth and preserve vendor-specific fields in <code>SourceMeta</code> for round-trip fidelity.</li> <li>Normalize schemas to JSON Schema internally and emit feature-loss warnings for protocols that do not support advanced schema features.</li> <li>Treat A2A AgentCard as a tool provider descriptor and map A2A skills to canonical tools.</li> <li>Use <code>CanonicalProvider</code> to model provider-level capabilities, security schemes, and default I/O modes.</li> <li>Map OpenAI/Anthropic/Gemini function tools to canonical tools with <code>InputSchema</code> and <code>OutputSchema</code>, and surface tool categories as tags or backend hints.</li> </ul>"},{"location":"architecture/protocol-crosswalk/#sources-urls","title":"Sources (URLs)","text":"<pre><code>https://modelcontextprotocol.io/specification/2025-11-25\nhttps://a2a-protocol.org/latest/specification/\nhttps://agent2agent.info/specification/\nhttps://openai.github.io/openai-agents-python/tools/\nhttps://platform.openai.com/docs/guides/agents-sdk\nhttps://platform.claude.com/docs/en/agents-and-tools/tool-use/overview\nhttps://ai.google.dev/gemini-api/docs/function-calling\nhttps://docs.cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling\n</code></pre>"},{"location":"architecture/stack-map/","title":"Stack Map (Repos, Packages, Interfaces)","text":"<p>This page summarizes what each repo is for and the primary interfaces that make the stack composable. It is the quickest way to see how pieces fit together and where to extend the system.</p>"},{"location":"architecture/stack-map/#toolfoundation-schemas-canonical-tool-model","title":"toolfoundation (Schemas + Canonical Tool Model)","text":"<p>Purpose: canonical tool representation, schema validation, adapter registry, versioning.</p> <p>Key packages: - <code>model</code> (MCP-aligned tool model + tags + backend binding) - <code>adapter</code> (protocol adapters and canonical tool) - <code>version</code> (stack version utilities)</p> <p>Key interfaces: - <code>SchemaValidator</code> (model) - <code>Adapter</code> (adapter)</p>"},{"location":"architecture/stack-map/#tooldiscovery-index-search-progressive-docs","title":"tooldiscovery (Index + Search + Progressive Docs)","text":"<p>Purpose: tool registry, search strategies, and progressive documentation levels.</p> <p>Key packages: - <code>index</code> (registry + search interfaces) - <code>search</code> (BM25 search) - <code>semantic</code> (embedding-based search) - <code>tooldoc</code> (progressive disclosure) - <code>discovery</code> (composite facade)</p> <p>Key interfaces: - <code>Index</code>, <code>Searcher</code>, <code>DeterministicSearcher</code>, <code>ChangeNotifier</code>, <code>Refresher</code> (index) - <code>Indexer</code>, <code>Strategy</code>, <code>Embedder</code>, <code>Searcher</code> (semantic) - <code>Store</code> (tooldoc)</p>"},{"location":"architecture/stack-map/#toolexec-execution-runtime-isolation","title":"toolexec (Execution + Runtime Isolation)","text":"<p>Purpose: validated tool execution across local, provider, and MCP backends; runtime isolation.</p> <p>Key packages: - <code>run</code> (tool invocation + chaining) - <code>backend</code> (backend registry + aggregator) - <code>code</code> (code execution engine) - <code>runtime</code> (sandboxed execution backends)</p> <p>Key interfaces: - <code>MCPExecutor</code>, <code>ProviderExecutor</code>, <code>Runner</code>, <code>ProgressRunner</code>, <code>LocalRegistry</code> (run) - <code>Backend</code>, <code>ConfigurableBackend</code>, <code>StreamingBackend</code> (backend) - <code>Executor</code>, <code>Engine</code>, <code>Tools</code> (code) - <code>Runtime</code>, <code>Backend</code>, <code>ToolGateway</code> (runtime)</p>"},{"location":"architecture/stack-map/#toolexec-integrations-runtime-clients","title":"toolexec-integrations (Runtime Clients)","text":"<p>Purpose: concrete runtime client implementations (Kubernetes, Proxmox, remote HTTP).</p> <p>Key packages: - <code>kubernetes</code> (client-go PodRunner/HealthChecker) - <code>proxmox</code> (HTTP API client for LXC) - <code>remotehttp</code> (HTTP/SSE client for remote runtime service)</p> <p>Key interfaces implemented: - <code>kubernetes.PodRunner</code>, <code>kubernetes.HealthChecker</code> - <code>proxmox.APIClient</code> - <code>remote.RemoteClient</code></p>"},{"location":"architecture/stack-map/#toolcompose-toolsets-skills","title":"toolcompose (Toolsets + Skills)","text":"<p>Purpose: composition of tools into sets/skills with policy and guardrails.</p> <p>Key packages: - <code>set</code> (registry and policy) - <code>skill</code> (skill execution and guards)</p> <p>Key interfaces: - <code>Registry</code>, <code>Policy</code> (set) - <code>Guard</code>, <code>Runner</code> (skill)</p>"},{"location":"architecture/stack-map/#toolops-auth-cache-observe-health","title":"toolops (Auth + Cache + Observe + Health)","text":"<p>Purpose: operational concerns for tool execution and serving.</p> <p>Key packages: - <code>auth</code> (authn/authz) - <code>cache</code> (tool result caching) - <code>observe</code> (tracing/metrics/logging) - <code>health</code> (health checks) - <code>resilience</code> (retry/circuit/bulkhead utilities)</p> <p>Key interfaces: - <code>Authenticator</code>, <code>Authorizer</code>, <code>APIKeyStore</code>, <code>KeyProvider</code> (auth) - <code>Cache</code>, <code>Keyer</code> (cache) - <code>Observer</code>, <code>Tracer</code>, <code>Metrics</code>, <code>Logger</code> (observe) - <code>Checker</code>, <code>PingChecker</code>, <code>InfoChecker</code> (health)</p>"},{"location":"architecture/stack-map/#toolprotocol-protocol-primitives","title":"toolprotocol (Protocol Primitives)","text":"<p>Purpose: protocol-agnostic primitives for transport/wire/content/task/streaming.</p> <p>Key packages: - <code>transport</code> (server + transport contracts) - <code>wire</code> (encoding/decoding) - <code>discover</code> (discovery primitives) - <code>content</code> (content payloads) - <code>task</code> (task state machine) - <code>stream</code> (streaming primitives) - <code>session</code> (session storage) - <code>resource</code> (resource providers/subscribers) - <code>prompt</code> (prompt providers) - <code>elicit</code> (elicitation protocol)</p> <p>Key interfaces: - <code>Transport</code>, <code>Server</code> (transport) - <code>Wire</code> (wire) - <code>Discovery</code>, <code>Discoverable</code> (discover) - <code>Content</code> (content) - <code>Manager</code>, <code>Store</code> (task) - <code>Stream</code>, <code>Source</code>, <code>Sink</code> (stream) - <code>Store</code> (session) - <code>Provider</code>, <code>Subscriber</code> (resource) - <code>Provider</code> (prompt) - <code>Elicitor</code>, <code>Handler</code> (elicit)</p>"},{"location":"architecture/stack-map/#metatools-mcp-reference-mcp-server","title":"metatools-mcp (Reference MCP Server)","text":"<p>Purpose: MCP server that wires the stack together; reference implementation.</p> <p>Key interfaces: - <code>ToolProvider</code>, <code>ConfigurableProvider</code>, <code>StreamingProvider</code> (provider) - <code>Index</code>, <code>Store</code>, <code>Runner</code>, <code>ProgressRunner</code>, <code>Executor</code> (handlers) - <code>Transport</code>, <code>Server</code> (transport)</p>"},{"location":"architecture/stack-map/#metatools-a2a-reference-a2a-server","title":"metatools-a2a (Reference A2A Server)","text":"<p>Purpose: A2A server that wires the stack together; reference implementation.</p> <p>Key interfaces: - <code>Agent</code>, <code>InvokeResult</code> (toolprotocol/a2a) - <code>Index</code>, <code>Discovery</code>, <code>Runner</code> (discovery + execution) - <code>Task.Manager</code> (task streaming)</p>"},{"location":"architecture/stack-map/#how-it-fits-together-conceptual","title":"How It Fits Together (Conceptual)","text":"<ul> <li><code>toolfoundation</code> defines canonical data and adapters.</li> <li><code>tooldiscovery</code> finds tools and serves progressive docs.</li> <li><code>toolexec</code> validates and runs tools across backends and runtimes.</li> <li><code>toolexec-integrations</code> supplies opt-in runtime SDK clients.</li> <li><code>toolcompose</code> builds toolsets/skills and applies policies.</li> <li><code>toolops</code> adds security, caching, and observability.</li> <li><code>toolprotocol</code> standardizes transports and protocol primitives.</li> <li><code>metatools-mcp</code> exposes everything via MCP as a reference server.</li> <li><code>metatools-a2a</code> exposes everything via A2A as a reference server.</li> </ul>"},{"location":"architecture/user-journeys/","title":"User Journeys Index","text":"<p>This page aggregates the per\u2011repo User Journey pages that describe full end\u2011to\u2011end workflows. These are ideal for onboarding and for validating that the progressive\u2011disclosure flow is coherent across layers.</p>"},{"location":"architecture/user-journeys/#perrepo-user-journeys","title":"Per\u2011repo User Journeys","text":"<ul> <li>toolfoundation \u2014 user-journey</li> <li>tooldiscovery \u2014 user-journey</li> <li>toolexec \u2014 user-journey</li> <li>toolcompose \u2014 user-journey</li> <li>toolops \u2014 user-journey</li> <li>toolprotocol \u2014 user-journey</li> <li>metatools-mcp \u2014 user-journey</li> <li>metatools\u2011mcp \u2014 user-journey</li> </ul>"},{"location":"architecture/user-journeys/#when-to-read-these","title":"When to read these","text":"<ul> <li>You want to understand how an agent discovers, inspects, and runs tools.</li> <li>You\u2019re validating the progressive disclosure path across components.</li> <li>You want examples that show how the pieces fit together end\u2011to\u2011end.</li> </ul>"},{"location":"architecture/why-go/","title":"Why Go","text":"<p>Go is a strong fit for this stack because it pairs high performance with a simple concurrency model and a clean interface story.</p>"},{"location":"architecture/why-go/#advantages-for-this-stack","title":"Advantages for this stack","text":""},{"location":"architecture/why-go/#compiled-fast-startup","title":"Compiled + fast startup","text":"<ul> <li>Small binaries and quick startup times are ideal for MCP servers</li> <li>Predictable performance for low-latency tool calls</li> </ul>"},{"location":"architecture/why-go/#concurrency-without-complexity","title":"Concurrency without complexity","text":"<ul> <li>Goroutines and channels make async tool execution straightforward</li> <li><code>context.Context</code> enables timeouts and cancellation across the stack</li> </ul>"},{"location":"architecture/why-go/#interface-first-extensibility","title":"Interface-first extensibility","text":"<ul> <li>Each layer (<code>Searcher</code>, <code>Runner</code>, <code>Engine</code>, <code>Backend</code>) is interface-driven</li> <li>You can plug in new languages, providers, or runtimes without redesigning</li> </ul>"},{"location":"architecture/why-go/#operational-simplicity","title":"Operational simplicity","text":"<ul> <li>Static binaries simplify deployment</li> <li>Works equally well in containers, VMs, or bare metal</li> </ul>"},{"location":"architecture/why-go/#summary","title":"Summary","text":"<p>Go lets you build a composable system that is fast, concurrent, and easy to extend. That is exactly what this stack needs.</p>"},{"location":"components/metatools-a2a/","title":"metatools-a2a","text":"<p><code>metatools-a2a</code> is the A2A reference server in the ApertureStack stack. It exposes the same tool ecosystem as metatools-mcp, but with A2A JSON-RPC, REST, and SSE streaming surfaces.</p> <p></p>"},{"location":"components/metatools-a2a/#responsibilities","title":"Responsibilities","text":"<ul> <li>Publish an A2A AgentCard</li> <li>Expose skills derived from <code>tooldiscovery</code></li> <li>Execute tools via <code>toolexec</code> and stream task updates</li> </ul>"},{"location":"components/metatools-a2a/#key-interfaces","title":"Key Interfaces","text":"<ul> <li><code>POST /a2a</code> \u2014 JSON-RPC <code>agent/invoke</code>, <code>agent/status</code></li> <li><code>GET /a2a/agent-card</code> \u2014 AgentCard document</li> <li><code>GET /a2a/skills</code> \u2014 skill list</li> <li><code>GET /a2a/tasks/{id}/events</code> \u2014 SSE task updates</li> </ul>"},{"location":"components/metatools-a2a/#dependencies","title":"Dependencies","text":"<ul> <li><code>toolfoundation</code> \u2014 canonical model + adapters</li> <li><code>tooldiscovery</code> \u2014 tool registry and docs</li> <li><code>toolexec</code> \u2014 execution pipeline</li> <li><code>toolprotocol</code> \u2014 A2A protocol binding</li> </ul>"},{"location":"components/metatools-mcp/","title":"metatools-mcp","text":"<p>MCP server that exposes the tool stack via standardized MCP tools with a progressive-disclosure flow.</p> <p>Companion A2A surface: see <code>metatools-a2a</code>.</p>"},{"location":"components/metatools-mcp/#motivation","title":"Motivation","text":"<ul> <li>Provide a minimal, consistent MCP surface</li> <li>Keep discovery cheap and execution safe</li> <li>Enable pluggable search and optional code execution</li> </ul>"},{"location":"components/metatools-mcp/#core-responsibilities","title":"Core responsibilities","text":"<ul> <li>Expose <code>search_tools</code>, <code>list_namespaces</code></li> <li>Expose <code>describe_tool</code>, <code>list_tool_examples</code></li> <li>Expose <code>run_tool</code>, <code>run_chain</code></li> <li>Optionally expose <code>execute_code</code></li> <li>Use the official MCP Go SDK</li> </ul>"},{"location":"components/metatools-mcp/#transport-surface","title":"Transport surface","text":"<ul> <li><code>stdio</code> (default): local clients/Claude Desktop.</li> <li><code>streamable</code> (recommended HTTP): MCP spec 2025-11-25 with session management.</li> <li><code>sse</code> (deprecated): legacy web clients.</li> </ul> <p>See <code>metatools-mcp/docs/usage.md</code> for the full config/env matrix.</p>"},{"location":"components/metatools-mcp/#optional-runtime-integration","title":"Optional runtime integration","text":"<p><code>execute_code</code> is enabled with the <code>toolruntime</code> build tag and selects a runtime profile at startup:</p> <ul> <li><code>dev</code> profile (default): unsafe subprocess backend.</li> <li><code>standard</code> profile: Docker sandbox (set <code>METATOOLS_RUNTIME_PROFILE=standard</code>).</li> <li><code>METATOOLS_DOCKER_IMAGE</code> overrides the sandbox image name.</li> <li><code>METATOOLS_WASM_ENABLED=true</code> enables the WASM backend (wazero).</li> <li><code>METATOOLS_RUNTIME_BACKEND=wasm</code> selects WASM for the standard profile.</li> </ul>"},{"location":"components/metatools-mcp/#example","title":"Example","text":"<pre><code>srv, _ := server.New(cfg)\n_ = srv.Run(context.Background(), &amp;mcp.StdioTransport{})\n</code></pre>"},{"location":"components/metatools-mcp/#diagram","title":"Diagram","text":""},{"location":"components/metatools-mcp/#usability-notes","title":"Usability notes","text":"<ul> <li>Small tool surface reduces prompt complexity</li> <li>Schemas and examples are fetched on demand</li> </ul>"},{"location":"components/toolcompose/","title":"toolcompose","text":"<p>Composition layer providing filtered tool collections and skill-based workflows. This repository enables building higher-level abstractions over tools.</p>"},{"location":"components/toolcompose/#packages","title":"Packages","text":"Package Purpose <code>set</code> Filtered tool collections with predicates <code>skill</code> Skill-based workflow composition"},{"location":"components/toolcompose/#motivation","title":"Motivation","text":"<ul> <li>Group related tools into logical collections</li> <li>Enable skill-based workflows for common tasks</li> <li>Provide filtered views without duplicating tools</li> <li>Support composition patterns for complex operations</li> </ul>"},{"location":"components/toolcompose/#set-package","title":"set Package","text":"<p>The <code>set</code> package provides filtered tool collections using predicates.</p>"},{"location":"components/toolcompose/#core-responsibilities","title":"Core Responsibilities","text":"<ul> <li>Create filtered views of tool registries</li> <li>Apply namespace, tag, and custom predicates</li> <li>Chain filters for complex selections</li> <li>Export filtered sets in multiple formats</li> </ul>"},{"location":"components/toolcompose/#example","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolcompose/set\"\n  \"github.com/jonwraymond/toolfoundation/adapter\"\n)\n\ntools := []*adapter.CanonicalTool{\n  {Namespace: \"github\", Name: \"create_issue\", Tags: []string{\"issues\"}, InputSchema: &amp;adapter.JSONSchema{Type: \"object\"}},\n  {Namespace: \"github\", Name: \"add_labels\", Tags: []string{\"issues\"}, InputSchema: &amp;adapter.JSONSchema{Type: \"object\"}},\n}\n\nts, _ := set.NewBuilder(\"github-issues\").\n  FromTools(tools).\n  WithNamespace(\"github\").\n  WithTags([]string{\"issues\"}).\n  WithPolicy(set.DenyTags(\"danger\")).\n  Build()\n\nids := ts.IDs()\n</code></pre>"},{"location":"components/toolcompose/#built-in-predicates","title":"Built-in Predicates","text":"Predicate Description <code>NamespaceFilter(ns...)</code> Match any namespace <code>TagsAny(tags...)</code> Match tools with any tag <code>TagsAll(tags...)</code> Match tools with all tags <code>TagsNone(tags...)</code> Match tools with none of the tags <code>CategoryFilter(cats...)</code> Match any category <code>AllowIDs(ids...)</code> Allow only listed IDs <code>DenyIDs(ids...)</code> Exclude listed IDs"},{"location":"components/toolcompose/#skill-package","title":"skill Package","text":"<p>The <code>skill</code> package provides skill-based workflow composition.</p>"},{"location":"components/toolcompose/#features","title":"Features","text":"<ul> <li>Define declarative skills from tool steps</li> <li>Deterministic planning (sorted by step ID)</li> <li>Guardrails for max steps and allowed tool IDs</li> <li>Execution via a pluggable runner</li> </ul>"},{"location":"components/toolcompose/#example_1","title":"Example","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolcompose/skill\"\n  \"github.com/jonwraymond/toolexec/run\"\n)\n\nsk := skill.Skill{\n  Name: \"create-issue\",\n  Steps: []skill.Step{\n    {ID: \"create\", ToolID: \"github:create_issue\", Inputs: map[string]any{\"title\": \"Bug report\"}},\n    {ID: \"label\", ToolID: \"github:add_labels\", Inputs: map[string]any{\"labels\": []string{\"bug\"}}},\n  },\n}\n\nplan, _ := skill.NewPlanner().Plan(sk)\n\ntype runAdapter struct{ exec run.Runner }\nfunc (r runAdapter) Run(ctx context.Context, step skill.Step) (any, error) {\n  res, err := r.exec.Run(ctx, step.ToolID, step.Inputs)\n  if err != nil {\n    return nil, err\n  }\n  return res.Output, nil\n}\n\nrunner := run.NewRunner()\n_, err := skill.Execute(context.Background(), plan, runAdapter{exec: runner})\n</code></pre>"},{"location":"components/toolcompose/#skill-composition","title":"Skill Composition","text":"<pre><code>flowchart TB\n    Input[\"Skill Inputs\"] --&gt; Step1[\"Step 1: create_issue\"]\n    Step1 --&gt; Cond{\"Has labels?\"}\n    Cond --&gt;|Yes| Step2[\"Step 2: add_labels\"]\n    Cond --&gt;|No| Output\n    Step2 --&gt; Output[\"Skill Output\"]</code></pre>"},{"location":"components/toolcompose/#diagram","title":"Diagram","text":""},{"location":"components/toolcompose/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Deterministic sets: Toolset listing is sorted and repeatable</li> <li>Filter + policy: Filters reduce candidates, policies enforce access</li> <li>Declarative skills: Skills are pure definitions, not executors</li> <li>Pluggable runners: Execution integrates with any tool runner</li> </ol>"},{"location":"components/toolcompose/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Design notes</li> <li>User journey</li> </ul>"},{"location":"components/tooldiscovery/","title":"tooldiscovery","text":"<p>Discovery layer providing tool registry, search strategies, and progressive documentation. This repository enables efficient tool discovery through multiple search approaches.</p>"},{"location":"components/tooldiscovery/#packages","title":"Packages","text":"Package Purpose <code>index</code> Global registry and lookup by tool ID <code>search</code> BM25-based full-text search strategy <code>semantic</code> Embedding-based semantic search (optional) <code>tooldoc</code> Progressive documentation with detail levels <code>discovery</code> Unified facade combining index + search + semantic + tooldoc <code>registry</code> MCP server helper with local + backend execution"},{"location":"components/tooldiscovery/#motivation","title":"Motivation","text":"<ul> <li>Keep discovery fast and cheap (token-efficient)</li> <li>Decouple search quality from core registry</li> <li>Support multiple search strategies (lexical, BM25, semantic)</li> <li>Provide progressive disclosure of tool documentation</li> <li>Offer a unified facade for most consumers (<code>discovery</code>)</li> </ul>"},{"location":"components/tooldiscovery/#discovery-package","title":"discovery Package","text":"<p>The <code>discovery</code> package provides a simple API that composes index, search, semantic search, and documentation into one facade.</p>"},{"location":"components/tooldiscovery/#example","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/discovery\"\n\ndisc, _ := discovery.New(discovery.Options{})\n_ = disc.RegisterTool(tool, backend)\n\nresults, _ := disc.Search(context.Background(), \"create issue\", 5)\nfor _, r := range results {\n  fmt.Println(r.ScoreType, r.Summary.ID)\n}\n</code></pre>"},{"location":"components/tooldiscovery/#registry-package","title":"registry Package","text":"<p>The <code>registry</code> package is a high-level helper for building MCP servers that combines index, search, local handlers, and MCP backend aggregation.</p>"},{"location":"components/tooldiscovery/#example_1","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/registry\"\n\nreg := registry.New(registry.Config{\n  ServerInfo: registry.ServerInfo{Name: \"my-mcp\", Version: \"1.0.0\"},\n})\n\n_ = reg.RegisterLocalFunc(\n  \"echo\",\n  \"Echo input\",\n  map[string]any{\"type\": \"object\"},\n  func(ctx context.Context, args map[string]any) (any, error) { return args, nil },\n)\n\n_ = reg.Start(context.Background())\ndefer reg.Stop()\n</code></pre>"},{"location":"components/tooldiscovery/#index-package","title":"index Package","text":"<p>The <code>index</code> package provides the global registry and search layer for tools.</p>"},{"location":"components/tooldiscovery/#core-responsibilities","title":"Core Responsibilities","text":"<ul> <li>Register tools + backends</li> <li>Search by name/namespace/description/tags</li> <li>List namespaces</li> <li>Resolve tools by canonical ID</li> </ul>"},{"location":"components/tooldiscovery/#example_2","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/index\"\n\nidx := index.NewInMemoryIndex()\n\n_ = idx.RegisterTool(tool, backend)\n\nsummaries, _ := idx.Search(\"repo\", 5)\nfor _, s := range summaries {\n  fmt.Println(s.ID, s.ShortDescription)\n}\n</code></pre>"},{"location":"components/tooldiscovery/#search-package","title":"search Package","text":"<p>The <code>search</code> package provides BM25-based full-text search using Bleve.</p>"},{"location":"components/tooldiscovery/#features","title":"Features","text":"<ul> <li>BM25 ranking algorithm</li> <li>Field boosts (name: 4x, namespace: 2x, tags: 1x)</li> <li>Fuzzy matching support</li> <li>Pluggable into index via <code>SearchStrategy</code> interface</li> </ul>"},{"location":"components/tooldiscovery/#example_3","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/search\"\n\nsearcher, _ := search.NewBM25Searcher(search.DefaultConfig())\ndefer searcher.Close()\n\n// Index documents\nsearcher.Index(docs)\n\n// Search\nresults, _ := searcher.Search(\"create issue\", 10)\n</code></pre>"},{"location":"components/tooldiscovery/#semantic-package","title":"semantic Package","text":"<p>The <code>semantic</code> package provides embedding-based semantic search (optional).</p>"},{"location":"components/tooldiscovery/#features_1","title":"Features","text":"<ul> <li>Vector similarity search</li> <li>Configurable embedder interface</li> <li>Cosine similarity ranking</li> <li>Hybrid search support (combine with BM25)</li> </ul>"},{"location":"components/tooldiscovery/#tooldoc-package","title":"tooldoc Package","text":"<p>The <code>tooldoc</code> package provides progressive documentation with multiple detail levels.</p>"},{"location":"components/tooldiscovery/#detail-levels","title":"Detail Levels","text":"Level Contents Use Case <code>Summary</code> Name, namespace, short description Listing, filtering <code>Schema</code> Input/output JSON schemas Execution <code>Full</code> Everything including metadata Documentation"},{"location":"components/tooldiscovery/#example_4","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n\nstore := tooldoc.NewInMemoryStore()\n\n// Get progressive documentation\ndoc, _ := store.GetDoc(toolID, tooldoc.DetailSchema)\nfmt.Println(doc.Tool.InputSchema)\n</code></pre>"},{"location":"components/tooldiscovery/#schemas-and-contracts","title":"Schemas and Contracts","text":"<p>tooldiscovery defines data contracts for discovery payloads (summaries, documentation records, and results) and relies on toolfoundation for JSON Schema validation. See:</p> <ul> <li>schemas and contracts</li> </ul>"},{"location":"components/tooldiscovery/#diagram","title":"Diagram","text":""},{"location":"components/tooldiscovery/#search-strategy-layering","title":"Search Strategy Layering","text":"<pre><code>flowchart TB\n    Query[\"Search Query\"] --&gt; Index[\"index.Search()\"]\n    Index --&gt; Lexical[\"Lexical (default)\"]\n    Index --&gt; BM25[\"search.BM25Searcher\"]\n    Index --&gt; Semantic[\"semantic.Searcher\"]\n\n    Lexical --&gt; Results\n    BM25 --&gt; Results\n    Semantic --&gt; Results\n\n    Results[\"Ranked Results\"]</code></pre>"},{"location":"components/tooldiscovery/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Pluggable strategies: Search implementations are swappable</li> <li>Token efficiency: Summaries exclude schemas to reduce tokens</li> <li>Progressive disclosure: Request only the detail level needed</li> <li>Optional semantic: Vector search is opt-in (requires embeddings)</li> </ol>"},{"location":"components/tooldiscovery/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Design notes</li> <li>User journey</li> <li>Schemas and contracts</li> <li>Architecture</li> <li>Concurrency</li> <li>Registry</li> </ul>"},{"location":"components/toolexec-integrations/","title":"toolexec-integrations","text":"<p>Purpose: concrete runtime client integrations for <code>toolexec</code> core.</p>"},{"location":"components/toolexec-integrations/#what-it-provides","title":"What it provides","text":"<ul> <li>Kubernetes client\u2011go implementation of <code>kubernetes.PodRunner</code></li> <li>Proxmox HTTP API client implementing <code>proxmox.APIClient</code></li> <li>Remote HTTP/SSE client implementing <code>remote.RemoteClient</code></li> </ul>"},{"location":"components/toolexec-integrations/#why-it-exists","title":"Why it exists","text":"<p><code>toolexec</code> core is interface\u2011only for runtime backends. This repo holds the SDKs and HTTP stacks so downstream consumers can opt in to only what they need.</p>"},{"location":"components/toolexec-integrations/#entrypoints","title":"Entrypoints","text":"<ul> <li><code>github.com/jonwraymond/toolexec-integrations/kubernetes</code></li> <li><code>github.com/jonwraymond/toolexec-integrations/proxmox</code></li> <li><code>github.com/jonwraymond/toolexec-integrations/remotehttp</code></li> </ul>"},{"location":"components/toolexec-integrations/#related","title":"Related","text":"<ul> <li><code>toolexec</code></li> <li><code>stack map</code></li> </ul>"},{"location":"components/toolexec/","title":"toolexec","text":"<p>Execution layer providing tool running, code orchestration, and runtime isolation. This repository handles the actual execution of tools across different backend types.</p>"},{"location":"components/toolexec/#packages","title":"Packages","text":"Package Purpose <code>exec</code> Unified facade combining discovery + execution <code>run</code> Core tool execution and chaining <code>code</code> Code-based tool orchestration <code>runtime</code> Sandbox and runtime isolation <code>backend</code> Backend registry and resolution"},{"location":"components/toolexec/#motivation","title":"Motivation","text":"<ul> <li>Execute tools with proper validation and error handling</li> <li>Support multiple backend types (local, provider, MCP server)</li> <li>Enable tool chaining and orchestration</li> <li>Provide secure runtime isolation</li> </ul>"},{"location":"components/toolexec/#run-package","title":"run Package","text":"<p>The <code>run</code> package provides the core tool execution engine.</p>"},{"location":"components/toolexec/#core-responsibilities","title":"Core Responsibilities","text":"<ul> <li>Validate input against tool schema</li> <li>Resolve backend and execute</li> <li>Normalize results</li> <li>Validate output against schema</li> </ul>"},{"location":"components/toolexec/#example","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/toolexec/run\"\n\nrunner := run.NewRunner(run.Config{\n  Index:    idx,\n  Backends: backends,\n})\n\nresult, err := runner.Run(ctx, \"github:create_issue\", map[string]any{\n  \"owner\": \"jonwraymond\",\n  \"repo\":  \"toolexec\",\n  \"title\": \"New issue\",\n})\n</code></pre>"},{"location":"components/toolexec/#execution-pipeline","title":"Execution Pipeline","text":"<pre><code>flowchart LR\n    Input[\"Tool ID + Args\"] --&gt; Validate1[\"Validate Input\"]\n    Validate1 --&gt; Resolve[\"Resolve Backend\"]\n    Resolve --&gt; Execute[\"Execute\"]\n    Execute --&gt; Normalize[\"Normalize Result\"]\n    Normalize --&gt; Validate2[\"Validate Output\"]\n    Validate2 --&gt; Result[\"RunResult\"]</code></pre>"},{"location":"components/toolexec/#exec-package","title":"exec Package","text":"<p>The <code>exec</code> facade composes discovery, documentation, and execution behind a single API for most callers.</p>"},{"location":"components/toolexec/#example_1","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolexec/exec\"\n  \"github.com/jonwraymond/tooldiscovery/index\"\n  \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n)\n\nidx := index.NewInMemoryIndex()\ndocs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\nexecutor, err := exec.New(exec.Options{Index: idx, Docs: docs})\nresult, err := executor.RunTool(ctx, \"math:add\", map[string]any{\"a\": 5, \"b\": 3})\n</code></pre>"},{"location":"components/toolexec/#code-package","title":"code Package","text":"<p>The <code>code</code> package provides code-based tool orchestration for complex workflows.</p>"},{"location":"components/toolexec/#features","title":"Features","text":"<ul> <li>Multi-tool orchestration</li> <li>Conditional execution</li> <li>Result aggregation</li> <li>Error handling with retries</li> </ul>"},{"location":"components/toolexec/#example_2","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/toolexec/code\"\n\nexecutor := code.NewExecutor(runner)\n\n// Execute a workflow\nresult, err := executor.Execute(ctx, `\n  issue := run(\"github:create_issue\", {title: \"Bug fix\"})\n  run(\"github:add_labels\", {issue: issue.number, labels: [\"bug\"]})\n`)\n</code></pre>"},{"location":"components/toolexec/#runtime-package","title":"runtime Package","text":"<p>The <code>runtime</code> package provides sandbox and runtime isolation for tool execution.</p> <p></p>"},{"location":"components/toolexec/#supported-runtimes","title":"Supported Runtimes","text":"Runtime Isolation Use Case <code>unsafe_host</code> Process Trusted tools (dev only) <code>docker</code> Container Standard isolation <code>containerd</code> Container Infra-native runtime <code>kubernetes</code> Pod/Job Cluster scheduling + quotas <code>gvisor</code> Container sandbox Hardened isolation <code>kata</code> MicroVM VM-level isolation <code>firecracker</code> MicroVM Strongest isolation <code>wasm</code> In-process sandbox Constrained SDK surface <code>remote</code> Remote service Dedicated runtime fleet <code>proxmox_lxc</code> LXC container Proxmox-backed runtime <code>temporal</code> Orchestrator Long-running workflows"},{"location":"components/toolexec/#runtime-backends-readiness","title":"Runtime Backends (Readiness)","text":"Backend Readiness Notes <code>unsafe_host</code> prod Development only; no isolation <code>docker</code> prod Default container isolation <code>containerd</code> beta Direct CRI runtime <code>kubernetes</code> beta Jobs/pods + runtimeClass <code>gvisor</code> beta runsc sandbox <code>kata</code> beta VM-level isolation <code>firecracker</code> beta MicroVM runtime <code>wasm</code> beta Wazero execution <code>remote</code> beta Signed HTTP runtime <code>proxmox_lxc</code> beta Proxmox API + runtime service <code>temporal</code> stub Orchestration only; compose with sandbox <p>Concrete runtime clients (Kubernetes, Proxmox, remote HTTP) live in <code>toolexec-integrations</code> and are injected into these backends via interfaces.</p>"},{"location":"components/toolexec/#example_3","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n  \"github.com/jonwraymond/toolexec/runtime\"\n  \"github.com/jonwraymond/toolexec/runtime/backend/unsafe\"\n  \"github.com/jonwraymond/toolexec/runtime/gateway/direct\"\n)\n\ndocs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\ngateway := direct.New(direct.Config{Index: idx, Docs: docs, Runner: runner})\n\nrt := runtime.NewDefaultRuntime(runtime.RuntimeConfig{\n  Backends: map[runtime.SecurityProfile]runtime.Backend{\n    runtime.ProfileDev: unsafe.New(unsafe.Config{RequireOptIn: true}),\n  },\n  DefaultProfile: runtime.ProfileDev,\n})\n\nresult, err := rt.Execute(ctx, runtime.ExecuteRequest{\n  Language: \"go\",\n  Code:     `__out = \"ok\"`,\n  Profile:  runtime.ProfileDev,\n  Gateway:  gateway,\n  Metadata: map[string]any{\"unsafeOptIn\": true},\n})\n</code></pre>"},{"location":"components/toolexec/#backend-package","title":"backend Package","text":"<p>The <code>backend</code> package provides backend registry and resolution.</p>"},{"location":"components/toolexec/#backend-types","title":"Backend Types","text":"Type Description <code>local</code> In-process handler function <code>provider</code> External tool provider <code>mcp</code> Remote MCP server"},{"location":"components/toolexec/#example_4","title":"Example","text":"<pre><code>import \"github.com/jonwraymond/toolexec/backend\"\n\nregistry := backend.NewRegistry()\n\n// Register a local backend\nregistry.Register(\"calculator\", backend.Local(func(ctx context.Context, args any) (any, error) {\n  // Implementation\n}))\n\n// Resolve backend for tool\nb, err := registry.Resolve(tool.Backend)\n</code></pre>"},{"location":"components/toolexec/#schemas-and-contracts","title":"Schemas and Contracts","text":"<p>toolexec enforces the canonical tool schema from toolfoundation. It does not define new input/output schemas; instead it validates against each <code>model.Tool</code> schema at execution time.</p> <p>Key guarantees:</p> <ul> <li>InputSchema is required for all tools.</li> <li>OutputSchema is optional; output validation runs only when present.</li> <li>Execution results are normalized into <code>run.RunResult</code> and <code>exec.Result</code>.</li> <li>Streaming uses <code>run.StreamEvent</code> with <code>progress</code>, <code>chunk</code>, <code>done</code>, <code>error</code>.</li> </ul> <p>See the full schema and contract details in: - toolexec schemas - toolfoundation schemas</p>"},{"location":"components/toolexec/#examples","title":"Examples","text":"<p>Runnable examples cover execution, chaining, discovery, and runtimes:</p> <pre><code>go run ./examples/basic\ngo run ./examples/chain\ngo run ./examples/discovery\ngo run ./examples/streaming\ngo run ./examples/runtime\ngo run ./examples/full\n</code></pre>"},{"location":"components/toolexec/#diagram","title":"Diagram","text":""},{"location":"components/toolexec/#architecture-plan-summary","title":"Architecture Plan Summary","text":"<p>The <code>toolexec</code> architecture plan focused on delivering a unified execution surface while keeping each layer isolated and testable:</p> <ul> <li>Facade-first API: <code>exec.Exec</code> provides the primary entry point, composing   discovery, documentation, and execution behind a single interface.</li> <li>Deterministic execution: <code>run.DefaultRunner</code> enforces a strict pipeline   (resolve \u2192 validate \u2192 execute \u2192 normalize \u2192 validate) with structured results.</li> <li>Runtime isolation: the <code>runtime</code> package allows sandboxed execution for   code workflows without coupling to tool execution paths.</li> <li>Schema contracts: execution never invents schemas; it validates against   <code>toolfoundation</code> and surfaces structured results for downstream chaining.</li> </ul> <p>See the full plan for rationale and milestones: Architecture plan.</p>"},{"location":"components/toolexec/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Schema validation: Both input and output are validated</li> <li>Backend abstraction: Execution is decoupled from backend type</li> <li>Unified facade: Most callers use exec instead of wiring packages</li> <li>Pluggable runtimes: Security profiles are configurable</li> <li>Chaining support: Tools can call other tools</li> </ol>"},{"location":"components/toolexec/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Schemas and contracts</li> <li>Architecture</li> <li>Design notes</li> <li>User journey</li> <li>Examples</li> <li>Architecture plan</li> </ul>"},{"location":"components/toolfoundation/","title":"toolfoundation","text":"<p>Foundational layer providing canonical schema definitions and protocol-agnostic format conversion. This repository contains the core data types that all other ApertureStack components depend on.</p>"},{"location":"components/toolfoundation/#packages","title":"Packages","text":"Package Purpose <code>model</code> Canonical MCP tool schema definitions, validation, backend bindings <code>adapter</code> Protocol-agnostic tool format conversion (MCP, OpenAI, Anthropic) <code>version</code> Semantic version parsing, constraints, compatibility matrices"},{"location":"components/toolfoundation/#motivation","title":"Motivation","text":"<ul> <li>Standardize tool definitions across the stack</li> <li>Align directly with MCP via the official Go SDK</li> <li>Enable multi-provider support without changing the MCP surface</li> <li>Keep schemas portable and validation deterministic</li> </ul>"},{"location":"components/toolfoundation/#model-package","title":"model Package","text":"<p>The <code>model</code> package provides the canonical schema definitions for all tools.</p>"},{"location":"components/toolfoundation/#core-types","title":"Core Types","text":"<ul> <li><code>Tool</code> (embeds MCP <code>mcp.Tool</code>, adds <code>Namespace</code>, <code>Version</code>, <code>Tags</code>)</li> <li><code>ToolBackend</code> (execution binding: mcp, provider, local)</li> <li><code>SchemaValidator</code> (input/output validation)</li> </ul>"},{"location":"components/toolfoundation/#example","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolfoundation/model\"\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\ntool := model.Tool{\n  Namespace: \"github\",\n  Tool: mcp.Tool{\n    Name:        \"get_repo\",\n    Description: \"Fetch repository metadata\",\n    InputSchema: map[string]any{\n      \"type\": \"object\",\n      \"properties\": map[string]any{\n        \"owner\": {\"type\": \"string\"},\n        \"repo\":  {\"type\": \"string\"},\n      },\n      \"required\": []string{\"owner\", \"repo\"},\n    },\n  },\n  Tags: model.NormalizeTags([]string{\"GitHub\", \"repos\"}),\n}\n\n_ = tool.Validate()\n</code></pre>"},{"location":"components/toolfoundation/#schema-contracts","title":"Schema contracts","text":"<p>Canonical schema rules and JSON Schema requirements are documented here:</p> <ul> <li>tool schemas</li> </ul>"},{"location":"components/toolfoundation/#adapter-package","title":"adapter Package","text":"<p>The <code>adapter</code> package enables bidirectional transformation between MCP, OpenAI, and Anthropic tool definitions through a canonical intermediate representation.</p>"},{"location":"components/toolfoundation/#core-types_1","title":"Core Types","text":"Type Purpose <code>CanonicalTool</code> Protocol-agnostic intermediate representation <code>JSONSchema</code> Superset of all supported schema features <code>Adapter</code> Interface for format-specific converters <code>AdapterRegistry</code> Thread-safe adapter management and conversion <code>FeatureLossWarning</code> Indicates unsupported features in target format"},{"location":"components/toolfoundation/#example_1","title":"Example","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolfoundation/adapter\"\n)\n\n// Set up registry with all adapters\nregistry := adapter.NewRegistry()\nregistry.Register(adapter.NewMCPAdapter())\nregistry.Register(adapter.NewOpenAIAdapter())\nregistry.Register(adapter.NewAnthropicAdapter())\n\n// Convert MCP tool to OpenAI format\nresult, err := registry.Convert(mcpTool, \"mcp\", \"openai\")\nif err != nil {\n  log.Fatal(err)\n}\n\n// Check for feature loss warnings\nfor _, w := range result.Warnings {\n  log.Printf(\"Warning: %s\", w)\n}\n</code></pre>"},{"location":"components/toolfoundation/#feature-support-matrix","title":"Feature Support Matrix","text":"Feature MCP OpenAI Anthropic <code>$ref/$defs</code> Yes No No <code>anyOf/oneOf/allOf</code> Yes No Yes <code>pattern</code> Yes Yes* Yes <code>enum/const</code> Yes Yes Yes"},{"location":"components/toolfoundation/#diagram","title":"Diagram","text":""},{"location":"components/toolfoundation/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>MCP alignment: Tool embeds official MCP SDK types</li> <li>Pure transforms: Adapter conversions have no I/O or side effects</li> <li>Loss visibility: Feature loss is tracked as warnings, not errors</li> <li>Minimal deps: Foundation has minimal external dependencies</li> <li>Explicit versioning: Compatibility rules are defined via <code>version.Matrix</code></li> </ol>"},{"location":"components/toolfoundation/#version-package","title":"version Package","text":"<p>The <code>version</code> package provides SemVer parsing, constraints, and compatibility negotiation across stack components.</p> <pre><code>import \"github.com/jonwraymond/toolfoundation/version\"\n\nbase := version.MustParse(\"v1.0.0\")\ncurrent := version.MustParse(\"v1.2.3\")\n\nif current.Compatible(base) {\n  fmt.Println(\"compatible\")\n}\n</code></pre>"},{"location":"components/toolfoundation/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Tool schemas</li> <li>Design notes</li> <li>User journey</li> </ul>"},{"location":"components/toolops/","title":"toolops","text":"<p>Operations layer providing observability, caching, authentication, health checks, and resilience patterns. This repository contains cross-cutting concerns for production deployments.</p>"},{"location":"components/toolops/#packages","title":"Packages","text":"Package Purpose <code>observe</code> OpenTelemetry-based tracing, metrics, and logging <code>cache</code> Deterministic caching with pluggable backends <code>auth</code> Authentication and authorization middleware <code>health</code> Health check endpoints and probes <code>resilience</code> Circuit breakers, retries, and rate limiting"},{"location":"components/toolops/#motivation","title":"Motivation","text":"<ul> <li>Provide production-ready observability out of the box</li> <li>Enable caching to reduce execution latency and costs</li> <li>Support authentication across different providers</li> <li>Expose health checks for orchestration platforms</li> <li>Handle transient failures gracefully</li> </ul>"},{"location":"components/toolops/#observe-package","title":"observe Package","text":"<p>The <code>observe</code> package provides OpenTelemetry-based observability middleware.</p>"},{"location":"components/toolops/#features","title":"Features","text":"<ul> <li>Distributed tracing with span attributes</li> <li>Prometheus-compatible metrics</li> <li>Structured logging with tool context</li> <li>OTLP export support</li> </ul>"},{"location":"components/toolops/#example","title":"Example","text":"<pre><code>import (\n  \"context\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolops/observe\"\n)\n\nobs, err := observe.NewObserver(ctx, observe.Config{\n  ServiceName: \"metatools-mcp\",\n  Tracing:     observe.TracingConfig{Enabled: true, Exporter: \"otlp\"},\n  Metrics:     observe.MetricsConfig{Enabled: true, Exporter: \"prometheus\"},\n  Logging:     observe.LoggingConfig{Enabled: true, Level: \"info\"},\n})\nif err != nil {\n  log.Fatal(err)\n}\ndefer obs.Shutdown(ctx)\n\nmw, _ := observe.MiddlewareFromObserver(obs)\nwrapped := mw.Wrap(func(ctx context.Context, tool observe.ToolMeta, input any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n\n_, _ = wrapped(ctx, observe.ToolMeta{Name: toolID}, args)\n</code></pre>"},{"location":"components/toolops/#metrics-emitted","title":"Metrics Emitted","text":"Metric Type Description <code>tool.exec.total</code> Counter Total tool executions <code>tool.exec.duration</code> Histogram Execution duration (ms) <code>tool.exec.errors</code> Counter Failed executions"},{"location":"components/toolops/#cache-package","title":"cache Package","text":"<p>The <code>cache</code> package provides deterministic caching with pluggable backends.</p>"},{"location":"components/toolops/#features_1","title":"Features","text":"<ul> <li>Content-addressable caching (hash of tool + args)</li> <li>TTL and size-based eviction</li> <li>Pluggable backends (memory, Redis, file)</li> <li>Cache invalidation patterns</li> </ul>"},{"location":"components/toolops/#example_1","title":"Example","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/cache\"\n)\n\npolicy := cache.DefaultPolicy()\nc := cache.NewMemoryCache(policy)\nkeyer := cache.NewDefaultKeyer()\nmw := cache.NewCacheMiddleware(c, keyer, policy, nil)\n\nresult, err := mw.Execute(ctx, toolID, args, []string{\"cacheable\"}, func(ctx context.Context, toolID string, input any) ([]byte, error) {\n  return []byte(\"{\\\"ok\\\":true}\"), nil\n})\n</code></pre>"},{"location":"components/toolops/#auth-package","title":"auth Package","text":"<p>The <code>auth</code> package provides authentication and authorization middleware.</p>"},{"location":"components/toolops/#features_2","title":"Features","text":"<ul> <li>Multiple auth providers (API keys, JWT, OAuth)</li> <li>Per-namespace authorization rules</li> <li>Rate limiting per identity</li> <li>Audit logging</li> </ul>"},{"location":"components/toolops/#example_2","title":"Example","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/auth\"\n)\n\nauthenticator := auth.NewJWTAuthenticator(auth.JWTConfig{Issuer: \"issuer\"})\nauthorizer := auth.NewSimpleRBACAuthorizer(auth.RBACConfig{\n  DefaultRole: \"reader\",\n  Roles: map[string]auth.RoleConfig{\n    \"reader\": {AllowedTools: []string{\"github:*\"}, AllowedActions: []string{\"list\"}},\n  },\n})\n\nreq := &amp;auth.AuthRequest{Headers: map[string][]string{\"Authorization\": {\"Bearer token\"}}}\nresult, _ := authenticator.Authenticate(ctx, req)\nif result != nil &amp;&amp; result.Identity != nil {\n  _ = authorizer.Authorize(ctx, &amp;auth.AuthzRequest{\n    Subject:  result.Identity,\n    Resource: \"tool:github:list_issues\",\n    Action:   \"list\",\n  })\n}\n</code></pre>"},{"location":"components/toolops/#health-package","title":"health Package","text":"<p>The <code>health</code> package provides health check endpoints and probes.</p>"},{"location":"components/toolops/#features_3","title":"Features","text":"<ul> <li>Kubernetes-compatible probes (liveness, readiness)</li> <li>Dependency health checks</li> <li>Graceful degradation reporting</li> </ul>"},{"location":"components/toolops/#example_3","title":"Example","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/health\"\n)\n\nagg := health.NewAggregator()\nagg.Register(\"memory\", health.NewMemoryChecker(health.MemoryCheckerConfig{\n  WarningThreshold:  0.80,\n  CriticalThreshold: 0.95,\n}))\n\nresults := agg.CheckAll(ctx)\noverall := agg.OverallStatus(results)\n_ = overall\n</code></pre>"},{"location":"components/toolops/#resilience-package","title":"resilience Package","text":"<p>The <code>resilience</code> package provides circuit breakers, retries, and rate limiting.</p>"},{"location":"components/toolops/#features_4","title":"Features","text":"<ul> <li>Circuit breaker with configurable thresholds</li> <li>Exponential backoff retries</li> <li>Token bucket rate limiting</li> <li>Bulkhead isolation</li> </ul>"},{"location":"components/toolops/#example_4","title":"Example","text":"<pre><code>import (\n  \"context\"\n  \"time\"\n\n  \"github.com/jonwraymond/toolops/resilience\"\n)\n\nexecutor := resilience.NewExecutor(\n  resilience.WithCircuitBreaker(resilience.NewCircuitBreaker(resilience.CircuitBreakerConfig{\n    MaxFailures:  5,\n    ResetTimeout: 30 * time.Second,\n  })),\n  resilience.WithRetry(resilience.NewRetry(resilience.RetryConfig{\n    MaxAttempts: 3,\n  })),\n  resilience.WithTimeout(5*time.Second),\n)\n\n_ = executor.Execute(ctx, func(ctx context.Context) error {\n  return nil\n})\n</code></pre>"},{"location":"components/toolops/#diagram","title":"Diagram","text":""},{"location":"components/toolops/#middleware-chain","title":"Middleware Chain","text":"<pre><code>flowchart LR\n    Request --&gt; Auth[\"auth\"]\n    Auth --&gt; RateLimit[\"resilience\"]\n    RateLimit --&gt; Cache[\"cache\"]\n    Cache --&gt; Observe[\"observe\"]\n    Observe --&gt; Runner[\"toolexec/run\"]\n    Runner --&gt; Response</code></pre>"},{"location":"components/toolops/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Middleware pattern: Observe/cache wrap execution functions</li> <li>Composable: Patterns stack in a deterministic order</li> <li>Explicit wiring: No implicit instrumentation or caching</li> <li>Standards-based: OpenTelemetry, Prometheus, K8s probes</li> </ol>"},{"location":"components/toolops/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Design notes</li> <li>User journey</li> </ul>"},{"location":"components/toolprotocol/","title":"toolprotocol","text":"<p>Protocol layer providing transport, wire format, and protocol primitives for MCP, A2A, and ACP integrations.</p>"},{"location":"components/toolprotocol/#packages","title":"Packages","text":"Package Purpose <code>content</code> Unified content parts (text, image, audio, file, resource) <code>discover</code> Service discovery + capability negotiation <code>transport</code> Transport interfaces (stdio, SSE, streamable HTTP) <code>wire</code> Protocol wire encoding (MCP, A2A, ACP) <code>stream</code> Streaming events for progress/partial/complete <code>session</code> Client session store + context helpers <code>task</code> Long-running task lifecycle + subscriptions <code>resource</code> MCP resources registry + subscriptions <code>prompt</code> Prompt templates + registry <code>elicit</code> User input elicitation (text/confirm/choice/form)"},{"location":"components/toolprotocol/#contracts-highlights","title":"Contracts (Highlights)","text":"<ul> <li>Transport: concurrent-safe; <code>Serve</code> honors context; <code>Close</code> is idempotent.</li> <li>Wire: deterministic encode/decode; capabilities reflect real support.</li> <li>Content: immutable content parts; MIME type always matches payload.</li> <li>Stream: event order preserved; <code>Done</code> closes on <code>Close</code>.</li> </ul>"},{"location":"components/toolprotocol/#example-wire-transport","title":"Example: Wire + Transport","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/transport\"\n  \"github.com/jonwraymond/toolprotocol/wire\"\n)\n\ntype server struct{}\n\nfunc (s *server) ServeTransport(ctx context.Context, t transport.Transport) error {\n  return nil\n}\n\nctx := context.Background()\ncodec := wire.NewMCP()\npayload, _ := codec.EncodeRequest(ctx, &amp;wire.Request{\n  ID:     \"1\",\n  Method: \"tools/list\",\n})\n\ntp, _ := transport.New(\"stdio\", nil)\n_ = payload\n_ = tp.Serve(ctx, &amp;server{})\n</code></pre>"},{"location":"components/toolprotocol/#diagram","title":"Diagram","text":""},{"location":"components/toolprotocol/#protocol-flow","title":"Protocol Flow","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Transport\n    participant Wire\n    participant Handler\n\n    Client-&gt;&gt;Transport: Connect\n    Transport-&gt;&gt;Wire: Decode request\n    Wire-&gt;&gt;Handler: Route to handler\n\n    Handler--&gt;&gt;Wire: Response\n    Wire--&gt;&gt;Transport: Encode response\n    Transport--&gt;&gt;Client: Send</code></pre>"},{"location":"components/toolprotocol/#links","title":"Links","text":"<ul> <li>Repository</li> <li>Docs index</li> <li>Architecture</li> <li>Schemas and contracts</li> <li>Examples</li> <li>Design notes</li> <li>User journey</li> </ul>"},{"location":"operations/ci-and-versioning/","title":"CI and Versioning","text":""},{"location":"operations/ci-and-versioning/#ci-checks","title":"CI checks","text":"<p>Each repo runs CI for:</p> <ul> <li>go vet</li> <li>go test</li> <li>lint + security (golangci-lint + gosec)</li> </ul>"},{"location":"operations/ci-and-versioning/#go-module-privacy-fast-tag-uptake","title":"Go module privacy (fast tag uptake)","text":"<p>CI sets:</p> <ul> <li><code>GOPRIVATE=github.com/jonwraymond/*</code></li> <li><code>GONOSUMDB=github.com/jonwraymond/*</code></li> </ul> <p>This bypasses the public proxy/sumdb for the org\u2019s modules so newly\u2011pushed tags are immediately usable in CI and local workflows.</p>"},{"location":"operations/ci-and-versioning/#version-alignment","title":"Version alignment","text":"<ul> <li><code>ai-tools-stack/go.mod</code> is the source of truth.</li> <li><code>VERSIONS.md</code> is generated in each repo and updated via:</li> </ul> <pre><code>scripts/update-version-matrix.sh --apply\n</code></pre>"},{"location":"operations/ci-and-versioning/#new-modules-example-toolprotocol","title":"New modules (example: toolprotocol)","text":"<p>When a new module is added to the stack (for example <code>toolprotocol</code>), the propagation steps are:</p> <p>1) Tag the new module (<code>vX.Y.Z</code>). 2) Add it to <code>ai-tools-stack/go.mod</code> at the tagged version. 3) Run <code>scripts/update-version-matrix.sh --apply</code> to sync <code>VERSIONS.md</code> across repos. 4) Update <code>mkdocs.yml</code> to include the new module in Components and Library Docs.</p>"},{"location":"operations/ci-and-versioning/#dependency-bumping","title":"Dependency bumping","text":"<p>Use the DAG-aware bump tool:</p> <pre><code>scripts/bump-dep.sh --dep toolexec --latest --apply\n</code></pre> <p>This updates all downstream repos and ai-tools-stack in order.</p>"},{"location":"operations/ci-and-versioning/#docs-automation","title":"Docs automation","text":"<p>The unified docs site is built from this repo using MkDocs + the multirepo plugin. GitHub Actions runs on push to main and nightly (scheduled) to pull fresh docs from the tool repos.</p> <p>Versioned docs are published with <code>mike</code>:</p> <ul> <li><code>latest</code> alias is deployed from <code>main</code></li> <li>tag builds deploy versioned docs (for example, <code>v0.1.8</code>) and set <code>stable</code></li> <li>the version selector appears in the site header once at least one tag build exists</li> </ul> <p>Local preview:</p> <pre><code>pip install -r requirements.txt\n./scripts/prepare-mkdocs-multirepo.sh\nmkdocs serve\n</code></pre> <p>Versioned preview:</p> <pre><code>pip install -r requirements.txt\n./scripts/prepare-mkdocs-multirepo.sh\nmike serve\n</code></pre>"},{"location":"operations/consolidation-validation-report/","title":"Consolidation Validation Report","text":"<p>Date: 2026-02-01 PRDs: PRD-190, PRD-191, PRD-192 Validator: Codex (local)</p>"},{"location":"operations/consolidation-validation-report/#executive-summary","title":"Executive Summary","text":"<p>The ApertureStack consolidation is complete. All 13 standalone repositories are archived with migration guidance. The stack is consolidated into 6 libraries + 2 application repos with updated documentation and diagrams.</p>"},{"location":"operations/consolidation-validation-report/#repository-status-local-validation","title":"Repository Status (Local Validation)","text":""},{"location":"operations/consolidation-validation-report/#consolidated-libraries","title":"Consolidated Libraries","text":"Repository Build Tests Status toolfoundation \u2713 \u2713 OK tooldiscovery \u2713 \u2713 OK toolexec \u2713 \u2713 OK toolcompose \u2713 \u2713 OK toolops \u2713 \u2713 OK toolprotocol \u2713 \u2713 OK <p>Notes: Tests run with <code>GOWORK=off</code> to avoid the global <code>go.work</code> at <code>/Users/jraymond/Documents/Projects/go.work</code>.</p>"},{"location":"operations/consolidation-validation-report/#application-layer","title":"Application Layer","text":"Repository Build Tests CLI Status metatools-mcp \u2713 \u2713 \u2713 (<code>./metatools version</code>) OK ai-tools-stack \u2713 \u2713 N/A OK"},{"location":"operations/consolidation-validation-report/#ci-status-latest-known","title":"CI Status (Latest Known)","text":"Repository CI Notes toolprotocol \u2713 success Last run 2026-02-01 metatools-mcp \u2713 success Last run 2026-02-01 ai-tools-stack \u2713 success Docs workflow green (2026-02-01)"},{"location":"operations/consolidation-validation-report/#archive-status","title":"Archive Status","text":"<p>All 13 standalone repositories are archived and verified:</p> Repository Migrated To Archived README Deprecated MIGRATION.md toolmodel toolfoundation/model \u2713 \u2713 \u2713 tooladapter toolfoundation/adapter \u2713 \u2713 \u2713 toolindex tooldiscovery/index \u2713 \u2713 \u2713 toolsearch tooldiscovery/search \u2713 \u2713 \u2713 toolsemantic tooldiscovery/semantic \u2713 \u2713 \u2713 tooldocs tooldiscovery/tooldoc \u2713 \u2713 \u2713 toolrun toolexec/run \u2713 \u2713 \u2713 toolruntime toolexec/runtime \u2713 \u2713 \u2713 toolcode toolexec/code \u2713 \u2713 \u2713 toolset toolcompose/set \u2713 \u2713 \u2713 toolskill toolcompose/skill \u2713 \u2713 \u2713 toolobserve toolops/observe \u2713 \u2713 \u2713 toolcache toolops/cache \u2713 \u2713 \u2713"},{"location":"operations/consolidation-validation-report/#submodule-status","title":"Submodule Status","text":"<p>Root repo uses consolidated submodules:</p> <pre><code>ai-tools-stack\nmetatools-mcp\ntoolcompose\ntooldiscovery\ntoolexec\ntoolfoundation\ntoolops\ntoolprotocol\n</code></pre>"},{"location":"operations/consolidation-validation-report/#documentation-status","title":"Documentation Status","text":"<ul> <li>D2 diagrams rendered to SVG for ai-tools-stack and metatools-mcp.</li> <li>MkDocs build validated in CI (Docs workflow).</li> <li>Documentation structure and navigation aligned to consolidated repos.</li> </ul>"},{"location":"operations/consolidation-validation-report/#conclusion","title":"Conclusion","text":"<p>Gate G7: PASSED</p>"},{"location":"operations/migration-guide/","title":"Migration Guide: Consolidated Repositories (v0.3.0)","text":"<p>This guide helps you migrate from the previous 14 standalone repositories to the new 6 consolidated repositories introduced in v0.3.0.</p>"},{"location":"operations/migration-guide/#overview-of-changes","title":"Overview of Changes","text":"<p>The ApertureStack tool framework has been reorganized to group related packages by architectural concern:</p> Old Repository New Location Import Path Change <code>toolmodel</code> <code>toolfoundation/model</code> <code>github.com/jonwraymond/toolfoundation/model</code> <code>tooladapter</code> <code>toolfoundation/adapter</code> <code>github.com/jonwraymond/toolfoundation/adapter</code> <code>toolindex</code> <code>tooldiscovery/index</code> <code>github.com/jonwraymond/tooldiscovery/index</code> <code>tooldocs</code> <code>tooldiscovery/tooldoc</code> <code>github.com/jonwraymond/tooldiscovery/tooldoc</code> <code>toolsearch</code> <code>tooldiscovery/search</code> <code>github.com/jonwraymond/tooldiscovery/search</code> <code>toolsemantic</code> <code>tooldiscovery/semantic</code> <code>github.com/jonwraymond/tooldiscovery/semantic</code> <code>toolrun</code> <code>toolexec/run</code> <code>github.com/jonwraymond/toolexec/run</code> <code>toolcode</code> <code>toolexec/code</code> <code>github.com/jonwraymond/toolexec/code</code> <code>toolruntime</code> <code>toolexec/runtime</code> <code>github.com/jonwraymond/toolexec/runtime</code> <code>toolset</code> <code>toolcompose/set</code> <code>github.com/jonwraymond/toolcompose/set</code> <code>toolskill</code> <code>toolcompose/skill</code> <code>github.com/jonwraymond/toolcompose/skill</code> <code>toolobserve</code> <code>toolops/observe</code> <code>github.com/jonwraymond/toolops/observe</code> <code>toolcache</code> <code>toolops/cache</code> <code>github.com/jonwraymond/toolops/cache</code>"},{"location":"operations/migration-guide/#migration-steps","title":"Migration Steps","text":""},{"location":"operations/migration-guide/#1-update-gomod-dependencies","title":"1. Update go.mod Dependencies","text":"<p>Replace old standalone dependencies with consolidated ones:</p> <pre><code># Remove old dependencies\ngo mod edit -droprequire github.com/jonwraymond/toolmodel\ngo mod edit -droprequire github.com/jonwraymond/tooladapter\ngo mod edit -droprequire github.com/jonwraymond/toolindex\n# ... repeat for all old repos\n\n# Add consolidated dependencies\ngo get github.com/jonwraymond/toolfoundation@latest\ngo get github.com/jonwraymond/tooldiscovery@latest\ngo get github.com/jonwraymond/toolexec@latest\ngo get github.com/jonwraymond/toolcompose@latest\ngo get github.com/jonwraymond/toolops@latest\ngo get github.com/jonwraymond/toolprotocol@latest\n</code></pre>"},{"location":"operations/migration-guide/#2-update-import-statements","title":"2. Update Import Statements","text":"<p>Use your editor's find-and-replace or a tool like <code>gofmt</code> to update imports:</p> <pre><code>// Before\nimport (\n    \"github.com/jonwraymond/toolmodel\"\n    \"github.com/jonwraymond/toolindex\"\n    \"github.com/jonwraymond/toolrun\"\n)\n\n// After\nimport (\n    \"github.com/jonwraymond/toolfoundation/model\"\n    \"github.com/jonwraymond/tooldiscovery/index\"\n    \"github.com/jonwraymond/toolexec/run\"\n)\n</code></pre>"},{"location":"operations/migration-guide/#3-update-package-aliases-if-needed","title":"3. Update Package Aliases (if needed)","text":"<p>If you used short aliases, update them:</p> <pre><code>// Before\nimport toolmodel \"github.com/jonwraymond/toolmodel\"\n\n// After (same alias, new path)\nimport toolmodel \"github.com/jonwraymond/toolfoundation/model\"\n</code></pre>"},{"location":"operations/migration-guide/#4-run-tests","title":"4. Run Tests","text":"<p>After updating imports, run your test suite to verify everything works:</p> <pre><code>go mod tidy\ngo test ./...\n</code></pre>"},{"location":"operations/migration-guide/#api-compatibility","title":"API Compatibility","text":"<p>All public APIs remain unchanged. The consolidation only affects import paths, not function signatures or types. Your existing code should work after updating the import statements.</p>"},{"location":"operations/migration-guide/#benefits-of-consolidation","title":"Benefits of Consolidation","text":"<ol> <li>Simpler dependency management - 6 repos instead of 14</li> <li>Clearer architecture - Packages grouped by concern</li> <li>Easier versioning - Related packages released together</li> <li>Better discoverability - Find related functionality in one place</li> </ol>"},{"location":"operations/migration-guide/#questions","title":"Questions?","text":"<p>If you encounter issues during migration, please open an issue on the ai-tools-stack repository.</p>"},{"location":"operations/stack-changelog/","title":"Stack Changelog","text":"<p>Aggregated highlights from each repo\u2019s latest release. For full history, use each repo\u2019s CHANGELOG.</p>"},{"location":"operations/stack-changelog/#version-matrix-current-tags","title":"Version matrix (current tags)","text":""},{"location":"operations/stack-changelog/#version-compatibility-current-tags","title":"Version compatibility (current tags)","text":"<ul> <li><code>toolfoundation</code>: <code>v0.3.0</code></li> <li><code>tooldiscovery</code>: <code>v0.3.0</code></li> <li><code>toolexec</code>: <code>v0.2.1</code></li> <li><code>toolcompose</code>: <code>v0.1.3</code></li> <li><code>toolops</code>: <code>v0.1.5</code></li> <li><code>toolprotocol</code>: <code>v0.1.7</code></li> <li><code>metatools-mcp</code>: <code>v0.5.3</code></li> <li><code>metatools-a2a</code>: <code>v0.1.1</code></li> </ul> <p>Generated from <code>ai-tools-stack/go.mod</code>.</p>"},{"location":"operations/stack-changelog/#repo-changelogs","title":"Repo changelogs","text":"<ul> <li>ai-tools-stack</li> <li>toolfoundation</li> <li>tooldiscovery</li> <li>toolexec</li> <li>toolexec-integrations</li> <li>toolcompose</li> <li>toolops</li> <li>toolprotocol</li> <li>metatools-mcp</li> <li>metatools-a2a</li> </ul>"},{"location":"operations/stack-changelog/#notes","title":"Notes","text":"<ul> <li>The stack was consolidated from 13 standalone repos into 6 library repos.</li> <li>Legacy repo changelogs remain available in their archived repositories.</li> </ul> <p>Generated by scripts/generate-combined-changelog.sh</p>"},{"location":"library-docs-from-repos/toolfoundation/","title":"toolfoundation","text":"<p>Foundation layer providing canonical schema definitions and protocol-agnostic format conversion for the ApertureStack tool framework.</p>"},{"location":"library-docs-from-repos/toolfoundation/#packages","title":"Packages","text":"Package Purpose <code>model</code> Canonical MCP tool schema definitions, validation, backend bindings <code>adapter</code> Protocol-agnostic tool format conversion (MCP, OpenAI, Anthropic, A2A, Gemini) <code>version</code> Semantic version parsing, constraints, compatibility matrices"},{"location":"library-docs-from-repos/toolfoundation/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolfoundation@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/#quick-start","title":"Quick Start","text":""},{"location":"library-docs-from-repos/toolfoundation/#defining-a-tool-model-package","title":"Defining a Tool (model package)","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolfoundation/model\"\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\ntool := model.Tool{\n  Namespace: \"github\",\n  Tool: mcp.Tool{\n    Name:        \"get_repo\",\n    Description: \"Fetch repository metadata\",\n    InputSchema: map[string]any{\n      \"type\": \"object\",\n      \"properties\": map[string]any{\n        \"owner\": map[string]any{\"type\": \"string\"},\n        \"repo\":  map[string]any{\"type\": \"string\"},\n      },\n      \"required\": []string{\"owner\", \"repo\"},\n    },\n  },\n  Tags: model.NormalizeTags([]string{\"GitHub\", \"repos\"}),\n}\n\nif err := tool.Validate(); err != nil {\n  log.Fatal(err)\n}\n\nfmt.Println(tool.ToolID()) // \"github:get_repo\" (or \"github:get_repo:1.0.0\" when version is set)\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/#converting-between-formats-adapter-package","title":"Converting Between Formats (adapter package)","text":"<pre><code>import \"github.com/jonwraymond/toolfoundation/adapter\"\n\n// Use the default registry with all built-in adapters\nregistry := adapter.DefaultRegistry()\n\nresult, err := registry.Convert(mcpTool, \"mcp\", \"openai\")\nif err != nil {\n  log.Fatal(err)\n}\n\n// Check for feature loss warnings\nfor _, w := range result.Warnings {\n  log.Printf(\"Feature loss: %s\", w)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/#versioning-utilities-version-package","title":"Versioning Utilities (version package)","text":"<pre><code>import \"github.com/jonwraymond/toolfoundation/version\"\n\nv1 := version.MustParse(\"v1.2.0\")\nv2 := version.MustParse(\"v1.3.1\")\n\nif v2.GreaterThan(v1) {\n  fmt.Println(\"upgrade available\")\n}\n\nmatrix := version.NewMatrix()\nmatrix.Add(version.Compatibility{\n  Component:  \"toolexec\",\n  MinVersion: version.MustParse(\"v1.0.0\"),\n})\n\nok, msg := matrix.Check(\"toolexec\", v1)\nif !ok {\n  log.Fatal(msg)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/#key-features","title":"Key Features","text":"<ul> <li>MCP-aligned: Tool type embeds official MCP SDK types</li> <li>Protocol-agnostic: Convert between MCP, OpenAI, and Anthropic formats</li> <li>Loss visibility: Feature loss during conversion is tracked as warnings</li> <li>Minimal dependencies: Foundation has minimal external dependencies</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/#schema-contracts","title":"Schema contracts","text":"<p>See the dedicated schema reference for field constraints, JSON Schema rules, and recommended patterns:</p> <ul> <li>tool schemas</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/#schema-validation-policy","title":"Schema Validation Policy","text":"<p>Schema validation follows JSON Schema 2020-12 by default with draft-07 support. External <code>$ref</code> resolution is disabled to prevent network access. See design notes for details and limitations.</p>"},{"location":"library-docs-from-repos/toolfoundation/#links","title":"Links","text":"<ul> <li>model design notes</li> <li>user journey</li> <li>tool schemas</li> <li>ai-tools-stack documentation</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/architecture/","title":"Architecture","text":"<p>This document describes the architecture of the toolfoundation package.</p>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#package-structure","title":"Package Structure","text":"<pre><code>toolfoundation/\n\u251c\u2500\u2500 model/      # Canonical tool definitions\n\u251c\u2500\u2500 adapter/    # Format conversion\n\u251c\u2500\u2500 version/    # Semantic versioning\n\u2514\u2500\u2500 examples/   # Usage examples\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#dependency-graph","title":"Dependency Graph","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     External                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  github.com/modelcontextprotocol/go-sdk/mcp     \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                          \u25b2                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   toolfoundation                        \u2502\n\u2502                          \u2502                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502                              \u2502\n\u2502  \u2502  version  \u2502 (standalone - no internal deps)          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502                              \u2502\n\u2502       \u25b2                  \u2502                              \u2502\n\u2502       \u2502                  \u2502                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502  \u2502           model             \u2502                        \u2502\n\u2502  \u2502  - Tool type (embeds mcp)   \u2502                        \u2502\n\u2502  \u2502  - Schema validation        \u2502                        \u2502\n\u2502  \u2502  - Backend bindings         \u2502                        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\n\u2502                \u25b2                                        \u2502\n\u2502                \u2502                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502  \u2502          adapter            \u2502                        \u2502\n\u2502  \u2502  - CanonicalTool            \u2502                        \u2502\n\u2502  \u2502  - CanonicalProvider        \u2502                        \u2502\n\u2502  \u2502  - MCPAdapter               \u2502                        \u2502\n\u2502  \u2502  - OpenAIAdapter            \u2502                        \u2502\n\u2502  \u2502  - AnthropicAdapter         \u2502                        \u2502\n\u2502  \u2502  - A2AAdapter               \u2502                        \u2502\n\u2502  \u2502  - GeminiAdapter            \u2502                        \u2502\n\u2502  \u2502  - AdapterRegistry          \u2502                        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\n\u2502                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#package-responsibilities","title":"Package Responsibilities","text":""},{"location":"library-docs-from-repos/toolfoundation/architecture/#version","title":"version","text":"<p>Standalone package with no internal dependencies.</p> <ul> <li>Semantic version parsing (<code>Parse</code>, <code>MustParse</code>)</li> <li>Version comparison (<code>Compare</code>, <code>LessThan</code>, <code>GreaterThan</code>, <code>Equal</code>)</li> <li>Version constraints (<code>ParseConstraint</code>, <code>Check</code>)</li> <li>Compatibility matrices (<code>Matrix</code>, <code>Negotiate</code>)</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#model","title":"model","text":"<p>Depends on: version, mcp-go SDK</p> <ul> <li>Canonical <code>Tool</code> type (embeds <code>mcp.Tool</code>)</li> <li>Tool extensions: <code>Namespace</code>, <code>Version</code>, <code>Tags</code>, <code>Backend</code></li> <li>Schema validation (<code>SchemaValidator</code>, <code>DefaultValidator</code>)</li> <li>Tag normalization (<code>NormalizeTags</code>)</li> <li>Backend factory functions (<code>NewMCPBackend</code>, <code>NewLocalBackend</code>, <code>NewProviderBackend</code>)</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#adapter","title":"adapter","text":"<p>Depends on: model</p> <ul> <li><code>CanonicalTool</code> - intermediate representation</li> <li><code>CanonicalProvider</code> - provider/agent metadata representation</li> <li><code>Adapter</code> interface for format converters</li> <li>Built-in adapters: MCP, OpenAI, Anthropic, A2A, Gemini</li> <li><code>AdapterRegistry</code> for managing converters</li> <li>Feature loss detection and warnings</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#data-flow","title":"Data Flow","text":""},{"location":"library-docs-from-repos/toolfoundation/architecture/#tool-conversion","title":"Tool Conversion","text":"<pre><code>Source Format    Canonical        Target Format\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500        \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   MCP   \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502Canonical\u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 OpenAI  \u2502\n\u2502  Tool   \u2502      \u2502  Tool   \u2502      \u2502  Tool   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u25b2                                \u2502\n      \u2502          ToCanonical()         \u2502\n      \u2502          FromCanonical()       \u2502\n      \u2502                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Anthropic\u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 OpenAI  \u2502\n\u2502  Tool   \u2502                      \u2502  Tool   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>All conversions pass through <code>CanonicalTool</code>, enabling N adapters to support N\u00b2 conversions with only 2N implementations.</p>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#feature-loss-detection","title":"Feature Loss Detection","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Source Schema  \u2502\n\u2502  (full features)\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Target Adapter  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502FeatureLossWarning\u2502\n\u2502SupportsFeature()\u2502     \u2502 - Feature       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502 - Path          \u2502\n                        \u2502 - Message       \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#design-principles","title":"Design Principles","text":"<ol> <li>Pure Transformations: Conversions have no I/O or side effects</li> <li>Minimal Dependencies: Only essential external packages</li> <li>MCP Alignment: Tool type embeds official MCP SDK types</li> <li>Explicit Loss: Feature degradation is warnings, not errors</li> <li>Thread Safety: Registry is safe for concurrent reads after setup</li> </ol>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#extension-points","title":"Extension Points","text":""},{"location":"library-docs-from-repos/toolfoundation/architecture/#custom-adapters","title":"Custom Adapters","text":"<p>Implement the <code>Adapter</code> interface:</p> <pre><code>type Adapter interface {\n    Name() string\n    ToCanonical(raw any) (*CanonicalTool, error)\n    FromCanonical(ct *CanonicalTool) (any, error)\n    SupportsFeature(feature SchemaFeature) bool\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/architecture/#custom-validators","title":"Custom Validators","text":"<p>Implement the <code>SchemaValidator</code> interface:</p> <pre><code>type SchemaValidator interface {\n    Validate(schema any, data any) error\n    ValidateInput(tool *Tool, input any) error\n    ValidateOutput(tool *Tool, output any) error\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/","title":"toolfoundation Design Notes","text":""},{"location":"library-docs-from-repos/toolfoundation/design-notes/#overview","title":"Overview","text":"<p>toolfoundation provides the canonical data types that all other ApertureStack components depend on. It contains two packages: <code>model</code> for tool definitions and <code>adapter</code> for format conversion.</p>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#model-package","title":"model Package","text":""},{"location":"library-docs-from-repos/toolfoundation/design-notes/#design-decisions","title":"Design Decisions","text":"<ol> <li> <p>MCP SDK Embedding: The <code>Tool</code> type embeds <code>mcp.Tool</code> from the official    MCP Go SDK rather than reimplementing the fields. This ensures 1:1 spec    compatibility while allowing extension.</p> </li> <li> <p>Namespace + Name (+ Version) = ID: Tool IDs are <code>namespace:name:version</code> when version is set (otherwise <code>namespace:name</code>), providing    stable identifiers across registry operations.</p> </li> <li> <p>Backend Abstraction: <code>ToolBackend</code> supports three kinds:</p> </li> <li><code>local</code>: In-process handler function</li> <li><code>provider</code>: External tool provider</li> <li> <p><code>mcp</code>: Remote MCP server</p> </li> <li> <p>Tag Normalization: Tags are normalized (lowercase, trimmed, deduped)    to ensure consistent search behavior.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#error-handling","title":"Error Handling","text":"<ul> <li><code>Validate()</code> returns descriptive errors for invalid tools</li> <li>Schema validation uses JSON Schema draft 2020-12</li> <li>Empty names, invalid characters, and missing schemas are rejected</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#schema-validation-policy","title":"Schema Validation Policy","text":"<p>The default validator supports the following dialects:</p> <ul> <li>JSON Schema 2020-12 (default)</li> <li>JSON Schema draft-07</li> </ul> <p>External <code>$ref</code> resolution is disabled to prevent network access during validation. Validation behavior is deterministic and does not perform I/O.</p> <p>Limitations (from the underlying jsonschema-go implementation):</p> <ul> <li><code>format</code> is treated as annotation (not validated)</li> <li><code>contentEncoding</code> and <code>contentMediaType</code> are not validated</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#adapter-package","title":"adapter Package","text":""},{"location":"library-docs-from-repos/toolfoundation/design-notes/#design-decisions_1","title":"Design Decisions","text":"<ol> <li> <p>Canonical Intermediate: All conversions go through <code>CanonicalTool</code>,    a protocol-agnostic intermediate representation.</p> </li> <li> <p>Pure Transforms: Conversions have no I/O or side effects. Same input    always produces same output.</p> </li> <li> <p>Feature Loss Warnings: When the target format doesn't support a feature    (e.g., <code>$ref</code> in OpenAI), warnings are returned instead of errors.</p> </li> <li> <p>Minimal Dependencies: The MCP adapter depends on the MCP SDK. OpenAI    and Anthropic adapters use self-contained types.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#supported-formats","title":"Supported Formats","text":"Format Adapter Notes MCP MCPAdapter Full spec support OpenAI OpenAIAdapter Strict mode support Anthropic AnthropicAdapter Full spec support"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#feature-compatibility","title":"Feature Compatibility","text":"Feature MCP OpenAI Anthropic <code>$ref/$defs</code> Yes No No <code>anyOf/oneOf</code> Yes No Yes <code>pattern</code> Yes Yes* Yes <code>enum/const</code> Yes Yes Yes <p>*OpenAI supports pattern only in strict mode.</p>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#feature-loss-warnings","title":"Feature Loss Warnings","text":"<p>Adapters emit <code>FeatureLossWarning</code> entries when the target format does not support a schema feature used by the source. Conversions still succeed, but consumers should review warnings before exposing the converted tool to users.</p>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#dependencies","title":"Dependencies","text":"<ul> <li><code>github.com/modelcontextprotocol/go-sdk/mcp</code> - MCP type definitions</li> <li><code>github.com/santhosh-tekuri/jsonschema</code> - Schema validation (optional)</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/design-notes/#links","title":"Links","text":"<ul> <li>index</li> <li>tool schemas</li> <li>user journey</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/schemas/","title":"Tool Schemas","text":"<p>toolfoundation defines the canonical tool schema (the <code>Tool</code> record) and the JSON Schemas used for tool input/output validation. This page documents the fields, constraints, and JSON Schema rules that all downstream components rely on.</p>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#tool-schema-fields-and-constraints","title":"Tool schema fields and constraints","text":"<p>The canonical tool record is <code>model.Tool</code>, which embeds the MCP SDK <code>mcp.Tool</code> fields and adds stack-specific extensions.</p>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#core-mcp-tool-fields","title":"Core MCP tool fields","text":"Field Required Constraints / Notes <code>name</code> Yes 1-128 chars, allowed: <code>[A-Za-z0-9_.-]</code> only. <code>description</code> No Human-readable description. <code>inputSchema</code> Yes JSON Schema object defining tool parameters. <code>outputSchema</code> No JSON Schema object for structured output (optional). <code>title</code> No Display name (preferred over <code>name</code>). <code>annotations</code> No Hints for clients (readOnly, idempotent, destructive, openWorld). <code>_meta</code> No Arbitrary metadata. <code>icons</code> No List of icon assets for UI."},{"location":"library-docs-from-repos/toolfoundation/schemas/#toolfoundation-extensions","title":"toolfoundation extensions","text":"Field Required Constraints / Notes <code>namespace</code> No Optional namespace for stable IDs. If present, tool ID is <code>namespace:name:version</code> when version is set, otherwise <code>namespace:name</code>. Namespace and name must both be non-empty when used. <code>version</code> No Optional semantic version string (accepts <code>v1.2.3</code> or <code>1.2.3</code>). <code>tags</code> No Normalized tags for discovery; see rules below."},{"location":"library-docs-from-repos/toolfoundation/schemas/#tool-id-rules","title":"Tool ID rules","text":"<ul> <li>Tool IDs are <code>namespace:name:version</code> when both namespace and version are set, <code>namespace:name</code> when only namespace is set, otherwise just <code>name</code>.</li> <li>Up to two <code>:</code> are permitted in an ID (the second separates version).</li> <li><code>namespace</code> and <code>name</code> must both be non-empty when a <code>:</code> is used.</li> <li><code>version</code> must be non-empty when present.</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#tag-normalization-rules","title":"Tag normalization rules","text":"<p>Tags are normalized for stable search behavior:</p> <ul> <li>Lowercased and trimmed.</li> <li>Whitespace collapsed to <code>-</code>.</li> <li>Allowed characters: <code>[a-z0-9-_.]</code> (others are removed).</li> <li>Max tag length: 64 chars.</li> <li>Max tag count: 20.</li> <li>Duplicates removed while preserving order.</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#inputschema-outputschema-requirements","title":"InputSchema / OutputSchema requirements","text":"<ul> <li>InputSchema is required. A tool without <code>inputSchema</code> is invalid.</li> <li>OutputSchema is optional. If omitted, output validation is skipped.</li> <li>Schemas must be valid JSON Schema objects. Accepted representations:</li> <li><code>map[string]any</code></li> <li><code>json.RawMessage</code></li> <li><code>[]byte</code></li> <li><code>*jsonschema.Schema</code></li> <li>Validation is performed by <code>model.SchemaValidator</code>:</li> <li><code>ValidateInput</code> must use <code>tool.InputSchema</code> and returns <code>ErrInvalidSchema</code>     if <code>tool</code> or <code>InputSchema</code> is nil.</li> <li><code>ValidateOutput</code> returns nil when <code>OutputSchema</code> is nil.</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#supported-dialects-and-limitations","title":"Supported dialects and limitations","text":"<ul> <li>Default dialect: JSON Schema 2020-12 (assumed when <code>$schema</code> is absent).</li> <li>Supported: 2020-12 and draft-07.</li> <li>External <code>$ref</code> resolution is disabled (no network access).</li> <li>Known limitations from the underlying validator:</li> <li><code>format</code> is treated as annotation (not enforced).</li> <li><code>contentEncoding</code> and <code>contentMediaType</code> are not validated.</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#recommended-no-parameters-schema","title":"Recommended \"no parameters\" schema","text":"<p>The MCP-recommended schema for tools that take no parameters:</p> <pre><code>{\n  \"type\": \"object\",\n  \"additionalProperties\": false\n}\n</code></pre> <p>The MCP-allowed (but less strict) variant:</p> <pre><code>{\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#example-schema-patterns","title":"Example schema patterns","text":""},{"location":"library-docs-from-repos/toolfoundation/schemas/#required-string-property","title":"Required string property","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"path\": {\"type\": \"string\", \"description\": \"File path\"}\n  },\n  \"required\": [\"path\"],\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#optional-enum-with-default","title":"Optional enum with default","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"encoding\": {\"type\": \"string\", \"enum\": [\"utf8\", \"ascii\"], \"default\": \"utf8\"}\n  },\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#array-of-objects","title":"Array of objects","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"items\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"id\": {\"type\": \"string\"},\n          \"value\": {\"type\": \"number\"}\n        },\n        \"required\": [\"id\"],\n        \"additionalProperties\": false\n      }\n    }\n  },\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#one-of-variants","title":"One-of variants","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"mode\": {\n      \"oneOf\": [\n        {\"type\": \"string\", \"enum\": [\"fast\", \"safe\"]},\n        {\"type\": \"number\", \"minimum\": 1, \"maximum\": 10}\n      ]\n    }\n  }\n}\n</code></pre> <p>Note: some adapters (e.g., OpenAI) do not support all schema features. See the adapter feature matrix in the toolfoundation component docs for details.</p>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#authoring-approaches-recommended","title":"Authoring approaches (recommended)","text":"<ol> <li>Go structs + schema generation (recommended default)</li> <li>Define input/output types in Go and generate JSON Schema.</li> <li>Example generator: <code>github.com/invopop/jsonschema</code>.</li> <li>Schema builder helpers</li> <li>Useful for advanced constructs not easily expressed in tags.</li> <li>Raw map/JSON schema</li> <li>Fully supported, but most error-prone.</li> <li>Schema validation libraries (implementation detail)</li> <li><code>github.com/santhosh-tekuri/jsonschema</code> is commonly used for      fast validation and supports 2020-12 and draft-07.</li> </ol>"},{"location":"library-docs-from-repos/toolfoundation/schemas/#links","title":"Links","text":"<ul> <li>Design notes</li> <li>User journey</li> </ul>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/","title":"toolfoundation User Journey","text":""},{"location":"library-docs-from-repos/toolfoundation/user-journey/#overview","title":"Overview","text":"<p>This guide walks through the typical usage patterns for toolfoundation, from defining your first tool to converting between LLM provider formats.</p>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#1-installation","title":"1. Installation","text":"<pre><code>go get github.com/jonwraymond/toolfoundation@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#2-define-your-first-tool","title":"2. Define Your First Tool","text":"<pre><code>import (\n  \"github.com/jonwraymond/toolfoundation/model\"\n  \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\n// Create a tool definition\ntool := model.Tool{\n  Namespace: \"calculator\",\n  Tool: mcp.Tool{\n    Name:        \"add\",\n    Description: \"Add two numbers together\",\n    InputSchema: map[string]any{\n      \"type\": \"object\",\n      \"properties\": map[string]any{\n        \"a\": map[string]any{\"type\": \"number\"},\n        \"b\": map[string]any{\"type\": \"number\"},\n      },\n      \"required\": []string{\"a\", \"b\"},\n    },\n  },\n  Tags: model.NormalizeTags([]string{\"math\", \"arithmetic\"}),\n}\n\n// Validate the tool\nif err := tool.Validate(); err != nil {\n  log.Fatalf(\"Invalid tool: %v\", err)\n}\n\n// Get the canonical ID\nfmt.Println(tool.ToolID()) // \"calculator:add\"\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#3-assign-a-backend","title":"3. Assign a Backend","text":"<pre><code>// Local handler backend\ntool.Backend = model.NewLocalBackend(\"add_handler\")\n\n// Or MCP server backend\ntool.Backend = model.NewMCPBackend(\"math-server\")\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#4-convert-to-openai-format","title":"4. Convert to OpenAI Format","text":"<pre><code>import \"github.com/jonwraymond/toolfoundation/adapter\"\n\n// Use the default registry with all built-in adapters\nregistry := adapter.DefaultRegistry()\n\n// Convert MCP tool to OpenAI format\nresult, err := registry.Convert(&amp;tool, \"mcp\", \"openai\")\nif err != nil {\n  log.Fatalf(\"Conversion failed: %v\", err)\n}\n\n// Check for feature loss\nfor _, warning := range result.Warnings {\n  log.Printf(\"Warning: %s\", warning)\n}\n\nopenaiTool := result.Tool.(*adapter.OpenAITool)\nfmt.Printf(\"OpenAI function: %s\\n\", openaiTool.Function.Name)\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#5-round-trip-conversion","title":"5. Round-Trip Conversion","text":"<pre><code>// Convert OpenAI \u2192 MCP\nresult2, err := registry.Convert(openaiTool, \"openai\", \"mcp\")\nif err != nil {\n  log.Fatal(err)\n}\n\nmcpTool := result2.Tool.(mcp.Tool)\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#common-patterns","title":"Common Patterns","text":""},{"location":"library-docs-from-repos/toolfoundation/user-journey/#batch-tool-registration","title":"Batch Tool Registration","text":"<pre><code>tools := []model.Tool{\n  {Namespace: \"math\", Tool: mcp.Tool{Name: \"add\", ...}},\n  {Namespace: \"math\", Tool: mcp.Tool{Name: \"subtract\", ...}},\n  {Namespace: \"math\", Tool: mcp.Tool{Name: \"multiply\", ...}},\n}\n\nfor _, t := range tools {\n  if err := t.Validate(); err != nil {\n    log.Printf(\"Skipping invalid tool %s: %v\", t.ToolID(), err)\n    continue\n  }\n  // Register with index...\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#schema-validation","title":"Schema Validation","text":"<pre><code>validator := model.NewDefaultValidator()\n\n// Validate input against tool schema\ninput := map[string]any{\"a\": 5, \"b\": 10}\nif err := validator.ValidateInput(&amp;tool, input); err != nil {\n  log.Fatalf(\"Invalid input: %v\", err)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#version-compatibility","title":"Version Compatibility","text":"<pre><code>import \"github.com/jonwraymond/toolfoundation/version\"\n\ncurrent := version.MustParse(\"v1.2.0\")\nrequired := version.MustParse(\"v1.0.0\")\n\nif !current.Compatible(required) {\n  log.Fatalf(\"version %s is not compatible with %s\", current, required)\n}\n\nmatrix := version.NewMatrix()\nmatrix.Add(version.Compatibility{\n  Component:  \"toolfoundation\",\n  MinVersion: required,\n})\n\nok, msg := matrix.Check(\"toolfoundation\", current)\nif !ok {\n  log.Fatal(msg)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolfoundation/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Register tools with tooldiscovery/index</li> <li>Execute tools with toolexec/run</li> <li>Expose via MCP with metatools-mcp</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/","title":"tooldiscovery","text":"<p>Discovery layer providing tool registry, search strategies, and progressive documentation for the ApertureStack tool framework.</p>"},{"location":"library-docs-from-repos/tooldiscovery/#packages","title":"Packages","text":"Package Purpose <code>discovery</code> Unified facade combining index, search, semantic, and tooldoc <code>index</code> Global registry, tool lookup, and search interface <code>search</code> BM25-based full-text search strategy <code>semantic</code> Embedding-based semantic search (optional) <code>tooldoc</code> Progressive documentation with detail levels <code>registry</code> MCP server helper with local + backend execution"},{"location":"library-docs-from-repos/tooldiscovery/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/tooldiscovery@latest\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#quick-start","title":"Quick Start","text":""},{"location":"library-docs-from-repos/tooldiscovery/#use-the-discovery-facade-recommended","title":"Use the Discovery Facade (Recommended)","text":"<pre><code>import (\n  \"context\"\n  \"github.com/jonwraymond/tooldiscovery/discovery\"\n)\n\ndisc, _ := discovery.New(discovery.Options{})\n\n// Register tools through the facade\n_ = disc.RegisterTool(tool, backend)\n\n// Search (hybrid-ready)\nresults, _ := disc.Search(context.Background(), \"create issue\", 5)\nfor _, r := range results {\n  fmt.Printf(\"[%s] %s\\n\", r.ScoreType, r.Summary.ID)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#build-an-mcp-server-registry","title":"Build an MCP Server (registry)","text":"<pre><code>import (\n  \"context\"\n  \"github.com/jonwraymond/tooldiscovery/registry\"\n)\n\nreg := registry.New(registry.Config{\n  ServerInfo: registry.ServerInfo{Name: \"my-mcp\", Version: \"1.0.0\"},\n})\n\n_ = reg.RegisterLocalFunc(\n  \"echo\",\n  \"Echo input\",\n  map[string]any{\"type\": \"object\"},\n  func(ctx context.Context, args map[string]any) (any, error) { return args, nil },\n)\n\n_ = reg.Start(context.Background())\ndefer reg.Stop()\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#register-and-search-tools","title":"Register and Search Tools","text":"<pre><code>import (\n  \"github.com/jonwraymond/tooldiscovery/index\"\n  \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Create an index\nidx := index.NewInMemoryIndex()\n\n// Register a tool\nerr := idx.RegisterTool(tool, backend)\nif err != nil {\n  log.Fatal(err)\n}\n\n// Search for tools\nsummaries, err := idx.Search(\"create issue\", 5)\nfor _, s := range summaries {\n  fmt.Printf(\"%s: %s\\n\", s.ID, s.Summary)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#enable-bm25-search","title":"Enable BM25 Search","text":"<pre><code>import (\n  \"github.com/jonwraymond/tooldiscovery/index\"\n  \"github.com/jonwraymond/tooldiscovery/search\"\n)\n\n// Create BM25 searcher\nsearcher, err := search.NewBM25Searcher(search.DefaultConfig())\nif err != nil {\n  log.Fatal(err)\n}\ndefer searcher.Close()\n\n// Create index with BM25\nidx := index.NewInMemoryIndex(index.WithSearchStrategy(searcher))\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#search-strategy-guidance","title":"Search Strategy Guidance","text":"<ul> <li>Lexical (default): simple substring matching; best for small registries.</li> <li>BM25 (<code>search</code>): higher quality ranking for larger registries.</li> <li>Semantic (<code>semantic</code>): intent-based matching when embeddings are available.</li> <li>Hybrid (<code>discovery</code>): combines BM25 + semantic with weighted scoring.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/#progressive-documentation","title":"Progressive Documentation","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n\nstore := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n// Get summary only (token-cheap)\ndoc, _ := store.GetDoc(toolID, tooldoc.DetailSummary)\n\n// Get full schema (on-demand)\ndoc, _ = store.GetDoc(toolID, tooldoc.DetailSchema)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#semantic-search-optional","title":"Semantic Search (Optional)","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/semantic\"\n\n// Provide an Embedder + VectorStore implementation\nsearcher := semantic.NewSemanticSearcher(embedder, vectorStore)\nidx := index.NewInMemoryIndex(index.WithSearchStrategy(searcher))\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/#key-features","title":"Key Features","text":"<ul> <li>Token-efficient: Summaries exclude schemas to reduce context usage</li> <li>Pluggable search: Swap between lexical, BM25, or semantic search</li> <li>Progressive disclosure: Request only the detail level needed</li> <li>Namespace support: List and filter tools by namespace</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/#links","title":"Links","text":"<ul> <li>design notes</li> <li>user journey</li> <li>schemas and contracts</li> <li>architecture</li> <li>registry</li> <li>concurrency</li> <li>error handling</li> <li>performance</li> <li>migration</li> <li>ai-tools-stack documentation</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/","title":"Architecture Overview","text":"<p>This document describes the component architecture of tooldiscovery and how the packages interact.</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#package-hierarchy","title":"Package Hierarchy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         discovery                                \u2502\n\u2502              (Unified Facade - Recommended Entry Point)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                 \u2502                 \u2502\n         v                 v                 v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    index    \u2502\u25c4\u2500\u2500\u2500\u2502   semantic   \u2502   \u2502  tooldoc \u2502\n\u2502  (Registry) \u2502    \u2502  (Scoring)   \u2502   \u2502  (Docs)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                    \u2502\n       v                                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n\u2502    search    \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502   (BM25)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  toolfoundation  \u2502\n\u2502     (model)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#package-responsibilities","title":"Package Responsibilities","text":""},{"location":"library-docs-from-repos/tooldiscovery/architecture/#discovery-unified-facade","title":"<code>discovery</code> - Unified Facade","text":"<p>The recommended entry point for most use cases. Combines all packages into a simple API.</p> <p>Provides: - Single <code>Discovery</code> type with unified operations - Built-in hybrid search (BM25 + semantic) - Integrated documentation management - Result filtering helpers</p> <p>Key Types: - <code>Discovery</code> - Main facade - <code>Options</code> - Configuration - <code>Result</code> / <code>Results</code> - Search results with scores - <code>HybridSearcher</code> - Composite searcher</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#registry-mcp-server-helper","title":"<code>registry</code> - MCP Server Helper","text":"<p>High-level helper for building MCP servers. It composes <code>index</code> + <code>search</code> with local execution handlers and MCP backend aggregation.</p> <p>Provides: - Local tool registration with handlers - MCP backend connections and tool aggregation - MCP protocol handlers (<code>initialize</code>, <code>tools/list</code>, <code>tools/call</code>) - Transports (<code>ServeStdio</code>, <code>ServeHTTP</code>, <code>ServeSSE</code>)</p> <p>Key Types: - <code>Registry</code> - Core registry + lifecycle - <code>ToolHandler</code> - Local execution handler - <code>BackendConfig</code> - MCP backend connection config</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#index-tool-registry","title":"<code>index</code> - Tool Registry","text":"<p>Core registry for tool storage, lookup, and search orchestration.</p> <p>Provides: - Tool registration with backends - Canonical ID generation (<code>namespace:name:version</code> when version is set) - Pluggable search via <code>Searcher</code> interface - Change notifications - Pagination support</p> <p>Key Types: - <code>Index</code> - Registry interface - <code>InMemoryIndex</code> - Default implementation - <code>Searcher</code> - Search strategy interface - <code>Summary</code> / <code>SearchDoc</code> - Lightweight search results</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#search-bm25-implementation","title":"<code>search</code> - BM25 Implementation","text":"<p>Production-ready BM25 search using Bleve.</p> <p>Provides: - Full-text search with field boosting - Configurable term weighting - Deterministic ordering for pagination - Efficient index caching</p> <p>Key Types: - <code>BM25Searcher</code> - Main searcher (implements <code>index.Searcher</code>) - <code>BM25Config</code> - Boost configuration</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#semantic-embedding-search","title":"<code>semantic</code> - Embedding Search","text":"<p>Pluggable semantic search with no external dependencies.</p> <p>Provides: - Strategy pattern for scoring (BM25, embedding, hybrid) - Document indexing for semantic operations - Bring-your-own-embedder support - Namespace/tag filtering</p> <p>Key Types: - <code>Strategy</code> - Scoring interface - <code>Embedder</code> - User-provided embedding generator - <code>Indexer</code> - Document storage interface - <code>Document</code> - Semantic document model</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#tooldoc-documentation-store","title":"<code>tooldoc</code> - Documentation Store","text":"<p>Progressive disclosure documentation system.</p> <p>Provides: - Three detail levels (summary, schema, full) - Example storage and validation - Schema information extraction - Integration with index for tool lookup</p> <p>Key Types: - <code>Store</code> - Documentation interface - <code>InMemoryStore</code> - Default implementation - <code>DetailLevel</code> - Disclosure granularity - <code>ToolDoc</code> / <code>DocEntry</code> - Documentation types</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#data-flow","title":"Data Flow","text":""},{"location":"library-docs-from-repos/tooldiscovery/architecture/#tool-registration","title":"Tool Registration","text":"<pre><code>model.Tool + ToolBackend\n        \u2502\n        v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 index.Index   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Stores tool + backend\n\u2502 RegisterTool  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Normalizes tags\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Builds SearchDoc\n        \u2502               \u2500\u2500\u2500\u2500\u2500\u2500\u25ba Notifies listeners\n        v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 tooldoc.Store \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Stores documentation\n\u2502 RegisterDoc   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Validates examples\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#search-flow","title":"Search Flow","text":"<pre><code>Query String\n     \u2502\n     v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 index.Search   \u2502\u25c4\u2500\u2500\u2500 Gets SearchDoc snapshot\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502\n        v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Searcher.Search\u2502\u25c4\u2500\u2500\u2500 BM25Searcher or HybridSearcher\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502\n        v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Strategy.Score \u2502\u25c4\u2500\u2500\u2500 BM25, Embedding, or Hybrid\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502\n        v\n   []Summary (sorted by score, then ID)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#progressive-disclosure","title":"Progressive Disclosure","text":"<pre><code>Tool ID\n   \u2502\n   \u251c\u2500\u2500\u25ba DetailSummary \u2500\u2500\u25ba Summary only (cheap)\n   \u2502\n   \u251c\u2500\u2500\u25ba DetailSchema  \u2500\u2500\u25ba Summary + Tool + SchemaInfo\n   \u2502\n   \u2514\u2500\u2500\u25ba DetailFull    \u2500\u2500\u25ba Everything + Notes + Examples\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#interface-contracts","title":"Interface Contracts","text":""},{"location":"library-docs-from-repos/tooldiscovery/architecture/#indexsearcher","title":"index.Searcher","text":"<pre><code>type Searcher interface {\n    Search(query string, limit int, docs []SearchDoc) ([]Summary, error)\n}\n</code></pre> <p>Contract: - Must be safe for concurrent use - Must return deterministic ordering (score desc, ID asc) - Must handle empty query (return first N docs) - Must respect limit parameter</p> <p>Implementations: - <code>search.BM25Searcher</code> - Bleve-based full-text search - <code>discovery.HybridSearcher</code> - BM25 + semantic combination - <code>discovery.BM25OnlySearcher</code> - Semantic BM25 with scores</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#indexdeterministicsearcher","title":"index.DeterministicSearcher","text":"<pre><code>type DeterministicSearcher interface {\n    Searcher\n    Deterministic() bool\n}\n</code></pre> <p>Required for pagination support. Implementations that return <code>true</code> guarantee stable ordering across calls with identical inputs.</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#semanticstrategy","title":"semantic.Strategy","text":"<pre><code>type Strategy interface {\n    Score(ctx context.Context, query string, doc Document) (float64, error)\n}\n</code></pre> <p>Contract: - Must honor context cancellation - Must return deterministic scores - Must be safe for concurrent use</p> <p>Implementations: - <code>bm25Strategy</code> - Token overlap scoring - <code>embeddingStrategy</code> - Cosine similarity of embeddings - <code>hybridStrategy</code> - Weighted combination</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#semanticembedder","title":"semantic.Embedder","text":"<pre><code>type Embedder interface {\n    Embed(ctx context.Context, text string) ([]float32, error)\n}\n</code></pre> <p>Contract: - Must honor context cancellation - Must return consistent-length vectors - Must be safe for concurrent use</p> <p>User-provided implementations connect to embedding services (OpenAI, Ollama, etc.).</p>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#type-mapping","title":"Type Mapping","text":""},{"location":"library-docs-from-repos/tooldiscovery/architecture/#indexsearchdoc-semanticdocument","title":"index.SearchDoc \u2194 semantic.Document","text":"<p>The <code>semantic/adapter.go</code> provides conversion between package types:</p> index.SearchDoc semantic.Document ID ID DocText Text Summary.Name Name Summary.Namespace Namespace Summary.Summary (fallback ShortDescription) Description Summary.Tags Tags Summary.Category Category"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#configuration-patterns","title":"Configuration Patterns","text":""},{"location":"library-docs-from-repos/tooldiscovery/architecture/#minimal-setup-bm25-only","title":"Minimal Setup (BM25 only)","text":"<pre><code>idx := index.NewInMemoryIndex()  // Uses built-in lexical searcher\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#bm25-with-custom-config","title":"BM25 with Custom Config","text":"<pre><code>searcher := search.NewBM25Searcher(search.BM25Config{\n    NameBoost: 3,\n    TagsBoost: 2,\n})\nidx := index.NewInMemoryIndex(index.IndexOptions{\n    Searcher: searcher,\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#hybrid-search-via-discovery","title":"Hybrid Search via Discovery","text":"<pre><code>disc, _ := discovery.New(discovery.Options{\n    Embedder:    myEmbedder,\n    HybridAlpha: 0.7,  // 70% BM25, 30% semantic\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/architecture/#extension-points","title":"Extension Points","text":"<ol> <li>Custom Searcher: Implement <code>index.Searcher</code> for alternative search backends</li> <li>Custom Embedder: Implement <code>semantic.Embedder</code> for any embedding provider</li> <li>Custom Strategy: Implement <code>semantic.Strategy</code> for custom scoring logic</li> <li>Custom Backend Selector: Provide <code>BackendSelector</code> function to <code>IndexOptions</code></li> <li>Change Listeners: Subscribe via <code>OnChange</code> for reactive integrations</li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/","title":"Concurrency Guide","text":"<p>All tooldiscovery types are safe for concurrent use. This document explains the concurrency model and provides examples of safe concurrent patterns.</p>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#thread-safety-guarantees","title":"Thread Safety Guarantees","text":""},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#index-package","title":"index Package","text":"Type Thread Safety Implementation <code>InMemoryIndex</code> Safe <code>sync.RWMutex</code> <code>Summary</code> Immutable Value type <code>SearchDoc</code> Immutable Value type <code>ChangeEvent</code> Immutable Value type <p>Operations: - <code>RegisterTool</code>: Write lock (exclusive) - <code>GetTool</code>: Read lock (shared) - <code>Search</code>: Read lock (shared) - <code>OnChange</code>: Write lock for subscription, callbacks run outside lock</p>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#search-package","title":"search Package","text":"Type Thread Safety Implementation <code>BM25Searcher</code> Safe <code>sync.RWMutex</code> + fingerprint caching <p>Operations: - <code>Search</code>: Read lock for cache check, write lock only on cache miss - <code>Close</code>: Write lock (exclusive)</p>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#semantic-package","title":"semantic Package","text":"Type Thread Safety Implementation <code>InMemoryIndex</code> Safe <code>sync.RWMutex</code>, point-in-time snapshots <code>InMemorySearcher</code> Safe Stateless All strategies Safe Stateless <p>Note: <code>InMemoryIndex.List()</code> holds the read lock for the entire operation to ensure point-in-time snapshot consistency.</p>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#tooldoc-package","title":"tooldoc Package","text":"Type Thread Safety Implementation <code>InMemoryStore</code> Safe <code>sync.RWMutex</code> <code>ToolDoc</code> Immutable Value type (deep copied) <code>DocEntry</code> Immutable Value type"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#discovery-package","title":"discovery Package","text":"Type Thread Safety Implementation <code>Discovery</code> Safe Delegates to thread-safe components <code>HybridSearcher</code> Safe Stateless <code>Results</code> Immutable Value type"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#concurrent-usage-patterns","title":"Concurrent Usage Patterns","text":""},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#concurrent-search","title":"Concurrent Search","text":"<p>Multiple goroutines can search simultaneously:</p> <pre><code>idx := index.NewInMemoryIndex()\n// ... register tools ...\n\nvar wg sync.WaitGroup\nqueries := []string{\"git\", \"docker\", \"kubernetes\", \"python\", \"javascript\"}\n\nfor _, query := range queries {\n    wg.Add(1)\n    go func(q string) {\n        defer wg.Done()\n\n        results, err := idx.Search(q, 10)\n        if err != nil {\n            log.Printf(\"Search failed for %q: %v\", q, err)\n            return\n        }\n        log.Printf(\"Found %d results for %q\", len(results), q)\n    }(query)\n}\n\nwg.Wait()\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#concurrent-registration-and-search","title":"Concurrent Registration and Search","text":"<p>Searches can run while registrations happen:</p> <pre><code>idx := index.NewInMemoryIndex()\nctx, cancel := context.WithCancel(context.Background())\ndefer cancel()\n\n// Background registration\ngo func() {\n    for i := 0; i &lt; 1000; i++ {\n        tool := createTool(i)\n        if err := idx.RegisterTool(tool, backend); err != nil {\n            log.Printf(\"Registration failed: %v\", err)\n        }\n        time.Sleep(10 * time.Millisecond)\n    }\n}()\n\n// Concurrent searches\nfor i := 0; i &lt; 10; i++ {\n    go func() {\n        for {\n            select {\n            case &lt;-ctx.Done():\n                return\n            default:\n                results, _ := idx.Search(\"tool\", 10)\n                log.Printf(\"Found %d tools\", len(results))\n                time.Sleep(50 * time.Millisecond)\n            }\n        }\n    }()\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#concurrent-documentation-access","title":"Concurrent Documentation Access","text":"<pre><code>store := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\nvar wg sync.WaitGroup\ntoolIDs := []string{\"git:status\", \"docker:ps\", \"kubectl:get\"}\n\nfor _, id := range toolIDs {\n    wg.Add(1)\n    go func(toolID string) {\n        defer wg.Done()\n\n        // These can all run concurrently\n        summary, _ := store.DescribeTool(toolID, tooldoc.DetailSummary)\n        schema, _ := store.DescribeTool(toolID, tooldoc.DetailSchema)\n        full, _ := store.DescribeTool(toolID, tooldoc.DetailFull)\n\n        log.Printf(\"%s: summary=%q, hasSchema=%v, notes=%q\",\n            toolID, summary.Summary, schema.SchemaInfo != nil, full.Notes)\n    }(id)\n}\n\nwg.Wait()\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#using-discovery-facade-concurrently","title":"Using Discovery Facade Concurrently","text":"<pre><code>disc, _ := discovery.New(discovery.Options{})\n// ... register tools ...\n\n// Concurrent hybrid search\nresults := make(chan discovery.Results, 10)\nqueries := []string{\"create issue\", \"list containers\", \"deploy app\"}\n\nfor _, q := range queries {\n    go func(query string) {\n        ctx := context.Background()\n        r, err := disc.Search(ctx, query, 10)\n        if err != nil {\n            log.Printf(\"Search error: %v\", err)\n            results &lt;- nil\n            return\n        }\n        results &lt;- r\n    }(q)\n}\n\nfor range queries {\n    r := &lt;-results\n    if r != nil {\n        log.Printf(\"Got %d results\", len(r))\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#change-notification-safety","title":"Change Notification Safety","text":"<p>Change listeners are called outside the index lock to prevent deadlocks:</p> <pre><code>idx := index.NewInMemoryIndex()\n\n// Safe: listener doesn't hold locks\nunsubscribe := idx.OnChange(func(event index.ChangeEvent) {\n    // This runs outside the index lock\n    log.Printf(\"Tool %s: %s\", event.ToolID, event.Type)\n\n    // Safe to call index methods (they acquire their own locks)\n    if event.Type == index.ChangeRegistered {\n        tool, _, _ := idx.GetTool(event.ToolID)\n        log.Printf(\"Registered: %s\", tool.Description)\n    }\n})\ndefer unsubscribe()\n\n// Registrations trigger callbacks\nidx.RegisterTool(tool, backend)\n</code></pre> <p>Warning: Don't hold your own locks when calling index methods from listeners, as this can cause deadlocks.</p>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#embedder-concurrency","title":"Embedder Concurrency","text":"<p>Custom embedders must be thread-safe:</p> <pre><code>type CachedEmbedder struct {\n    client *openai.Client\n    cache  sync.Map // Thread-safe cache\n}\n\nfunc (e *CachedEmbedder) Embed(ctx context.Context, text string) ([]float32, error) {\n    // Check cache (thread-safe)\n    if cached, ok := e.cache.Load(text); ok {\n        return cached.([]float32), nil\n    }\n\n    // Make API call\n    resp, err := e.client.CreateEmbedding(ctx, openai.EmbeddingRequest{\n        Model: \"text-embedding-3-small\",\n        Input: []string{text},\n    })\n    if err != nil {\n        return nil, err\n    }\n\n    vec := resp.Data[0].Embedding\n\n    // Store in cache (thread-safe)\n    e.cache.Store(text, vec)\n\n    return vec, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#avoiding-common-pitfalls","title":"Avoiding Common Pitfalls","text":""},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#dont-hold-locks-across-calls","title":"Don't Hold Locks Across Calls","text":"<pre><code>// BAD: Holding your own lock while calling index methods\nfunc (s *MyService) badPattern() {\n    s.mu.Lock()\n    defer s.mu.Unlock()\n\n    // This acquires the index lock while holding s.mu\n    // If another goroutine holds index lock and tries to acquire s.mu,\n    // you have a deadlock\n    results, _ := s.idx.Search(\"query\", 10)\n    s.cache = results\n}\n\n// GOOD: Release your lock before calling index methods\nfunc (s *MyService) goodPattern() {\n    results, _ := s.idx.Search(\"query\", 10)\n\n    s.mu.Lock()\n    s.cache = results\n    s.mu.Unlock()\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#dont-modify-returned-slices","title":"Don't Modify Returned Slices","text":"<pre><code>// BAD: Modifying returned slice\nresults, _ := idx.Search(\"query\", 10)\nresults[0].Name = \"modified\" // Don't do this!\n\n// GOOD: Copy if you need to modify\nresults, _ := idx.Search(\"query\", 10)\nmyResults := make([]index.Summary, len(results))\ncopy(myResults, results)\nmyResults[0].Name = \"modified\" // Safe\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#use-context-for-timeouts","title":"Use Context for Timeouts","text":"<pre><code>// GOOD: Use context to prevent hanging on slow embedders\nfunc (s *MyService) SearchWithTimeout(query string) ([]Result, error) {\n    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n    defer cancel()\n\n    return s.searcher.Search(ctx, query)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/concurrency/#benchmarking-concurrent-performance","title":"Benchmarking Concurrent Performance","text":"<p>Use the provided benchmarks to measure concurrent performance:</p> <pre><code># Run concurrent benchmarks\ngo test ./index -bench=Concurrent -benchtime=5s\n\n# Example output:\n# BenchmarkIndex_Concurrent_Search-8     50000    25000 ns/op\n# BenchmarkIndex_Concurrent_Mixed-8      30000    40000 ns/op\n</code></pre> <p>The benchmarks use <code>b.RunParallel</code> to test concurrent access patterns.</p>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/","title":"tooldiscovery Design Notes","text":""},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#overview","title":"Overview","text":"<p>tooldiscovery provides the discovery layer for the ApertureStack tool framework. It handles tool registration, search, and progressive documentation.</p>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#index-package","title":"index Package","text":""},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#design-decisions","title":"Design Decisions","text":"<ol> <li> <p>Single Source of Truth: The index is the authoritative registry for all    registered tools. Tool IDs are derived from <code>toolfoundation/model.Tool.ToolID()</code>.</p> </li> <li> <p>Search Strategy Interface: Search is pluggable via the <code>SearchStrategy</code>    interface. Default is lexical substring matching.</p> </li> <li> <p>Token-Efficient Summaries: <code>Search()</code> returns <code>Summary</code> objects that    exclude schemas, keeping discovery cheap in terms of LLM context tokens.</p> </li> <li> <p>Namespace Isolation: Tools are grouped by namespace, enabling filtered    views and multi-tenant scenarios.</p> </li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#error-handling","title":"Error Handling","text":"<ul> <li>Duplicate tool registration returns an error</li> <li>Invalid tool IDs return descriptive errors</li> <li>Search errors are logged but don't fail the request</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#search-package","title":"search Package","text":""},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#design-decisions_1","title":"Design Decisions","text":"<ol> <li> <p>BM25 Algorithm: Uses Okapi BM25 for relevance ranking, implemented via    the Bleve search library.</p> </li> <li> <p>Field Boosting: Configurable boosts for name (4x), namespace (2x), and    tags (1x) fields.</p> </li> <li> <p>Optional Dependency: BM25 support depends on Bleve and is only used when    the <code>search</code> package is imported. Consumers can omit BM25 entirely by    sticking with the default lexical strategy.</p> </li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#search-strategy-policy","title":"Search Strategy Policy","text":"<ul> <li>Lexical (default): Lightweight substring matching; best for small indexes.</li> <li>BM25 (search package): Preferred for larger registries; tunable boosts.</li> <li>Semantic (semantic package): Best for fuzzy intent matching; requires embeddings.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#configuration","title":"Configuration","text":"Config Default Description NameBoost 4.0 Boost for tool name matches NamespaceBoost 2.0 Boost for namespace matches TagBoost 1.0 Boost for tag matches MaxDocs 0 Max docs to index (0=unlimited)"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#semantic-package","title":"semantic Package","text":""},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#design-decisions_2","title":"Design Decisions","text":"<ol> <li> <p>Embedder Interface: Abstracts the embedding model, allowing different    providers (OpenAI, local models, etc.).</p> </li> <li> <p>Vector Store Interface: Abstracts the vector storage, supporting    in-memory, file-based, or external stores.</p> </li> <li> <p>Optional Dependency: Semantic search is opt-in and requires additional    setup (embeddings, vector store).</p> </li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#contract-expectations","title":"Contract Expectations","text":"<ul> <li>Embedder: Must be deterministic for the same input and return fixed-size   vectors. Errors should be propagated rather than swallowed.</li> <li>VectorStore: Must return results ordered by similarity and include IDs   that map back to registered tools.</li> <li>Hybrid: The hybrid searcher uses Reciprocal Rank Fusion (RRF) to combine   BM25 and semantic results.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#tooldoc-package","title":"tooldoc Package","text":""},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#design-decisions_3","title":"Design Decisions","text":"<ol> <li>Detail Levels: Three progressive levels:</li> <li><code>Summary</code>: Name, namespace, short description</li> <li><code>Schema</code>: Input/output JSON schemas</li> <li> <p><code>Full</code>: Everything including examples</p> </li> <li> <p>On-Demand Loading: Schemas are only loaded when requested at    <code>DetailSchema</code> or <code>DetailFull</code> level.</p> </li> <li> <p>Index Integration: DocStore can use an Index to derive documentation    from registered tools.</p> </li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#detail-level-field-matrix","title":"Detail-Level Field Matrix","text":"Level Fields Summary ID, Name, Namespace, ShortDescription, Summary, Category, InputModes, OutputModes, SecuritySummary Schema Summary + InputSchema, OutputSchema Full Schema + Examples, Metadata"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#dependencies","title":"Dependencies","text":"<ul> <li><code>github.com/jonwraymond/toolfoundation/model</code> - Tool definitions</li> <li><code>github.com/blevesearch/bleve/v2</code> - BM25 search (optional)</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/design-notes/#links","title":"Links","text":"<ul> <li>index</li> <li>user journey</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/","title":"Error Handling Guide","text":"<p>This document describes the error types and error handling patterns used throughout tooldiscovery.</p>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#error-types-by-package","title":"Error Types by Package","text":""},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#index-package","title":"index Package","text":"Error When Returned Example Cause <code>ErrNotFound</code> Tool/backend lookup fails <code>GetTool(\"nonexistent:tool\")</code> <code>ErrInvalidTool</code> Tool validation fails Empty name, invalid schema <code>ErrInvalidBackend</code> Backend validation fails MCP backend missing ServerName <code>ErrInvalidCursor</code> Pagination cursor invalid Malformed or expired cursor <code>ErrNonDeterministicSearcher</code> SearchPage with non-deterministic searcher Custom searcher without stable ordering"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#search-package","title":"search Package","text":"<p>The search package returns errors from the underlying Bleve index but doesn't define custom error types. Errors are typically related to index operations.</p>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#semantic-package","title":"semantic Package","text":"Error When Returned Example Cause <code>ErrInvalidSearcher</code> Searcher missing components <code>NewSearcher(nil, nil)</code> <code>ErrInvalidDocumentID</code> Document ID is empty <code>idx.Add(ctx, Document{})</code> <code>ErrInvalidEmbedder</code> Embedder is nil <code>NewEmbeddingStrategy(nil)</code> <code>ErrInvalidHybridConfig</code> Invalid hybrid config Alpha outside [0,1] range"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#tooldoc-package","title":"tooldoc Package","text":"Error When Returned Example Cause <code>ErrNotFound</code> Tool not in index/resolver Unknown tool ID <code>ErrInvalidDetail</code> Invalid detail level Unrecognized DetailLevel value <code>ErrNoTool</code> No tool source configured Store without Index or ToolResolver <code>ErrArgsTooLarge</code> Example args exceed limits Nesting &gt; 5 or keys &gt; 50"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#discovery-package","title":"discovery Package","text":"Error When Returned Example Cause <code>ErrNotFound</code> Tool lookup fails Forwarded from index package"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#error-checking-patterns","title":"Error Checking Patterns","text":""},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#using-errorsis","title":"Using errors.Is","text":"<p>Always use <code>errors.Is</code> for error checking, as errors may be wrapped:</p> <pre><code>tool, backend, err := idx.GetTool(\"github:create-issue\")\nif errors.Is(err, index.ErrNotFound) {\n    // Tool doesn't exist\n    log.Printf(\"Tool not found: %s\", toolID)\n    return\n}\nif err != nil {\n    // Other error\n    return fmt.Errorf(\"failed to get tool: %w\", err)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#handling-validation-errors","title":"Handling Validation Errors","text":"<p>Validation errors often wrap the sentinel error with additional context:</p> <pre><code>err := idx.RegisterTool(tool, backend)\nif errors.Is(err, index.ErrInvalidTool) {\n    // Tool validation failed - check the error message for details\n    log.Printf(\"Invalid tool: %v\", err)\n    return\n}\nif errors.Is(err, index.ErrInvalidBackend) {\n    // Backend validation failed\n    log.Printf(\"Invalid backend: %v\", err)\n    return\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#handling-search-errors","title":"Handling Search Errors","text":"<pre><code>results, err := searcher.Search(ctx, query)\nif errors.Is(err, semantic.ErrInvalidSearcher) {\n    // Searcher not properly configured\n    log.Fatal(\"Searcher missing index or strategy\")\n}\nif errors.Is(err, semantic.ErrInvalidEmbedder) {\n    // Embedder is nil (for embedding/hybrid strategies)\n    log.Fatal(\"Embedder required for semantic search\")\n}\nif err != nil {\n    // May be context cancellation or embedder error\n    return fmt.Errorf(\"search failed: %w\", err)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#handling-documentation-errors","title":"Handling Documentation Errors","text":"<pre><code>doc, err := store.DescribeTool(toolID, tooldoc.DetailFull)\nif errors.Is(err, tooldoc.ErrNotFound) {\n    // Tool not found in index\n    return nil, fmt.Errorf(\"unknown tool: %s\", toolID)\n}\nif errors.Is(err, tooldoc.ErrNoTool) {\n    // Store has no way to look up tools\n    log.Fatal(\"Store not configured with Index or ToolResolver\")\n}\nif errors.Is(err, tooldoc.ErrInvalidDetail) {\n    // Invalid detail level (shouldn't happen with constants)\n    return nil, fmt.Errorf(\"invalid detail level\")\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#context-errors","title":"Context Errors","text":"<p>Many operations accept a context and honor cancellation:</p> <pre><code>ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\ndefer cancel()\n\nresults, err := searcher.Search(ctx, query)\nif errors.Is(err, context.DeadlineExceeded) {\n    log.Printf(\"Search timed out\")\n    return nil, err\n}\nif errors.Is(err, context.Canceled) {\n    log.Printf(\"Search was canceled\")\n    return nil, err\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#wrapping-errors","title":"Wrapping Errors","text":"<p>When propagating errors, wrap them with context:</p> <pre><code>func (s *MyService) FindTools(query string) ([]Tool, error) {\n    results, err := s.discovery.Search(ctx, query, 10)\n    if err != nil {\n        return nil, fmt.Errorf(\"tool search failed: %w\", err)\n    }\n\n    var tools []Tool\n    for _, r := range results {\n        tool, _, err := s.discovery.GetTool(r.Summary.ID)\n        if err != nil {\n            // Log but continue - tool may have been removed\n            log.Printf(\"Failed to get tool %s: %v\", r.Summary.ID, err)\n            continue\n        }\n        tools = append(tools, tool)\n    }\n    return tools, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#validation-before-operations","title":"Validation Before Operations","text":"<p>Validate inputs before expensive operations:</p> <pre><code>// Validate tool before registration\nif tool.Name == \"\" {\n    return fmt.Errorf(\"tool name is required\")\n}\nif tool.InputSchema == nil {\n    return fmt.Errorf(\"tool InputSchema is required\")\n}\n\n// Now safe to register\nif err := idx.RegisterTool(tool, backend); err != nil {\n    return fmt.Errorf(\"registration failed: %w\", err)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#error-recovery-patterns","title":"Error Recovery Patterns","text":""},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>func (s *MyService) Search(query string) ([]Result, error) {\n    // Try hybrid search first\n    if s.embedder != nil {\n        results, err := s.hybridSearch(query)\n        if err == nil {\n            return results, nil\n        }\n        // Log and fall back to BM25\n        log.Printf(\"Hybrid search failed, falling back to BM25: %v\", err)\n    }\n\n    // Fall back to BM25-only search\n    return s.bm25Search(query)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#retry-with-backoff","title":"Retry with Backoff","text":"<pre><code>func (e *MyEmbedder) EmbedWithRetry(ctx context.Context, text string) ([]float32, error) {\n    var lastErr error\n    for i := 0; i &lt; 3; i++ {\n        vec, err := e.Embed(ctx, text)\n        if err == nil {\n            return vec, nil\n        }\n        lastErr = err\n\n        // Don't retry on context errors\n        if errors.Is(err, context.Canceled) || errors.Is(err, context.DeadlineExceeded) {\n            return nil, err\n        }\n\n        // Exponential backoff\n        time.Sleep(time.Duration(1&lt;&lt;i) * 100 * time.Millisecond)\n    }\n    return nil, fmt.Errorf(\"embedding failed after 3 retries: %w\", lastErr)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/error-handling/#testing-error-conditions","title":"Testing Error Conditions","text":"<pre><code>func TestGetTool_NotFound(t *testing.T) {\n    idx := index.NewInMemoryIndex()\n\n    _, _, err := idx.GetTool(\"nonexistent:tool\")\n\n    if !errors.Is(err, index.ErrNotFound) {\n        t.Errorf(\"expected ErrNotFound, got %v\", err)\n    }\n}\n\nfunc TestRegisterTool_InvalidTool(t *testing.T) {\n    idx := index.NewInMemoryIndex()\n\n    // Tool with empty name\n    tool := model.Tool{\n        Tool: mcp.Tool{\n            Name: \"\", // Invalid\n            InputSchema: map[string]any{\"type\": \"object\"},\n        },\n    }\n\n    err := idx.RegisterTool(tool, model.NewMCPBackend(\"server\"))\n\n    if !errors.Is(err, index.ErrInvalidTool) {\n        t.Errorf(\"expected ErrInvalidTool, got %v\", err)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/examples/","title":"Examples","text":"<p>tooldiscovery ships with runnable examples that demonstrate each search mode and documentation level.</p>"},{"location":"library-docs-from-repos/tooldiscovery/examples/#basic-discovery-bm25-progressive-docs","title":"Basic discovery (BM25 + progressive docs)","text":"<pre><code>go run ./examples/basic\n</code></pre> <p>Shows: - Registering tools in the index - BM25 search results - Summary vs schema disclosure</p>"},{"location":"library-docs-from-repos/tooldiscovery/examples/#semantic-search","title":"Semantic search","text":"<pre><code>go run ./examples/semantic\n</code></pre> <p>Shows: - Custom embedder stub - Semantic index + searcher - Score ordering</p>"},{"location":"library-docs-from-repos/tooldiscovery/examples/#hybrid-search","title":"Hybrid search","text":"<pre><code>go run ./examples/hybrid\n</code></pre> <p>Shows: - BM25 + semantic weighted scoring - Score type tracking</p>"},{"location":"library-docs-from-repos/tooldiscovery/examples/#full-discovery-facade","title":"Full discovery facade","text":"<pre><code>go run ./examples/full\n</code></pre> <p>Shows: - <code>discovery.Discovery</code> unified API - Registration + search + describe flow</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/","title":"Migration Guide","text":"<p>This guide helps you migrate to tooldiscovery from other tool discovery systems.</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#migrating-from-toolindex","title":"Migrating from toolindex","text":"<p>The <code>tooldiscovery/index</code> package is the successor to <code>github.com/jonwraymond/toolindex</code>. The migration is straightforward as the API is largely compatible.</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#import-changes","title":"Import Changes","text":"<pre><code>// Before\nimport \"github.com/jonwraymond/toolindex\"\n\n// After\nimport \"github.com/jonwraymond/tooldiscovery/index\"\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#type-mapping","title":"Type Mapping","text":"toolindex tooldiscovery/index Notes <code>Index</code> <code>Index</code> Same interface <code>InMemoryIndex</code> <code>InMemoryIndex</code> Same implementation <code>Summary</code> <code>Summary</code> Same fields <code>SearchDoc</code> <code>SearchDoc</code> Same fields <code>Searcher</code> <code>Searcher</code> Same interface <code>ToolRegistration</code> <code>ToolRegistration</code> Same struct"},{"location":"library-docs-from-repos/tooldiscovery/migration/#new-features","title":"New Features","text":"<p>tooldiscovery adds: - <code>discovery</code> package for unified facade - <code>semantic</code> package for embedding-based search - <code>tooldoc</code> package for progressive documentation - <code>search</code> package with production BM25</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#code-changes","title":"Code Changes","text":"<p>Most code works unchanged:</p> <pre><code>// Before\nidx := toolindex.NewInMemoryIndex()\nidx.RegisterTool(tool, backend)\nresults, _ := idx.Search(\"query\", 10)\n\n// After (identical)\nidx := index.NewInMemoryIndex()\nidx.RegisterTool(tool, backend)\nresults, _ := idx.Search(\"query\", 10)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#using-discovery-facade-recommended","title":"Using Discovery Facade (Recommended)","text":"<p>For new code, use the <code>discovery</code> package:</p> <pre><code>// New recommended approach\ndisc, _ := discovery.New(discovery.Options{})\ndisc.RegisterTool(tool, backend, &amp;tooldoc.DocEntry{\n    Summary: \"Tool description\",\n})\nresults, _ := disc.Search(ctx, \"query\", 10)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#migrating-from-custom-tool-registries","title":"Migrating from Custom Tool Registries","text":"<p>If you have a custom tool registry, here's how to migrate:</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#step-1-map-your-tool-type","title":"Step 1: Map Your Tool Type","text":"<p>Create a function to convert your tools to <code>model.Tool</code>:</p> <pre><code>func convertTool(myTool MyTool) model.Tool {\n    return model.Tool{\n        Tool: mcp.Tool{\n            Name:        myTool.Name,\n            Description: myTool.Description,\n            InputSchema: myTool.Schema,\n        },\n        Namespace: myTool.Category, // Map to namespace\n        Tags:      myTool.Keywords, // Map to tags\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#step-2-map-your-backend-type","title":"Step 2: Map Your Backend Type","text":"<pre><code>func convertBackend(myBackend MyBackend) model.ToolBackend {\n    switch myBackend.Type {\n    case \"mcp\":\n        return model.NewMCPBackend(myBackend.ServerName)\n    case \"local\":\n        return model.NewLocalBackend(myBackend.HandlerName)\n    case \"external\":\n        return model.NewProviderBackend(myBackend.Provider, myBackend.ID)\n    default:\n        return model.NewMCPBackend(\"default\")\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#step-3-migrate-registration","title":"Step 3: Migrate Registration","text":"<pre><code>// Create index\nidx := index.NewInMemoryIndex()\n\n// Migrate existing tools\nfor _, myTool := range myRegistry.GetAllTools() {\n    tool := convertTool(myTool)\n    backend := convertBackend(myTool.Backend)\n\n    if err := idx.RegisterTool(tool, backend); err != nil {\n        log.Printf(\"Failed to migrate %s: %v\", myTool.Name, err)\n        continue\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#step-4-migrate-search","title":"Step 4: Migrate Search","text":"<pre><code>// Before (custom registry)\nresults := myRegistry.Search(query)\n\n// After\nsummaries, _ := idx.Search(query, 100)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#step-5-add-documentation-optional","title":"Step 5: Add Documentation (Optional)","text":"<pre><code>store := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\nfor _, myTool := range myRegistry.GetAllTools() {\n    toolID := fmt.Sprintf(\"%s:%s\", myTool.Category, myTool.Name)\n\n    store.RegisterDoc(toolID, tooldoc.DocEntry{\n        Summary:  myTool.ShortHelp,\n        Notes:    myTool.LongHelp,\n        Examples: convertExamples(myTool.Examples),\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#integrating-with-existing-mcp-servers","title":"Integrating with Existing MCP Servers","text":""},{"location":"library-docs-from-repos/tooldiscovery/migration/#receiving-tools-from-mcp-server","title":"Receiving Tools from MCP Server","text":"<pre><code>// When you receive tools from an MCP server\nfunc onToolsReceived(serverName string, mcpTools []mcp.Tool) {\n    // Convert to model.Tool (which embeds mcp.Tool)\n    tools := make([]model.Tool, len(mcpTools))\n    for i, t := range mcpTools {\n        tools[i] = model.Tool{Tool: t}\n    }\n\n    // Register all tools from this server\n    if err := idx.RegisterToolsFromMCP(serverName, tools); err != nil {\n        log.Printf(\"Failed to register tools from %s: %v\", serverName, err)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#handling-server-disconnect","title":"Handling Server Disconnect","text":"<pre><code>// When an MCP server disconnects, remove its tools\nfunc onServerDisconnect(serverName string) {\n    // Get all tools and find ones from this server\n    // (You'd need to track this mapping separately)\n    for _, toolID := range toolsFromServer[serverName] {\n        idx.UnregisterBackend(toolID, model.BackendKindMCP, serverName)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#using-with-toolfoundation-v020","title":"Using with toolfoundation v0.2.0","text":"<p>tooldiscovery requires toolfoundation v0.2.0+:</p> <pre><code>go get github.com/jonwraymond/toolfoundation@v0.2.0\n</code></pre> <p>Key features from toolfoundation used by tooldiscovery: - <code>model.Tool</code> with embedded <code>mcp.Tool</code> - <code>model.ToolBackend</code> with MCP/Provider/Local variants - <code>model.NormalizeTags</code> for consistent tag handling - Backend factory functions (<code>NewMCPBackend</code>, etc.)</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#gradual-migration-strategy","title":"Gradual Migration Strategy","text":"<p>For large codebases, migrate gradually:</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#phase-1-add-tooldiscovery-alongside-existing","title":"Phase 1: Add tooldiscovery Alongside Existing","text":"<pre><code>// Keep existing registry\noldRegistry := myRegistry.New()\n\n// Add tooldiscovery\nidx := index.NewInMemoryIndex()\n\n// Sync tools to both\nfunc registerTool(tool MyTool) {\n    oldRegistry.Register(tool)\n    idx.RegisterTool(convertTool(tool), convertBackend(tool.Backend))\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#phase-2-shadow-read","title":"Phase 2: Shadow Read","text":"<pre><code>// Search both, compare results\nfunc search(query string) []MyTool {\n    oldResults := oldRegistry.Search(query)\n\n    // Shadow: also search new index\n    newResults, _ := idx.Search(query, 100)\n    logComparison(oldResults, newResults)\n\n    return oldResults // Still use old results\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#phase-3-switch-read-path","title":"Phase 3: Switch Read Path","text":"<pre><code>func search(query string) []MyTool {\n    summaries, _ := idx.Search(query, 100)\n    return convertToMyTools(summaries)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#phase-4-remove-old-registry","title":"Phase 4: Remove Old Registry","text":"<pre><code>// Only use tooldiscovery\nidx := index.NewInMemoryIndex()\n// ... registration and search ...\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#common-migration-issues","title":"Common Migration Issues","text":""},{"location":"library-docs-from-repos/tooldiscovery/migration/#tool-id-format","title":"Tool ID Format","text":"<p>tooldiscovery uses <code>namespace:name:version</code> format for tool IDs when version is set (otherwise <code>namespace:name</code>):</p> <pre><code>// Tool with namespace \"git\" and name \"status\"\ntoolID := \"git:status\"\n\n// Tool without namespace\ntoolID := \"simple_tool\"\n</code></pre> <p>Ensure your code handles both formats.</p>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#search-result-differences","title":"Search Result Differences","text":"<p>tooldiscovery's BM25 search may return different results than simple substring matching. Tune the <code>BM25Config</code> to match your expected behavior:</p> <pre><code>// For behavior closer to substring matching\nsearcher := search.NewBM25Searcher(search.BM25Config{\n    NameBoost:      5,  // Strongly prefer name matches\n    NamespaceBoost: 1,\n    TagsBoost:      1,\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/migration/#backend-selection","title":"Backend Selection","text":"<p>If you have multiple backends per tool, customize the selector:</p> <pre><code>idx := index.NewInMemoryIndex(index.IndexOptions{\n    BackendSelector: func(backends []model.ToolBackend) model.ToolBackend {\n        // Your custom logic\n        for _, b := range backends {\n            if b.Kind == model.BackendKindLocal {\n                return b // Prefer local backends\n            }\n        }\n        return backends[0]\n    },\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/","title":"Performance Tuning Guide","text":"<p>This guide covers performance characteristics and tuning options for tooldiscovery.</p>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#search-strategy-selection","title":"Search Strategy Selection","text":"<p>Choose the right search strategy based on your needs:</p> Strategy Speed Quality Dependencies Use When Lexical (built-in) Fastest Basic None Simple substring matching BM25 Fast Good Bleve Production text search Embedding Slow Best Embedder Semantic similarity needed Hybrid Medium Best Embedder Balance of speed and quality"},{"location":"library-docs-from-repos/tooldiscovery/performance/#recommendation-by-corpus-size","title":"Recommendation by Corpus Size","text":"Corpus Size Recommended Strategy Rationale &lt; 100 tools Lexical or BM25 Low overhead, fast enough 100-1000 tools BM25 Good balance of speed and quality 1000+ tools BM25 or Hybrid May benefit from semantic ranking"},{"location":"library-docs-from-repos/tooldiscovery/performance/#bm25-configuration","title":"BM25 Configuration","text":""},{"location":"library-docs-from-repos/tooldiscovery/performance/#field-boost-values","title":"Field Boost Values","text":"<p>The <code>BM25Config</code> controls how different fields affect ranking:</p> <pre><code>searcher := search.NewBM25Searcher(search.BM25Config{\n    NameBoost:      3,  // Name matches are 3x more important\n    NamespaceBoost: 2,  // Namespace matches are 2x\n    TagsBoost:      2,  // Tag matches are 2x\n})\n</code></pre> <p>Guidelines: - Higher <code>NameBoost</code> (3-5): Prefer exact tool name matches - Higher <code>TagsBoost</code> (2-3): Prefer keyword/category matches - Higher <code>NamespaceBoost</code> (2-3): Group related tools together</p>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#corpus-size-limits","title":"Corpus Size Limits","text":"<p>For very large corpora, use limits to control memory:</p> <pre><code>searcher := search.NewBM25Searcher(search.BM25Config{\n    MaxDocs:       5000,  // Limit indexed documents\n    MaxDocTextLen: 1000,  // Truncate long descriptions\n})\n</code></pre> <p>Trade-offs: - <code>MaxDocs</code>: Older documents may be excluded from search - <code>MaxDocTextLen</code>: Long descriptions truncated (may miss relevant terms)</p>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#benchmark-results","title":"Benchmark Results","text":"<p>Representative benchmarks on Apple M4 Max (run with <code>go test -bench=.</code>):</p>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#index-operations","title":"Index Operations","text":"Operation Corpus Size Time/Op Notes RegisterTool N/A ~900ns Single tool registration RegisterTool (sequential) Growing ~1.5\u03bcs With index growth GetTool 1000 ~110ns Hash map lookup ListNamespaces 1000 ~210ns Set iteration"},{"location":"library-docs-from-repos/tooldiscovery/performance/#search-operations","title":"Search Operations","text":"Operation Corpus Size Time/Op Notes Search (lexical) 1000 ~80\u03bcs Built-in searcher Search (BM25 cold) 1000 ~52ms First search, builds index Search (BM25 warm) 1000 ~580\u03bcs Cached index Search (BM25) 100 ~7\u03bcs Small corpus Search (BM25) 500 ~49\u03bcs Medium corpus Search (BM25) 2000 ~1.2ms Large corpus"},{"location":"library-docs-from-repos/tooldiscovery/performance/#semantic-operations","title":"Semantic Operations","text":"Operation Corpus Size Time/Op Notes BM25 Strategy Score 1 ~700ns Per document Embedding Strategy Score 1 ~1\u03bcs Per document (mock embedder) Hybrid Search 1000 ~1.9ms With mock embedder"},{"location":"library-docs-from-repos/tooldiscovery/performance/#documentation-operations","title":"Documentation Operations","text":"Operation Detail Level Time/Op Notes DescribeTool Summary ~250ns Minimal data DescribeTool Schema ~260ns With schema info DescribeTool Full ~250ns All details ListExamples N/A ~215ns Example retrieval"},{"location":"library-docs-from-repos/tooldiscovery/performance/#optimization-strategies","title":"Optimization Strategies","text":""},{"location":"library-docs-from-repos/tooldiscovery/performance/#1-warm-up-bm25-index","title":"1. Warm Up BM25 Index","text":"<p>The BM25 searcher builds its Bleve index on first search. Warm it up at startup:</p> <pre><code>func warmupSearcher(idx *index.InMemoryIndex) {\n    // Trigger index build with empty query\n    _, _ = idx.Search(\"\", 1)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#2-batch-tool-registration","title":"2. Batch Tool Registration","text":"<p>Use <code>RegisterTools</code> for batch registration instead of individual calls:</p> <pre><code>// Slower: individual registrations\nfor _, tool := range tools {\n    idx.RegisterTool(tool, backend)\n}\n\n// Faster: batch registration\nregs := make([]index.ToolRegistration, len(tools))\nfor i, tool := range tools {\n    regs[i] = index.ToolRegistration{Tool: tool, Backend: backend}\n}\nidx.RegisterTools(regs)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#3-cache-embeddings","title":"3. Cache Embeddings","text":"<p>For hybrid search, cache embeddings to avoid repeated API calls:</p> <pre><code>type CachedEmbedder struct {\n    embedder semantic.Embedder\n    cache    sync.Map\n}\n\nfunc (e *CachedEmbedder) Embed(ctx context.Context, text string) ([]float32, error) {\n    if vec, ok := e.cache.Load(text); ok {\n        return vec.([]float32), nil\n    }\n    vec, err := e.embedder.Embed(ctx, text)\n    if err != nil {\n        return nil, err\n    }\n    e.cache.Store(text, vec)\n    return vec, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#4-use-progressive-disclosure","title":"4. Use Progressive Disclosure","text":"<p>Fetch only the detail level you need:</p> <pre><code>// For search result display - use Summary (cheapest)\nfor _, r := range results {\n    summary, _ := store.DescribeTool(r.ID, tooldoc.DetailSummary)\n    displayResult(summary.Summary)\n}\n\n// Only fetch Full when user selects a tool\nfull, _ := store.DescribeTool(selectedID, tooldoc.DetailFull)\ndisplayFullDoc(full)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#5-limit-search-results","title":"5. Limit Search Results","text":"<p>Always specify a reasonable limit:</p> <pre><code>// Good: limited results\nresults, _ := idx.Search(query, 10)\n\n// Bad: potentially returns entire corpus\nresults, _ := idx.Search(query, 1000000)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#6-use-pagination-for-large-result-sets","title":"6. Use Pagination for Large Result Sets","text":"<pre><code>var allResults []index.Summary\ncursor := \"\"\n\nfor {\n    page, nextCursor, err := idx.SearchPage(query, 50, cursor)\n    if err != nil {\n        break\n    }\n    allResults = append(allResults, page...)\n    if nextCursor == \"\" {\n        break\n    }\n    cursor = nextCursor\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#memory-considerations","title":"Memory Considerations","text":""},{"location":"library-docs-from-repos/tooldiscovery/performance/#index-memory-usage","title":"Index Memory Usage","text":"<p>Approximate memory per tool: - <code>InMemoryIndex</code>: ~500 bytes (tool metadata + search doc) - <code>BM25Searcher</code>: +200-500 bytes (Bleve index entry) - <code>tooldoc.InMemoryStore</code>: +100-500 bytes (documentation)</p> <p>Estimate: ~1KB per tool with full documentation</p>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#search-doc-caching","title":"Search Doc Caching","text":"<p>The index caches search documents. This is rebuilt when: - New tools are registered - Tools are updated - Backends are removed - <code>Refresh()</code> is called</p> <p>Force a refresh if you need immediate consistency:</p> <pre><code>idx.Refresh() // Rebuilds search doc cache\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#profiling","title":"Profiling","text":"<p>Use Go's built-in profiling to identify bottlenecks:</p> <pre><code>import _ \"net/http/pprof\"\n\nfunc main() {\n    go func() {\n        log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n    }()\n    // ... your code ...\n}\n</code></pre> <p>Then profile with:</p> <pre><code># CPU profile\ngo tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n\n# Memory profile\ngo tool pprof http://localhost:6060/debug/pprof/heap\n\n# Goroutine profile\ngo tool pprof http://localhost:6060/debug/pprof/goroutine\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/performance/#running-benchmarks","title":"Running Benchmarks","text":"<pre><code># Run all benchmarks\ngo test ./... -bench=. -benchmem\n\n# Run specific package benchmarks\ngo test ./index -bench=. -benchmem\ngo test ./search -bench=. -benchmem\ngo test ./semantic -bench=. -benchmem\n\n# Run with longer duration for stable results\ngo test ./... -bench=. -benchtime=5s\n\n# Save baseline for comparison\ngo test ./... -bench=. &gt; benchmark_baseline.txt\n\n# Compare after changes\ngo test ./... -bench=. &gt; benchmark_new.txt\nbenchstat benchmark_baseline.txt benchmark_new.txt\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/","title":"registry","text":"<p>High-level helpers for building MCP servers with tool discovery, registration, local execution, and MCP backend aggregation. The registry composes:</p> <ul> <li><code>toolfoundation/model</code> (tool schema + validation)</li> <li><code>tooldiscovery/index</code> (registry + lookup)</li> <li><code>tooldiscovery/search</code> (BM25 search)</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#goals","title":"Goals","text":"<ul> <li>Provide a fast path to a working MCP server.</li> <li>Keep tool discovery and tool execution in a single, minimal API.</li> <li>Support local tools and federated MCP backends.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#package-overview","title":"Package Overview","text":"<pre><code>registry/\n\u251c\u2500\u2500 registry.go   # Core Registry type and lifecycle\n\u251c\u2500\u2500 handler.go    # Local tool handler and registration helpers\n\u251c\u2500\u2500 backend.go    # MCP backend connections\n\u251c\u2500\u2500 mcp.go        # MCP JSON-RPC request/response handling\n\u251c\u2500\u2500 server.go     # ServeStdio, ServeHTTP, ServeSSE\n\u2514\u2500\u2500 errors.go     # Sentinel errors + MCP error codes\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#core-types","title":"Core Types","text":"<pre><code>// Config configures a Registry.\ntype Config struct {\n    SearchConfig    *search.BM25Config\n    ServerInfo      ServerInfo\n    BackendSelector index.BackendSelector\n}\n\n// ServerInfo describes this MCP server for initialize response.\ntype ServerInfo struct {\n    Name    string\n    Version string\n}\n\n// Registry is a high-level MCP tool registry.\ntype Registry struct { /* ... */ }\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#local-tools","title":"Local Tools","text":"<pre><code>reg := registry.New(registry.Config{\n    ServerInfo: registry.ServerInfo{\n        Name:    \"my-mcp\",\n        Version: \"1.0.0\",\n    },\n})\n\nreg.RegisterLocalFunc(\n    \"echo\",\n    \"Echoes back input\",\n    map[string]any{\n        \"type\": \"object\",\n        \"properties\": map[string]any{\n            \"message\": map[string]any{\"type\": \"string\"},\n        },\n        \"required\": []string{\"message\"},\n    },\n    func(ctx context.Context, args map[string]any) (any, error) {\n        return map[string]any{\"echo\": args[\"message\"]}, nil\n    },\n    registry.WithNamespace(\"utility\"),\n    registry.WithTags(\"echo\", \"debug\"),\n)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#mcp-backends","title":"MCP Backends","text":"<p>Backends allow the registry to aggregate tools from other MCP servers.</p> <pre><code>err := reg.RegisterMCP(registry.BackendConfig{\n    Name: \"remote-tools\",\n    URL:  \"https://example.com/mcp\",\n    Headers: map[string]string{\n        \"Authorization\": \"Bearer ...\",\n    },\n})\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#backendconfig","title":"BackendConfig","text":"<pre><code>type BackendConfig struct {\n    Name          string\n    URL           string\n    Headers       map[string]string\n    MaxRetries    int\n    RetryInterval time.Duration\n    Transport     mcp.Transport // optional override\n}\n</code></pre> <ul> <li><code>URL</code> supports <code>http(s)://</code> (streamable HTTP), <code>sse://</code> (legacy SSE), and   <code>stdio://</code> (stdio transport bound to the current process).</li> <li><code>Headers</code> are injected into HTTP requests.</li> <li><code>Transport</code> is useful for tests or custom transports (e.g. in-memory).</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#execution","title":"Execution","text":"<pre><code>result, err := reg.Execute(ctx, \"utility:echo\", map[string]any{\"message\": \"hi\"})\n</code></pre> <p>Execution routing:</p> <ol> <li>Tool lookup in <code>index</code></li> <li>Backend selection via <code>BackendSelector</code></li> <li>Local handler or MCP backend call</li> </ol>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#result-mapping","title":"Result Mapping","text":"<p>When calling an MCP backend:</p> <ul> <li><code>StructuredContent</code> is returned when available</li> <li>single <code>TextContent</code> returns a string</li> <li>otherwise, the full <code>[]mcp.Content</code> is returned</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#mcp-protocol-handling","title":"MCP Protocol Handling","text":"<p>The registry handles MCP JSON-RPC methods:</p> <ul> <li><code>initialize</code></li> <li><code>tools/list</code></li> <li><code>tools/call</code></li> </ul> <p>These are exposed via <code>ServeStdio</code>, <code>ServeHTTP</code>, or <code>ServeSSE</code>.</p>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#transports","title":"Transports","text":"<pre><code>// Stdio\n_ = registry.ServeStdio(ctx, reg)\n\n// HTTP (streamable)\nhttp.Handle(\"/mcp\", registry.ServeHTTP(reg))\n\n// SSE (legacy)\nhttp.Handle(\"/mcp-sse\", registry.ServeSSE(reg))\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#lifecycle","title":"Lifecycle","text":"<pre><code>if err := reg.Start(ctx); err != nil {\n    log.Fatal(err)\n}\ndefer reg.Stop()\n</code></pre> <ul> <li><code>Start</code> connects registered MCP backends and registers their tools</li> <li><code>Stop</code> closes backend sessions</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#errors","title":"Errors","text":"<p>Registry returns sentinel errors from <code>errors.go</code>:</p> <ul> <li><code>ErrNotStarted</code></li> <li><code>ErrAlreadyStarted</code></li> <li><code>ErrToolNotFound</code></li> <li><code>ErrBackendNotFound</code></li> <li><code>ErrHandlerNotFound</code></li> <li><code>ErrExecutionFailed</code></li> <li><code>ErrInvalidRequest</code></li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/registry/#diagram","title":"Diagram","text":"<pre><code>flowchart LR\n    Local[\"Local handlers\"] --&gt; Registry\n    MCP[\"MCP backends\"] --&gt; Registry\n    Registry --&gt; Index\n    Index --&gt; Search\n    Registry --&gt;|ServeStdio / ServeHTTP / ServeSSE| Transports</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/","title":"Schemas and Data Contracts","text":"<p>tooldiscovery does not define new JSON Schemas for tool input/output. Those come from toolfoundation/model.Tool and are treated as opaque, validated payloads. What tooldiscovery does define are the data contracts that shape discovery, documentation, and search outputs.</p> <p>This page documents those contracts, their constraints, and how they relate to the underlying tool schemas.</p>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#canonical-tool-schema-dependency","title":"Canonical tool schema dependency","text":"<ul> <li><code>model.Tool</code> is the canonical tool record (from toolfoundation).</li> <li><code>InputSchema</code> is required; <code>OutputSchema</code> is optional.</li> <li>tooldiscovery never mutates schemas \u2014 it passes them through for   describe or execution flows.</li> </ul> <p>If you need the JSON Schema contracts, see the toolfoundation schema docs.</p>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#summary-schema-indexsummary","title":"Summary schema (index.Summary)","text":"<p><code>Summary</code> is the minimal discovery payload returned from search and list calls.</p> <p>Fields:</p> Field Type Notes <code>id</code> string Canonical tool ID (<code>namespace:name:version</code>, <code>namespace:name</code>, or <code>name</code>) <code>name</code> string Tool name <code>namespace</code> string Optional namespace <code>shortDescription</code> string Truncated to 120 chars <code>summary</code> string Short summary (mirrors shortDescription) <code>category</code> string Optional category label <code>inputModes</code> []string Supported input media types <code>outputModes</code> []string Supported output media types <code>securitySummary</code> string Short auth scheme summary <code>tags</code> []string Normalized tags <p>Constraints:</p> <ul> <li><code>shortDescription</code> is capped by <code>index.MaxShortDescriptionLen</code> (120).</li> <li><code>summary</code> mirrors the shortDescription payload for search results.</li> <li><code>inputModes</code>, <code>outputModes</code>, and <code>securitySummary</code> are derived from tool metadata.</li> <li><code>tags</code> are normalized and deduplicated by the index.</li> <li><code>Summary</code> never includes schemas.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#searchdoc-schema-indexsearchdoc","title":"SearchDoc schema (index.SearchDoc)","text":"<p><code>SearchDoc</code> is the internal/searcher payload used to score results.</p> <p>Fields:</p> Field Type Notes <code>ID</code> string Canonical tool ID <code>DocText</code> string Lowercased concatenation of name, namespace, description, summary, category, modes, tags <code>Summary</code> Summary Prebuilt summary returned to callers <p>Contracts:</p> <ul> <li><code>DocText</code> must be deterministic for the same tool.</li> <li><code>SearchDoc</code> is read-only for searchers; mutating it is forbidden.</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#documentation-schema-tooldoctooldoc","title":"Documentation schema (tooldoc.ToolDoc)","text":"<p><code>ToolDoc</code> is the progressive documentation payload returned by <code>tooldoc.Store</code>.</p> <p>Fields:</p> Field Type Notes <code>tool</code> *model.Tool Present for <code>schema</code>/<code>full</code> levels <code>summary</code> string Capped at 200 chars <code>inputModes</code> []string Supported input media types <code>outputModes</code> []string Supported output media types <code>securitySummary</code> string Short auth scheme summary <code>annotations</code> map[string]any Tool annotations for UI hints <code>schemaInfo</code> *SchemaInfo Derived from input schema <code>notes</code> string Capped at 2000 chars <code>examples</code> []ToolExample Optional usage examples <code>externalRefs</code> []string URLs or resource IDs"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#schemainfo","title":"SchemaInfo","text":"<p>Derived from a tool\u2019s InputSchema (best effort):</p> Field Type Notes <code>required</code> []string Required parameter names <code>defaults</code> map[string]any Default values <code>types</code> map[string][]string Allowed types by param"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#toolexample","title":"ToolExample","text":"<p>Usage examples are bounded to prevent context bloat:</p> <ul> <li><code>Description</code> max 300 chars</li> <li><code>ResultHint</code> max 200 chars</li> <li><code>Args</code> capped at depth 5 and size 50 (keys + items)</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#detail-levels-tooldocdetaillevel","title":"Detail levels (tooldoc.DetailLevel)","text":"Level Contents <code>summary</code> Summary only <code>schema</code> Summary + tool + schema info <code>full</code> Schema + notes + examples + external refs"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#discovery-results-discoveryresult","title":"Discovery results (discovery.Result)","text":"<p>The discovery facade wraps summaries with scoring metadata:</p> Field Type Notes <code>summary</code> Summary Tool metadata <code>score</code> float64 Relevance score <code>scoreType</code> string <code>bm25</code>, <code>embedding</code>, or <code>hybrid</code>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#semantic-document-contract-semanticdocument","title":"Semantic document contract (semantic.Document)","text":"<p>Semantic search operates on normalized <code>Document</code> payloads:</p> Field Type Notes <code>id</code> string Canonical tool ID <code>namespace</code> string Optional <code>name</code> string Tool name <code>description</code> string Short description <code>tags</code> []string Lowercased + sorted <code>category</code> string Optional category <code>text</code> string Normalized search text <p><code>Document.Normalized()</code> lowercases and sorts tags and builds <code>text</code>.</p>"},{"location":"library-docs-from-repos/tooldiscovery/schemas/#json-schema-guidance","title":"JSON Schema guidance","text":"<p>For JSON Schema input/output contract details, reference:</p> <ul> <li>toolfoundation schema docs</li> <li><code>model.Tool</code> in toolfoundation/model</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/","title":"tooldiscovery User Journey","text":""},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#overview","title":"Overview","text":"<p>This guide walks through the progressive disclosure pattern that tooldiscovery enables: discover cheaply, inspect on-demand, then execute.</p>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#1-installation","title":"1. Installation","text":"<pre><code>go get github.com/jonwraymond/tooldiscovery@latest\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#2-set-up-the-index","title":"2. Set Up the Index","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/index\"\n\n// Create an in-memory index\nidx := index.NewInMemoryIndex()\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#3-register-tools","title":"3. Register Tools","text":"<pre><code>import \"github.com/jonwraymond/toolfoundation/model\"\n\n// Create and validate a tool\ntool := model.Tool{\n  Namespace: \"github\",\n  Tool: mcp.Tool{\n    Name:        \"create_issue\",\n    Description: \"Create a new GitHub issue\",\n    InputSchema: map[string]any{...},\n  },\n}\n\n// Define the backend\nbackend := model.ToolBackend{\n  Kind:       model.BackendKindMCP,\n  ServerName: \"github-mcp\",\n}\n\n// Register\nerr := idx.RegisterTool(tool, backend)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#4-search-for-tools-token-cheap","title":"4. Search for Tools (Token-Cheap)","text":"<pre><code>// Search returns summaries without schemas\nsummaries, err := idx.Search(\"create issue\", 5)\nif err != nil {\n  log.Fatal(err)\n}\n\nfor _, s := range summaries {\n  fmt.Printf(\"Found: %s - %s\\n\", s.ID, s.Summary)\n}\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#5-get-full-documentation-on-demand","title":"5. Get Full Documentation (On-Demand)","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n\nstore := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n// Progressive detail levels\ndoc, _ := store.GetDoc(\"github:create_issue\", tooldoc.DetailSummary)\nfmt.Println(doc.Summary)\n\ndoc, _ = store.GetDoc(\"github:create_issue\", tooldoc.DetailSchema)\nfmt.Printf(\"Input Schema: %v\\n\", doc.Tool.InputSchema)\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#detail-level-guidance","title":"Detail Level Guidance","text":"<ul> <li>Summary: listing/search results (token-cheap)</li> <li>Schema: just-in-time execution</li> <li>Full: documentation view or export</li> </ul>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#6-enable-bm25-search-optional","title":"6. Enable BM25 Search (Optional)","text":"<pre><code>import \"github.com/jonwraymond/tooldiscovery/search\"\n\n// Create BM25 searcher with custom config\nconfig := search.Config{\n  NameBoost:      4.0,\n  NamespaceBoost: 2.0,\n  TagBoost:       1.0,\n}\n\nsearcher, err := search.NewBM25Searcher(config)\nif err != nil {\n  log.Fatal(err)\n}\ndefer searcher.Close()\n\n// Create index with BM25 strategy\nidx := index.NewInMemoryIndex(index.WithSearchStrategy(searcher))\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#7-list-namespaces","title":"7. List Namespaces","text":"<pre><code>namespaces := idx.ListNamespaces()\n// [\"github\", \"slack\", \"jira\", ...]\n\n// Filter tools by namespace\ntools := idx.ListToolsInNamespace(\"github\")\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#progressive-disclosure-flow","title":"Progressive Disclosure Flow","text":"<pre><code>Agent                    MCP Server              tooldiscovery\n  |                          |                        |\n  |-- search_tools(\"issue\") -|                        |\n  |                          |-- idx.Search() --------|\n  |                          |&lt;-- []Summary ----------|\n  |&lt;- summaries (no schema) -|                        |\n  |                          |                        |\n  |-- describe_tool(id) -----|                        |\n  |                          |-- store.GetDoc() -----|\n  |                          |&lt;-- ToolDoc w/schema ---|\n  |&lt;-- full schema ----------|                        |\n  |                          |                        |\n  |-- run_tool(id, args) ----|                        |\n  |                          |      (to toolexec)     |\n</code></pre>"},{"location":"library-docs-from-repos/tooldiscovery/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Execute tools with toolexec/run</li> <li>Expose via MCP with metatools-mcp</li> </ul>"},{"location":"library-docs-from-repos/toolexec/","title":"toolexec","text":"<p>Execution layer providing tool running, code orchestration, and runtime isolation for the ApertureStack tool framework.</p>"},{"location":"library-docs-from-repos/toolexec/#packages","title":"Packages","text":"Package Purpose <code>exec</code> Unified facade - combines discovery + execution into single API <code>run</code> Core tool execution engine with validation <code>code</code> Code-based tool orchestration for sandboxed execution <code>runtime</code> Sandbox and runtime isolation with security profiles <code>backend</code> Backend registry and resolution"},{"location":"library-docs-from-repos/toolexec/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolexec@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/#quick-start","title":"Quick Start","text":""},{"location":"library-docs-from-repos/toolexec/#using-the-unified-facade-recommended","title":"Using the Unified Facade (Recommended)","text":"<pre><code>import (\n    \"github.com/jonwraymond/toolexec/exec\"\n    \"github.com/jonwraymond/tooldiscovery/index\"\n    \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n)\n\n// Setup discovery infrastructure\nidx := index.NewInMemoryIndex()\ndocs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n// Create executor with local handlers\nexecutor, err := exec.New(exec.Options{\n    Index: idx,\n    Docs:  docs,\n    LocalHandlers: map[string]exec.Handler{\n        \"math-add\": func(ctx context.Context, args map[string]any) (any, error) {\n            a, b := args[\"a\"].(float64), args[\"b\"].(float64)\n            return a + b, nil\n        },\n    },\n})\n\n// Execute a tool\nresult, err := executor.RunTool(ctx, \"math:add\", map[string]any{\"a\": 5, \"b\": 3})\nfmt.Println(result.Value) // 8\n\n// Search for tools\nresults, _ := executor.SearchTools(ctx, \"calculator\", 10)\n\n// Chain tools together\nchainResult, steps, _ := executor.RunChain(ctx, []exec.Step{\n    {ToolID: \"text:format\", Args: map[string]any{\"text\": \"hello\", \"style\": \"upper\"}},\n    {ToolID: \"text:analyze\", Args: map[string]any{}, UsePrevious: true},\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/#using-the-run-package-directly","title":"Using the Run Package Directly","text":"<pre><code>import \"github.com/jonwraymond/toolexec/run\"\n\n// Create runner with index\nrunner := run.NewRunner(run.WithIndex(idx))\n\n// Execute a tool\nresult, err := runner.Run(ctx, \"github:create_issue\", map[string]any{\n    \"owner\": \"jonwraymond\",\n    \"repo\":  \"toolexec\",\n    \"title\": \"New issue\",\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/#register-a-local-backend","title":"Register a Local Backend","text":"<pre><code>import \"github.com/jonwraymond/toolexec/backend/local\"\n\nbackend := local.New(\"math\")\nbackend.RegisterHandler(\"add\", local.ToolDef{\n    Name:        \"add\",\n    Description: \"Adds two numbers\",\n    Handler: func(ctx context.Context, args map[string]any) (any, error) {\n        a, b := args[\"a\"].(float64), args[\"b\"].(float64)\n        return a + b, nil\n    },\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/#key-features","title":"Key Features","text":"<ul> <li>Unified Facade: Single API for discovery, execution, and documentation</li> <li>Schema Validation: Input and output validated against tool schemas</li> <li>Backend Abstraction: Execute local, provider, or MCP server backends</li> <li>Tool Chaining: Chain multiple tool calls with <code>UsePrevious</code> result passing</li> <li>Security Profiles: Dev, Standard, and Hardened isolation levels</li> <li>Runtime Isolation: Sandbox untrusted code with Docker, containerd, Kubernetes, gVisor, Kata, Firecracker, WASM, remote, or Proxmox LXC backends</li> <li>Integration Boundary: Concrete runtime SDK clients live in <code>toolexec-integrations</code> and are injected into core backends via interfaces</li> </ul>"},{"location":"library-docs-from-repos/toolexec/#examples","title":"Examples","text":"<p>See examples for runnable walkthroughs.</p>"},{"location":"library-docs-from-repos/toolexec/#links","title":"Links","text":"<ul> <li>Architecture</li> <li>Schemas and contracts</li> <li>Design notes</li> <li>User journey</li> <li>ai-tools-stack documentation</li> </ul>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/","title":"toolexec Architecture Improvement Plan","text":"<p>\u2705 COMPLETED: This plan was fully implemented on 2026-02-01. All phases completed: exec/ facade, examples, example tests, coverage improvements, documentation. See CHANGELOG.md for details.</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#executive-summary","title":"Executive Summary","text":"<p>Architectural review and improvement plan for the toolexec submodule, focusing on better integration with toolfoundation and tooldiscovery, comprehensive examples, and coverage improvements.</p> <p>Current State: 18 packages, 62-94% coverage Dependencies: toolfoundation v0.2.0, tooldiscovery v0.2.1</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#1-current-architecture-overview","title":"1. Current Architecture Overview","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#package-dependency-graph","title":"Package Dependency Graph","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         EXTERNAL DEPENDENCIES                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  toolfoundation                    tooldiscovery                     \u2502\n\u2502  \u251c\u2500\u2500 model.Tool                    \u251c\u2500\u2500 index.Index                   \u2502\n\u2502  \u251c\u2500\u2500 model.ToolBackend             \u251c\u2500\u2500 search.BM25Searcher           \u2502\n\u2502  \u2514\u2500\u2500 model.SchemaValidator         \u2514\u2500\u2500 tooldoc.Store                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           toolexec                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502   \u2502   backend/   \u2502      \u2502     run/     \u2502      \u2502    code/     \u2502      \u2502\n\u2502   \u2502              \u2502      \u2502              \u2502      \u2502              \u2502      \u2502\n\u2502   \u2502 \u2022 Backend    \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2502 \u2022 Runner     \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2502 \u2022 Executor   \u2502      \u2502\n\u2502   \u2502 \u2022 Registry   \u2502      \u2502 \u2022 dispatch   \u2502      \u2502 \u2022 Engine     \u2502      \u2502\n\u2502   \u2502 \u2022 Aggregator \u2502      \u2502 \u2022 resolve    \u2502      \u2502 \u2022 Tools      \u2502      \u2502\n\u2502   \u2502 \u2022 local/     \u2502      \u2502 \u2022 normalize  \u2502      \u2502 \u2022 Config     \u2502      \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502          \u2502                     \u2502                     \u2502               \u2502\n\u2502          \u2502                     \u2502                     \u25bc               \u2502\n\u2502          \u2502                     \u2502            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502          \u2502                     \u2502            \u2502   runtime/   \u2502         \u2502\n\u2502          \u2502                     \u2502            \u2502              \u2502         \u2502\n\u2502          \u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 \u2022 Runtime    \u2502         \u2502\n\u2502          \u2502                                  \u2502 \u2022 Backend    \u2502         \u2502\n\u2502          \u2502                                  \u2502 \u2022 Gateway    \u2502         \u2502\n\u2502          \u2502                                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502          \u2502                                         \u2502                 \u2502\n\u2502          \u2502                                         \u25bc                 \u2502\n\u2502          \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502          \u2502              \u2502         runtime/backend/               \u2502   \u2502\n\u2502          \u2502              \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2502          \u2502              \u2502 unsafe \u2502 docker \u2502 wasm \u2502 gvisor \u2502 ...  \u2502   \u2502\n\u2502          \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502          \u2502                                         \u2502                 \u2502\n\u2502          \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502          \u2502              \u2502         runtime/gateway/               \u2502   \u2502\n\u2502          \u2502              \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u2502\n\u2502          \u2502              \u2502         direct    \u2502    proxy           \u2502   \u2502\n\u2502          \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502          \u2502                                                           \u2502\n\u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\n\u2502                                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#execution-flow","title":"Execution Flow","text":"<pre><code>User Code Request\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 code.Executor   \u2502 \u2500\u2500 Orchestrates execution with limits\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 code.Engine     \u2502 \u2500\u2500 Pluggable language runtime (Go, Python, etc.)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 runtime/toolcodeengine      \u2502 \u2500\u2500 Adapter: code.Engine \u2192 runtime.Backend\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 runtime.Runtime \u2502 \u2500\u2500 Routes by security profile\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510\n    \u25bc         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502unsafe \u2502 \u2502docker \u2502 ... (10 backend implementations)\n\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n    \u2502         \u2502\n    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 runtime.Gateway \u2502 \u2500\u2500 Tool access from sandbox\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 run.Runner      \u2502 \u2500\u2500 Tool execution pipeline\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u25bc         \u25bc        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  MCP  \u2502 \u2502Provider\u2502 \u2502 Local \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#2-identified-gaps","title":"2. Identified Gaps","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#21-coverage-gaps","title":"2.1 Coverage Gaps","text":"Package Current Target Gap Analysis <code>backend/</code> 67.0% 90%+ Registry lifecycle, concurrent access <code>backend/local/</code> 62.9% 90%+ Handler edge cases, error paths <code>code/</code> 72.6% 90%+ Limit enforcement, timeout handling <code>runtime/gateway/proxy/</code> 68.4% 85%+ Connection failures, codec errors <code>run/</code> ~75% 90%+ Chain execution, streaming"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#22-documentation-gaps","title":"2.2 Documentation Gaps","text":"Gap Severity Description Empty examples/ High No runnable examples showing integration Missing architecture doc High No high-level overview of package relationships Interface contracts Medium Some contracts lack error semantics Migration guide Low No guide from direct usage to facades"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#23-integration-gaps","title":"2.3 Integration Gaps","text":"Gap Description No unified facade Users must understand 4+ packages to use toolexec Bridge patterns unclear How tooldiscovery \u2192 toolexec \u2192 runtime flows Backend selection logic No documented strategy for profile \u2192 backend mapping"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#3-improvement-plan","title":"3. Improvement Plan","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#phase-1-unified-facade-package-new","title":"Phase 1: Unified Facade Package (NEW)","text":"<p>Create a <code>toolexec/exec</code> package that provides a simplified entry point.</p> <pre><code>// exec/exec.go - Unified facade for tool execution\n\npackage exec\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/tooldiscovery/index\"\n    \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n    \"github.com/jonwraymond/toolexec/run\"\n    \"github.com/jonwraymond/toolexec/code\"\n    \"github.com/jonwraymond/toolexec/runtime\"\n)\n\n// Exec is the unified facade for tool execution.\n// It combines discovery, execution, and runtime management.\ntype Exec struct {\n    index   index.Index\n    docs    tooldoc.Store\n    runner  run.Runner\n    runtime runtime.Runtime\n    code    code.Executor\n}\n\n// Options configures an Exec instance.\ntype Options struct {\n    // Index provides tool discovery. Required.\n    Index index.Index\n\n    // Docs provides tool documentation. Required.\n    Docs tooldoc.Store\n\n    // SecurityProfile determines the runtime backend.\n    // Default: ProfileDev\n    SecurityProfile runtime.SecurityProfile\n\n    // EnableCodeExecution enables the code execution subsystem.\n    // Default: false (tool execution only)\n    EnableCodeExecution bool\n\n    // MaxToolCalls limits tool calls in code execution.\n    // Default: 100\n    MaxToolCalls int\n\n    // DefaultLanguage for code execution.\n    // Default: \"go\"\n    DefaultLanguage string\n}\n\n// New creates a new Exec instance.\nfunc New(opts Options) (*Exec, error)\n\n// RunTool executes a single tool by ID.\nfunc (e *Exec) RunTool(ctx context.Context, toolID string, args map[string]any) (Result, error)\n\n// RunChain executes a sequence of tools.\nfunc (e *Exec) RunChain(ctx context.Context, steps []Step) (Result, []StepResult, error)\n\n// ExecuteCode runs code with tool access.\nfunc (e *Exec) ExecuteCode(ctx context.Context, params CodeParams) (CodeResult, error)\n\n// SearchTools finds tools matching a query.\nfunc (e *Exec) SearchTools(ctx context.Context, query string, limit int) ([]ToolSummary, error)\n\n// GetToolDoc retrieves tool documentation.\nfunc (e *Exec) GetToolDoc(ctx context.Context, toolID string, level tooldoc.DetailLevel) (tooldoc.ToolDoc, error)\n</code></pre> <p>Files to create: - <code>exec/exec.go</code> - Main facade - <code>exec/result.go</code> - Unified result types - <code>exec/options.go</code> - Configuration and validation - <code>exec/exec_test.go</code> - Comprehensive tests - <code>exec/example_test.go</code> - pkg.go.dev examples - <code>exec/doc.go</code> - Package documentation</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#phase-2-comprehensive-examples","title":"Phase 2: Comprehensive Examples","text":"<p>Create runnable examples showing the full integration:</p> <pre><code>examples/\n\u251c\u2500\u2500 basic/\n\u2502   \u2514\u2500\u2500 main.go           # Simple tool execution\n\u251c\u2500\u2500 chain/\n\u2502   \u2514\u2500\u2500 main.go           # Sequential tool chaining\n\u251c\u2500\u2500 code/\n\u2502   \u2514\u2500\u2500 main.go           # Code execution with tool access\n\u251c\u2500\u2500 discovery/\n\u2502   \u2514\u2500\u2500 main.go           # Search \u2192 Execute workflow\n\u251c\u2500\u2500 streaming/\n\u2502   \u2514\u2500\u2500 main.go           # Streaming tool execution\n\u251c\u2500\u2500 runtime/\n\u2502   \u2514\u2500\u2500 main.go           # Custom runtime configuration\n\u2514\u2500\u2500 full/\n    \u2514\u2500\u2500 main.go           # Complete integration example\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#examplesbasicmaingo","title":"examples/basic/main.go","text":"<pre><code>// Demonstrates basic tool execution with toolexec.\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"github.com/jonwraymond/tooldiscovery/index\"\n    \"github.com/jonwraymond/tooldiscovery/search\"\n    \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n    \"github.com/jonwraymond/toolexec/exec\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n    \"github.com/modelcontextprotocol/go-sdk/mcp\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    // 1. Setup tool discovery (from tooldiscovery)\n    idx := index.NewInMemoryIndex(index.IndexOptions{\n        Searcher: search.NewBM25Searcher(search.BM25Config{\n            NameBoost: 3,\n            TagsBoost: 2,\n        }),\n    })\n    docs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n    // 2. Register a sample tool\n    tool := model.Tool{\n        Tool: mcp.Tool{\n            Name:        \"greet\",\n            Description: \"Greets a user by name\",\n            InputSchema: map[string]any{\n                \"type\": \"object\",\n                \"properties\": map[string]any{\n                    \"name\": map[string]any{\"type\": \"string\"},\n                },\n                \"required\": []any{\"name\"},\n            },\n        },\n        Namespace: \"demo\",\n    }\n\n    // Register with local handler\n    if err := idx.RegisterTool(tool, model.NewLocalBackend(\"greet-handler\")); err != nil {\n        log.Fatal(err)\n    }\n\n    // Add documentation\n    docs.RegisterDoc(\"demo:greet\", tooldoc.DocEntry{\n        Summary: \"Greets a user with a friendly message\",\n        Notes:   \"Returns a greeting string\",\n        Examples: []tooldoc.ToolExample{\n            {Title: \"Basic greeting\", Args: map[string]any{\"name\": \"World\"}},\n        },\n    })\n\n    // 3. Create executor with unified facade\n    executor, err := exec.New(exec.Options{\n        Index: idx,\n        Docs:  docs,\n        LocalHandlers: map[string]exec.Handler{\n            \"greet-handler\": func(ctx context.Context, args map[string]any) (any, error) {\n                name := args[\"name\"].(string)\n                return fmt.Sprintf(\"Hello, %s!\", name), nil\n            },\n        },\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // 4. Execute the tool\n    result, err := executor.RunTool(ctx, \"demo:greet\", map[string]any{\"name\": \"World\"})\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    fmt.Printf(\"Result: %v\\n\", result.Value)\n    // Output: Result: Hello, World!\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#examplesdiscoverymaingo","title":"examples/discovery/main.go","text":"<pre><code>// Demonstrates search \u2192 execute workflow combining tooldiscovery and toolexec.\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"github.com/jonwraymond/tooldiscovery/discovery\"\n    \"github.com/jonwraymond/toolexec/exec\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    // 1. Create discovery facade (from tooldiscovery)\n    disc, err := discovery.New(discovery.Options{})\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // 2. Register tools (simplified)\n    registerDemoTools(disc)\n\n    // 3. Create executor using discovery's index\n    executor, err := exec.New(exec.Options{\n        Index: disc.Index(),\n        Docs:  disc.DocStore(),\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // 4. Search for tools\n    results, err := disc.Search(ctx, \"file operations\", 5)\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    fmt.Printf(\"Found %d tools:\\n\", len(results))\n    for _, r := range results {\n        fmt.Printf(\"  - %s (score: %.2f)\\n\", r.Summary.ID, r.Score)\n    }\n\n    // 5. Execute the top result\n    if len(results) &gt; 0 {\n        topTool := results[0].Summary.ID\n        result, err := executor.RunTool(ctx, topTool, map[string]any{\n            \"path\": \"/tmp/example.txt\",\n        })\n        if err != nil {\n            log.Printf(\"Execution failed: %v\", err)\n            return\n        }\n        fmt.Printf(\"Executed %s: %v\\n\", topTool, result.Value)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#examplesfullmaingo","title":"examples/full/main.go","text":"<pre><code>// Complete integration example showing all layers working together.\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"time\"\n\n    // Foundation layer\n    \"github.com/jonwraymond/toolfoundation/model\"\n\n    // Discovery layer\n    \"github.com/jonwraymond/tooldiscovery/discovery\"\n    \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n\n    // Execution layer\n    \"github.com/jonwraymond/toolexec/exec\"\n    \"github.com/jonwraymond/toolexec/runtime\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // LAYER 1: Foundation (toolfoundation)\n    // Define tool types and schemas\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    tools := []struct {\n        tool    model.Tool\n        backend model.ToolBackend\n        doc     tooldoc.DocEntry\n        handler exec.Handler\n    }{\n        {\n            tool: model.Tool{\n                Tool: mcp.Tool{\n                    Name:        \"calculate\",\n                    Description: \"Performs basic arithmetic\",\n                    InputSchema: calculateSchema(),\n                },\n                Namespace: \"math\",\n                Tags:      []string{\"math\", \"calculator\"},\n            },\n            backend: model.NewLocalBackend(\"calc-handler\"),\n            doc: tooldoc.DocEntry{\n                Summary: \"Basic arithmetic operations\",\n                Notes:   \"Supports add, subtract, multiply, divide\",\n            },\n            handler: calculateHandler,\n        },\n        // ... more tools\n    }\n\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // LAYER 2: Discovery (tooldiscovery)\n    // Register and search for tools\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    disc, _ := discovery.New(discovery.Options{})\n\n    for _, t := range tools {\n        disc.RegisterTool(t.tool, t.backend, &amp;t.doc)\n    }\n\n    // Search demonstration\n    results, _ := disc.Search(ctx, \"arithmetic\", 10)\n    fmt.Printf(\"Discovery found %d tools for 'arithmetic'\\n\", len(results))\n\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // LAYER 3: Execution (toolexec)\n    // Execute tools with proper runtime management\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    handlers := make(map[string]exec.Handler)\n    for _, t := range tools {\n        handlers[t.backend.Local.Name] = t.handler\n    }\n\n    executor, _ := exec.New(exec.Options{\n        Index:           disc.Index(),\n        Docs:            disc.DocStore(),\n        LocalHandlers:   handlers,\n        SecurityProfile: runtime.ProfileDev,\n\n        // Code execution settings\n        EnableCodeExecution: true,\n        MaxToolCalls:        50,\n        DefaultLanguage:     \"go\",\n        DefaultTimeout:      30 * time.Second,\n    })\n\n    // Single tool execution\n    result, _ := executor.RunTool(ctx, \"math:calculate\", map[string]any{\n        \"operation\": \"add\",\n        \"a\":         10,\n        \"b\":         20,\n    })\n    fmt.Printf(\"10 + 20 = %v\\n\", result.Value)\n\n    // Chain execution\n    chainResult, steps, _ := executor.RunChain(ctx, []exec.Step{\n        {ToolID: \"math:calculate\", Args: map[string]any{\"operation\": \"add\", \"a\": 5, \"b\": 3}},\n        {ToolID: \"math:calculate\", Args: map[string]any{\"operation\": \"multiply\", \"a\": 0, \"b\": 2}, UsePrevious: true},\n    })\n    fmt.Printf(\"Chain result: %v (steps: %d)\\n\", chainResult.Value, len(steps))\n\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // LAYER 4: Code Execution (with tool access)\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    codeResult, _ := executor.ExecuteCode(ctx, exec.CodeParams{\n        Language: \"go\",\n        Code: `\n            // This code runs in a sandbox with tool access\n            result, _ := tools.Run(\"math:calculate\", map[string]any{\n                \"operation\": \"add\",\n                \"a\": 100,\n                \"b\": 200,\n            })\n            return result\n        `,\n        Timeout: 10 * time.Second,\n    })\n    fmt.Printf(\"Code execution result: %v\\n\", codeResult.Value)\n    fmt.Printf(\"Tool calls made: %d\\n\", len(codeResult.ToolCalls))\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#phase-3-example-tests-pkggodev","title":"Phase 3: Example Tests (pkg.go.dev)","text":"<p>Create example tests for each core package:</p> <p>Files to create: - <code>run/example_test.go</code> - Runner examples - <code>code/example_test.go</code> - Executor examples - <code>backend/example_test.go</code> - Backend/registry examples - <code>runtime/example_test.go</code> - Runtime examples - <code>exec/example_test.go</code> - Unified facade examples</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#phase-4-coverage-improvements","title":"Phase 4: Coverage Improvements","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#backend-67-90","title":"backend/ (67% \u2192 90%+)","text":"<p>Add tests for: - Registry concurrent access - Backend lifecycle (Start/Stop) - Aggregator with multiple backends - Error paths (backend unavailable, tool not found)</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#backendlocal-629-90","title":"backend/local/ (62.9% \u2192 90%+)","text":"<p>Add tests for: - Handler registration/unregistration - Concurrent handler execution - Panic recovery in handlers - Context cancellation</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#code-726-90","title":"code/ (72.6% \u2192 90%+)","text":"<p>Add tests for: - MaxToolCalls enforcement - MaxChainSteps enforcement - Timeout handling - Engine error propagation</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#runtimegatewayproxy-684-85","title":"runtime/gateway/proxy/ (68.4% \u2192 85%+)","text":"<p>Add tests for: - Connection failures - Codec errors - Timeout scenarios - Large payload handling</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#phase-5-documentation","title":"Phase 5: Documentation","text":"<p>Files to create: - <code>docs/architecture.md</code> - Package hierarchy and data flow - <code>docs/integration.md</code> - How to integrate with tooldiscovery - <code>docs/security-profiles.md</code> - Runtime security configuration - <code>docs/error-handling.md</code> - Error types and handling patterns - <code>docs/migration.md</code> - Upgrading from direct package usage</p>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#4-integration-patterns","title":"4. Integration Patterns","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#pattern-1-discovery-execution","title":"Pattern 1: Discovery \u2192 Execution","text":"<pre><code>// Search for tools, then execute\ndisc, _ := discovery.New(discovery.Options{})\nexec, _ := exec.New(exec.Options{Index: disc.Index(), Docs: disc.DocStore()})\n\nresults, _ := disc.Search(ctx, \"query\", 10)\nfor _, r := range results {\n    result, _ := exec.RunTool(ctx, r.Summary.ID, args)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#pattern-2-code-with-tool-access","title":"Pattern 2: Code with Tool Access","text":"<pre><code>// Execute code that can call tools\nexec, _ := exec.New(exec.Options{\n    Index: idx,\n    Docs:  docs,\n    EnableCodeExecution: true,\n})\n\nresult, _ := exec.ExecuteCode(ctx, exec.CodeParams{\n    Code: `tools.Run(\"ns:tool\", args)`,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#pattern-3-chain-execution","title":"Pattern 3: Chain Execution","text":"<pre><code>// Execute tools in sequence\nresult, steps, _ := exec.RunChain(ctx, []exec.Step{\n    {ToolID: \"ns:tool1\", Args: args1},\n    {ToolID: \"ns:tool2\", UsePrevious: true}, // Uses tool1's result\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#pattern-4-custom-runtime","title":"Pattern 4: Custom Runtime","text":"<pre><code>// Configure specific backend for security\nexec, _ := exec.New(exec.Options{\n    Index:           idx,\n    Docs:            docs,\n    SecurityProfile: runtime.ProfileHardened,\n    RuntimeBackends: map[runtime.SecurityProfile]runtime.Backend{\n        runtime.ProfileHardened: gvisor.NewBackend(gvisor.Config{}),\n    },\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#5-file-summary","title":"5. File Summary","text":"Phase File Action Est. Lines 1 <code>exec/exec.go</code> Create ~200 1 <code>exec/result.go</code> Create ~80 1 <code>exec/options.go</code> Create ~100 1 <code>exec/exec_test.go</code> Create ~400 1 <code>exec/example_test.go</code> Create ~150 1 <code>exec/doc.go</code> Create ~50 2 <code>examples/basic/main.go</code> Create ~80 2 <code>examples/chain/main.go</code> Create ~100 2 <code>examples/code/main.go</code> Create ~120 2 <code>examples/discovery/main.go</code> Create ~100 2 <code>examples/streaming/main.go</code> Create ~100 2 <code>examples/runtime/main.go</code> Create ~120 2 <code>examples/full/main.go</code> Create ~200 3 <code>run/example_test.go</code> Create ~100 3 <code>code/example_test.go</code> Create ~100 3 <code>backend/example_test.go</code> Create ~80 3 <code>runtime/example_test.go</code> Create ~100 4 <code>backend/backend_test.go</code> Expand ~150 4 <code>backend/local/local_test.go</code> Expand ~150 4 <code>code/executor_test.go</code> Expand ~200 4 <code>runtime/gateway/proxy/*_test.go</code> Expand ~150 5 <code>docs/architecture.md</code> Create ~200 5 <code>docs/integration.md</code> Create ~150 5 <code>docs/security-profiles.md</code> Create ~100 5 <code>docs/error-handling.md</code> Create ~150"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#6-verification","title":"6. Verification","text":""},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#unit-tests","title":"Unit Tests","text":"<pre><code>go test ./... -v -race -cover\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#coverage-target","title":"Coverage Target","text":"<pre><code>go test ./... -coverprofile=cover.out\ngo tool cover -func=cover.out | grep total\n# Target: 85%+ overall\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#example-execution","title":"Example Execution","text":"<pre><code>go run examples/basic/main.go\ngo run examples/full/main.go\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/ARCHITECTURE_PLAN/#7-implementation-order","title":"7. Implementation Order","text":"<ol> <li>Phase 1: exec/ facade - Unified entry point (enables Phase 2)</li> <li>Phase 2: examples/ - Runnable integration examples</li> <li>Phase 3: example_test.go - pkg.go.dev documentation</li> <li>Phase 4: coverage - Test gap closure</li> <li>Phase 5: docs/ - Written documentation</li> </ol> <p>Each phase can be committed independently and provides incremental value.</p>"},{"location":"library-docs-from-repos/toolexec/architecture/","title":"Architecture Overview","text":"<p>toolexec is the execution layer for MCP-style tools. It focuses on running validated tools across different backends and isolating untrusted code with configurable runtimes.</p>"},{"location":"library-docs-from-repos/toolexec/architecture/#core-packages","title":"Core Packages","text":"Package Responsibility <code>exec</code> Unified facade that composes discovery + execution + docs <code>run</code> Execution pipeline with validation + chaining <code>backend</code> Backend registry and resolution <code>runtime</code> Sandbox runtimes and security profiles <code>code</code> Orchestration of code with tool access"},{"location":"library-docs-from-repos/toolexec/architecture/#execution-flow","title":"Execution Flow","text":"<ol> <li>Resolve tool definition and backend binding</li> <li>Validate input against JSON Schema</li> <li>Execute tool on backend (local, provider, MCP)</li> <li>Normalize results into structured output</li> <li>Validate output (if OutputSchema present)</li> </ol>"},{"location":"library-docs-from-repos/toolexec/architecture/#chaining","title":"Chaining","text":"<p>Chains execute sequentially. If <code>UsePrevious</code> is true, the prior step\u2019s structured result is injected into <code>args[\"previous\"]</code> for the next step.</p>"},{"location":"library-docs-from-repos/toolexec/architecture/#runtime-isolation","title":"Runtime Isolation","text":"<p>The <code>runtime</code> package provides isolation levels via security profiles:</p> <ul> <li>Dev: local / unsafe execution with explicit opt\u2011in</li> <li>Standard: container or sandbox runtime</li> <li>Hardened: strongest isolation (Docker/gVisor/WASM)</li> </ul> <p>Concrete runtime SDK clients (Kubernetes, Proxmox, remote HTTP) live in <code>toolexec-integrations</code> and are injected into the core backends via interfaces.</p>"},{"location":"library-docs-from-repos/toolexec/architecture/#observability","title":"Observability","text":"<p>Execution surfaces timing and tool call metadata in <code>exec.Result</code> and <code>run.RunResult</code>, enabling tracing and audits in higher layers.</p>"},{"location":"library-docs-from-repos/toolexec/architecture/#related-docs","title":"Related Docs","text":"<ul> <li>Schemas and Contracts</li> <li>Design Notes</li> <li>User Journey</li> </ul>"},{"location":"library-docs-from-repos/toolexec/design-notes/","title":"toolexec Design Notes","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#overview","title":"Overview","text":"<p>toolexec provides the execution layer for the ApertureStack tool framework. It handles tool execution, code orchestration, and runtime isolation.</p>"},{"location":"library-docs-from-repos/toolexec/design-notes/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          exec                                \u2502\n\u2502              (Unified Facade - Single Entry Point)          \u2502\n\u2502  SearchTools, RunTool, RunChain, GetToolDoc                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          v               v               v\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  index   \u2502   \u2502     run      \u2502  \u2502 tooldoc  \u2502\n    \u2502(discover)\u2502   \u2502  (execute)   \u2502  \u2502  (docs)  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          v\n                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                   \u2502   backend    \u2502\n                   \u2502  (registry)  \u2502\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          v               v               v\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  local   \u2502   \u2502     mcp      \u2502  \u2502 provider \u2502\n    \u2502 handlers \u2502   \u2502   servers    \u2502  \u2502   APIs   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/design-notes/#exec-package-unified-facade","title":"exec Package (Unified Facade)","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#design-decisions","title":"Design Decisions","text":"<ol> <li> <p>Single Entry Point: The <code>exec.Exec</code> type provides a unified API combining    discovery (search, describe) with execution (run, chain). Users don't need    to understand multiple packages for basic operations.</p> </li> <li> <p>Options Pattern: Configuration via <code>exec.Options</code> allows:</p> </li> <li>Custom index and doc store</li> <li>Local handler registration via map</li> <li>MCP and provider executors</li> <li>Input/output validation toggles</li> <li> <p>Security profile selection</p> </li> <li> <p>Result Types: Consistent <code>Result</code> and <code>StepResult</code> types wrap lower-level    <code>run.RunResult</code> with additional context (toolID, duration, error).</p> </li> <li> <p>Handler Function: Simple <code>func(ctx, args) (any, error)</code> signature for    local tool handlers, avoiding the need to understand backend interfaces.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolexec/design-notes/#run-package","title":"run Package","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#design-decisions_1","title":"Design Decisions","text":"<ol> <li>Execution Pipeline: Every tool call follows a strict pipeline:</li> <li>Validate tool ID format</li> <li>Validate input against schema</li> <li>Resolve tool definition from index</li> <li>Select and invoke backend</li> <li>Normalize result</li> <li> <p>Validate output against schema</p> </li> <li> <p>Backend Abstraction: The runner doesn't care how tools are executed.    It delegates to the backend registry which supports local, provider, and    MCP server backends.</p> </li> <li> <p>Result Normalization: All backends return results in a consistent    <code>RunResult</code> format with output, error, duration, and metadata.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolexec/design-notes/#error-handling","title":"Error Handling","text":"<ul> <li>Input validation errors include the failing field and constraint</li> <li>Backend errors are wrapped with context</li> <li>Output validation errors are warnings (logged but not fatal)</li> </ul>"},{"location":"library-docs-from-repos/toolexec/design-notes/#code-package","title":"code Package","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#design-decisions_2","title":"Design Decisions","text":"<ol> <li> <p>DSL for Orchestration: Provides a simple DSL for chaining tool calls    with variable binding and conditional logic.</p> </li> <li> <p>Runner Integration: Delegates actual tool execution to the <code>run</code>    package, ensuring consistent validation and error handling.</p> </li> <li> <p>Runtime Integration: Code execution can be isolated by wiring a    <code>runtime.Runtime</code> via the <code>runtime/toolcodeengine</code> adapter.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolexec/design-notes/#runtime-package","title":"runtime Package","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#design-decisions_3","title":"Design Decisions","text":"<ol> <li> <p>Runtime Interface: Abstracts sandbox implementations behind a common    interface supporting Execute and Cleanup operations.</p> </li> <li> <p>Security Profiles:</p> </li> <li><code>ProfileDev</code>: Unsafe host execution (development only)</li> <li><code>ProfileStandard</code>: Container-based isolation</li> <li> <p><code>ProfileHardened</code>: Maximum isolation (seccomp + VM/VM-like backends)</p> </li> <li> <p>Resource Limits: Configurable CPU, memory, and timeout limits for    sandboxed execution.</p> </li> <li>Gateway Requirement: Every execution request must include a    <code>ToolGateway</code> to broker tool discovery/execution for sandboxed code.</li> </ol>"},{"location":"library-docs-from-repos/toolexec/design-notes/#supported-runtimes","title":"Supported Runtimes","text":"Runtime Isolation Performance Use Case Unsafe host None Fast Trusted/dev Docker Container Medium Production WASM Sandbox Varies Edge/browser"},{"location":"library-docs-from-repos/toolexec/design-notes/#runtime-backend-matrix","title":"Runtime Backend Matrix","text":"<p>Readiness tiers: - prod: production-ready - beta: usable, still evolving - stub: placeholder or incomplete</p> <p>Concrete runtime clients (Kubernetes, Proxmox, remote HTTP) live in <code>toolexec-integrations</code> and are injected into <code>toolexec</code> core backends via interfaces (<code>PodRunner</code>, <code>APIClient</code>, <code>RemoteClient</code>). This keeps the core dependency-light while integrations remain opt-in.</p> BackendKind Readiness Isolation Requirements Notes <code>BackendUnsafeHost</code> prod None Go toolchain (subprocess mode) Dev-only, explicit opt-in supported <code>BackendDocker</code> prod Container Docker daemon + ContainerRunner Standard isolation <code>BackendContainerd</code> beta Container containerd client Infrastructure-native <code>BackendKubernetes</code> beta Pod/Job <code>toolexec-integrations/kubernetes</code> + kubeconfig Cluster execution <code>BackendGVisor</code> beta Sandbox gVisor/runsc (<code>io.containerd.runsc.v1</code>) Stronger isolation <code>BackendKata</code> beta VM Kata runtime (<code>io.containerd.kata.v2</code>) VM-level isolation <code>BackendFirecracker</code> beta MicroVM Firecracker runtime (<code>aws.firecracker</code>) Strongest isolation <code>BackendWASM</code> beta Sandbox wazero In-process WASM <code>BackendTemporal</code> stub Workflow Temporal client Orchestrated execution <code>BackendRemote</code> beta Remote <code>toolexec-integrations/remotehttp</code> External runtime with signed requests <code>BackendProxmoxLXC</code> beta Container <code>toolexec-integrations/proxmox</code> + runtime client LXC-backed runtime service"},{"location":"library-docs-from-repos/toolexec/design-notes/#toolcode-runtime-contract","title":"Toolcode \u2194 Runtime Contract","text":"<p>The <code>code</code> package uses the <code>runtime/toolcodeengine</code> adapter to bridge code execution with runtime backends. The adapter maps <code>code.ExecuteParams</code> to <code>runtime.ExecuteRequest</code>, preserving:</p> <ul> <li>Security profile selection</li> <li>Resource limits (timeouts, tool-call/chain limits)</li> <li>ToolGateway injection for tool discovery/execution</li> </ul>"},{"location":"library-docs-from-repos/toolexec/design-notes/#backend-package","title":"backend Package","text":""},{"location":"library-docs-from-repos/toolexec/design-notes/#design-decisions_4","title":"Design Decisions","text":"<ol> <li> <p>Backend Registry: Central registry for all backend implementations,    enabling runtime backend selection.</p> </li> <li> <p>Backend Kinds:</p> </li> <li><code>local</code>: In-process Go function</li> <li><code>provider</code>: External tool provider via HTTP/gRPC</li> <li> <p><code>mcp</code>: Remote MCP server via JSON-RPC</p> </li> <li> <p>Lazy Resolution: Backends are resolved at execution time, allowing    dynamic registration and configuration.</p> </li> </ol>"},{"location":"library-docs-from-repos/toolexec/design-notes/#dependencies","title":"Dependencies","text":"<ul> <li><code>github.com/jonwraymond/toolfoundation/model</code> - Tool definitions</li> <li><code>github.com/jonwraymond/tooldiscovery/index</code> - Tool resolution</li> <li><code>github.com/tetratelabs/wazero</code> - WASM runtime (optional)</li> </ul>"},{"location":"library-docs-from-repos/toolexec/design-notes/#links","title":"Links","text":"<ul> <li>index</li> <li>user journey</li> </ul>"},{"location":"library-docs-from-repos/toolexec/examples/","title":"Examples","text":"<p>toolexec ships with runnable examples that cover execution, chaining, streaming, discovery integration, and runtime isolation.</p>"},{"location":"library-docs-from-repos/toolexec/examples/#basic-execution","title":"Basic execution","text":"<pre><code>go run ./examples/basic\n</code></pre> <p>Shows: - Local backend registration - Input validation and execution - Structured results</p>"},{"location":"library-docs-from-repos/toolexec/examples/#tool-chaining","title":"Tool chaining","text":"<pre><code>go run ./examples/chain\n</code></pre> <p>Shows: - Sequential chains - <code>UsePrevious</code> argument injection - Step results and errors</p>"},{"location":"library-docs-from-repos/toolexec/examples/#discovery-execution","title":"Discovery + execution","text":"<pre><code>go run ./examples/discovery\n</code></pre> <p>Shows: - Index + docs store integration - Search + execute via <code>exec</code> facade</p>"},{"location":"library-docs-from-repos/toolexec/examples/#streaming","title":"Streaming","text":"<pre><code>go run ./examples/streaming\n</code></pre> <p>Shows: - Streaming events from execution - Progress + chunk envelopes</p>"},{"location":"library-docs-from-repos/toolexec/examples/#runtime-isolation","title":"Runtime isolation","text":"<pre><code>go run ./examples/runtime\n</code></pre> <p>Shows: - Security profiles - Runtime selection (unsafe / docker / wasm)</p>"},{"location":"library-docs-from-repos/toolexec/examples/#full-integration","title":"Full integration","text":"<pre><code>go run ./examples/full\n</code></pre> <p>Shows: - End-to-end setup with discovery + exec + runtime</p>"},{"location":"library-docs-from-repos/toolexec/schemas/","title":"Schemas and Contracts","text":"<p>toolexec relies on toolfoundation/model.Tool as the canonical tool schema. It does not introduce new input/output JSON Schema formats; instead it executes tools and validates against the schemas defined on each <code>model.Tool</code>.</p> <p>This page documents: - The canonical tool schema fields and constraints (summary) - Input/Output schema requirements as enforced by the runner - JSON Schema dialect support and limitations - Execution payload contracts (RunResult, StreamEvent, ChainStep) - Runtime execution results (ExecuteResult, BackendInfo) - Recommended schema patterns</p> <p>For full schema details, see toolfoundation\u2019s schema docs.</p>"},{"location":"library-docs-from-repos/toolexec/schemas/#tool-schema-fieldsconstraints-summary","title":"Tool schema fields/constraints (summary)","text":"<p><code>model.Tool</code> embeds the MCP SDK <code>mcp.Tool</code> and adds stack extensions.</p>"},{"location":"library-docs-from-repos/toolexec/schemas/#core-mcp-fields","title":"Core MCP fields","text":"Field Required Notes <code>name</code> Yes 1\u2013128 chars, <code>[A-Za-z0-9_.-]</code> only <code>description</code> No Human-readable description <code>inputSchema</code> Yes JSON Schema object for tool parameters <code>outputSchema</code> No JSON Schema object for structured output <code>title</code> No Display label <code>annotations</code> No Hints (readOnly, idempotent, destructive, openWorld) <code>_meta</code> No Arbitrary metadata <code>icons</code> No Optional icon assets"},{"location":"library-docs-from-repos/toolexec/schemas/#extensions","title":"Extensions","text":"Field Required Notes <code>namespace</code> No Tool ID is <code>namespace:name:version</code> when version is set (otherwise <code>namespace:name</code>) <code>version</code> No SemVer (<code>v1.2.3</code> or <code>1.2.3</code>) <code>tags</code> No Normalized tags for discovery"},{"location":"library-docs-from-repos/toolexec/schemas/#inputschema-outputschema-requirements","title":"InputSchema / OutputSchema requirements","text":"<ul> <li>InputSchema is required. A tool without <code>inputSchema</code> is invalid.</li> <li>OutputSchema is optional. If omitted, output validation is skipped.</li> <li>Validation in <code>run</code> uses <code>model.SchemaValidator</code>:</li> <li>Input validation runs before execution.</li> <li>Output validation runs after execution when <code>OutputSchema</code> is present.</li> </ul>"},{"location":"library-docs-from-repos/toolexec/schemas/#supported-dialects-and-limitations","title":"Supported dialects and limitations","text":"<p>Inherited from toolfoundation:</p> <ul> <li>Default dialect: JSON Schema 2020-12 (when <code>$schema</code> is absent)</li> <li>Supported: 2020-12 and draft-07</li> <li>External <code>$ref</code> resolution is disabled (no network I/O)</li> <li><code>format</code> is treated as annotation (not enforced)</li> </ul>"},{"location":"library-docs-from-repos/toolexec/schemas/#execution-payload-contracts","title":"Execution payload contracts","text":""},{"location":"library-docs-from-repos/toolexec/schemas/#runresult-runrunresult","title":"RunResult (<code>run.RunResult</code>)","text":"<p>Normalized result of executing a tool:</p> Field Type Notes <code>tool</code> <code>model.Tool</code> Resolved tool definition <code>backend</code> <code>model.ToolBackend</code> Backend used for execution <code>structured</code> <code>any</code> Normalized result value <code>mcpResult</code> <code>*mcp.CallToolResult</code> Raw MCP result when backend is MCP"},{"location":"library-docs-from-repos/toolexec/schemas/#streamevent-runstreamevent","title":"StreamEvent (<code>run.StreamEvent</code>)","text":"<p>Transport-agnostic streaming envelope:</p> Field Type Notes <code>kind</code> string <code>progress</code>, <code>chunk</code>, <code>done</code>, <code>error</code> <code>toolId</code> string Canonical tool ID <code>data</code> any Event payload (progress/chunk details)"},{"location":"library-docs-from-repos/toolexec/schemas/#chainstep-runchainstep","title":"ChainStep (<code>run.ChainStep</code>)","text":"Field Type Notes <code>toolId</code> string Canonical tool ID <code>args</code> map Tool arguments <code>usePrevious</code> bool Inject prior result into <code>args[\"previous\"]</code>"},{"location":"library-docs-from-repos/toolexec/schemas/#executeresult-runtimeexecuteresult","title":"ExecuteResult (<code>runtime.ExecuteResult</code>)","text":"<p>Result of executing code via a runtime backend:</p> Field Type Notes <code>value</code> any Final value (from <code>__out</code> convention) <code>stdout</code> string Captured stdout <code>stderr</code> string Captured stderr <code>toolCalls</code> list Tool invocation trace <code>duration</code> duration Total execution time <code>backend</code> <code>runtime.BackendInfo</code> Backend details + readiness"},{"location":"library-docs-from-repos/toolexec/schemas/#backendinfo-runtimebackendinfo","title":"BackendInfo (<code>runtime.BackendInfo</code>)","text":"Field Type Notes <code>kind</code> string Backend kind (<code>docker</code>, <code>wasm</code>, etc.) <code>readiness</code> string <code>prod</code>, <code>beta</code>, or <code>stub</code> <code>details</code> map Backend-specific metadata"},{"location":"library-docs-from-repos/toolexec/schemas/#recommended-no-parameters-schema","title":"Recommended \u201cno parameters\u201d schema","text":"<p>Strict MCP-recommended schema:</p> <pre><code>{\n  \"type\": \"object\",\n  \"additionalProperties\": false\n}\n</code></pre> <p>Less strict variant:</p> <pre><code>{\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/schemas/#example-schema-patterns","title":"Example schema patterns","text":""},{"location":"library-docs-from-repos/toolexec/schemas/#required-string-property","title":"Required string property","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"path\": {\"type\": \"string\", \"description\": \"File path\"}\n  },\n  \"required\": [\"path\"],\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/schemas/#optional-enum-with-default","title":"Optional enum with default","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"encoding\": {\"type\": \"string\", \"enum\": [\"utf8\", \"ascii\"], \"default\": \"utf8\"}\n  },\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/schemas/#array-of-objects","title":"Array of objects","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"items\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"id\": {\"type\": \"string\"},\n          \"value\": {\"type\": \"number\"}\n        },\n        \"required\": [\"id\"],\n        \"additionalProperties\": false\n      }\n    }\n  },\n  \"additionalProperties\": false\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/schemas/#one-of-variants","title":"One-of variants","text":"<pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"mode\": {\n      \"oneOf\": [\n        {\"type\": \"string\", \"enum\": [\"fast\", \"safe\"]},\n        {\"type\": \"number\", \"minimum\": 1, \"maximum\": 10}\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/schemas/#links","title":"Links","text":"<ul> <li>Architecture</li> <li>Design notes</li> <li>User journey</li> <li>toolfoundation schemas</li> </ul>"},{"location":"library-docs-from-repos/toolexec/user-journey/","title":"toolexec User Journey","text":""},{"location":"library-docs-from-repos/toolexec/user-journey/#overview","title":"Overview","text":"<p>This guide walks through using toolexec to execute tools, from simple single-tool calls to complex orchestrated workflows.</p>"},{"location":"library-docs-from-repos/toolexec/user-journey/#1-installation","title":"1. Installation","text":"<pre><code>go get github.com/jonwraymond/toolexec@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#2-quick-start-with-the-unified-facade-recommended","title":"2. Quick Start with the Unified Facade (Recommended)","text":"<p>The <code>exec</code> package provides a unified facade combining discovery and execution:</p> <pre><code>import (\n    \"github.com/jonwraymond/toolexec/exec\"\n    \"github.com/jonwraymond/tooldiscovery/index\"\n    \"github.com/jonwraymond/tooldiscovery/tooldoc\"\n)\n\n// Setup discovery infrastructure\nidx := index.NewInMemoryIndex()\ndocs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\n\n// Create executor with local handlers\nexecutor, err := exec.New(exec.Options{\n    Index: idx,\n    Docs:  docs,\n    LocalHandlers: map[string]exec.Handler{\n        \"calculator-add\": func(ctx context.Context, args map[string]any) (any, error) {\n            a, b := args[\"a\"].(float64), args[\"b\"].(float64)\n            return a + b, nil\n        },\n    },\n})\n\n// Execute a tool\nresult, err := executor.RunTool(ctx, \"math:add\", map[string]any{\"a\": 5, \"b\": 3})\nfmt.Println(result.Value) // 8\n\n// Search for tools\nresults, _ := executor.SearchTools(ctx, \"calculator\", 10)\n\n// Get tool documentation\ndoc, _ := executor.GetToolDoc(ctx, \"math:add\", tooldoc.DetailFull)\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#3-execute-a-single-tool","title":"3. Execute a Single Tool","text":"<pre><code>result, err := executor.RunTool(ctx, \"github:create_issue\", map[string]any{\n    \"owner\": \"jonwraymond\",\n    \"repo\":  \"toolexec\",\n    \"title\": \"Bug report\",\n    \"body\":  \"Description here\",\n})\n\nif err != nil {\n    log.Fatalf(\"Execution failed: %v\", err)\n}\n\nfmt.Printf(\"Created issue: %v\\n\", result.Value)\nfmt.Printf(\"Duration: %v\\n\", result.Duration)\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#4-chain-tool-calls","title":"4. Chain Tool Calls","text":"<p>Use <code>UsePrevious</code> to pass results between steps:</p> <pre><code>result, steps, err := executor.RunChain(ctx, []exec.Step{\n    {ToolID: \"github:create_issue\", Args: map[string]any{\n        \"title\": \"Bug report\",\n    }},\n    {ToolID: \"github:add_labels\", Args: map[string]any{\n        \"labels\": []string{\"bug\"},\n    }, UsePrevious: true}, // Injects previous result as \"previous\" arg\n})\n\nfmt.Printf(\"Final result: %v\\n\", result.Value)\nfor i, step := range steps {\n    fmt.Printf(\"Step %d: %s \u2192 %v\\n\", i+1, step.ToolID, step.Value)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#5-register-local-tools","title":"5. Register Local Tools","text":"<p>Register tools using the backend/local package:</p> <pre><code>import \"github.com/jonwraymond/toolexec/backend/local\"\n\nbackend := local.New(\"calculator\")\nbackend.RegisterHandler(\"add\", local.ToolDef{\n    Name:        \"add\",\n    Description: \"Adds two numbers\",\n    InputSchema: map[string]any{\n        \"type\": \"object\",\n        \"properties\": map[string]any{\n            \"a\": map[string]any{\"type\": \"number\"},\n            \"b\": map[string]any{\"type\": \"number\"},\n        },\n    },\n    Handler: func(ctx context.Context, args map[string]any) (any, error) {\n        a, b := args[\"a\"].(float64), args[\"b\"].(float64)\n        return a + b, nil\n    },\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#6-using-the-run-package-directly-advanced","title":"6. Using the Run Package Directly (Advanced)","text":"<p>For more control, use the <code>run</code> package directly:</p> <pre><code>import \"github.com/jonwraymond/toolexec/run\"\n\nrunner := run.NewRunner(\n    run.WithIndex(idx),\n    run.WithLocalRegistry(localReg),\n    run.WithValidation(true, true),\n)\n\nresult, err := runner.Run(ctx, \"ns:tool\", args)\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#7-code-orchestration-sandboxed-execution","title":"7. Code Orchestration (Sandboxed Execution)","text":"<p>The <code>code</code> package enables executing user-provided code that can call tools:</p> <pre><code>import \"github.com/jonwraymond/toolexec/code\"\n\n// Create code executor with limits\ncodeExec := code.NewExecutor(code.Config{\n    Index:        idx,\n    Docs:         docs,\n    Run:          runner,\n    MaxToolCalls: 50,\n    Timeout:      30 * time.Second,\n})\n\nresult, err := codeExec.Execute(ctx, code.ExecuteParams{\n    Language: \"go\",\n    Code: `\n        // Access tools via the tools interface\n        result, _ := tools.RunTool(ctx, \"math:add\", map[string]any{\"a\": 1, \"b\": 2})\n        return result.Structured\n    `,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#8-runtime-isolation-security-profiles","title":"8. Runtime Isolation (Security Profiles)","text":"<p>toolexec supports three security profiles for different isolation levels:</p> Profile Isolation Use Case <code>ProfileDev</code> None Development/testing <code>ProfileStandard</code> Container Production <code>ProfileHardened</code> VM/gVisor Untrusted code <pre><code>import (\n    \"github.com/jonwraymond/toolexec/runtime\"\n    \"github.com/jonwraymond/toolexec/runtime/backend/unsafe\"\n    \"github.com/jonwraymond/toolexec/runtime/gateway/direct\"\n)\n\n// Gateway exposes tool discovery + execution to sandboxed code\ngateway := direct.New(direct.Config{\n    Index:  idx,\n    Docs:   docs,\n    Runner: runner,\n})\n\n// Runtime with security profile selection\nrt := runtime.NewDefaultRuntime(runtime.RuntimeConfig{\n    Backends: map[runtime.SecurityProfile]runtime.Backend{\n        runtime.ProfileDev: unsafe.New(unsafe.Config{RequireOptIn: true}),\n    },\n    DefaultProfile: runtime.ProfileDev,\n})\n\n// Execute code in the runtime\nresult, err := rt.Execute(ctx, runtime.ExecuteRequest{\n    Language: \"go\",\n    Code:     `__out = 1 + 1`,\n    Profile:  runtime.ProfileDev,\n    Gateway:  gateway,\n    Limits: runtime.Limits{\n        MaxToolCalls:   100,\n        MemoryBytes:    512 * 1024 * 1024, // 512MB\n        CPUQuotaMillis: 60000,             // 60s\n    },\n})\n</code></pre> <p>For container isolation, use <code>runtime/backend/docker</code> or <code>runtime/backend/containerd</code> with <code>ProfileStandard</code>.</p> <p>For maximum isolation, use <code>runtime/backend/gvisor</code>, <code>runtime/backend/kata</code>, or <code>runtime/backend/firecracker</code> with <code>ProfileHardened</code>.</p>"},{"location":"library-docs-from-repos/toolexec/user-journey/#wasm-execution-input","title":"WASM Execution Input","text":"<p>The WASM backend expects a compiled module provided via <code>ExecuteRequest.Metadata</code>:</p> <pre><code>req := runtime.ExecuteRequest{\n    Language: \"wasm\",\n    Code:     \"ignored for wasm\",\n    Gateway:  gateway,\n    Metadata: map[string]any{\n        \"wasm_module\": []byte{0x00, 0x61, 0x73, 0x6d, 0x01, 0x00, 0x00, 0x00},\n        // or \"wasm_module_b64\": \"&lt;base64-encoded module bytes&gt;\"\n    },\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#execution-flow","title":"Execution Flow","text":"<pre><code>Client              exec.Exec            run.Runner           Backend\n  |                     |                     |                    |\n  |-- RunTool(id) ------|                     |                    |\n  |                     |-- Run(id, args) ----|                    |\n  |                     |                     |-- Validate --------|\n  |                     |                     |-- Resolve ---------|\n  |                     |                     |-- Execute ---------|\n  |                     |                     |&lt;-- Result ---------|\n  |                     |&lt;-- RunResult -------|                    |\n  |&lt;-- Result ----------|                     |                    |\n</code></pre>"},{"location":"library-docs-from-repos/toolexec/user-journey/#examples","title":"Examples","text":"<p>See the examples page for runnable examples (source lives in <code>toolexec/examples/</code>):</p> <ul> <li><code>basic/</code> - Simple tool execution</li> <li><code>chain/</code> - Sequential tool chaining</li> <li><code>discovery/</code> - Search and execute workflow</li> <li><code>streaming/</code> - Streaming execution events</li> <li><code>runtime/</code> - Security profile configuration</li> <li><code>full/</code> - Complete integration example</li> </ul>"},{"location":"library-docs-from-repos/toolexec/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Add observability with toolops/observe</li> <li>Expose via MCP with metatools-mcp</li> </ul>"},{"location":"library-docs-from-repos/toolexec-integrations/","title":"toolexec-integrations","text":"<p>This repo hosts opt\u2011in runtime clients for <code>toolexec</code> backends. Core <code>toolexec</code> stays interface\u2011only; these packages supply concrete SDK integrations.</p>"},{"location":"library-docs-from-repos/toolexec-integrations/#packages","title":"Packages","text":"Package Implements Typical Use <code>kubernetes</code> <code>kubernetes.PodRunner</code>, <code>kubernetes.HealthChecker</code> Run executions in Kubernetes Jobs/Pods via client\u2011go <code>proxmox</code> <code>proxmox.APIClient</code> Control Proxmox LXC status/start/stop <code>remotehttp</code> <code>remote.RemoteClient</code> Call remote runtime service over HTTP/SSE"},{"location":"library-docs-from-repos/toolexec-integrations/#wiring-examples","title":"Wiring Examples","text":""},{"location":"library-docs-from-repos/toolexec-integrations/#kubernetes","title":"Kubernetes","text":"<pre><code>corekube := kubernetescore.New(kubernetescore.Config{\n    Namespace: \"default\",\n    Image:     \"toolruntime-sandbox:latest\",\n    Client:    kubeClient,\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec-integrations/#proxmox","title":"Proxmox","text":"<pre><code>backend := proxmoxcore.New(proxmoxcore.Config{\n    Node:                  \"pve-1\",\n    VMID:                  100,\n    Client:                proxmoxClient,\n    RuntimeClient:         runtimeClient,\n    RuntimeGatewayEndpoint:\"https://gateway.internal\",\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec-integrations/#remote-http","title":"Remote HTTP","text":"<pre><code>client, _ := remotehttp.NewClient(remotehttp.Config{\n    Endpoint:  \"https://runtime.example.com/v1/execute\",\n    AuthToken: \"...\",\n})\nbackend := remote.New(remote.Config{Client: client})\n</code></pre>"},{"location":"library-docs-from-repos/toolexec-integrations/#compatibility","title":"Compatibility","text":"<p>Use <code>ai-tools-stack</code> for the authoritative version matrix. This repo tracks those versions in <code>VERSIONS.md</code>.</p>"},{"location":"library-docs-from-repos/toolexec-integrations/architecture/","title":"Architecture","text":"<p><code>toolexec-integrations</code> provides concrete client implementations for runtime backends. The core <code>toolexec</code> module defines interfaces/specs/validation only; integrations satisfy those interfaces.</p>"},{"location":"library-docs-from-repos/toolexec-integrations/architecture/#boundary","title":"Boundary","text":"<ul> <li>Core: <code>toolexec/runtime/backend/*</code> (interfaces + validation)</li> <li>Integrations: this repo (SDKs + HTTP clients)</li> </ul> <p>A hard dependency guard in <code>toolexec</code> prevents SDKs (client\u2011go, Docker, etc.) from leaking into core.</p>"},{"location":"library-docs-from-repos/toolexec-integrations/architecture/#packages","title":"Packages","text":""},{"location":"library-docs-from-repos/toolexec-integrations/architecture/#kubernetes","title":"Kubernetes","text":"<p>Implements <code>kubernetes.PodRunner</code> and <code>kubernetes.HealthChecker</code> using client\u2011go. The client converts <code>PodSpec</code> into a Job/Pod, streams logs, and maps results back to <code>PodResult</code>.</p>"},{"location":"library-docs-from-repos/toolexec-integrations/architecture/#proxmox","title":"Proxmox","text":"<p>Implements <code>proxmox.APIClient</code> using the Proxmox HTTP API. Used by the core <code>proxmox</code> backend to start/stop LXC containers and check status.</p>"},{"location":"library-docs-from-repos/toolexec-integrations/architecture/#remote-http","title":"Remote HTTP","text":"<p>Implements <code>remote.RemoteClient</code> using HTTP + optional SSE streaming. The core <code>remote</code> backend handles timeouts and request shaping; the integration handles transport, retries, and request signing.</p>"},{"location":"library-docs-from-repos/toolexec-integrations/design-notes/","title":"Design Notes","text":""},{"location":"library-docs-from-repos/toolexec-integrations/design-notes/#why-integrations-live-separately","title":"Why Integrations Live Separately","text":"<ul> <li>Keeps <code>toolexec</code> core dependency\u2011light.</li> <li>Allows downstream users to opt into only the SDKs they need.</li> <li>Enables faster iteration on integrations without destabilizing the core.</li> </ul>"},{"location":"library-docs-from-repos/toolexec-integrations/design-notes/#interface-contracts","title":"Interface Contracts","text":"<p>Each package implements a minimal interface from <code>toolexec</code>:</p> <ul> <li><code>kubernetes.PodRunner</code></li> <li><code>proxmox.APIClient</code></li> <li><code>remote.RemoteClient</code></li> </ul> <p>Clients are required to be concurrency\u2011safe and respect <code>context.Context</code> cancellation.</p>"},{"location":"library-docs-from-repos/toolexec-integrations/design-notes/#error-handling","title":"Error Handling","text":"<p>Integrations return errors defined in core when possible (for consistent handling in the stack). Transport\u2011specific errors should be wrapped with core errors like <code>remote.ErrRemoteExecutionFailed</code> or <code>proxmox.ErrProxmoxNotAvailable</code>.</p>"},{"location":"library-docs-from-repos/toolcompose/","title":"toolcompose","text":"<p>Composition layer for building filtered tool collections and declarative skills.</p>"},{"location":"library-docs-from-repos/toolcompose/#packages","title":"Packages","text":"Package Purpose <code>set</code> Toolset composition, filtering, and exposure <code>skill</code> Declarative skill planning and execution"},{"location":"library-docs-from-repos/toolcompose/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolcompose@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/#quick-start-toolset","title":"Quick Start: Toolset","text":"<pre><code>import (\n  \"fmt\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolcompose/set\"\n  \"github.com/jonwraymond/toolfoundation/adapter\"\n)\n\ntools := []*adapter.CanonicalTool{\n  {\n    Namespace: \"github\",\n    Name:      \"create_issue\",\n    Tags:      []string{\"issues\"},\n    InputSchema: &amp;adapter.JSONSchema{Type: \"object\"},\n  },\n  {\n    Namespace: \"github\",\n    Name:      \"list_issues\",\n    Tags:      []string{\"issues\"},\n    InputSchema: &amp;adapter.JSONSchema{Type: \"object\"},\n  },\n}\n\nts, err := set.NewBuilder(\"github-issues\").\n  FromTools(tools).\n  WithNamespace(\"github\").\n  WithTags([]string{\"issues\"}).\n  WithPolicy(set.DenyTags(\"danger\")).\n  Build()\nif err != nil {\n  log.Fatal(err)\n}\n\nfmt.Println(ts.IDs())\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/#quick-start-skill","title":"Quick Start: Skill","text":"<pre><code>import (\n  \"context\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolcompose/skill\"\n  \"github.com/jonwraymond/toolexec/run\"\n)\n\n// Define a skill\nsk := skill.Skill{\n  Name: \"triage-issue\",\n  Steps: []skill.Step{\n    {ID: \"create\", ToolID: \"github:create_issue\", Inputs: map[string]any{\"title\": \"Bug\"}},\n    {ID: \"label\", ToolID: \"github:add_labels\", Inputs: map[string]any{\"labels\": []string{\"bug\"}}},\n  },\n}\n\nplan, err := skill.NewPlanner().Plan(sk)\nif err != nil {\n  log.Fatal(err)\n}\n\nrunner := run.NewRunner()\n\n// Adapt toolexec runner to skill.Runner\ntype runAdapter struct{ exec run.Runner }\nfunc (r runAdapter) Run(ctx context.Context, step skill.Step) (any, error) {\n  res, err := r.exec.Run(ctx, step.ToolID, step.Inputs)\n  if err != nil {\n    return nil, err\n  }\n  return res.Output, nil\n}\n\nctx := context.Background()\nresults, err := skill.Execute(ctx, plan, runAdapter{exec: runner})\nif err != nil {\n  log.Fatal(err)\n}\n_ = results\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/","title":"toolcompose Design Notes","text":""},{"location":"library-docs-from-repos/toolcompose/design-notes/#overview","title":"Overview","text":"<p>toolcompose provides composition primitives for the ApertureStack ecosystem:</p> <ul> <li>set: build filtered, access-controlled tool collections</li> <li>skill: declare tool-based workflows and execute them deterministically</li> </ul>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#ecosystem-position","title":"Ecosystem Position","text":"<pre><code>flowchart TB\n    subgraph Foundation[\"toolfoundation\"]\n        Model[model.Tool]\n        Adapter[adapter.CanonicalTool]\n        Backend[model.ToolBackend]\n    end\n\n    subgraph Discovery[\"tooldiscovery\"]\n        Index[index.Index]\n        Search[search.BM25Searcher]\n        Docs[tooldoc.Store]\n    end\n\n    subgraph Exec[\"toolexec\"]\n        Runner[run.Runner]\n        Code[code.Executor]\n        Runtime[runtime.Sandbox]\n    end\n\n    subgraph Compose[\"toolcompose\"]\n        Set[set.Toolset]\n        Skill[skill.Skill]\n        Exposure[set.Exposure]\n    end\n\n    Model --&gt; Adapter\n    Adapter --&gt; Set\n    Index --&gt; Set\n    Set --&gt; Exposure\n    Runner --&gt; Skill\n    Exposure --&gt; Code</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#dependency-flow","title":"Dependency Flow","text":"Package Depends On Provides To toolfoundation - All packages (core types) tooldiscovery toolfoundation toolcompose (registry source) toolexec toolfoundation, tooldiscovery toolcompose (Runner impl) toolcompose toolfoundation End users (composition API)"},{"location":"library-docs-from-repos/toolcompose/design-notes/#set-package","title":"set Package","text":""},{"location":"library-docs-from-repos/toolcompose/design-notes/#design-decisions","title":"Design Decisions","text":"<ol> <li>Thread-safe Toolset: Toolsets wrap a map with RW locks for safe concurrent access.</li> <li>Deterministic Ordering: <code>IDs()</code> and <code>Tools()</code> return lexicographically sorted results.</li> <li>Pure Composition: No I/O or execution; callers supply tools as input.</li> <li>Filter + Policy: Filters reduce candidates; policies enforce access rules.</li> <li>Export via Adapters: <code>Exposure</code> converts toolsets to protocol-specific shapes.</li> </ol>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#filter-policy-semantics","title":"Filter + Policy Semantics","text":"<ul> <li>Filters are AND-composed in builder order.</li> <li>Policies run after filters.</li> <li><code>nil</code> tools are always rejected.</li> </ul> <pre><code>flowchart LR\n    Source[Canonical Tools] --&gt; Filters\n    Filters --&gt; Policy\n    Policy --&gt; Toolset\n    Toolset --&gt; Exposure</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#thread-safety-model","title":"Thread Safety Model","text":"Type Safe For Notes <code>Toolset</code> Concurrent reads Uses <code>sync.RWMutex</code> <code>Builder</code> Single goroutine Configure, then call <code>Build()</code> once <code>Exposure</code> Concurrent reads After construction only <code>FilterFunc</code> Must be thread-safe If Toolset is shared"},{"location":"library-docs-from-repos/toolcompose/design-notes/#error-handling","title":"Error Handling","text":"<p>Sentinel errors enable programmatic handling:</p> <pre><code>ts, err := builder.Build()\nif errors.Is(err, set.ErrNoSource) {\n    // No tools provided - call FromTools or FromRegistry\n}\nif errors.Is(err, set.ErrNilAdapter) {\n    // Adapter is nil in Exposure\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#skill-package","title":"skill Package","text":""},{"location":"library-docs-from-repos/toolcompose/design-notes/#design-decisions_1","title":"Design Decisions","text":"<ol> <li>Declarative Skills: Skills are lightweight definitions of steps.</li> <li>Deterministic Planning: Planner sorts steps by ID to guarantee stable execution order.</li> <li>Runner Interface: Execution delegates to a <code>Runner</code> for tool integration.</li> <li>Guards: Optional validation hooks (max steps, allowed tool IDs).</li> <li>Fail-fast Execution: Execution stops on the first step error.</li> </ol> <pre><code>flowchart LR\n    Skill --&gt; Planner\n    Planner --&gt; Plan\n    Plan --&gt; Execute\n    Execute --&gt; Runner</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#execution-model","title":"Execution Model","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Planner\n    participant Execute\n    participant Guard\n    participant Runner\n\n    User-&gt;&gt;Planner: Plan(skill)\n    Planner-&gt;&gt;Planner: Validate skill\n    Planner-&gt;&gt;Planner: Apply guards\n    Planner--&gt;&gt;User: Plan\n\n    User-&gt;&gt;Execute: Execute(ctx, plan, runner)\n    loop Each Step\n        Execute-&gt;&gt;Runner: Run(ctx, toolID, inputs)\n        Runner--&gt;&gt;Execute: Result\n        alt Error\n            Execute--&gt;&gt;User: Partial results + error\n        end\n    end\n    Execute--&gt;&gt;User: All results</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#guard-contract","title":"Guard Contract","text":"<p>Guards must be: - Idempotent: Same skill \u2192 same result - Pure: No side effects during <code>Check()</code> - Thread-safe: If planner is shared</p>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#thread-safety-model_1","title":"Thread Safety Model","text":"Type Safe For Notes <code>Planner</code> Concurrent use Stateless after construction <code>Plan</code> Concurrent reads Immutable after creation <code>Runner</code> Implementation-dependent Check implementation docs <code>Guard</code> Must be thread-safe If Planner is shared"},{"location":"library-docs-from-repos/toolcompose/design-notes/#error-handling_1","title":"Error Handling","text":"<p>Sentinel errors for programmatic handling:</p> <pre><code>plan, err := planner.Plan(skill)\nif errors.Is(err, skill.ErrNoSteps) {\n    // Skill has no steps defined\n}\nif errors.Is(err, skill.ErrMaxStepsExceeded) {\n    // MaxStepsGuard rejected the skill\n}\nif errors.Is(err, skill.ErrToolNotAllowed) {\n    // AllowedToolIDsGuard rejected a tool\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#trade-offs","title":"Trade-offs","text":"Decision Benefit Cost No implicit parallelism Deterministic, easy to reason about Sequential execution only Explicit runner adapter No hard dependency on execution engine Requires integration work Binary policy Simple allow/deny semantics Rich policies need wrappers Fail-fast execution Errors surface immediately No partial recovery Deterministic ordering Reproducible results Sorting overhead"},{"location":"library-docs-from-repos/toolcompose/design-notes/#integration-patterns","title":"Integration Patterns","text":""},{"location":"library-docs-from-repos/toolcompose/design-notes/#with-tooldiscovery","title":"With tooldiscovery","text":"<pre><code>// Build toolset from registry\nts, err := set.NewBuilder(\"github-tools\").\n    FromRegistry(registry).\n    WithNamespace(\"github\").\n    Build()\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#with-toolexec","title":"With toolexec","text":"<pre><code>// Execute skill with toolexec runner\nrunner := exec.NewRunner(executor)\nplanner := skill.NewPlanner(skill.PlannerOptions{Runner: runner})\nplan, _ := planner.Plan(mySkill)\nresults, _ := skill.Execute(ctx, plan, runner)\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/design-notes/#protocol-export","title":"Protocol Export","text":"<pre><code>// Export for MCP server\nexposure := set.NewExposure(ts, adapter.NewMCPAdapter())\ntools, warnings, errs := exposure.ExportWithWarnings()\nfor _, w := range warnings {\n    log.Printf(\"Feature %s lost converting %s \u2192 %s\",\n        w.Feature, w.FromAdapter, w.ToAdapter)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/","title":"toolcompose User Journey","text":""},{"location":"library-docs-from-repos/toolcompose/user-journey/#1-installation","title":"1. Installation","text":"<pre><code>go get github.com/jonwraymond/toolcompose@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#2-build-a-toolset","title":"2. Build a Toolset","text":"<pre><code>import (\n  \"fmt\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolcompose/set\"\n  \"github.com/jonwraymond/toolfoundation/adapter\"\n)\n\ntools := []*adapter.CanonicalTool{\n  {Namespace: \"github\", Name: \"create_issue\", Tags: []string{\"issues\"}, InputSchema: &amp;adapter.JSONSchema{Type: \"object\"}},\n  {Namespace: \"github\", Name: \"add_labels\", Tags: []string{\"issues\"}, InputSchema: &amp;adapter.JSONSchema{Type: \"object\"}},\n  {Namespace: \"slack\", Name: \"post_message\", Tags: []string{\"chat\"}, InputSchema: &amp;adapter.JSONSchema{Type: \"object\"}},\n}\n\nts, err := set.NewBuilder(\"issue-workflow\").\n  FromTools(tools).\n  WithNamespace(\"github\").\n  WithTags([]string{\"issues\"}).\n  WithPolicy(set.DenyTags(\"danger\")).\n  Build()\nif err != nil {\n  log.Fatal(err)\n}\n\nfmt.Println(\"Toolset IDs:\", ts.IDs())\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#3-filter-an-existing-toolset","title":"3. Filter an Existing Toolset","text":"<pre><code>filtered := ts.Filter(set.TagsAny(\"issues\"))\nfmt.Println(filtered.IDs())\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#4-export-toolsets","title":"4. Export Toolsets","text":"<pre><code>import (\n  \"log\"\n\n  \"github.com/jonwraymond/toolfoundation/adapter/mcp\"\n)\n\nexposure := set.NewExposure(ts, mcp.NewAdapter())\ntools, warnings, errs := exposure.ExportWithWarnings()\n\nif len(errs) &gt; 0 {\n  log.Printf(\"conversion errors: %v\", errs)\n}\n_ = warnings\n_ = tools\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#5-define-a-skill","title":"5. Define a Skill","text":"<pre><code>import \"github.com/jonwraymond/toolcompose/skill\"\n\nsk := skill.Skill{\n  Name: \"triage-issue\",\n  Steps: []skill.Step{\n    {ID: \"create\", ToolID: \"github:create_issue\", Inputs: map[string]any{\"title\": \"Bug\"}},\n    {ID: \"label\", ToolID: \"github:add_labels\", Inputs: map[string]any{\"labels\": []string{\"bug\"}}},\n  },\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#6-plan-guard","title":"6. Plan + Guard","text":"<pre><code>planner := skill.NewPlanner()\nplan, err := planner.Plan(sk)\nif err != nil {\n  log.Fatal(err)\n}\n\nguard := skill.MaxStepsGuard(5)\nif err := guard.Validate(sk); err != nil {\n  log.Fatal(err)\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#7-execute-via-toolexec","title":"7. Execute via toolexec","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolcompose/skill\"\n  \"github.com/jonwraymond/toolexec/run\"\n)\n\ntype runAdapter struct{ exec run.Runner }\nfunc (r runAdapter) Run(ctx context.Context, step skill.Step) (any, error) {\n  res, err := r.exec.Run(ctx, step.ToolID, step.Inputs)\n  if err != nil {\n    return nil, err\n  }\n  return res.Output, nil\n}\n\nrunner := run.NewRunner()\nresults, err := skill.Execute(context.Background(), plan, runAdapter{exec: runner})\nif err != nil {\n  log.Fatal(err)\n}\n_ = results\n</code></pre>"},{"location":"library-docs-from-repos/toolcompose/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Combine with <code>toolcompose/set</code> to scope which tools a skill can access.</li> <li>Use <code>toolcompose/set</code> exposures to export protocol-specific tool lists.</li> </ul>"},{"location":"library-docs-from-repos/toolops/","title":"toolops","text":"<p>Operations layer providing observability, caching, authentication, health checks, and resilience patterns for production deployments.</p>"},{"location":"library-docs-from-repos/toolops/#packages","title":"Packages","text":"Package Purpose <code>observe</code> OpenTelemetry-based tracing, metrics, and logging <code>cache</code> Deterministic caching with policies and middleware <code>auth</code> Authentication and authorization primitives <code>health</code> Health checks and HTTP probes <code>resilience</code> Circuit breakers, retries, rate limits, bulkheads"},{"location":"library-docs-from-repos/toolops/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolops@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolops/#documentation-map","title":"Documentation Map","text":"<ul> <li>Architecture</li> <li>Schemas and Contracts</li> <li>Examples</li> <li>Design Notes</li> </ul>"},{"location":"library-docs-from-repos/toolops/#quick-start-observability","title":"Quick Start: Observability","text":"<pre><code>import (\n  \"context\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolops/observe\"\n)\n\nobs, err := observe.NewObserver(context.Background(), observe.Config{\n  ServiceName: \"metatools-mcp\",\n  Tracing:     observe.TracingConfig{Enabled: true, Exporter: \"otlp\"},\n  Metrics:     observe.MetricsConfig{Enabled: true, Exporter: \"prometheus\"},\n  Logging:     observe.LoggingConfig{Enabled: true, Level: \"info\"},\n})\nif err != nil {\n  log.Fatal(err)\n}\ndefer obs.Shutdown(context.Background())\n\nmw, _ := observe.MiddlewareFromObserver(obs)\nwrapped := mw.Wrap(func(ctx context.Context, tool observe.ToolMeta, input any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n\n_, _ = wrapped(context.Background(), observe.ToolMeta{Name: \"echo\"}, map[string]any{\"msg\": \"hi\"})\n</code></pre>"},{"location":"library-docs-from-repos/toolops/#quick-start-cache","title":"Quick Start: Cache","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/cache\"\n)\n\nc := cache.NewMemoryCache(cache.DefaultPolicy())\nkeyer := cache.NewDefaultKeyer()\nmw := cache.NewCacheMiddleware(c, keyer, cache.DefaultPolicy(), nil)\n\nresult, err := mw.Execute(context.Background(), \"github:create_issue\", map[string]any{\"title\": \"Bug\"}, []string{\"issues\"},\n  func(ctx context.Context, toolID string, input any) ([]byte, error) {\n    return []byte(\"{\\\"ok\\\":true}\"), nil\n  })\n_ = result\n_ = err\n</code></pre>"},{"location":"library-docs-from-repos/toolops/architecture/","title":"toolops Architecture","text":"<p>The toolops layer provides operational capabilities around tool execution. It does not execute tools itself. Instead, it wraps execution with observability, caching, authentication, health checks, and resilience.</p>"},{"location":"library-docs-from-repos/toolops/architecture/#design-principles","title":"Design Principles","text":"<ul> <li>Pure operations layer: No tool execution, no transport. Wraps calls only.</li> <li>Composable middleware: Each capability exposes a middleware function that   can be stacked around tool execution.</li> <li>Deterministic behavior: Policies and configuration produce predictable   outcomes for retries, caching, and rate limits.</li> <li>Fail-safe defaults: Misconfiguration fails fast with explicit errors.</li> </ul>"},{"location":"library-docs-from-repos/toolops/architecture/#core-packages","title":"Core Packages","text":"Package Responsibility <code>observe</code> Tracing, metrics, structured logging <code>cache</code> Deterministic caching + policies <code>auth</code> Authentication + authorization utilities <code>health</code> Health checks, HTTP probes, readiness <code>resilience</code> Retries, circuit breakers, rate limits, bulkheads"},{"location":"library-docs-from-repos/toolops/architecture/#execution-boundary","title":"Execution Boundary","text":"<p>Tool execution lives in <code>toolexec</code>. toolops sits around it:</p> <pre><code>flowchart LR\n    Exec[\"toolexec/run\"] --&gt; Observe[\"toolops/observe\"]\n    Exec --&gt; Cache[\"toolops/cache\"]\n    Exec --&gt; Auth[\"toolops/auth\"]\n    Exec --&gt; Resilience[\"toolops/resilience\"]\n    Exec --&gt; Health[\"toolops/health\"]</code></pre>"},{"location":"library-docs-from-repos/toolops/architecture/#recommended-middleware-order","title":"Recommended Middleware Order","text":"<p>The order below is optimized for correctness and observability:</p> <ol> <li>Auth \u2014 reject unauthorized requests early.</li> <li>Rate limit / Resilience \u2014 prevent overload and retry safely.</li> <li>Cache \u2014 serve deterministic cached results when allowed.</li> <li>Observe \u2014 record spans/metrics/logs around the final execution.</li> </ol> <pre><code>flowchart LR\n    In[\"Request\"] --&gt; Auth\n    Auth --&gt; Resilience\n    Resilience --&gt; Cache\n    Cache --&gt; Observe\n    Observe --&gt; Exec[\"Execute Tool\"]\n    Exec --&gt; Out[\"Result\"]</code></pre>"},{"location":"library-docs-from-repos/toolops/architecture/#operational-contracts","title":"Operational Contracts","text":"<ul> <li>Concurrency: All middleware must be safe for concurrent use.</li> <li>Context: Context cancellations should abort operations quickly.</li> <li>Errors: All packages expose sentinel errors for configuration issues.</li> <li>No mutation: Middleware must not mutate tool inputs; use copies where needed.</li> </ul>"},{"location":"library-docs-from-repos/toolops/architecture/#consolidation-note","title":"Consolidation Note","text":"<p>The legacy <code>toolobserve</code> and <code>toolcache</code> repositories are consolidated into <code>toolops/observe</code> and <code>toolops/cache</code>. All behavior and contracts live here.</p>"},{"location":"library-docs-from-repos/toolops/design-notes/","title":"toolops Design Notes","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#overview","title":"Overview","text":"<p>toolops provides cross-cutting operational concerns for tool execution:</p> <ul> <li>observe: tracing, metrics, structured logging</li> <li>cache: deterministic caching with TTL policy</li> <li>auth: authentication + authorization primitives</li> <li>health: health checks and probe handlers</li> <li>resilience: retries, timeouts, circuit breakers, rate limits, bulkheads</li> </ul>"},{"location":"library-docs-from-repos/toolops/design-notes/#observe-package","title":"observe Package","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#design-decisions","title":"Design Decisions","text":"<ol> <li>Observer abstraction: Wraps OpenTelemetry tracer/meter/logger into one object.</li> <li>Middleware wrapping: <code>Middleware</code> decorates an <code>ExecuteFunc</code> for execution telemetry.</li> <li>No execution dependency: observe only instruments; it does not call tools.</li> </ol>"},{"location":"library-docs-from-repos/toolops/design-notes/#contracts","title":"Contracts","text":"<ul> <li>Observer must be shut down to flush exporters.</li> <li>Middleware wraps an <code>ExecuteFunc</code> and records telemetry per call.</li> <li>ToolMeta drives span naming (<code>tool.exec.&lt;namespace&gt;.&lt;name&gt;</code>).</li> </ul>"},{"location":"library-docs-from-repos/toolops/design-notes/#cache-package","title":"cache Package","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#design-decisions_1","title":"Design Decisions","text":"<ol> <li>Deterministic keys: Inputs are canonicalized and hashed (SHA\u2011256).</li> <li>Explicit policy: TTL and unsafe tag handling are policy\u2011driven.</li> <li>No caching on error: executor failures are never cached.</li> </ol>"},{"location":"library-docs-from-repos/toolops/design-notes/#policy-semantics","title":"Policy Semantics","text":"<ul> <li>DefaultTTL controls caching enablement (0 disables).</li> <li>MaxTTL clamps overrides.</li> <li>AllowUnsafe gates caching for unsafe-tagged tools.</li> </ul>"},{"location":"library-docs-from-repos/toolops/design-notes/#auth-package","title":"auth Package","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#design-decisions_2","title":"Design Decisions","text":"<ol> <li>Authenticator vs Authorizer: Authentication returns identities; authorization enforces permissions.</li> <li>RBAC support: Simple RBAC authorizer with role inheritance.</li> <li>Protocol-agnostic: Works with any transport layer.</li> </ol>"},{"location":"library-docs-from-repos/toolops/design-notes/#contracts_1","title":"Contracts","text":"<ul> <li>Authenticator returns <code>AuthResult</code> for success/failure; errors indicate internal failure.</li> <li>Authorizer returns an <code>AuthzError</code> when denied.</li> </ul>"},{"location":"library-docs-from-repos/toolops/design-notes/#health-package","title":"health Package","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#design-decisions_3","title":"Design Decisions","text":"<ol> <li>Checker interface: Components implement <code>Check(ctx)</code> returning <code>Result</code>.</li> <li>Aggregator: Multiple checkers can be composed into liveness/readiness endpoints.</li> <li>HTTP handlers: Built-in probe handlers for orchestration platforms.</li> </ol>"},{"location":"library-docs-from-repos/toolops/design-notes/#contracts_2","title":"Contracts","text":"<ul> <li>Checker returns a <code>Result</code> with status + details.</li> <li>Aggregator combines results and computes overall status.</li> </ul>"},{"location":"library-docs-from-repos/toolops/design-notes/#resilience-package","title":"resilience Package","text":""},{"location":"library-docs-from-repos/toolops/design-notes/#design-decisions_4","title":"Design Decisions","text":"<ol> <li>Composable executor: Pattern chain order is deterministic and documented.</li> <li>Minimal state: Each pattern is isolated and configurable.</li> <li>Context-aware: All patterns honor cancellation and deadlines.</li> </ol>"},{"location":"library-docs-from-repos/toolops/design-notes/#execution-order","title":"Execution Order","text":"<p>The executor composes patterns in this order: 1. Rate limiter 2. Bulkhead 3. Circuit breaker 4. Retry 5. Timeout</p>"},{"location":"library-docs-from-repos/toolops/design-notes/#trade-offs","title":"Trade-offs","text":"<ul> <li>No built-in storage: cache is in-memory by default; external backends are explicit.</li> <li>No implicit telemetry: callers must wire observe middleware to execution functions.</li> <li>Fail-fast execution: resilience executor stops on first failure after pattern handling.</li> </ul>"},{"location":"library-docs-from-repos/toolops/examples/","title":"Examples","text":"<p>This page collects runnable examples for each toolops capability.</p>"},{"location":"library-docs-from-repos/toolops/examples/#observability","title":"Observability","text":"<pre><code>import (\n  \"context\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolops/observe\"\n)\n\nobs, err := observe.NewObserver(context.Background(), observe.Config{\n  ServiceName: \"metatools-mcp\",\n  Tracing:     observe.TracingConfig{Enabled: true, Exporter: \"otlp\", SamplePct: 1.0},\n  Metrics:     observe.MetricsConfig{Enabled: true, Exporter: \"prometheus\"},\n  Logging:     observe.LoggingConfig{Enabled: true, Level: \"info\"},\n})\nif err != nil {\n  log.Fatal(err)\n}\n\ndefer obs.Shutdown(context.Background())\n\nmw, _ := observe.MiddlewareFromObserver(obs)\nwrapped := mw.Wrap(func(ctx context.Context, tool observe.ToolMeta, input any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n\n_, _ = wrapped(context.Background(), observe.ToolMeta{Name: \"echo\"}, map[string]any{\"msg\": \"hi\"})\n</code></pre>"},{"location":"library-docs-from-repos/toolops/examples/#cache","title":"Cache","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/cache\"\n)\n\nc := cache.NewMemoryCache(cache.DefaultPolicy())\nkeyer := cache.NewDefaultKeyer()\npolicy := cache.DefaultPolicy()\n\nmw := cache.NewCacheMiddleware(c, keyer, policy, nil)\nresult, err := mw.Execute(context.Background(), \"github:create_issue\", map[string]any{\"title\": \"Bug\"}, []string{\"issues\"},\n  func(ctx context.Context, toolID string, input any) ([]byte, error) {\n    return []byte(\"{\\\"ok\\\":true}\"), nil\n  })\n_ = result\n_ = err\n</code></pre>"},{"location":"library-docs-from-repos/toolops/examples/#auth-jwt","title":"Auth (JWT)","text":"<pre><code>import \"github.com/jonwraymond/toolops/auth\"\n\nvalidator := auth.NewJWTValidator(auth.JWTConfig{\n  Issuer:   \"https://issuer.example.com\",\n  Audience: \"mcp\",\n})\n\nok, claims, err := validator.ValidateToken(\"&lt;token&gt;\")\n_ = ok\n_ = claims\n_ = err\n</code></pre>"},{"location":"library-docs-from-repos/toolops/examples/#health","title":"Health","text":"<pre><code>import \"github.com/jonwraymond/toolops/health\"\n\nagg := health.NewAggregator(health.AggregatorConfig{ServiceName: \"metatools-mcp\"})\nagg.Register(\"memory\", health.NewMemoryChecker(health.MemoryCheckerConfig{MaxRSSBytes: 512 * 1024 * 1024}))\n\nstatus := agg.Check(context.Background())\n_ = status\n</code></pre>"},{"location":"library-docs-from-repos/toolops/examples/#resilience","title":"Resilience","text":"<pre><code>import \"github.com/jonwraymond/toolops/resilience\"\n\nretry := resilience.NewRetry(resilience.RetryConfig{\n  MaxAttempts: 3,\n})\n\ncb := resilience.NewCircuitBreaker(resilience.CircuitBreakerConfig{\n  FailureThreshold: 5,\n})\n\n_ = retry\n_ = cb\n</code></pre>"},{"location":"library-docs-from-repos/toolops/schemas/","title":"Schemas and Contracts","text":"<p>This document describes the configuration schemas and behavioral contracts for <code>toolops</code>. These schemas are expressed as Go types with validation rules.</p>"},{"location":"library-docs-from-repos/toolops/schemas/#observe","title":"observe","text":""},{"location":"library-docs-from-repos/toolops/schemas/#config","title":"Config","text":"<p><code>observe.Config</code> is the root configuration for observability.</p> Field Type Required Notes <code>ServiceName</code> <code>string</code> Yes Required for tracing/metrics resource attribution. <code>Version</code> <code>string</code> No Optional service version label. <code>Tracing</code> <code>TracingConfig</code> No Enables and configures tracing. <code>Metrics</code> <code>MetricsConfig</code> No Enables and configures metrics. <code>Logging</code> <code>LoggingConfig</code> No Enables structured logs. <p>Validation errors (sentinels): - <code>ErrMissingServiceName</code> - <code>ErrInvalidTracingExporter</code> - <code>ErrInvalidSamplePct</code> - <code>ErrInvalidMetricsExporter</code> - <code>ErrInvalidLogLevel</code></p>"},{"location":"library-docs-from-repos/toolops/schemas/#tracingconfig","title":"TracingConfig","text":"Field Type Required Notes <code>Enabled</code> <code>bool</code> No Enable tracing. <code>Exporter</code> <code>string</code> No <code>otlp</code>, <code>jaeger</code>, <code>stdout</code>, <code>none</code>. <code>SamplePct</code> <code>float64</code> No Range <code>0.0</code>\u2013<code>1.0</code>."},{"location":"library-docs-from-repos/toolops/schemas/#metricsconfig","title":"MetricsConfig","text":"Field Type Required Notes <code>Enabled</code> <code>bool</code> No Enable metrics. <code>Exporter</code> <code>string</code> No <code>otlp</code>, <code>prometheus</code>, <code>stdout</code>, <code>none</code>."},{"location":"library-docs-from-repos/toolops/schemas/#loggingconfig","title":"LoggingConfig","text":"Field Type Required Notes <code>Enabled</code> <code>bool</code> No Enable logging. <code>Level</code> <code>string</code> No <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>. <p>Redaction: - Sensitive fields are automatically redacted using <code>observe.RedactedFields</code>.</p>"},{"location":"library-docs-from-repos/toolops/schemas/#cache","title":"cache","text":""},{"location":"library-docs-from-repos/toolops/schemas/#policy","title":"Policy","text":"<p><code>cache.Policy</code> defines caching behavior.</p> Field Type Required Notes <code>DefaultTTL</code> <code>time.Duration</code> No <code>0</code> disables caching by default. <code>MaxTTL</code> <code>time.Duration</code> No Clamp TTL overrides; <code>0</code> = no max. <code>AllowUnsafe</code> <code>bool</code> No Allow caching tools tagged as unsafe."},{"location":"library-docs-from-repos/toolops/schemas/#cache-contract","title":"Cache Contract","text":"<ul> <li><code>Get</code> returns <code>(nil, false)</code> on miss and must not error.</li> <li><code>Set</code> with <code>ttl=0</code> disables caching.</li> <li><code>Delete</code> is idempotent; no error on miss.</li> </ul>"},{"location":"library-docs-from-repos/toolops/schemas/#keyer-contract","title":"Keyer Contract","text":"<ul> <li><code>cache.Keyer</code> must return deterministic, stable keys.</li> <li>Keys must pass <code>cache.ValidateKey</code> (non-empty, &lt;=512 chars, no newlines).</li> </ul>"},{"location":"library-docs-from-repos/toolops/schemas/#auth","title":"auth","text":"<p>Auth uses specific config types per mechanism:</p> Type Purpose <code>JWTConfig</code> Validate JWT tokens and claims <code>JWKSConfig</code> JWKS URL + caching for JWT verification <code>APIKeyConfig</code> Static API key validation <code>OAuth2Config</code> Introspection settings <code>RBACConfig</code> Role-based access control <code>RoleConfig</code> Role definition + permissions <p>Contracts: - All auth checks are deterministic and side-effect free. - Errors are explicit; deny-by-default on failure.</p>"},{"location":"library-docs-from-repos/toolops/schemas/#health","title":"health","text":"Type Purpose <code>AggregatorConfig</code> Aggregates multiple checks and configures thresholds <code>MemoryCheckerConfig</code> Memory health thresholds <p>Contracts: - Health checks are fast and non-blocking. - Failures return structured errors with context.</p>"},{"location":"library-docs-from-repos/toolops/schemas/#resilience","title":"resilience","text":"Type Purpose <code>RetryConfig</code> Retry count, backoff, jitter <code>CircuitBreakerConfig</code> Failure thresholds, open/half-open timings <code>RateLimiterConfig</code> Rate, burst, time window <code>BulkheadConfig</code> Concurrency limits <code>TimeoutConfig</code> Max execution duration <p>Contracts: - All resilience middleware must be concurrency-safe. - Timeouts and cancellations honor <code>context.Context</code>. - Retry policies never retry on context cancellation.</p>"},{"location":"library-docs-from-repos/toolops/user-journey/","title":"toolops User Journey","text":""},{"location":"library-docs-from-repos/toolops/user-journey/#1-installation","title":"1. Installation","text":"<pre><code>go get github.com/jonwraymond/toolops@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#2-observability-middleware","title":"2. Observability Middleware","text":"<pre><code>import (\n  \"context\"\n  \"log\"\n\n  \"github.com/jonwraymond/toolops/observe\"\n)\n\nobs, err := observe.NewObserver(context.Background(), observe.Config{\n  ServiceName: \"metatools-mcp\",\n  Tracing:     observe.TracingConfig{Enabled: true, Exporter: \"otlp\"},\n  Metrics:     observe.MetricsConfig{Enabled: true, Exporter: \"prometheus\"},\n  Logging:     observe.LoggingConfig{Enabled: true, Level: \"info\"},\n})\nif err != nil {\n  log.Fatal(err)\n}\ndefer obs.Shutdown(context.Background())\n\nmw, _ := observe.MiddlewareFromObserver(obs)\nwrapped := mw.Wrap(func(ctx context.Context, tool observe.ToolMeta, input any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n_, _ = wrapped(context.Background(), observe.ToolMeta{Name: \"echo\"}, map[string]any{\"msg\": \"hi\"})\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#3-caching-with-policies","title":"3. Caching with Policies","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/cache\"\n)\n\npolicy := cache.DefaultPolicy()\nc := cache.NewMemoryCache(policy)\nkeyer := cache.NewDefaultKeyer()\nmw := cache.NewCacheMiddleware(c, keyer, policy, nil)\n\n_, _ = mw.Execute(context.Background(), \"github:list_issues\", map[string]any{\"repo\": \"toolops\"}, []string{\"issues\"},\n  func(ctx context.Context, toolID string, input any) ([]byte, error) {\n    return []byte(\"{\\\"ok\\\":true}\"), nil\n  })\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#4-authentication-authorization","title":"4. Authentication + Authorization","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/auth\"\n)\n\nauthenticator := auth.NewAPIKeyAuthenticator(auth.APIKeyConfig{\n  Header: \"X-API-Key\",\n  Keys:   map[string]string{\"dev-key\": \"developer\"},\n})\n\nauthorizer := auth.NewSimpleRBACAuthorizer(auth.RBACConfig{\n  DefaultRole: \"reader\",\n  Roles: map[string]auth.RoleConfig{\n    \"reader\": {AllowedTools: []string{\"github:*\"}, AllowedActions: []string{\"list\"}},\n  },\n})\n\nreq := &amp;auth.AuthRequest{Headers: map[string][]string{\"X-API-Key\": {\"dev-key\"}}}\nresult, _ := authenticator.Authenticate(context.Background(), req)\nif result != nil &amp;&amp; result.Identity != nil {\n  _ = authorizer.Authorize(context.Background(), &amp;auth.AuthzRequest{\n    Subject: result.Identity,\n    Resource: \"tool:github:list_issues\",\n    Action: \"list\",\n  })\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#5-health-checks","title":"5. Health Checks","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolops/health\"\n)\n\nagg := health.NewAggregator()\nagg.Register(\"memory\", health.NewMemoryChecker(health.MemoryCheckerConfig{\n  WarningThreshold: 0.80,\n  CriticalThreshold: 0.95,\n}))\n\nresults := agg.CheckAll(context.Background())\noverall := agg.OverallStatus(results)\n_ = overall\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#6-resilience-patterns","title":"6. Resilience Patterns","text":"<pre><code>import (\n  \"context\"\n  \"time\"\n\n  \"github.com/jonwraymond/toolops/resilience\"\n)\n\nexecutor := resilience.NewExecutor(\n  resilience.WithRetry(resilience.NewRetry(resilience.RetryConfig{\n    MaxAttempts: 3,\n  })),\n  resilience.WithTimeout(2*time.Second),\n)\n\n_ = executor.Execute(context.Background(), func(ctx context.Context) error {\n  return nil\n})\n</code></pre>"},{"location":"library-docs-from-repos/toolops/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Combine <code>observe</code> + <code>cache</code> + <code>resilience</code> in a middleware chain.</li> <li>Use <code>auth</code> + <code>health</code> to harden MCP endpoints.</li> <li>Review the Examples page for runnable snippets.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/","title":"toolprotocol","text":"<p>Protocol layer providing transport, wire format, and protocol primitives for MCP, A2A, and ACP integrations. The packages here are transport-agnostic and composable.</p>"},{"location":"library-docs-from-repos/toolprotocol/#packages","title":"Packages","text":"Package Purpose <code>content</code> Unified content parts (text, image, audio, file, resource) <code>discover</code> Service discovery + capability negotiation <code>transport</code> Transport interfaces (stdio, SSE, streamable HTTP) <code>wire</code> Protocol wire encoding (MCP, A2A, ACP) <code>a2a</code> A2A JSON-RPC + REST/SSE bindings <code>stream</code> Streaming events for progress/partial/complete <code>session</code> Client session store + context helpers <code>task</code> Long-running task lifecycle + subscriptions <code>resource</code> MCP resources registry + subscriptions <code>prompt</code> Prompt templates + registry <code>elicit</code> User input elicitation (text/confirm/choice/form)"},{"location":"library-docs-from-repos/toolprotocol/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolprotocol@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/#documentation-map","title":"Documentation Map","text":"<ul> <li>Architecture</li> <li>Schemas and Contracts</li> <li>Examples</li> <li>Design Notes</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/#quick-start-wire-transport","title":"Quick Start: Wire + Transport","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/transport\"\n  \"github.com/jonwraymond/toolprotocol/wire\"\n)\n\ntype server struct{}\n\nfunc (s *server) ServeTransport(ctx context.Context, t transport.Transport) error {\n  // decode/route using wire codecs\n  return nil\n}\n\nctx := context.Background()\ncodec := wire.NewMCP()\npayload, _ := codec.EncodeRequest(ctx, &amp;wire.Request{\n  ID:        \"1\",\n  Method:    \"tools/list\",\n  ToolID:    \"\",\n  Arguments: nil,\n})\n\ntp, _ := transport.New(\"stdio\", nil)\n_ = payload\n_ = tp.Serve(ctx, &amp;server{})\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/#quick-start-tasks-streaming","title":"Quick Start: Tasks + Streaming","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/stream\"\n  \"github.com/jonwraymond/toolprotocol/task\"\n)\n\nctx := context.Background()\nmgr := task.NewManager()\n_ , _ = mgr.Create(ctx, \"task-1\")\n\nsource := stream.NewSource()\ns := source.NewBufferedStream(ctx, 50)\n_ = s.Send(ctx, stream.Event{Type: stream.EventProgress, Data: 0.5})\n_ = s.Send(ctx, stream.Event{Type: stream.EventComplete, Data: map[string]any{\"ok\": true}})\n_ = s.Close()\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/#contracts-summary","title":"Contracts (Summary)","text":"<ul> <li>Transport: concurrent-safe; <code>Serve</code> honors context; <code>Close</code> is idempotent.</li> <li>Wire: encode/decode deterministic; <code>Capabilities</code> must match actual behavior.</li> <li>Content: immutable content instances; <code>Bytes</code> must be safe to call multiple times.</li> <li>Stream: event ordering preserved; <code>Done</code> closes after <code>Close</code>.</li> <li>Task: state machine enforces valid transitions; terminal states are final.</li> <li>Session: store guarantees TTL cleanup and thread safety.</li> <li>Resource/Prompt/Elicit: registries are concurrency-safe; errors are explicit.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/architecture/","title":"toolprotocol Architecture","text":"<p>The toolprotocol layer defines protocol primitives for tool exchange. It does not implement execution or discovery; it standardizes how tools, results, and streams are transported between systems.</p>"},{"location":"library-docs-from-repos/toolprotocol/architecture/#design-principles","title":"Design Principles","text":"<ul> <li>Protocol-first: wire/transport types are independent of transport runtime.</li> <li>Composable: packages can be used individually (e.g., <code>wire</code> only).</li> <li>Deterministic: message schemas are stable and versioned.</li> <li>Streaming-safe: stream/session types are concurrency-safe by default.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/architecture/#core-packages","title":"Core Packages","text":"Package Responsibility <code>wire</code> Low-level protocol types and envelopes <code>transport</code> Transport-agnostic interfaces (SSE/stdio/etc.) <code>content</code> Content blocks and rendering helpers <code>stream</code> Streaming event types and default stream implementation <code>session</code> Session identifiers, lifecycles, and context <code>task</code> Task/event primitives for long-running work <code>resource</code> Resource references and metadata <code>prompt</code> Prompt templates and variables <code>discover</code> Discovery request/response types <code>elicit</code> Elicitation prompts and responses"},{"location":"library-docs-from-repos/toolprotocol/architecture/#layering","title":"Layering","text":"<pre><code>flowchart TB\n    subgraph Protocol\n        Wire[\"wire\"]\n        Transport[\"transport\"]\n        Stream[\"stream\"]\n        Session[\"session\"]\n    end\n\n    subgraph Content\n        ContentPkg[\"content\"]\n        Prompt[\"prompt\"]\n        Resource[\"resource\"]\n        Elicit[\"elicit\"]\n    end\n\n    subgraph Tasks\n        Task[\"task\"]\n        Discover[\"discover\"]\n    end\n\n    Wire --&gt; Transport\n    Wire --&gt; Stream\n    Stream --&gt; Session\n    ContentPkg --&gt; Wire\n    Prompt --&gt; ContentPkg\n    Resource --&gt; ContentPkg\n    Elicit --&gt; ContentPkg\n    Task --&gt; Wire\n    Discover --&gt; Wire</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/architecture/#protocol-boundary","title":"Protocol Boundary","text":"<p><code>toolprotocol</code> is consumed by higher layers (e.g., <code>metatools-mcp</code>). It does not own transport servers/clients itself. The intention is to keep protocol types portable across SSE, stdio, and HTTP.</p>"},{"location":"library-docs-from-repos/toolprotocol/architecture/#concurrency-contract","title":"Concurrency Contract","text":"<ul> <li>Streams must be safe for concurrent writers and readers.</li> <li>Close operations are idempotent.</li> <li>Sessions must not leak goroutines or block on close.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/architecture/#consolidation-note","title":"Consolidation Note","text":"<p>Legacy protocol primitives from the pre-consolidation stack are now unified here, with stable import paths under <code>github.com/jonwraymond/toolprotocol/...</code>.</p>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/","title":"Design Notes","text":""},{"location":"library-docs-from-repos/toolprotocol/design-notes/#architecture-decisions","title":"Architecture Decisions","text":"<ol> <li>Layered protocols, not monoliths. Transport, wire format, and content are    isolated so that new protocols can reuse the same primitives.</li> <li>Protocol-agnostic primitives. Packages like <code>task</code>, <code>stream</code>, <code>session</code>,    <code>resource</code>, and <code>prompt</code> are independent of MCP/A2A/ACP specifics.</li> <li>Deterministic encoding. <code>wire</code> implementations must encode/decode    deterministically to preserve caching and reproducibility.</li> <li>Minimal dependencies. The repo avoids heavy deps to keep transport    implementations portable across environments.</li> </ol>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#contract-semantics","title":"Contract Semantics","text":""},{"location":"library-docs-from-repos/toolprotocol/design-notes/#transport","title":"transport","text":"<ul> <li>Concurrency: implementations must be safe for concurrent use.</li> <li>Cancellation: <code>Serve</code> must respect context cancellation.</li> <li>Idempotency: <code>Close</code> is safe to call multiple times.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#wire","title":"wire","text":"<ul> <li>Lossless mapping: encode/decode preserves request/response shape.</li> <li>Capabilities: <code>Capabilities()</code> must reflect actual encoder support.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#content","title":"content","text":"<ul> <li>Immutability: content instances are safe to share across goroutines.</li> <li>MIME fidelity: <code>MIMEType</code> must always match the payload.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#stream","title":"stream","text":"<ul> <li>Ordering: events are delivered in send order.</li> <li>Termination: <code>Done()</code> closes after <code>Close()</code> completes.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#task","title":"task","text":"<ul> <li>State machine: only valid transitions are allowed.</li> <li>Subscriptions: updates are fan-out safe and non-blocking.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#sessionresourcepromptelicit","title":"session/resource/prompt/elicit","text":"<ul> <li>Thread safety: registries are concurrency-safe.</li> <li>Explicit errors: missing keys or invalid args return typed errors.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/design-notes/#trade-offs","title":"Trade-offs","text":"<ul> <li>Pure interfaces vs. convenience helpers. We keep core interfaces small and   provide optional helpers in each package to avoid bloated APIs.</li> <li>Broad scope vs. cohesion. This repo groups protocol primitives to simplify   versioning, but avoids pulling in execution or schema concerns.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/toolprotocol/examples/#wire-envelope","title":"Wire Envelope","text":"<pre><code>import \"github.com/jonwraymond/toolprotocol/wire\"\n\nmsg := wire.Envelope{\n  Version: \"1.0\",\n  Type:    \"discover.request\",\n  Payload: map[string]any{\n    \"query\": \"create issue\",\n  },\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/examples/#stream","title":"Stream","text":"<pre><code>import \"github.com/jonwraymond/toolprotocol/stream\"\n\ns := stream.NewDefaultStream()\n\ngo func() {\n  _ = s.Send(stream.Event{Type: \"progress\", Data: map[string]any{\"pct\": 50}})\n  _ = s.Close()\n}()\n\nfor ev := range s.Events() {\n  _ = ev\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/examples/#session","title":"Session","text":"<pre><code>import \"github.com/jonwraymond/toolprotocol/session\"\n\nsess := session.New(session.Config{ID: \"session-1\"})\nctx := sess.Context()\n_ = ctx\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/examples/#content-blocks","title":"Content Blocks","text":"<pre><code>import \"github.com/jonwraymond/toolprotocol/content\"\n\nblock := content.Block{\n  Type: \"text\",\n  Data: map[string]any{\"text\": \"hello\"},\n}\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/schemas/","title":"Schemas and Contracts","text":"<p>This document defines the protocol schema contracts in <code>toolprotocol</code>. These are structural schemas (wire formats, streaming events, sessions), not execution schemas.</p>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#wire","title":"wire","text":"<p>The <code>wire</code> package defines protocol envelopes for requests and responses.</p> <p>Contract highlights:</p> <ul> <li>All envelopes carry a version and type.</li> <li>Payloads are JSON-serializable and stable across transports.</li> <li>Unknown fields must be ignored for forward compatibility.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#transport","title":"transport","text":"<p><code>transport</code> defines interfaces for moving <code>wire</code> payloads across channels.</p> <p>Contract highlights:</p> <ul> <li>Implementations must be concurrency-safe.</li> <li>Close operations are idempotent.</li> <li>Errors must wrap <code>context.Canceled</code> and <code>context.DeadlineExceeded</code> when applicable.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#stream","title":"stream","text":"<p>Streams represent ordered event sequences.</p> <p>Contract highlights:</p> <ul> <li>Events are delivered in-order.</li> <li>Close is idempotent; no panic on double-close.</li> <li>Readers must not block indefinitely after Close.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#session","title":"session","text":"<p>Sessions track ongoing interactions across transports.</p> <p>Contract highlights:</p> <ul> <li>Session IDs are unique and immutable.</li> <li>Context cancellation must terminate session-bound operations.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#content","title":"content","text":"<p><code>content</code> defines structured content blocks.</p> <p>Contract highlights:</p> <ul> <li>Content blocks are self-describing (<code>type</code> + <code>data</code>).</li> <li>Blocks must be valid JSON and stable for storage/transmission.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#task","title":"task","text":"<p><code>task</code> defines long-running work events.</p> <p>Contract highlights:</p> <ul> <li>Task state transitions are monotonic.</li> <li>Errors are represented using a stable error envelope.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#discover","title":"discover","text":"<p>Discovery request/response shapes.</p> <p>Contract highlights:</p> <ul> <li>Search requests are deterministic.</li> <li>Responses include stable identifiers; schemas are not required in discovery.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/schemas/#prompt-elicit","title":"prompt + elicit","text":"<p>Prompt templates and elicitation flows.</p> <p>Contract highlights:</p> <ul> <li>Prompts are explicit about required variables.</li> <li>Elicitation responses map 1:1 to requested fields.</li> </ul>"},{"location":"library-docs-from-repos/toolprotocol/user-journey/","title":"User Journey","text":""},{"location":"library-docs-from-repos/toolprotocol/user-journey/#installation","title":"Installation","text":"<pre><code>go get github.com/jonwraymond/toolprotocol@latest\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/user-journey/#basic-usage-minimal-protocol-server","title":"Basic Usage: Minimal Protocol Server","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/transport\"\n  \"github.com/jonwraymond/toolprotocol/wire\"\n)\n\ntype server struct{\n  codec wire.Wire\n}\n\nfunc (s *server) ServeTransport(ctx context.Context, t transport.Transport) error {\n  // Read bytes from transport, decode with s.codec, route to handlers.\n  return nil\n}\n\nctx := context.Background()\nsrv := &amp;server{codec: wire.NewMCP()}\ntp, _ := transport.New(\"stdio\", nil)\n_ = tp.Serve(ctx, srv)\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/user-journey/#intermediate-sessions-resources","title":"Intermediate: Sessions + Resources","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/resource\"\n  \"github.com/jonwraymond/toolprotocol/session\"\n)\n\nctx := context.Background()\n\nstore := session.NewMemoryStore()\nsess, _ := store.Create(ctx, \"client-1\")\nctx = session.WithSession(ctx, sess)\n\nregistry := resource.NewRegistry()\nstatic := resource.NewStaticProvider()\nstatic.Add(\n  resource.Resource{URI: \"file:///readme.md\", Name: \"README\", MIMEType: \"text/markdown\"},\n  resource.Contents{URI: \"file:///readme.md\", MIMEType: \"text/markdown\", Text: \"# README\"},\n)\nregistry.Register(\"file\", static)\n\n_, _ = registry.Read(ctx, \"file:///readme.md\")\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/user-journey/#advanced-task-streaming","title":"Advanced: Task + Streaming","text":"<pre><code>import (\n  \"context\"\n\n  \"github.com/jonwraymond/toolprotocol/stream\"\n  \"github.com/jonwraymond/toolprotocol/task\"\n)\n\nctx := context.Background()\nmgr := task.NewManager()\n_ , _ = mgr.Create(ctx, \"job-123\")\n\nsource := stream.NewSource()\ns := source.NewBufferedStream(ctx, 100)\n_ = s.Send(ctx, stream.Event{Type: stream.EventProgress, Data: 0.3})\n_ = s.Send(ctx, stream.Event{Type: stream.EventComplete, Data: map[string]any{\"ok\": true}})\n_ = s.Close()\n</code></pre>"},{"location":"library-docs-from-repos/toolprotocol/user-journey/#next-steps","title":"Next Steps","text":"<ul> <li>Review the Examples page for runnable snippets.</li> <li>Use <code>toolprotocol/wire</code> + <code>toolprotocol/transport</code> inside <code>metatools-mcp</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/","title":"metatools-mcp","text":"<p><code>metatools-mcp</code> is the MCP server that exposes the tool stack via a small, progressive-disclosure tool surface. It composes <code>toolfoundation</code>, <code>tooldiscovery</code>, <code>toolexec</code>, and optionally <code>toolexec/runtime</code> for sandboxed execution.</p> <p></p>"},{"location":"library-docs-from-repos/metatools-mcp/#deep-dives","title":"Deep dives","text":"<ul> <li>Design Notes: design-notes.md</li> <li>User Journey: user-journey.md</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#motivation","title":"Motivation","text":"<ul> <li>One MCP surface for discovery, docs, and execution</li> <li>Progressive disclosure to keep tool context small</li> <li>Pluggable design for search, runtimes, and engines</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#mcp-tools-exposed","title":"MCP tools exposed","text":"<ul> <li><code>search_tools</code></li> <li><code>list_namespaces</code></li> <li><code>describe_tool</code></li> <li><code>list_tool_examples</code></li> <li><code>run_tool</code></li> <li><code>run_chain</code></li> <li><code>execute_code</code> (optional)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#quickstart","title":"Quickstart","text":"<pre><code>idx := index.NewInMemoryIndex()\ndocs := tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx})\nrunner := run.NewRunner(run.WithIndex(idx))\n\ncfg := adapters.NewConfig(idx, docs, runner, nil)\nserver, _ := server.New(cfg)\n\n_ = server.Run(context.Background(), &amp;mcp.StdioTransport{})\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/#usability-notes","title":"Usability notes","text":"<ul> <li>Fewer MCP tools means simpler agent prompts</li> <li>Outputs are structured and aligned to MCP schemas</li> <li>Search and execution behaviors are deterministic by default</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#runtime-notes-execute_code","title":"Runtime notes (execute_code)","text":"<p><code>execute_code</code> is optional and wired behind the <code>toolruntime</code> build tag. By default, the runtime uses the unsafe dev profile; when Docker is available, set <code>METATOOLS_RUNTIME_PROFILE=standard</code> to enable the hardened Docker backend. WASM can be enabled with <code>METATOOLS_WASM_ENABLED=true</code> and selected with <code>METATOOLS_RUNTIME_BACKEND=wasm</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/#interface-contracts","title":"Interface Contracts","text":"<ul> <li>Transport: thread-safe; <code>Serve</code> honors context; <code>Close</code> is idempotent.</li> <li>Backend: thread-safe; <code>ListTools</code>/<code>Execute</code> honor context; streaming backends return non-nil channel when err is nil.</li> <li>ToolProvider: thread-safe; <code>Handle</code> honors context; streaming providers return non-nil channel when err is nil.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#next","title":"Next","text":"<ul> <li>Server architecture: <code>architecture.md</code></li> <li>Ordered execution plan: <code>plan-of-record.md</code></li> <li>Configuration and env vars: <code>usage.md</code></li> <li>Examples: <code>examples.md</code></li> <li>Design Notes: design-notes.md</li> <li>User Journey: user-journey.md</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/#proposals","title":"Proposals","text":"<p>Master Plan: - ROADMAP - Master roadmap with all work streams, phases, and milestones</p> <p>Architecture: - Pluggable Architecture - Extensible, modular design - Architecture Evaluation - Championship-level comparison - Component Library Analysis - Tool* library ecosystem - Architecture Review - Comprehensive proposal analysis and consistency check - MCP Spec Alignment - Targeted spec compliance improvements</p> <p>Features: - Protocol-Agnostic Tools - Composable toolsets and protocol adapters - Multi-Tenancy Extension - Tenant isolation patterns - Agent Skills - Higher-level capability composition (see ROADMAP)</p> <p>Implementation: - Implementation Phases - Phased rollout plan</p>"},{"location":"library-docs-from-repos/metatools-mcp/api/","title":"API Reference","text":""},{"location":"library-docs-from-repos/metatools-mcp/api/#server","title":"Server","text":"<pre><code>func New(cfg config.Config) (*Server, error)\nfunc (s *Server) Run(ctx context.Context, transport mcp.Transport) error\nfunc (s *Server) MCPServer() *mcp.Server\nfunc (s *Server) ListTools() []*mcp.Tool\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/api/#config","title":"Config","text":"<pre><code>type Config struct {\n  Index    index.Index\n  Docs     tooldoc.Store\n  Runner   run.Runner\n  Executor code.Executor // optional\n\n  NotifyToolListChanged           bool\n  NotifyToolListChangedDebounceMs int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/api/#interface-contracts","title":"Interface Contracts","text":"<ul> <li>Transport: thread-safe; <code>Serve</code> honors context; <code>Close</code> is idempotent.</li> <li>Backend: thread-safe; <code>ListTools</code>/<code>Execute</code> honor context; streaming backends must return non-nil channel when err is nil.</li> <li>ToolProvider: thread-safe; <code>Handle</code> honors context; streaming providers must return non-nil channel when err is nil.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/api/#transport","title":"Transport","text":"<p>The transport layer is in <code>internal/transport</code>:</p> <pre><code>// Transport interface for MCP protocol transports\ntype Transport interface {\n  Name() string\n  Info() Info\n  Serve(ctx context.Context, server Server) error\n  Close() error\n}\n\n// Info describes a transport instance\ntype Info struct {\n  Name string\n  Addr string\n  Path string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/api/#available-transports","title":"Available transports","text":"Type Struct Use Case stdio <code>StdioTransport</code> Claude Desktop, local CLI streamable <code>StreamableHTTPTransport</code> Web apps, HTTP clients (MCP 2025-11-25) sse <code>SSETransport</code> Legacy HTTP clients (deprecated)"},{"location":"library-docs-from-repos/metatools-mcp/api/#streamablehttpconfig","title":"StreamableHTTPConfig","text":"<pre><code>type StreamableHTTPConfig struct {\n  Host              string        // Network interface (default: \"0.0.0.0\")\n  Port              int           // TCP port (required)\n  Path              string        // Endpoint path (default: \"/mcp\")\n  ReadHeaderTimeout time.Duration // Header read timeout (default: 10s)\n  TLS               TLSConfig     // HTTPS configuration\n  Stateless         bool          // Disable session management\n  JSONResponse      bool          // Prefer JSON over SSE streaming\n  SessionTimeout    time.Duration // Idle session cleanup\n}\n\ntype TLSConfig struct {\n  Enabled  bool\n  CertFile string\n  KeyFile  string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/api/#toolruntime-integration","title":"Toolruntime integration","text":"<p>When built with <code>-tags toolruntime</code>, <code>execute_code</code> is backed by a <code>toolexec/runtime</code> runtime. The runtime selects a profile at startup:</p> <ul> <li><code>dev</code> profile: unsafe subprocess backend (default).</li> <li><code>standard</code> profile: Docker sandbox by default or WASM when selected.</li> <li><code>METATOOLS_DOCKER_IMAGE</code> overrides the sandbox image name.</li> <li><code>METATOOLS_WASM_ENABLED=true</code> enables the WASM backend (wazero).</li> <li><code>METATOOLS_RUNTIME_BACKEND=wasm</code> selects WASM for the standard profile.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/api/#mcp-tool-io-types","title":"MCP tool I/O types","text":"<p>These are exported in <code>pkg/metatools</code>:</p> <ul> <li><code>SearchToolsInput</code> / <code>SearchToolsOutput</code></li> <li><code>ListNamespacesInput</code> / <code>ListNamespacesOutput</code></li> <li><code>DescribeToolInput</code> / <code>DescribeToolOutput</code></li> <li><code>ListToolExamplesInput</code> / <code>ListToolExamplesOutput</code></li> <li><code>RunToolInput</code> / <code>RunToolOutput</code></li> <li><code>RunChainInput</code> / <code>RunChainOutput</code></li> <li><code>ExecuteCodeInput</code> / <code>ExecuteCodeOutput</code></li> </ul> <p>Notes: - <code>SearchToolsInput</code>/<code>ListNamespacesInput</code> accept <code>limit</code> + <code>cursor</code>. - <code>SearchToolsOutput</code>/<code>ListNamespacesOutput</code> return <code>nextCursor</code> when more data exists.</p>"},{"location":"library-docs-from-repos/metatools-mcp/api/#error-codes","title":"Error codes","text":"<p>Metatools surfaces standardized error codes (strings), including:</p> <ul> <li><code>tool_not_found</code></li> <li><code>no_backends</code></li> <li><code>validation_input</code></li> <li><code>validation_output</code></li> <li><code>execution_failed</code></li> <li><code>stream_not_supported</code></li> <li><code>chain_step_failed</code></li> <li><code>cancelled</code></li> <li><code>timeout</code></li> <li><code>internal</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/architecture/","title":"Architecture","text":"<p><code>metatools-mcp</code> composes the core libraries and exposes a small MCP tool surface.</p>"},{"location":"library-docs-from-repos/metatools-mcp/architecture/#transport-layer","title":"Transport layer","text":"<p>The transport layer abstracts how clients connect to the MCP server. All transports implement the <code>Transport</code> interface, enabling protocol flexibility without changing server logic.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#805ad5'}}}%%\nclassDiagram\n    class Transport {\n        &lt;&lt;interface&gt;&gt;\n        +Name() string\n        +Info() Info\n        +Serve(ctx, server) error\n        +Close() error\n    }\n\n    class StdioTransport {\n        +Name() \"stdio\"\n        +Serve() stdin/stdout\n    }\n\n    class StreamableHTTPTransport {\n        +Config StreamableHTTPConfig\n        +Name() \"streamable\"\n        +Serve() HTTP POST/GET/DELETE\n    }\n\n    class SSETransport {\n        +Config SSEConfig\n        +Name() \"sse\"\n        +Serve() HTTP + SSE\n    }\n\n    Transport &lt;|.. StdioTransport\n    Transport &lt;|.. StreamableHTTPTransport\n    Transport &lt;|.. SSETransport\n\n    note for StreamableHTTPTransport \"MCP spec 2025-11-25\\nRecommended for HTTP\"\n    note for SSETransport \"Deprecated\"</code></pre> Transport Protocol Session Best For <code>stdio</code> stdin/stdout JSON-RPC Implicit Claude Desktop, local CLI <code>streamable</code> HTTP POST/GET/DELETE Mcp-Session-Id header Web apps, remote clients <code>sse</code> HTTP + Server-Sent Events Cookie-based Legacy (deprecated)"},{"location":"library-docs-from-repos/metatools-mcp/architecture/#component-wiring","title":"Component wiring","text":""},{"location":"library-docs-from-repos/metatools-mcp/architecture/#runtime-layer-execute_code","title":"Runtime layer (execute_code)","text":"<p>When built with the <code>toolruntime</code> tag, <code>execute_code</code> is backed by a runtime that selects between an unsafe dev backend and a Docker-backed standard backend. Docker is opt-in via <code>METATOOLS_RUNTIME_PROFILE=standard</code>.</p> <p>Standard isolation can also be provided by the WASM backend when enabled (<code>METATOOLS_WASM_ENABLED=true</code>, <code>METATOOLS_RUNTIME_BACKEND=wasm</code>). If Docker is unavailable and WASM is enabled, the server falls back to WASM for the standard profile.</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0'}}}%%\nflowchart LR\n    Agent[\"AI Agent\"] --&gt; MCP[\"metatools-mcp\"]\n    MCP --&gt; Toolcode[\"toolexec/code Executor\"]\n    Toolcode --&gt; Runtime[\"toolexec/runtime\"]\n\n    Runtime --&gt; Dev[\"dev profile&lt;br/&gt;unsafe subprocess\"]\n    Runtime --&gt; Standard[\"standard profile&lt;br/&gt;Docker sandbox\"]\n\n    style MCP fill:#2b6cb0,stroke:#2c5282\n    style Toolcode fill:#6b46c1,stroke:#553c9a\n    style Runtime fill:#4a5568,stroke:#2d3748\n    style Dev fill:#dd6b20,stroke:#c05621\n    style Standard fill:#2f855a,stroke:#276749</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/architecture/#progressive-disclosure-flow","title":"Progressive disclosure flow","text":""},{"location":"library-docs-from-repos/metatools-mcp/architecture/#mcp-tool-mapping","title":"MCP tool mapping","text":""},{"location":"library-docs-from-repos/metatools-mcp/changelog/","title":"Changelog","text":""},{"location":"library-docs-from-repos/metatools-mcp/changelog/#unreleased","title":"Unreleased","text":""},{"location":"library-docs-from-repos/metatools-mcp/changelog/#added","title":"Added","text":"<ul> <li>Cursor-based pagination for <code>search_tools</code> and <code>list_namespaces</code> with opaque cursors.</li> <li><code>notifications/tools/list_changed</code> support with debounce and env toggle.</li> <li>Tests for list-changed notifications and cancellation propagation.</li> <li>Progress notifications for <code>run_tool</code>, <code>run_chain</code>, and <code>execute_code</code> when a progress token is provided.</li> <li>Cancellation and timeout error codes (<code>cancelled</code>, <code>timeout</code>) for tool failures.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/changelog/#changed","title":"Changed","text":"<ul> <li><code>list_namespaces</code> input/output schemas now include <code>limit</code>, <code>cursor</code>, and <code>nextCursor</code>.</li> <li>Cursor helpers marked deprecated in favor of toolindex tokens.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/","title":"Design Notes","text":"<p>This page documents the tradeoffs and error semantics behind <code>metatools-mcp</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#design-tradeoffs","title":"Design tradeoffs","text":"<ul> <li>MCP-native surface. All metatools (search, describe, run, chain, execute_code) are exposed via the official MCP Go SDK types to keep wire compatibility.</li> <li>Adapters, not re-implementation. The server delegates to tooldiscovery/index, tooldiscovery/tooldoc, toolexec/run, and toolexec/code via thin adapters so the libraries remain the source of truth.</li> <li>Structured error objects. Tool-level errors are returned in a consistent <code>ErrorObject</code> shape rather than raw Go errors, preserving the MCP tool contract.</li> <li>Explicit limits. Inputs such as <code>limit</code> and <code>max</code> are capped for safe defaults (e.g., search limit cap 100, examples cap 5).</li> <li>Opaque pagination. Cursor tokens are opaque and validated against index mutations to prevent stale paging.</li> <li>Pluggable search. BM25 is optional via build tags (<code>toolsearch</code>) and runtime config via env vars.</li> <li>Change notifications. Tool list updates emit <code>notifications/tools/list_changed</code> with a debounce window; notifications can be disabled and are emitted as a single list change per debounce window.</li> <li>Transport abstraction. The <code>Transport</code> interface decouples protocol handling from server logic, enabling stdio, SSE, and Streamable HTTP without code changes.</li> <li>Runtime isolation. <code>execute_code</code> is optional; the <code>toolruntime</code> build tag enables sandboxed execution via toolexec/runtime with runtime profile selection.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#transport-layer","title":"Transport layer","text":"<p>The transport layer abstracts how clients connect to the MCP server. All transports implement the same <code>Transport</code> interface, ensuring identical behavior regardless of protocol:</p> <pre><code>type Transport interface {\n    Name() string\n    Info() Info\n    Serve(ctx context.Context, server Server) error\n    Close() error\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#transport-selection-rationale","title":"Transport selection rationale","text":"Transport Status Use Case Rationale <code>stdio</code> Recommended (local) Claude Desktop, local CLIs Zero config, implicit session, lowest latency <code>streamable</code> Recommended (HTTP) Web apps, remote clients MCP spec 2025-11-25 compliant, session management, bidirectional <code>sse</code> Deprecated Legacy web clients Superseded by streamable per MCP spec"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#streamable-http-design-decisions","title":"Streamable HTTP design decisions","text":"<ol> <li> <p>Single endpoint (<code>/mcp</code>): Follows MCP spec 2025-11-25 with POST/GET/DELETE methods    on one path, simplifying routing and CORS configuration.</p> </li> <li> <p>Session management via header: Uses <code>Mcp-Session-Id</code> header (not cookies) for    stateless load balancing compatibility and explicit session lifecycle.</p> </li> <li> <p>Stateless mode option: Enables serverless/FaaS deployments where session    persistence is impractical. Trade-off: no server-initiated requests.</p> </li> <li> <p>JSON vs SSE response modes: Default SSE streaming supports long-running tools;    <code>JSONResponse=true</code> option for simpler request/response patterns.</p> </li> <li> <p>TLS built-in: Direct TLS support avoids reverse proxy requirements for simple    deployments while allowing proxy termination for complex setups.</p> </li> <li> <p>Graceful shutdown: 5-second timeout allows in-flight requests to complete,    balancing responsiveness with reliability.</p> </li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#error-semantics","title":"Error semantics","text":"<p><code>metatools-mcp</code> distinguishes protocol errors from tool errors:</p> <ul> <li>Protocol errors (invalid input) return a non-nil error from handlers.</li> <li>Tool errors are wrapped into <code>ErrorObject</code> and returned with <code>isError = true</code> so MCP clients treat them as tool failures.</li> </ul> <p>Key error behaviors:</p> <ul> <li><code>run_tool</code> rejects <code>stream=true</code> and <code>backend_override</code> in the default handler (not supported yet).</li> <li><code>run_chain</code> stops on first error and returns partial results with an <code>ErrorObject</code>.</li> <li><code>describe_tool</code>/<code>list_tool_examples</code> return validation errors when required fields are missing.</li> <li>Invalid cursors return JSON-RPC invalid params.</li> <li>Cancellation and timeouts map to <code>cancelled</code> and <code>timeout</code> error codes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#extension-points","title":"Extension points","text":"<ul> <li>Transport: implement <code>Transport</code> interface to add new protocols (e.g., WebSocket, gRPC).</li> <li>Search strategy: enable BM25 via the <code>toolsearch</code> build tag and env vars.</li> <li>Tool execution: swap <code>toolexec/run</code> runner implementation or configure different backends.</li> <li>Code execution: plug in a different <code>toolexec/code</code> engine (e.g., toolexec/runtime-backed).</li> <li>Progress: when a progress token is provided, <code>run_tool</code>, <code>run_chain</code>, and <code>execute_code</code> emit progress notifications. If the runner supports progress callbacks, step-level updates are forwarded; otherwise a coarse start/end signal is sent.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#runtime-profile-selection","title":"Runtime profile selection","text":"<p>When built with <code>-tags toolruntime</code>, metatools-mcp wires <code>toolexec/runtime</code> into <code>toolexec/code</code>:</p> <ul> <li>Dev profile (<code>dev</code>) uses the unsafe subprocess backend for fast iteration.</li> <li>Standard profile (<code>standard</code>) uses Docker by default or WASM when selected.</li> <li>Set <code>METATOOLS_RUNTIME_PROFILE=standard</code> to opt into standard isolation.</li> <li>Use <code>METATOOLS_RUNTIME_BACKEND=wasm</code> with <code>METATOOLS_WASM_ENABLED=true</code> to   prefer the WASM backend (wazero) for standard profile.</li> <li>If Docker is unavailable and WASM is enabled, the server falls back to WASM   for the standard profile.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#operational-guidance","title":"Operational guidance","text":""},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#transport-configuration","title":"Transport configuration","text":"<ul> <li>Use <code>--transport=stdio</code> (default) for Claude Desktop and local CLI integration.</li> <li>Use <code>--transport=streamable --port=8080</code> for HTTP-based clients and web applications.</li> <li>Configure TLS for production HTTP deployments: <code>--tls --tls-cert=cert.pem --tls-key=key.pem</code></li> <li>Use <code>--stateless</code> for serverless/FaaS where session persistence is unavailable.</li> <li>Set <code>METATOOLS_TRANSPORT_STREAMABLE_SESSION_TIMEOUT</code> to control idle session cleanup.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#search-configuration","title":"Search configuration","text":"<ul> <li>Use environment variables to configure search strategy:</li> <li><code>METATOOLS_SEARCH_STRATEGY=lexical|bm25</code></li> <li><code>METATOOLS_SEARCH_BM25_*</code> for weighting and caps</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/design-notes/#general-guidance","title":"General guidance","text":"<ul> <li>Keep tool schemas in <code>toolfoundation/model</code> to preserve MCP compatibility end-to-end.</li> <li>Treat metatools as the stable surface; update libraries behind it as needed.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/examples/","title":"Examples","text":""},{"location":"library-docs-from-repos/metatools-mcp/examples/#register-a-local-tool-expose-mcp-server","title":"Register a local tool + expose MCP server","text":"<pre><code>type localRegistry struct {\n  handlers map[string]run.LocalHandler\n}\n\nfunc newLocalRegistry() *localRegistry {\n  return &amp;localRegistry{handlers: make(map[string]run.LocalHandler)}\n}\n\nfunc (r *localRegistry) Get(name string) (run.LocalHandler, bool) {\n  h, ok := r.handlers[name]\n  return h, ok\n}\n\nfunc (r *localRegistry) Register(name string, h run.LocalHandler) {\n  r.handlers[name] = h\n}\n\nidx := index.NewInMemoryIndex()\n\nlocal := newLocalRegistry()\nlocal.Register(\"ping\", func(ctx context.Context, args map[string]any) (any, error) {\n  return map[string]any{\"ok\": true}, nil\n})\n\n_ = idx.RegisterTool(model.Tool{\n  Namespace: \"local\",\n  Tool: mcp.Tool{\n    Name:        \"ping\",\n    Description: \"Simple health check\",\n    InputSchema: map[string]any{\"type\": \"object\"},\n  },\n}, model.ToolBackend{\n  Kind:  model.BackendKindLocal,\n  Local: &amp;model.LocalBackend{Name: \"ping\"},\n})\n\nrunner := run.NewRunner(run.WithIndex(idx), run.WithLocalRegistry(local))\n\ncfg := adapters.NewConfig(idx, tooldoc.NewInMemoryStore(tooldoc.StoreOptions{Index: idx}), runner, nil)\nserver, _ := server.New(cfg)\n_ = server.Run(context.Background(), &amp;mcp.StdioTransport{})\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/examples/#tool-search-and-execution","title":"Tool search and execution","text":"<pre><code>summaries, _ := idx.Search(\"ping\", 3)\n\nres, _ := runner.Run(ctx, summaries[0].ID, map[string]any{})\nfmt.Println(res.Structured)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/","title":"Plan of Record (Ordered Execution)","text":"<p>Status: Superseded Canonical Roadmap: <code>ai-tools-stack/docs/roadmap.md</code></p> <p>This page consolidates all proposals and PRDs into a single, ordered execution sequence. It is intentionally Go\u2011architecture focused: concurrency safety, context propagation, and production operational boundaries are explicit in each phase.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#principles-go-architect-evaluation","title":"Principles (Go Architect Evaluation)","text":"<ul> <li>Context propagation is a contract: every long\u2011running or remote execution path must honor <code>context.Context</code> for cancellation and timeouts.</li> <li>Concurrency safety by default: all registries and caches must be thread\u2011safe under concurrent reads/writes.</li> <li>Errors are data: tool errors should be structured and preserved end\u2011to\u2011end rather than surfaced as raw panics.</li> <li>Stable seams first: prioritize interfaces, wiring, and deterministic behaviors before adding new feature surface.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#current-baseline-already-in-place","title":"Current Baseline (already in place)","text":"<p>These libraries and contracts are the foundation and must remain stable:</p> <ul> <li><code>toolfoundation</code> \u2013 core types + adapters + versioning</li> <li><code>tooldiscovery</code> \u2013 registry, docs, search strategies</li> <li><code>toolexec</code> \u2013 execution, orchestration, runtime isolation</li> <li><code>toolcompose</code> \u2013 toolsets + skills</li> <li><code>toolops</code> \u2013 observability, cache, auth, resilience, health</li> <li><code>toolprotocol</code> \u2013 transport, wire, content, session, task primitives</li> </ul> <p>See the canonical stack roadmap for current status and version matrix: <code>ai-tools-stack/docs/roadmap.md</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-0-spec-alignment-server-correctness-p1","title":"Phase 0 \u2014 Spec Alignment &amp; Server Correctness (P1)","text":"<p>Goal: Ensure the MCP server edge is protocol\u2011correct before expanding capability.</p> <ol> <li>MCP spec alignment</li> <li><code>notifications/tools/list_changed</code></li> <li>pagination/cursor consistency</li> <li>cancellation propagation</li> <li>optional progress forwarding</li> </ol> <p>Docs: - Proposal: MCP Spec Alignment - PRD: PRD\u2011180</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-1-core-exposure-mvp-foundation","title":"Phase 1 \u2014 Core Exposure (MVP Foundation)","text":"<p>Goal: Provide CLI, configuration, transport, and provider/backends for production use.</p> <ol> <li>Repo scaffolding + CLI surface</li> <li>Configuration layer</li> <li>Transport layer</li> <li>Tool provider registry</li> <li>Backend registry</li> <li>Middleware chain</li> </ol> <p>Docs: - PRDs: PRD\u2011110, PRD\u2011111,   PRD\u2011112, PRD\u2011113</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-2-protocol-layer","title":"Phase 2 \u2014 Protocol Layer","text":"<p>Goal: Normalize tools into composable, protocol\u2011agnostic sets without changing core semantics.</p> <ol> <li>tooladapter \u2192 now <code>toolfoundation/adapter</code></li> <li>toolset \u2192 now <code>toolcompose/set</code></li> </ol> <p>Docs: - PRD\u2011121 - PRD\u2011150</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-3-crosscutting-observability-caching","title":"Phase 3 \u2014 Cross\u2011Cutting Observability &amp; Caching","text":"<p>Goal: Make the system operationally measurable and resilient.</p> <ol> <li>toolobserve \u2192 now <code>toolops/observe</code></li> <li>toolcache \u2192 now <code>toolops/cache</code></li> </ol> <p>Docs: - PRD\u2011160 - PRD\u2011161</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-4-enterprise-extensions","title":"Phase 4 \u2014 Enterprise Extensions","text":"<p>Goal: Enable scale, isolation, and advanced discovery without destabilizing core APIs.</p> <ol> <li>Multi\u2011tenancy core</li> <li>toolsemantic \u2192 now <code>tooldiscovery/semantic</code></li> </ol> <p>Docs: - Proposal: Multi\u2011Tenancy - PRD\u2011132</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-5-agent-skills","title":"Phase 5 \u2014 Agent Skills","text":"<p>Goal: Higher\u2011level capability composition for reusable workflows.</p> <ol> <li>toolskill \u2192 now <code>toolcompose/skill</code></li> </ol> <p>Docs: - PRD\u2011151</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#phase-6-runtime-expansion","title":"Phase 6 \u2014 Runtime Expansion","text":"<p>Goal: Expand sandbox options and isolation strategies.</p> <ol> <li>toolruntime Docker backend \u2192 now <code>toolexec/runtime</code></li> </ol> <p>Docs: - PRD\u2011141</p>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#go-architecture-review-summary","title":"Go Architecture Review (Summary)","text":"<ul> <li>Context propagation: enforce in all public execution APIs; cancellation must be honored by toolexec/run and toolexec/runtime to avoid leaked goroutines.</li> <li>Concurrency safety: all registries must be RW\u2011safe; avoid maps without guards under write paths.</li> <li>Pagination correctness: use stable cursors and cap limits across list endpoints.</li> <li>Error semantics: preserve tool errors as structured data; avoid panics in runtime paths.</li> <li>Observability: add tracing hooks before multi\u2011tenant and semantic layers to avoid blind spots.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plan-of-record/#reference-docs","title":"Reference Docs","text":"<ul> <li>ROADMAP</li> <li>Pluggable Architecture</li> <li>Implementation Phases</li> <li>Architecture Evaluation</li> <li>Protocol\u2011Agnostic Tools</li> <li>Multi\u2011Tenancy</li> <li>Architecture Review</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/metatools-mcp/usage/#build-and-run-stdio","title":"Build and run (stdio)","text":"<pre><code>go run ./cmd/metatools serve\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#cli-overview","title":"CLI overview","text":"<pre><code>metatools serve --transport=stdio                        # Local/Claude Desktop (default)\nmetatools serve --transport=streamable --port=8080       # HTTP clients (recommended)\nmetatools serve --transport=sse --port=8080              # Legacy HTTP clients (deprecated)\nmetatools version\nmetatools config validate --config examples/metatools.yaml\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#transport-selection","title":"Transport selection","text":"Transport Use Case Protocol <code>stdio</code> Claude Desktop, local CLI clients stdin/stdout JSON-RPC <code>streamable</code> Web apps, REST APIs, remote clients HTTP POST/GET/DELETE (MCP 2025-11-25) <code>sse</code> Legacy web clients HTTP + Server-Sent Events (deprecated)"},{"location":"library-docs-from-repos/metatools-mcp/usage/#streamable-http-recommended-for-http","title":"Streamable HTTP (recommended for HTTP)","text":"<p>Streamable HTTP is the MCP spec (2025-11-25) transport replacing SSE:</p> <pre><code># Basic HTTP server\nmetatools serve --transport=streamable --port=8080\n\n# With TLS\nmetatools serve --transport=streamable --port=443 \\\n  --tls --tls-cert=cert.pem --tls-key=key.pem\n\n# Stateless mode (no session tracking)\nmetatools serve --transport=streamable --port=8080 --stateless\n</code></pre> <p>Protocol flow: 1. Client POSTs JSON-RPC to <code>/mcp</code> with <code>initialize</code> request 2. Server responds with <code>Mcp-Session-Id</code> header 3. Client includes session ID in subsequent requests 4. Client may GET <code>/mcp</code> for server notification stream 5. Client DELETEs <code>/mcp</code> to terminate session</p> <p>YAML configuration: <pre><code>transport:\n  type: streamable\n  http:\n    host: 0.0.0.0\n    port: 8080\n    tls:\n      enabled: true\n      cert: /path/to/cert.pem\n      key: /path/to/key.pem\n  streamable:\n    stateless: false        # Enable session management\n    json_response: false    # Use SSE streaming (default)\n    session_timeout: 30m    # Clean up idle sessions\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#configuration-files-koanf","title":"Configuration files (Koanf)","text":"<p>Config precedence: 1. Defaults 2. Config file (<code>--config</code>) 3. Environment variables (<code>METATOOLS_</code> prefix) 4. CLI flags</p> <p>Example file: <code>examples/metatools.yaml</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#provider-toggles","title":"Provider toggles","text":"<p>Built-in metatools can be enabled/disabled via <code>providers.*.enabled</code> in the config file (see the <code>providers</code> block in <code>examples/metatools.yaml</code>). This controls which MCP tools are registered at startup.</p>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#middleware-chain","title":"Middleware chain","text":"<p>Configure optional middleware in <code>middleware.chain</code> (ordered) with per-middleware settings under <code>middleware.configs</code>. Built-in middleware: <code>auth</code>, <code>logging</code>, <code>metrics</code>, <code>ratelimit</code>, <code>audit</code>.</p> <p>Example (JWT auth + RBAC):</p> <pre><code>middleware:\n  chain: [\"auth\", \"logging\", \"metrics\"]\n  configs:\n    auth:\n      config:\n        allow_anonymous: false\n        authenticators:\n          - name: \"jwt\"\n            config:\n              issuer: \"https://auth.example.com\"\n              audience: \"metatools\"\n              jwks_url: \"https://auth.example.com/.well-known/jwks.json\"\n        authorizer:\n          name: \"simple_rbac\"\n          config:\n            roles:\n              admin:\n                allow:\n                  - tool: \"*\"\n                    actions: [\"call\", \"list\"]\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#enable-bm25-search-build-tag-env","title":"Enable BM25 search (build tag + env)","text":"<pre><code>go build -tags toolsearch ./cmd/metatools\nMETATOOLS_SEARCH_STRATEGY=bm25 ./metatools\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#environment-variables","title":"Environment variables","text":""},{"location":"library-docs-from-repos/metatools-mcp/usage/#cli-defaults-serve-command","title":"CLI defaults (serve command)","text":"<p>These map directly to <code>metatools serve</code> flags when the flags are not set:</p> Variable Default Description <code>METATOOLS_TRANSPORT</code> <code>stdio</code> Transport type: <code>stdio</code>, <code>streamable</code>, <code>sse</code> <code>METATOOLS_PORT</code> <code>8080</code> Port for HTTP transports <code>METATOOLS_HOST</code> <code>0.0.0.0</code> Host/interface for HTTP transports <code>METATOOLS_CONFIG</code> \"\" Path to config file"},{"location":"library-docs-from-repos/metatools-mcp/usage/#transport-configuration-koanf-config","title":"Transport configuration (Koanf config)","text":"<p>These map to the config schema loaded by <code>config.Load</code>:</p> Variable Default Description <code>METATOOLS_TRANSPORT_TYPE</code> <code>stdio</code> Transport type: <code>stdio</code>, <code>streamable</code>, <code>sse</code> <code>METATOOLS_TRANSPORT_HTTP_HOST</code> <code>0.0.0.0</code> Host/interface for HTTP transports <code>METATOOLS_TRANSPORT_HTTP_PORT</code> <code>8080</code> Port for HTTP transports <code>METATOOLS_TRANSPORT_HTTP_TLS_ENABLED</code> <code>false</code> Enable TLS for HTTP transports <code>METATOOLS_TRANSPORT_HTTP_TLS_CERT</code> \"\" TLS certificate path <code>METATOOLS_TRANSPORT_HTTP_TLS_KEY</code> \"\" TLS key path <code>METATOOLS_TRANSPORT_STREAMABLE_STATELESS</code> <code>false</code> Disable session management <code>METATOOLS_TRANSPORT_STREAMABLE_JSON_RESPONSE</code> <code>false</code> Prefer JSON over SSE streaming <code>METATOOLS_TRANSPORT_STREAMABLE_SESSION_TIMEOUT</code> <code>30m</code> Idle session cleanup duration <code>METATOOLS_STATE_RUNTIME_LIMITS_DB</code> \"\" SQLite file for persisted execution limits"},{"location":"library-docs-from-repos/metatools-mcp/usage/#runtime-configuration-toolruntime-build-tag","title":"Runtime configuration (toolruntime build tag)","text":"Variable Default Description <code>METATOOLS_RUNTIME_PROFILE</code> <code>dev</code> <code>dev</code> (unsafe) or <code>standard</code> (Docker) <code>METATOOLS_DOCKER_IMAGE</code> <code>toolruntime-sandbox:latest</code> Docker image for standard profile <code>METATOOLS_WASM_ENABLED</code> <code>false</code> Enable WASM backend (wazero) <code>METATOOLS_RUNTIME_BACKEND</code> <code>docker</code> Preferred standard backend: <code>docker</code> or <code>wasm</code>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#search-configuration","title":"Search configuration","text":"Variable Default Description <code>METATOOLS_SEARCH_STRATEGY</code> <code>lexical</code> <code>lexical</code> or <code>bm25</code> <code>METATOOLS_SEARCH_BM25_NAME_BOOST</code> <code>3</code> BM25 name field boost <code>METATOOLS_SEARCH_BM25_NAMESPACE_BOOST</code> <code>2</code> BM25 namespace field boost <code>METATOOLS_SEARCH_BM25_TAGS_BOOST</code> <code>2</code> BM25 tags field boost <code>METATOOLS_SEARCH_BM25_MAX_DOCS</code> <code>0</code> Max docs to index (0=unlimited) <code>METATOOLS_SEARCH_BM25_MAX_DOCTEXT_LEN</code> <code>0</code> Max doc text length (0=unlimited) <code>METATOOLS_NOTIFY_TOOL_LIST_CHANGED</code> <code>true</code> Emit <code>notifications/tools/list_changed</code> on index updates <code>METATOOLS_NOTIFY_TOOL_LIST_CHANGED_DEBOUNCE_MS</code> <code>150</code> Debounce window for list change notifications"},{"location":"library-docs-from-repos/metatools-mcp/usage/#pagination-and-cursors","title":"Pagination and cursors","text":"<ul> <li><code>search_tools</code> and <code>list_namespaces</code> accept <code>limit</code> (default 20, max 100) and <code>cursor</code>.</li> <li>Responses include <code>nextCursor</code> when more results are available.</li> <li>Cursor tokens are opaque and invalid cursors return JSON-RPC invalid params.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#tool-list-change-notifications","title":"Tool list change notifications","text":"<ul> <li><code>notifications/tools/list_changed</code> is emitted when the underlying tooldiscovery/index changes.</li> <li>Notifications are debounced to avoid client spam and can be disabled with <code>METATOOLS_NOTIFY_TOOL_LIST_CHANGED=false</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#progress-notifications","title":"Progress notifications","text":"<p>When callers supply a progress token, <code>run_tool</code>, <code>run_chain</code>, and <code>execute_code</code> emit progress notifications. If the runner exposes progress callbacks, step-level updates are forwarded; otherwise a coarse start/end signal is emitted.</p>"},{"location":"library-docs-from-repos/metatools-mcp/usage/#optional-toolruntime-support","title":"Optional toolruntime support","text":"<pre><code>go run -tags toolruntime ./cmd/metatools\n</code></pre> <p>This enables <code>execute_code</code> backed by a <code>toolexec/runtime</code> engine. By default it uses the <code>dev</code> (unsafe) profile; set <code>METATOOLS_RUNTIME_PROFILE=standard</code> to enable the Docker backend when available. To use WASM instead, set <code>METATOOLS_WASM_ENABLED=true</code> and <code>METATOOLS_RUNTIME_BACKEND=wasm</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/","title":"User Journey","text":"<p>This journey shows the full end-to-end agent workflow via MCP metatools.</p>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#transport-selection","title":"Transport selection","text":"<p>Before tool discovery begins, clients establish a connection via one of the supported transports. The transport choice depends on the client environment:</p> <pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0'}}}%%\nflowchart LR\n    subgraph clients[\"Clients\"]\n        Claude[\"\ud83d\udda5\ufe0f Claude Desktop\"]\n        WebApp[\"\ud83c\udf10 Web Application\"]\n        CLI[\"\u2328\ufe0f CLI Tool\"]\n    end\n\n    subgraph transports[\"Transport Layer\"]\n        Stdio[\"\ud83d\udcdf stdio&lt;br/&gt;&lt;small&gt;stdin/stdout&lt;/small&gt;\"]\n        Streamable[\"\ud83d\udd04 streamable&lt;br/&gt;&lt;small&gt;HTTP POST/GET/DELETE&lt;/small&gt;\"]\n        SSE[\"\ud83d\udce1 sse&lt;br/&gt;&lt;small&gt;deprecated&lt;/small&gt;\"]\n    end\n\n    subgraph server[\"metatools-mcp\"]\n        MCP[\"\ud83d\udd37 MCP Server\"]\n    end\n\n    Claude --&gt; Stdio --&gt; MCP\n    WebApp --&gt; Streamable --&gt; MCP\n    CLI --&gt; Stdio --&gt; MCP\n    WebApp -.-&gt; SSE -.-&gt; MCP\n\n    style clients fill:#4a5568,stroke:#2d3748\n    style transports fill:#805ad5,stroke:#6b46c1\n    style server fill:#2b6cb0,stroke:#2c5282\n    style SSE fill:#718096,stroke:#4a5568,stroke-dasharray: 5 5</code></pre> Transport Client Type Session Protocol <code>stdio</code> Local CLI, Claude Desktop Implicit stdin/stdout JSON-RPC <code>streamable</code> Web apps, remote clients Mcp-Session-Id header HTTP (MCP 2025-11-25) <code>sse</code> Legacy web clients Cookie-based HTTP + SSE (deprecated) <p>Streamable HTTP session flow: 1. Client POSTs <code>initialize</code> request to <code>/mcp</code> 2. Server returns <code>Mcp-Session-Id</code> header 3. Client includes session ID in all subsequent requests 4. Client may open GET stream for server notifications 5. Client sends DELETE to terminate session</p>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#end-to-end-flow-agent-view","title":"End-to-end flow (agent view)","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0', 'primaryTextColor': '#fff'}}}%%\nsequenceDiagram\n    autonumber\n\n    participant Agent as \ud83e\udd16 AI Agent\n    participant Transport as \ud83d\udd04 Transport\n    participant MCP as \ud83d\udd37 metatools-mcp\n    participant Index as \ud83d\udcc7 tooldiscovery/index\n    participant Docs as \ud83d\udcda tooldiscovery/tooldoc\n    participant Run as \u25b6\ufe0f toolexec/run\n    participant Code as \ud83d\udcbb toolexec/code\n\n    rect rgb(128, 90, 213, 0.1)\n        Note over Agent,MCP: Phase 0: Connection\n        Agent-&gt;&gt;+Transport: Connect (stdio/streamable/sse)\n        Transport-&gt;&gt;+MCP: initialize\n        MCP--&gt;&gt;-Transport: capabilities + session\n        Transport--&gt;&gt;-Agent: Ready\n    end\n\n    rect rgb(43, 108, 176, 0.1)\n        Note over Agent,Index: Phase 1: Discovery\n        Agent-&gt;&gt;+MCP: search_tools(\"create issue\", 5)\n        MCP-&gt;&gt;+Index: Search(query, limit)\n        Index--&gt;&gt;-MCP: Summary[]\n        MCP--&gt;&gt;-Agent: summaries (no schemas)\n    end\n\n    rect rgb(214, 158, 46, 0.1)\n        Note over Agent,Docs: Phase 2: Documentation\n        Agent-&gt;&gt;+MCP: describe_tool(id, \"schema\")\n        MCP-&gt;&gt;+Docs: DescribeTool(id, DetailSchema)\n        Docs--&gt;&gt;-MCP: ToolDoc\n        MCP--&gt;&gt;-Agent: tool schema + description\n    end\n\n    rect rgb(56, 161, 105, 0.1)\n        Note over Agent,Run: Phase 3: Execution\n        Agent-&gt;&gt;+MCP: run_tool(id, args)\n        MCP-&gt;&gt;+Run: Run(ctx, id, args)\n        Run--&gt;&gt;-MCP: RunResult\n        MCP--&gt;&gt;-Agent: result\n    end\n\n    rect rgb(107, 70, 193, 0.1)\n        Note over Agent,Code: Phase 4: Orchestration (optional)\n        Agent-&gt;&gt;+MCP: execute_code(snippet)\n        MCP-&gt;&gt;+Code: ExecuteCode(ctx, params)\n        Code--&gt;&gt;-MCP: ExecuteResult\n        MCP--&gt;&gt;-Agent: value + tool calls\n    end</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#mcp-tool-surface","title":"MCP Tool Surface","text":"<pre><code>%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#2b6cb0'}}}%%\nflowchart TB\n    subgraph agent[\"AI Agent\"]\n        Request[\"\ud83d\udce5 MCP Request&lt;br/&gt;&lt;small&gt;JSON-RPC&lt;/small&gt;\"]\n    end\n\n    subgraph transport[\"Transport Layer\"]\n        Stdio[\"\ud83d\udcdf stdio\"]\n        Streamable[\"\ud83d\udd04 streamable\"]\n    end\n\n    subgraph metatools[\"metatools-mcp\"]\n        Server[\"\ud83d\udd37 MCP Server\"]\n\n        subgraph discovery[\"Discovery Tools\"]\n            SearchTools[\"\ud83d\udd0d search_tools\"]\n            ListNS[\"\ud83d\udcc1 list_namespaces\"]\n        end\n\n        subgraph docs[\"Documentation Tools\"]\n            DescribeTool[\"\ud83d\udcda describe_tool\"]\n            ListExamples[\"\ud83d\udca1 list_tool_examples\"]\n        end\n\n        subgraph execution[\"Execution Tools\"]\n            RunTool[\"\u25b6\ufe0f run_tool\"]\n            RunChain[\"\ud83d\udd17 run_chain\"]\n        end\n\n        subgraph orchestration[\"Orchestration (optional)\"]\n            ExecCode[\"\ud83d\udcbb execute_code\"]\n        end\n    end\n\n    subgraph stack[\"Stack Libraries\"]\n        Index[\"\ud83d\udcc7 tooldiscovery/index\"]\n        Docs2[\"\ud83d\udcda tooldiscovery/tooldoc\"]\n        Run[\"\u25b6\ufe0f toolexec/run\"]\n        Code[\"\ud83d\udcbb toolexec/code\"]\n    end\n\n    Request --&gt; Stdio &amp; Streamable --&gt; Server\n    Server --&gt; SearchTools --&gt; Index\n    Server --&gt; ListNS --&gt; Index\n    Server --&gt; DescribeTool --&gt; Docs2\n    Server --&gt; ListExamples --&gt; Docs2\n    Server --&gt; RunTool --&gt; Run\n    Server --&gt; RunChain --&gt; Run\n    Server --&gt; ExecCode --&gt; Code\n\n    style agent fill:#4a5568,stroke:#2d3748\n    style transport fill:#805ad5,stroke:#6b46c1\n    style metatools fill:#2b6cb0,stroke:#2c5282,stroke-width:2px\n    style discovery fill:#3182ce,stroke:#2c5282\n    style docs fill:#d69e2e,stroke:#b7791f\n    style execution fill:#38a169,stroke:#276749\n    style orchestration fill:#6b46c1,stroke:#553c9a\n    style stack fill:#718096,stroke:#4a5568</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#step-by-step","title":"Step-by-step","text":"<ol> <li>Connect via transport (stdio for local, streamable HTTP for remote).</li> <li>Discover tools with <code>search_tools</code> (summary-only results).</li> <li>Inspect schema using <code>describe_tool</code> (schema or full detail).</li> <li>Execute a single tool with <code>run_tool</code> or a sequence with <code>run_chain</code>.</li> <li>Orchestrate complex flows using <code>execute_code</code> (optional).</li> </ol> <p>When built with <code>-tags toolruntime</code>, <code>execute_code</code> runs in a sandboxed toolexec/runtime. Default profile is <code>dev</code> (unsafe); set <code>METATOOLS_RUNTIME_PROFILE=standard</code> to enable Docker when available. Set <code>METATOOLS_WASM_ENABLED=true</code> and <code>METATOOLS_RUNTIME_BACKEND=wasm</code> to use the WASM backend instead.</p>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#example-full-agent-workflow","title":"Example: full agent workflow","text":"<pre><code>1) search_tools(\"create issue\", limit=5)\n2) describe_tool(\"github:create_issue\", detail_level=\"schema\")\n3) run_tool(\"github:create_issue\", args={...})\n4) run_chain([{tool_id:\"github:get_issue\"}, {tool_id:\"github:add_label\", use_previous:true}])\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#expected-outcomes","title":"Expected outcomes","text":"<ul> <li>Stable MCP-compatible APIs for discovery, documentation, and execution.</li> <li>Consistent error objects for tool failures.</li> <li>Progressive disclosure to minimize token costs.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/user-journey/#common-failure-modes","title":"Common failure modes","text":"<ul> <li>Invalid input payloads (handler validation errors).</li> <li>Tool-level errors returned in <code>ErrorObject</code> with <code>code</code> and <code>op</code> fields.</li> <li>Unsupported options (e.g., <code>stream=true</code> for <code>run_tool</code>).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/data-flow/","title":"Data Flow","text":""},{"location":"library-docs-from-repos/metatools-mcp/diagrams/data-flow/#overview","title":"Overview","text":"<p>End-to-end flow for discovery and execution requests across the stack.</p>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/data-flow/#diagram","title":"Diagram","text":"<pre><code>sequenceDiagram\n    autonumber\n    actor Agent\n    participant MCP as metatools-mcp\n    participant Discovery as tooldiscovery\n    participant Compose as toolcompose\n    participant Exec as toolexec\n    participant Ops as toolops\n    participant Proto as toolprotocol\n    participant Provider as External Tool Provider\n\n    Agent-&gt;&gt;MCP: tools/search\n    MCP-&gt;&gt;Discovery: search(query)\n    Discovery--&gt;&gt;MCP: results\n    MCP--&gt;&gt;Agent: tool list\n\n    Agent-&gt;&gt;MCP: tools/call\n    MCP-&gt;&gt;Compose: select toolset/policy\n    Compose--&gt;&gt;MCP: allowed tool(s)\n    MCP-&gt;&gt;Exec: run(tool, input)\n    Exec-&gt;&gt;Ops: observe/cache/resilience/auth\n    Ops--&gt;&gt;Exec: policy + telemetry\n    Exec-&gt;&gt;Proto: encode + transport\n    Proto-&gt;&gt;Provider: request\n    Provider--&gt;&gt;Proto: response\n    Proto--&gt;&gt;Exec: decoded result\n    Exec--&gt;&gt;MCP: result\n    MCP--&gt;&gt;Agent: output</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/dependency-graph/","title":"Dependency Graph","text":""},{"location":"library-docs-from-repos/metatools-mcp/diagrams/dependency-graph/#overview","title":"Overview","text":"<p>Inter-repo dependencies (conceptual view). Higher layers depend on lower layers only.</p>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/dependency-graph/#diagram","title":"Diagram","text":"<pre><code>graph LR\n    mcp[\"MCP Go SDK\"]\n\n    toolfoundation[\"toolfoundation\"]\n    tooldiscovery[\"tooldiscovery\"]\n    toolexec[\"toolexec\"]\n    toolcompose[\"toolcompose\"]\n    toolops[\"toolops\"]\n    toolprotocol[\"toolprotocol\"]\n    metatools[\"metatools-mcp\"]\n\n    tooldiscovery --&gt; toolfoundation\n    toolexec --&gt; toolfoundation\n    toolexec --&gt; tooldiscovery\n    toolcompose --&gt; toolfoundation\n    toolops --&gt; toolfoundation\n    toolprotocol --&gt; toolfoundation\n\n    toolprotocol --&gt; mcp\n\n    metatools --&gt; toolprotocol\n    metatools --&gt; toolops\n    metatools --&gt; toolcompose\n    metatools --&gt; toolexec\n    metatools --&gt; tooldiscovery\n    metatools --&gt; toolfoundation</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/layer-architecture/","title":"Layer Architecture","text":""},{"location":"library-docs-from-repos/metatools-mcp/diagrams/layer-architecture/#overview","title":"Overview","text":"<p>The ApertureStack ecosystem is organized into layered tiers. Each higher tier depends on lower tiers only.</p>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/layer-architecture/#diagram","title":"Diagram","text":"<pre><code>graph TB\n    subgraph \"Tier 8: Application\"\n        metatools[\"metatools-mcp\\n(MCP Server)\"]\n    end\n\n    subgraph \"Tier 7: Protocol\"\n        toolprotocol[\"toolprotocol\"]\n        subgraph \"toolprotocol packages\"\n            transport[\"transport\"]\n            wire[\"wire\"]\n            discover[\"discover\"]\n            content[\"content\"]\n            task[\"task\"]\n            stream[\"stream\"]\n            session[\"session\"]\n            elicit[\"elicit\"]\n            resource[\"resource\"]\n            prompt[\"prompt\"]\n        end\n    end\n\n    subgraph \"Tier 6: Operations\"\n        toolops[\"toolops\"]\n        subgraph \"toolops packages\"\n            observe[\"observe\"]\n            cache[\"cache\"]\n            resilience[\"resilience\"]\n            health[\"health\"]\n            auth[\"auth\"]\n        end\n    end\n\n    subgraph \"Tier 5: Composition\"\n        toolcompose[\"toolcompose\"]\n        subgraph \"toolcompose packages\"\n            set[\"set\"]\n            skill[\"skill\"]\n        end\n    end\n\n    subgraph \"Tier 4: Execution\"\n        toolexec[\"toolexec\"]\n        subgraph \"toolexec packages\"\n            run[\"run\"]\n            runtime[\"runtime\"]\n            code[\"code\"]\n            backend[\"backend\"]\n        end\n    end\n\n    subgraph \"Tier 3: Discovery\"\n        tooldiscovery[\"tooldiscovery\"]\n        subgraph \"tooldiscovery packages\"\n            index[\"index\"]\n            search[\"search\"]\n            semantic[\"semantic\"]\n            docs[\"tooldoc\"]\n        end\n    end\n\n    subgraph \"Tier 2: Foundation\"\n        toolfoundation[\"toolfoundation\"]\n        subgraph \"toolfoundation packages\"\n            model[\"model\"]\n            adapter[\"adapter\"]\n            version[\"version\"]\n        end\n    end\n\n    subgraph \"Tier 1: External\"\n        mcp[\"MCP Go SDK\"]\n    end\n\n    metatools --&gt; toolprotocol\n    metatools --&gt; toolops\n    metatools --&gt; toolcompose\n    metatools --&gt; toolexec\n    metatools --&gt; tooldiscovery\n    metatools --&gt; toolfoundation\n\n    toolprotocol --&gt; toolfoundation\n    toolops --&gt; toolfoundation\n    toolcompose --&gt; toolfoundation\n    toolexec --&gt; toolfoundation\n    tooldiscovery --&gt; toolfoundation\n\n    toolprotocol --&gt; mcp</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/protocol-adapters/","title":"Protocol Adapters","text":""},{"location":"library-docs-from-repos/metatools-mcp/diagrams/protocol-adapters/#overview","title":"Overview","text":"<p><code>toolprotocol</code> provides transport and wire adapters to support multiple client/server protocols.</p>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/protocol-adapters/#diagram","title":"Diagram","text":"<pre><code>graph LR\n    model[\"toolfoundation/model\"] --&gt; wire[\"toolprotocol/wire\"]\n    wire --&gt; transport[\"toolprotocol/transport\"]\n\n    transport --&gt; mcp[\"MCP (JSON-RPC)\"]\n    transport --&gt; sse[\"SSE\"]\n    transport --&gt; stdio[\"stdio\"]\n    transport --&gt; http[\"HTTP/JSON\"]\n    transport --&gt; grpc[\"gRPC\"]\n\n    wire --&gt; adapters[\"Protocol Adapters\"]\n    adapters --&gt; openai[\"OpenAI tools\"]\n    adapters --&gt; anthropic[\"Anthropic tools\"]\n    adapters --&gt; custom[\"Custom adapters\"]</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/repository-map/","title":"Repository Map","text":""},{"location":"library-docs-from-repos/metatools-mcp/diagrams/repository-map/#overview","title":"Overview","text":"<p>This map shows the six consolidated repositories and the packages they contain.</p>"},{"location":"library-docs-from-repos/metatools-mcp/diagrams/repository-map/#diagram","title":"Diagram","text":"<pre><code>graph TB\n    subgraph toolfoundation\n        tf_model[\"model\"]\n        tf_adapter[\"adapter\"]\n        tf_version[\"version\"]\n    end\n\n    subgraph tooldiscovery\n        td_index[\"index\"]\n        td_search[\"search\"]\n        td_semantic[\"semantic\"]\n        td_doc[\"tooldoc\"]\n    end\n\n    subgraph toolexec\n        te_run[\"run\"]\n        te_runtime[\"runtime\"]\n        te_code[\"code\"]\n        te_backend[\"backend\"]\n    end\n\n    subgraph toolcompose\n        tc_set[\"set\"]\n        tc_skill[\"skill\"]\n    end\n\n    subgraph toolops\n        to_observe[\"observe\"]\n        to_cache[\"cache\"]\n        to_auth[\"auth\"]\n        to_resilience[\"resilience\"]\n        to_health[\"health\"]\n    end\n\n    subgraph toolprotocol\n        tp_transport[\"transport\"]\n        tp_wire[\"wire\"]\n        tp_discover[\"discover\"]\n        tp_content[\"content\"]\n        tp_task[\"task\"]\n        tp_stream[\"stream\"]\n        tp_session[\"session\"]\n        tp_elicit[\"elicit\"]\n        tp_resource[\"resource\"]\n        tp_prompt[\"prompt\"]\n    end</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/","title":"ApertureStack Consolidation PRDs (Archived)","text":"<p>All consolidation PRDs were moved to <code>docs/plans/archive/</code>.</p> <ul> <li>Canonical roadmap: <code>ai-tools-stack/docs/roadmap.md</code></li> <li>Archived PRDs index: <code>docs/plans/archive/README.md</code></li> <li>Active plan(s): <code>docs/plans/2026-01-30-prd-017-auth-middleware.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/","title":"PRD-017: Pluggable Authentication &amp; Authorization Middleware","text":"<p>Status: Complete Date: 2026-02-03 Priority: P1 (High) Depends On: PRD-016 (Interface Contracts) [archived] Proposal: <code>../proposals/auth-middleware.md</code> Architecture: <code>../proposals/persistence-boundary.md</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#overview","title":"Overview","text":"<p>Consolidate authentication and authorization behind toolops/auth and wire it into <code>metatools-mcp</code> as middleware. This replaces duplicate auth code and provides a single contract for identity, authorization, and request context propagation.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#goals","title":"Goals","text":"<ul> <li>Use <code>toolops/auth</code> as the only auth source of truth.</li> <li>Enforce auth for discovery + execution in <code>metatools-mcp</code>.</li> <li>Propagate identity into request context for downstream policy checks.</li> <li>Provide a simple config surface for selecting auth strategies.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#non-goals","title":"Non-Goals","text":"<ul> <li>Full IAM system or user management.</li> <li>Multi-tenancy (separate proposal).</li> <li>Long-term persistence of auth state (see persistence-boundary proposal).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#scope","title":"Scope","text":"<ul> <li>Replace <code>metatools-mcp/internal/auth</code> usage with <code>toolops/auth</code>.</li> <li>Add auth middleware in <code>metatools-mcp/internal/middleware</code> using <code>toolops/auth</code>.</li> <li>Update config and docs to describe auth setup.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Replaced internal auth usage with <code>toolops/auth</code> (transport + middleware).</li> <li>Added auth middleware factory in <code>metatools-mcp/internal/middleware</code>.</li> <li>Updated middleware registry and docs/examples to reflect new config.</li> <li>Removed duplicated internal auth implementation.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li><code>metatools-mcp</code> uses <code>toolops/auth</code> for all auth decisions.</li> <li>No duplicated auth implementation remains in the reference server.</li> <li>Tests cover allow/deny paths for discovery + execution.</li> <li>Docs show clear setup steps.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#risks","title":"Risks","text":"<ul> <li>Divergent auth semantics between old and new implementations.</li> <li>Breaking change for users relying on internal auth types.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/2026-01-30-prd-017-auth-middleware/#references","title":"References","text":"<ul> <li><code>toolops/auth</code></li> <li><code>metatools-mcp/internal/middleware</code></li> <li><code>ai-tools-stack/docs/roadmap.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/","title":"ApertureStack Consolidation PRDs","text":"<p>This directory contains historical Product Requirement Documents for the ApertureStack consolidation from 15 standalone repositories into 6 consolidated repositories.</p> <p>Canonical roadmap: <code>ai-tools-stack/docs/roadmap.md</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#quick-links","title":"Quick Links","text":"<ul> <li>Master Plan - Executive overview</li> <li>Order of Operations - Execution sequence</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#prd-summary","title":"PRD Summary","text":"<p>Total PRDs: 41 Total Effort: 236 hours (~29.5 days) Timeline: 6-8 weeks with parallelization</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#phase-0-planning-documentation-12h","title":"Phase 0: Planning &amp; Documentation (12h)","text":"PRD Title Effort Status PRD-100 Master Consolidation Plan 4h Done PRD-101 Architecture Diagrams 4h Done PRD-102 Schema Definitions 4h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#phase-1-infrastructure-setup-16h","title":"Phase 1: Infrastructure Setup (16h)","text":"PRD Title Effort Status PRD-110 Repository Creation 8h Done PRD-111 CI/CD Templates 4h Done PRD-112 GitHub Org Config 2h Done PRD-113 Release Automation 2h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#phase-2-foundation-layer-toolfoundation-16h","title":"Phase 2: Foundation Layer - toolfoundation (16h)","text":"PRD Title Effort Status PRD-120 Migrate toolmodel 4h Done PRD-121 Migrate tooladapter 4h Done PRD-122 Create toolversion 8h Done PRD-123 Docs + README alignment 3h Done PRD-124 Schema validation policy docs 2h Done PRD-125 Adapter feature matrix docs 2h Done PRD-126 Version package usage docs 2h Done PRD-127 Contract verification 1h Done PRD-128 Release + propagation 1h Done PRD-129 Gate G2 validation 1h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#phase-3-discovery-layer-tooldiscovery-18h","title":"Phase 3: Discovery Layer - tooldiscovery (18h)","text":"PRD Title Effort Status PRD-130 Migrate toolindex 4h Done PRD-131 Migrate toolsearch 4h Done PRD-132 Migrate toolsemantic 6h Done PRD-133 Migrate tooldocs 4h Done PRD-134 Docs + README alignment 2h Done PRD-135 Search strategy policy docs 2h Done PRD-136 Semantic contracts docs 2h Done PRD-137 Progressive docs details 2h Done PRD-138 Release + propagation 1h Done PRD-139 Discovery validation 1h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#phase-4-execution-layer-toolexec-18h","title":"Phase 4: Execution Layer - toolexec (18h)","text":"PRD Title Effort Status PRD-140 Migrate toolrun 4h Done PRD-141 Migrate toolruntime 4h Done PRD-142 Migrate toolcode 4h Done PRD-143 Extract toolbackend 6h Done PRD-144 toolexec docs alignment 2h Done PRD-145 Runtime security profile docs 2h Done PRD-146 Backend matrix docs 2h Done PRD-147 Toolcode/runtime contract docs 2h Done PRD-148 Release + propagation 1h Done PRD-149 toolexec validation 1h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#phase-5-composition-layer-toolcompose-12h","title":"Phase 5: Composition Layer - toolcompose (12h)","text":"PRD Title Effort Status PRD-150 Migrate toolset 4h Done PRD-151 Complete toolskill 8h Done PRD-152 toolcompose docs alignment 2h Done PRD-153 set filter/policy docs 2h Done PRD-154 skill contract docs 2h Done PRD-155 user journey + examples 2h Done PRD-156 docs site integration 1h Done PRD-157 Release + propagation 1h Done PRD-158 toolcompose validation 1h Done PRD-159 docs publish readiness 1h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#phase-6-operations-layer-toolops-30h","title":"Phase 6: Operations Layer - toolops (30h)","text":"PRD Title Effort Status PRD-160 Migrate toolobserve 4h Done PRD-161 Migrate toolcache 4h Done PRD-162 Extract toolauth 8h Done PRD-163 Create toolresilience 8h Done PRD-164 Create toolhealth 6h Done PRD-165 toolops docs alignment 2h Done PRD-166 observe contracts docs 2h Done PRD-167 cache policy docs 2h Done PRD-168 auth/health/resilience docs 2h Done PRD-169 release + validation 2h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#phase-7-protocol-layer-toolprotocol-84h","title":"Phase 7: Protocol Layer - toolprotocol (84h)","text":"PRD Title Effort Status PRD-170 Create tooltransport 8h Done PRD-171 Create toolwire 12h Done PRD-172 Create tooldiscover 8h Done PRD-173 Create toolcontent 8h Done PRD-174 Create tooltask 10h Done PRD-175 Create toolstream 8h Done PRD-176 Create toolsession 6h Done PRD-177 Create toolelicit 6h Done PRD-178 Create toolresource 10h Done PRD-179 Create toolprompt 8h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#phase-8-integration-22h","title":"Phase 8: Integration (22h)","text":"PRD Title Effort Status PRD-180 Update metatools-mcp 12h Done PRD-181 Update ai-tools-stack 4h Done PRD-182 Documentation Site 6h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#phase-9-cleanup-8h","title":"Phase 9: Cleanup (8h)","text":"PRD Title Effort Status PRD-190 Archive Old Repos 2h Done PRD-191 Update Submodules 2h Done PRD-192 Validation 4h Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#checkpoint-gates","title":"Checkpoint Gates","text":"Gate After PRD Validation G1 PRD-113 All repos created, CI working G2 PRD-122 Foundation layer complete G3 PRD-143 Discovery + Execution layers complete G4 PRD-164 Composition + Operations layers complete G5 PRD-179 Protocol layer complete G6 PRD-182 Integration complete G7 PRD-192 Full validation complete"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#consolidated-repositories","title":"Consolidated Repositories","text":"Repository Packages toolfoundation model, adapter, version tooldiscovery index, search, semantic, docs toolexec run, runtime, code, backend toolcompose set, skill toolops observe, cache, resilience, health, auth toolprotocol transport, wire, discover, content, task, stream, session, elicit, resource, prompt"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/#previous-plans","title":"Previous Plans","text":"Item File Status PRD-016 <code>2026-01-30-prd-016-interface-contracts.md</code> Done PRD-017 <code>2026-01-30-prd-017-auth-middleware.md</code> Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/","title":"PRD-016 Execution Plan \u2014 metatools-mcp (TDD)","text":"<p>Status: Done Date: 2026-01-30 PRD: <code>2026-01-30-prd-016-interface-contracts.md</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#tdd-workflow-required","title":"TDD Workflow (required)","text":"<ol> <li>Red \u2014 write failing contract tests</li> <li>Red verification \u2014 run tests</li> <li>Green \u2014 minimal code/doc changes</li> <li>Green verification \u2014 run tests</li> <li>Commit \u2014 one commit per task</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#task-0-inventory-contract-outline","title":"Task 0 \u2014 Inventory + contract outline","text":"<ul> <li>Confirm interface list and method signatures.</li> <li>Draft explicit contract bullets for each interface.</li> <li>Update docs/plans/README.md with this PRD + plan.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#task-1-contract-tests-redgreen","title":"Task 1 \u2014 Contract tests (Red/Green)","text":"<ul> <li>Add <code>*_contract_test.go</code> with tests for each interface listed below.</li> <li>Use stub implementations where needed.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#task-2-godoc-contracts","title":"Task 2 \u2014 GoDoc contracts","text":"<ul> <li>Add/expand GoDoc on each interface with explicit contract clauses (thread-safety, errors, context, ownership).</li> <li>Update README/design-notes if user-facing.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#task-3-verification","title":"Task 3 \u2014 Verification","text":"<ul> <li>Run <code>go test ./...</code></li> <li>Run linters if configured (golangci-lint / gosec).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#test-skeletons-contract_testgo","title":"Test Skeletons (contract_test.go)","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#metricscollector","title":"MetricsCollector","text":"<pre><code>func TestMetricsCollector_Contract(t *testing.T) {\n    // Methods:\n    // - Start(tool string)\n    // - Finish(tool string, err error, duration time.Duration)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#server","title":"Server","text":"<pre><code>func TestServer_Contract(t *testing.T) {\n    // Methods:\n    // - Run(ctx context.Context, transport mcp.Transport) error\n    // - MCPServer() *mcp.Server\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#transport","title":"Transport","text":"<pre><code>func TestTransport_Contract(t *testing.T) {\n    // Methods:\n    // - Name() string\n    // - Info() Info\n    // - Serve(ctx context.Context, server Server) error\n    // - Close() error\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#toolprovider","title":"ToolProvider","text":"<pre><code>func TestToolProvider_Contract(t *testing.T) {\n    // Methods:\n    // - Name() string\n    // - Enabled() bool\n    // - Tool() mcp.Tool\n    // - Handle(ctx context.Context, req *mcp.CallToolRequest, args map[string]any) (*mcp.CallToolResult, any, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#configurableprovider","title":"ConfigurableProvider","text":"<pre><code>func TestConfigurableProvider_Contract(t *testing.T) {\n    // Methods:\n    // - ToolProvider\n    // - Configure(cfg map[string]any) error\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#streamingprovider","title":"StreamingProvider","text":"<pre><code>func TestStreamingProvider_Contract(t *testing.T) {\n    // Methods:\n    // - ToolProvider\n    // - HandleStream(ctx context.Context, req *mcp.CallToolRequest, args map[string]any) (&lt;-chan any, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#backend","title":"Backend","text":"<pre><code>func TestBackend_Contract(t *testing.T) {\n    // Methods:\n    // - Kind() string\n    // - Name() string\n    // - Enabled() bool\n    // - ListTools(ctx context.Context) ([]toolmodel.Tool, error)\n    // - Execute(ctx context.Context, tool string, args map[string]any) (any, error)\n    // - Start(ctx context.Context) error\n    // - Stop() error\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#configurablebackend","title":"ConfigurableBackend","text":"<pre><code>func TestConfigurableBackend_Contract(t *testing.T) {\n    // Methods:\n    // - Backend\n    // - Configure(raw []byte) error\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#streamingbackend","title":"StreamingBackend","text":"<pre><code>func TestStreamingBackend_Contract(t *testing.T) {\n    // Methods:\n    // - Backend\n    // - ExecuteStream(ctx context.Context, tool string, args map[string]any) (&lt;-chan any, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#index","title":"Index","text":"<pre><code>func TestIndex_Contract(t *testing.T) {\n    // Methods:\n    // - SearchPage(ctx context.Context, query string, limit int, cursor string) ([]metatools.ToolSummary, string, error)\n    // - ListNamespacesPage(ctx context.Context, limit int, cursor string) ([]string, string, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#store","title":"Store","text":"<pre><code>func TestStore_Contract(t *testing.T) {\n    // Methods:\n    // - DescribeTool(ctx context.Context, id string, level string) (ToolDoc, error)\n    // - ListExamples(ctx context.Context, id string, maxExamples int) ([]metatools.ToolExample, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#runner","title":"Runner","text":"<pre><code>func TestRunner_Contract(t *testing.T) {\n    // Methods:\n    // - Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)\n    // - RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#progressrunner","title":"ProgressRunner","text":"<pre><code>func TestProgressRunner_Contract(t *testing.T) {\n    // Methods:\n    // - RunWithProgress(ctx context.Context, toolID string, args map[string]any, onProgress func(ProgressEvent)) (RunResult, error)\n    // - RunChainWithProgress(ctx context.Context, steps []ChainStep, onProgress func(ProgressEvent)) (RunResult, []StepResult, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-execution-plan/#executor","title":"Executor","text":"<pre><code>func TestExecutor_Contract(t *testing.T) {\n    // Methods:\n    // - ExecuteCode(ctx context.Context, params ExecuteParams) (ExecuteResult, error)\n    // Contract assertions:\n    // - Concurrency guarantees documented and enforced\n    // - Error semantics (types/wrapping) validated\n    // - Context cancellation respected (if applicable)\n    // - Deterministic ordering where required\n    // - Nil/zero input handling specified\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-interface-contracts/","title":"PRD-016 Interface Contracts \u2014 metatools-mcp","text":"<p>Status: Done Date: 2026-01-30</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-interface-contracts/#overview","title":"Overview","text":"<p>Define explicit interface contracts (GoDoc + documented semantics) for all interfaces in this repo. Contracts must state concurrency guarantees, error semantics, ownership of inputs/outputs, and context handling.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-interface-contracts/#goals","title":"Goals","text":"<ul> <li>Every interface has explicit GoDoc describing behavioral contract.</li> <li>Contract behavior is codified in tests (contract tests).</li> <li>Docs/README updated where behavior is user-facing.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-interface-contracts/#non-goals","title":"Non-Goals","text":"<ul> <li>No API shape changes unless required to satisfy the contract tests.</li> <li>No new features beyond contract clarity and tests.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-interface-contracts/#interface-inventory","title":"Interface Inventory","text":"Interface File Methods <code>MetricsCollector</code> <code>metatools-mcp/internal/middleware/metrics.go:22</code> Start(tool string)Finish(tool string, err error, duration time.Duration) <code>Server</code> <code>metatools-mcp/internal/transport/transport.go:10</code> Run(ctx context.Context, transport mcp.Transport) errorMCPServer() *mcp.Server <code>Transport</code> <code>metatools-mcp/internal/transport/transport.go:23</code> Name() stringInfo() InfoServe(ctx context.Context, server Server) errorClose() error <code>ToolProvider</code> <code>metatools-mcp/internal/provider/provider.go:11</code> Name() stringEnabled() boolTool() mcp.ToolHandle(ctx context.Context, req mcp.CallToolRequest, args map[string]any) (mcp.CallToolResult, any, error) <code>ConfigurableProvider</code> <code>metatools-mcp/internal/provider/provider.go:27</code> ToolProviderConfigure(cfg map[string]any) error <code>StreamingProvider</code> <code>metatools-mcp/internal/provider/provider.go:35</code> ToolProviderHandleStream(ctx context.Context, req *mcp.CallToolRequest, args map[string]any) (&lt;-chan any, error) <code>Backend</code> <code>toolexec/backend/backend.go:20</code> Kind() stringName() stringEnabled() boolListTools(ctx context.Context) ([]toolmodel.Tool, error)Execute(ctx context.Context, tool string, args map[string]any) (any, error)Start(ctx context.Context) errorStop() error <code>ConfigurableBackend</code> <code>toolexec/backend/backend.go:44</code> BackendConfigure(raw []byte) error <code>StreamingBackend</code> <code>toolexec/backend/backend.go:51</code> BackendExecuteStream(ctx context.Context, tool string, args map[string]any) (&lt;-chan any, error) <code>Index</code> <code>metatools-mcp/internal/handlers/interfaces.go:10</code> SearchPage(ctx context.Context, query string, limit int, cursor string) ([]metatools.ToolSummary, string, error)ListNamespacesPage(ctx context.Context, limit int, cursor string) ([]string, string, error) <code>Store</code> <code>metatools-mcp/internal/handlers/interfaces.go:26</code> DescribeTool(ctx context.Context, id string, level string) (ToolDoc, error)ListExamples(ctx context.Context, id string, maxExamples int) ([]metatools.ToolExample, error) <code>Runner</code> <code>metatools-mcp/internal/handlers/interfaces.go:64</code> Run(ctx context.Context, toolID string, args map[string]any) (RunResult, error)RunChain(ctx context.Context, steps []ChainStep) (RunResult, []StepResult, error) <code>ProgressRunner</code> <code>metatools-mcp/internal/handlers/interfaces.go:70</code> RunWithProgress(ctx context.Context, toolID string, args map[string]any, onProgress func(ProgressEvent)) (RunResult, error)RunChainWithProgress(ctx context.Context, steps []ChainStep, onProgress func(ProgressEvent)) (RunResult, []StepResult, error) <code>Executor</code> <code>metatools-mcp/internal/handlers/interfaces.go:92</code> ExecuteCode(ctx context.Context, params ExecuteParams) (ExecuteResult, error)"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-interface-contracts/#contract-template-apply-per-interface","title":"Contract Template (apply per interface)","text":"<ul> <li>Thread-safety: explicitly state if safe for concurrent use.</li> <li>Context: cancellation/deadline handling (if context is a parameter).</li> <li>Errors: classification, retryability, and wrapping expectations.</li> <li>Ownership: who owns/allocates inputs/outputs; mutation expectations.</li> <li>Determinism/order: ordering guarantees for returned slices/maps/streams.</li> <li>Nil/zero handling: behavior for nil inputs or empty values.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/2026-01-30-prd-016-interface-contracts/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>All interfaces have GoDoc with explicit behavioral contract.</li> <li>Contract tests exist and pass.</li> <li>No interface contract contradictions across repos.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/","title":"ApertureStack Consolidation Master Plan","text":"<p>Date: 2026-01-30 Version: 1.0 Status: Planning</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#executive-summary","title":"Executive Summary","text":"<p>This document outlines the complete consolidation of the ApertureStack ecosystem from 15 standalone repositories into 6 consolidated repositories plus metatools-mcp. This is a breaking change with no backward compatibility requirements.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#current-state","title":"Current State","text":"<pre><code>ApertureStack/\n\u251c\u2500\u2500 toolmodel/          # Standalone\n\u251c\u2500\u2500 tooladapter/        # Standalone\n\u251c\u2500\u2500 toolindex/          # Standalone\n\u251c\u2500\u2500 toolsearch/         # Standalone\n\u251c\u2500\u2500 toolsemantic/       # Standalone (partial)\n\u251c\u2500\u2500 tooldocs/           # Standalone\n\u251c\u2500\u2500 toolrun/            # Standalone\n\u251c\u2500\u2500 toolruntime/        # Standalone\n\u251c\u2500\u2500 toolcode/           # Standalone\n\u251c\u2500\u2500 toolset/            # Standalone\n\u251c\u2500\u2500 toolskill/          # Standalone (partial)\n\u251c\u2500\u2500 toolobserve/        # Standalone\n\u251c\u2500\u2500 toolcache/          # Standalone\n\u251c\u2500\u2500 ai-tools-stack/     # Coordination repo\n\u2514\u2500\u2500 metatools-mcp/      # MCP server\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#target-state","title":"Target State","text":"<pre><code>ApertureStack/\n\u251c\u2500\u2500 toolfoundation/     # model + adapter + version\n\u251c\u2500\u2500 tooldiscovery/      # index + search + semantic + docs\n\u251c\u2500\u2500 toolexec/           # run + runtime + code + backend\n\u251c\u2500\u2500 toolcompose/        # set + skill\n\u251c\u2500\u2500 toolops/            # observe + cache + resilience + health + auth\n\u251c\u2500\u2500 toolprotocol/       # transport + wire + discover + content + task + stream + session + elicit + resource + prompt\n\u251c\u2500\u2500 ai-tools-stack/     # Coordination repo (updated)\n\u2514\u2500\u2500 metatools-mcp/      # MCP server (updated)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-overview","title":"Phase Overview","text":"Phase Name PRDs Effort Dependencies 0 Planning &amp; Documentation 100-102 2 days None 1 Infrastructure Setup 110-113 3 days Phase 0 2 Foundation Layer 120-122 3 days Phase 1 3 Discovery Layer 130-133 4 days Phase 2 4 Execution Layer 140-143 4 days Phase 2 5 Composition Layer 150-151 2 days Phase 3, 4 6 Operations Layer 160-164 5 days Phase 2 7 Protocol Layer 170-179 10 days Phase 2, 4, 6 8 Integration 180-182 3 days Phase 2-7 9 Cleanup 190-192 2 days Phase 8 <p>Total Estimated: 38 days (~8 weeks)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#prd-index","title":"PRD Index","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-0-planning-documentation","title":"Phase 0: Planning &amp; Documentation","text":"PRD Title Description PRD-100 Master Consolidation Plan This document PRD-101 Architecture Diagrams D2/Mermaid diagrams for all layers PRD-102 Schema Definitions JSON Schema for all data types"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-1-infrastructure-setup","title":"Phase 1: Infrastructure Setup","text":"PRD Title Description PRD-110 Repository Creation Create 6 new repos with structure PRD-111 CI/CD Templates Reusable workflow templates PRD-112 GitHub Org Config Secrets, branch protection, teams PRD-113 Release Automation Release-please config for monorepos"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-2-foundation-layer-toolfoundation","title":"Phase 2: Foundation Layer (toolfoundation)","text":"PRD Title Description PRD-120 Migrate toolmodel Move to toolfoundation/model PRD-121 Migrate tooladapter Move to toolfoundation/adapter PRD-122 Create toolversion New: toolfoundation/version"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-3-discovery-layer-tooldiscovery","title":"Phase 3: Discovery Layer (tooldiscovery)","text":"PRD Title Description PRD-130 Migrate toolindex Move to tooldiscovery/index PRD-131 Migrate toolsearch Move to tooldiscovery/search PRD-132 Migrate toolsemantic Move to tooldiscovery/semantic PRD-133 Migrate tooldocs Move to tooldiscovery/docs"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-4-execution-layer-toolexec","title":"Phase 4: Execution Layer (toolexec)","text":"PRD Title Description PRD-140 Migrate toolrun Move to toolexec/run PRD-141 Migrate toolruntime Move to toolexec/runtime PRD-142 Migrate toolcode Move to toolexec/code PRD-143 Extract toolbackend Extract from metatools-mcp"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-5-composition-layer-toolcompose","title":"Phase 5: Composition Layer (toolcompose)","text":"PRD Title Description PRD-150 Migrate toolset Move to toolcompose/set PRD-151 Complete toolskill Move + implement toolcompose/skill"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-6-operations-layer-toolops","title":"Phase 6: Operations Layer (toolops)","text":"PRD Title Description PRD-160 Migrate toolobserve Move to toolops/observe PRD-161 Migrate toolcache Move to toolops/cache PRD-162 Extract toolauth Extract from metatools-mcp PRD-163 Create toolresilience New: toolops/resilience PRD-164 Create toolhealth New: toolops/health"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-7-protocol-layer-toolprotocol","title":"Phase 7: Protocol Layer (toolprotocol)","text":"PRD Title Description PRD-170 Create tooltransport Wire layer (HTTP, gRPC, WS, Stdio) PRD-171 Create toolwire Protocol adapters (MCP, A2A, ACP) PRD-172 Create tooldiscover Capability discovery PRD-173 Create toolcontent Content/Part abstraction PRD-174 Create tooltask Task lifecycle PRD-175 Create toolstream Streaming/updates PRD-176 Create toolsession Session management PRD-177 Create toolelicit User input elicitation PRD-178 Create toolresource MCP Resources PRD-179 Create toolprompt MCP Prompts"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-8-integration","title":"Phase 8: Integration","text":"PRD Title Description PRD-180 Update metatools-mcp Use consolidated repos PRD-181 Update ai-tools-stack Version matrix, docs PRD-182 Documentation Site MkDocs update"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#phase-9-cleanup","title":"Phase 9: Cleanup","text":"PRD Title Description PRD-190 Archive Old Repos Archive 13 standalone repos PRD-191 Update Submodules New submodule structure PRD-192 Validation Smoke tests, final checks"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#execution-order","title":"Execution Order","text":"<pre><code>gantt\n    title ApertureStack Consolidation Timeline\n    dateFormat  YYYY-MM-DD\n\n    section Phase 0\n    Planning &amp; Docs       :p0, 2026-02-01, 2d\n\n    section Phase 1\n    Infrastructure        :p1, after p0, 3d\n\n    section Phase 2\n    Foundation Layer      :p2, after p1, 3d\n\n    section Phase 3-4\n    Discovery Layer       :p3, after p2, 4d\n    Execution Layer       :p4, after p2, 4d\n\n    section Phase 5-6\n    Composition Layer     :p5, after p3 p4, 2d\n    Operations Layer      :p6, after p2, 5d\n\n    section Phase 7\n    Protocol Layer        :p7, after p2 p4 p6, 10d\n\n    section Phase 8\n    Integration           :p8, after p5 p6 p7, 3d\n\n    section Phase 9\n    Cleanup               :p9, after p8, 2d</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#repository-structure","title":"Repository Structure","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#standard-layout-all-consolidated-repos","title":"Standard Layout (All Consolidated Repos)","text":"<pre><code>repo-name/\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u251c\u2500\u2500 ci.yml              # Test all subpackages\n\u2502       \u251c\u2500\u2500 lint-security.yml   # Lint + security scan\n\u2502       \u251c\u2500\u2500 commitlint.yml      # Conventional commits\n\u2502       \u2514\u2500\u2500 release-please.yml  # Multi-package releases\n\u251c\u2500\u2500 subpkg1/\n\u2502   \u251c\u2500\u2500 doc.go\n\u2502   \u251c\u2500\u2500 types.go\n\u2502   \u251c\u2500\u2500 implementation.go\n\u2502   \u2514\u2500\u2500 implementation_test.go\n\u251c\u2500\u2500 subpkg2/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 design-notes.md\n\u2502   \u2514\u2500\u2500 user-journey.md\n\u251c\u2500\u2500 examples/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 go.sum\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 LICENSE\n\u2514\u2500\u2500 release-please-config.json\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#go-module-structure","title":"Go Module Structure","text":"<p>Each consolidated repo uses a single go.mod with subpackages:</p> <pre><code>// go.mod for toolfoundation\nmodule github.com/ApertureStack/toolfoundation\n\ngo 1.24\n\nrequire (\n    github.com/modelcontextprotocol/go-sdk v1.2.0\n)\n</code></pre> <p>Import paths: <pre><code>import (\n    \"github.com/ApertureStack/toolfoundation/model\"\n    \"github.com/ApertureStack/toolfoundation/adapter\"\n    \"github.com/ApertureStack/toolfoundation/version\"\n)\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#cicd-strategy","title":"CI/CD Strategy","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#workflow-templates","title":"Workflow Templates","text":"<p>Create reusable workflows in <code>.github/workflows/</code>:</p> <p>ci.yml: <pre><code>name: CI\n\non:\n  push:\n    branches: [\"main\"]\n    paths-ignore: [\"**.md\", \"docs/**\"]\n  pull_request:\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        go: [\"1.24\"]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version: ${{ matrix.go }}\n      - name: Test all packages\n        run: go test -race -coverprofile=coverage.out ./...\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n</code></pre></p> <p>lint-security.yml: <pre><code>name: Lint &amp; Security\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n      - uses: golangci/golangci-lint-action@v6\n        with:\n          version: latest\n\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: securego/gosec@master\n        with:\n          args: ./...\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#release-strategy","title":"Release Strategy","text":"<p>Use release-please with multi-package support:</p> <p>release-please-config.json: <pre><code>{\n  \"$schema\": \"https://raw.githubusercontent.com/googleapis/release-please/main/schemas/config.json\",\n  \"release-type\": \"go\",\n  \"packages\": {\n    \".\": {}\n  },\n  \"changelog-sections\": [\n    {\"type\": \"feat\", \"section\": \"Features\"},\n    {\"type\": \"fix\", \"section\": \"Bug Fixes\"},\n    {\"type\": \"perf\", \"section\": \"Performance\"},\n    {\"type\": \"refactor\", \"section\": \"Refactoring\"}\n  ]\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#github-secrets-required","title":"GitHub Secrets Required","text":"Secret Purpose Scope <code>CODECOV_TOKEN</code> Coverage upload Org-level <code>RELEASE_PLEASE_TOKEN</code> Release automation Org-level <code>GOPRIVATE</code> Private module access Org-level"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#migration-checklist-template","title":"Migration Checklist Template","text":"<p>For each migration PRD:</p> <ul> <li>[ ] Create target directory structure</li> <li>[ ] Copy source files preserving git history (<code>git filter-repo</code>)</li> <li>[ ] Update import paths</li> <li>[ ] Update go.mod dependencies</li> <li>[ ] Update tests</li> <li>[ ] Run full test suite</li> <li>[ ] Update documentation</li> <li>[ ] Create PR</li> <li>[ ] Merge and tag</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#risk-mitigation","title":"Risk Mitigation","text":"Risk Mitigation Breaking imports No backward compat (per requirements) Lost git history Use <code>git subtree</code> or <code>git filter-repo</code> CI failures Test templates before bulk migration Dependency cycles Strict layer boundaries Scope creep Stick to migration, defer improvements"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#success-criteria","title":"Success Criteria","text":"<ul> <li>[ ] All 6 consolidated repos created and tested</li> <li>[ ] All existing functionality preserved</li> <li>[ ] CI/CD working for all repos</li> <li>[ ] Documentation updated</li> <li>[ ] metatools-mcp using consolidated repos</li> <li>[ ] Old repos archived</li> <li>[ ] ApertureStack submodules updated</li> <li>[ ] Smoke tests passing</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/CONSOLIDATION-MASTER-PLAN/#references","title":"References","text":"<ul> <li>LIBRARY-CATEGORIZATION.md - Full library inventory</li> <li>MULTI-PROTOCOL-TRANSPORT.md - Protocol layer design</li> <li>EXTRACTION-ANALYSIS.md - metatools-mcp extraction</li> <li>MCP-FEATURES-ANALYSIS.md - MCP protocol features</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-109-remediation/","title":"PRD-100\u2013109 Remediation Plan","text":"<p>Date: 2026-01-31 Owner: Jon W. Raymond Scope: PRD-100, PRD-101, PRD-102</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-109-remediation/#objective","title":"Objective","text":"<p>Close the remaining planning/documentation gaps in Phase 0 by: 1. Delivering the missing architecture diagrams (Mermaid). 2. Publishing the JSON schema definitions specified in PRD-102. 3. Updating plan status to reflect completion.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-109-remediation/#deliverables","title":"Deliverables","text":"Item Location Status Layer architecture diagram <code>docs/diagrams/layer-architecture.md</code> Planned Repository map diagram <code>docs/diagrams/repository-map.md</code> Planned Dependency graph <code>docs/diagrams/dependency-graph.md</code> Planned Data flow diagram <code>docs/diagrams/data-flow.md</code> Planned Protocol adapters diagram <code>docs/diagrams/protocol-adapters.md</code> Planned Tool schema <code>schemas/tool.schema.json</code> Planned Toolset schema <code>schemas/toolset.schema.json</code> Planned Execution schema <code>schemas/execution.schema.json</code> Planned Discovery schema <code>schemas/discovery.schema.json</code> Planned Config schema <code>schemas/config.schema.json</code> Planned Schema index <code>schemas/README.md</code> Planned Plan status update <code>docs/plans/README.md</code> Planned"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-109-remediation/#plan-of-record","title":"Plan of Record","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-109-remediation/#task-1-prd-101-diagrams","title":"Task 1 \u2014 PRD-101 Diagrams","text":"<ul> <li>Create the five Mermaid diagram markdown files under <code>docs/diagrams/</code>.</li> <li>Ensure diagrams reflect the consolidated repos and package layout.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-109-remediation/#task-2-prd-102-schemas","title":"Task 2 \u2014 PRD-102 Schemas","text":"<ul> <li>Create <code>schemas/</code> directory with JSON Schema files from PRD-102.</li> <li>Add <code>schemas/README.md</code> indexing the schema set.</li> <li>Validate JSON syntax locally (<code>python3 -m json.tool</code>).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-109-remediation/#task-3-update-plan-status","title":"Task 3 \u2014 Update Plan Status","text":"<ul> <li>Update <code>docs/plans/README.md</code> to mark PRD-100/101/102 as Done.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-109-remediation/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All diagram files exist and render in Mermaid.</li> <li>[ ] All schema files exist and are valid JSON.</li> <li>[ ] <code>schemas/README.md</code> references all schema files.</li> <li>[ ] <code>docs/plans/README.md</code> updated to reflect completion.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-109-remediation/#execution-notes","title":"Execution Notes","text":"<ul> <li>No code paths changed; documentation-only changes.</li> <li>Follows existing PRD definitions verbatim unless noted.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/","title":"PRD-100: Master Consolidation Plan","text":"<p>Phase: 0 - Planning &amp; Documentation Priority: Critical Effort: 4 hours Dependencies: None</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#objective","title":"Objective","text":"<p>Document the complete consolidation strategy, serving as the authoritative reference for all subsequent PRDs.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#deliverables","title":"Deliverables","text":"Deliverable Location Description Master Plan <code>docs/plans/CONSOLIDATION-MASTER-PLAN.md</code> Executive summary, phase overview, success criteria Order of Operations <code>docs/plans/PRD-ORDER-OF-OPERATIONS.md</code> Sequential execution order for all 41 PRDs This PRD <code>docs/plans/PRD-100-master-plan.md</code> Self-referential documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#task-1-create-master-plan-document","title":"Task 1: Create Master Plan Document","text":"<p>File: <code>docs/plans/CONSOLIDATION-MASTER-PLAN.md</code></p> <p>Content Requirements: - Executive summary with current/target state diagrams - Phase overview table (9 phases, effort estimates) - PRD index by phase - Execution order Mermaid gantt chart - Repository structure standards - Go module structure with import path examples - CI/CD strategy overview - GitHub secrets requirements - Migration checklist template - Risk mitigation table - Success criteria checklist - References to supporting documents</p> <p>Verification: <pre><code># Confirm document exists and has required sections\ngrep -c \"## Executive Summary\\|## Phase Overview\\|## PRD Index\\|## Execution Order\\|## Repository Structure\\|## CI/CD Strategy\\|## Success Criteria\" docs/plans/CONSOLIDATION-MASTER-PLAN.md\n# Should return 7 (all sections present)\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#task-2-create-order-of-operations-document","title":"Task 2: Create Order of Operations Document","text":"<p>File: <code>docs/plans/PRD-ORDER-OF-OPERATIONS.md</code></p> <p>Content Requirements: - Critical path diagram (ASCII or Mermaid) - Execution order table by week (9 weeks) - Parallel execution opportunities - Checkpoint gates table - PRD file naming convention - Quick reference: What each PRD delivers - Total effort summary</p> <p>Verification: <pre><code># Confirm all 41 PRDs are listed\ngrep -c \"PRD-1[0-9][0-9]\" docs/plans/PRD-ORDER-OF-OPERATIONS.md\n# Should return count &gt;= 41\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#task-3-create-prd-template","title":"Task 3: Create PRD Template","text":"<p>File: <code>docs/plans/PRD-TEMPLATE.md</code></p> <p>Content: <pre><code># PRD-XXX: [Title]\n\n**Phase:** X - [Phase Name]\n**Priority:** [Critical/High/Medium/Low]\n**Effort:** Xh\n**Dependencies:** PRD-XXX, PRD-YYY\n\n---\n\n## Objective\n\n[One paragraph describing what this PRD accomplishes]\n\n---\n\n## Deliverables\n\n| Deliverable | Location | Description |\n|-------------|----------|-------------|\n\n---\n\n## Tasks\n\n### Task 1: [Task Title]\n\n**Description:**\n\n**Commands/Code:**\n\n**Verification:**\n\n---\n\n## Verification Checklist\n\n- [ ] Item 1\n- [ ] Item 2\n\n---\n\n## Acceptance Criteria\n\n1. Criterion 1\n2. Criterion 2\n\n---\n\n## Rollback Plan\n\n[Commands to undo changes if needed]\n\n---\n\n## Next Steps\n\n- PRD-XXX: [Next PRD title]\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#task-4-cross-reference-validation","title":"Task 4: Cross-Reference Validation","text":"<p>Ensure all documents reference each other correctly:</p> <pre><code># Check CONSOLIDATION-MASTER-PLAN.md references\ngrep -l \"PRD-ORDER-OF-OPERATIONS\\|LIBRARY-CATEGORIZATION\\|MULTI-PROTOCOL-TRANSPORT\" docs/plans/CONSOLIDATION-MASTER-PLAN.md\n\n# Check PRD-ORDER-OF-OPERATIONS.md format\nhead -50 docs/plans/PRD-ORDER-OF-OPERATIONS.md\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] CONSOLIDATION-MASTER-PLAN.md created with all sections</li> <li>[ ] PRD-ORDER-OF-OPERATIONS.md created with all 41 PRDs</li> <li>[ ] PRD-TEMPLATE.md created for consistency</li> <li>[ ] All documents use consistent formatting</li> <li>[ ] Cross-references validated</li> <li>[ ] Mermaid diagrams render correctly</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>Master plan provides complete overview of consolidation effort</li> <li>Order of operations enables sequential execution</li> <li>Template ensures PRD consistency</li> <li>All effort estimates sum to 236 hours</li> <li>Parallel execution opportunities documented</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#rollback-plan","title":"Rollback Plan","text":"<pre><code># Revert to previous state\ngit checkout HEAD~1 -- docs/plans/CONSOLIDATION-MASTER-PLAN.md\ngit checkout HEAD~1 -- docs/plans/PRD-ORDER-OF-OPERATIONS.md\ngit checkout HEAD~1 -- docs/plans/PRD-TEMPLATE.md\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-100-master-plan/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-101: Architecture Diagrams</li> <li>PRD-102: Schema Definitions</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/","title":"PRD-101: Architecture Diagrams","text":"<p>Phase: 0 - Planning &amp; Documentation Priority: High Effort: 4 hours Dependencies: PRD-100</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#objective","title":"Objective","text":"<p>Create comprehensive architecture diagrams using Mermaid syntax to visualize the consolidated ecosystem structure, layer dependencies, and data flows.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#deliverables","title":"Deliverables","text":"Deliverable Location Description Layer Architecture <code>docs/diagrams/layer-architecture.md</code> 8-tier layer diagram Repository Map <code>docs/diagrams/repository-map.md</code> 6 repos with packages Dependency Graph <code>docs/diagrams/dependency-graph.md</code> Inter-repo dependencies Data Flow <code>docs/diagrams/data-flow.md</code> Request/response flows Protocol Adapters <code>docs/diagrams/protocol-adapters.md</code> Multi-protocol support"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#task-1-create-layer-architecture-diagram","title":"Task 1: Create Layer Architecture Diagram","text":"<p>File: <code>docs/diagrams/layer-architecture.md</code></p> <pre><code># Layer Architecture\n\n## Overview\n\nThe ApertureStack ecosystem is organized into 8 distinct tiers, each with clear responsibilities and dependencies.\n\n## Diagram\n\n\\`\\`\\`mermaid\ngraph TB\n    subgraph \"Tier 8: Application\"\n        metatools-mcp[\"metatools-mcp&lt;br/&gt;(MCP Server)\"]\n    end\n\n    subgraph \"Tier 7: Protocol\"\n        toolprotocol[\"toolprotocol\"]\n        subgraph \"toolprotocol packages\"\n            transport[\"transport\"]\n            wire[\"wire\"]\n            discover[\"discover\"]\n            content[\"content\"]\n            task[\"task\"]\n            stream[\"stream\"]\n            session[\"session\"]\n            elicit[\"elicit\"]\n            resource[\"resource\"]\n            prompt[\"prompt\"]\n        end\n    end\n\n    subgraph \"Tier 6: Operations\"\n        toolops[\"toolops\"]\n        subgraph \"toolops packages\"\n            observe[\"observe\"]\n            cache[\"cache\"]\n            resilience[\"resilience\"]\n            health[\"health\"]\n            auth[\"auth\"]\n        end\n    end\n\n    subgraph \"Tier 5: Composition\"\n        toolcompose[\"toolcompose\"]\n        subgraph \"toolcompose packages\"\n            set[\"set\"]\n            skill[\"skill\"]\n        end\n    end\n\n    subgraph \"Tier 4: Execution\"\n        toolexec[\"toolexec\"]\n        subgraph \"toolexec packages\"\n            run[\"run\"]\n            runtime[\"runtime\"]\n            code[\"code\"]\n            backend[\"backend\"]\n        end\n    end\n\n    subgraph \"Tier 3: Discovery\"\n        tooldiscovery[\"tooldiscovery\"]\n        subgraph \"tooldiscovery packages\"\n            index[\"index\"]\n            search[\"search\"]\n            semantic[\"semantic\"]\n            docs[\"docs\"]\n        end\n    end\n\n    subgraph \"Tier 2: Foundation\"\n        toolfoundation[\"toolfoundation\"]\n        subgraph \"toolfoundation packages\"\n            model[\"model\"]\n            adapter[\"adapter\"]\n            version[\"version\"]\n        end\n    end\n\n    subgraph \"Tier 1: External\"\n        mcp-sdk[\"MCP Go SDK\"]\n    end\n\n    metatools-mcp --&gt; toolprotocol\n    metatools-mcp --&gt; toolops\n    metatools-mcp --&gt; toolcompose\n    metatools-mcp --&gt; toolexec\n    metatools-mcp --&gt; tooldiscovery\n\n    toolprotocol --&gt; toolfoundation\n    toolops --&gt; toolfoundation\n    toolcompose --&gt; toolexec\n    toolcompose --&gt; tooldiscovery\n    toolexec --&gt; toolfoundation\n    tooldiscovery --&gt; toolfoundation\n    toolfoundation --&gt; mcp-sdk\n\\`\\`\\`\n\n## Layer Descriptions\n\n| Tier | Repository | Purpose |\n|------|------------|---------|\n| 8 | metatools-mcp | MCP server exposing metatools |\n| 7 | toolprotocol | Multi-protocol transport and wire adapters |\n| 6 | toolops | Cross-cutting operational concerns |\n| 5 | toolcompose | Tool composition and agent skills |\n| 4 | toolexec | Tool execution and runtime |\n| 3 | tooldiscovery | Tool registry and search |\n| 2 | toolfoundation | Core schemas and adapters |\n| 1 | (external) | MCP Go SDK |\n\\`\\`\\`\n\n### Task 2: Create Repository Map\n\n**File:** `docs/diagrams/repository-map.md`\n\n```markdown\n# Repository Map\n\n## Consolidated Structure\n\n\\`\\`\\`mermaid\ngraph LR\n    subgraph \"toolfoundation\"\n        tf-model[\"model/\"]\n        tf-adapter[\"adapter/\"]\n        tf-version[\"version/\"]\n    end\n\n    subgraph \"tooldiscovery\"\n        td-index[\"index/\"]\n        td-search[\"search/\"]\n        td-semantic[\"semantic/\"]\n        td-docs[\"docs/\"]\n    end\n\n    subgraph \"toolexec\"\n        te-run[\"run/\"]\n        te-runtime[\"runtime/\"]\n        te-code[\"code/\"]\n        te-backend[\"backend/\"]\n    end\n\n    subgraph \"toolcompose\"\n        tc-set[\"set/\"]\n        tc-skill[\"skill/\"]\n    end\n\n    subgraph \"toolops\"\n        to-observe[\"observe/\"]\n        to-cache[\"cache/\"]\n        to-resilience[\"resilience/\"]\n        to-health[\"health/\"]\n        to-auth[\"auth/\"]\n    end\n\n    subgraph \"toolprotocol\"\n        tp-transport[\"transport/\"]\n        tp-wire[\"wire/\"]\n        tp-discover[\"discover/\"]\n        tp-content[\"content/\"]\n        tp-task[\"task/\"]\n        tp-stream[\"stream/\"]\n        tp-session[\"session/\"]\n        tp-elicit[\"elicit/\"]\n        tp-resource[\"resource/\"]\n        tp-prompt[\"prompt/\"]\n    end\n\\`\\`\\`\n\n## Package Counts\n\n| Repository | Packages | Lines (est.) |\n|------------|----------|--------------|\n| toolfoundation | 3 | ~8,000 |\n| tooldiscovery | 4 | ~10,000 |\n| toolexec | 4 | ~15,000 |\n| toolcompose | 2 | ~5,000 |\n| toolops | 5 | ~12,000 |\n| toolprotocol | 10 | ~20,000 |\n| **Total** | **28** | **~70,000** |\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#task-3-create-dependency-graph","title":"Task 3: Create Dependency Graph","text":"<p>File: <code>docs/diagrams/dependency-graph.md</code></p> <pre><code># Dependency Graph\n\n## Inter-Repository Dependencies\n\n\\`\\`\\`mermaid\ngraph TD\n    metatools-mcp --&gt; toolprotocol\n    metatools-mcp --&gt; toolops\n    metatools-mcp --&gt; toolcompose\n    metatools-mcp --&gt; toolexec\n    metatools-mcp --&gt; tooldiscovery\n    metatools-mcp --&gt; toolfoundation\n\n    toolprotocol --&gt; toolfoundation\n    toolprotocol --&gt; toolops\n\n    toolops --&gt; toolfoundation\n\n    toolcompose --&gt; toolexec\n    toolcompose --&gt; tooldiscovery\n    toolcompose --&gt; toolfoundation\n\n    toolexec --&gt; toolfoundation\n\n    tooldiscovery --&gt; toolfoundation\n\n    toolfoundation --&gt; mcp-sdk[\"MCP Go SDK\"]\n\\`\\`\\`\n\n## Dependency Matrix\n\n|  | foundation | discovery | exec | compose | ops | protocol |\n|--|------------|-----------|------|---------|-----|----------|\n| **foundation** | - | | | | | |\n| **discovery** | \u2713 | - | | | | |\n| **exec** | \u2713 | | - | | | |\n| **compose** | \u2713 | \u2713 | \u2713 | - | | |\n| **ops** | \u2713 | | | | - | |\n| **protocol** | \u2713 | | | | \u2713 | - |\n| **metatools-mcp** | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 |\n\n## Build Order\n\nBased on dependencies, build order is:\n1. toolfoundation (no internal deps)\n2. tooldiscovery, toolexec, toolops (parallel, depend on foundation)\n3. toolcompose (depends on discovery + exec)\n4. toolprotocol (depends on foundation + ops)\n5. metatools-mcp (depends on all)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#task-4-create-data-flow-diagram","title":"Task 4: Create Data Flow Diagram","text":"<p>File: <code>docs/diagrams/data-flow.md</code></p> <pre><code># Data Flow\n\n## Tool Execution Flow\n\n\\`\\`\\`mermaid\nsequenceDiagram\n    participant Client\n    participant Transport as toolprotocol/transport\n    participant Wire as toolprotocol/wire\n    participant Auth as toolops/auth\n    participant Cache as toolops/cache\n    participant Exec as toolexec/run\n    participant Runtime as toolexec/runtime\n\n    Client-&gt;&gt;Transport: HTTP/gRPC/WebSocket Request\n    Transport-&gt;&gt;Wire: Decode Protocol (MCP/A2A/ACP)\n    Wire-&gt;&gt;Auth: Authenticate Request\n    Auth-&gt;&gt;Cache: Check Cache\n\n    alt Cache Hit\n        Cache--&gt;&gt;Wire: Cached Result\n    else Cache Miss\n        Cache-&gt;&gt;Exec: Execute Tool\n        Exec-&gt;&gt;Runtime: Sandbox Execution\n        Runtime--&gt;&gt;Exec: Result\n        Exec-&gt;&gt;Cache: Store Result\n        Cache--&gt;&gt;Wire: Fresh Result\n    end\n\n    Wire-&gt;&gt;Transport: Encode Response\n    Transport--&gt;&gt;Client: Response\n\\`\\`\\`\n\n## Tool Discovery Flow\n\n\\`\\`\\`mermaid\nsequenceDiagram\n    participant Client\n    participant Index as tooldiscovery/index\n    participant Search as tooldiscovery/search\n    participant Semantic as tooldiscovery/semantic\n    participant Docs as tooldiscovery/docs\n\n    Client-&gt;&gt;Index: List/Search Tools\n    Index-&gt;&gt;Search: BM25 Search\n\n    opt Semantic Search Enabled\n        Search-&gt;&gt;Semantic: Vector Search\n        Semantic--&gt;&gt;Search: Semantic Results\n    end\n\n    Search--&gt;&gt;Index: Ranked Results\n    Index-&gt;&gt;Docs: Get Documentation\n    Docs--&gt;&gt;Index: Tool Docs\n    Index--&gt;&gt;Client: Tools with Docs\n\\`\\`\\`\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#task-5-create-protocol-adapters-diagram","title":"Task 5: Create Protocol Adapters Diagram","text":"<p>File: <code>docs/diagrams/protocol-adapters.md</code></p> <pre><code># Protocol Adapters\n\n## Multi-Protocol Architecture\n\n\\`\\`\\`mermaid\ngraph TB\n    subgraph \"Clients\"\n        mcp-client[\"MCP Client\"]\n        a2a-client[\"A2A Agent\"]\n        acp-client[\"ACP Client\"]\n        http-client[\"HTTP Client\"]\n    end\n\n    subgraph \"Transport Layer\"\n        stdio[\"Stdio\"]\n        sse[\"SSE\"]\n        ws[\"WebSocket\"]\n        grpc[\"gRPC\"]\n        http[\"HTTP\"]\n    end\n\n    subgraph \"Wire Adapters\"\n        mcp-wire[\"MCP Wire\"]\n        a2a-wire[\"A2A Wire\"]\n        acp-wire[\"ACP Wire\"]\n    end\n\n    subgraph \"Canonical Layer\"\n        canonical[\"Canonical Tool Interface\"]\n    end\n\n    mcp-client --&gt; stdio\n    mcp-client --&gt; sse\n    a2a-client --&gt; grpc\n    acp-client --&gt; http\n    http-client --&gt; http\n\n    stdio --&gt; mcp-wire\n    sse --&gt; mcp-wire\n    grpc --&gt; a2a-wire\n    http --&gt; acp-wire\n\n    mcp-wire --&gt; canonical\n    a2a-wire --&gt; canonical\n    acp-wire --&gt; canonical\n\\`\\`\\`\n\n## Protocol Feature Matrix\n\n| Feature | MCP | A2A | ACP |\n|---------|-----|-----|-----|\n| Tool Discovery | \u2713 | \u2713 | \u2713 |\n| Tool Execution | \u2713 | \u2713 | \u2713 |\n| Streaming | \u2713 | \u2713 | \u2713 |\n| Resources | \u2713 | - | - |\n| Prompts | \u2713 | - | - |\n| Sessions | - | \u2713 | \u2713 |\n| Tasks | - | \u2713 | \u2713 |\n| Elicitation | \u2713 | - | - |\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All 5 diagram files created</li> <li>[ ] Mermaid syntax validates (no errors)</li> <li>[ ] Diagrams render in GitHub markdown preview</li> <li>[ ] All 6 repositories represented</li> <li>[ ] All 28 packages shown</li> <li>[ ] Dependency arrows are accurate</li> <li>[ ] Protocol adapters show all 3 protocols</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>Diagrams provide clear visual understanding of architecture</li> <li>All relationships between components are accurate</li> <li>Diagrams can be embedded in documentation</li> <li>Mermaid syntax is valid and renders correctly</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#rollback-plan","title":"Rollback Plan","text":"<pre><code># Remove diagram files\nrm -rf docs/diagrams/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-101-architecture-diagrams/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-102: Schema Definitions</li> <li>PRD-110: Repository Creation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/","title":"PRD-102: Schema Definitions","text":"<p>Phase: 0 - Planning &amp; Documentation Priority: High Effort: 4 hours Dependencies: PRD-100</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#objective","title":"Objective","text":"<p>Define JSON Schema specifications for all core data types used across the consolidated ecosystem, ensuring type safety and validation consistency.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#deliverables","title":"Deliverables","text":"Deliverable Location Description Tool Schema <code>schemas/tool.schema.json</code> Canonical tool definition Toolset Schema <code>schemas/toolset.schema.json</code> Tool collection schema Execution Schema <code>schemas/execution.schema.json</code> Tool execution request/result Discovery Schema <code>schemas/discovery.schema.json</code> Tool discovery structures Config Schema <code>schemas/config.schema.json</code> Configuration file schema"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#task-1-create-tool-schema","title":"Task 1: Create Tool Schema","text":"<p>File: <code>schemas/tool.schema.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://aperturestack.dev/schemas/tool.schema.json\",\n  \"title\": \"Tool\",\n  \"description\": \"Canonical tool definition for ApertureStack\",\n  \"type\": \"object\",\n  \"required\": [\"id\", \"name\", \"description\"],\n  \"properties\": {\n    \"id\": {\n      \"type\": \"string\",\n      \"pattern\": \"^[a-z][a-z0-9_-]*$\",\n      \"description\": \"Unique tool identifier\"\n    },\n    \"name\": {\n      \"type\": \"string\",\n      \"minLength\": 1,\n      \"maxLength\": 100,\n      \"description\": \"Human-readable tool name\"\n    },\n    \"description\": {\n      \"type\": \"string\",\n      \"minLength\": 1,\n      \"maxLength\": 1000,\n      \"description\": \"Tool description for discovery\"\n    },\n    \"version\": {\n      \"type\": \"string\",\n      \"pattern\": \"^v?\\\\d+\\\\.\\\\d+\\\\.\\\\d+(-[a-zA-Z0-9.]+)?$\",\n      \"description\": \"Semantic version\"\n    },\n    \"namespace\": {\n      \"type\": \"string\",\n      \"pattern\": \"^[a-z][a-z0-9_-]*$\",\n      \"description\": \"Tool namespace for grouping\"\n    },\n    \"inputSchema\": {\n      \"$ref\": \"https://json-schema.org/draft/2020-12/schema\",\n      \"description\": \"JSON Schema for tool input\"\n    },\n    \"outputSchema\": {\n      \"$ref\": \"https://json-schema.org/draft/2020-12/schema\",\n      \"description\": \"JSON Schema for tool output\"\n    },\n    \"metadata\": {\n      \"type\": \"object\",\n      \"additionalProperties\": true,\n      \"description\": \"Arbitrary metadata\"\n    },\n    \"tags\": {\n      \"type\": \"array\",\n      \"items\": {\"type\": \"string\"},\n      \"description\": \"Searchable tags\"\n    },\n    \"capabilities\": {\n      \"$ref\": \"#/$defs/Capabilities\"\n    }\n  },\n  \"$defs\": {\n    \"Capabilities\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"streaming\": {\"type\": \"boolean\", \"default\": false},\n        \"batch\": {\"type\": \"boolean\", \"default\": false},\n        \"async\": {\"type\": \"boolean\", \"default\": false},\n        \"cacheable\": {\"type\": \"boolean\", \"default\": true},\n        \"idempotent\": {\"type\": \"boolean\", \"default\": false}\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#task-2-create-toolset-schema","title":"Task 2: Create Toolset Schema","text":"<p>File: <code>schemas/toolset.schema.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://aperturestack.dev/schemas/toolset.schema.json\",\n  \"title\": \"Toolset\",\n  \"description\": \"Collection of tools with shared configuration\",\n  \"type\": \"object\",\n  \"required\": [\"id\", \"name\", \"tools\"],\n  \"properties\": {\n    \"id\": {\n      \"type\": \"string\",\n      \"pattern\": \"^[a-z][a-z0-9_-]*$\"\n    },\n    \"name\": {\n      \"type\": \"string\",\n      \"minLength\": 1,\n      \"maxLength\": 100\n    },\n    \"description\": {\n      \"type\": \"string\",\n      \"maxLength\": 1000\n    },\n    \"version\": {\n      \"type\": \"string\",\n      \"pattern\": \"^v?\\\\d+\\\\.\\\\d+\\\\.\\\\d+(-[a-zA-Z0-9.]+)?$\"\n    },\n    \"tools\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"oneOf\": [\n          {\"type\": \"string\", \"description\": \"Tool ID reference\"},\n          {\"$ref\": \"tool.schema.json\"}\n        ]\n      },\n      \"minItems\": 1\n    },\n    \"config\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"timeout\": {\n          \"type\": \"string\",\n          \"pattern\": \"^\\\\d+[smh]$\",\n          \"description\": \"Execution timeout (e.g., '30s', '5m')\"\n        },\n        \"retries\": {\n          \"type\": \"integer\",\n          \"minimum\": 0,\n          \"maximum\": 10\n        },\n        \"cachePolicy\": {\n          \"type\": \"string\",\n          \"enum\": [\"none\", \"default\", \"aggressive\"]\n        }\n      }\n    },\n    \"permissions\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\",\n        \"enum\": [\"read\", \"write\", \"execute\", \"admin\"]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#task-3-create-execution-schema","title":"Task 3: Create Execution Schema","text":"<p>File: <code>schemas/execution.schema.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://aperturestack.dev/schemas/execution.schema.json\",\n  \"title\": \"Execution\",\n  \"description\": \"Tool execution request and result schemas\",\n  \"$defs\": {\n    \"ExecutionRequest\": {\n      \"type\": \"object\",\n      \"required\": [\"toolId\", \"input\"],\n      \"properties\": {\n        \"toolId\": {\n          \"type\": \"string\",\n          \"description\": \"Tool to execute\"\n        },\n        \"input\": {\n          \"type\": \"object\",\n          \"description\": \"Tool input arguments\"\n        },\n        \"context\": {\n          \"$ref\": \"#/$defs/ExecutionContext\"\n        },\n        \"options\": {\n          \"$ref\": \"#/$defs/ExecutionOptions\"\n        }\n      }\n    },\n    \"ExecutionContext\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"requestId\": {\"type\": \"string\", \"format\": \"uuid\"},\n        \"traceId\": {\"type\": \"string\"},\n        \"spanId\": {\"type\": \"string\"},\n        \"userId\": {\"type\": \"string\"},\n        \"tenantId\": {\"type\": \"string\"},\n        \"metadata\": {\"type\": \"object\"}\n      }\n    },\n    \"ExecutionOptions\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"timeout\": {\"type\": \"string\", \"pattern\": \"^\\\\d+[smh]$\"},\n        \"backend\": {\"type\": \"string\", \"enum\": [\"local\", \"docker\", \"wasm\", \"remote\"]},\n        \"sandbox\": {\"type\": \"string\", \"enum\": [\"none\", \"basic\", \"strict\"]},\n        \"stream\": {\"type\": \"boolean\", \"default\": false},\n        \"cache\": {\"type\": \"boolean\", \"default\": true}\n      }\n    },\n    \"ExecutionResult\": {\n      \"type\": \"object\",\n      \"required\": [\"status\"],\n      \"properties\": {\n        \"status\": {\n          \"type\": \"string\",\n          \"enum\": [\"success\", \"error\", \"timeout\", \"cancelled\"]\n        },\n        \"output\": {\n          \"description\": \"Tool output on success\"\n        },\n        \"error\": {\n          \"$ref\": \"#/$defs/ExecutionError\"\n        },\n        \"metrics\": {\n          \"$ref\": \"#/$defs/ExecutionMetrics\"\n        }\n      }\n    },\n    \"ExecutionError\": {\n      \"type\": \"object\",\n      \"required\": [\"code\", \"message\"],\n      \"properties\": {\n        \"code\": {\"type\": \"string\"},\n        \"message\": {\"type\": \"string\"},\n        \"details\": {\"type\": \"object\"},\n        \"retryable\": {\"type\": \"boolean\", \"default\": false}\n      }\n    },\n    \"ExecutionMetrics\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"startTime\": {\"type\": \"string\", \"format\": \"date-time\"},\n        \"endTime\": {\"type\": \"string\", \"format\": \"date-time\"},\n        \"durationMs\": {\"type\": \"integer\", \"minimum\": 0},\n        \"backend\": {\"type\": \"string\"},\n        \"cached\": {\"type\": \"boolean\"}\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#task-4-create-discovery-schema","title":"Task 4: Create Discovery Schema","text":"<p>File: <code>schemas/discovery.schema.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://aperturestack.dev/schemas/discovery.schema.json\",\n  \"title\": \"Discovery\",\n  \"description\": \"Tool discovery and search schemas\",\n  \"$defs\": {\n    \"SearchQuery\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"query\": {\n          \"type\": \"string\",\n          \"description\": \"Search query text\"\n        },\n        \"filters\": {\n          \"$ref\": \"#/$defs/SearchFilters\"\n        },\n        \"options\": {\n          \"$ref\": \"#/$defs/SearchOptions\"\n        }\n      }\n    },\n    \"SearchFilters\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"namespace\": {\"type\": \"string\"},\n        \"tags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n        \"capabilities\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n        \"minVersion\": {\"type\": \"string\"},\n        \"maxVersion\": {\"type\": \"string\"}\n      }\n    },\n    \"SearchOptions\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"limit\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 100, \"default\": 10},\n        \"offset\": {\"type\": \"integer\", \"minimum\": 0, \"default\": 0},\n        \"sortBy\": {\"type\": \"string\", \"enum\": [\"relevance\", \"name\", \"updated\"]},\n        \"sortOrder\": {\"type\": \"string\", \"enum\": [\"asc\", \"desc\"]},\n        \"includeDeprecated\": {\"type\": \"boolean\", \"default\": false},\n        \"searchMode\": {\"type\": \"string\", \"enum\": [\"bm25\", \"semantic\", \"hybrid\"]}\n      }\n    },\n    \"SearchResult\": {\n      \"type\": \"object\",\n      \"required\": [\"tools\", \"total\"],\n      \"properties\": {\n        \"tools\": {\n          \"type\": \"array\",\n          \"items\": {\"$ref\": \"#/$defs/SearchHit\"}\n        },\n        \"total\": {\"type\": \"integer\", \"minimum\": 0},\n        \"hasMore\": {\"type\": \"boolean\"},\n        \"searchTime\": {\"type\": \"integer\", \"description\": \"Search time in milliseconds\"}\n      }\n    },\n    \"SearchHit\": {\n      \"type\": \"object\",\n      \"required\": [\"tool\", \"score\"],\n      \"properties\": {\n        \"tool\": {\"$ref\": \"tool.schema.json\"},\n        \"score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1},\n        \"highlights\": {\n          \"type\": \"object\",\n          \"additionalProperties\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#task-5-create-config-schema","title":"Task 5: Create Config Schema","text":"<p>File: <code>schemas/config.schema.json</code></p> <pre><code>{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://aperturestack.dev/schemas/config.schema.json\",\n  \"title\": \"Config\",\n  \"description\": \"metatools-mcp configuration schema\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"server\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"transport\": {\n          \"type\": \"string\",\n          \"enum\": [\"stdio\", \"sse\", \"websocket\", \"grpc\"],\n          \"default\": \"stdio\"\n        },\n        \"host\": {\"type\": \"string\", \"default\": \"localhost\"},\n        \"port\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 65535, \"default\": 8080},\n        \"tls\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"enabled\": {\"type\": \"boolean\", \"default\": false},\n            \"certFile\": {\"type\": \"string\"},\n            \"keyFile\": {\"type\": \"string\"}\n          }\n        }\n      }\n    },\n    \"tools\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"directories\": {\n          \"type\": \"array\",\n          \"items\": {\"type\": \"string\"},\n          \"default\": [\"./tools\"]\n        },\n        \"providers\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"object\",\n            \"required\": [\"type\", \"url\"],\n            \"properties\": {\n              \"type\": {\"type\": \"string\", \"enum\": [\"http\", \"grpc\", \"mcp\"]},\n              \"url\": {\"type\": \"string\", \"format\": \"uri\"},\n              \"timeout\": {\"type\": \"string\", \"pattern\": \"^\\\\d+[smh]$\"}\n            }\n          }\n        }\n      }\n    },\n    \"execution\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"defaultBackend\": {\n          \"type\": \"string\",\n          \"enum\": [\"local\", \"docker\", \"wasm\", \"kubernetes\"],\n          \"default\": \"local\"\n        },\n        \"timeout\": {\"type\": \"string\", \"default\": \"30s\"},\n        \"maxConcurrent\": {\"type\": \"integer\", \"minimum\": 1, \"default\": 10}\n      }\n    },\n    \"cache\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"enabled\": {\"type\": \"boolean\", \"default\": true},\n        \"backend\": {\"type\": \"string\", \"enum\": [\"memory\", \"redis\", \"file\"]},\n        \"ttl\": {\"type\": \"string\", \"default\": \"5m\"},\n        \"maxSize\": {\"type\": \"string\", \"default\": \"100MB\"}\n      }\n    },\n    \"observability\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"tracing\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"enabled\": {\"type\": \"boolean\", \"default\": false},\n            \"exporter\": {\"type\": \"string\", \"enum\": [\"otlp\", \"jaeger\", \"zipkin\"]},\n            \"endpoint\": {\"type\": \"string\", \"format\": \"uri\"}\n          }\n        },\n        \"metrics\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"enabled\": {\"type\": \"boolean\", \"default\": true},\n            \"port\": {\"type\": \"integer\", \"default\": 9090}\n          }\n        },\n        \"logging\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"level\": {\"type\": \"string\", \"enum\": [\"debug\", \"info\", \"warn\", \"error\"]},\n            \"format\": {\"type\": \"string\", \"enum\": [\"json\", \"text\"]}\n          }\n        }\n      }\n    },\n    \"auth\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"enabled\": {\"type\": \"boolean\", \"default\": false},\n        \"provider\": {\"type\": \"string\", \"enum\": [\"jwt\", \"apikey\", \"oauth2\"]},\n        \"config\": {\"type\": \"object\"}\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#task-6-create-schema-index","title":"Task 6: Create Schema Index","text":"<p>File: <code>schemas/README.md</code></p> <pre><code># ApertureStack JSON Schemas\n\nThis directory contains JSON Schema definitions for all core data types in the ApertureStack ecosystem.\n\n## Schemas\n\n| Schema | Description | Go Package |\n|--------|-------------|------------|\n| [tool.schema.json](./tool.schema.json) | Canonical tool definition | `toolfoundation/model` |\n| [toolset.schema.json](./toolset.schema.json) | Tool collection | `toolcompose/set` |\n| [execution.schema.json](./execution.schema.json) | Execution request/result | `toolexec/run` |\n| [discovery.schema.json](./discovery.schema.json) | Search query/result | `tooldiscovery/search` |\n| [config.schema.json](./config.schema.json) | Configuration file | `metatools-mcp` |\n\n## Usage\n\n### Validation in Go\n\n```go\nimport \"github.com/xeipuuv/gojsonschema\"\n\nschemaLoader := gojsonschema.NewReferenceLoader(\"file:///path/to/tool.schema.json\")\ndocumentLoader := gojsonschema.NewGoLoader(myTool)\n\nresult, err := gojsonschema.Validate(schemaLoader, documentLoader)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#validation-in-typescript","title":"Validation in TypeScript","text":"<pre><code>import Ajv from \"ajv\";\nimport toolSchema from \"./tool.schema.json\";\n\nconst ajv = new Ajv();\nconst validate = ajv.compile(toolSchema);\nconst valid = validate(myTool);\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#schema-uris","title":"Schema URIs","text":"<p>All schemas are published at: - <code>https://aperturestack.dev/schemas/{name}.schema.json</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#versioning","title":"Versioning","text":"<p>Schemas follow semantic versioning. Breaking changes increment the major version and are published as new files (e.g., <code>tool.v2.schema.json</code>). <pre><code>---\n\n## Verification Checklist\n\n- [ ] All 5 schema files created\n- [ ] JSON syntax is valid\n- [ ] Schema `$id` URIs are consistent\n- [ ] Cross-references use correct paths\n- [ ] README documents all schemas\n- [ ] Go package mappings are accurate\n\n**Validation Commands:**\n```bash\n# Validate JSON syntax\nfor f in schemas/*.json; do\n  python3 -m json.tool \"$f\" &gt; /dev/null &amp;&amp; echo \"\u2713 $f\" || echo \"\u2717 $f\"\ndone\n\n# Validate schema structure (requires ajv-cli)\nnpx ajv validate -s schemas/tool.schema.json -d /dev/null --strict=false\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>All schemas are valid JSON Schema draft 2020-12</li> <li>Schemas accurately represent Go types</li> <li>Cross-references resolve correctly</li> <li>Documentation is complete</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#rollback-plan","title":"Rollback Plan","text":"<pre><code>rm -rf schemas/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-102-schema-definitions/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-110: Repository Creation</li> <li>PRD-120: Migrate toolmodel (implement schema validation)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-119-remediation/","title":"PRD-110\u2013119 Remediation Plan","text":"<p>Date: 2026-01-31 Owner: Jon W. Raymond Scope: PRD-110, PRD-111, PRD-112, PRD-113</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-119-remediation/#objective","title":"Objective","text":"<p>Close the Phase 1 infrastructure gaps by stabilizing repository setup, CI/CD workflows, org/repo settings, and release automation.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-119-remediation/#deliverables","title":"Deliverables","text":"Item Location Status Workflow templates <code>.github/workflow-templates/*</code> Done Dependency review workflow <code>.github/workflows/dependency-review.yml</code> (each repo) Done Release-please config updated <code>release-please-config.json</code> (each repo) Done Release-please manifest normalized <code>.release-please-manifest.json</code> Done Workflow permissions set Repo settings (GITHUB_TOKEN write) Done Branch protection applied main branch Done Repo settings standardized allow-squash/rebase, delete-branch Done Topics + descriptions set per-repo Done"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-119-remediation/#plan-of-record","title":"Plan of Record","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-119-remediation/#task-1-repo-baseline-prd-110","title":"Task 1 \u2014 Repo Baseline (PRD-110)","text":"<ul> <li>Verify all six repos exist and are public.</li> <li>Verify standard structure and workflows exist.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-119-remediation/#task-2-cicd-templates-prd-111","title":"Task 2 \u2014 CI/CD Templates (PRD-111)","text":"<ul> <li>Add <code>.github/workflow-templates/</code> in root with CI, lint, commitlint, release-please, dependency-review templates.</li> <li>Add dependency-review workflow to each consolidated repo.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-119-remediation/#task-3-github-orgrepo-config-prd-112","title":"Task 3 \u2014 GitHub Org/Repo Config (PRD-112)","text":"<ul> <li>Enable workflow permissions (GITHUB_TOKEN write).</li> <li>Apply branch protection (status checks + code owner review).</li> <li>Standardize repo settings (merge strategy, delete branch on merge).</li> <li>Set topics + descriptions.</li> <li>Enable security features (vulnerability alerts + automated fixes).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-119-remediation/#task-4-release-automation-prd-113","title":"Task 4 \u2014 Release Automation (PRD-113)","text":"<ul> <li>Update <code>release-please-config.json</code> to include component naming per repo.</li> <li>Normalize <code>.release-please-manifest.json</code> to <code>{\".\": \"0.0.0\"}</code>.</li> <li>Verify release-please workflow permissions enable PR creation.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-119-remediation/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All six repos exist and are public</li> <li>[x] Workflow templates created</li> <li>[x] Dependency review workflow present in each repo</li> <li>[x] Release-please config/manifest updated per repo</li> <li>[x] Workflow permissions set to write</li> <li>[x] Branch protection enabled</li> <li>[x] Repo settings + topics applied</li> <li>[x] Security alerts enabled</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-119-remediation/#notes","title":"Notes","text":"<ul> <li>Org name in examples is <code>ApertureStack</code>, but active repos are under <code>jonwraymond</code>. Commands will target <code>jonwraymond/*</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/","title":"PRD-110: Repository Creation","text":"<p>Phase: 1 - Infrastructure Setup Priority: Critical Effort: 8 hours Dependencies: PRD-100</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#objective","title":"Objective","text":"<p>Create 6 new consolidated repositories with standardized structure, ready for code migration.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#repositories-to-create","title":"Repositories to Create","text":"Repository GitHub URL Description toolfoundation github.com/ApertureStack/toolfoundation Canonical schema, protocol adapters, versioning tooldiscovery github.com/ApertureStack/tooldiscovery Registry, search, semantic, documentation toolexec github.com/ApertureStack/toolexec Execution pipeline, runtime, code orchestration toolcompose github.com/ApertureStack/toolcompose Toolsets, agent skills toolops github.com/ApertureStack/toolops Observability, caching, resilience, health, auth toolprotocol github.com/ApertureStack/toolprotocol Transport, wire adapters, protocol features"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#standard-repository-structure","title":"Standard Repository Structure","text":"<p>Each repository follows this exact structure:</p> <pre><code>{repo-name}/\n\u251c\u2500\u2500 .github/\n\u2502   \u251c\u2500\u2500 CODEOWNERS\n\u2502   \u251c\u2500\u2500 PULL_REQUEST_TEMPLATE.md\n\u2502   \u251c\u2500\u2500 ISSUE_TEMPLATE/\n\u2502   \u2502   \u251c\u2500\u2500 bug_report.md\n\u2502   \u2502   \u2514\u2500\u2500 feature_request.md\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u251c\u2500\u2500 ci.yml\n\u2502       \u251c\u2500\u2500 lint-security.yml\n\u2502       \u251c\u2500\u2500 commitlint.yml\n\u2502       \u2514\u2500\u2500 release-please.yml\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 design-notes.md\n\u2502   \u2514\u2500\u2500 user-journey.md\n\u251c\u2500\u2500 examples/\n\u2502   \u2514\u2500\u2500 .gitkeep\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .golangci.yml\n\u251c\u2500\u2500 commitlint.config.cjs\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 go.sum\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 release-please-config.json\n\u2514\u2500\u2500 .release-please-manifest.json\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#task-1-create-github-repositories","title":"Task 1: Create GitHub Repositories","text":"<p>Commands: <pre><code># Using GitHub CLI\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  gh repo create ApertureStack/$repo \\\n    --public \\\n    --description \"ApertureStack $repo - AI tool ecosystem\" \\\n    --license MIT \\\n    --clone\ndone\n</code></pre></p> <p>Verification: <pre><code>gh repo list ApertureStack --limit 20\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#task-2-initialize-repository-structure","title":"Task 2: Initialize Repository Structure","text":"<p>For each repository, create the standard structure:</p> <p>Script: <code>scripts/init-repo.sh</code> <pre><code>#!/bin/bash\nset -euo pipefail\n\nREPO_NAME=$1\nMODULE_PATH=\"github.com/ApertureStack/$REPO_NAME\"\n\ncd \"$REPO_NAME\"\n\n# Create directories\nmkdir -p .github/workflows .github/ISSUE_TEMPLATE docs examples\n\n# Create .gitignore\ncat &gt; .gitignore &lt;&lt; 'EOF'\n# Binaries\n*.exe\n*.exe~\n*.dll\n*.so\n*.dylib\n*.test\n*.out\n\n# Go\nvendor/\ngo.work\ngo.work.sum\n\n# IDE\n.idea/\n.vscode/\n*.swp\n*.swo\n\n# OS\n.DS_Store\nThumbs.db\n\n# Coverage\ncoverage.out\ncoverage.html\n\n# Build\ndist/\nbin/\nEOF\n\n# Create go.mod\ncat &gt; go.mod &lt;&lt; EOF\nmodule $MODULE_PATH\n\ngo 1.24\nEOF\n\n# Create LICENSE (MIT)\ncat &gt; LICENSE &lt;&lt; 'EOF'\nMIT License\n\nCopyright (c) 2026 ApertureStack\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\nEOF\n\n# Create README.md\ncat &gt; README.md &lt;&lt; EOF\n# $REPO_NAME\n\nPart of the [ApertureStack](https://github.com/ApertureStack) AI tool ecosystem.\n\n## Installation\n\n\\`\\`\\`bash\ngo get $MODULE_PATH\n\\`\\`\\`\n\n## Packages\n\n| Package | Description | Documentation |\n|---------|-------------|---------------|\n| TBD | TBD | [docs](./docs/) |\n\n## License\n\nMIT License - see [LICENSE](./LICENSE)\nEOF\n\n# Create CHANGELOG.md\ncat &gt; CHANGELOG.md &lt;&lt; 'EOF'\n# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [Unreleased]\n\n### Added\n- Initial repository structure\nEOF\n\n# Create .golangci.yml\ncat &gt; .golangci.yml &lt;&lt; 'EOF'\nrun:\n  timeout: 5m\n  modules-download-mode: readonly\n\nlinters:\n  enable:\n    - errcheck\n    - gosimple\n    - govet\n    - ineffassign\n    - staticcheck\n    - unused\n    - gofmt\n    - goimports\n    - misspell\n    - unconvert\n    - unparam\n\nlinters-settings:\n  goimports:\n    local-prefixes: github.com/ApertureStack\n\nissues:\n  exclude-use-default: false\n  max-issues-per-linter: 0\n  max-same-issues: 0\nEOF\n\n# Create commitlint.config.cjs\ncat &gt; commitlint.config.cjs &lt;&lt; 'EOF'\nmodule.exports = { extends: ['@commitlint/config-conventional'] };\nEOF\n\n# Create release-please-config.json\ncat &gt; release-please-config.json &lt;&lt; 'EOF'\n{\n  \"$schema\": \"https://raw.githubusercontent.com/googleapis/release-please/main/schemas/config.json\",\n  \"release-type\": \"go\",\n  \"packages\": {\n    \".\": {}\n  },\n  \"changelog-sections\": [\n    {\"type\": \"feat\", \"section\": \"Features\"},\n    {\"type\": \"fix\", \"section\": \"Bug Fixes\"},\n    {\"type\": \"perf\", \"section\": \"Performance Improvements\"},\n    {\"type\": \"refactor\", \"section\": \"Code Refactoring\"},\n    {\"type\": \"docs\", \"section\": \"Documentation\"},\n    {\"type\": \"chore\", \"section\": \"Miscellaneous\"}\n  ]\n}\nEOF\n\n# Create .release-please-manifest.json\necho '{\".\":\" 0.0.0\"}' &gt; .release-please-manifest.json\n\n# Create GitHub templates\ncat &gt; .github/CODEOWNERS &lt;&lt; 'EOF'\n* @jonwraymond\nEOF\n\ncat &gt; .github/PULL_REQUEST_TEMPLATE.md &lt;&lt; 'EOF'\n## Description\n\n&lt;!-- Describe your changes --&gt;\n\n## Type of Change\n\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update\n\n## Checklist\n\n- [ ] Tests pass (`go test ./...`)\n- [ ] Linter passes (`golangci-lint run`)\n- [ ] Documentation updated\n- [ ] CHANGELOG.md updated (if applicable)\nEOF\n\ncat &gt; .github/ISSUE_TEMPLATE/bug_report.md &lt;&lt; 'EOF'\n---\nname: Bug Report\nabout: Report a bug\ntitle: '[BUG] '\nlabels: bug\n---\n\n## Description\n\n## Steps to Reproduce\n\n1.\n2.\n3.\n\n## Expected Behavior\n\n## Actual Behavior\n\n## Environment\n\n- Go version:\n- OS:\nEOF\n\ncat &gt; .github/ISSUE_TEMPLATE/feature_request.md &lt;&lt; 'EOF'\n---\nname: Feature Request\nabout: Suggest a feature\ntitle: '[FEATURE] '\nlabels: enhancement\n---\n\n## Description\n\n## Use Case\n\n## Proposed Solution\n\n## Alternatives Considered\nEOF\n\n# Create docs\ncat &gt; docs/index.md &lt;&lt; EOF\n# $REPO_NAME\n\nOverview documentation for $REPO_NAME.\n\n## Packages\n\nTBD\n\n## Getting Started\n\nTBD\nEOF\n\ncat &gt; docs/design-notes.md &lt;&lt; 'EOF'\n# Design Notes\n\n## Architecture Decisions\n\nTBD\n\n## Trade-offs\n\nTBD\nEOF\n\ncat &gt; docs/user-journey.md &lt;&lt; 'EOF'\n# User Journey\n\n## Installation\n\nTBD\n\n## Basic Usage\n\nTBD\n\n## Advanced Usage\n\nTBD\nEOF\n\n# Create examples placeholder\ntouch examples/.gitkeep\n\necho \"\u2705 Initialized $REPO_NAME\"\n</code></pre></p> <p>Execute: <pre><code>chmod +x scripts/init-repo.sh\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  ./scripts/init-repo.sh $repo\ndone\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#task-3-create-ci-workflows","title":"Task 3: Create CI Workflows","text":"<p>File: <code>.github/workflows/ci.yml</code> <pre><code>name: CI\n\non:\n  push:\n    branches: [\"main\"]\n    paths-ignore:\n      - \"**.md\"\n      - \"docs/**\"\n  pull_request:\n    paths-ignore:\n      - \"**.md\"\n      - \"docs/**\"\n\npermissions:\n  contents: read\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        go: [\"1.24\"]\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: ${{ matrix.go }}\n          cache: true\n\n      - name: Download dependencies\n        run: go mod download\n\n      - name: Verify dependencies\n        run: go mod verify\n\n      - name: Build\n        run: go build ./...\n\n      - name: Test\n        run: go test -race -coverprofile=coverage.out -covermode=atomic ./...\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          token: ${{ secrets.CODECOV_TOKEN }}\n          files: coverage.out\n          fail_ci_if_error: false\n</code></pre></p> <p>File: <code>.github/workflows/lint-security.yml</code> <pre><code>name: Lint &amp; Security\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n\npermissions:\n  contents: read\n  security-events: write\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n          cache: true\n\n      - name: golangci-lint\n        uses: golangci/golangci-lint-action@v6\n        with:\n          version: latest\n          args: --timeout=5m\n\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n\n      - name: Run gosec\n        uses: securego/gosec@master\n        with:\n          args: -fmt sarif -out gosec.sarif ./...\n\n      - name: Upload SARIF\n        uses: github/codeql-action/upload-sarif@v3\n        with:\n          sarif_file: gosec.sarif\n</code></pre></p> <p>File: <code>.github/workflows/commitlint.yml</code> <pre><code>name: Commitlint\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n\njobs:\n  commitlint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup Node\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"20\"\n\n      - name: Install commitlint\n        run: npm install -g @commitlint/cli @commitlint/config-conventional\n\n      - name: Lint commits\n        run: npx commitlint --from HEAD~1 --to HEAD --verbose\n</code></pre></p> <p>File: <code>.github/workflows/release-please.yml</code> <pre><code>name: Release Please\n\non:\n  push:\n    branches: [\"main\"]\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  release-please:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Release Please\n        uses: google-github-actions/release-please-action@v4\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          config-file: release-please-config.json\n          manifest-file: .release-please-manifest.json\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#task-4-push-initial-structure","title":"Task 4: Push Initial Structure","text":"<pre><code>for repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  cd $repo\n  git add -A\n  git commit -m \"feat: initial repository structure\n\n- Add standard directory layout\n- Add CI/CD workflows\n- Add documentation templates\n- Add release automation\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n  git push origin main\n  cd ..\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#task-5-add-as-submodules-to-aperturestack","title":"Task 5: Add as Submodules to ApertureStack","text":"<pre><code>cd /Users/jraymond/Documents/Projects/ApertureStack\n\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  git submodule add git@github.com:ApertureStack/$repo.git $repo\ndone\n\ngit add .gitmodules\ngit commit -m \"feat: add consolidated repository submodules\n\n- toolfoundation (model, adapter, version)\n- tooldiscovery (index, search, semantic, docs)\n- toolexec (run, runtime, code, backend)\n- toolcompose (set, skill)\n- toolops (observe, cache, resilience, health, auth)\n- toolprotocol (transport, wire, discover, content, task, stream, session, elicit, resource, prompt)\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All 6 repositories created on GitHub</li> <li>[ ] Each repo has correct structure</li> <li>[ ] Each repo has all 4 workflow files</li> <li>[ ] All workflows pass initial run</li> <li>[ ] Repos added as submodules to ApertureStack</li> <li>[ ] Git push succeeds for all repos</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>gh repo view ApertureStack/{toolfoundation,tooldiscovery,toolexec,toolcompose,toolops,toolprotocol}</code> succeeds</li> <li>Each repo has passing CI badge</li> <li>Release-please PR created on first push</li> <li>Submodules appear in ApertureStack root</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#rollback-plan","title":"Rollback Plan","text":"<pre><code># Delete repos if needed\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  gh repo delete ApertureStack/$repo --yes\ndone\n\n# Remove submodules\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  git submodule deinit -f $repo\n  git rm -f $repo\n  rm -rf .git/modules/$repo\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-110-repo-creation/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-111: CI/CD Templates (reusable workflows)</li> <li>PRD-112: GitHub Org Config (secrets)</li> <li>PRD-113: Release Automation (multi-package)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/","title":"PRD-111: CI/CD Templates","text":"<p>Phase: 1 - Infrastructure Setup Priority: High Effort: 4 hours Dependencies: PRD-110</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#objective","title":"Objective","text":"<p>Create reusable GitHub Actions workflow templates that will be used across all 6 consolidated repositories, ensuring consistent CI/CD practices.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#deliverables","title":"Deliverables","text":"Deliverable Location Description CI Template <code>.github/workflow-templates/ci.yml</code> Test, build, coverage Lint/Security <code>.github/workflow-templates/lint-security.yml</code> Linting + security scan Commitlint <code>.github/workflow-templates/commitlint.yml</code> Conventional commits Release Please <code>.github/workflow-templates/release-please.yml</code> Automated releases Dependency Review <code>.github/workflow-templates/dependency-review.yml</code> Dependency checks"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#task-1-create-workflow-templates-directory","title":"Task 1: Create Workflow Templates Directory","text":"<pre><code>mkdir -p .github/workflow-templates\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#task-2-ci-workflow-template","title":"Task 2: CI Workflow Template","text":"<p>File: <code>.github/workflow-templates/ci.yml</code></p> <pre><code># Template for ci.yml in all consolidated repos\n# Copy to .github/workflows/ci.yml\n\nname: CI\n\non:\n  push:\n    branches: [\"main\"]\n    paths-ignore:\n      - \"**.md\"\n      - \"docs/**\"\n      - \"examples/**\"\n  pull_request:\n    paths-ignore:\n      - \"**.md\"\n      - \"docs/**\"\n      - \"examples/**\"\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\nenv:\n  GO_VERSION: \"1.24\"\n  GOPRIVATE: \"github.com/ApertureStack/*\"\n\njobs:\n  test:\n    name: Test\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        go: [\"1.23\", \"1.24\"]\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: ${{ matrix.go }}\n          cache: true\n\n      - name: Configure Git for private repos\n        run: |\n          git config --global url.\"https://${{ secrets.GH_TOKEN }}@github.com/\".insteadOf \"https://github.com/\"\n\n      - name: Download dependencies\n        run: go mod download\n\n      - name: Verify dependencies\n        run: go mod verify\n\n      - name: Build\n        run: go build -v ./...\n\n      - name: Test with coverage\n        run: go test -race -coverprofile=coverage.out -covermode=atomic -v ./...\n\n      - name: Upload coverage\n        if: matrix.go == '1.24'\n        uses: codecov/codecov-action@v4\n        with:\n          token: ${{ secrets.CODECOV_TOKEN }}\n          files: coverage.out\n          fail_ci_if_error: false\n          verbose: true\n\n  integration:\n    name: Integration Tests\n    runs-on: ubuntu-latest\n    needs: test\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: ${{ env.GO_VERSION }}\n          cache: true\n\n      - name: Run integration tests\n        run: go test -tags=integration -v ./...\n        env:\n          INTEGRATION_TEST: \"true\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#task-3-lint-security-workflow-template","title":"Task 3: Lint &amp; Security Workflow Template","text":"<p>File: <code>.github/workflow-templates/lint-security.yml</code></p> <pre><code># Template for lint-security.yml in all consolidated repos\n# Copy to .github/workflows/lint-security.yml\n\nname: Lint &amp; Security\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n\npermissions:\n  contents: read\n  security-events: write\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  lint:\n    name: Lint\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n          cache: true\n\n      - name: golangci-lint\n        uses: golangci/golangci-lint-action@v6\n        with:\n          version: latest\n          args: --timeout=5m --config=.golangci.yml\n\n  security:\n    name: Security Scan\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n\n      - name: Run gosec\n        uses: securego/gosec@master\n        with:\n          args: -fmt sarif -out gosec.sarif -exclude-dir=examples ./...\n\n      - name: Upload SARIF\n        uses: github/codeql-action/upload-sarif@v3\n        if: always()\n        with:\n          sarif_file: gosec.sarif\n\n  govulncheck:\n    name: Vulnerability Check\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n\n      - name: Install govulncheck\n        run: go install golang.org/x/vuln/cmd/govulncheck@latest\n\n      - name: Run govulncheck\n        run: govulncheck ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#task-4-commitlint-workflow-template","title":"Task 4: Commitlint Workflow Template","text":"<p>File: <code>.github/workflow-templates/commitlint.yml</code></p> <pre><code># Template for commitlint.yml in all consolidated repos\n# Copy to .github/workflows/commitlint.yml\n\nname: Commitlint\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n\npermissions:\n  contents: read\n\njobs:\n  commitlint:\n    name: Lint Commits\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup Node\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"20\"\n\n      - name: Install commitlint\n        run: npm install -g @commitlint/cli @commitlint/config-conventional\n\n      - name: Validate current commit (push)\n        if: github.event_name == 'push'\n        run: npx commitlint --from HEAD~1 --to HEAD --verbose\n\n      - name: Validate PR commits\n        if: github.event_name == 'pull_request'\n        run: npx commitlint --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }} --verbose\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#task-5-release-please-workflow-template","title":"Task 5: Release Please Workflow Template","text":"<p>File: <code>.github/workflow-templates/release-please.yml</code></p> <pre><code># Template for release-please.yml in all consolidated repos\n# Copy to .github/workflows/release-please.yml\n\nname: Release Please\n\non:\n  push:\n    branches: [\"main\"]\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  release-please:\n    name: Release\n    runs-on: ubuntu-latest\n    outputs:\n      release_created: ${{ steps.release.outputs.release_created }}\n      tag_name: ${{ steps.release.outputs.tag_name }}\n      version: ${{ steps.release.outputs.version }}\n    steps:\n      - name: Release Please\n        id: release\n        uses: google-github-actions/release-please-action@v4\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          config-file: release-please-config.json\n          manifest-file: .release-please-manifest.json\n\n      - name: Checkout (on release)\n        if: steps.release.outputs.release_created\n        uses: actions/checkout@v4\n\n      - name: Set up Go (on release)\n        if: steps.release.outputs.release_created\n        uses: actions/setup-go@v5\n        with:\n          go-version-file: go.mod\n\n      - name: Verify module (on release)\n        if: steps.release.outputs.release_created\n        run: |\n          go mod verify\n          go build ./...\n          go test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#task-6-dependency-review-workflow-template","title":"Task 6: Dependency Review Workflow Template","text":"<p>File: <code>.github/workflow-templates/dependency-review.yml</code></p> <pre><code># Template for dependency-review.yml in all consolidated repos\n# Copy to .github/workflows/dependency-review.yml\n\nname: Dependency Review\n\non:\n  pull_request:\n    paths:\n      - \"go.mod\"\n      - \"go.sum\"\n\npermissions:\n  contents: read\n  pull-requests: write\n\njobs:\n  dependency-review:\n    name: Review Dependencies\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Dependency Review\n        uses: actions/dependency-review-action@v4\n        with:\n          fail-on-severity: high\n          deny-licenses: GPL-3.0, AGPL-3.0\n          allow-licenses: MIT, Apache-2.0, BSD-2-Clause, BSD-3-Clause, ISC\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#task-7-create-template-readme","title":"Task 7: Create Template README","text":"<p>File: <code>.github/workflow-templates/README.md</code></p> <pre><code># Workflow Templates\n\nReusable GitHub Actions workflows for ApertureStack consolidated repositories.\n\n## Usage\n\nCopy the needed workflow files to `.github/workflows/` in each repository:\n\n```bash\n# From repository root\ncp /path/to/workflow-templates/*.yml .github/workflows/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#workflows","title":"Workflows","text":"Workflow Triggers Purpose <code>ci.yml</code> push, PR Build, test, coverage <code>lint-security.yml</code> push, PR golangci-lint, gosec, govulncheck <code>commitlint.yml</code> push, PR Conventional commits <code>release-please.yml</code> push to main Automated releases <code>dependency-review.yml</code> PR (go.mod) License + vulnerability check"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#required-secrets","title":"Required Secrets","text":"Secret Scope Purpose <code>CODECOV_TOKEN</code> Org Coverage upload <code>GH_TOKEN</code> Org Private repo access"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#customization","title":"Customization","text":"<p>Each workflow includes comments for customization points: - Go version matrix - Test tags - Lint configuration - Security exclusions <pre><code>---\n\n## Verification Checklist\n\n- [ ] All 5 workflow templates created\n- [ ] YAML syntax valid\n- [ ] Consistent naming conventions\n- [ ] Required secrets documented\n- [ ] README explains usage\n- [ ] Templates tested locally with `act` (optional)\n\n**Validation:**\n```bash\n# Validate YAML syntax\nfor f in .github/workflow-templates/*.yml; do\n  python3 -c \"import yaml; yaml.safe_load(open('$f'))\" &amp;&amp; echo \"\u2713 $f\" || echo \"\u2717 $f\"\ndone\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>All templates are valid GitHub Actions syntax</li> <li>Workflows can be copied directly to repos</li> <li>Documentation is complete</li> <li>Secrets requirements are documented</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#rollback-plan","title":"Rollback Plan","text":"<pre><code>rm -rf .github/workflow-templates/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-111-cicd-templates/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-112: GitHub Org Config (configure secrets)</li> <li>PRD-113: Release Automation (release-please config)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/","title":"PRD-112: GitHub Organization Configuration","text":"<p>Phase: 1 - Infrastructure Setup Priority: High Effort: 2 hours Dependencies: PRD-110</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#objective","title":"Objective","text":"<p>Configure GitHub organization settings, secrets, and branch protection rules for all ApertureStack repositories.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#deliverables","title":"Deliverables","text":"Deliverable Description Org Secrets CODECOV_TOKEN, GH_TOKEN configured Branch Protection Main branch protection on all repos Repository Settings Consistent settings across repos Teams CODEOWNERS team configuration"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#task-1-configure-organization-secrets","title":"Task 1: Configure Organization Secrets","text":"<p>Commands: <pre><code># Set organization-level secrets (requires admin access)\n# These secrets are inherited by all repos in the org\n\n# Codecov token for coverage uploads\ngh secret set CODECOV_TOKEN --org ApertureStack --visibility all\n\n# GitHub token for cross-repo access (PAT with repo scope)\ngh secret set GH_TOKEN --org ApertureStack --visibility all\n\n# Verify secrets are set\ngh secret list --org ApertureStack\n</code></pre></p> <p>Required Secrets:</p> Secret Purpose Scope <code>CODECOV_TOKEN</code> Upload test coverage to Codecov All repos <code>GH_TOKEN</code> Access private repos in go mod download All repos"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#task-2-configure-branch-protection","title":"Task 2: Configure Branch Protection","text":"<p>Script: <code>scripts/configure-branch-protection.sh</code></p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nREPOS=(\n  toolfoundation\n  tooldiscovery\n  toolexec\n  toolcompose\n  toolops\n  toolprotocol\n)\n\nfor repo in \"${REPOS[@]}\"; do\n  echo \"Configuring branch protection for ApertureStack/$repo...\"\n\n  gh api \\\n    --method PUT \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"/repos/ApertureStack/$repo/branches/main/protection\" \\\n    -f required_status_checks='{\"strict\":true,\"contexts\":[\"test\",\"lint\"]}' \\\n    -f enforce_admins=false \\\n    -f required_pull_request_reviews='{\"dismiss_stale_reviews\":true,\"require_code_owner_reviews\":true,\"required_approving_review_count\":1}' \\\n    -f restrictions=null \\\n    -f allow_force_pushes=false \\\n    -f allow_deletions=false \\\n    -f block_creations=false \\\n    -f required_conversation_resolution=true\n\n  echo \"\u2713 $repo configured\"\ndone\n\necho \"All repositories configured!\"\n</code></pre> <p>Execute: <pre><code>chmod +x scripts/configure-branch-protection.sh\n./scripts/configure-branch-protection.sh\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#task-3-configure-repository-settings","title":"Task 3: Configure Repository Settings","text":"<p>Script: <code>scripts/configure-repo-settings.sh</code></p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nREPOS=(\n  toolfoundation\n  tooldiscovery\n  toolexec\n  toolcompose\n  toolops\n  toolprotocol\n)\n\nfor repo in \"${REPOS[@]}\"; do\n  echo \"Configuring settings for ApertureStack/$repo...\"\n\n  # Update repository settings\n  gh api \\\n    --method PATCH \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"/repos/ApertureStack/$repo\" \\\n    -f has_issues=true \\\n    -f has_projects=false \\\n    -f has_wiki=false \\\n    -f has_discussions=false \\\n    -f allow_squash_merge=true \\\n    -f allow_merge_commit=false \\\n    -f allow_rebase_merge=true \\\n    -f allow_auto_merge=true \\\n    -f delete_branch_on_merge=true \\\n    -f allow_update_branch=true\n\n  echo \"\u2713 $repo settings updated\"\ndone\n\necho \"All repository settings configured!\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#task-4-configure-topics-and-description","title":"Task 4: Configure Topics and Description","text":"<p>Script: <code>scripts/configure-repo-topics.sh</code></p> <pre><code>#!/bin/bash\nset -euo pipefail\n\ndeclare -A DESCRIPTIONS=(\n  [\"toolfoundation\"]=\"Core schemas, protocol adapters, and versioning for ApertureStack AI tool ecosystem\"\n  [\"tooldiscovery\"]=\"Tool registry, search, semantic indexing, and documentation\"\n  [\"toolexec\"]=\"Tool execution pipeline, runtime sandboxing, and code orchestration\"\n  [\"toolcompose\"]=\"Tool composition, toolsets, and agent skills\"\n  [\"toolops\"]=\"Observability, caching, resilience, health checks, and authentication\"\n  [\"toolprotocol\"]=\"Multi-protocol transport layer: MCP, A2A, ACP adapters\"\n)\n\nCOMMON_TOPICS=\"golang,ai-tools,mcp,llm-tools,agent-tools\"\n\ndeclare -A SPECIFIC_TOPICS=(\n  [\"toolfoundation\"]=\"json-schema,protocol-adapters\"\n  [\"tooldiscovery\"]=\"search,bm25,semantic-search\"\n  [\"toolexec\"]=\"execution,sandbox,docker,wasm\"\n  [\"toolcompose\"]=\"composition,skills,toolsets\"\n  [\"toolops\"]=\"observability,caching,circuit-breaker,authentication\"\n  [\"toolprotocol\"]=\"mcp-protocol,a2a-protocol,grpc,websocket\"\n)\n\nfor repo in \"${!DESCRIPTIONS[@]}\"; do\n  echo \"Configuring ApertureStack/$repo...\"\n\n  # Update description\n  gh repo edit \"ApertureStack/$repo\" --description \"${DESCRIPTIONS[$repo]}\"\n\n  # Set topics\n  TOPICS=\"$COMMON_TOPICS,${SPECIFIC_TOPICS[$repo]}\"\n  gh api \\\n    --method PUT \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"/repos/ApertureStack/$repo/topics\" \\\n    -f names=\"[$(echo $TOPICS | sed 's/,/\",\"/g' | sed 's/^/\"/' | sed 's/$/\"/')\"]\"\n\n  echo \"\u2713 $repo configured\"\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#task-5-configure-codeowners","title":"Task 5: Configure CODEOWNERS","text":"<p>Each repository already has <code>.github/CODEOWNERS</code> from PRD-110. Verify:</p> <pre><code>for repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  echo \"Checking CODEOWNERS in $repo...\"\n  gh api \"/repos/ApertureStack/$repo/contents/.github/CODEOWNERS\" -q '.content' | base64 -d\ndone\n</code></pre> <p>Expected content: <pre><code>* @jonwraymond\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#task-6-configure-security-settings","title":"Task 6: Configure Security Settings","text":"<pre><code>#!/bin/bash\nset -euo pipefail\n\nREPOS=(\n  toolfoundation\n  tooldiscovery\n  toolexec\n  toolcompose\n  toolops\n  toolprotocol\n)\n\nfor repo in \"${REPOS[@]}\"; do\n  echo \"Enabling security features for ApertureStack/$repo...\"\n\n  # Enable Dependabot alerts\n  gh api \\\n    --method PUT \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"/repos/ApertureStack/$repo/vulnerability-alerts\"\n\n  # Enable Dependabot security updates\n  gh api \\\n    --method PUT \\\n    -H \"Accept: application/vnd.github+json\" \\\n    \"/repos/ApertureStack/$repo/automated-security-fixes\"\n\n  echo \"\u2713 $repo security enabled\"\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#task-7-verification","title":"Task 7: Verification","text":"<pre><code># Verify all configurations\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  echo \"=== ApertureStack/$repo ===\"\n\n  # Check branch protection\n  gh api \"/repos/ApertureStack/$repo/branches/main/protection\" -q '.required_status_checks.contexts[]' 2&gt;/dev/null || echo \"No branch protection\"\n\n  # Check secrets (just confirms they exist)\n  gh secret list -R \"ApertureStack/$repo\" 2&gt;/dev/null || echo \"Using org secrets\"\n\n  # Check settings\n  gh repo view \"ApertureStack/$repo\" --json allowSquashMerge,deleteBranchOnMerge\n\n  echo \"\"\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] CODECOV_TOKEN org secret configured</li> <li>[ ] GH_TOKEN org secret configured</li> <li>[ ] Branch protection enabled on all repos</li> <li>[ ] Require status checks (test, lint)</li> <li>[ ] Require code review</li> <li>[ ] Squash merge enabled</li> <li>[ ] Delete branch on merge enabled</li> <li>[ ] Dependabot alerts enabled</li> <li>[ ] Repository topics set</li> <li>[ ] CODEOWNERS verified</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>All org secrets are accessible to workflows</li> <li>PRs require passing CI and code review</li> <li>Force push to main is blocked</li> <li>Consistent settings across all repos</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#rollback-plan","title":"Rollback Plan","text":"<pre><code># Disable branch protection (allows force push to fix issues)\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  gh api --method DELETE \"/repos/ApertureStack/$repo/branches/main/protection\"\ndone\n\n# Remove org secrets\ngh secret delete CODECOV_TOKEN --org ApertureStack\ngh secret delete GH_TOKEN --org ApertureStack\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-112-github-org-config/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-113: Release Automation</li> <li>PRD-120: Migrate toolmodel</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/","title":"PRD-113: Release Automation","text":"<p>Phase: 1 - Infrastructure Setup Priority: High Effort: 2 hours Dependencies: PRD-110, PRD-111</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#objective","title":"Objective","text":"<p>Configure release-please for automated semantic versioning and changelog generation across all consolidated repositories.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Release Config <code>release-please-config.json</code> Per-repo release configuration Manifest <code>.release-please-manifest.json</code> Version tracking Changelog Sections Configured Categorized changelog entries"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#task-1-create-release-configuration-template","title":"Task 1: Create Release Configuration Template","text":"<p>File: <code>release-please-config.json</code> (template for all repos)</p> <pre><code>{\n  \"$schema\": \"https://raw.githubusercontent.com/googleapis/release-please/main/schemas/config.json\",\n  \"release-type\": \"go\",\n  \"packages\": {\n    \".\": {\n      \"component\": \"REPO_NAME\",\n      \"changelog-path\": \"CHANGELOG.md\"\n    }\n  },\n  \"changelog-sections\": [\n    {\"type\": \"feat\", \"section\": \"Features\", \"hidden\": false},\n    {\"type\": \"fix\", \"section\": \"Bug Fixes\", \"hidden\": false},\n    {\"type\": \"perf\", \"section\": \"Performance Improvements\", \"hidden\": false},\n    {\"type\": \"refactor\", \"section\": \"Code Refactoring\", \"hidden\": false},\n    {\"type\": \"docs\", \"section\": \"Documentation\", \"hidden\": false},\n    {\"type\": \"test\", \"section\": \"Tests\", \"hidden\": true},\n    {\"type\": \"chore\", \"section\": \"Miscellaneous\", \"hidden\": true},\n    {\"type\": \"ci\", \"section\": \"Continuous Integration\", \"hidden\": true},\n    {\"type\": \"build\", \"section\": \"Build System\", \"hidden\": true}\n  ],\n  \"bump-minor-pre-major\": true,\n  \"bump-patch-for-minor-pre-major\": true,\n  \"draft\": false,\n  \"prerelease\": false,\n  \"include-component-in-tag\": false,\n  \"include-v-in-tag\": true,\n  \"pull-request-title-pattern\": \"chore(release): ${version}\",\n  \"pull-request-header\": \"## Release PR\\n\\nThis PR was generated by release-please.\",\n  \"separate-pull-requests\": false,\n  \"sequential-calls\": false,\n  \"group-pull-request-title-pattern\": \"chore(release): ${version}\",\n  \"release-search-depth\": 500,\n  \"commit-search-depth\": 500\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#task-2-create-manifest-template","title":"Task 2: Create Manifest Template","text":"<p>File: <code>.release-please-manifest.json</code> (template)</p> <pre><code>{\n  \".\": \"0.0.0\"\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#task-3-deploy-to-all-repositories","title":"Task 3: Deploy to All Repositories","text":"<p>Script: <code>scripts/deploy-release-config.sh</code></p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nREPOS=(\n  toolfoundation\n  tooldiscovery\n  toolexec\n  toolcompose\n  toolops\n  toolprotocol\n)\n\nBASE_DIR=$(pwd)\n\nfor repo in \"${REPOS[@]}\"; do\n  REPO_DIR=\"../$repo\"\n\n  if [ ! -d \"$REPO_DIR\" ]; then\n    echo \"\u26a0 $repo directory not found, skipping...\"\n    continue\n  fi\n\n  echo \"Configuring release-please for $repo...\"\n\n  cd \"$REPO_DIR\"\n\n  # Create release-please-config.json with repo-specific component name\n  cat &gt; release-please-config.json &lt;&lt; EOF\n{\n  \"\\$schema\": \"https://raw.githubusercontent.com/googleapis/release-please/main/schemas/config.json\",\n  \"release-type\": \"go\",\n  \"packages\": {\n    \".\": {\n      \"component\": \"$repo\",\n      \"changelog-path\": \"CHANGELOG.md\"\n    }\n  },\n  \"changelog-sections\": [\n    {\"type\": \"feat\", \"section\": \"Features\", \"hidden\": false},\n    {\"type\": \"fix\", \"section\": \"Bug Fixes\", \"hidden\": false},\n    {\"type\": \"perf\", \"section\": \"Performance Improvements\", \"hidden\": false},\n    {\"type\": \"refactor\", \"section\": \"Code Refactoring\", \"hidden\": false},\n    {\"type\": \"docs\", \"section\": \"Documentation\", \"hidden\": false},\n    {\"type\": \"test\", \"section\": \"Tests\", \"hidden\": true},\n    {\"type\": \"chore\", \"section\": \"Miscellaneous\", \"hidden\": true},\n    {\"type\": \"ci\", \"section\": \"Continuous Integration\", \"hidden\": true},\n    {\"type\": \"build\", \"section\": \"Build System\", \"hidden\": true}\n  ],\n  \"bump-minor-pre-major\": true,\n  \"bump-patch-for-minor-pre-major\": true,\n  \"draft\": false,\n  \"prerelease\": false,\n  \"include-component-in-tag\": false,\n  \"include-v-in-tag\": true,\n  \"pull-request-title-pattern\": \"chore(release): \\${version}\",\n  \"separate-pull-requests\": false\n}\nEOF\n\n  # Create manifest\n  echo '{\".\":\" 0.0.0\"}' &gt; .release-please-manifest.json\n\n  # Commit if there are changes\n  if [ -n \"$(git status --porcelain)\" ]; then\n    git add release-please-config.json .release-please-manifest.json\n    git commit -m \"chore: configure release-please\n\n- Add release-please-config.json\n- Add .release-please-manifest.json\n- Configure changelog sections\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n    git push origin main\n    echo \"\u2713 $repo configured and pushed\"\n  else\n    echo \"\u2713 $repo already configured\"\n  fi\n\n  cd \"$BASE_DIR\"\ndone\n\necho \"\"\necho \"All repositories configured!\"\necho \"\"\necho \"Release-please will create PRs on next push to main with conventional commits.\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#task-4-verify-release-workflow","title":"Task 4: Verify Release Workflow","text":"<p>After pushing changes, verify the release-please workflow runs:</p> <pre><code>for repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  echo \"=== ApertureStack/$repo ===\"\n  gh run list -R \"ApertureStack/$repo\" --workflow=\"Release Please\" --limit 1\n  echo \"\"\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#task-5-test-release-flow","title":"Task 5: Test Release Flow","text":"<p>Create a test commit to verify the release process:</p> <pre><code>cd ../toolfoundation\n\n# Create a feature commit (this will trigger a minor version bump)\necho \"// test\" &gt;&gt; model/doc.go\ngit add model/doc.go\ngit commit -m \"feat: add initial model package\n\nThis commit sets up the foundation model package structure.\n\n- Add doc.go with package documentation\n- Prepare for tool schema types\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n\n# Check for release PR\nsleep 30  # Wait for workflow to run\ngh pr list -R \"ApertureStack/toolfoundation\" --label \"autorelease: pending\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#task-6-document-release-process","title":"Task 6: Document Release Process","text":"<p>File: <code>docs/RELEASE-PROCESS.md</code></p> <pre><code># Release Process\n\n## Overview\n\nAll ApertureStack repositories use [Release Please](https://github.com/googleapis/release-please) for automated releases.\n\n## How It Works\n\n1. **Commit with Conventional Commits**\n   ```bash\n   git commit -m \"feat: add new feature\"\n   git commit -m \"fix: resolve bug\"\n   git commit -m \"docs: update readme\"\n   ```\n\n2. **Push to Main**\n   ```bash\n   git push origin main\n   ```\n\n3. **Release PR Created**\n   - Release Please analyzes commits\n   - Creates/updates a release PR\n   - Generates CHANGELOG.md entries\n\n4. **Merge Release PR**\n   - Review the generated changelog\n   - Merge the PR\n   - Tag is created automatically\n   - GitHub Release is published\n\n## Version Bumping\n\n| Commit Type | Version Bump |\n|-------------|--------------|\n| `feat:` | Minor (0.1.0 \u2192 0.2.0) |\n| `fix:` | Patch (0.1.0 \u2192 0.1.1) |\n| `feat!:` or `BREAKING CHANGE:` | Major (0.1.0 \u2192 1.0.0) |\n| `docs:`, `chore:`, `ci:` | No bump |\n\n## Breaking Changes\n\nInclude `BREAKING CHANGE:` in the commit body:\n\n```bash\ngit commit -m \"feat: change API\n\nBREAKING CHANGE: This changes the public API signature\"\n</code></pre> <p>Or use <code>!</code> after the type:</p> <pre><code>git commit -m \"feat!: change API signature\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#manual-release","title":"Manual Release","text":"<p>If needed, you can create a release manually:</p> <pre><code># Create tag\ngit tag v1.0.0\ngit push origin v1.0.0\n\n# Create GitHub release\ngh release create v1.0.0 --generate-notes\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#release-pr-not-created","title":"Release PR not created","text":"<ol> <li>Check workflow ran: <code>gh run list --workflow=\"Release Please\"</code></li> <li>Verify conventional commits: <code>git log --oneline -5</code></li> <li>Check manifest: <code>cat .release-please-manifest.json</code></li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#wrong-version","title":"Wrong version","text":"<p>Edit <code>.release-please-manifest.json</code> to set the correct version. <pre><code>---\n\n## Verification Checklist\n\n- [ ] `release-please-config.json` in all repos\n- [ ] `.release-please-manifest.json` in all repos\n- [ ] Release Please workflow exists in all repos\n- [ ] Changelog sections configured correctly\n- [ ] Test commit triggers release PR\n- [ ] Documentation created\n\n---\n\n## Acceptance Criteria\n\n1. Conventional commits trigger release PRs\n2. Changelog is generated with correct sections\n3. Version bumping follows semver\n4. Tags include `v` prefix (e.g., `v1.0.0`)\n5. Go module versioning works correctly\n\n---\n\n## Rollback Plan\n\n```bash\n# Remove release-please config\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  cd ../$repo\n  rm -f release-please-config.json .release-please-manifest.json\n  git add -A\n  git commit -m \"chore: remove release-please config\"\n  git push origin main\n  cd -\ndone\n\n# Delete release workflow\nfor repo in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  rm ../$repo/.github/workflows/release-please.yml\ndone\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-113-release-automation/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-120: Migrate toolmodel (first actual code migration)</li> <li>Gate G1: Verify all infrastructure is working</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/","title":"PRD-120: Migrate toolmodel","text":"<p>Phase: 2 - Foundation Layer Priority: Critical Effort: 4 hours Dependencies: PRD-110 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolmodel</code> repository into <code>toolfoundation/model/</code> as the first package in the consolidated foundation layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolmodel</code> Target Location: <code>github.com/jonwraymond/toolfoundation/model</code></p> <p>Package Contents: - Core tool schema types (<code>Tool</code>, <code>ToolInput</code>, <code>ToolOutput</code>) - JSON Schema validation - Serialization helpers - ~2,500 lines of code - 89.6% test coverage</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#deliverables","title":"Deliverables","text":"Deliverable Location Description Model Package <code>toolfoundation/model/</code> Migrated tool schema types Tests <code>toolfoundation/model/*_test.go</code> All existing tests Documentation <code>toolfoundation/model/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#task-1-clone-source-repository","title":"Task 1: Clone Source Repository","text":"<pre><code># Create working directory\nmkdir -p /tmp/migration\ncd /tmp/migration\n\n# Clone source with full history\ngit clone git@github.com:jonwraymond/toolmodel.git\ncd toolmodel\n\n# Verify contents\nls -la\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#task-2-prepare-target-repository","title":"Task 2: Prepare Target Repository","text":"<pre><code># Clone target\ncd /tmp/migration\ngit clone git@github.com:jonwraymond/toolfoundation.git\ncd toolfoundation\n\n# Create model directory\nmkdir -p model\n\n# Verify go.mod exists\ncat go.mod\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#task-3-copy-source-files","title":"Task 3: Copy Source Files","text":"<pre><code>cd /tmp/migration\n\n# Copy Go source files (exclude go.mod, go.sum, .git)\ncp toolmodel/*.go toolfoundation/model/\n\n# List copied files\nls -la toolfoundation/model/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#task-4-update-import-paths","title":"Task 4: Update Import Paths","text":"<p>Script: <code>scripts/update-imports.sh</code></p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nOLD_IMPORT=\"github.com/jonwraymond/toolmodel\"\nNEW_IMPORT=\"github.com/jonwraymond/toolfoundation/model\"\n\ncd toolfoundation/model\n\n# Update all Go files\nfor file in *.go; do\n  if [ -f \"$file\" ]; then\n    sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\n    echo \"Updated: $file\"\n  fi\ndone\n\n# Verify no old imports remain\ngrep -r \"jonwraymond/toolmodel\" . &amp;&amp; echo \"\u26a0 Old imports still exist!\" || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#task-5-update-package-documentation","title":"Task 5: Update Package Documentation","text":"<p>File: <code>toolfoundation/model/doc.go</code></p> <pre><code>// Package model provides the canonical tool schema types for the ApertureStack ecosystem.\n//\n// This package defines the core data structures used to represent tools across\n// all layers of the stack, including:\n//\n//   - Tool: The primary tool definition with name, description, and schema\n//   - ToolInput: JSON Schema-based input parameter definitions\n//   - ToolOutput: Output type definitions and validation\n//   - Metadata: Extensible tool metadata\n//\n// # Usage\n//\n// Create a new tool definition:\n//\n//  tool := model.Tool{\n//      ID:          \"calculator\",\n//      Name:        \"Calculator\",\n//      Description: \"Performs arithmetic operations\",\n//      InputSchema: model.InputSchema{\n//          Type: \"object\",\n//          Properties: map[string]model.Property{\n//              \"operation\": {Type: \"string\", Enum: []string{\"add\", \"subtract\"}},\n//              \"a\":         {Type: \"number\"},\n//              \"b\":         {Type: \"number\"},\n//          },\n//          Required: []string{\"operation\", \"a\", \"b\"},\n//      },\n//  }\n//\n// Validate tool input:\n//\n//  if err := tool.ValidateInput(input); err != nil {\n//      return fmt.Errorf(\"invalid input: %w\", err)\n//  }\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolmodel as part of\n// the ApertureStack consolidation. The API remains unchanged.\npackage model\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#task-6-update-gomod-dependencies","title":"Task 6: Update go.mod Dependencies","text":"<pre><code>cd toolfoundation\n\n# Tidy dependencies\ngo mod tidy\n\n# Verify build\ngo build ./...\n\n# Run tests\ngo test -v ./model/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#task-7-verify-test-coverage","title":"Task 7: Verify Test Coverage","text":"<pre><code>cd toolfoundation\n\n# Run tests with coverage\ngo test -coverprofile=coverage.out ./model/...\n\n# Check coverage percentage (should be &gt;= 89%)\ngo tool cover -func=coverage.out | grep total\n\n# Generate HTML coverage report\ngo tool cover -html=coverage.out -o coverage.html\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd toolfoundation\n\ngit add -A\ngit commit -m \"feat(model): migrate toolmodel package\n\nMigrate the canonical tool schema types from standalone toolmodel repository.\n\nPackage contents:\n- Tool, ToolInput, ToolOutput types\n- JSON Schema validation\n- Serialization helpers\n- Full test coverage (89.6%)\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolmodel \u2192 toolfoundation/model\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#task-9-update-dependent-repositories","title":"Task 9: Update Dependent Repositories","text":"<p>Create a tracking issue for updating imports in dependent repos:</p> <pre><code>gh issue create -R jonwraymond/toolfoundation \\\n  --title \"Update dependent repos to use toolfoundation/model\" \\\n  --body \"## Dependent Repositories\n\nThe following repositories need import updates:\n\n- [ ] toolindex\n- [ ] toolsearch\n- [ ] toolrun\n- [ ] toolcode\n- [ ] metatools-mcp\n\n## Old Import\n\\`\\`\\`go\nimport \\\"github.com/jonwraymond/toolmodel\\\"\n\\`\\`\\`\n\n## New Import\n\\`\\`\\`go\nimport \\\"github.com/jonwraymond/toolfoundation/model\\\"\n\\`\\`\\`\n\n## Timeline\nWill be updated as part of each repo's migration PRD.\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#file-mapping","title":"File Mapping","text":"Source Target <code>toolmodel/tool.go</code> <code>toolfoundation/model/tool.go</code> <code>toolmodel/tool_test.go</code> <code>toolfoundation/model/tool_test.go</code> <code>toolmodel/schema.go</code> <code>toolfoundation/model/schema.go</code> <code>toolmodel/schema_test.go</code> <code>toolfoundation/model/schema_test.go</code> <code>toolmodel/validate.go</code> <code>toolfoundation/model/validate.go</code> <code>toolmodel/validate_test.go</code> <code>toolfoundation/model/validate_test.go</code> <code>toolmodel/doc.go</code> <code>toolfoundation/model/doc.go</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Coverage &gt;= 89%</li> <li>[ ] Package documentation updated</li> <li>[ ] Committed with proper message</li> <li>[ ] Pushed to main</li> <li>[ ] Dependent repos tracked</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolfoundation/model</code> package builds successfully</li> <li>All tests pass with &gt;= 89% coverage</li> <li>No references to old import path</li> <li>Package can be imported by other repos</li> <li>API is unchanged from original toolmodel</li> </ol> <p>Verification: <pre><code>// This should work in any dependent package\nimport \"github.com/jonwraymond/toolfoundation/model\"\n\nfunc example() {\n    tool := model.Tool{\n        ID:   \"test\",\n        Name: \"Test Tool\",\n    }\n    _ = tool\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolfoundation/model/</code> contains migrated sources and tests.</li> <li><code>toolfoundation/model/doc.go</code> documents the package contract.</li> <li><code>go test ./model/...</code> passes in <code>toolfoundation</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd toolfoundation\n\n# Remove model package\nrm -rf model/\n\n# Reset to previous state\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-120-migrate-toolmodel/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-121: Migrate tooladapter</li> <li>PRD-122: Create toolversion</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/","title":"PRD-121: Migrate tooladapter","text":"<p>Phase: 2 - Foundation Layer Priority: Critical Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#objective","title":"Objective","text":"<p>Migrate the existing <code>tooladapter</code> repository into <code>toolfoundation/adapter/</code> as the second package in the consolidated foundation layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/tooladapter</code> Target Location: <code>github.com/jonwraymond/toolfoundation/adapter</code></p> <p>Package Contents: - Schema adapters for converting between tool formats - MCP \u2194 OpenAI \u2194 Anthropic format conversion - LangChain tool format support - ~1,500 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#deliverables","title":"Deliverables","text":"Deliverable Location Description Adapter Package <code>toolfoundation/adapter/</code> Schema format adapters Tests <code>toolfoundation/adapter/*_test.go</code> All existing tests Documentation <code>toolfoundation/adapter/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#task-1-clone-source-repository","title":"Task 1: Clone Source Repository","text":"<pre><code>cd /tmp/migration\n\n# Clone source with full history\ngit clone git@github.com:jonwraymond/tooladapter.git\ncd tooladapter\n\n# Verify contents\nls -la\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#task-2-copy-source-files","title":"Task 2: Copy Source Files","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Create adapter directory\nmkdir -p adapter\n\n# Copy Go source files\ncp ../tooladapter/*.go adapter/\n\n# List copied files\nls -la adapter/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#task-3-update-import-paths","title":"Task 3: Update Import Paths","text":"<pre><code>cd /tmp/migration/toolfoundation/adapter\n\nOLD_IMPORT=\"github.com/jonwraymond/tooladapter\"\nNEW_IMPORT=\"github.com/jonwraymond/toolfoundation/adapter\"\n\n# Update all Go files\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\n  echo \"Updated: $file\"\ndone\n\n# Also update toolmodel import to toolfoundation/model\nOLD_MODEL=\"github.com/jonwraymond/toolmodel\"\nNEW_MODEL=\"github.com/jonwraymond/toolfoundation/model\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_MODEL|$NEW_MODEL|g\" \"$file\"\ndone\n\n# Verify\ngrep -r \"jonwraymond/tooladapter\\|jonwraymond/toolmodel\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#task-4-update-package-documentation","title":"Task 4: Update Package Documentation","text":"<p>File: <code>toolfoundation/adapter/doc.go</code></p> <pre><code>// Package adapter provides schema format conversion between different AI tool specifications.\n//\n// This package enables interoperability between various AI tool formats:\n//\n//   - MCP (Model Context Protocol) - Anthropic's standard\n//   - OpenAI Function Calling format\n//   - Anthropic Tool Use format\n//   - LangChain Tool format\n//\n// # Adapters\n//\n// Each adapter implements bidirectional conversion:\n//\n//  // Convert MCP tool to OpenAI format\n//  openaiTool := adapter.ToOpenAI(mcpTool)\n//\n//  // Convert OpenAI tool to MCP format\n//  mcpTool := adapter.FromOpenAI(openaiTool)\n//\n// # Supported Formats\n//\n//  | Format     | To MCP | From MCP |\n//  |------------|--------|----------|\n//  | OpenAI     | \u2713      | \u2713        |\n//  | Anthropic  | \u2713      | \u2713        |\n//  | LangChain  | \u2713      | \u2713        |\n//\n// # Schema Compatibility\n//\n// Not all schema features are supported across formats. The adapter handles:\n//\n//   - Parameter type mapping\n//   - Required field conversion\n//   - Description propagation\n//   - Enum value handling\n//\n// Features not supported in target format are gracefully degraded.\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/tooladapter as part of\n// the ApertureStack consolidation.\npackage adapter\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#task-5-verify-internal-dependencies","title":"Task 5: Verify Internal Dependencies","text":"<p>The adapter package depends on the model package. Verify the import works:</p> <pre><code>cd /tmp/migration/toolfoundation\n\n# Check imports in adapter files\ngrep -h \"import\" adapter/*.go | sort -u\n\n# Should include:\n# \"github.com/jonwraymond/toolfoundation/model\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#task-6-update-gomod-and-build","title":"Task 6: Update go.mod and Build","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Tidy dependencies\ngo mod tidy\n\n# Verify build\ngo build ./...\n\n# Run all tests\ngo test -v ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#task-7-verify-test-coverage","title":"Task 7: Verify Test Coverage","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Run adapter tests with coverage\ngo test -coverprofile=adapter_coverage.out ./adapter/...\n\n# Check coverage\ngo tool cover -func=adapter_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd /tmp/migration/toolfoundation\n\ngit add -A\ngit commit -m \"feat(adapter): migrate tooladapter package\n\nMigrate schema format adapters from standalone tooladapter repository.\n\nPackage contents:\n- MCP \u2194 OpenAI format conversion\n- MCP \u2194 Anthropic format conversion\n- MCP \u2194 LangChain format conversion\n- Bidirectional adapters with graceful degradation\n\nInternal dependency:\n- Uses toolfoundation/model for canonical types\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/tooladapter \u2192 toolfoundation/adapter\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#adapter-interface-design","title":"Adapter Interface Design","text":"<p>The migrated adapter package should follow this interface pattern:</p> <pre><code>package adapter\n\nimport \"github.com/jonwraymond/toolfoundation/model\"\n\n// Adapter converts between MCP tool format and external formats.\ntype Adapter interface {\n    // ToExternal converts an MCP tool to the external format.\n    ToExternal(tool model.Tool) (any, error)\n\n    // FromExternal converts an external format tool to MCP.\n    FromExternal(external any) (model.Tool, error)\n\n    // Name returns the adapter name (e.g., \"openai\", \"anthropic\").\n    Name() string\n}\n\n// OpenAIAdapter converts between MCP and OpenAI function calling format.\ntype OpenAIAdapter struct{}\n\nfunc (a *OpenAIAdapter) ToExternal(tool model.Tool) (any, error) { ... }\nfunc (a *OpenAIAdapter) FromExternal(external any) (model.Tool, error) { ... }\nfunc (a *OpenAIAdapter) Name() string { return \"openai\" }\n\n// AnthropicAdapter converts between MCP and Anthropic tool use format.\ntype AnthropicAdapter struct{}\n\n// LangChainAdapter converts between MCP and LangChain tool format.\ntype LangChainAdapter struct{}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#file-mapping","title":"File Mapping","text":"Source Target <code>tooladapter/adapter.go</code> <code>toolfoundation/adapter/adapter.go</code> <code>tooladapter/adapter_test.go</code> <code>toolfoundation/adapter/adapter_test.go</code> <code>tooladapter/openai.go</code> <code>toolfoundation/adapter/openai.go</code> <code>tooladapter/openai_test.go</code> <code>toolfoundation/adapter/openai_test.go</code> <code>tooladapter/anthropic.go</code> <code>toolfoundation/adapter/anthropic.go</code> <code>tooladapter/langchain.go</code> <code>toolfoundation/adapter/langchain.go</code> <code>tooladapter/doc.go</code> <code>toolfoundation/adapter/doc.go</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated (both adapter and model)</li> <li>[ ] Internal dependency on model/ works</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Package documentation updated</li> <li>[ ] Committed with proper message</li> <li>[ ] Pushed to main</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolfoundation/adapter</code> package builds successfully</li> <li>All tests pass</li> <li>Can import both <code>model</code> and <code>adapter</code> from same repo</li> <li>Adapter interface is well-defined</li> <li>No references to old import paths</li> </ol> <p>Verification: <pre><code>import (\n    \"github.com/jonwraymond/toolfoundation/model\"\n    \"github.com/jonwraymond/toolfoundation/adapter\"\n)\n\nfunc example() {\n    tool := model.Tool{ID: \"test\", Name: \"Test\"}\n    openaiAdapter := &amp;adapter.OpenAIAdapter{}\n    external, _ := openaiAdapter.ToExternal(tool)\n    _ = external\n}\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolfoundation/adapter/</code> contains migrated sources and tests.</li> <li><code>toolfoundation/adapter/doc.go</code> documents the adapter contract.</li> <li><code>go test ./adapter/...</code> passes in <code>toolfoundation</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Remove adapter package\nrm -rf adapter/\n\n# Reset to previous state\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-121-migrate-tooladapter/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-122: Create toolversion</li> <li>Gate G2: Foundation layer complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/","title":"PRD-122: Create toolversion","text":"<p>Phase: 2 - Foundation Layer Priority: High Effort: 8 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#objective","title":"Objective","text":"<p>Create a new <code>toolfoundation/version</code> package for semantic versioning, compatibility checking, and version negotiation across the ApertureStack ecosystem.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#package-design","title":"Package Design","text":"<p>Location: <code>github.com/jonwraymond/toolfoundation/version</code></p> <p>Purpose: - Semantic version parsing and comparison - Version compatibility matrices - Protocol version negotiation - Deprecation tracking</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#deliverables","title":"Deliverables","text":"Deliverable Location Description Version Package <code>toolfoundation/version/</code> Version management utilities Tests <code>toolfoundation/version/*_test.go</code> Comprehensive tests Documentation <code>toolfoundation/version/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#task-1-create-package-structure","title":"Task 1: Create Package Structure","text":"<pre><code>cd /tmp/migration/toolfoundation\n\nmkdir -p version\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#task-2-create-core-types","title":"Task 2: Create Core Types","text":"<p>File: <code>toolfoundation/version/version.go</code></p> <pre><code>package version\n\nimport (\n    \"fmt\"\n    \"regexp\"\n    \"strconv\"\n    \"strings\"\n)\n\n// Version represents a semantic version (major.minor.patch-prerelease+build).\ntype Version struct {\n    Major      int\n    Minor      int\n    Patch      int\n    Prerelease string\n    Build      string\n}\n\nvar semverRegex = regexp.MustCompile(`^v?(\\d+)\\.(\\d+)\\.(\\d+)(?:-([0-9A-Za-z-.]+))?(?:\\+([0-9A-Za-z-.]+))?$`)\n\n// Parse parses a semantic version string.\nfunc Parse(s string) (Version, error) {\n    matches := semverRegex.FindStringSubmatch(s)\n    if matches == nil {\n        return Version{}, fmt.Errorf(\"invalid semantic version: %s\", s)\n    }\n\n    major, _ := strconv.Atoi(matches[1])\n    minor, _ := strconv.Atoi(matches[2])\n    patch, _ := strconv.Atoi(matches[3])\n\n    return Version{\n        Major:      major,\n        Minor:      minor,\n        Patch:      patch,\n        Prerelease: matches[4],\n        Build:      matches[5],\n    }, nil\n}\n\n// MustParse parses a version string and panics on error.\nfunc MustParse(s string) Version {\n    v, err := Parse(s)\n    if err != nil {\n        panic(err)\n    }\n    return v\n}\n\n// String returns the version as a string (with v prefix).\nfunc (v Version) String() string {\n    s := fmt.Sprintf(\"v%d.%d.%d\", v.Major, v.Minor, v.Patch)\n    if v.Prerelease != \"\" {\n        s += \"-\" + v.Prerelease\n    }\n    if v.Build != \"\" {\n        s += \"+\" + v.Build\n    }\n    return s\n}\n\n// Compare returns -1, 0, or 1 if v &lt; other, v == other, or v &gt; other.\nfunc (v Version) Compare(other Version) int {\n    if v.Major != other.Major {\n        return compareInt(v.Major, other.Major)\n    }\n    if v.Minor != other.Minor {\n        return compareInt(v.Minor, other.Minor)\n    }\n    if v.Patch != other.Patch {\n        return compareInt(v.Patch, other.Patch)\n    }\n    return comparePrerelease(v.Prerelease, other.Prerelease)\n}\n\n// LessThan returns true if v &lt; other.\nfunc (v Version) LessThan(other Version) bool {\n    return v.Compare(other) &lt; 0\n}\n\n// GreaterThan returns true if v &gt; other.\nfunc (v Version) GreaterThan(other Version) bool {\n    return v.Compare(other) &gt; 0\n}\n\n// Equal returns true if v == other (ignoring build metadata).\nfunc (v Version) Equal(other Version) bool {\n    return v.Compare(other) == 0\n}\n\n// Compatible returns true if v is compatible with other (same major, v &gt;= other).\nfunc (v Version) Compatible(other Version) bool {\n    if v.Major != other.Major {\n        return false\n    }\n    return v.Compare(other) &gt;= 0\n}\n\nfunc compareInt(a, b int) int {\n    if a &lt; b {\n        return -1\n    }\n    if a &gt; b {\n        return 1\n    }\n    return 0\n}\n\nfunc comparePrerelease(a, b string) int {\n    if a == \"\" &amp;&amp; b == \"\" {\n        return 0\n    }\n    if a == \"\" {\n        return 1 // no prerelease &gt; prerelease\n    }\n    if b == \"\" {\n        return -1\n    }\n    return strings.Compare(a, b)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#task-3-create-constraint-types","title":"Task 3: Create Constraint Types","text":"<p>File: <code>toolfoundation/version/constraint.go</code></p> <pre><code>package version\n\nimport (\n    \"fmt\"\n    \"strings\"\n)\n\n// Constraint represents a version constraint (e.g., \"&gt;=1.0.0\", \"^2.0.0\").\ntype Constraint struct {\n    Op      string  // \"\", \"=\", \"&gt;\", \"&gt;=\", \"&lt;\", \"&lt;=\", \"^\", \"~\"\n    Version Version\n}\n\n// ParseConstraint parses a version constraint string.\nfunc ParseConstraint(s string) (Constraint, error) {\n    s = strings.TrimSpace(s)\n\n    var op string\n    var versionStr string\n\n    switch {\n    case strings.HasPrefix(s, \"&gt;=\"):\n        op = \"&gt;=\"\n        versionStr = strings.TrimPrefix(s, \"&gt;=\")\n    case strings.HasPrefix(s, \"&lt;=\"):\n        op = \"&lt;=\"\n        versionStr = strings.TrimPrefix(s, \"&lt;=\")\n    case strings.HasPrefix(s, \"&gt;\"):\n        op = \"&gt;\"\n        versionStr = strings.TrimPrefix(s, \"&gt;\")\n    case strings.HasPrefix(s, \"&lt;\"):\n        op = \"&lt;\"\n        versionStr = strings.TrimPrefix(s, \"&lt;\")\n    case strings.HasPrefix(s, \"^\"):\n        op = \"^\"\n        versionStr = strings.TrimPrefix(s, \"^\")\n    case strings.HasPrefix(s, \"~\"):\n        op = \"~\"\n        versionStr = strings.TrimPrefix(s, \"~\")\n    case strings.HasPrefix(s, \"=\"):\n        op = \"=\"\n        versionStr = strings.TrimPrefix(s, \"=\")\n    default:\n        op = \"=\"\n        versionStr = s\n    }\n\n    v, err := Parse(strings.TrimSpace(versionStr))\n    if err != nil {\n        return Constraint{}, err\n    }\n\n    return Constraint{Op: op, Version: v}, nil\n}\n\n// Check returns true if the given version satisfies the constraint.\nfunc (c Constraint) Check(v Version) bool {\n    switch c.Op {\n    case \"\", \"=\":\n        return v.Equal(c.Version)\n    case \"&gt;\":\n        return v.GreaterThan(c.Version)\n    case \"&gt;=\":\n        return v.GreaterThan(c.Version) || v.Equal(c.Version)\n    case \"&lt;\":\n        return v.LessThan(c.Version)\n    case \"&lt;=\":\n        return v.LessThan(c.Version) || v.Equal(c.Version)\n    case \"^\":\n        // Caret: compatible with (same major, &gt;= version)\n        return v.Major == c.Version.Major &amp;&amp; (v.GreaterThan(c.Version) || v.Equal(c.Version))\n    case \"~\":\n        // Tilde: same major.minor, &gt;= version\n        return v.Major == c.Version.Major &amp;&amp; v.Minor == c.Version.Minor &amp;&amp;\n            (v.GreaterThan(c.Version) || v.Equal(c.Version))\n    default:\n        return false\n    }\n}\n\n// String returns the constraint as a string.\nfunc (c Constraint) String() string {\n    if c.Op == \"\" || c.Op == \"=\" {\n        return c.Version.String()\n    }\n    return c.Op + c.Version.String()\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#task-4-create-compatibility-matrix","title":"Task 4: Create Compatibility Matrix","text":"<p>File: <code>toolfoundation/version/compatibility.go</code></p> <pre><code>package version\n\nimport (\n    \"fmt\"\n)\n\n// Compatibility represents version compatibility between components.\ntype Compatibility struct {\n    Component  string\n    MinVersion Version\n    MaxVersion *Version // nil means no upper bound\n    Deprecated bool\n    Message    string\n}\n\n// Matrix holds compatibility information for multiple components.\ntype Matrix struct {\n    entries map[string][]Compatibility\n}\n\n// NewMatrix creates a new compatibility matrix.\nfunc NewMatrix() *Matrix {\n    return &amp;Matrix{\n        entries: make(map[string][]Compatibility),\n    }\n}\n\n// Add adds a compatibility entry for a component.\nfunc (m *Matrix) Add(comp Compatibility) {\n    m.entries[comp.Component] = append(m.entries[comp.Component], comp)\n}\n\n// Check checks if a version is compatible for a component.\nfunc (m *Matrix) Check(component string, v Version) (bool, string) {\n    entries, ok := m.entries[component]\n    if !ok {\n        return true, \"\" // unknown component, assume compatible\n    }\n\n    for _, entry := range entries {\n        if v.Compare(entry.MinVersion) &lt; 0 {\n            return false, fmt.Sprintf(\"version %s is below minimum %s\", v, entry.MinVersion)\n        }\n        if entry.MaxVersion != nil &amp;&amp; v.Compare(*entry.MaxVersion) &gt; 0 {\n            return false, fmt.Sprintf(\"version %s exceeds maximum %s\", v, entry.MaxVersion)\n        }\n        if entry.Deprecated {\n            return true, entry.Message // compatible but deprecated\n        }\n    }\n\n    return true, \"\"\n}\n\n// Negotiate finds the best compatible version from a list.\nfunc (m *Matrix) Negotiate(component string, available []Version) (Version, error) {\n    var best *Version\n\n    for _, v := range available {\n        compatible, _ := m.Check(component, v)\n        if compatible {\n            if best == nil || v.GreaterThan(*best) {\n                vCopy := v\n                best = &amp;vCopy\n            }\n        }\n    }\n\n    if best == nil {\n        return Version{}, fmt.Errorf(\"no compatible version found for %s\", component)\n    }\n\n    return *best, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#task-5-create-package-documentation","title":"Task 5: Create Package Documentation","text":"<p>File: <code>toolfoundation/version/doc.go</code></p> <pre><code>// Package version provides semantic versioning utilities for the ApertureStack ecosystem.\n//\n// This package handles version parsing, comparison, compatibility checking, and\n// version negotiation for tool and protocol versions.\n//\n// # Parsing Versions\n//\n// Parse semantic version strings:\n//\n//  v, err := version.Parse(\"1.2.3\")\n//  v, err := version.Parse(\"v2.0.0-beta.1+build.123\")\n//\n// # Comparing Versions\n//\n//  v1 := version.MustParse(\"1.0.0\")\n//  v2 := version.MustParse(\"2.0.0\")\n//\n//  v1.LessThan(v2)    // true\n//  v1.GreaterThan(v2) // false\n//  v1.Equal(v2)       // false\n//  v1.Compatible(v2)  // false (different major)\n//\n// # Version Constraints\n//\n// Parse and check version constraints:\n//\n//  c, _ := version.ParseConstraint(\"&gt;=1.0.0\")\n//  c.Check(version.MustParse(\"1.5.0\")) // true\n//  c.Check(version.MustParse(\"0.9.0\")) // false\n//\n// Supported constraint operators:\n//   - \"=\" or \"\" - exact match\n//   - \"&gt;\" - greater than\n//   - \"&gt;=\" - greater than or equal\n//   - \"&lt;\" - less than\n//   - \"&lt;=\" - less than or equal\n//   - \"^\" - compatible (same major)\n//   - \"~\" - approximately (same major.minor)\n//\n// # Compatibility Matrix\n//\n// Track version compatibility across components:\n//\n//  matrix := version.NewMatrix()\n//  matrix.Add(version.Compatibility{\n//      Component:  \"toolfoundation\",\n//      MinVersion: version.MustParse(\"0.1.0\"),\n//  })\n//\n//  ok, msg := matrix.Check(\"toolfoundation\", version.MustParse(\"0.2.0\"))\n//\n// # Version Negotiation\n//\n// Find the best compatible version from available options:\n//\n//  available := []version.Version{\n//      version.MustParse(\"1.0.0\"),\n//      version.MustParse(\"1.1.0\"),\n//      version.MustParse(\"2.0.0\"),\n//  }\n//  best, err := matrix.Negotiate(\"component\", available)\npackage version\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#task-6-create-tests","title":"Task 6: Create Tests","text":"<p>File: <code>toolfoundation/version/version_test.go</code></p> <pre><code>package version\n\nimport (\n    \"testing\"\n)\n\nfunc TestParse(t *testing.T) {\n    tests := []struct {\n        input   string\n        want    Version\n        wantErr bool\n    }{\n        {\"1.0.0\", Version{1, 0, 0, \"\", \"\"}, false},\n        {\"v1.0.0\", Version{1, 0, 0, \"\", \"\"}, false},\n        {\"1.2.3\", Version{1, 2, 3, \"\", \"\"}, false},\n        {\"1.0.0-alpha\", Version{1, 0, 0, \"alpha\", \"\"}, false},\n        {\"1.0.0-alpha.1\", Version{1, 0, 0, \"alpha.1\", \"\"}, false},\n        {\"1.0.0+build\", Version{1, 0, 0, \"\", \"build\"}, false},\n        {\"1.0.0-beta+build.123\", Version{1, 0, 0, \"beta\", \"build.123\"}, false},\n        {\"invalid\", Version{}, true},\n        {\"1.0\", Version{}, true},\n        {\"1\", Version{}, true},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.input, func(t *testing.T) {\n            got, err := Parse(tt.input)\n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Parse(%q) error = %v, wantErr %v\", tt.input, err, tt.wantErr)\n                return\n            }\n            if !tt.wantErr &amp;&amp; got != tt.want {\n                t.Errorf(\"Parse(%q) = %v, want %v\", tt.input, got, tt.want)\n            }\n        })\n    }\n}\n\nfunc TestVersion_Compare(t *testing.T) {\n    tests := []struct {\n        a, b string\n        want int\n    }{\n        {\"1.0.0\", \"1.0.0\", 0},\n        {\"1.0.0\", \"2.0.0\", -1},\n        {\"2.0.0\", \"1.0.0\", 1},\n        {\"1.0.0\", \"1.1.0\", -1},\n        {\"1.1.0\", \"1.0.0\", 1},\n        {\"1.0.0\", \"1.0.1\", -1},\n        {\"1.0.0-alpha\", \"1.0.0\", -1},\n        {\"1.0.0\", \"1.0.0-alpha\", 1},\n        {\"1.0.0-alpha\", \"1.0.0-beta\", -1},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.a+\"_vs_\"+tt.b, func(t *testing.T) {\n            a := MustParse(tt.a)\n            b := MustParse(tt.b)\n            if got := a.Compare(b); got != tt.want {\n                t.Errorf(\"%s.Compare(%s) = %d, want %d\", tt.a, tt.b, got, tt.want)\n            }\n        })\n    }\n}\n\nfunc TestVersion_Compatible(t *testing.T) {\n    tests := []struct {\n        a, b string\n        want bool\n    }{\n        {\"1.0.0\", \"1.0.0\", true},\n        {\"1.1.0\", \"1.0.0\", true},\n        {\"1.0.0\", \"1.1.0\", false}, // v &lt; other\n        {\"2.0.0\", \"1.0.0\", false}, // different major\n        {\"1.0.0\", \"2.0.0\", false}, // different major\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.a+\"_compat_\"+tt.b, func(t *testing.T) {\n            a := MustParse(tt.a)\n            b := MustParse(tt.b)\n            if got := a.Compatible(b); got != tt.want {\n                t.Errorf(\"%s.Compatible(%s) = %v, want %v\", tt.a, tt.b, got, tt.want)\n            }\n        })\n    }\n}\n\nfunc TestConstraint_Check(t *testing.T) {\n    tests := []struct {\n        constraint string\n        version    string\n        want       bool\n    }{\n        {\"1.0.0\", \"1.0.0\", true},\n        {\"=1.0.0\", \"1.0.0\", true},\n        {\"=1.0.0\", \"1.0.1\", false},\n        {\"&gt;1.0.0\", \"1.0.1\", true},\n        {\"&gt;1.0.0\", \"1.0.0\", false},\n        {\"&gt;=1.0.0\", \"1.0.0\", true},\n        {\"&gt;=1.0.0\", \"0.9.0\", false},\n        {\"&lt;2.0.0\", \"1.9.9\", true},\n        {\"&lt;2.0.0\", \"2.0.0\", false},\n        {\"&lt;=2.0.0\", \"2.0.0\", true},\n        {\"^1.0.0\", \"1.5.0\", true},\n        {\"^1.0.0\", \"2.0.0\", false},\n        {\"~1.0.0\", \"1.0.5\", true},\n        {\"~1.0.0\", \"1.1.0\", false},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.constraint+\"_\"+tt.version, func(t *testing.T) {\n            c, err := ParseConstraint(tt.constraint)\n            if err != nil {\n                t.Fatalf(\"ParseConstraint(%q) error: %v\", tt.constraint, err)\n            }\n            v := MustParse(tt.version)\n            if got := c.Check(v); got != tt.want {\n                t.Errorf(\"Constraint(%q).Check(%s) = %v, want %v\", tt.constraint, tt.version, got, tt.want)\n            }\n        })\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#task-7-build-and-test","title":"Task 7: Build and Test","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Tidy dependencies\ngo mod tidy\n\n# Build\ngo build ./...\n\n# Test with coverage\ngo test -v -coverprofile=version_coverage.out ./version/...\n\n# Check coverage (target: &gt;90%)\ngo tool cover -func=version_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd /tmp/migration/toolfoundation\n\ngit add -A\ngit commit -m \"feat(version): add semantic versioning package\n\nAdd new version package for semantic versioning and compatibility management.\n\nPackage contents:\n- Version parsing and comparison\n- Version constraint checking (&gt;=, &lt;=, ^, ~, etc.)\n- Compatibility matrix for component version tracking\n- Version negotiation for finding best compatible version\n\nFeatures:\n- Full semver 2.0 support (major.minor.patch-prerelease+build)\n- Constraint operators: =, &gt;, &gt;=, &lt;, &lt;=, ^, ~\n- Matrix-based compatibility checking\n- Deprecation tracking\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All source files created</li> <li>[x] <code>go build ./...</code> succeeds</li> <li>[x] <code>go test ./...</code> passes</li> <li>[x] Coverage &gt;= 90%</li> <li>[x] Package documentation complete</li> <li>[x] Committed with proper message</li> <li>[x] Pushed to main</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolfoundation/version</code> package builds successfully</li> <li>All tests pass with &gt;= 90% coverage</li> <li>Semver 2.0 parsing works correctly</li> <li>Constraint checking is accurate</li> <li>Compatibility matrix tracks versions correctly</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolfoundation/version/</code> contains version, constraint, compatibility types and tests.</li> <li><code>toolfoundation/version/doc.go</code> documents the package and usage.</li> <li><code>go test ./version/...</code> passes in <code>toolfoundation</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolfoundation\n\n# Remove version package\nrm -rf version/\n\n# Reset to previous state\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-122-create-toolversion/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G2: Foundation layer complete (all 3 packages)</li> <li>PRD-130: Migrate toolindex</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/","title":"PRD-123: toolfoundation Docs + README Alignment","text":"<p>Phase: 2 - Foundation Layer Priority: High Effort: 3 hours Dependencies: PRD-120, PRD-121, PRD-122 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#objective","title":"Objective","text":"<p>Align public-facing documentation with the consolidated <code>toolfoundation</code> API:</p> <ul> <li>Remove placeholders (README <code>TBD</code> entries).</li> <li>Ensure docs reflect the actual API (validator constructors, signatures).</li> <li>Add <code>version</code> package coverage in docs and user journey.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#scope","title":"Scope","text":"<p>In scope - <code>toolfoundation/README.md</code> - <code>toolfoundation/docs/index.md</code> - <code>toolfoundation/docs/user-journey.md</code></p> <p>Out of scope - API changes or behavior changes in code - New functionality beyond documentation</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#deliverables","title":"Deliverables","text":"Deliverable Location Description Updated README <code>toolfoundation/README.md</code> Package table + quick usage Updated index docs <code>toolfoundation/docs/index.md</code> Include <code>version</code> package + accurate API snippets Updated user journey <code>toolfoundation/docs/user-journey.md</code> Correct validator usage + version walkthrough"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#task-1-readme-package-table","title":"Task 1: README package table","text":"<ul> <li>Replace <code>TBD</code> with concrete package list:</li> <li><code>model</code></li> <li><code>adapter</code></li> <li><code>version</code></li> <li>Add short descriptions + link to <code>docs/</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#task-2-docsindexmd","title":"Task 2: docs/index.md","text":"<ul> <li>Add <code>version</code> package to Packages table.</li> <li>Add a short version example (Parse / Compare / Compatible).</li> <li>Ensure schema validation example uses <code>NewDefaultValidator</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#task-3-docsuser-journeymd","title":"Task 3: docs/user-journey.md","text":"<ul> <li>Fix schema validation snippet to use <code>NewDefaultValidator</code> and <code>ValidateInput(&amp;tool, input)</code>.</li> <li>Add a section showing version negotiation (compatibility matrix and constraints).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#task-4-verification","title":"Task 4: Verification","text":"<pre><code>cd toolfoundation\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>README has concrete package table (no <code>TBD</code>).</li> <li>Docs show <code>version</code> package in index + user journey.</li> <li>All snippets compile against current API.</li> <li><code>go test ./...</code> passes.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolfoundation/README.md</code> package table updated.</li> <li><code>toolfoundation/docs/index.md</code> includes <code>version</code> package + examples.</li> <li><code>toolfoundation/docs/user-journey.md</code> uses correct validator API.</li> <li><code>go test ./...</code> passes in <code>toolfoundation</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-123-toolfoundation-docs-alignment/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-124: Schema validation policy documentation</li> <li>PRD-125: Adapter feature matrix documentation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-124-toolfoundation-schema-policy/","title":"PRD-124: toolfoundation Schema Validation Policy","text":"<p>Phase: 2 - Foundation Layer Priority: Medium Effort: 2 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-124-toolfoundation-schema-policy/#objective","title":"Objective","text":"<p>Document the JSON Schema validation contract for <code>toolfoundation/model</code>:</p> <ul> <li>Supported dialects (2020-12, draft-07)</li> <li>External <code>$ref</code> handling policy (blocked)</li> <li>Validation limitations (format/content keywords)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-124-toolfoundation-schema-policy/#scope","title":"Scope","text":"<p>In scope - <code>toolfoundation/docs/design-notes.md</code> - <code>toolfoundation/docs/index.md</code></p> <p>Out of scope - Changing validation behavior - Adding new validation libraries</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-124-toolfoundation-schema-policy/#deliverables","title":"Deliverables","text":"Deliverable Location Description Schema policy notes <code>docs/design-notes.md</code> Dialects + external ref policy + limitations Public summary <code>docs/index.md</code> Short section linking to design notes"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-124-toolfoundation-schema-policy/#tasks","title":"Tasks","text":"<ol> <li>Add a \u201cSchema Validation Policy\u201d section to <code>docs/design-notes.md</code>.</li> <li>Add a short summary in <code>docs/index.md</code> with a link to the policy section.</li> <li>Verify examples remain accurate.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-124-toolfoundation-schema-policy/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Supported dialects and limitations are explicitly documented.</li> <li>External <code>$ref</code> policy is stated.</li> <li>Docs are consistent with <code>model/validator.go</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-124-toolfoundation-schema-policy/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Schema policy documented in <code>toolfoundation/docs/design-notes.md</code>.</li> <li>Summary added to <code>toolfoundation/docs/index.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-124-toolfoundation-schema-policy/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-125: Adapter feature matrix documentation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-125-toolfoundation-adapter-matrix/","title":"PRD-125: toolfoundation Adapter Feature Matrix Docs","text":"<p>Phase: 2 - Foundation Layer Priority: Medium Effort: 2 hours Dependencies: PRD-121 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-125-toolfoundation-adapter-matrix/#objective","title":"Objective","text":"<p>Document adapter feature support and loss semantics for <code>toolfoundation/adapter</code>:</p> <ul> <li>Supported schema features by target format</li> <li>How <code>FeatureLossWarning</code> is generated</li> <li>Guidance for consumers on safe conversions</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-125-toolfoundation-adapter-matrix/#scope","title":"Scope","text":"<p>In scope - <code>toolfoundation/docs/design-notes.md</code> - <code>toolfoundation/docs/index.md</code></p> <p>Out of scope - Changing adapter behavior - Adding new adapters</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-125-toolfoundation-adapter-matrix/#deliverables","title":"Deliverables","text":"Deliverable Location Description Feature matrix <code>docs/design-notes.md</code> Table of features by adapter Warnings guidance <code>docs/design-notes.md</code> How to interpret <code>FeatureLossWarning</code> Public summary <code>docs/index.md</code> Short summary with link"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-125-toolfoundation-adapter-matrix/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Feature matrix is present and aligns with adapter implementation.</li> <li>Warning semantics are documented with an example.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-125-toolfoundation-adapter-matrix/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Feature matrix + warning semantics documented in <code>toolfoundation/docs/design-notes.md</code>.</li> <li>Summary link added in <code>toolfoundation/docs/index.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-125-toolfoundation-adapter-matrix/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-126: Version package usage docs</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-126-toolfoundation-version-usage/","title":"PRD-126: toolfoundation Version Package Usage Docs","text":"<p>Phase: 2 - Foundation Layer Priority: Medium Effort: 2 hours Dependencies: PRD-122 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-126-toolfoundation-version-usage/#objective","title":"Objective","text":"<p>Publish usage guidance for <code>toolfoundation/version</code>:</p> <ul> <li>Semantic version parsing and comparison</li> <li>Constraints (<code>&gt;=</code>, <code>^</code>, <code>~</code>)</li> <li>Compatibility matrix + negotiation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-126-toolfoundation-version-usage/#scope","title":"Scope","text":"<p>In scope - <code>toolfoundation/docs/index.md</code> - <code>toolfoundation/docs/user-journey.md</code></p> <p>Out of scope - Changing version semantics</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-126-toolfoundation-version-usage/#deliverables","title":"Deliverables","text":"Deliverable Location Description Version example <code>docs/index.md</code> Parse/Compare/Compatible usage Compatibility example <code>docs/user-journey.md</code> Matrix + negotiate example"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-126-toolfoundation-version-usage/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Version package is documented in both index and user journey.</li> <li>Examples compile against current API.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-126-toolfoundation-version-usage/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>version</code> examples added to <code>toolfoundation/docs/index.md</code>.</li> <li>Compatibility example added to <code>toolfoundation/docs/user-journey.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-126-toolfoundation-version-usage/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-127: Contract verification</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-127-toolfoundation-contracts/","title":"PRD-127: toolfoundation Contract Verification","text":"<p>Phase: 2 - Foundation Layer Priority: Medium Effort: 1 hour Dependencies: PRD-120, PRD-121 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-127-toolfoundation-contracts/#objective","title":"Objective","text":"<p>Verify interface contracts in <code>toolfoundation</code> are explicitly documented and enforced with tests.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-127-toolfoundation-contracts/#deliverables","title":"Deliverables","text":"Deliverable Location Description SchemaValidator contract test <code>model/schema_validator_contract_test.go</code> Ensures validator behavior contract Adapter contract test <code>adapter/adapter_contract_test.go</code> Ensures adapter interface contract GoDoc contracts <code>model/validator.go</code>, <code>adapter/adapter.go</code> Contract comments present"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-127-toolfoundation-contracts/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>model/SchemaValidator</code> has explicit contract in GoDoc and contract tests.</li> <li><code>adapter/Adapter</code> has explicit contract in GoDoc and contract tests.</li> <li><code>go test ./...</code> passes in <code>toolfoundation</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-128-toolfoundation-release-propagation/","title":"PRD-128: toolfoundation Release + Version Propagation","text":"<p>Phase: 2 - Foundation Layer Priority: Medium Effort: 1 hour Dependencies: PRD-122 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-128-toolfoundation-release-propagation/#objective","title":"Objective","text":"<p>Ensure <code>toolfoundation</code> is tagged and propagated into the stack version matrix.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-128-toolfoundation-release-propagation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Module tag <code>toolfoundation</code> <code>v0.1.0</code> tag exists Version matrix entry <code>ai-tools-stack/VERSIONS.md</code> toolfoundation row present go.mod alignment <code>ai-tools-stack/go.mod</code> toolfoundation dependency pinned"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-128-toolfoundation-release-propagation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>ai-tools-stack/VERSIONS.md</code> lists <code>toolfoundation v0.1.0</code>.</li> <li><code>ai-tools-stack/go.mod</code> includes <code>github.com/jonwraymond/toolfoundation v0.1.0</code>.</li> <li>toolfoundation tag <code>v0.1.0</code> present.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-129-toolfoundation-g2-validation/","title":"PRD-129: toolfoundation G2 Validation","text":"<p>Phase: 2 - Foundation Layer Priority: High Effort: 1 hour Dependencies: PRD-120, PRD-121, PRD-122 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-129-toolfoundation-g2-validation/#objective","title":"Objective","text":"<p>Confirm the Foundation layer meets Gate G2 requirements:</p> <ul> <li>All three packages (<code>model</code>, <code>adapter</code>, <code>version</code>) compile and pass tests</li> <li>Linting passes</li> <li>Documentation exists for each package</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-129-toolfoundation-g2-validation/#verification-steps","title":"Verification Steps","text":"<pre><code>cd toolfoundation\n\ngo test ./...\n\ngolangci-lint run\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-129-toolfoundation-g2-validation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>go test ./...</code> passes in <code>toolfoundation</code>.</li> <li><code>golangci-lint run</code> passes in <code>toolfoundation</code>.</li> <li>Package docs exist: <code>model/doc.go</code>, <code>adapter/doc.go</code>, <code>version/doc.go</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/","title":"PRD-130: Migrate toolindex","text":"<p>Phase: 3 - Discovery Layer Priority: Critical Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolindex</code> repository into <code>tooldiscovery/index/</code> as the first package in the consolidated discovery layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolindex</code> Target Location: <code>github.com/jonwraymond/tooldiscovery/index</code></p> <p>Package Contents: - Tool registry with CRUD operations - In-memory and file-based index implementations - Searcher interface for pluggable search backends - Progressive disclosure support - ~3,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#deliverables","title":"Deliverables","text":"Deliverable Location Description Index Package <code>tooldiscovery/index/</code> Tool registry implementation Tests <code>tooldiscovery/index/*_test.go</code> All existing tests Documentation <code>tooldiscovery/index/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#task-1-prepare-target-repository","title":"Task 1: Prepare Target Repository","text":"<pre><code># Clone/create target\ncd /tmp/migration\ngit clone git@github.com:jonwraymond/tooldiscovery.git\ncd tooldiscovery\n\n# Create index directory\nmkdir -p index\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#task-2-clone-and-analyze-source","title":"Task 2: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolindex.git\ncd toolindex\n\n# Analyze contents\nls -la\nwc -l *.go\ngo test ./... -v\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#task-3-copy-source-files","title":"Task 3: Copy Source Files","text":"<pre><code>cd /tmp/migration\n\n# Copy Go source files\ncp toolindex/*.go tooldiscovery/index/\n\n# Verify\nls -la tooldiscovery/index/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#task-4-update-import-paths","title":"Task 4: Update Import Paths","text":"<pre><code>cd /tmp/migration/tooldiscovery/index\n\n# Update toolindex import\nOLD_IMPORT=\"github.com/jonwraymond/toolindex\"\nNEW_IMPORT=\"github.com/jonwraymond/tooldiscovery/index\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\ndone\n\n# Update toolmodel to toolfoundation/model\nOLD_MODEL=\"github.com/jonwraymond/toolmodel\"\nNEW_MODEL=\"github.com/jonwraymond/toolfoundation/model\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_MODEL|$NEW_MODEL|g\" \"$file\"\ndone\n\n# Verify\ngrep -r \"jonwraymond/toolindex\\|jonwraymond/toolmodel\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#task-5-update-gomod","title":"Task 5: Update go.mod","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\n# Add dependency on toolfoundation\ncat &gt;&gt; go.mod &lt;&lt; EOF\nrequire github.com/jonwraymond/toolfoundation v0.1.0\nEOF\n\ngo mod tidy\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#task-6-update-package-documentation","title":"Task 6: Update Package Documentation","text":"<p>File: <code>tooldiscovery/index/doc.go</code></p> <pre><code>// Package index provides the core tool registry for the ApertureStack ecosystem.\n//\n// This package implements tool registration, storage, retrieval, and search\n// capabilities. It supports multiple index backends and pluggable search strategies.\n//\n// # Index Types\n//\n// The package provides two built-in index implementations:\n//\n//   - InMemoryIndex: Fast, ephemeral storage for development and testing\n//   - FileIndex: Persistent JSON-based storage for single-node deployments\n//\n// # Usage\n//\n// Create and populate an index:\n//\n//  idx := index.NewInMemoryIndex(index.Options{})\n//\n//  tool := model.Tool{\n//      ID:          \"calculator\",\n//      Name:        \"Calculator\",\n//      Description: \"Performs arithmetic\",\n//  }\n//  err := idx.Add(ctx, tool)\n//\n// Search for tools:\n//\n//  results, err := idx.Search(ctx, \"arithmetic\")\n//\n// # Pluggable Search\n//\n// The index accepts a custom Searcher for advanced search capabilities:\n//\n//  searcher := search.NewBM25Searcher(config)\n//  idx := index.NewInMemoryIndex(index.Options{\n//      Searcher: searcher,\n//  })\n//\n// # Progressive Disclosure\n//\n// Tools support three disclosure levels:\n//\n//   - Summary: ID, name, description only\n//   - Schema: Includes input/output schemas\n//   - Full: Complete tool definition with examples\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolindex as part of\n// the ApertureStack consolidation.\npackage index\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#task-7-build-and-test","title":"Task 7: Build and Test","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=coverage.out ./index/...\n\n# Check coverage\ngo tool cover -func=coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngit add -A\ngit commit -m \"feat(index): migrate toolindex package\n\nMigrate the tool registry from standalone toolindex repository.\n\nPackage contents:\n- Index interface with CRUD operations\n- InMemoryIndex for ephemeral storage\n- FileIndex for persistent storage\n- Pluggable Searcher interface\n- Progressive disclosure support\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolindex \u2192 tooldiscovery/index\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#key-interfaces","title":"Key Interfaces","text":"<p>The migrated package should expose these key interfaces:</p> <pre><code>package index\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Index provides tool storage and retrieval.\ntype Index interface {\n    // Add registers a tool in the index.\n    Add(ctx context.Context, tool model.Tool) error\n\n    // Get retrieves a tool by ID.\n    Get(ctx context.Context, id string) (model.Tool, error)\n\n    // Remove deletes a tool from the index.\n    Remove(ctx context.Context, id string) error\n\n    // List returns all tools.\n    List(ctx context.Context) ([]model.Tool, error)\n\n    // Search finds tools matching the query.\n    Search(ctx context.Context, query string) ([]model.Tool, error)\n\n    // Count returns the number of tools.\n    Count(ctx context.Context) (int, error)\n}\n\n// Searcher defines the search strategy interface.\ntype Searcher interface {\n    // Search searches for tools matching the query.\n    Search(ctx context.Context, tools []model.Tool, query string) ([]model.Tool, error)\n}\n\n// Options configures index behavior.\ntype Options struct {\n    Searcher Searcher\n    MaxTools int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All source files copied</li> <li>[x] Import paths updated</li> <li>[x] Dependency on toolfoundation works</li> <li>[x] <code>go build ./...</code> succeeds</li> <li>[x] <code>go test ./...</code> passes</li> <li>[x] Package documentation updated</li> <li>[x] Committed with proper message</li> <li>[x] Pushed to main</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>tooldiscovery/index</code> package builds successfully</li> <li>All tests pass</li> <li>Can import from <code>toolfoundation/model</code></li> <li>Index and Searcher interfaces preserved</li> <li>Progressive disclosure works</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>tooldiscovery/index/</code> contains migrated sources and tests.</li> <li><code>tooldiscovery/index/doc.go</code> documents the package.</li> <li><code>go test ./index/...</code> passes in <code>tooldiscovery</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/tooldiscovery\nrm -rf index/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-130-migrate-toolindex/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-131: Migrate toolsearch</li> <li>PRD-132: Migrate toolsemantic</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/","title":"PRD-131: Migrate toolsearch","text":"<p>Phase: 3 - Discovery Layer Priority: High Effort: 4 hours Dependencies: PRD-130 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolsearch</code> repository into <code>tooldiscovery/search/</code> as the second package in the consolidated discovery layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolsearch</code> Target Location: <code>github.com/jonwraymond/tooldiscovery/search</code></p> <p>Package Contents: - BM25 search implementation using Bleve - Fingerprint-based index caching - Configurable field boosting - ~1,500 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#deliverables","title":"Deliverables","text":"Deliverable Location Description Search Package <code>tooldiscovery/search/</code> BM25 search implementation Tests <code>tooldiscovery/search/*_test.go</code> All existing tests Documentation <code>tooldiscovery/search/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#task-1-clone-and-analyze-source","title":"Task 1: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolsearch.git\ncd toolsearch\n\n# Analyze\nls -la\nwc -l *.go\ngo test ./... -v\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#task-2-copy-source-files","title":"Task 2: Copy Source Files","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\nmkdir -p search\ncp ../toolsearch/*.go search/\n\nls -la search/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#task-3-update-import-paths","title":"Task 3: Update Import Paths","text":"<pre><code>cd /tmp/migration/tooldiscovery/search\n\n# Update self-reference\nOLD_IMPORT=\"github.com/jonwraymond/toolsearch\"\nNEW_IMPORT=\"github.com/jonwraymond/tooldiscovery/search\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\ndone\n\n# Update toolindex to tooldiscovery/index\nOLD_INDEX=\"github.com/jonwraymond/toolindex\"\nNEW_INDEX=\"github.com/jonwraymond/tooldiscovery/index\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_INDEX|$NEW_INDEX|g\" \"$file\"\ndone\n\n# Update toolmodel to toolfoundation/model\nOLD_MODEL=\"github.com/jonwraymond/toolmodel\"\nNEW_MODEL=\"github.com/jonwraymond/toolfoundation/model\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_MODEL|$NEW_MODEL|g\" \"$file\"\ndone\n\n# Verify\ngrep -r \"jonwraymond/toolsearch\\|jonwraymond/toolindex\\|jonwraymond/toolmodel\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#task-4-update-package-documentation","title":"Task 4: Update Package Documentation","text":"<p>File: <code>tooldiscovery/search/doc.go</code></p> <pre><code>// Package search provides BM25-based full-text search for tool discovery.\n//\n// This package implements a high-quality search strategy using the BM25 algorithm\n// via the Bleve search library. It integrates with tooldiscovery/index via the\n// Searcher interface.\n//\n// # Features\n//\n//   - BM25 ranking algorithm for relevance scoring\n//   - Fingerprint-based index caching for efficiency\n//   - Configurable field boosting\n//   - MaxDocs limiting for resource bounds\n//   - Text length truncation\n//\n// # Usage\n//\n// Create a BM25 searcher and inject into index:\n//\n//  searcher := search.NewBM25Searcher(search.Config{\n//      NameBoost:        2.0,\n//      DescriptionBoost: 1.0,\n//      MaxDocs:          1000,\n//      MaxDocTextLen:    10000,\n//  })\n//\n//  idx := index.NewInMemoryIndex(index.Options{\n//      Searcher: searcher,\n//  })\n//\n// # BM25 Behavior\n//\n// The searcher provides three guarantees:\n//\n//   - Deterministic: Sorted by ID before indexing, consistent tie-breaking\n//   - Efficient: Fingerprint-based caching, rebuild only when tools change\n//   - Bounded: MaxDocs and MaxDocTextLen prevent resource exhaustion\n//\n// # Configuration\n//\n//  type Config struct {\n//      NameBoost        float64 // Boost for name field (default: 2.0)\n//      DescriptionBoost float64 // Boost for description (default: 1.0)\n//      TagBoost         float64 // Boost for tags (default: 1.5)\n//      MaxDocs          int     // Maximum indexed documents\n//      MaxDocTextLen    int     // Maximum text length per field\n//  }\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolsearch as part of\n// the ApertureStack consolidation.\npackage search\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#task-5-verify-bleve-dependency","title":"Task 5: Verify Bleve Dependency","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\n# Check for Bleve import\ngrep -r \"blevesearch/bleve\" search/*.go\n\n# Add to go.mod if needed\ngo get github.com/blevesearch/bleve/v2\ngo mod tidy\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngo build ./...\ngo test -v -coverprofile=search_coverage.out ./search/...\n\n# Check coverage\ngo tool cover -func=search_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngit add -A\ngit commit -m \"feat(search): migrate toolsearch package\n\nMigrate BM25 search implementation from standalone toolsearch repository.\n\nPackage contents:\n- BM25Searcher implementing index.Searcher interface\n- Fingerprint-based index caching\n- Configurable field boosting\n- MaxDocs and MaxDocTextLen bounds\n\nDependencies:\n- github.com/blevesearch/bleve/v2\n- github.com/jonwraymond/toolfoundation/model\n- github.com/jonwraymond/tooldiscovery/index (interface only)\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolsearch \u2192 tooldiscovery/search\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#key-types","title":"Key Types","text":"<pre><code>package search\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Config configures the BM25 searcher.\ntype Config struct {\n    NameBoost        float64\n    DescriptionBoost float64\n    TagBoost         float64\n    MaxDocs          int\n    MaxDocTextLen    int\n    CacheDir         string\n}\n\n// BM25Searcher implements index.Searcher using BM25 algorithm.\ntype BM25Searcher struct {\n    config      Config\n    fingerprint string\n    index       bleve.Index\n    mu          sync.RWMutex\n}\n\n// NewBM25Searcher creates a new BM25 searcher.\nfunc NewBM25Searcher(config Config) *BM25Searcher\n\n// Search implements index.Searcher.\nfunc (s *BM25Searcher) Search(ctx context.Context, tools []model.Tool, query string) ([]model.Tool, error)\n\n// Fingerprint returns the current document fingerprint.\nfunc (s *BM25Searcher) Fingerprint() string\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All source files copied</li> <li>[x] Import paths updated (search, index, model)</li> <li>[x] Bleve dependency resolved</li> <li>[x] <code>go build ./...</code> succeeds</li> <li>[x] <code>go test ./...</code> passes</li> <li>[x] Fingerprint caching works</li> <li>[x] Package documentation updated</li> <li>[x] Committed with proper message</li> <li>[x] Pushed to main</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>tooldiscovery/search</code> package builds successfully</li> <li>All tests pass</li> <li>BM25 search returns relevant results</li> <li>Fingerprint caching is efficient</li> <li>Implements <code>index.Searcher</code> interface</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>tooldiscovery/search/</code> contains migrated sources and tests.</li> <li><code>tooldiscovery/search/doc.go</code> documents the package.</li> <li><code>go test ./search/...</code> passes in <code>tooldiscovery</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/tooldiscovery\nrm -rf search/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-131-migrate-toolsearch/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-132: Migrate toolsemantic</li> <li>PRD-133: Migrate tooldocs</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/","title":"PRD-132: Migrate toolsemantic","text":"<p>Phase: 3 - Discovery Layer Priority: High Effort: 6 hours Dependencies: PRD-131 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#objective","title":"Objective","text":"<p>Migrate and complete the partial <code>toolsemantic</code> implementation into <code>tooldiscovery/semantic/</code> for vector-based semantic search capabilities.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolsemantic</code> (partial implementation) Target Location: <code>github.com/jonwraymond/tooldiscovery/semantic</code></p> <p>Current State: - Partial implementation with interfaces defined - Embedder interface for text-to-vector conversion - Vector index interface for similarity search - Needs completion: actual implementations</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#deliverables","title":"Deliverables","text":"Deliverable Location Description Semantic Package <code>tooldiscovery/semantic/</code> Vector search implementation Embedder Interface <code>semantic/embedder.go</code> Text embedding abstraction Vector Index <code>semantic/index.go</code> Vector similarity search Hybrid Searcher <code>semantic/hybrid.go</code> Combined BM25 + vector search Tests <code>semantic/*_test.go</code> Comprehensive tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#task-1-create-package-structure","title":"Task 1: Create Package Structure","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\nmkdir -p semantic\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#task-2-copy-existing-code","title":"Task 2: Copy Existing Code","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolsemantic.git\ncd toolsemantic\n\n# Copy existing files\ncp *.go ../tooldiscovery/semantic/\n\n# Update imports\ncd ../tooldiscovery/semantic\nsed -i '' 's|github.com/jonwraymond/toolsemantic|github.com/jonwraymond/tooldiscovery/semantic|g' *.go\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#task-3-define-core-interfaces","title":"Task 3: Define Core Interfaces","text":"<p>File: <code>tooldiscovery/semantic/embedder.go</code></p> <pre><code>package semantic\n\nimport \"context\"\n\n// Embedder converts text to vector embeddings.\ntype Embedder interface {\n    // Embed converts text to a vector embedding.\n    Embed(ctx context.Context, text string) ([]float32, error)\n\n    // EmbedBatch converts multiple texts to embeddings.\n    EmbedBatch(ctx context.Context, texts []string) ([][]float32, error)\n\n    // Dimension returns the embedding dimension.\n    Dimension() int\n\n    // Name returns the embedder name (e.g., \"openai\", \"cohere\").\n    Name() string\n}\n\n// EmbedderConfig is the base configuration for embedders.\ntype EmbedderConfig struct {\n    Model     string\n    Dimension int\n    BatchSize int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#task-4-define-vector-index-interface","title":"Task 4: Define Vector Index Interface","text":"<p>File: <code>tooldiscovery/semantic/index.go</code></p> <pre><code>package semantic\n\nimport (\n    \"context\"\n)\n\n// VectorIndex stores and searches vector embeddings.\ntype VectorIndex interface {\n    // Add adds a vector with its ID.\n    Add(ctx context.Context, id string, vector []float32) error\n\n    // AddBatch adds multiple vectors.\n    AddBatch(ctx context.Context, ids []string, vectors [][]float32) error\n\n    // Search finds the k most similar vectors to the query.\n    Search(ctx context.Context, query []float32, k int) ([]SearchResult, error)\n\n    // Remove deletes a vector by ID.\n    Remove(ctx context.Context, id string) error\n\n    // Count returns the number of vectors.\n    Count(ctx context.Context) (int, error)\n}\n\n// SearchResult represents a similarity search result.\ntype SearchResult struct {\n    ID       string\n    Score    float32\n    Distance float32\n}\n\n// VectorIndexConfig configures the vector index.\ntype VectorIndexConfig struct {\n    Dimension    int\n    Metric       string // \"cosine\", \"euclidean\", \"dot\"\n    MaxElements  int\n    EfSearch     int // HNSW search parameter\n    EfConstruct  int // HNSW construction parameter\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#task-5-implement-in-memory-vector-index","title":"Task 5: Implement In-Memory Vector Index","text":"<p>File: <code>tooldiscovery/semantic/memory_index.go</code></p> <pre><code>package semantic\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"math\"\n    \"sort\"\n    \"sync\"\n)\n\n// MemoryVectorIndex is an in-memory vector index using brute-force search.\n// Suitable for small to medium datasets (&lt;10k vectors).\ntype MemoryVectorIndex struct {\n    vectors   map[string][]float32\n    dimension int\n    metric    string\n    mu        sync.RWMutex\n}\n\n// NewMemoryVectorIndex creates a new in-memory vector index.\nfunc NewMemoryVectorIndex(config VectorIndexConfig) *MemoryVectorIndex {\n    return &amp;MemoryVectorIndex{\n        vectors:   make(map[string][]float32),\n        dimension: config.Dimension,\n        metric:    config.Metric,\n    }\n}\n\nfunc (m *MemoryVectorIndex) Add(ctx context.Context, id string, vector []float32) error {\n    if len(vector) != m.dimension {\n        return fmt.Errorf(\"expected dimension %d, got %d\", m.dimension, len(vector))\n    }\n    m.mu.Lock()\n    defer m.mu.Unlock()\n    m.vectors[id] = vector\n    return nil\n}\n\nfunc (m *MemoryVectorIndex) AddBatch(ctx context.Context, ids []string, vectors [][]float32) error {\n    if len(ids) != len(vectors) {\n        return fmt.Errorf(\"ids and vectors length mismatch\")\n    }\n    for i, id := range ids {\n        if err := m.Add(ctx, id, vectors[i]); err != nil {\n            return err\n        }\n    }\n    return nil\n}\n\nfunc (m *MemoryVectorIndex) Search(ctx context.Context, query []float32, k int) ([]SearchResult, error) {\n    m.mu.RLock()\n    defer m.mu.RUnlock()\n\n    results := make([]SearchResult, 0, len(m.vectors))\n    for id, vector := range m.vectors {\n        score := m.similarity(query, vector)\n        results = append(results, SearchResult{\n            ID:    id,\n            Score: score,\n        })\n    }\n\n    sort.Slice(results, func(i, j int) bool {\n        return results[i].Score &gt; results[j].Score\n    })\n\n    if k &lt; len(results) {\n        results = results[:k]\n    }\n    return results, nil\n}\n\nfunc (m *MemoryVectorIndex) Remove(ctx context.Context, id string) error {\n    m.mu.Lock()\n    defer m.mu.Unlock()\n    delete(m.vectors, id)\n    return nil\n}\n\nfunc (m *MemoryVectorIndex) Count(ctx context.Context) (int, error) {\n    m.mu.RLock()\n    defer m.mu.RUnlock()\n    return len(m.vectors), nil\n}\n\nfunc (m *MemoryVectorIndex) similarity(a, b []float32) float32 {\n    switch m.metric {\n    case \"cosine\":\n        return cosineSimilarity(a, b)\n    case \"dot\":\n        return dotProduct(a, b)\n    default:\n        return cosineSimilarity(a, b)\n    }\n}\n\nfunc cosineSimilarity(a, b []float32) float32 {\n    var dot, normA, normB float32\n    for i := range a {\n        dot += a[i] * b[i]\n        normA += a[i] * a[i]\n        normB += b[i] * b[i]\n    }\n    if normA == 0 || normB == 0 {\n        return 0\n    }\n    return dot / (float32(math.Sqrt(float64(normA))) * float32(math.Sqrt(float64(normB))))\n}\n\nfunc dotProduct(a, b []float32) float32 {\n    var dot float32\n    for i := range a {\n        dot += a[i] * b[i]\n    }\n    return dot\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#task-6-implement-hybrid-searcher","title":"Task 6: Implement Hybrid Searcher","text":"<p>File: <code>tooldiscovery/semantic/hybrid.go</code></p> <pre><code>package semantic\n\nimport (\n    \"context\"\n    \"sort\"\n\n    \"github.com/jonwraymond/toolfoundation/model\"\n    \"github.com/jonwraymond/tooldiscovery/index\"\n)\n\n// HybridSearcher combines BM25 and semantic search.\ntype HybridSearcher struct {\n    bm25Searcher   index.Searcher\n    embedder       Embedder\n    vectorIndex    VectorIndex\n    bm25Weight     float32\n    semanticWeight float32\n}\n\n// HybridConfig configures the hybrid searcher.\ntype HybridConfig struct {\n    BM25Searcher   index.Searcher\n    Embedder       Embedder\n    VectorIndex    VectorIndex\n    BM25Weight     float32 // default: 0.5\n    SemanticWeight float32 // default: 0.5\n}\n\n// NewHybridSearcher creates a hybrid BM25 + semantic searcher.\nfunc NewHybridSearcher(config HybridConfig) *HybridSearcher {\n    bm25Weight := config.BM25Weight\n    semanticWeight := config.SemanticWeight\n    if bm25Weight == 0 &amp;&amp; semanticWeight == 0 {\n        bm25Weight = 0.5\n        semanticWeight = 0.5\n    }\n\n    return &amp;HybridSearcher{\n        bm25Searcher:   config.BM25Searcher,\n        embedder:       config.Embedder,\n        vectorIndex:    config.VectorIndex,\n        bm25Weight:     bm25Weight,\n        semanticWeight: semanticWeight,\n    }\n}\n\n// Search performs hybrid search combining BM25 and semantic results.\nfunc (h *HybridSearcher) Search(ctx context.Context, tools []model.Tool, query string) ([]model.Tool, error) {\n    // Index tools if needed\n    if err := h.indexTools(ctx, tools); err != nil {\n        return nil, err\n    }\n\n    // Get BM25 results\n    bm25Results, err := h.bm25Searcher.Search(ctx, tools, query)\n    if err != nil {\n        return nil, err\n    }\n\n    // Get semantic results\n    queryVec, err := h.embedder.Embed(ctx, query)\n    if err != nil {\n        return nil, err\n    }\n\n    semanticResults, err := h.vectorIndex.Search(ctx, queryVec, len(tools))\n    if err != nil {\n        return nil, err\n    }\n\n    // Combine results using reciprocal rank fusion\n    return h.fuseResults(tools, bm25Results, semanticResults), nil\n}\n\nfunc (h *HybridSearcher) indexTools(ctx context.Context, tools []model.Tool) error {\n    count, _ := h.vectorIndex.Count(ctx)\n    if count &gt;= len(tools) {\n        return nil // Already indexed\n    }\n\n    texts := make([]string, len(tools))\n    ids := make([]string, len(tools))\n    for i, tool := range tools {\n        texts[i] = tool.Name + \" \" + tool.Description\n        ids[i] = tool.ID\n    }\n\n    vectors, err := h.embedder.EmbedBatch(ctx, texts)\n    if err != nil {\n        return err\n    }\n\n    return h.vectorIndex.AddBatch(ctx, ids, vectors)\n}\n\nfunc (h *HybridSearcher) fuseResults(tools []model.Tool, bm25Results []model.Tool, semanticResults []SearchResult) []model.Tool {\n    // Reciprocal Rank Fusion\n    const k = 60.0 // RRF constant\n\n    scores := make(map[string]float32)\n\n    // BM25 scores\n    for i, tool := range bm25Results {\n        rank := float32(i + 1)\n        scores[tool.ID] += h.bm25Weight * (1.0 / (k + rank))\n    }\n\n    // Semantic scores\n    for i, result := range semanticResults {\n        rank := float32(i + 1)\n        scores[result.ID] += h.semanticWeight * (1.0 / (k + rank))\n    }\n\n    // Sort by combined score\n    type scored struct {\n        tool  model.Tool\n        score float32\n    }\n    toolMap := make(map[string]model.Tool)\n    for _, t := range tools {\n        toolMap[t.ID] = t\n    }\n\n    results := make([]scored, 0, len(scores))\n    for id, score := range scores {\n        if tool, ok := toolMap[id]; ok {\n            results = append(results, scored{tool, score})\n        }\n    }\n\n    sort.Slice(results, func(i, j int) bool {\n        return results[i].score &gt; results[j].score\n    })\n\n    output := make([]model.Tool, len(results))\n    for i, r := range results {\n        output[i] = r.tool\n    }\n    return output\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#task-7-create-package-documentation","title":"Task 7: Create Package Documentation","text":"<p>File: <code>tooldiscovery/semantic/doc.go</code></p> <pre><code>// Package semantic provides vector-based semantic search for tool discovery.\n//\n// This package enables semantic similarity search using vector embeddings,\n// complementing the BM25 keyword search in tooldiscovery/search.\n//\n// # Components\n//\n//   - Embedder: Converts text to vector embeddings\n//   - VectorIndex: Stores and searches vector embeddings\n//   - HybridSearcher: Combines BM25 and semantic search\n//\n// # Usage\n//\n// Create a hybrid searcher:\n//\n//  embedder := openai.NewEmbedder(apiKey)\n//  vectorIndex := semantic.NewMemoryVectorIndex(semantic.VectorIndexConfig{\n//      Dimension: 1536,\n//      Metric:    \"cosine\",\n//  })\n//  bm25 := search.NewBM25Searcher(search.Config{})\n//\n//  hybrid := semantic.NewHybridSearcher(semantic.HybridConfig{\n//      BM25Searcher:   bm25,\n//      Embedder:       embedder,\n//      VectorIndex:    vectorIndex,\n//      BM25Weight:     0.5,\n//      SemanticWeight: 0.5,\n//  })\n//\n// # Fusion Strategy\n//\n// The hybrid searcher uses Reciprocal Rank Fusion (RRF) to combine results:\n//\n//  score(d) = \u03a3(weight_i / (k + rank_i(d)))\n//\n// This produces robust rankings without score normalization.\n//\n// # Embedder Implementations\n//\n// The package defines the Embedder interface. Implementations are provided\n// separately to avoid API key dependencies:\n//\n//   - OpenAI: text-embedding-3-small/large\n//   - Cohere: embed-english-v3\n//   - Local: sentence-transformers via gRPC\n//\n// # Migration Note\n//\n// This package consolidates and completes the partial toolsemantic\n// implementation as part of the ApertureStack consolidation.\npackage semantic\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#task-8-create-tests","title":"Task 8: Create Tests","text":"<p>File: <code>tooldiscovery/semantic/semantic_test.go</code></p> <pre><code>package semantic\n\nimport (\n    \"context\"\n    \"testing\"\n)\n\nfunc TestMemoryVectorIndex(t *testing.T) {\n    ctx := context.Background()\n    idx := NewMemoryVectorIndex(VectorIndexConfig{\n        Dimension: 3,\n        Metric:    \"cosine\",\n    })\n\n    // Add vectors\n    err := idx.Add(ctx, \"a\", []float32{1, 0, 0})\n    if err != nil {\n        t.Fatal(err)\n    }\n    err = idx.Add(ctx, \"b\", []float32{0, 1, 0})\n    if err != nil {\n        t.Fatal(err)\n    }\n    err = idx.Add(ctx, \"c\", []float32{0.9, 0.1, 0})\n    if err != nil {\n        t.Fatal(err)\n    }\n\n    // Search for similar to a\n    results, err := idx.Search(ctx, []float32{1, 0, 0}, 2)\n    if err != nil {\n        t.Fatal(err)\n    }\n\n    if len(results) != 2 {\n        t.Errorf(\"expected 2 results, got %d\", len(results))\n    }\n    if results[0].ID != \"a\" {\n        t.Errorf(\"expected first result to be 'a', got '%s'\", results[0].ID)\n    }\n    if results[1].ID != \"c\" {\n        t.Errorf(\"expected second result to be 'c', got '%s'\", results[1].ID)\n    }\n}\n\nfunc TestCosineSimilarity(t *testing.T) {\n    tests := []struct {\n        a, b []float32\n        want float32\n    }{\n        {[]float32{1, 0}, []float32{1, 0}, 1.0},\n        {[]float32{1, 0}, []float32{0, 1}, 0.0},\n        {[]float32{1, 0}, []float32{-1, 0}, -1.0},\n    }\n\n    for _, tt := range tests {\n        got := cosineSimilarity(tt.a, tt.b)\n        if got != tt.want {\n            t.Errorf(\"cosineSimilarity(%v, %v) = %f, want %f\", tt.a, tt.b, got, tt.want)\n        }\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#task-9-build-and-test","title":"Task 9: Build and Test","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=semantic_coverage.out ./semantic/...\ngo tool cover -func=semantic_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#task-10-commit-and-push","title":"Task 10: Commit and Push","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngit add -A\ngit commit -m \"feat(semantic): add semantic search package\n\nAdd vector-based semantic search capabilities for tool discovery.\n\nPackage contents:\n- Embedder interface for text-to-vector conversion\n- VectorIndex interface for similarity search\n- MemoryVectorIndex for in-memory brute-force search\n- HybridSearcher combining BM25 + semantic with RRF fusion\n\nFeatures:\n- Cosine and dot product similarity metrics\n- Reciprocal Rank Fusion for result combination\n- Configurable BM25/semantic weight balance\n- Pluggable embedder and vector index backends\n\nThis consolidates and completes the partial toolsemantic implementation.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] Core interfaces defined (Embedder, VectorIndex)</li> <li>[x] MemoryVectorIndex implemented</li> <li>[x] HybridSearcher implemented</li> <li>[x] Cosine similarity works correctly</li> <li>[x] <code>go build ./...</code> succeeds</li> <li>[x] <code>go test ./...</code> passes</li> <li>[x] Package documentation complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>tooldiscovery/semantic</code> builds successfully</li> <li>MemoryVectorIndex passes tests</li> <li>HybridSearcher combines BM25 and semantic results</li> <li>RRF fusion produces meaningful rankings</li> <li>Implements <code>index.Searcher</code> interface</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>tooldiscovery/semantic/</code> contains interfaces and in-memory implementations.</li> <li><code>tooldiscovery/semantic/doc.go</code> documents the package.</li> <li><code>go test ./semantic/...</code> passes in <code>tooldiscovery</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/tooldiscovery\nrm -rf semantic/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-132-migrate-toolsemantic/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-133: Migrate tooldocs</li> <li>Gate G3: Discovery + Execution layers complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/","title":"PRD-133: Migrate tooldocs","text":"<p>Phase: 3 - Discovery Layer Priority: Medium Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#objective","title":"Objective","text":"<p>Migrate the existing <code>tooldocs</code> repository into <code>tooldiscovery/tooldoc/</code> as the fourth package in the consolidated discovery layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/tooldocs</code> Target Location: <code>github.com/jonwraymond/tooldiscovery/tooldoc</code></p> <p>Package Contents: - Tool documentation storage and retrieval - Progressive disclosure (Summary/Schema/Full) - Example management - Markdown rendering support - ~1,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#deliverables","title":"Deliverables","text":"Deliverable Location Description Docs Package <code>tooldiscovery/tooldoc/</code> Documentation management Tests <code>tooldiscovery/tooldoc/*_test.go</code> All existing tests Documentation <code>tooldiscovery/tooldoc/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#task-1-clone-and-analyze-source","title":"Task 1: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/tooldocs.git\ncd tooldocs\n\nls -la\nwc -l *.go\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#task-2-copy-source-files","title":"Task 2: Copy Source Files","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\n# Note: using 'docs' as package name (not 'tooldocs')\nmkdir -p docs\ncp ../tooldocs/*.go docs/\n\nls -la docs/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#task-3-update-import-paths","title":"Task 3: Update Import Paths","text":"<pre><code>cd /tmp/migration/tooldiscovery/tooldoc\n\n# Update self-reference\nOLD_IMPORT=\"github.com/jonwraymond/tooldocs\"\nNEW_IMPORT=\"github.com/jonwraymond/tooldiscovery/tooldoc\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\ndone\n\n# Update toolmodel to toolfoundation/model\nOLD_MODEL=\"github.com/jonwraymond/toolmodel\"\nNEW_MODEL=\"github.com/jonwraymond/toolfoundation/model\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_MODEL|$NEW_MODEL|g\" \"$file\"\ndone\n\n# Verify\ngrep -r \"jonwraymond/tooldocs\\|jonwraymond/toolmodel\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#task-4-update-package-documentation","title":"Task 4: Update Package Documentation","text":"<p>File: <code>tooldiscovery/tooldoc/doc.go</code></p> <pre><code>// Package docs provides documentation storage and retrieval for tools.\n//\n// This package manages tool documentation with support for progressive disclosure,\n// allowing clients to request varying levels of detail based on their needs.\n//\n// # Disclosure Levels\n//\n// The package supports three disclosure levels:\n//\n//   - Summary: Minimal information (ID, name, description)\n//   - Schema: Includes input/output JSON schemas\n//   - Full: Complete documentation including examples and usage\n//\n// # Usage\n//\n// Create a documentation store:\n//\n//  store := docs.NewStore(docs.Config{\n//      BaseDir: \"./tool-docs\",\n//  })\n//\n// Get documentation at different levels:\n//\n//  summary, _ := store.Get(ctx, \"calculator\", docs.LevelSummary)\n//  schema, _ := store.Get(ctx, \"calculator\", docs.LevelSchema)\n//  full, _ := store.Get(ctx, \"calculator\", docs.LevelFull)\n//\n// # Storage\n//\n// Documentation is stored as structured files:\n//\n//  tool-docs/\n//  \u251c\u2500\u2500 calculator/\n//  \u2502   \u251c\u2500\u2500 README.md      # Full documentation\n//  \u2502   \u251c\u2500\u2500 schema.json    # Input/output schemas\n//  \u2502   \u2514\u2500\u2500 examples/\n//  \u2502       \u251c\u2500\u2500 basic.json\n//  \u2502       \u2514\u2500\u2500 advanced.json\n//\n// # Examples\n//\n// The package includes example management:\n//\n//  examples, _ := store.GetExamples(ctx, \"calculator\")\n//  for _, ex := range examples {\n//      fmt.Printf(\"Example: %s\\n\", ex.Name)\n//      fmt.Printf(\"Input: %s\\n\", ex.Input)\n//      fmt.Printf(\"Output: %s\\n\", ex.Output)\n//  }\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/tooldocs as part of\n// the ApertureStack consolidation.\npackage docs\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#task-5-define-core-types","title":"Task 5: Define Core Types","text":"<p>Ensure these types exist in the migrated code:</p> <p>File: <code>tooldiscovery/tooldoc/types.go</code></p> <pre><code>package docs\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Level represents the disclosure level for documentation.\ntype Level int\n\nconst (\n    // LevelSummary provides minimal information.\n    LevelSummary Level = iota\n    // LevelSchema includes input/output schemas.\n    LevelSchema\n    // LevelFull provides complete documentation.\n    LevelFull\n)\n\n// Documentation holds tool documentation at various levels.\ntype Documentation struct {\n    Tool        model.Tool\n    Level       Level\n    Markdown    string\n    Examples    []Example\n    LastUpdated string\n}\n\n// Example represents a tool usage example.\ntype Example struct {\n    Name        string\n    Description string\n    Input       map[string]any\n    Output      any\n    Tags        []string\n}\n\n// Store provides documentation storage and retrieval.\ntype Store interface {\n    // Get retrieves documentation at the specified level.\n    Get(ctx context.Context, toolID string, level Level) (*Documentation, error)\n\n    // Set stores documentation for a tool.\n    Set(ctx context.Context, doc *Documentation) error\n\n    // GetExamples retrieves examples for a tool.\n    GetExamples(ctx context.Context, toolID string) ([]Example, error)\n\n    // AddExample adds an example to a tool.\n    AddExample(ctx context.Context, toolID string, example Example) error\n\n    // List returns all documented tool IDs.\n    List(ctx context.Context) ([]string, error)\n}\n\n// Config configures the documentation store.\ntype Config struct {\n    BaseDir     string\n    CacheSize   int\n    EnableCache bool\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=docs_coverage.out ./docs/...\n\ngo tool cover -func=docs_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/tooldiscovery\n\ngit add -A\ngit commit -m \"feat(docs): migrate tooldocs package\n\nMigrate tool documentation management from standalone tooldocs repository.\n\nPackage contents:\n- Store interface for documentation CRUD\n- Progressive disclosure levels (Summary/Schema/Full)\n- Example management\n- File-based storage implementation\n- Optional caching\n\nFeatures:\n- Three-tier disclosure: summary, schema, full\n- Markdown documentation support\n- JSON example storage\n- Last-updated tracking\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/tooldocs \u2192 tooldiscovery/tooldoc\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#file-mapping","title":"File Mapping","text":"Source Target <code>tooldocs/store.go</code> <code>tooldiscovery/tooldoc/store.go</code> <code>tooldocs/store_test.go</code> <code>tooldiscovery/tooldoc/store_test.go</code> <code>tooldocs/types.go</code> <code>tooldiscovery/tooldoc/types.go</code> <code>tooldocs/file.go</code> <code>tooldiscovery/tooldoc/file.go</code> <code>tooldocs/cache.go</code> <code>tooldiscovery/tooldoc/cache.go</code> <code>tooldocs/doc.go</code> <code>tooldiscovery/tooldoc/doc.go</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All source files copied</li> <li>[x] Import paths updated</li> <li>[x] <code>go build ./...</code> succeeds</li> <li>[x] <code>go test ./...</code> passes</li> <li>[x] Progressive disclosure works</li> <li>[x] Example management works</li> <li>[x] Package documentation updated</li> <li>[x] Committed with proper message</li> <li>[x] Pushed to main</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>tooldiscovery/tooldoc</code> package builds successfully</li> <li>All tests pass</li> <li>Three disclosure levels work correctly</li> <li>Examples can be stored and retrieved</li> <li>File-based storage persists data</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>tooldiscovery/tooldoc/</code> contains migrated sources and tests.</li> <li><code>tooldiscovery/tooldoc/doc.go</code> documents the package.</li> <li><code>go test ./tooldoc/...</code> passes in <code>tooldiscovery</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/tooldiscovery\nrm -rf tooldoc/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-133-migrate-tooldocs/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G3: Discovery layer complete (all 4 packages)</li> <li>PRD-140: Migrate toolrun</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-134-tooldiscovery-docs-alignment/","title":"PRD-134: tooldiscovery Docs + README Alignment","text":"<p>Phase: 3 - Discovery Layer Priority: High Effort: 2 hours Dependencies: PRD-130\u2013133 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-134-tooldiscovery-docs-alignment/#objective","title":"Objective","text":"<p>Align public-facing documentation with the consolidated <code>tooldiscovery</code> API:</p> <ul> <li>Replace README placeholders.</li> <li>Ensure docs show correct package names and usage.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-134-tooldiscovery-docs-alignment/#deliverables","title":"Deliverables","text":"Deliverable Location Description Updated README <code>tooldiscovery/README.md</code> Package table + descriptions Updated docs <code>tooldiscovery/docs/*</code> Accurate usage examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-134-tooldiscovery-docs-alignment/#tasks","title":"Tasks","text":"<ol> <li>Update README package table (index/search/semantic/tooldoc).</li> <li>Verify docs/index.md examples compile against current API.</li> <li>Verify user-journey.md uses correct types and packages.</li> <li>Run tests.</li> </ol> <pre><code>cd tooldiscovery\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-134-tooldiscovery-docs-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>README has no <code>TBD</code> entries.</li> <li>Docs reflect current package names and usage.</li> <li>Tests pass.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-134-tooldiscovery-docs-alignment/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>README updated and committed.</li> <li>Docs updated with current package names and examples.</li> <li><code>go test ./...</code> passes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-135-tooldiscovery-search-policy/","title":"PRD-135: tooldiscovery Search Strategy Policy Docs","text":"<p>Phase: 3 - Discovery Layer Priority: Medium Effort: 2 hours Dependencies: PRD-131 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-135-tooldiscovery-search-policy/#objective","title":"Objective","text":"<p>Document search strategy behavior and configuration for the <code>search</code> package:</p> <ul> <li>BM25 configuration (field boosts)</li> <li>Indexing scope and caching behavior</li> <li>Guidance for choosing strategies</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-135-tooldiscovery-search-policy/#deliverables","title":"Deliverables","text":"Deliverable Location Description Search policy section <code>tooldiscovery/docs/design-notes.md</code> BM25 config + behavior Summary note <code>tooldiscovery/docs/index.md</code> Short guidance + link"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-135-tooldiscovery-search-policy/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>BM25 configuration is explicitly documented.</li> <li>Guidance for selecting lexical vs BM25 vs semantic is present.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-135-tooldiscovery-search-policy/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Search policy documented in <code>tooldiscovery/docs/design-notes.md</code>.</li> <li>Summary guidance added in <code>tooldiscovery/docs/index.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-136-tooldiscovery-semantic-contracts/","title":"PRD-136: tooldiscovery Semantic Contracts","text":"<p>Phase: 3 - Discovery Layer Priority: Medium Effort: 2 hours Dependencies: PRD-132 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-136-tooldiscovery-semantic-contracts/#objective","title":"Objective","text":"<p>Document the semantic search contracts:</p> <ul> <li><code>Embedder</code> interface expectations</li> <li><code>VectorStore</code> behaviors and result format</li> <li>Hybrid search + RRF fusion behavior</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-136-tooldiscovery-semantic-contracts/#deliverables","title":"Deliverables","text":"Deliverable Location Description Contract section <code>tooldiscovery/docs/design-notes.md</code> Interface expectations Usage example <code>tooldiscovery/docs/index.md</code> Minimal semantic search example"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-136-tooldiscovery-semantic-contracts/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Embedder/VectorStore contracts are documented.</li> <li>Hybrid search semantics are stated.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-136-tooldiscovery-semantic-contracts/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Semantic contracts documented in <code>tooldiscovery/docs/design-notes.md</code>.</li> <li>Usage example added in <code>tooldiscovery/docs/index.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-137-tooldiscovery-progressive-docs/","title":"PRD-137: tooldiscovery Progressive Documentation Details","text":"<p>Phase: 3 - Discovery Layer Priority: Medium Effort: 2 hours Dependencies: PRD-133 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-137-tooldiscovery-progressive-docs/#objective","title":"Objective","text":"<p>Document the progressive disclosure model in <code>tooldoc</code>:</p> <ul> <li>Detail levels and what each includes</li> <li>Performance considerations (token cost)</li> <li>Example usage patterns</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-137-tooldiscovery-progressive-docs/#deliverables","title":"Deliverables","text":"Deliverable Location Description Detail-level table <code>tooldiscovery/docs/design-notes.md</code> Explicit fields per level User guidance <code>tooldiscovery/docs/user-journey.md</code> When to request each level"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-137-tooldiscovery-progressive-docs/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Detail level semantics are explicit.</li> <li>Usage guidance is present in user journey.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-137-tooldiscovery-progressive-docs/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Detail-level matrix documented in <code>tooldiscovery/docs/design-notes.md</code>.</li> <li>Guidance added to <code>tooldiscovery/docs/user-journey.md</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-138-tooldiscovery-release-propagation/","title":"PRD-138: tooldiscovery Release + Version Propagation","text":"<p>Phase: 3 - Discovery Layer Priority: Medium Effort: 1 hour Dependencies: PRD-130\u2013133 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-138-tooldiscovery-release-propagation/#objective","title":"Objective","text":"<p>Tag and propagate the consolidated <code>tooldiscovery</code> module version into the stack.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-138-tooldiscovery-release-propagation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Module tag <code>tooldiscovery</code> <code>v0.1.0</code> tag exists Version matrix entry <code>ai-tools-stack/VERSIONS.md</code> tooldiscovery row present go.mod alignment <code>ai-tools-stack/go.mod</code> tooldiscovery dependency pinned"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-138-tooldiscovery-release-propagation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Tag <code>v0.1.0</code> exists in <code>tooldiscovery</code>.</li> <li>Version matrix already reflects tooldiscovery v0.1.0.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-138-tooldiscovery-release-propagation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li>Tag <code>v0.1.0</code> pushed in <code>tooldiscovery</code>.</li> <li><code>ai-tools-stack/VERSIONS.md</code> already lists tooldiscovery v0.1.0.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-139-tooldiscovery-validation/","title":"PRD-139: tooldiscovery Validation (G3 - Discovery Only)","text":"<p>Phase: 3 - Discovery Layer Priority: High Effort: 1 hour Dependencies: PRD-130\u2013138 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-139-tooldiscovery-validation/#objective","title":"Objective","text":"<p>Validate the discovery layer implementation for correctness and CI readiness.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-139-tooldiscovery-validation/#verification-steps","title":"Verification Steps","text":"<pre><code>cd tooldiscovery\n\ngo test ./...\n\ngolangci-lint run\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-139-tooldiscovery-validation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li><code>go test ./...</code> passes.</li> <li><code>golangci-lint run</code> passes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-139-tooldiscovery-validation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>go test ./...</code> passes in <code>tooldiscovery</code>.</li> <li><code>golangci-lint run</code> passes in <code>tooldiscovery</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/","title":"PRD-140: Migrate toolrun","text":"<p>Phase: 4 - Execution Layer Priority: Critical Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolrun</code> repository into <code>toolexec/run/</code> as the first package in the consolidated execution layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolrun</code> Target Location: <code>github.com/jonwraymond/toolexec/run</code></p> <p>Package Contents: - Tool execution pipeline (6-step execution) - Backend dispatch (local, docker, wasm, remote) - Chain execution for tool sequences - Streaming support - ~5,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#deliverables","title":"Deliverables","text":"Deliverable Location Description Run Package <code>toolexec/run/</code> Execution pipeline Tests <code>toolexec/run/*_test.go</code> All existing tests Documentation <code>toolexec/run/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#task-1-prepare-target-repository","title":"Task 1: Prepare Target Repository","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolexec.git\ncd toolexec\n\nmkdir -p run\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#task-2-clone-and-analyze-source","title":"Task 2: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolrun.git\ncd toolrun\n\nls -la\nwc -l *.go\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#task-3-copy-source-files","title":"Task 3: Copy Source Files","text":"<pre><code>cd /tmp/migration\n\ncp toolrun/*.go toolexec/run/\nls -la toolexec/run/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#task-4-update-import-paths","title":"Task 4: Update Import Paths","text":"<pre><code>cd /tmp/migration/toolexec/run\n\n# Update self-reference\nOLD_IMPORT=\"github.com/jonwraymond/toolrun\"\nNEW_IMPORT=\"github.com/jonwraymond/toolexec/run\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\ndone\n\n# Update toolmodel to toolfoundation/model\nOLD_MODEL=\"github.com/jonwraymond/toolmodel\"\nNEW_MODEL=\"github.com/jonwraymond/toolfoundation/model\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_MODEL|$NEW_MODEL|g\" \"$file\"\ndone\n\n# Update toolruntime if referenced\nOLD_RUNTIME=\"github.com/jonwraymond/toolruntime\"\nNEW_RUNTIME=\"github.com/jonwraymond/toolexec/runtime\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_RUNTIME|$NEW_RUNTIME|g\" \"$file\"\ndone\n\n# Verify\ngrep -r \"jonwraymond/toolrun\\|jonwraymond/toolmodel\\|jonwraymond/toolruntime\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#task-5-update-package-documentation","title":"Task 5: Update Package Documentation","text":"<p>File: <code>toolexec/run/doc.go</code></p> <pre><code>// Package run provides the tool execution pipeline for the ApertureStack ecosystem.\n//\n// This package implements a 6-step execution pipeline that handles tool invocation\n// from request to response, with support for multiple execution backends and\n// chain execution.\n//\n// # Execution Pipeline\n//\n// The pipeline consists of six steps:\n//\n//  1. Validate: Check input against tool schema\n//  2. Authorize: Verify execution permissions\n//  3. Prepare: Set up execution context\n//  4. Execute: Run tool via selected backend\n//  5. Transform: Post-process output\n//  6. Respond: Format and return result\n//\n// # Usage\n//\n// Create a runner and execute tools:\n//\n//  runner := run.NewRunner(run.Config{\n//      DefaultBackend: \"local\",\n//      Timeout:        30 * time.Second,\n//  })\n//\n//  result, err := runner.Run(ctx, run.Request{\n//      ToolID: \"calculator\",\n//      Input:  map[string]any{\"operation\": \"add\", \"a\": 1, \"b\": 2},\n//  })\n//\n// # Backends\n//\n// The runner supports multiple execution backends:\n//\n//   - local: Direct in-process execution\n//   - docker: Container-based isolation\n//   - wasm: WebAssembly sandbox\n//   - remote: HTTP/gRPC remote execution\n//\n// # Chain Execution\n//\n// Execute a sequence of tools where output flows to input:\n//\n//  chain := run.Chain{\n//      Steps: []run.ChainStep{\n//          {ToolID: \"fetch-data\", Input: map[string]any{\"url\": \"...\"}},\n//          {ToolID: \"transform\", InputMapping: map[string]string{\"data\": \"$.output\"}},\n//          {ToolID: \"store\", InputMapping: map[string]string{\"content\": \"$.output\"}},\n//      },\n//  }\n//  results, err := runner.RunChain(ctx, chain)\n//\n// # Streaming\n//\n// For long-running tools, use streaming execution:\n//\n//  stream, err := runner.RunStream(ctx, request)\n//  for event := range stream.Events() {\n//      fmt.Printf(\"Progress: %s\\n\", event.Message)\n//  }\n//  result := stream.Result()\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolrun as part of\n// the ApertureStack consolidation.\npackage run\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/toolexec\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=run_coverage.out ./run/...\n\ngo tool cover -func=run_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/toolexec\n\ngit add -A\ngit commit -m \"feat(run): migrate toolrun package\n\nMigrate the execution pipeline from standalone toolrun repository.\n\nPackage contents:\n- 6-step execution pipeline\n- Multi-backend dispatch (local, docker, wasm, remote)\n- Chain execution for tool sequences\n- Streaming execution support\n- Configurable timeouts and retries\n\nFeatures:\n- Input validation against tool schema\n- Authorization hooks\n- Context preparation\n- Backend selection\n- Output transformation\n- Response formatting\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolrun \u2192 toolexec/run\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#key-interfaces","title":"Key Interfaces","text":"<pre><code>package run\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Runner executes tools.\ntype Runner interface {\n    // Run executes a single tool.\n    Run(ctx context.Context, req Request) (*Result, error)\n\n    // RunChain executes a sequence of tools.\n    RunChain(ctx context.Context, chain Chain) ([]Result, error)\n\n    // RunStream executes a tool with streaming output.\n    RunStream(ctx context.Context, req Request) (Stream, error)\n}\n\n// Request represents an execution request.\ntype Request struct {\n    ToolID   string\n    Tool     *model.Tool // Optional: provide tool directly\n    Input    map[string]any\n    Options  Options\n    Metadata map[string]any\n}\n\n// Result represents an execution result.\ntype Result struct {\n    ToolID   string\n    Output   any\n    Error    *Error\n    Metrics  Metrics\n    Metadata map[string]any\n}\n\n// Chain represents a sequence of tool executions.\ntype Chain struct {\n    ID    string\n    Steps []ChainStep\n}\n\n// ChainStep represents a step in a chain.\ntype ChainStep struct {\n    ToolID       string\n    Input        map[string]any\n    InputMapping map[string]string // JSONPath mappings\n}\n\n// Backend executes tools in a specific environment.\ntype Backend interface {\n    Execute(ctx context.Context, tool model.Tool, input map[string]any) (any, error)\n    Name() string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] 6-step pipeline works</li> <li>[ ] Chain execution works</li> <li>[ ] Streaming works</li> <li>[ ] Package documentation updated</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolexec/run</code> package builds successfully</li> <li>All tests pass</li> <li>Single tool execution works</li> <li>Chain execution produces correct results</li> <li>Multiple backends supported</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#completion-notes","title":"Completion Notes","text":"<ul> <li>Migration completed into <code>toolexec/run</code> with tests and <code>doc.go</code>.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> <li>Runner uses option-based configuration (<code>NewRunner(WithIndex(...), WithBackends(...))</code>).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolexec\nrm -rf run/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-140-migrate-toolrun/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-141: Migrate toolruntime</li> <li>PRD-142: Migrate toolcode</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/","title":"PRD-141: Migrate toolruntime","text":"<p>Phase: 4 - Execution Layer Priority: Critical Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolruntime</code> repository into <code>toolexec/runtime/</code> as the second package in the consolidated execution layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolruntime</code> Target Location: <code>github.com/jonwraymond/toolexec/runtime</code></p> <p>Package Contents: - Runtime abstraction for tool execution - 10 sandbox backends (unsafe, docker, containerd, kubernetes, firecracker, kata, gvisor, wasm, temporal, remote) - 3 security profiles (dev, standard, hardened) - Error handling with structured errors - ~8,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#deliverables","title":"Deliverables","text":"Deliverable Location Description Runtime Package <code>toolexec/runtime/</code> Runtime abstraction Backend Implementations <code>toolexec/runtime/backend/</code> Sandbox backends Tests <code>toolexec/runtime/*_test.go</code> All existing tests Documentation <code>toolexec/runtime/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#task-1-clone-and-analyze-source","title":"Task 1: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolruntime.git\ncd toolruntime\n\nls -la\nfind . -name \"*.go\" | wc -l\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#task-2-copy-source-files-preserving-structure","title":"Task 2: Copy Source Files (Preserving Structure)","text":"<pre><code>cd /tmp/migration/toolexec\n\n# Create directories\nmkdir -p runtime/backend\n\n# Copy root package files\ncp ../toolruntime/*.go runtime/\n\n# Copy backend subdirectory\ncp -r ../toolruntime/backend/* runtime/backend/\n\nls -la runtime/\nls -la runtime/backend/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#task-3-update-import-paths","title":"Task 3: Update Import Paths","text":"<pre><code>cd /tmp/migration/toolexec\n\n# Update all Go files recursively\nfind runtime -name \"*.go\" -exec sed -i '' 's|github.com/jonwraymond/toolruntime|github.com/jonwraymond/toolexec/runtime|g' {} \\;\n\n# Update toolmodel references\nfind runtime -name \"*.go\" -exec sed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' {} \\;\n\n# Verify\ngrep -r \"jonwraymond/toolruntime\\|jonwraymond/toolmodel\" runtime/ || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#task-4-update-package-documentation","title":"Task 4: Update Package Documentation","text":"<p>File: <code>toolexec/runtime/doc.go</code></p> <pre><code>// Package runtime provides sandboxed execution environments for tools.\n//\n// This package implements a runtime abstraction that enables tool execution\n// in various isolated environments, from no isolation (development) to\n// strict container-based isolation (production).\n//\n// # Backends\n//\n// The package supports 10 execution backends:\n//\n//   - unsafe: No isolation (development only)\n//   - docker: Docker container isolation\n//   - containerd: containerd-based containers\n//   - kubernetes: Kubernetes pod execution\n//   - firecracker: MicroVM isolation\n//   - kata: Kata Containers\n//   - gvisor: gVisor sandbox\n//   - wasm: WebAssembly sandbox\n//   - temporal: Temporal workflow execution\n//   - remote: Remote execution via HTTP/gRPC\n//\n// # Security Profiles\n//\n// Three security profiles control isolation level:\n//\n//   - SecurityNone: No isolation (unsafe backend)\n//   - SecurityBasic: Container isolation with defaults\n//   - SecurityStrict: Hardened isolation with restricted capabilities\n//\n// # Usage\n//\n// Create a runtime with a specific backend:\n//\n//  rt, err := runtime.New(runtime.Config{\n//      Backend:  \"docker\",\n//      Security: runtime.SecurityBasic,\n//      Timeout:  30 * time.Second,\n//  })\n//\n//  result, err := rt.Execute(ctx, runtime.Task{\n//      Tool:  tool,\n//      Input: input,\n//  })\n//\n// # Resource Limits\n//\n// Configure resource limits for execution:\n//\n//  rt, _ := runtime.New(runtime.Config{\n//      Backend: \"docker\",\n//      Resources: runtime.Resources{\n//          Memory:    \"256Mi\",\n//          CPU:       \"0.5\",\n//          Timeout:   \"30s\",\n//          DiskSpace: \"100Mi\",\n//      },\n//  })\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolruntime as part of\n// the ApertureStack consolidation.\npackage runtime\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#task-5-backend-build-tags-optional","title":"Task 5: Backend Build Tags (Optional)","text":"<p>Backends are configured at runtime; no build tags are required. If tags are introduced later, document them alongside the backend matrix.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#task-6-update-gomod-dependencies","title":"Task 6: Update go.mod Dependencies","text":"<pre><code>cd /tmp/migration/toolexec\n\n# The runtime package may have significant dependencies\ncat go.mod\n\n# Add required dependencies\ngo get github.com/docker/docker/client\ngo get k8s.io/client-go@latest\n\ngo mod tidy\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#task-7-build-and-test","title":"Task 7: Build and Test","text":"<pre><code>cd /tmp/migration/toolexec\n\n# Build all (without optional backends)\ngo build ./...\n\n# Build with docker backend\ngo build -tags=docker ./...\n\n# Test\ngo test -v -coverprofile=runtime_coverage.out ./runtime/...\ngo tool cover -func=runtime_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd /tmp/migration/toolexec\n\ngit add -A\ngit commit -m \"feat(runtime): migrate toolruntime package\n\nMigrate the sandbox runtime from standalone toolruntime repository.\n\nPackage contents:\n- Runtime interface for sandboxed execution\n- 10 backend implementations\n- 3 security profiles (none, basic, strict)\n- Resource limit configuration\n- Structured error handling\n\nBackends (via build tags):\n- unsafe: always included\n- docker: -tags=docker\n- containerd: -tags=containerd\n- kubernetes: -tags=kubernetes\n- firecracker: -tags=firecracker\n- kata: -tags=kata\n- gvisor: -tags=gvisor\n- wasm: -tags=wasm\n- temporal: -tags=temporal\n- remote: always included\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n- Various backend-specific dependencies\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolruntime \u2192 toolexec/runtime\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#key-interfaces","title":"Key Interfaces","text":"<pre><code>package runtime\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Runtime executes tools in isolated environments.\ntype Runtime interface {\n    // Execute runs a tool in the sandbox.\n    Execute(ctx context.Context, task Task) (*Result, error)\n\n    // Close releases runtime resources.\n    Close() error\n\n    // Backend returns the backend name.\n    Backend() string\n\n    // Security returns the security profile.\n    Security() SecurityProfile\n}\n\n// Task represents an execution task.\ntype Task struct {\n    Tool      model.Tool\n    Input     map[string]any\n    Env       map[string]string\n    Resources *Resources\n}\n\n// Result represents an execution result.\ntype Result struct {\n    Output   any\n    ExitCode int\n    Stdout   string\n    Stderr   string\n    Duration time.Duration\n}\n\n// Config configures the runtime.\ntype Config struct {\n    Backend   string\n    Security  SecurityProfile\n    Timeout   time.Duration\n    Resources *Resources\n}\n\n// SecurityProfile defines isolation level.\ntype SecurityProfile int\n\nconst (\n    SecurityNone SecurityProfile = iota\n    SecurityBasic\n    SecurityStrict\n)\n\n// Resources defines execution resource limits.\ntype Resources struct {\n    Memory    string // e.g., \"256Mi\"\n    CPU       string // e.g., \"0.5\"\n    Timeout   string // e.g., \"30s\"\n    DiskSpace string // e.g., \"100Mi\"\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied (including backend/)</li> <li>[ ] Import paths updated</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Security profiles work</li> <li>[ ] Package documentation updated</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolexec/runtime</code> package builds successfully</li> <li>All tests pass</li> <li>Unsafe backend works without extra dependencies</li> <li>Docker backend works when configured with a container runner</li> <li>Security profiles enforce appropriate isolation</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#completion-notes","title":"Completion Notes","text":"<ul> <li>Migration completed into <code>toolexec/runtime</code> with <code>runtime/backend/*</code>.</li> <li>Security profiles are <code>ProfileDev</code>, <code>ProfileStandard</code>, <code>ProfileHardened</code>.</li> <li>No build tags are required; backend selection is runtime-configured.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolexec\nrm -rf runtime/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-141-migrate-toolruntime/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-142: Migrate toolcode</li> <li>PRD-143: Extract toolbackend</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/","title":"PRD-142: Migrate toolcode","text":"<p>Phase: 4 - Execution Layer Priority: High Effort: 4 hours Dependencies: PRD-140 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolcode</code> repository into <code>toolexec/code/</code> as the third package in the consolidated execution layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolcode</code> Target Location: <code>github.com/jonwraymond/toolexec/code</code></p> <p>Package Contents: - Code-based tool orchestration - Dynamic tool generation from code - TypeScript/JavaScript execution integration - Tool chain composition via code - ~2,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#deliverables","title":"Deliverables","text":"Deliverable Location Description Code Package <code>toolexec/code/</code> Code orchestration Tests <code>toolexec/code/*_test.go</code> All existing tests Documentation <code>toolexec/code/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#task-1-clone-and-analyze-source","title":"Task 1: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolcode.git\ncd toolcode\n\nls -la\nwc -l *.go\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#task-2-copy-source-files","title":"Task 2: Copy Source Files","text":"<pre><code>cd /tmp/migration/toolexec\n\nmkdir -p code\ncp ../toolcode/*.go code/\n\nls -la code/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#task-3-update-import-paths","title":"Task 3: Update Import Paths","text":"<pre><code>cd /tmp/migration/toolexec/code\n\n# Update self-reference\nOLD_IMPORT=\"github.com/jonwraymond/toolcode\"\nNEW_IMPORT=\"github.com/jonwraymond/toolexec/code\"\n\nfor file in *.go; do\n  sed -i '' \"s|$OLD_IMPORT|$NEW_IMPORT|g\" \"$file\"\ndone\n\n# Update toolmodel to toolfoundation/model\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n\n# Update toolrun to toolexec/run\nsed -i '' 's|github.com/jonwraymond/toolrun|github.com/jonwraymond/toolexec/run|g' *.go\n\n# Verify\ngrep -r \"jonwraymond/toolcode\\|jonwraymond/toolmodel\\|jonwraymond/toolrun\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#task-4-update-package-documentation","title":"Task 4: Update Package Documentation","text":"<p>File: <code>toolexec/code/doc.go</code></p> <pre><code>// Package code provides code-based tool orchestration for the ApertureStack ecosystem.\n//\n// This package enables developers to define tool workflows using code, supporting\n// dynamic tool generation, conditional execution, and complex orchestration patterns.\n//\n// # Overview\n//\n// While toolexec/run handles individual tool execution and chains, the code package\n// provides a higher-level abstraction for code-driven orchestration:\n//\n//   - Dynamic tool generation from runtime data\n//   - Conditional branching based on execution results\n//   - Parallel execution with result aggregation\n//   - Error handling and retry logic\n//\n// # Usage\n//\n// Create a code orchestrator:\n//\n//  orchestrator := code.NewOrchestrator(code.Config{\n//      Runner: runner,\n//      Logger: logger,\n//  })\n//\n// Define and execute a workflow:\n//\n//  workflow := code.Workflow{\n//      Name: \"data-pipeline\",\n//      Steps: []code.Step{\n//          {Tool: \"fetch\", Input: fetchInput},\n//          {Tool: \"transform\", DependsOn: []string{\"fetch\"}},\n//          {Tool: \"store\", DependsOn: []string{\"transform\"}},\n//      },\n//  }\n//\n//  results, err := orchestrator.Execute(ctx, workflow)\n//\n// # TypeScript Integration\n//\n// For TypeScript-based orchestration, see the toolcodeengine companion:\n//\n//  engine := codeengine.New(codeengine.Config{\n//      Orchestrator: orchestrator,\n//      Runtime:      \"deno\",\n//  })\n//\n//  result, err := engine.Execute(ctx, `\n//      const data = await tools.fetch({url: \"...\"});\n//      return tools.transform({data});\n//  `)\n//\n// # Parallel Execution\n//\n// Execute multiple tools in parallel:\n//\n//  parallel := code.Parallel{\n//      Steps: []code.Step{\n//          {Tool: \"api-a\", Input: inputA},\n//          {Tool: \"api-b\", Input: inputB},\n//          {Tool: \"api-c\", Input: inputC},\n//      },\n//  }\n//\n//  results, err := orchestrator.ExecuteParallel(ctx, parallel)\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolcode as part of\n// the ApertureStack consolidation.\npackage code\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#task-5-verify-internal-dependencies","title":"Task 5: Verify Internal Dependencies","text":"<pre><code>cd /tmp/migration/toolexec\n\n# The code package depends on run package\ngrep -h \"import\" code/*.go | sort -u\n\n# Should include:\n# \"github.com/jonwraymond/toolexec/run\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/toolexec\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=code_coverage.out ./code/...\n\ngo tool cover -func=code_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/toolexec\n\ngit add -A\ngit commit -m \"feat(code): migrate toolcode package\n\nMigrate code-based orchestration from standalone toolcode repository.\n\nPackage contents:\n- Orchestrator for code-driven workflows\n- Step-based workflow definition\n- Parallel execution support\n- Conditional branching\n- Result aggregation\n\nFeatures:\n- Dynamic tool generation\n- Dependency-based execution order\n- Error handling and retries\n- TypeScript/JavaScript integration (via codeengine)\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n- github.com/jonwraymond/toolexec/run\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolcode \u2192 toolexec/code\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#key-interfaces","title":"Key Interfaces","text":"<pre><code>package code\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolexec/run\"\n)\n\n// Orchestrator manages code-based tool workflows.\ntype Orchestrator interface {\n    // Execute runs a workflow.\n    Execute(ctx context.Context, workflow Workflow) ([]run.Result, error)\n\n    // ExecuteParallel runs steps in parallel.\n    ExecuteParallel(ctx context.Context, parallel Parallel) ([]run.Result, error)\n\n    // ExecuteConditional runs steps conditionally.\n    ExecuteConditional(ctx context.Context, cond Conditional) (*run.Result, error)\n}\n\n// Workflow represents a sequence of steps.\ntype Workflow struct {\n    Name  string\n    Steps []Step\n}\n\n// Step represents a workflow step.\ntype Step struct {\n    ID        string\n    Tool      string\n    Input     map[string]any\n    DependsOn []string\n    Condition string // Expression for conditional execution\n    Retry     *RetryConfig\n}\n\n// Parallel represents parallel execution.\ntype Parallel struct {\n    Steps   []Step\n    MaxWorkers int\n}\n\n// Conditional represents conditional execution.\ntype Conditional struct {\n    Condition string\n    IfTrue    Step\n    IfFalse   *Step\n}\n\n// Config configures the orchestrator.\ntype Config struct {\n    Runner run.Runner\n    Logger Logger\n    MaxParallel int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated</li> <li>[ ] Dependency on toolexec/run works</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Workflow execution works</li> <li>[ ] Parallel execution works</li> <li>[ ] Package documentation updated</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolexec/code</code> package builds successfully</li> <li>All tests pass</li> <li>Workflow execution produces correct results</li> <li>Parallel execution respects MaxWorkers</li> <li>Conditional execution works</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#completion-notes","title":"Completion Notes","text":"<ul> <li>Migration completed into <code>toolexec/code</code> with docs and tests.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code> and <code>toolexec/run</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolexec\nrm -rf code/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-142-migrate-toolcode/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-143: Extract toolbackend</li> <li>Gate G3: Execution layer complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/","title":"PRD-143: Extract toolbackend","text":"<p>Phase: 4 - Execution Layer Priority: High Effort: 6 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#objective","title":"Objective","text":"<p>Extract backend management code from <code>metatools-mcp</code> into <code>toolexec/backend/</code> as the fourth package in the consolidated execution layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>toolexec/backend/</code> (extracted from MCP server) Target Location: <code>github.com/jonwraymond/toolexec/backend</code></p> <p>Code to Extract: - Backend registry and management - Provider interface for tool backends - Multi-backend aggregation - Backend health checking - ~600 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#deliverables","title":"Deliverables","text":"Deliverable Location Description Backend Package <code>toolexec/backend/</code> Backend management Tests <code>toolexec/backend/*_test.go</code> Comprehensive tests Documentation <code>toolexec/backend/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#task-1-analyze-source-code","title":"Task 1: Analyze Source Code","text":"<pre><code>cd /Users/jraymond/Documents/Projects/ApertureStack/metatools-mcp\n\n# Find backend-related code\nfind . -name \"*.go\" -exec grep -l \"Backend\\|Provider\" {} \\;\n\n# Count lines in relevant files\nwc -l ../toolexec/backend/*.go 2&gt;/dev/null || echo \"Check actual path\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#task-2-create-package-structure","title":"Task 2: Create Package Structure","text":"<pre><code>cd /tmp/migration/toolexec\n\nmkdir -p backend\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#task-3-define-core-interfaces","title":"Task 3: Define Core Interfaces","text":"<p>File: <code>toolexec/backend/backend.go</code></p> <pre><code>package backend\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Backend represents a tool execution backend.\ntype Backend interface {\n    // Name returns the backend identifier.\n    Name() string\n\n    // Type returns the backend type (local, mcp, http, grpc).\n    Type() string\n\n    // ListTools returns available tools from this backend.\n    ListTools(ctx context.Context) ([]model.Tool, error)\n\n    // GetTool retrieves a specific tool by ID.\n    GetTool(ctx context.Context, id string) (*model.Tool, error)\n\n    // Execute runs a tool with the given input.\n    Execute(ctx context.Context, toolID string, input map[string]any) (any, error)\n\n    // Health returns the backend health status.\n    Health(ctx context.Context) (*HealthStatus, error)\n\n    // Close releases backend resources.\n    Close() error\n}\n\n// HealthStatus represents backend health.\ntype HealthStatus struct {\n    Healthy     bool\n    Message     string\n    LastChecked time.Time\n    Latency     time.Duration\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#task-4-implement-registry","title":"Task 4: Implement Registry","text":"<p>File: <code>toolexec/backend/registry.go</code></p> <pre><code>package backend\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Registry manages multiple backends.\ntype Registry struct {\n    backends map[string]Backend\n    mu       sync.RWMutex\n}\n\n// NewRegistry creates a new backend registry.\nfunc NewRegistry() *Registry {\n    return &amp;Registry{\n        backends: make(map[string]Backend),\n    }\n}\n\n// Register adds a backend to the registry.\nfunc (r *Registry) Register(backend Backend) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    name := backend.Name()\n    if _, exists := r.backends[name]; exists {\n        return fmt.Errorf(\"backend %q already registered\", name)\n    }\n    r.backends[name] = backend\n    return nil\n}\n\n// Unregister removes a backend from the registry.\nfunc (r *Registry) Unregister(name string) error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    backend, exists := r.backends[name]\n    if !exists {\n        return fmt.Errorf(\"backend %q not found\", name)\n    }\n\n    if err := backend.Close(); err != nil {\n        return fmt.Errorf(\"closing backend %q: %w\", name, err)\n    }\n\n    delete(r.backends, name)\n    return nil\n}\n\n// Get retrieves a backend by name.\nfunc (r *Registry) Get(name string) (Backend, bool) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n    b, ok := r.backends[name]\n    return b, ok\n}\n\n// List returns all registered backend names.\nfunc (r *Registry) List() []string {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    names := make([]string, 0, len(r.backends))\n    for name := range r.backends {\n        names = append(names, name)\n    }\n    return names\n}\n\n// ListAllTools aggregates tools from all backends.\nfunc (r *Registry) ListAllTools(ctx context.Context) ([]model.Tool, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    var allTools []model.Tool\n    for _, backend := range r.backends {\n        tools, err := backend.ListTools(ctx)\n        if err != nil {\n            continue // Skip failing backends\n        }\n        allTools = append(allTools, tools...)\n    }\n    return allTools, nil\n}\n\n// FindTool searches all backends for a tool.\nfunc (r *Registry) FindTool(ctx context.Context, toolID string) (*model.Tool, Backend, error) {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    for _, backend := range r.backends {\n        tool, err := backend.GetTool(ctx, toolID)\n        if err == nil &amp;&amp; tool != nil {\n            return tool, backend, nil\n        }\n    }\n    return nil, nil, fmt.Errorf(\"tool %q not found in any backend\", toolID)\n}\n\n// HealthCheck returns health status for all backends.\nfunc (r *Registry) HealthCheck(ctx context.Context) map[string]*HealthStatus {\n    r.mu.RLock()\n    defer r.mu.RUnlock()\n\n    results := make(map[string]*HealthStatus)\n    for name, backend := range r.backends {\n        status, err := backend.Health(ctx)\n        if err != nil {\n            results[name] = &amp;HealthStatus{\n                Healthy: false,\n                Message: err.Error(),\n            }\n        } else {\n            results[name] = status\n        }\n    }\n    return results\n}\n\n// Close closes all backends.\nfunc (r *Registry) Close() error {\n    r.mu.Lock()\n    defer r.mu.Unlock()\n\n    var errs []error\n    for name, backend := range r.backends {\n        if err := backend.Close(); err != nil {\n            errs = append(errs, fmt.Errorf(\"closing %s: %w\", name, err))\n        }\n    }\n    r.backends = make(map[string]Backend)\n\n    if len(errs) &gt; 0 {\n        return fmt.Errorf(\"errors closing backends: %v\", errs)\n    }\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#task-5-implement-local-backend","title":"Task 5: Implement Local Backend","text":"<p>File: <code>toolexec/backend/local.go</code></p> <pre><code>package backend\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n    \"time\"\n\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// LocalBackend provides in-process tool execution.\ntype LocalBackend struct {\n    name     string\n    tools    map[string]model.Tool\n    handlers map[string]Handler\n    mu       sync.RWMutex\n}\n\n// Handler executes a tool.\ntype Handler func(ctx context.Context, input map[string]any) (any, error)\n\n// NewLocalBackend creates a new local backend.\nfunc NewLocalBackend(name string) *LocalBackend {\n    return &amp;LocalBackend{\n        name:     name,\n        tools:    make(map[string]model.Tool),\n        handlers: make(map[string]Handler),\n    }\n}\n\nfunc (b *LocalBackend) Name() string { return b.name }\nfunc (b *LocalBackend) Type() string { return \"local\" }\n\n// RegisterTool adds a tool with its handler.\nfunc (b *LocalBackend) RegisterTool(tool model.Tool, handler Handler) error {\n    b.mu.Lock()\n    defer b.mu.Unlock()\n\n    if _, exists := b.tools[tool.ID]; exists {\n        return fmt.Errorf(\"tool %q already registered\", tool.ID)\n    }\n    b.tools[tool.ID] = tool\n    b.handlers[tool.ID] = handler\n    return nil\n}\n\nfunc (b *LocalBackend) ListTools(ctx context.Context) ([]model.Tool, error) {\n    b.mu.RLock()\n    defer b.mu.RUnlock()\n\n    tools := make([]model.Tool, 0, len(b.tools))\n    for _, tool := range b.tools {\n        tools = append(tools, tool)\n    }\n    return tools, nil\n}\n\nfunc (b *LocalBackend) GetTool(ctx context.Context, id string) (*model.Tool, error) {\n    b.mu.RLock()\n    defer b.mu.RUnlock()\n\n    tool, ok := b.tools[id]\n    if !ok {\n        return nil, fmt.Errorf(\"tool %q not found\", id)\n    }\n    return &amp;tool, nil\n}\n\nfunc (b *LocalBackend) Execute(ctx context.Context, toolID string, input map[string]any) (any, error) {\n    b.mu.RLock()\n    handler, ok := b.handlers[toolID]\n    b.mu.RUnlock()\n\n    if !ok {\n        return nil, fmt.Errorf(\"tool %q not found\", toolID)\n    }\n\n    return handler(ctx, input)\n}\n\nfunc (b *LocalBackend) Health(ctx context.Context) (*HealthStatus, error) {\n    return &amp;HealthStatus{\n        Healthy:     true,\n        Message:     \"local backend healthy\",\n        LastChecked: time.Now(),\n        Latency:     0,\n    }, nil\n}\n\nfunc (b *LocalBackend) Close() error {\n    return nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#task-6-create-package-documentation","title":"Task 6: Create Package Documentation","text":"<p>File: <code>toolexec/backend/doc.go</code></p> <pre><code>// Package backend provides backend management for tool execution.\n//\n// This package implements the registry pattern for managing multiple tool\n// execution backends. It supports local, MCP, HTTP, and gRPC backends with\n// unified discovery and execution APIs.\n//\n// # Registry\n//\n// The Registry aggregates multiple backends:\n//\n//  registry := backend.NewRegistry()\n//  registry.Register(localBackend)\n//  registry.Register(mcpBackend)\n//  registry.Register(httpBackend)\n//\n//  // List tools from all backends\n//  tools, _ := registry.ListAllTools(ctx)\n//\n//  // Find and execute a tool\n//  tool, backend, _ := registry.FindTool(ctx, \"calculator\")\n//  result, _ := backend.Execute(ctx, tool.ID, input)\n//\n// # Backend Types\n//\n// Built-in backend implementations:\n//\n//   - LocalBackend: In-process tool execution\n//   - MCPBackend: MCP server tool provider\n//   - HTTPBackend: HTTP API tool provider\n//   - GRPCBackend: gRPC tool provider\n//\n// # Health Checking\n//\n// Monitor backend health:\n//\n//  status := registry.HealthCheck(ctx)\n//  for name, health := range status {\n//      fmt.Printf(\"%s: healthy=%v latency=%v\\n\",\n//          name, health.Healthy, health.Latency)\n//  }\n//\n// # Custom Backends\n//\n// Implement the Backend interface for custom backends:\n//\n//  type MyBackend struct {}\n//  func (b *MyBackend) Name() string { return \"my-backend\" }\n//  func (b *MyBackend) Type() string { return \"custom\" }\n//  func (b *MyBackend) ListTools(ctx context.Context) ([]model.Tool, error) { ... }\n//  func (b *MyBackend) Execute(ctx context.Context, toolID string, input map[string]any) (any, error) { ... }\n//\n// # Extraction Note\n//\n// This package was extracted from metatools-mcp/internal/backend as part of\n// the ApertureStack consolidation to enable reuse across projects.\npackage backend\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#task-7-create-tests","title":"Task 7: Create Tests","text":"<p>File: <code>toolexec/backend/backend_test.go</code></p> <pre><code>package backend\n\nimport (\n    \"context\"\n    \"testing\"\n\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\nfunc TestRegistry(t *testing.T) {\n    ctx := context.Background()\n    registry := NewRegistry()\n\n    // Create local backend with a tool\n    local := NewLocalBackend(\"local\")\n    local.RegisterTool(\n        model.Tool{ID: \"test\", Name: \"Test Tool\"},\n        func(ctx context.Context, input map[string]any) (any, error) {\n            return \"success\", nil\n        },\n    )\n\n    // Register\n    if err := registry.Register(local); err != nil {\n        t.Fatal(err)\n    }\n\n    // List\n    names := registry.List()\n    if len(names) != 1 || names[0] != \"local\" {\n        t.Errorf(\"expected [local], got %v\", names)\n    }\n\n    // Get\n    b, ok := registry.Get(\"local\")\n    if !ok || b.Name() != \"local\" {\n        t.Error(\"failed to get backend\")\n    }\n\n    // Find tool\n    tool, backend, err := registry.FindTool(ctx, \"test\")\n    if err != nil {\n        t.Fatal(err)\n    }\n    if tool.ID != \"test\" || backend.Name() != \"local\" {\n        t.Error(\"wrong tool or backend\")\n    }\n\n    // Execute\n    result, err := backend.Execute(ctx, \"test\", nil)\n    if err != nil {\n        t.Fatal(err)\n    }\n    if result != \"success\" {\n        t.Errorf(\"expected 'success', got %v\", result)\n    }\n}\n\nfunc TestLocalBackend(t *testing.T) {\n    ctx := context.Background()\n    backend := NewLocalBackend(\"test\")\n\n    // Register tool\n    tool := model.Tool{ID: \"calc\", Name: \"Calculator\"}\n    handler := func(ctx context.Context, input map[string]any) (any, error) {\n        a := input[\"a\"].(float64)\n        b := input[\"b\"].(float64)\n        return a + b, nil\n    }\n\n    if err := backend.RegisterTool(tool, handler); err != nil {\n        t.Fatal(err)\n    }\n\n    // List tools\n    tools, err := backend.ListTools(ctx)\n    if err != nil {\n        t.Fatal(err)\n    }\n    if len(tools) != 1 {\n        t.Errorf(\"expected 1 tool, got %d\", len(tools))\n    }\n\n    // Execute\n    result, err := backend.Execute(ctx, \"calc\", map[string]any{\"a\": 1.0, \"b\": 2.0})\n    if err != nil {\n        t.Fatal(err)\n    }\n    if result != 3.0 {\n        t.Errorf(\"expected 3.0, got %v\", result)\n    }\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#task-8-build-and-test","title":"Task 8: Build and Test","text":"<pre><code>cd /tmp/migration/toolexec\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=backend_coverage.out ./backend/...\n\ngo tool cover -func=backend_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#task-9-commit-and-push","title":"Task 9: Commit and Push","text":"<pre><code>cd /tmp/migration/toolexec\n\ngit add -A\ngit commit -m \"feat(backend): extract backend management package\n\nExtract backend registry and management from metatools-mcp.\n\nPackage contents:\n- Backend interface for tool providers\n- Registry for multi-backend management\n- LocalBackend for in-process execution\n- Health checking for all backends\n- Tool aggregation across backends\n\nFeatures:\n- Register/unregister backends dynamically\n- Find tools across all backends\n- Execute tools via appropriate backend\n- Health monitoring with latency tracking\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n\nThis extraction enables backend reuse across projects.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Backend interface defined</li> <li>[ ] Registry implemented</li> <li>[ ] LocalBackend implemented</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Health checking works</li> <li>[ ] Tool aggregation works</li> <li>[ ] Package documentation complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolexec/backend</code> package builds successfully</li> <li>All tests pass with &gt;= 80% coverage</li> <li>Registry manages multiple backends</li> <li>Tools can be found across backends</li> <li>Health status is accurate</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#completion-notes","title":"Completion Notes","text":"<ul> <li>Backend package extracted into <code>toolexec/backend</code> with registry, aggregator, and local backend.</li> <li>Contracts documented in <code>backend.go</code> and validated by tests.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolexec\nrm -rf backend/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-143-extract-toolbackend/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G3: Execution layer complete (all 4 packages)</li> <li>PRD-150: Migrate toolset</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-144-toolexec-docs-alignment/","title":"PRD-144: toolexec Docs + README Alignment","text":"<p>Phase: 4 - Execution Layer Priority: High Effort: 2 hours Dependencies: PRD-140\u2013143 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-144-toolexec-docs-alignment/#objective","title":"Objective","text":"<p>Align public-facing documentation with the consolidated <code>toolexec</code> API:</p> <ul> <li>Replace README placeholders.</li> <li>Ensure docs show correct package names and usage.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-144-toolexec-docs-alignment/#deliverables","title":"Deliverables","text":"Deliverable Location Description Updated README <code>toolexec/README.md</code> Package table + descriptions Updated docs <code>toolexec/docs/*</code> Accurate usage examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-144-toolexec-docs-alignment/#tasks","title":"Tasks","text":"<ol> <li>Update README package table (run/runtime/code/backend).</li> <li>Verify docs/index.md examples match current API.</li> <li>Update docs/user-journey.md runtime example to use <code>runtime.ExecuteRequest</code>.</li> <li>Update docs/design-notes.md with current runtime semantics.</li> <li>Run tests.</li> </ol> <pre><code>cd toolexec\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-144-toolexec-docs-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>README has no <code>TBD</code> entries.</li> <li>Docs reflect current package names and usage.</li> <li>Tests pass.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-144-toolexec-docs-alignment/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolexec/README.md</code> updated with final package list.</li> <li><code>toolexec/docs/user-journey.md</code> runtime example updated to <code>runtime.ExecuteRequest</code>.</li> <li><code>toolexec/docs/design-notes.md</code> updated with current runtime profile semantics.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-145-toolexec-runtime-security-profiles/","title":"PRD-145: toolexec Runtime Security Profiles Documentation","text":"<p>Phase: 4 - Execution Layer Priority: Medium Effort: 2 hours Dependencies: PRD-141 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-145-toolexec-runtime-security-profiles/#objective","title":"Objective","text":"<p>Document the runtime security profiles and their contract so consumers know which isolation guarantees they receive for each profile.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-145-toolexec-runtime-security-profiles/#deliverables","title":"Deliverables","text":"Deliverable Location Description Profile contract <code>toolexec/docs/design-notes.md</code> Profile definitions + usage guidance Runtime doc update <code>toolexec/runtime/doc.go</code> Package name + contract summary"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-145-toolexec-runtime-security-profiles/#tasks","title":"Tasks","text":"<ol> <li>Document <code>ProfileDev</code>, <code>ProfileStandard</code>, <code>ProfileHardened</code> semantics.</li> <li>Clarify Gateway requirement and limit enforcement expectations.</li> <li>Ensure package doc comment matches <code>package runtime</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-145-toolexec-runtime-security-profiles/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Profiles are described with intended isolation level.</li> <li>Gateway requirement is explicit.</li> <li>Package documentation is consistent with <code>package runtime</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-145-toolexec-runtime-security-profiles/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolexec/docs/design-notes.md</code> updated with profile definitions and Gateway requirement.</li> <li><code>toolexec/runtime/doc.go</code> comment updated to <code>Package runtime</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-146-toolexec-backend-matrix/","title":"PRD-146: toolexec Backend Matrix Documentation","text":"<p>Phase: 4 - Execution Layer Priority: Medium Effort: 2 hours Dependencies: PRD-141, PRD-143 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-146-toolexec-backend-matrix/#objective","title":"Objective","text":"<p>Provide a clear matrix of runtime backend kinds, isolation levels, and environment requirements so operators can choose appropriate backends.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-146-toolexec-backend-matrix/#deliverables","title":"Deliverables","text":"Deliverable Location Description Backend matrix <code>toolexec/docs/design-notes.md</code> Table of backend kinds + requirements"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-146-toolexec-backend-matrix/#tasks","title":"Tasks","text":"<ol> <li>List all runtime backend kinds in a single table.</li> <li>Capture isolation level and key requirements (Docker, containerd, k8s, etc.).</li> <li>Note dev-only and strongest-isolation options.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-146-toolexec-backend-matrix/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Backend kinds are enumerated.</li> <li>Requirements and isolation levels are documented.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-146-toolexec-backend-matrix/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolexec/docs/design-notes.md</code> includes a Runtime Backend Matrix table.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-147-toolexec-toolcode-runtime-contract/","title":"PRD-147: toolexec Toolcode \u2194 Runtime Contract","text":"<p>Phase: 4 - Execution Layer Priority: Medium Effort: 2 hours Dependencies: PRD-142, PRD-141 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-147-toolexec-toolcode-runtime-contract/#objective","title":"Objective","text":"<p>Document the contract between <code>code</code> orchestration and the runtime layer, including how <code>ExecuteParams</code> map to <code>runtime.ExecuteRequest</code> and how tool calls flow through the Gateway.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-147-toolexec-toolcode-runtime-contract/#deliverables","title":"Deliverables","text":"Deliverable Location Description Contract section <code>toolexec/docs/design-notes.md</code> Toolcode \u2194 Runtime mapping"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-147-toolexec-toolcode-runtime-contract/#tasks","title":"Tasks","text":"<ol> <li>Describe how <code>code</code> delegates to <code>runtime/toolcodeengine</code>.</li> <li>Document mapping of profile, limits, and Gateway injection.</li> <li>Note that the runtime enforces tool call limits and returns ToolCall records.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-147-toolexec-toolcode-runtime-contract/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Contract is documented in design notes.</li> <li>Mapping of parameters is explicit.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-147-toolexec-toolcode-runtime-contract/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolexec/docs/design-notes.md</code> includes Toolcode \u2194 Runtime Contract section.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-148-toolexec-release-propagation/","title":"PRD-148: toolexec Release + Propagation","text":"<p>Phase: 4 - Execution Layer Priority: High Effort: 1 hour Dependencies: PRD-140\u2013147 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-148-toolexec-release-propagation/#objective","title":"Objective","text":"<p>Tag and propagate the consolidated <code>toolexec</code> module into the stack version matrix.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-148-toolexec-release-propagation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Tag <code>v0.1.0</code> <code>toolexec</code> Go module release tag Version matrix <code>ai-tools-stack/VERSIONS.md</code> Already includes toolexec Dependency update <code>toolexec/go.mod</code> Use <code>tooldiscovery v0.1.0</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-148-toolexec-release-propagation/#tasks","title":"Tasks","text":"<ol> <li>Ensure <code>toolexec/go.mod</code> depends on <code>tooldiscovery v0.1.0</code>.</li> <li>Tag and push <code>v0.1.0</code> in <code>toolexec</code>.</li> <li>Verify <code>ai-tools-stack/VERSIONS.md</code> reflects <code>toolexec v0.1.0</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-148-toolexec-release-propagation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li><code>v0.1.0</code> tag exists in <code>toolexec</code>.</li> <li><code>toolexec/go.mod</code> uses <code>tooldiscovery v0.1.0</code>.</li> <li>Version matrix remains consistent.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-148-toolexec-release-propagation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolexec</code> tagged <code>v0.1.0</code> and pushed.</li> <li><code>toolexec/go.mod</code> updated to <code>tooldiscovery v0.1.0</code>.</li> <li><code>ai-tools-stack/VERSIONS.md</code> already lists <code>toolexec v0.1.0</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-149-toolexec-validation/","title":"PRD-149: toolexec Validation","text":"<p>Phase: 4 - Execution Layer Priority: High Effort: 1 hour Dependencies: PRD-140\u2013148 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-149-toolexec-validation/#objective","title":"Objective","text":"<p>Verify the toolexec layer is healthy, documented, and CI-ready.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-149-toolexec-validation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Test run <code>toolexec</code> <code>go test ./...</code> Lint run <code>toolexec</code> <code>golangci-lint run</code> Docs consistency <code>ai-tools-stack/docs/components/toolexec.md</code> Examples match API"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-149-toolexec-validation/#tasks","title":"Tasks","text":"<ol> <li>Run tests and lint in <code>toolexec</code>.</li> <li>Ensure component docs examples reflect actual API.</li> <li>Update gap tracking if needed.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-149-toolexec-validation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Tests and lint are clean.</li> <li>Docs examples align with API.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-149-toolexec-validation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>go test ./...</code> and <code>golangci-lint run</code> pass in <code>toolexec</code>.</li> <li><code>ai-tools-stack/docs/components/toolexec.md</code> updated to match runtime API.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/","title":"PRD-150: Migrate toolset","text":"<p>Phase: 5 - Composition Layer Priority: High Effort: 4 hours Dependencies: PRD-121, PRD-130 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolset</code> repository into <code>toolcompose/set/</code> as the first package in the consolidated composition layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolset</code> Target Location: <code>github.com/jonwraymond/toolcompose/set</code></p> <p>Package Contents: - Tool collection management - Toolset composition and filtering - Namespace-based organization - Permission scoping - ~1,500 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#deliverables","title":"Deliverables","text":"Deliverable Location Description Set Package <code>toolcompose/set/</code> Toolset management Tests <code>toolcompose/set/*_test.go</code> All existing tests Documentation <code>toolcompose/set/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#task-1-prepare-target-repository","title":"Task 1: Prepare Target Repository","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolcompose.git\ncd toolcompose\n\nmkdir -p set\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#task-2-clone-and-analyze-source","title":"Task 2: Clone and Analyze Source","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolset.git\ncd toolset\n\nls -la\nwc -l *.go\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#task-3-copy-source-files","title":"Task 3: Copy Source Files","text":"<pre><code>cd /tmp/migration\n\ncp toolset/*.go toolcompose/set/\nls -la toolcompose/set/\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#task-4-update-import-paths","title":"Task 4: Update Import Paths","text":"<pre><code>cd /tmp/migration/toolcompose/set\n\n# Update self-reference\nsed -i '' 's|github.com/jonwraymond/toolset|github.com/jonwraymond/toolcompose/set|g' *.go\n\n# Update dependencies\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\nsed -i '' 's|github.com/jonwraymond/tooladapter|github.com/jonwraymond/toolfoundation/adapter|g' *.go\nsed -i '' 's|github.com/jonwraymond/toolindex|github.com/jonwraymond/tooldiscovery/index|g' *.go\n\n# Verify\ngrep -r \"jonwraymond/toolset\\|jonwraymond/toolmodel\\|jonwraymond/toolindex\" . || echo \"\u2713 All imports updated\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#task-5-update-package-documentation","title":"Task 5: Update Package Documentation","text":"<p>File: <code>toolcompose/set/doc.go</code></p> <pre><code>// Package set provides toolset composition and management.\n//\n// This package enables creating, managing, and filtering collections of tools.\n// Toolsets provide a higher-level abstraction over individual tools, supporting\n// namespace-based organization and permission scoping.\n//\n// # Overview\n//\n// A Toolset is a named collection of tools with shared configuration:\n//\n//   - Grouping related tools together\n//   - Applying common settings (timeout, retries)\n//   - Scoping permissions\n//   - Filtering by namespace or tags\n//\n// # Usage\n//\n// Create a toolset:\n//\n//  ts := set.New(set.Config{\n//      Name:      \"data-tools\",\n//      Namespace: \"data\",\n//  })\n//\n//  ts.Add(fetchTool)\n//  ts.Add(transformTool)\n//  ts.Add(storeTool)\n//\n// Filter tools:\n//\n//  filtered := ts.Filter(set.Filter{\n//      Tags:       []string{\"input\"},\n//      Namespace:  \"data\",\n//  })\n//\n// # Composition\n//\n// Combine multiple toolsets:\n//\n//  combined := set.Merge(dataTools, apiTools, utilityTools)\n//\n// Apply restrictions:\n//\n//  restricted := ts.WithPermissions(set.Permissions{\n//      AllowedTools: []string{\"fetch\", \"transform\"},\n//      DeniedTools:  []string{\"delete\"},\n//  })\n//\n// # Registry Integration\n//\n// Register toolsets with the index:\n//\n//  idx.RegisterSet(ctx, toolset)\n//  tools, _ := idx.ListBySet(ctx, \"data-tools\")\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolset as part of\n// the ApertureStack consolidation.\npackage set\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/toolcompose\n\ngo mod tidy\ngo build ./...\ngo test -v -coverprofile=set_coverage.out ./set/...\n\ngo tool cover -func=set_coverage.out | grep total\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/toolcompose\n\ngit add -A\ngit commit -m \"feat(set): migrate toolset package\n\nMigrate toolset composition from standalone toolset repository.\n\nPackage contents:\n- Toolset type for tool collections\n- Namespace-based organization\n- Tag-based filtering\n- Permission scoping\n- Toolset merging\n\nFeatures:\n- Add/remove tools from sets\n- Filter by namespace, tags, capabilities\n- Apply shared configuration\n- Restrict permissions per set\n- Merge multiple toolsets\n\nDependencies:\n- github.com/jonwraymond/toolfoundation/model\n- github.com/jonwraymond/tooldiscovery/index\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolset \u2192 toolcompose/set\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#key-interfaces","title":"Key Interfaces","text":"<pre><code>package set\n\nimport (\n    \"context\"\n    \"github.com/jonwraymond/toolfoundation/model\"\n)\n\n// Toolset represents a collection of tools.\ntype Toolset struct {\n    ID          string\n    Name        string\n    Description string\n    Namespace   string\n    Tools       []model.Tool\n    Config      Config\n    Permissions Permissions\n}\n\n// Config defines toolset configuration.\ntype Config struct {\n    Timeout     time.Duration\n    Retries     int\n    CachePolicy string\n    Metadata    map[string]any\n}\n\n// Permissions defines access restrictions.\ntype Permissions struct {\n    AllowedTools []string\n    DeniedTools  []string\n    Roles        []string\n}\n\n// Filter defines filtering criteria.\ntype Filter struct {\n    Namespace    string\n    Tags         []string\n    Capabilities []string\n    Pattern      string // Glob pattern for IDs\n}\n\n// New creates a new toolset.\nfunc New(cfg Config) *Toolset\n\n// Add adds a tool to the set.\nfunc (ts *Toolset) Add(tool model.Tool) error\n\n// Remove removes a tool from the set.\nfunc (ts *Toolset) Remove(toolID string) error\n\n// Filter returns tools matching the filter.\nfunc (ts *Toolset) Filter(f Filter) []model.Tool\n\n// WithPermissions returns a restricted copy.\nfunc (ts *Toolset) WithPermissions(p Permissions) *Toolset\n\n// Merge combines multiple toolsets.\nfunc Merge(sets ...*Toolset) *Toolset\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Toolset creation works</li> <li>[ ] Filtering works</li> <li>[ ] Permission scoping works</li> <li>[ ] Package documentation updated</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolcompose/set</code> package builds successfully</li> <li>All tests pass</li> <li>Toolsets can be created and populated</li> <li>Filtering produces correct results</li> <li>Merge combines tools correctly</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#completion-notes","title":"Completion Notes","text":"<ul> <li>Toolset migrated into <code>toolcompose/set</code> with builder, filters, policy, and exposure helpers.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolcompose\nrm -rf set/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-150-migrate-toolset/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-151: Complete toolskill</li> <li>Gate G4: Composition layer complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-151-complete-toolskill/","title":"PRD-151: Complete toolskill","text":"<p>Phase: 5 - Composition Layer Priority: High Effort: 8 hours Dependencies: PRD-150, PRD-140 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-151-complete-toolskill/#objective","title":"Objective","text":"<p>Migrate the partial <code>toolskill</code> implementation and complete it as <code>toolcompose/skill/</code> for agent skills management.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-151-complete-toolskill/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolskill</code> (partial implementation) Target Location: <code>github.com/jonwraymond/toolcompose/skill</code></p> <p>Current State: - Minimal declarative skill model (Skill/Step) implemented - Planner provides deterministic ordering - Guards + Execute flow exist via Runner interface</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-151-complete-toolskill/#deliverables","title":"Deliverables","text":"Deliverable Location Description Skill Package <code>toolcompose/skill/</code> Declarative skill model Planner <code>skill/planner.go</code> Deterministic plan generation Guards <code>skill/guard.go</code> Policy validation helpers Executor <code>skill/execute.go</code> Step execution via Runner Tests <code>skill/*_test.go</code> Contract + behavior tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-151-complete-toolskill/#tasks","title":"Tasks","text":"<ol> <li>Ensure <code>Skill</code>, <code>Step</code>, <code>Planner</code>, <code>Guard</code>, and <code>Execute</code> are implemented in <code>toolcompose/skill</code>.</li> <li>Validate deterministic planning (sorted by step ID).</li> <li>Provide guard helpers for max steps and allowed tool IDs.</li> <li>Ensure runner interface is documented and tested.</li> <li>Update docs/examples to reflect the minimal skill model.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-151-complete-toolskill/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Core interfaces defined</li> <li>[ ] Planner produces deterministic ordering</li> <li>[ ] Guard helpers enforce constraints</li> <li>[ ] Execute uses Runner</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Error handling works</li> <li>[ ] Package documentation complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-151-complete-toolskill/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li><code>toolcompose/skill</code> package builds successfully</li> <li>Skill + Step validation behaves correctly</li> <li>Planner produces deterministic ordering</li> <li>Execute uses Runner and returns StepResults</li> <li>Guards enforce max steps and allowed tool IDs</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-151-complete-toolskill/#completion-notes","title":"Completion Notes","text":"<ul> <li>Skill package provides <code>Skill</code>, <code>Step</code>, <code>Planner</code>, <code>Guard</code>, and <code>Execute</code> primitives.</li> <li>Runner integration is explicit to keep tool execution decoupled.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-151-complete-toolskill/#rollback-plan","title":"Rollback Plan","text":"<pre><code>cd /tmp/migration/toolcompose\nrm -rf skill/\ngit checkout HEAD~1 -- .\ngit push origin main --force-with-lease\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-151-complete-toolskill/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G4: Composition layer complete (both packages)</li> <li>PRD-160: Migrate toolobserve</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-152-toolcompose-docs-alignment/","title":"PRD-152: toolcompose Docs + README Alignment","text":"<p>Phase: 5 - Composition Layer Priority: High Effort: 2 hours Dependencies: PRD-150\u2013151 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-152-toolcompose-docs-alignment/#objective","title":"Objective","text":"<p>Align public-facing documentation with the consolidated <code>toolcompose</code> API.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-152-toolcompose-docs-alignment/#deliverables","title":"Deliverables","text":"Deliverable Location Description Updated README <code>toolcompose/README.md</code> Package table + descriptions Updated docs <code>toolcompose/docs/*</code> Accurate usage examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-152-toolcompose-docs-alignment/#tasks","title":"Tasks","text":"<ol> <li>Update README package table (<code>set</code>, <code>skill</code>).</li> <li>Populate <code>docs/index.md</code> with quick-start examples.</li> <li>Populate <code>docs/user-journey.md</code> with step-by-step workflow.</li> <li>Populate <code>docs/design-notes.md</code> with architecture decisions.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-152-toolcompose-docs-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>README has no <code>TBD</code> entries.</li> <li>Docs reflect current package names and usage.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-152-toolcompose-docs-alignment/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolcompose/README.md</code> updated.</li> <li><code>toolcompose/docs/index.md</code>, <code>user-journey.md</code>, <code>design-notes.md</code> populated with current API.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-153-toolcompose-set-policy-docs/","title":"PRD-153: toolcompose Set Filter + Policy Docs","text":"<p>Phase: 5 - Composition Layer Priority: Medium Effort: 2 hours Dependencies: PRD-150 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-153-toolcompose-set-policy-docs/#objective","title":"Objective","text":"<p>Document filter and policy semantics for <code>toolcompose/set</code> so callers understand how toolsets are filtered and access-controlled.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-153-toolcompose-set-policy-docs/#deliverables","title":"Deliverables","text":"Deliverable Location Description Filter/policy docs <code>toolcompose/docs/design-notes.md</code> Filter + policy ordering and semantics"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-153-toolcompose-set-policy-docs/#tasks","title":"Tasks","text":"<ol> <li>Document filter ordering and AND-composition.</li> <li>Document policy application order (after filters).</li> <li>Note determinism guarantees for Toolset listing.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-153-toolcompose-set-policy-docs/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Filter and policy semantics are documented.</li> <li>Deterministic ordering guarantees are explicit.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-153-toolcompose-set-policy-docs/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolcompose/docs/design-notes.md</code> includes filter + policy semantics.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-154-toolcompose-skill-contracts/","title":"PRD-154: toolcompose Skill Contracts","text":"<p>Phase: 5 - Composition Layer Priority: Medium Effort: 2 hours Dependencies: PRD-151 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-154-toolcompose-skill-contracts/#objective","title":"Objective","text":"<p>Document the skill contracts (validation, planning, guard, execution) so integrators understand the expected behavior.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-154-toolcompose-skill-contracts/#deliverables","title":"Deliverables","text":"Deliverable Location Description Skill contract docs <code>toolcompose/docs/design-notes.md</code> Planner/Guard/Runner semantics"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-154-toolcompose-skill-contracts/#tasks","title":"Tasks","text":"<ol> <li>Document deterministic planning (sorted by step ID).</li> <li>Document guard contracts and common helpers.</li> <li>Document runner execution contract and fail-fast behavior.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-154-toolcompose-skill-contracts/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Skill contracts are documented in design notes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-154-toolcompose-skill-contracts/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolcompose/docs/design-notes.md</code> includes skill planning + execution contracts.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-155-toolcompose-user-journey/","title":"PRD-155: toolcompose User Journey + Examples","text":"<p>Phase: 5 - Composition Layer Priority: Medium Effort: 2 hours Dependencies: PRD-150\u2013151 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-155-toolcompose-user-journey/#objective","title":"Objective","text":"<p>Provide a step-by-step user journey showing how to build toolsets and execute skills, including integration with <code>toolexec/run</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-155-toolcompose-user-journey/#deliverables","title":"Deliverables","text":"Deliverable Location Description User journey <code>toolcompose/docs/user-journey.md</code> End-to-end examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-155-toolcompose-user-journey/#tasks","title":"Tasks","text":"<ol> <li>Add toolset creation + filtering examples.</li> <li>Add skill planning + guard example.</li> <li>Add execution example using a toolexec runner adapter.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-155-toolcompose-user-journey/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>User journey contains working, API-accurate examples.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-155-toolcompose-user-journey/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolcompose/docs/user-journey.md</code> updated with toolset + skill flow.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-156-toolcompose-docs-site/","title":"PRD-156: toolcompose Docs Site Integration","text":"<p>Phase: 5 - Composition Layer Priority: Medium Effort: 1 hour Dependencies: PRD-152\u2013155 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-156-toolcompose-docs-site/#objective","title":"Objective","text":"<p>Ensure the ai-tools-stack component docs reflect the current toolcompose APIs.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-156-toolcompose-docs-site/#deliverables","title":"Deliverables","text":"Deliverable Location Description Component docs <code>ai-tools-stack/docs/components/toolcompose.md</code> Accurate API examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-156-toolcompose-docs-site/#tasks","title":"Tasks","text":"<ol> <li>Update <code>set</code> example to use builder/filter/policy APIs.</li> <li>Update <code>skill</code> example to use Planner + Execute with runner adapter.</li> <li>Update design decision bullets to match actual behavior.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-156-toolcompose-docs-site/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Component docs examples match current APIs.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-156-toolcompose-docs-site/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>ai-tools-stack/docs/components/toolcompose.md</code> updated with current API examples.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-157-toolcompose-release-propagation/","title":"PRD-157: toolcompose Release + Propagation","text":"<p>Phase: 5 - Composition Layer Priority: High Effort: 1 hour Dependencies: PRD-150\u2013156 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-157-toolcompose-release-propagation/#objective","title":"Objective","text":"<p>Tag and propagate the consolidated <code>toolcompose</code> module into the stack version matrix.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-157-toolcompose-release-propagation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Tag <code>v0.1.0</code> <code>toolcompose</code> Go module release tag Version matrix <code>ai-tools-stack/VERSIONS.md</code> Already includes toolcompose"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-157-toolcompose-release-propagation/#tasks","title":"Tasks","text":"<ol> <li>Tag and push <code>v0.1.0</code> in <code>toolcompose</code>.</li> <li>Verify <code>ai-tools-stack/VERSIONS.md</code> reflects <code>toolcompose v0.1.0</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-157-toolcompose-release-propagation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li><code>v0.1.0</code> tag exists in <code>toolcompose</code>.</li> <li>Version matrix remains consistent.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-157-toolcompose-release-propagation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolcompose</code> tagged <code>v0.1.0</code> and pushed.</li> <li><code>ai-tools-stack/VERSIONS.md</code> already lists <code>toolcompose v0.1.0</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-158-toolcompose-validation/","title":"PRD-158: toolcompose Validation","text":"<p>Phase: 5 - Composition Layer Priority: High Effort: 1 hour Dependencies: PRD-150\u2013157 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-158-toolcompose-validation/#objective","title":"Objective","text":"<p>Verify the toolcompose layer is healthy, documented, and CI-ready.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-158-toolcompose-validation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Test run <code>toolcompose</code> <code>go test ./...</code> Lint run <code>toolcompose</code> <code>golangci-lint run</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-158-toolcompose-validation/#tasks","title":"Tasks","text":"<ol> <li>Run tests and lint in <code>toolcompose</code>.</li> <li>Update gap tracking if needed.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-158-toolcompose-validation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Tests and lint are clean.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-158-toolcompose-validation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>go test ./...</code> and <code>golangci-lint run</code> pass in <code>toolcompose</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-159-toolcompose-docs-publish/","title":"PRD-159: toolcompose Docs Publish Readiness","text":"<p>Phase: 5 - Composition Layer Priority: Medium Effort: 1 hour Dependencies: PRD-156 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-159-toolcompose-docs-publish/#objective","title":"Objective","text":"<p>Confirm the docs site is wired to include toolcompose content via MkDocs multirepo imports.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-159-toolcompose-docs-publish/#deliverables","title":"Deliverables","text":"Deliverable Location Description MkDocs nav <code>ai-tools-stack/mkdocs.yml</code> toolcompose component + docs import"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-159-toolcompose-docs-publish/#tasks","title":"Tasks","text":"<ol> <li>Verify mkdocs nav includes toolcompose component page.</li> <li>Verify multirepo import for toolcompose docs is present.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-159-toolcompose-docs-publish/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>MkDocs nav includes toolcompose component and import.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-159-toolcompose-docs-publish/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>ai-tools-stack/mkdocs.yml</code> already includes toolcompose component + import.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/","title":"PRD-160: Migrate toolobserve","text":"<p>Phase: 6 - Operations Layer Priority: High Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolobserve</code> repository into <code>toolops/observe/</code> as the first package in the consolidated operations layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolobserve</code> Target Location: <code>github.com/jonwraymond/toolops/observe</code></p> <p>Package Contents: - OpenTelemetry integration for tracing - Metrics collection (Prometheus) - Structured logging (slog) - ~2,000 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#deliverables","title":"Deliverables","text":"Deliverable Location Description Observe Package <code>toolops/observe/</code> Observability infrastructure Tests <code>toolops/observe/*_test.go</code> All existing tests Documentation <code>toolops/observe/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#task-1-prepare-target-repository","title":"Task 1: Prepare Target Repository","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolops.git\ncd toolops\n\nmkdir -p observe\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#task-2-clone-and-migrate","title":"Task 2: Clone and Migrate","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolobserve.git\n\ncp toolobserve/*.go toolops/observe/\n\ncd toolops/observe\nsed -i '' 's|github.com/jonwraymond/toolobserve|github.com/jonwraymond/toolops/observe|g' *.go\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#task-3-update-package-documentation","title":"Task 3: Update Package Documentation","text":"<p>File: <code>toolops/observe/doc.go</code></p> <pre><code>// Package observe provides observability infrastructure for the ApertureStack ecosystem.\n//\n// This package implements distributed tracing, metrics collection, and structured\n// logging using industry-standard tools (OpenTelemetry, Prometheus, slog).\n//\n// # Tracing\n//\n// Create spans for tool execution:\n//\n//  tracer := observe.NewTracer(observe.TracerConfig{\n//      ServiceName: \"metatools-mcp\",\n//      Endpoint:    \"http://jaeger:4317\",\n//  })\n//\n//  ctx, span := tracer.Start(ctx, \"tool.execute\",\n//      observe.WithToolID(tool.ID),\n//      observe.WithToolName(tool.Name),\n//  )\n//  defer span.End()\n//\n// # Metrics\n//\n// Collect metrics for monitoring:\n//\n//  metrics := observe.NewMetrics(observe.MetricsConfig{\n//      Namespace: \"metatools\",\n//  })\n//\n//  metrics.ToolExecutions.Inc()\n//  metrics.ToolLatency.Observe(duration.Seconds())\n//\n// # Logging\n//\n// Structured logging with context:\n//\n//  logger := observe.NewLogger(observe.LogConfig{\n//      Level:  slog.LevelInfo,\n//      Format: \"json\",\n//  })\n//\n//  logger.Info(\"tool executed\",\n//      slog.String(\"tool_id\", tool.ID),\n//      slog.Duration(\"duration\", elapsed),\n//  )\n//\n// # Middleware\n//\n// Wrap tool providers with observability:\n//\n//  observed := observe.Middleware(provider, observe.MiddlewareConfig{\n//      Tracer:  tracer,\n//      Metrics: metrics,\n//      Logger:  logger,\n//  })\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolobserve as part of\n// the ApertureStack consolidation.\npackage observe\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#task-4-build-and-test","title":"Task 4: Build and Test","text":"<pre><code>cd /tmp/migration/toolops\n\ngo mod tidy\ngo build ./...\ngo test -v ./observe/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#task-5-commit-and-push","title":"Task 5: Commit and Push","text":"<pre><code>cd /tmp/migration/toolops\n\ngit add -A\ngit commit -m \"feat(observe): migrate toolobserve package\n\nMigrate observability infrastructure from standalone toolobserve repository.\n\nPackage contents:\n- OpenTelemetry tracing integration\n- Prometheus metrics collection\n- Structured logging with slog\n- Observability middleware\n\nFeatures:\n- Distributed tracing across tool executions\n- Standard metrics (requests, latency, errors)\n- JSON/text logging formats\n- Context propagation\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolobserve \u2192 toolops/observe\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All source files copied</li> <li>[ ] Import paths updated</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> <li>[ ] Tracing works</li> <li>[ ] Metrics collection works</li> <li>[ ] Logging works</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#completion-notes","title":"Completion Notes","text":"<ul> <li><code>toolops/observe</code> includes observer, tracer, metrics, logger, and middleware helpers.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-160-migrate-toolobserve/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-161: Migrate toolcache</li> <li>PRD-162: Extract toolauth</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/","title":"PRD-161: Migrate toolcache","text":"<p>Phase: 6 - Operations Layer Priority: High Effort: 4 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/#objective","title":"Objective","text":"<p>Migrate the existing <code>toolcache</code> repository into <code>toolops/cache/</code> as the second package in the consolidated operations layer.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>github.com/jonwraymond/toolcache</code> Target Location: <code>github.com/jonwraymond/toolops/cache</code></p> <p>Package Contents: - Response caching middleware - Memory and Redis backends - TTL-based expiration - Key generation strategies - ~1,500 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/#deliverables","title":"Deliverables","text":"Deliverable Location Description Cache Package <code>toolops/cache/</code> Response caching Tests <code>toolops/cache/*_test.go</code> All existing tests Documentation <code>toolops/cache/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/#task-1-clone-and-migrate","title":"Task 1: Clone and Migrate","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:jonwraymond/toolcache.git\n\ncp toolcache/*.go toolops/cache/\n\ncd toolops/cache\nsed -i '' 's|github.com/jonwraymond/toolcache|github.com/jonwraymond/toolops/cache|g' *.go\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/#task-2-update-package-documentation","title":"Task 2: Update Package Documentation","text":"<p>File: <code>toolops/cache/doc.go</code></p> <pre><code>// Package cache provides response caching for tool executions.\n//\n// This package implements caching middleware that reduces latency and load\n// by storing and reusing tool execution results.\n//\n// # Cache Backends\n//\n// Built-in cache implementations:\n//\n//   - MemoryCache: In-process LRU cache\n//   - RedisCache: Distributed cache using Redis\n//\n// # Usage\n//\n// Create and use a cache:\n//\n//  cache := cache.NewMemoryCache(cache.MemoryConfig{\n//      MaxSize: 1000,\n//      TTL:     5 * time.Minute,\n//  })\n//\n//  // Cache middleware\n//  cached := cache.Middleware(provider, cache.MiddlewareConfig{\n//      Cache:       cache,\n//      KeyGen:      cache.DefaultKeyGenerator,\n//      SkipTools:   []string{\"random\"},\n//      ToolTTLs:    map[string]time.Duration{\"search\": 1*time.Minute},\n//  })\n//\n// # Key Generation\n//\n// Keys are generated from tool ID and arguments:\n//\n//  keyGen := cache.NewKeyGenerator(cache.KeyConfig{\n//      Prefix:      \"metatools:\",\n//      IncludeNS:   true,\n//      IgnoredArgs: []string{\"timestamp\"},\n//  })\n//\n// # Cache Statistics\n//\n// Monitor cache performance:\n//\n//  stats := cache.Stats()\n//  fmt.Printf(\"Hits: %d, Misses: %d, Ratio: %.2f%%\\n\",\n//      stats.Hits, stats.Misses, stats.HitRatio*100)\n//\n// # Migration Note\n//\n// This package was migrated from github.com/jonwraymond/toolcache as part of\n// the ApertureStack consolidation.\npackage cache\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/#task-3-build-and-test","title":"Task 3: Build and Test","text":"<pre><code>cd /tmp/migration/toolops\n\ngo mod tidy\ngo build ./...\ngo test -v ./cache/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/#task-4-commit-and-push","title":"Task 4: Commit and Push","text":"<pre><code>cd /tmp/migration/toolops\n\ngit add -A\ngit commit -m \"feat(cache): migrate toolcache package\n\nMigrate response caching from standalone toolcache repository.\n\nPackage contents:\n- Cache interface for pluggable backends\n- MemoryCache with LRU eviction\n- RedisCache for distributed caching\n- Caching middleware\n- Key generation strategies\n\nFeatures:\n- TTL-based expiration\n- Per-tool TTL overrides\n- Skip list for uncacheable tools\n- Cache statistics\n- Thread-safe operations\n\nThis is part of the ApertureStack consolidation effort.\n\nMigration: github.com/jonwraymond/toolcache \u2192 toolops/cache\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-162: Extract toolauth</li> <li>PRD-163: Create toolresilience</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-161-migrate-toolcache/#completion-notes","title":"Completion Notes","text":"<ul> <li><code>toolops/cache</code> includes deterministic keying, policies, memory cache, and middleware.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/","title":"PRD-162: Extract toolauth","text":"<p>Phase: 6 - Operations Layer Priority: High Effort: 8 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#objective","title":"Objective","text":"<p>Extract authentication code from <code>metatools-mcp/internal/auth/</code> into <code>toolops/auth/</code> for reusable authentication middleware.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#source-analysis","title":"Source Analysis","text":"<p>Current Location: <code>metatools-mcp/internal/auth/</code> (embedded) Target Location: <code>github.com/jonwraymond/toolops/auth</code></p> <p>Code to Extract: - JWT authentication - API key authentication - RBAC authorization - Auth middleware - ~6,400 lines of code</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#deliverables","title":"Deliverables","text":"Deliverable Location Description Auth Package <code>toolops/auth/</code> Authentication/authorization Tests <code>toolops/auth/*_test.go</code> Comprehensive tests Documentation <code>toolops/auth/doc.go</code> Package documentation"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#task-1-analyze-and-copy-source","title":"Task 1: Analyze and Copy Source","text":"<pre><code>cd /Users/jraymond/Documents/Projects/jonwraymond/metatools-mcp\n\nwc -l internal/auth/*.go\n\ncd /tmp/migration/toolops\nmkdir -p auth\ncp /Users/jraymond/Documents/Projects/jonwraymond/metatools-mcp/internal/auth/*.go auth/\n\n# Update package name if needed\nsed -i '' 's|package auth|package auth|g' auth/*.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#task-2-update-imports","title":"Task 2: Update Imports","text":"<pre><code>cd /tmp/migration/toolops/auth\n\n# Update internal references\nsed -i '' 's|metatools-mcp/internal/auth|github.com/jonwraymond/toolops/auth|g' *.go\nsed -i '' 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#task-3-define-core-interfaces","title":"Task 3: Define Core Interfaces","text":"<p>File: <code>toolops/auth/auth.go</code></p> <pre><code>package auth\n\nimport (\n    \"context\"\n)\n\n// Authenticator validates credentials and returns an identity.\ntype Authenticator interface {\n    // Authenticate validates credentials in the request.\n    Authenticate(ctx context.Context, req *AuthRequest) (*AuthResult, error)\n\n    // Name returns the authenticator name (e.g., \"jwt\", \"apikey\").\n    Name() string\n\n    // Supports returns true if this authenticator can handle the request.\n    Supports(ctx context.Context, req *AuthRequest) bool\n}\n\n// Authorizer checks if an identity can perform an action.\ntype Authorizer interface {\n    // Authorize checks if the identity can perform the action.\n    Authorize(ctx context.Context, identity *Identity, action *Action) (*AuthzResult, error)\n}\n\n// AuthRequest contains authentication request data.\ntype AuthRequest struct {\n    Headers map[string]string\n    Token   string\n    APIKey  string\n    Method  string\n    Path    string\n}\n\n// AuthResult contains authentication result.\ntype AuthResult struct {\n    Authenticated bool\n    Identity      *Identity\n    Error         error\n}\n\n// Identity represents an authenticated entity.\ntype Identity struct {\n    Subject   string\n    TenantID  string\n    Roles     []string\n    Claims    map[string]any\n    ExpiresAt time.Time\n}\n\n// Action represents an authorization action.\ntype Action struct {\n    Resource   string // e.g., \"tool:calculator\"\n    Operation  string // e.g., \"execute\"\n    Context    map[string]any\n}\n\n// AuthzResult contains authorization result.\ntype AuthzResult struct {\n    Allowed bool\n    Reason  string\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#task-4-create-package-documentation","title":"Task 4: Create Package Documentation","text":"<p>File: <code>toolops/auth/doc.go</code></p> <pre><code>// Package auth provides authentication and authorization for tool access.\n//\n// This package implements pluggable authentication strategies and role-based\n// access control for tool execution.\n//\n// # Authenticators\n//\n// Built-in authenticators:\n//\n//   - JWTAuthenticator: Validates JWT tokens\n//   - APIKeyAuthenticator: Validates API keys\n//   - CompositeAuthenticator: Chains multiple authenticators\n//\n// # Usage\n//\n// Create and use authenticators:\n//\n//  jwtAuth := auth.NewJWTAuthenticator(auth.JWTConfig{\n//      Secret: []byte(\"secret\"),\n//      Issuer: \"metatools\",\n//  })\n//\n//  apiKeyAuth := auth.NewAPIKeyAuthenticator(auth.APIKeyConfig{\n//      Store: keyStore,\n//  })\n//\n//  composite := auth.NewCompositeAuthenticator(jwtAuth, apiKeyAuth)\n//\n// # Authorization\n//\n// Role-based access control:\n//\n//  rbac := auth.NewRBACAuthorizer(auth.RBACConfig{\n//      Roles: map[string][]string{\n//          \"admin\": {\"*\"},\n//          \"user\":  {\"tool:*:execute\"},\n//      },\n//  })\n//\n//  result, _ := rbac.Authorize(ctx, identity, action)\n//  if !result.Allowed {\n//      // Access denied\n//  }\n//\n// # Middleware\n//\n// Protect tool providers with auth middleware:\n//\n//  protected := auth.Middleware(provider, auth.MiddlewareConfig{\n//      Authenticator: composite,\n//      Authorizer:    rbac,\n//  })\n//\n// # Extraction Note\n//\n// This package was extracted from metatools-mcp/internal/auth as part of\n// the ApertureStack consolidation to enable reuse across projects.\npackage auth\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#task-5-build-and-test","title":"Task 5: Build and Test","text":"<pre><code>cd /tmp/migration/toolops\n\ngo mod tidy\ngo build ./...\ngo test -v ./auth/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#task-6-commit-and-push","title":"Task 6: Commit and Push","text":"<pre><code>cd /tmp/migration/toolops\n\ngit add -A\ngit commit -m \"feat(auth): extract authentication package\n\nExtract auth infrastructure from metatools-mcp for reuse.\n\nPackage contents:\n- Authenticator interface\n- JWTAuthenticator for JWT tokens\n- APIKeyAuthenticator for API keys\n- CompositeAuthenticator for chaining\n- RBACAuthorizer for role-based access\n- Auth middleware\n\nFeatures:\n- Pluggable authentication strategies\n- Role-based access control\n- Identity management\n- Multi-tenant support\n- Factory-based configuration\n\nThis extraction enables auth reuse across projects.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-163: Create toolresilience</li> <li>PRD-164: Create toolhealth</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-162-extract-toolauth/#completion-notes","title":"Completion Notes","text":"<ul> <li><code>toolops/auth</code> provides authenticators (JWT/API key/OAuth2), RBAC, and transport helpers.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/","title":"PRD-163: Create toolresilience","text":"<p>Phase: 6 - Operations Layer Priority: Medium Effort: 8 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#objective","title":"Objective","text":"<p>Create a new <code>toolops/resilience/</code> package for fault tolerance patterns including circuit breakers, retries, timeouts, and bulkheads.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#package-design","title":"Package Design","text":"<p>Location: <code>github.com/jonwraymond/toolops/resilience</code></p> <p>Purpose: - Circuit breaker pattern - Retry with backoff - Timeout management - Bulkhead isolation - Rate limiting</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#deliverables","title":"Deliverables","text":"Deliverable Location Description Resilience Package <code>toolops/resilience/</code> Fault tolerance patterns Circuit Breaker <code>resilience/circuitbreaker.go</code> Circuit breaker implementation Retry <code>resilience/retry.go</code> Retry with backoff Bulkhead <code>resilience/bulkhead.go</code> Concurrency isolation Tests <code>resilience/*_test.go</code> Comprehensive tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#task-1-create-package-structure","title":"Task 1: Create Package Structure","text":"<pre><code>cd /tmp/migration/toolops\nmkdir -p resilience\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#task-2-implement-circuit-breaker","title":"Task 2: Implement Circuit Breaker","text":"<p>File: <code>toolops/resilience/circuitbreaker.go</code></p> <pre><code>package resilience\n\nimport (\n    \"context\"\n    \"errors\"\n    \"sync\"\n    \"time\"\n)\n\n// State represents circuit breaker state.\ntype State int\n\nconst (\n    StateClosed State = iota\n    StateOpen\n    StateHalfOpen\n)\n\nvar (\n    ErrCircuitOpen = errors.New(\"circuit breaker is open\")\n)\n\n// CircuitBreaker implements the circuit breaker pattern.\ntype CircuitBreaker struct {\n    name          string\n    maxFailures   int\n    timeout       time.Duration\n    halfOpenMax   int\n\n    state         State\n    failures      int\n    successes     int\n    lastFailure   time.Time\n    mu            sync.RWMutex\n}\n\n// CircuitBreakerConfig configures the circuit breaker.\ntype CircuitBreakerConfig struct {\n    Name        string\n    MaxFailures int           // Failures before opening\n    Timeout     time.Duration // Time before half-open\n    HalfOpenMax int           // Successes to close\n}\n\n// NewCircuitBreaker creates a new circuit breaker.\nfunc NewCircuitBreaker(config CircuitBreakerConfig) *CircuitBreaker {\n    return &amp;CircuitBreaker{\n        name:        config.Name,\n        maxFailures: config.MaxFailures,\n        timeout:     config.Timeout,\n        halfOpenMax: config.HalfOpenMax,\n        state:       StateClosed,\n    }\n}\n\n// Execute runs the function with circuit breaker protection.\nfunc (cb *CircuitBreaker) Execute(ctx context.Context, fn func() error) error {\n    if !cb.canExecute() {\n        return ErrCircuitOpen\n    }\n\n    err := fn()\n\n    if err != nil {\n        cb.recordFailure()\n        return err\n    }\n\n    cb.recordSuccess()\n    return nil\n}\n\nfunc (cb *CircuitBreaker) canExecute() bool {\n    cb.mu.RLock()\n    defer cb.mu.RUnlock()\n\n    switch cb.state {\n    case StateClosed:\n        return true\n    case StateOpen:\n        if time.Since(cb.lastFailure) &gt; cb.timeout {\n            cb.mu.RUnlock()\n            cb.mu.Lock()\n            cb.state = StateHalfOpen\n            cb.successes = 0\n            cb.mu.Unlock()\n            cb.mu.RLock()\n            return true\n        }\n        return false\n    case StateHalfOpen:\n        return true\n    }\n    return false\n}\n\nfunc (cb *CircuitBreaker) recordFailure() {\n    cb.mu.Lock()\n    defer cb.mu.Unlock()\n\n    cb.failures++\n    cb.lastFailure = time.Now()\n\n    if cb.failures &gt;= cb.maxFailures {\n        cb.state = StateOpen\n    }\n}\n\nfunc (cb *CircuitBreaker) recordSuccess() {\n    cb.mu.Lock()\n    defer cb.mu.Unlock()\n\n    if cb.state == StateHalfOpen {\n        cb.successes++\n        if cb.successes &gt;= cb.halfOpenMax {\n            cb.state = StateClosed\n            cb.failures = 0\n        }\n    }\n}\n\n// State returns current state.\nfunc (cb *CircuitBreaker) State() State {\n    cb.mu.RLock()\n    defer cb.mu.RUnlock()\n    return cb.state\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#task-3-implement-retry","title":"Task 3: Implement Retry","text":"<p>File: <code>toolops/resilience/retry.go</code></p> <pre><code>package resilience\n\nimport (\n    \"context\"\n    \"math\"\n    \"time\"\n)\n\n// RetryConfig configures retry behavior.\ntype RetryConfig struct {\n    MaxAttempts     int\n    InitialInterval time.Duration\n    MaxInterval     time.Duration\n    Multiplier      float64\n    RetryIf         func(error) bool\n}\n\n// DefaultRetryConfig returns default retry configuration.\nfunc DefaultRetryConfig() RetryConfig {\n    return RetryConfig{\n        MaxAttempts:     3,\n        InitialInterval: 100 * time.Millisecond,\n        MaxInterval:     10 * time.Second,\n        Multiplier:      2.0,\n        RetryIf:         func(err error) bool { return true },\n    }\n}\n\n// Retry executes the function with retry logic.\nfunc Retry(ctx context.Context, config RetryConfig, fn func() error) error {\n    var lastErr error\n    interval := config.InitialInterval\n\n    for attempt := 0; attempt &lt; config.MaxAttempts; attempt++ {\n        if err := ctx.Err(); err != nil {\n            return err\n        }\n\n        err := fn()\n        if err == nil {\n            return nil\n        }\n\n        lastErr = err\n        if !config.RetryIf(err) {\n            return err\n        }\n\n        if attempt &lt; config.MaxAttempts-1 {\n            select {\n            case &lt;-ctx.Done():\n                return ctx.Err()\n            case &lt;-time.After(interval):\n            }\n\n            interval = time.Duration(float64(interval) * config.Multiplier)\n            if interval &gt; config.MaxInterval {\n                interval = config.MaxInterval\n            }\n        }\n    }\n\n    return lastErr\n}\n\n// RetryWithResult retries a function that returns a result.\nfunc RetryWithResult[T any](ctx context.Context, config RetryConfig, fn func() (T, error)) (T, error) {\n    var result T\n    var lastErr error\n    interval := config.InitialInterval\n\n    for attempt := 0; attempt &lt; config.MaxAttempts; attempt++ {\n        if err := ctx.Err(); err != nil {\n            return result, err\n        }\n\n        res, err := fn()\n        if err == nil {\n            return res, nil\n        }\n\n        lastErr = err\n        if !config.RetryIf(err) {\n            return result, err\n        }\n\n        if attempt &lt; config.MaxAttempts-1 {\n            select {\n            case &lt;-ctx.Done():\n                return result, ctx.Err()\n            case &lt;-time.After(interval):\n            }\n\n            interval = time.Duration(float64(interval) * config.Multiplier)\n            if interval &gt; config.MaxInterval {\n                interval = config.MaxInterval\n            }\n        }\n    }\n\n    return result, lastErr\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#task-4-implement-bulkhead","title":"Task 4: Implement Bulkhead","text":"<p>File: <code>toolops/resilience/bulkhead.go</code></p> <pre><code>package resilience\n\nimport (\n    \"context\"\n    \"errors\"\n)\n\nvar (\n    ErrBulkheadFull = errors.New(\"bulkhead is full\")\n)\n\n// Bulkhead limits concurrent executions.\ntype Bulkhead struct {\n    name     string\n    maxConc  int\n    sem      chan struct{}\n}\n\n// BulkheadConfig configures the bulkhead.\ntype BulkheadConfig struct {\n    Name           string\n    MaxConcurrent  int\n}\n\n// NewBulkhead creates a new bulkhead.\nfunc NewBulkhead(config BulkheadConfig) *Bulkhead {\n    return &amp;Bulkhead{\n        name:    config.Name,\n        maxConc: config.MaxConcurrent,\n        sem:     make(chan struct{}, config.MaxConcurrent),\n    }\n}\n\n// Execute runs the function with bulkhead protection.\nfunc (b *Bulkhead) Execute(ctx context.Context, fn func() error) error {\n    select {\n    case b.sem &lt;- struct{}{}:\n        defer func() { &lt;-b.sem }()\n        return fn()\n    case &lt;-ctx.Done():\n        return ctx.Err()\n    default:\n        return ErrBulkheadFull\n    }\n}\n\n// ExecuteBlocking waits for a slot and then executes.\nfunc (b *Bulkhead) ExecuteBlocking(ctx context.Context, fn func() error) error {\n    select {\n    case b.sem &lt;- struct{}{}:\n        defer func() { &lt;-b.sem }()\n        return fn()\n    case &lt;-ctx.Done():\n        return ctx.Err()\n    }\n}\n\n// Available returns available slots.\nfunc (b *Bulkhead) Available() int {\n    return b.maxConc - len(b.sem)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#task-5-create-package-documentation","title":"Task 5: Create Package Documentation","text":"<p>File: <code>toolops/resilience/doc.go</code></p> <pre><code>// Package resilience provides fault tolerance patterns for tool execution.\n//\n// This package implements common resilience patterns to handle failures\n// gracefully and prevent cascading failures in distributed systems.\n//\n// # Circuit Breaker\n//\n// Prevent repeated calls to failing services:\n//\n//  cb := resilience.NewCircuitBreaker(resilience.CircuitBreakerConfig{\n//      Name:        \"backend\",\n//      MaxFailures: 5,\n//      Timeout:     30 * time.Second,\n//      HalfOpenMax: 2,\n//  })\n//\n//  err := cb.Execute(ctx, func() error {\n//      return callBackend()\n//  })\n//\n// # Retry with Backoff\n//\n// Retry failed operations with exponential backoff:\n//\n//  err := resilience.Retry(ctx, resilience.RetryConfig{\n//      MaxAttempts:     3,\n//      InitialInterval: 100 * time.Millisecond,\n//      MaxInterval:     10 * time.Second,\n//      Multiplier:      2.0,\n//  }, func() error {\n//      return callService()\n//  })\n//\n// # Bulkhead\n//\n// Limit concurrent executions to prevent resource exhaustion:\n//\n//  bulkhead := resilience.NewBulkhead(resilience.BulkheadConfig{\n//      Name:          \"api-calls\",\n//      MaxConcurrent: 10,\n//  })\n//\n//  err := bulkhead.Execute(ctx, func() error {\n//      return makeAPICall()\n//  })\n//\n// # Middleware\n//\n// Apply resilience patterns to tool providers:\n//\n//  resilient := resilience.Middleware(provider, resilience.MiddlewareConfig{\n//      CircuitBreaker: cb,\n//      Retry:          retryConfig,\n//      Bulkhead:       bulkhead,\n//  })\npackage resilience\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/toolops\n\ngo mod tidy\ngo build ./...\ngo test -v ./resilience/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/toolops\n\ngit add -A\ngit commit -m \"feat(resilience): add fault tolerance patterns\n\nCreate new resilience package for fault tolerance.\n\nPackage contents:\n- CircuitBreaker for failure isolation\n- Retry with exponential backoff\n- Bulkhead for concurrency limiting\n- Resilience middleware\n\nFeatures:\n- Three-state circuit breaker (closed/open/half-open)\n- Configurable failure thresholds\n- Exponential backoff with jitter\n- Non-blocking and blocking bulkhead modes\n- Generic retry with result support\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-164: Create toolhealth</li> <li>Gate G4: Operations layer complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-163-create-toolresilience/#completion-notes","title":"Completion Notes","text":"<ul> <li><code>toolops/resilience</code> implements circuit breaker, retry, rate limiter, bulkhead, timeout, and executor composition.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/","title":"PRD-164: Create toolhealth","text":"<p>Phase: 6 - Operations Layer Priority: Medium Effort: 6 hours Dependencies: PRD-120 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#objective","title":"Objective","text":"<p>Create a new <code>toolops/health/</code> package for health checking, readiness probes, and service status reporting.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#package-design","title":"Package Design","text":"<p>Location: <code>github.com/jonwraymond/toolops/health</code></p> <p>Purpose: - Health check endpoints - Liveness and readiness probes - Dependency health aggregation - Status reporting</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#deliverables","title":"Deliverables","text":"Deliverable Location Description Health Package <code>toolops/health/</code> Health check infrastructure Checker <code>health/checker.go</code> Health check interface Aggregator <code>health/aggregator.go</code> Multi-check aggregation HTTP Handler <code>health/handler.go</code> HTTP endpoints Tests <code>health/*_test.go</code> Comprehensive tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#task-1-create-package-structure","title":"Task 1: Create Package Structure","text":"<pre><code>cd /tmp/migration/toolops\nmkdir -p health\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#task-2-define-health-check-interface","title":"Task 2: Define Health Check Interface","text":"<p>File: <code>toolops/health/checker.go</code></p> <pre><code>package health\n\nimport (\n    \"context\"\n    \"time\"\n)\n\n// Status represents health status.\ntype Status string\n\nconst (\n    StatusHealthy   Status = \"healthy\"\n    StatusUnhealthy Status = \"unhealthy\"\n    StatusDegraded  Status = \"degraded\"\n    StatusUnknown   Status = \"unknown\"\n)\n\n// CheckResult represents a health check result.\ntype CheckResult struct {\n    Name      string\n    Status    Status\n    Message   string\n    Timestamp time.Time\n    Duration  time.Duration\n    Details   map[string]any\n}\n\n// Checker performs health checks.\ntype Checker interface {\n    // Name returns the check name.\n    Name() string\n\n    // Check performs the health check.\n    Check(ctx context.Context) *CheckResult\n}\n\n// CheckFunc is a function that performs a health check.\ntype CheckFunc func(ctx context.Context) *CheckResult\n\n// FuncChecker wraps a function as a Checker.\ntype FuncChecker struct {\n    name string\n    fn   CheckFunc\n}\n\n// NewFuncChecker creates a checker from a function.\nfunc NewFuncChecker(name string, fn CheckFunc) *FuncChecker {\n    return &amp;FuncChecker{name: name, fn: fn}\n}\n\nfunc (c *FuncChecker) Name() string                         { return c.name }\nfunc (c *FuncChecker) Check(ctx context.Context) *CheckResult { return c.fn(ctx) }\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#task-3-implement-health-aggregator","title":"Task 3: Implement Health Aggregator","text":"<p>File: <code>toolops/health/aggregator.go</code></p> <pre><code>package health\n\nimport (\n    \"context\"\n    \"sync\"\n    \"time\"\n)\n\n// AggregatedResult contains results from multiple checks.\ntype AggregatedResult struct {\n    Status    Status\n    Checks    map[string]*CheckResult\n    Timestamp time.Time\n}\n\n// Aggregator combines multiple health checkers.\ntype Aggregator struct {\n    checkers []Checker\n    timeout  time.Duration\n    mu       sync.RWMutex\n    cache    *AggregatedResult\n    cacheTTL time.Duration\n}\n\n// AggregatorConfig configures the aggregator.\ntype AggregatorConfig struct {\n    Timeout  time.Duration\n    CacheTTL time.Duration\n}\n\n// NewAggregator creates a new health aggregator.\nfunc NewAggregator(config AggregatorConfig) *Aggregator {\n    return &amp;Aggregator{\n        checkers: make([]Checker, 0),\n        timeout:  config.Timeout,\n        cacheTTL: config.CacheTTL,\n    }\n}\n\n// Register adds a checker to the aggregator.\nfunc (a *Aggregator) Register(checker Checker) {\n    a.mu.Lock()\n    defer a.mu.Unlock()\n    a.checkers = append(a.checkers, checker)\n}\n\n// Check runs all health checks.\nfunc (a *Aggregator) Check(ctx context.Context) *AggregatedResult {\n    // Check cache\n    a.mu.RLock()\n    if a.cache != nil &amp;&amp; time.Since(a.cache.Timestamp) &lt; a.cacheTTL {\n        result := a.cache\n        a.mu.RUnlock()\n        return result\n    }\n    a.mu.RUnlock()\n\n    // Run checks in parallel\n    ctx, cancel := context.WithTimeout(ctx, a.timeout)\n    defer cancel()\n\n    results := make(map[string]*CheckResult)\n    var wg sync.WaitGroup\n    var mu sync.Mutex\n\n    a.mu.RLock()\n    checkers := make([]Checker, len(a.checkers))\n    copy(checkers, a.checkers)\n    a.mu.RUnlock()\n\n    for _, checker := range checkers {\n        wg.Add(1)\n        go func(c Checker) {\n            defer wg.Done()\n\n            start := time.Now()\n            result := c.Check(ctx)\n            result.Duration = time.Since(start)\n            result.Timestamp = start\n\n            mu.Lock()\n            results[c.Name()] = result\n            mu.Unlock()\n        }(checker)\n    }\n\n    wg.Wait()\n\n    // Aggregate status\n    overallStatus := StatusHealthy\n    for _, result := range results {\n        if result.Status == StatusUnhealthy {\n            overallStatus = StatusUnhealthy\n            break\n        }\n        if result.Status == StatusDegraded &amp;&amp; overallStatus == StatusHealthy {\n            overallStatus = StatusDegraded\n        }\n    }\n\n    aggregated := &amp;AggregatedResult{\n        Status:    overallStatus,\n        Checks:    results,\n        Timestamp: time.Now(),\n    }\n\n    // Update cache\n    a.mu.Lock()\n    a.cache = aggregated\n    a.mu.Unlock()\n\n    return aggregated\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#task-4-implement-http-handler","title":"Task 4: Implement HTTP Handler","text":"<p>File: <code>toolops/health/handler.go</code></p> <pre><code>package health\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"net/http\"\n)\n\n// Handler provides HTTP health check endpoints.\ntype Handler struct {\n    aggregator *Aggregator\n    liveness   Checker\n}\n\n// NewHandler creates a new health HTTP handler.\nfunc NewHandler(aggregator *Aggregator, liveness Checker) *Handler {\n    return &amp;Handler{\n        aggregator: aggregator,\n        liveness:   liveness,\n    }\n}\n\n// LivenessHandler handles /health/live endpoint.\nfunc (h *Handler) LivenessHandler() http.HandlerFunc {\n    return func(w http.ResponseWriter, r *http.Request) {\n        ctx := r.Context()\n\n        result := h.liveness.Check(ctx)\n\n        w.Header().Set(\"Content-Type\", \"application/json\")\n\n        if result.Status != StatusHealthy {\n            w.WriteHeader(http.StatusServiceUnavailable)\n        }\n\n        json.NewEncoder(w).Encode(result)\n    }\n}\n\n// ReadinessHandler handles /health/ready endpoint.\nfunc (h *Handler) ReadinessHandler() http.HandlerFunc {\n    return func(w http.ResponseWriter, r *http.Request) {\n        ctx := r.Context()\n\n        result := h.aggregator.Check(ctx)\n\n        w.Header().Set(\"Content-Type\", \"application/json\")\n\n        switch result.Status {\n        case StatusHealthy:\n            w.WriteHeader(http.StatusOK)\n        case StatusDegraded:\n            w.WriteHeader(http.StatusOK) // Still ready, but degraded\n        default:\n            w.WriteHeader(http.StatusServiceUnavailable)\n        }\n\n        json.NewEncoder(w).Encode(result)\n    }\n}\n\n// HealthHandler handles /health endpoint (full status).\nfunc (h *Handler) HealthHandler() http.HandlerFunc {\n    return func(w http.ResponseWriter, r *http.Request) {\n        ctx := r.Context()\n\n        result := h.aggregator.Check(ctx)\n\n        w.Header().Set(\"Content-Type\", \"application/json\")\n\n        switch result.Status {\n        case StatusHealthy:\n            w.WriteHeader(http.StatusOK)\n        case StatusDegraded:\n            w.WriteHeader(http.StatusOK)\n        default:\n            w.WriteHeader(http.StatusServiceUnavailable)\n        }\n\n        json.NewEncoder(w).Encode(result)\n    }\n}\n\n// RegisterRoutes registers health endpoints on a mux.\nfunc (h *Handler) RegisterRoutes(mux *http.ServeMux) {\n    mux.HandleFunc(\"/health\", h.HealthHandler())\n    mux.HandleFunc(\"/health/live\", h.LivenessHandler())\n    mux.HandleFunc(\"/health/ready\", h.ReadinessHandler())\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#task-5-create-common-checkers","title":"Task 5: Create Common Checkers","text":"<p>File: <code>toolops/health/checkers.go</code></p> <pre><code>package health\n\nimport (\n    \"context\"\n    \"database/sql\"\n    \"net/http\"\n    \"time\"\n)\n\n// DatabaseChecker checks database connectivity.\nfunc DatabaseChecker(name string, db *sql.DB) Checker {\n    return NewFuncChecker(name, func(ctx context.Context) *CheckResult {\n        if err := db.PingContext(ctx); err != nil {\n            return &amp;CheckResult{\n                Name:    name,\n                Status:  StatusUnhealthy,\n                Message: err.Error(),\n            }\n        }\n        return &amp;CheckResult{\n            Name:    name,\n            Status:  StatusHealthy,\n            Message: \"database connection ok\",\n        }\n    })\n}\n\n// HTTPChecker checks HTTP endpoint availability.\nfunc HTTPChecker(name, url string, timeout time.Duration) Checker {\n    client := &amp;http.Client{Timeout: timeout}\n\n    return NewFuncChecker(name, func(ctx context.Context) *CheckResult {\n        req, _ := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n        resp, err := client.Do(req)\n\n        if err != nil {\n            return &amp;CheckResult{\n                Name:    name,\n                Status:  StatusUnhealthy,\n                Message: err.Error(),\n            }\n        }\n        defer resp.Body.Close()\n\n        if resp.StatusCode &gt;= 500 {\n            return &amp;CheckResult{\n                Name:    name,\n                Status:  StatusUnhealthy,\n                Message: \"service returned \" + resp.Status,\n            }\n        }\n\n        return &amp;CheckResult{\n            Name:    name,\n            Status:  StatusHealthy,\n            Message: \"endpoint reachable\",\n        }\n    })\n}\n\n// MemoryChecker checks memory usage.\nfunc MemoryChecker(name string, maxBytes uint64) Checker {\n    return NewFuncChecker(name, func(ctx context.Context) *CheckResult {\n        var m runtime.MemStats\n        runtime.ReadMemStats(&amp;m)\n\n        if m.Alloc &gt; maxBytes {\n            return &amp;CheckResult{\n                Name:    name,\n                Status:  StatusDegraded,\n                Message: \"memory usage high\",\n                Details: map[string]any{\n                    \"alloc_bytes\": m.Alloc,\n                    \"max_bytes\":   maxBytes,\n                },\n            }\n        }\n\n        return &amp;CheckResult{\n            Name:   name,\n            Status: StatusHealthy,\n            Details: map[string]any{\n                \"alloc_bytes\": m.Alloc,\n            },\n        }\n    })\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#task-6-create-package-documentation","title":"Task 6: Create Package Documentation","text":"<p>File: <code>toolops/health/doc.go</code></p> <pre><code>// Package health provides health checking infrastructure.\n//\n// This package implements Kubernetes-style health probes for\n// monitoring service availability and dependencies.\n//\n// # Health Checks\n//\n// Create custom health checkers:\n//\n//  dbChecker := health.DatabaseChecker(\"postgres\", db)\n//  redisChecker := health.HTTPChecker(\"redis\", \"http://redis:6379/ping\", 5*time.Second)\n//\n// # Aggregation\n//\n// Combine multiple checks:\n//\n//  aggregator := health.NewAggregator(health.AggregatorConfig{\n//      Timeout:  5 * time.Second,\n//      CacheTTL: 10 * time.Second,\n//  })\n//  aggregator.Register(dbChecker)\n//  aggregator.Register(redisChecker)\n//\n//  result := aggregator.Check(ctx)\n//\n// # HTTP Endpoints\n//\n// Expose health endpoints:\n//\n//  handler := health.NewHandler(aggregator, liveness)\n//  handler.RegisterRoutes(mux)\n//\n// Endpoints:\n//   - /health - Full health status\n//   - /health/live - Liveness probe (is the process alive?)\n//   - /health/ready - Readiness probe (can it serve traffic?)\n//\n// # Kubernetes Integration\n//\n// Configure Kubernetes probes:\n//\n//  livenessProbe:\n//    httpGet:\n//      path: /health/live\n//      port: 8080\n//  readinessProbe:\n//    httpGet:\n//      path: /health/ready\n//      port: 8080\npackage health\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#task-7-build-and-test","title":"Task 7: Build and Test","text":"<pre><code>cd /tmp/migration/toolops\n\ngo mod tidy\ngo build ./...\ngo test -v ./health/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#task-8-commit-and-push","title":"Task 8: Commit and Push","text":"<pre><code>cd /tmp/migration/toolops\n\ngit add -A\ngit commit -m \"feat(health): add health check infrastructure\n\nCreate new health package for service health monitoring.\n\nPackage contents:\n- Checker interface for health checks\n- Aggregator for combining multiple checks\n- HTTP handler for health endpoints\n- Common checkers (database, HTTP, memory)\n\nFeatures:\n- Kubernetes-style liveness/readiness probes\n- Parallel check execution\n- Result caching\n- Status aggregation\n- Built-in common checkers\n\nEndpoints:\n- /health - Full health status\n- /health/live - Liveness probe\n- /health/ready - Readiness probe\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] Checker interface defined</li> <li>[ ] Aggregator implemented</li> <li>[ ] HTTP handlers work</li> <li>[ ] Common checkers available</li> <li>[ ] <code>go build ./...</code> succeeds</li> <li>[ ] <code>go test ./...</code> passes</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G4: Operations layer complete (all 5 packages)</li> <li>PRD-170: Create tooltransport</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-164-create-toolhealth/#completion-notes","title":"Completion Notes","text":"<ul> <li><code>toolops/health</code> provides checkers, aggregators, and probe handlers.</li> <li>Imports updated to <code>github.com/jonwraymond/...</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-165-toolops-docs-alignment/","title":"PRD-165: toolops Docs + README Alignment","text":"<p>Phase: 6 - Operations Layer Priority: High Effort: 2 hours Dependencies: PRD-160\u2013164 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-165-toolops-docs-alignment/#objective","title":"Objective","text":"<p>Align public-facing documentation with the consolidated <code>toolops</code> API.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-165-toolops-docs-alignment/#deliverables","title":"Deliverables","text":"Deliverable Location Description Updated README <code>toolops/README.md</code> Package table + descriptions Updated docs <code>toolops/docs/*</code> Accurate usage examples"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-165-toolops-docs-alignment/#tasks","title":"Tasks","text":"<ol> <li>Update README package table (<code>observe</code>, <code>cache</code>, <code>auth</code>, <code>health</code>, <code>resilience</code>).</li> <li>Populate docs/index.md with quick-start examples.</li> <li>Populate docs/user-journey.md with step-by-step workflow.</li> <li>Populate docs/design-notes.md with architecture decisions.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-165-toolops-docs-alignment/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>README has no <code>TBD</code> entries.</li> <li>Docs reflect current package names and usage.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-165-toolops-docs-alignment/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolops/README.md</code> updated.</li> <li><code>toolops/docs/index.md</code>, <code>user-journey.md</code>, <code>design-notes.md</code> populated with current API.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-166-toolops-observe-contracts/","title":"PRD-166: toolops Observe Contracts","text":"<p>Phase: 6 - Operations Layer Priority: Medium Effort: 2 hours Dependencies: PRD-160 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-166-toolops-observe-contracts/#objective","title":"Objective","text":"<p>Document the observe contracts (Observer, Tracer, Metrics, Logger, Middleware) and how they are intended to be used.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-166-toolops-observe-contracts/#deliverables","title":"Deliverables","text":"Deliverable Location Description Observe contracts <code>toolops/docs/design-notes.md</code> Contracts and integration patterns"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-166-toolops-observe-contracts/#tasks","title":"Tasks","text":"<ol> <li>Document Observer lifecycle and shutdown expectations.</li> <li>Document Middleware usage with <code>ExecuteFunc</code>.</li> <li>Document ToolMeta fields and span naming.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-166-toolops-observe-contracts/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Observe contracts are documented in design notes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-166-toolops-observe-contracts/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolops/docs/design-notes.md</code> includes observe contract notes.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-167-toolops-cache-policy-docs/","title":"PRD-167: toolops Cache Policy Docs","text":"<p>Phase: 6 - Operations Layer Priority: Medium Effort: 2 hours Dependencies: PRD-161 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-167-toolops-cache-policy-docs/#objective","title":"Objective","text":"<p>Document cache keying, policy semantics, and unsafe tag handling.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-167-toolops-cache-policy-docs/#deliverables","title":"Deliverables","text":"Deliverable Location Description Cache policy docs <code>toolops/docs/design-notes.md</code> Keying + policy semantics"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-167-toolops-cache-policy-docs/#tasks","title":"Tasks","text":"<ol> <li>Document deterministic keying (canonical JSON + SHA\u2011256).</li> <li>Document policy behavior (TTL defaults, clamping, unsafe tags).</li> <li>Document middleware behavior (no cache on errors).</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-167-toolops-cache-policy-docs/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Cache policy and keying are documented.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-167-toolops-cache-policy-docs/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolops/docs/design-notes.md</code> includes cache policy section.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-168-toolops-auth-health-resilience-docs/","title":"PRD-168: toolops Auth/Health/Resilience Docs","text":"<p>Phase: 6 - Operations Layer Priority: Medium Effort: 2 hours Dependencies: PRD-162\u2013164 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-168-toolops-auth-health-resilience-docs/#objective","title":"Objective","text":"<p>Document auth, health, and resilience contracts so integrators understand the expected behaviors and ordering.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-168-toolops-auth-health-resilience-docs/#deliverables","title":"Deliverables","text":"Deliverable Location Description Auth/health/resilience docs <code>toolops/docs/design-notes.md</code> Contracts and usage notes"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-168-toolops-auth-health-resilience-docs/#tasks","title":"Tasks","text":"<ol> <li>Document authenticator vs authorizer and RBAC contract.</li> <li>Document checker/aggregator semantics for health.</li> <li>Document resilience executor ordering and context behavior.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-168-toolops-auth-health-resilience-docs/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Auth/health/resilience contracts are documented.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-168-toolops-auth-health-resilience-docs/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolops/docs/design-notes.md</code> includes auth/health/resilience sections.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-169-toolops-release-validation/","title":"PRD-169: toolops Release + Validation","text":"<p>Phase: 6 - Operations Layer Priority: High Effort: 2 hours Dependencies: PRD-160\u2013168 Status: Done (2026-01-31)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-169-toolops-release-validation/#objective","title":"Objective","text":"<p>Tag and validate the consolidated <code>toolops</code> module.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-169-toolops-release-validation/#deliverables","title":"Deliverables","text":"Deliverable Location Description Tag <code>v0.1.0</code> <code>toolops</code> Go module release tag Test + lint <code>toolops</code> <code>go test ./...</code> + <code>golangci-lint run</code>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-169-toolops-release-validation/#tasks","title":"Tasks","text":"<ol> <li>Tag and push <code>v0.1.0</code> in <code>toolops</code>.</li> <li>Run tests and lint in <code>toolops</code>.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-169-toolops-release-validation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li><code>v0.1.0</code> tag exists in <code>toolops</code>.</li> <li>Tests and lint are clean.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-169-toolops-release-validation/#completion-evidence","title":"Completion Evidence","text":"<ul> <li><code>toolops</code> tagged <code>v0.1.0</code> and pushed.</li> <li><code>go test ./...</code> and <code>golangci-lint run</code> pass.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/","title":"PRD-170: Create tooltransport","text":"<p>Phase: 7 - Protocol Layer Priority: Critical Effort: 8 hours Dependencies: PRD-120 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/transport/</code> for multi-transport support including stdio, SSE, and Streamable HTTP. WebSocket/gRPC are deferred.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#package-design","title":"Package Design","text":"<p>Location: <code>github.com/jonwraymond/toolprotocol/transport</code></p> <p>Purpose: - Transport abstraction layer - Stdio transport (MCP default) - SSE transport (legacy HTTP) - Streamable HTTP transport (MCP 2025-03-26)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#deliverables","title":"Deliverables","text":"Deliverable Location Description Transport Package <code>toolprotocol/transport/</code> Transport abstraction Stdio <code>transport/stdio.go</code> Stdio implementation SSE <code>transport/sse.go</code> HTTP SSE implementation Streamable HTTP <code>transport/streamable.go</code> MCP 2025-03-26 HTTP transport Registry <code>transport/factory.go</code> Transport registry + factory Tests <code>transport/*_test.go</code> Comprehensive tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Transport</code> and <code>Server</code> contracts with concurrency + cancellation requirements.</li> <li>Shipped stdio, SSE, and streamable HTTP transports; WebSocket/gRPC deferred.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#task-1-create-package-structure","title":"Task 1: Create Package Structure","text":"<pre><code>cd /tmp/migration\ngit clone git@github.com:ApertureStack/toolprotocol.git\ncd toolprotocol\n\nmkdir -p transport\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#task-2-define-transport-interface","title":"Task 2: Define Transport Interface","text":"<p>File: <code>toolprotocol/transport/transport.go</code></p> <pre><code>package transport\n\nimport (\n    \"context\"\n    \"io\"\n)\n\n// Transport represents a communication transport.\ntype Transport interface {\n    // Start starts the transport.\n    Start(ctx context.Context) error\n\n    // Stop stops the transport gracefully.\n    Stop(ctx context.Context) error\n\n    // Send sends a message.\n    Send(ctx context.Context, msg Message) error\n\n    // Receive returns a channel of incoming messages.\n    Receive() &lt;-chan Message\n\n    // Type returns the transport type.\n    Type() string\n}\n\n// Message represents a transport message.\ntype Message struct {\n    ID      string\n    Type    MessageType\n    Payload []byte\n    Error   error\n}\n\n// MessageType defines message types.\ntype MessageType string\n\nconst (\n    MessageRequest  MessageType = \"request\"\n    MessageResponse MessageType = \"response\"\n    MessageNotify   MessageType = \"notification\"\n    MessageError    MessageType = \"error\"\n)\n\n// Server is a transport that accepts connections.\ntype Server interface {\n    Transport\n\n    // Listen starts accepting connections.\n    Listen(addr string) error\n\n    // Connections returns a channel of new connections.\n    Connections() &lt;-chan Connection\n}\n\n// Connection represents a client connection.\ntype Connection interface {\n    io.ReadWriteCloser\n    ID() string\n}\n\n// Config is base transport configuration.\ntype Config struct {\n    ReadTimeout  time.Duration\n    WriteTimeout time.Duration\n    MaxMsgSize   int\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#task-3-implement-stdio-transport","title":"Task 3: Implement Stdio Transport","text":"<p>File: <code>toolprotocol/transport/stdio.go</code></p> <pre><code>package transport\n\nimport (\n    \"bufio\"\n    \"context\"\n    \"encoding/json\"\n    \"io\"\n    \"os\"\n    \"sync\"\n)\n\n// StdioTransport implements Transport for stdio communication.\ntype StdioTransport struct {\n    reader  io.Reader\n    writer  io.Writer\n    recv    chan Message\n    done    chan struct{}\n    scanner *bufio.Scanner\n    mu      sync.Mutex\n}\n\n// StdioConfig configures stdio transport.\ntype StdioConfig struct {\n    Reader io.Reader\n    Writer io.Writer\n}\n\n// NewStdioTransport creates a new stdio transport.\nfunc NewStdioTransport(config StdioConfig) *StdioTransport {\n    reader := config.Reader\n    writer := config.Writer\n    if reader == nil {\n        reader = os.Stdin\n    }\n    if writer == nil {\n        writer = os.Stdout\n    }\n\n    return &amp;StdioTransport{\n        reader: reader,\n        writer: writer,\n        recv:   make(chan Message, 100),\n        done:   make(chan struct{}),\n    }\n}\n\nfunc (t *StdioTransport) Type() string { return \"stdio\" }\n\nfunc (t *StdioTransport) Start(ctx context.Context) error {\n    t.scanner = bufio.NewScanner(t.reader)\n    t.scanner.Buffer(make([]byte, 1024*1024), 10*1024*1024)\n\n    go t.readLoop(ctx)\n    return nil\n}\n\nfunc (t *StdioTransport) readLoop(ctx context.Context) {\n    for {\n        select {\n        case &lt;-ctx.Done():\n            return\n        case &lt;-t.done:\n            return\n        default:\n            if !t.scanner.Scan() {\n                if err := t.scanner.Err(); err != nil {\n                    t.recv &lt;- Message{Type: MessageError, Error: err}\n                }\n                return\n            }\n\n            line := t.scanner.Bytes()\n            if len(line) == 0 {\n                continue\n            }\n\n            msg := Message{\n                Type:    MessageRequest,\n                Payload: make([]byte, len(line)),\n            }\n            copy(msg.Payload, line)\n            t.recv &lt;- msg\n        }\n    }\n}\n\nfunc (t *StdioTransport) Stop(ctx context.Context) error {\n    close(t.done)\n    return nil\n}\n\nfunc (t *StdioTransport) Send(ctx context.Context, msg Message) error {\n    t.mu.Lock()\n    defer t.mu.Unlock()\n\n    _, err := t.writer.Write(append(msg.Payload, '\\n'))\n    return err\n}\n\nfunc (t *StdioTransport) Receive() &lt;-chan Message {\n    return t.recv\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#task-4-implement-sse-transport","title":"Task 4: Implement SSE Transport","text":"<p>File: <code>toolprotocol/transport/sse.go</code></p> <pre><code>package transport\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"net/http\"\n    \"sync\"\n)\n\n// SSETransport implements Server for HTTP SSE communication.\ntype SSETransport struct {\n    config SSEConfig\n    server *http.Server\n    recv   chan Message\n    conns  chan Connection\n    done   chan struct{}\n    mu     sync.RWMutex\n}\n\n// SSEConfig configures SSE transport.\ntype SSEConfig struct {\n    Host        string\n    Port        int\n    TLSCert     string\n    TLSKey      string\n    CORSOrigins []string\n}\n\n// NewSSETransport creates a new SSE transport server.\nfunc NewSSETransport(config SSEConfig) *SSETransport {\n    return &amp;SSETransport{\n        config: config,\n        recv:   make(chan Message, 100),\n        conns:  make(chan Connection, 10),\n        done:   make(chan struct{}),\n    }\n}\n\nfunc (t *SSETransport) Type() string { return \"sse\" }\n\nfunc (t *SSETransport) Start(ctx context.Context) error {\n    mux := http.NewServeMux()\n    mux.HandleFunc(\"/mcp\", t.handleMCP)\n    mux.HandleFunc(\"/health\", t.handleHealth)\n\n    addr := fmt.Sprintf(\"%s:%d\", t.config.Host, t.config.Port)\n    t.server = &amp;http.Server{\n        Addr:    addr,\n        Handler: t.corsMiddleware(mux),\n    }\n\n    go func() {\n        var err error\n        if t.config.TLSCert != \"\" {\n            err = t.server.ListenAndServeTLS(t.config.TLSCert, t.config.TLSKey)\n        } else {\n            err = t.server.ListenAndServe()\n        }\n        if err != nil &amp;&amp; err != http.ErrServerClosed {\n            t.recv &lt;- Message{Type: MessageError, Error: err}\n        }\n    }()\n\n    return nil\n}\n\nfunc (t *SSETransport) handleMCP(w http.ResponseWriter, r *http.Request) {\n    if r.Method != http.MethodPost {\n        http.Error(w, \"Method not allowed\", http.StatusMethodNotAllowed)\n        return\n    }\n\n    // Read request\n    var payload []byte\n    payload, err := io.ReadAll(r.Body)\n    if err != nil {\n        http.Error(w, err.Error(), http.StatusBadRequest)\n        return\n    }\n\n    // Create response channel\n    respChan := make(chan Message, 1)\n    msg := Message{\n        ID:      r.Header.Get(\"X-Request-ID\"),\n        Type:    MessageRequest,\n        Payload: payload,\n    }\n\n    t.recv &lt;- msg\n\n    // Wait for response (simplified - real impl needs response routing)\n    // Set SSE headers\n    w.Header().Set(\"Content-Type\", \"text/event-stream\")\n    w.Header().Set(\"Cache-Control\", \"no-cache\")\n    w.Header().Set(\"Connection\", \"keep-alive\")\n\n    flusher, ok := w.(http.Flusher)\n    if !ok {\n        http.Error(w, \"Streaming unsupported\", http.StatusInternalServerError)\n        return\n    }\n\n    select {\n    case resp := &lt;-respChan:\n        fmt.Fprintf(w, \"event: message\\ndata: %s\\n\\n\", resp.Payload)\n        flusher.Flush()\n    case &lt;-r.Context().Done():\n        return\n    }\n}\n\nfunc (t *SSETransport) handleHealth(w http.ResponseWriter, r *http.Request) {\n    w.WriteHeader(http.StatusOK)\n    w.Write([]byte(`{\"status\":\"ok\"}`))\n}\n\nfunc (t *SSETransport) corsMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        origin := r.Header.Get(\"Origin\")\n        for _, allowed := range t.config.CORSOrigins {\n            if allowed == \"*\" || allowed == origin {\n                w.Header().Set(\"Access-Control-Allow-Origin\", origin)\n                break\n            }\n        }\n        w.Header().Set(\"Access-Control-Allow-Methods\", \"POST, OPTIONS\")\n        w.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, X-Request-ID\")\n\n        if r.Method == http.MethodOptions {\n            w.WriteHeader(http.StatusNoContent)\n            return\n        }\n\n        next.ServeHTTP(w, r)\n    })\n}\n\nfunc (t *SSETransport) Stop(ctx context.Context) error {\n    close(t.done)\n    return t.server.Shutdown(ctx)\n}\n\nfunc (t *SSETransport) Send(ctx context.Context, msg Message) error {\n    // Implementation depends on connection management\n    return nil\n}\n\nfunc (t *SSETransport) Receive() &lt;-chan Message {\n    return t.recv\n}\n\nfunc (t *SSETransport) Listen(addr string) error {\n    return nil // Start handles this\n}\n\nfunc (t *SSETransport) Connections() &lt;-chan Connection {\n    return t.conns\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#task-5-create-package-documentation","title":"Task 5: Create Package Documentation","text":"<p>File: <code>toolprotocol/transport/doc.go</code></p> <pre><code>// Package transport provides multi-transport support for tool communication.\n//\n// This package implements various transport mechanisms for the MCP protocol\n// and other AI tool protocols.\n//\n// # Transports\n//\n// Built-in transports:\n//\n//   - StdioTransport: Standard input/output (MCP default)\n//   - SSETransport: HTTP with Server-Sent Events\n//   - WebSocketTransport: WebSocket bidirectional\n//   - GRPCTransport: gRPC for high-performance\n//\n// # Usage\n//\n// Create and use a transport:\n//\n//  // Stdio (default MCP)\n//  stdio := transport.NewStdioTransport(transport.StdioConfig{})\n//  stdio.Start(ctx)\n//\n//  // SSE for web clients\n//  sse := transport.NewSSETransport(transport.SSEConfig{\n//      Host: \"localhost\",\n//      Port: 8080,\n//  })\n//  sse.Start(ctx)\n//\n// # Message Loop\n//\n// Process incoming messages:\n//\n//  for msg := range transport.Receive() {\n//      response := handleMessage(msg)\n//      transport.Send(ctx, response)\n//  }\n//\n// # Transport Selection\n//\n// Select transport based on configuration:\n//\n//  func NewTransport(typ string, config any) (Transport, error) {\n//      switch typ {\n//      case \"stdio\":\n//          return NewStdioTransport(config.(StdioConfig)), nil\n//      case \"sse\":\n//          return NewSSETransport(config.(SSEConfig)), nil\n//      default:\n//          return nil, fmt.Errorf(\"unknown transport: %s\", typ)\n//      }\n//  }\npackage transport\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#task-6-build-and-test","title":"Task 6: Build and Test","text":"<pre><code>cd /tmp/migration/toolprotocol\n\ngo mod tidy\ngo build ./...\ngo test -v ./transport/...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#task-7-commit-and-push","title":"Task 7: Commit and Push","text":"<pre><code>cd /tmp/migration/toolprotocol\n\ngit add -A\ngit commit -m \"feat(transport): add multi-transport support\n\nCreate transport package for protocol communication.\n\nPackage contents:\n- Transport interface for pluggable transports\n- StdioTransport for MCP stdio mode\n- SSETransport for HTTP/SSE\n- WebSocketTransport for bidirectional\n- GRPCTransport for high-performance\n\nFeatures:\n- Pluggable transport abstraction\n- Message-based communication\n- Graceful shutdown\n- CORS support for SSE\n- TLS support\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-170-create-tooltransport/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-171: Create toolwire</li> <li>PRD-172: Create tooldiscover</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/","title":"PRD-171: Create toolwire","text":"<p>Phase: 7 - Protocol Layer Priority: Critical Effort: 12 hours Dependencies: PRD-170 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/wire/</code> for protocol wire adapters supporting MCP, A2A (Google), and ACP (IBM).</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/#package-design","title":"Package Design","text":"<p>Location: <code>github.com/jonwraymond/toolprotocol/wire</code></p> <p>Purpose: - Wire protocol adapters - MCP JSON-RPC 2.0 encoding - A2A protocol encoding - ACP protocol encoding - Protocol negotiation</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/#deliverables","title":"Deliverables","text":"Deliverable Location Description Wire Package <code>toolprotocol/wire/</code> Protocol adapters MCP <code>wire/mcp.go</code> MCP wire adapter A2A <code>wire/a2a.go</code> Google A2A adapter ACP <code>wire/acp.go</code> IBM ACP adapter Registry <code>wire/registry.go</code> Wire registry + factory Tests <code>wire/*_test.go</code> Comprehensive tests"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Wire</code> interface with deterministic encode/decode.</li> <li>Added MCP, A2A, and ACP wire formats plus registry and error types.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/#task-1-define-wire-interface","title":"Task 1: Define Wire Interface","text":"<p>File: <code>toolprotocol/wire/wire.go</code></p> <pre><code>package wire\n\nimport (\n    \"context\"\n    \"github.com/ApertureStack/toolfoundation/model\"\n)\n\n// Wire encodes/decodes protocol messages.\ntype Wire interface {\n    // Name returns the protocol name.\n    Name() string\n\n    // Version returns the protocol version.\n    Version() string\n\n    // EncodeRequest encodes a tool request.\n    EncodeRequest(ctx context.Context, req *ToolRequest) ([]byte, error)\n\n    // DecodeRequest decodes a tool request.\n    DecodeRequest(ctx context.Context, data []byte) (*ToolRequest, error)\n\n    // EncodeResponse encodes a tool response.\n    EncodeResponse(ctx context.Context, resp *ToolResponse) ([]byte, error)\n\n    // DecodeResponse decodes a tool response.\n    DecodeResponse(ctx context.Context, data []byte) (*ToolResponse, error)\n\n    // EncodeToolList encodes a tool list.\n    EncodeToolList(ctx context.Context, tools []model.Tool) ([]byte, error)\n\n    // DecodeToolList decodes a tool list.\n    DecodeToolList(ctx context.Context, data []byte) ([]model.Tool, error)\n}\n\n// ToolRequest represents a canonical tool call request.\ntype ToolRequest struct {\n    ID        string\n    ToolID    string\n    Arguments map[string]any\n    Context   map[string]any\n}\n\n// ToolResponse represents a canonical tool call response.\ntype ToolResponse struct {\n    ID      string\n    Content []Content\n    IsError bool\n    Error   *ToolError\n}\n\n// Content represents response content.\ntype Content struct {\n    Type string // \"text\", \"image\", \"resource\"\n    Text string\n    Data []byte\n    URI  string\n}\n\n// ToolError represents a tool execution error.\ntype ToolError struct {\n    Code    int\n    Message string\n    Data    any\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/#task-2-implement-mcp-wire","title":"Task 2: Implement MCP Wire","text":"<p>File: <code>toolprotocol/wire/mcp.go</code></p> <pre><code>package wire\n\nimport (\n    \"context\"\n    \"encoding/json\"\n\n    \"github.com/ApertureStack/toolfoundation/model\"\n)\n\n// MCPWire implements Wire for MCP protocol.\ntype MCPWire struct {\n    version string\n}\n\n// NewMCPWire creates a new MCP wire adapter.\nfunc NewMCPWire() *MCPWire {\n    return &amp;MCPWire{version: \"2024-11-05\"}\n}\n\nfunc (w *MCPWire) Name() string    { return \"mcp\" }\nfunc (w *MCPWire) Version() string { return w.version }\n\n// MCP JSON-RPC structures\ntype mcpRequest struct {\n    JSONRPC string         `json:\"jsonrpc\"`\n    ID      any            `json:\"id\"`\n    Method  string         `json:\"method\"`\n    Params  map[string]any `json:\"params,omitempty\"`\n}\n\ntype mcpResponse struct {\n    JSONRPC string    `json:\"jsonrpc\"`\n    ID      any       `json:\"id\"`\n    Result  any       `json:\"result,omitempty\"`\n    Error   *mcpError `json:\"error,omitempty\"`\n}\n\ntype mcpError struct {\n    Code    int    `json:\"code\"`\n    Message string `json:\"message\"`\n    Data    any    `json:\"data,omitempty\"`\n}\n\nfunc (w *MCPWire) EncodeRequest(ctx context.Context, req *ToolRequest) ([]byte, error) {\n    mcpReq := mcpRequest{\n        JSONRPC: \"2.0\",\n        ID:      req.ID,\n        Method:  \"tools/call\",\n        Params: map[string]any{\n            \"name\":      req.ToolID,\n            \"arguments\": req.Arguments,\n        },\n    }\n    return json.Marshal(mcpReq)\n}\n\nfunc (w *MCPWire) DecodeRequest(ctx context.Context, data []byte) (*ToolRequest, error) {\n    var mcpReq mcpRequest\n    if err := json.Unmarshal(data, &amp;mcpReq); err != nil {\n        return nil, err\n    }\n\n    req := &amp;ToolRequest{\n        ID:        fmt.Sprintf(\"%v\", mcpReq.ID),\n        Arguments: make(map[string]any),\n    }\n\n    if params, ok := mcpReq.Params[\"name\"].(string); ok {\n        req.ToolID = params\n    }\n    if args, ok := mcpReq.Params[\"arguments\"].(map[string]any); ok {\n        req.Arguments = args\n    }\n\n    return req, nil\n}\n\nfunc (w *MCPWire) EncodeResponse(ctx context.Context, resp *ToolResponse) ([]byte, error) {\n    mcpResp := mcpResponse{\n        JSONRPC: \"2.0\",\n        ID:      resp.ID,\n    }\n\n    if resp.IsError {\n        mcpResp.Error = &amp;mcpError{\n            Code:    resp.Error.Code,\n            Message: resp.Error.Message,\n            Data:    resp.Error.Data,\n        }\n    } else {\n        // Convert content to MCP format\n        content := make([]map[string]any, len(resp.Content))\n        for i, c := range resp.Content {\n            content[i] = map[string]any{\n                \"type\": c.Type,\n                \"text\": c.Text,\n            }\n        }\n        mcpResp.Result = map[string]any{\n            \"content\": content,\n            \"isError\": false,\n        }\n    }\n\n    return json.Marshal(mcpResp)\n}\n\nfunc (w *MCPWire) DecodeResponse(ctx context.Context, data []byte) (*ToolResponse, error) {\n    var mcpResp mcpResponse\n    if err := json.Unmarshal(data, &amp;mcpResp); err != nil {\n        return nil, err\n    }\n\n    resp := &amp;ToolResponse{\n        ID: fmt.Sprintf(\"%v\", mcpResp.ID),\n    }\n\n    if mcpResp.Error != nil {\n        resp.IsError = true\n        resp.Error = &amp;ToolError{\n            Code:    mcpResp.Error.Code,\n            Message: mcpResp.Error.Message,\n            Data:    mcpResp.Error.Data,\n        }\n    } else if result, ok := mcpResp.Result.(map[string]any); ok {\n        if content, ok := result[\"content\"].([]any); ok {\n            for _, c := range content {\n                if cm, ok := c.(map[string]any); ok {\n                    resp.Content = append(resp.Content, Content{\n                        Type: cm[\"type\"].(string),\n                        Text: cm[\"text\"].(string),\n                    })\n                }\n            }\n        }\n    }\n\n    return resp, nil\n}\n\nfunc (w *MCPWire) EncodeToolList(ctx context.Context, tools []model.Tool) ([]byte, error) {\n    mcpTools := make([]map[string]any, len(tools))\n    for i, tool := range tools {\n        mcpTools[i] = map[string]any{\n            \"name\":        tool.ID,\n            \"description\": tool.Description,\n            \"inputSchema\": tool.InputSchema,\n        }\n    }\n\n    return json.Marshal(mcpResponse{\n        JSONRPC: \"2.0\",\n        Result: map[string]any{\n            \"tools\": mcpTools,\n        },\n    })\n}\n\nfunc (w *MCPWire) DecodeToolList(ctx context.Context, data []byte) ([]model.Tool, error) {\n    var mcpResp mcpResponse\n    if err := json.Unmarshal(data, &amp;mcpResp); err != nil {\n        return nil, err\n    }\n\n    result, ok := mcpResp.Result.(map[string]any)\n    if !ok {\n        return nil, nil\n    }\n\n    toolList, ok := result[\"tools\"].([]any)\n    if !ok {\n        return nil, nil\n    }\n\n    tools := make([]model.Tool, len(toolList))\n    for i, t := range toolList {\n        tm := t.(map[string]any)\n        tools[i] = model.Tool{\n            ID:          tm[\"name\"].(string),\n            Name:        tm[\"name\"].(string),\n            Description: tm[\"description\"].(string),\n        }\n    }\n\n    return tools, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/#task-3-implement-a2a-wire","title":"Task 3: Implement A2A Wire","text":"<p>File: <code>toolprotocol/wire/a2a.go</code></p> <pre><code>package wire\n\nimport (\n    \"context\"\n    \"encoding/json\"\n\n    \"github.com/ApertureStack/toolfoundation/model\"\n)\n\n// A2AWire implements Wire for Google A2A protocol.\ntype A2AWire struct {\n    version string\n}\n\n// NewA2AWire creates a new A2A wire adapter.\nfunc NewA2AWire() *A2AWire {\n    return &amp;A2AWire{version: \"1.0\"}\n}\n\nfunc (w *A2AWire) Name() string    { return \"a2a\" }\nfunc (w *A2AWire) Version() string { return w.version }\n\n// A2A uses different message structures focused on agent-to-agent communication\ntype a2aMessage struct {\n    ID        string         `json:\"id\"`\n    Type      string         `json:\"type\"` // \"task\", \"result\", \"error\"\n    AgentID   string         `json:\"agent_id\"`\n    TaskID    string         `json:\"task_id,omitempty\"`\n    Action    string         `json:\"action,omitempty\"`\n    Input     map[string]any `json:\"input,omitempty\"`\n    Output    any            `json:\"output,omitempty\"`\n    Error     *a2aError      `json:\"error,omitempty\"`\n}\n\ntype a2aError struct {\n    Type    string `json:\"type\"`\n    Message string `json:\"message\"`\n}\n\nfunc (w *A2AWire) EncodeRequest(ctx context.Context, req *ToolRequest) ([]byte, error) {\n    msg := a2aMessage{\n        ID:     req.ID,\n        Type:   \"task\",\n        Action: req.ToolID,\n        Input:  req.Arguments,\n    }\n    return json.Marshal(msg)\n}\n\nfunc (w *A2AWire) DecodeRequest(ctx context.Context, data []byte) (*ToolRequest, error) {\n    var msg a2aMessage\n    if err := json.Unmarshal(data, &amp;msg); err != nil {\n        return nil, err\n    }\n\n    return &amp;ToolRequest{\n        ID:        msg.ID,\n        ToolID:    msg.Action,\n        Arguments: msg.Input,\n    }, nil\n}\n\nfunc (w *A2AWire) EncodeResponse(ctx context.Context, resp *ToolResponse) ([]byte, error) {\n    msg := a2aMessage{\n        ID:   resp.ID,\n        Type: \"result\",\n    }\n\n    if resp.IsError {\n        msg.Type = \"error\"\n        msg.Error = &amp;a2aError{\n            Type:    \"execution_error\",\n            Message: resp.Error.Message,\n        }\n    } else {\n        // Combine content into output\n        var text string\n        for _, c := range resp.Content {\n            text += c.Text\n        }\n        msg.Output = text\n    }\n\n    return json.Marshal(msg)\n}\n\nfunc (w *A2AWire) DecodeResponse(ctx context.Context, data []byte) (*ToolResponse, error) {\n    var msg a2aMessage\n    if err := json.Unmarshal(data, &amp;msg); err != nil {\n        return nil, err\n    }\n\n    resp := &amp;ToolResponse{ID: msg.ID}\n\n    if msg.Error != nil {\n        resp.IsError = true\n        resp.Error = &amp;ToolError{\n            Code:    -1,\n            Message: msg.Error.Message,\n        }\n    } else if text, ok := msg.Output.(string); ok {\n        resp.Content = []Content{{Type: \"text\", Text: text}}\n    }\n\n    return resp, nil\n}\n\nfunc (w *A2AWire) EncodeToolList(ctx context.Context, tools []model.Tool) ([]byte, error) {\n    a2aTools := make([]map[string]any, len(tools))\n    for i, tool := range tools {\n        a2aTools[i] = map[string]any{\n            \"action\":      tool.ID,\n            \"description\": tool.Description,\n            \"parameters\":  tool.InputSchema,\n        }\n    }\n    return json.Marshal(map[string]any{\"actions\": a2aTools})\n}\n\nfunc (w *A2AWire) DecodeToolList(ctx context.Context, data []byte) ([]model.Tool, error) {\n    var result map[string]any\n    if err := json.Unmarshal(data, &amp;result); err != nil {\n        return nil, err\n    }\n\n    actions, ok := result[\"actions\"].([]any)\n    if !ok {\n        return nil, nil\n    }\n\n    tools := make([]model.Tool, len(actions))\n    for i, a := range actions {\n        am := a.(map[string]any)\n        tools[i] = model.Tool{\n            ID:          am[\"action\"].(string),\n            Name:        am[\"action\"].(string),\n            Description: am[\"description\"].(string),\n        }\n    }\n    return tools, nil\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/#task-4-create-package-documentation-and-commit","title":"Task 4: Create Package Documentation and Commit","text":"<pre><code>cd /tmp/migration/toolprotocol\n\ngit add -A\ngit commit -m \"feat(wire): add protocol wire adapters\n\nCreate wire package for protocol encoding/decoding.\n\nPackage contents:\n- Wire interface for protocol adapters\n- MCPWire for MCP JSON-RPC 2.0\n- A2AWire for Google A2A protocol\n- ACPWire for IBM ACP protocol\n- Canonical request/response types\n\nFeatures:\n- Protocol-agnostic tool requests\n- Bidirectional conversion\n- Tool list encoding\n- Error propagation\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-171-create-toolwire/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-172: Create tooldiscover</li> <li>PRD-173: Create toolcontent</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-172-create-tooldiscover/","title":"PRD-172: Create tooldiscover","text":"<p>Phase: 7 - Protocol Layer Priority: High Effort: 8 hours Dependencies: PRD-171 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-172-create-tooldiscover/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/discover/</code> for capability discovery across protocols.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-172-create-tooldiscover/#package-contents","title":"Package Contents","text":"<ul> <li>Capability advertisement</li> <li>Service discovery</li> <li>Protocol negotiation</li> <li>In-memory discovery implementation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-172-create-tooldiscover/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Discoverable</code> + <code>Discovery</code> interfaces.</li> <li>Added memory-backed registry with filtering + capability negotiation.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-172-create-tooldiscover/#key-implementation","title":"Key Implementation","text":"<pre><code>package discover\n\n// Discoverable represents a discoverable service.\ntype Discoverable interface {\n    Name() string\n    Description() string\n    Version() string\n    Capabilities() *Capabilities\n    DiscoveryEndpoint() string\n}\n\n// Capabilities describes service capabilities.\ntype Capabilities struct {\n    Tools       bool\n    Resources   bool\n    Prompts     bool\n    Streaming   bool\n    Sampling    bool\n    Extensions  []string\n}\n\n// Discovery performs service discovery.\ntype Discovery struct {\n    registry map[string]Discoverable\n}\n\nfunc (d *Discovery) Register(svc Discoverable) error\nfunc (d *Discovery) Discover(ctx context.Context, filter DiscoveryFilter) ([]Discoverable, error)\nfunc (d *Discovery) Negotiate(ctx context.Context, client, server *Capabilities) (*Capabilities, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-172-create-tooldiscover/#commit-message","title":"Commit Message","text":"<pre><code>feat(discover): add capability discovery\n\nCreate discover package for service discovery.\n\nFeatures:\n- Capability advertisement\n- Service registration\n- Protocol negotiation\n- Agent card support\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-172-create-tooldiscover/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-173: Create toolcontent</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-173-create-toolcontent/","title":"PRD-173: Create toolcontent","text":"<p>Phase: 7 - Protocol Layer Priority: High Effort: 8 hours Dependencies: PRD-120 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-173-create-toolcontent/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/content/</code> for unified content/part abstraction across protocols.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-173-create-toolcontent/#package-contents","title":"Package Contents","text":"<ul> <li>Content type abstraction</li> <li>Text, image, resource, audio, file content</li> <li>MIME type handling</li> <li>Builder utilities</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-173-create-toolcontent/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Content</code> interface with concrete types and builder helpers.</li> <li>Added tests covering each content type and MIME handling.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-173-create-toolcontent/#key-implementation","title":"Key Implementation","text":"<pre><code>package content\n\n// Content represents response content.\ntype Content interface {\n    Type() ContentType\n    MimeType() string\n    Bytes() ([]byte, error)\n}\n\n// ContentType defines content types.\ntype ContentType string\n\nconst (\n    TypeText     ContentType = \"text\"\n    TypeImage    ContentType = \"image\"\n    TypeResource ContentType = \"resource\"\n    TypeAudio    ContentType = \"audio\"\n    TypeFile     ContentType = \"file\"\n)\n\n// TextContent is text-based content.\ntype TextContent struct {\n    Text string\n}\n\n// ImageContent is image-based content.\ntype ImageContent struct {\n    Data     []byte\n    MIMEType string\n    URI      string\n}\n\n// ResourceContent references a resource.\ntype ResourceContent struct {\n    URI      string\n    MIMEType string\n    Text     string\n    Blob     []byte\n}\n\n// Builder builds content.\ntype Builder struct{}\n\nfunc (b *Builder) Text(text string) Content\nfunc (b *Builder) Image(data []byte, mimeType string) Content\nfunc (b *Builder) Resource(uri string) Content\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-173-create-toolcontent/#commit-message","title":"Commit Message","text":"<pre><code>feat(content): add content abstraction\n\nCreate content package for unified content handling.\n\nFeatures:\n- Content type abstraction\n- Text, image, resource types\n- MIME type handling\n- Content builder\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-173-create-toolcontent/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-174: Create tooltask</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-174-create-tooltask/","title":"PRD-174: Create tooltask","text":"<p>Phase: 7 - Protocol Layer Priority: High Effort: 10 hours Dependencies: PRD-140, PRD-173 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-174-create-tooltask/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/task/</code> for task lifecycle management across protocols.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-174-create-tooltask/#package-contents","title":"Package Contents","text":"<ul> <li>Task creation and tracking</li> <li>State machine (pending \u2192 running \u2192 complete/failed/cancelled)</li> <li>Progress updates</li> <li>Subscriptions + cancellation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-174-create-tooltask/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Manager</code> interface with in-memory store and strict transitions.</li> <li>Added subscription channels for progress updates.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-174-create-tooltask/#key-implementation","title":"Key Implementation","text":"<pre><code>package task\n\nimport \"context\"\n\n// State represents task state.\ntype State string\n\nconst (\n    StatePending   State = \"pending\"\n    StateRunning   State = \"running\"\n    StateComplete  State = \"complete\"\n    StateFailed    State = \"failed\"\n    StateCancelled State = \"cancelled\"\n)\n\n// Task represents a long-running task.\ntype Task struct {\n    ID          string\n    State       State\n    Progress    float64\n    Message     string\n    Result      any\n    Error       error\n    CreatedAt   time.Time\n    UpdatedAt   time.Time\n    CompletedAt *time.Time\n}\n\n// Manager manages task lifecycle.\ntype Manager struct {\n    tasks map[string]*Task\n    mu    sync.RWMutex\n}\n\nfunc (m *Manager) Create(ctx context.Context, id string) (*Task, error)\nfunc (m *Manager) Get(ctx context.Context, id string) (*Task, error)\nfunc (m *Manager) Update(ctx context.Context, id string, progress float64, message string) error\nfunc (m *Manager) Complete(ctx context.Context, id string, result any) error\nfunc (m *Manager) Fail(ctx context.Context, id string, err error) error\nfunc (m *Manager) Cancel(ctx context.Context, id string) error\nfunc (m *Manager) Subscribe(ctx context.Context, id string) (&lt;-chan *Task, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-174-create-tooltask/#commit-message","title":"Commit Message","text":"<pre><code>feat(task): add task lifecycle management\n\nCreate task package for long-running operations.\n\nFeatures:\n- Task state machine\n- Progress tracking\n- Task cancellation\n- Event subscription\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-174-create-tooltask/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-175: Create toolstream</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-175-create-toolstream/","title":"PRD-175: Create toolstream","text":"<p>Phase: 7 - Protocol Layer Priority: High Effort: 8 hours Dependencies: PRD-170 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-175-create-toolstream/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/stream/</code> for streaming and incremental updates.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-175-create-toolstream/#package-contents","title":"Package Contents","text":"<ul> <li>Stream abstraction</li> <li>Progress notifications + partial results</li> <li>Backpressure handling</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-175-create-toolstream/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Source</code>/<code>Sink</code> with buffered streams and backpressure options.</li> <li>Added event types for progress/partial/complete/error/heartbeat.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-175-create-toolstream/#key-implementation","title":"Key Implementation","text":"<pre><code>package stream\n\nimport \"context\"\n\n// Stream represents a streaming response.\ntype Stream interface {\n    // Send sends an event.\n    Send(ctx context.Context, event Event) error\n\n    // Close closes the stream.\n    Close() error\n\n    // Done returns a channel closed when stream ends.\n    Done() &lt;-chan struct{}\n}\n\n// Event represents a stream event.\ntype Event struct {\n    Type    EventType\n    ID      string\n    Data    any\n    Retry   int\n}\n\n// EventType defines event types.\ntype EventType string\n\nconst (\n    EventProgress    EventType = \"progress\"\n    EventPartial     EventType = \"partial\"\n    EventComplete    EventType = \"complete\"\n    EventError       EventType = \"error\"\n    EventHeartbeat   EventType = \"heartbeat\"\n)\n\n// Source creates streams.\ntype Source struct{}\n\nfunc (s *Source) NewStream(ctx context.Context) Stream\nfunc (s *Source) NewBufferedStream(ctx context.Context, size int) Stream\n\n// Sink consumes streams.\ntype Sink struct{}\n\nfunc (s *Sink) Consume(ctx context.Context, stream Stream, handler EventHandler) error\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-175-create-toolstream/#commit-message","title":"Commit Message","text":"<pre><code>feat(stream): add streaming support\n\nCreate stream package for incremental updates.\n\nFeatures:\n- Stream abstraction\n- Event types\n- Progress notifications\n- Backpressure via buffering\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-175-create-toolstream/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-176: Create toolsession</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-176-create-toolsession/","title":"PRD-176: Create toolsession","text":"<p>Phase: 7 - Protocol Layer Priority: Medium Effort: 6 hours Dependencies: PRD-120 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-176-create-toolsession/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/session/</code> for session management.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-176-create-toolsession/#package-contents","title":"Package Contents","text":"<ul> <li>Session lifecycle</li> <li>Context preservation</li> <li>Session state storage</li> <li>TTL cleanup</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-176-create-toolsession/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Store</code> interface with memory-backed store + TTL cleanup.</li> <li>Added context helpers for request-scoped sessions.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-176-create-toolsession/#key-implementation","title":"Key Implementation","text":"<pre><code>package session\n\nimport \"context\"\n\n// Session represents a client session.\ntype Session struct {\n    ID        string\n    ClientID  string\n    State     map[string]any\n    CreatedAt time.Time\n    ExpiresAt time.Time\n}\n\n// Store manages sessions.\ntype Store interface {\n    Create(ctx context.Context, clientID string) (*Session, error)\n    Get(ctx context.Context, id string) (*Session, error)\n    Update(ctx context.Context, session *Session) error\n    Delete(ctx context.Context, id string) error\n    Cleanup(ctx context.Context) error\n}\n\n// MemoryStore is an in-memory session store.\ntype MemoryStore struct {\n    sessions map[string]*Session\n    mu       sync.RWMutex\n    ttl      time.Duration\n}\n\nfunc NewMemoryStore(ttl time.Duration) *MemoryStore\n\n// Context helpers\nfunc WithSession(ctx context.Context, session *Session) context.Context\nfunc FromContext(ctx context.Context) (*Session, bool)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-176-create-toolsession/#commit-message","title":"Commit Message","text":"<pre><code>feat(session): add session management\n\nCreate session package for state management.\n\nFeatures:\n- Session lifecycle\n- In-memory store\n- Context integration\n- Automatic cleanup\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-176-create-toolsession/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-177: Create toolelicit</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-177-create-toolelicit/","title":"PRD-177: Create toolelicit","text":"<p>Phase: 7 - Protocol Layer Priority: Medium Effort: 6 hours Dependencies: PRD-173 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-177-create-toolelicit/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/elicit/</code> for user input elicitation (MCP feature).</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-177-create-toolelicit/#package-contents","title":"Package Contents","text":"<ul> <li>Elicitation requests</li> <li>Input types (text, confirmation, choice, form)</li> <li>Response handling</li> <li>Timeout management</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-177-create-toolelicit/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented request/response types with JSON Schema support for forms.</li> <li>Added <code>Elicitor</code> and <code>Handler</code> interfaces for server/client flows.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-177-create-toolelicit/#key-implementation","title":"Key Implementation","text":"<pre><code>package elicit\n\nimport \"context\"\n\n// Request represents an elicitation request.\ntype Request struct {\n    ID          string\n    Type        RequestType\n    Message     string\n    Schema      any        // JSON Schema for structured input\n    Choices     []Choice   // For choice type\n    Default     any\n    Timeout     time.Duration\n}\n\n// RequestType defines elicitation types.\ntype RequestType string\n\nconst (\n    TypeText         RequestType = \"text\"\n    TypeConfirmation RequestType = \"confirmation\"\n    TypeChoice       RequestType = \"choice\"\n    TypeForm         RequestType = \"form\"\n)\n\n// Choice represents a selection option.\ntype Choice struct {\n    ID          string\n    Label       string\n    Description string\n}\n\n// Response represents user response.\ntype Response struct {\n    RequestID string\n    Value     any\n    Cancelled bool\n    Timeout   bool\n}\n\n// Elicitor handles user input requests.\ntype Elicitor interface {\n    Elicit(ctx context.Context, req *Request) (*Response, error)\n}\n\n// Handler processes elicitation on client side.\ntype Handler interface {\n    Handle(ctx context.Context, req *Request) (*Response, error)\n}\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-177-create-toolelicit/#commit-message","title":"Commit Message","text":"<pre><code>feat(elicit): add input elicitation\n\nCreate elicit package for user input requests.\n\nFeatures:\n- Multiple input types\n- JSON Schema validation\n- Timeout handling\n- Choice selection\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-177-create-toolelicit/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-178: Create toolresource</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-178-create-toolresource/","title":"PRD-178: Create toolresource","text":"<p>Phase: 7 - Protocol Layer Priority: Medium Effort: 10 hours Dependencies: PRD-130 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-178-create-toolresource/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/resource/</code> for MCP Resources support.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-178-create-toolresource/#package-contents","title":"Package Contents","text":"<ul> <li>Resource definition and storage</li> <li>Resource templates</li> <li>Subscription management</li> <li>Static provider helpers</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-178-create-toolresource/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Provider</code> interface, registry, and subscription manager.</li> <li>Added static provider with template support and tests.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-178-create-toolresource/#key-implementation","title":"Key Implementation","text":"<pre><code>package resource\n\nimport \"context\"\n\n// Resource represents an MCP resource.\ntype Resource struct {\n    URI         string\n    Name        string\n    Description string\n    MIMEType    string\n}\n\n// Contents represents resource contents.\ntype Contents struct {\n    URI      string\n    MIMEType string\n    Text     string\n    Blob     []byte\n}\n\n// Template represents a resource template.\ntype Template struct {\n    URITemplate string\n    Name        string\n    Description string\n    MIMEType    string\n}\n\n// Provider serves resources.\ntype Provider interface {\n    List(ctx context.Context) ([]Resource, error)\n    Read(ctx context.Context, uri string) (*Contents, error)\n    Templates(ctx context.Context) ([]Template, error)\n}\n\n// Subscriber receives resource updates.\ntype Subscriber interface {\n    Subscribe(ctx context.Context, uri string) (&lt;-chan *Contents, error)\n    Unsubscribe(ctx context.Context, uri string) error\n}\n\n// Registry manages resource providers.\ntype Registry struct {\n    providers map[string]Provider\n    mu        sync.RWMutex\n}\n\nfunc (r *Registry) Register(scheme string, provider Provider) error\nfunc (r *Registry) List(ctx context.Context) ([]Resource, error)\nfunc (r *Registry) Read(ctx context.Context, uri string) (*Contents, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-178-create-toolresource/#commit-message","title":"Commit Message","text":"<pre><code>feat(resource): add MCP resources support\n\nCreate resource package for content serving.\n\nFeatures:\n- Resource definition\n- Template support\n- Subscription management\n- Multi-provider registry\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-178-create-toolresource/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-179: Create toolprompt</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-179-create-toolprompt/","title":"PRD-179: Create toolprompt","text":"<p>Phase: 7 - Protocol Layer Priority: Medium Effort: 8 hours Dependencies: PRD-173 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-179-create-toolprompt/#objective","title":"Objective","text":"<p>Create <code>toolprotocol/prompt/</code> for MCP Prompts support.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-179-create-toolprompt/#package-contents","title":"Package Contents","text":"<ul> <li>Prompt definition and storage</li> <li>Prompt templates with arguments</li> <li>Message generation</li> <li>Prompt registry</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-179-create-toolprompt/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Implemented <code>Provider</code> + registry with argument validation.</li> <li>Added helpers for message/content creation.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-179-create-toolprompt/#key-implementation","title":"Key Implementation","text":"<pre><code>package prompt\n\nimport \"context\"\n\n// Prompt represents an MCP prompt.\ntype Prompt struct {\n    Name        string\n    Description string\n    Arguments   []Argument\n}\n\n// Argument describes a prompt argument.\ntype Argument struct {\n    Name        string\n    Description string\n    Required    bool\n}\n\n// Message represents a generated message.\ntype Message struct {\n    Role    string // \"user\" or \"assistant\"\n    Content Content\n}\n\n// Content represents message content.\ntype Content struct {\n    Type     string // \"text\", \"image\", \"resource\"\n    Text     string\n    MIMEType string\n    Data     []byte\n    Resource *ResourceRef\n}\n\n// ResourceRef references a resource.\ntype ResourceRef struct {\n    URI string\n}\n\n// Provider serves prompts.\ntype Provider interface {\n    List(ctx context.Context) ([]Prompt, error)\n    Get(ctx context.Context, name string, args map[string]string) ([]Message, error)\n}\n\n// Registry manages prompt providers.\ntype Registry struct {\n    prompts map[string]*Prompt\n    handlers map[string]PromptHandler\n    mu      sync.RWMutex\n}\n\n// PromptHandler generates messages from arguments.\ntype PromptHandler func(ctx context.Context, args map[string]string) ([]Message, error)\n\nfunc (r *Registry) Register(prompt Prompt, handler PromptHandler) error\nfunc (r *Registry) List(ctx context.Context) ([]Prompt, error)\nfunc (r *Registry) Get(ctx context.Context, name string, args map[string]string) ([]Message, error)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-179-create-toolprompt/#commit-message","title":"Commit Message","text":"<pre><code>feat(prompt): add MCP prompts support\n\nCreate prompt package for prompt templates.\n\nFeatures:\n- Prompt definition\n- Argument handling\n- Message generation\n- Provider registry\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-179-create-toolprompt/#next-steps","title":"Next Steps","text":"<ul> <li>Gate G5: Protocol layer complete (all 10 packages)</li> <li>PRD-180: Update metatools-mcp</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/","title":"PRD-180: Update metatools-mcp","text":"<p>Phase: 8 - Integration Priority: Critical Effort: 12 hours Dependencies: All Phase 2-7 PRDs Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/#objective","title":"Objective","text":"<p>Update metatools-mcp to use all consolidated repositories instead of standalone repos.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/#task-1-update-gomod","title":"Task 1: Update go.mod","text":"<p>Replace all standalone imports with consolidated repos:</p> <pre><code>// Before\nrequire (\n    github.com/jonwraymond/toolmodel v0.x.x\n    github.com/jonwraymond/tooladapter v0.x.x\n    github.com/jonwraymond/toolindex v0.x.x\n    github.com/jonwraymond/toolsearch v0.x.x\n    github.com/jonwraymond/toolrun v0.x.x\n    github.com/jonwraymond/toolruntime v0.x.x\n    github.com/jonwraymond/toolcode v0.x.x\n    github.com/jonwraymond/toolset v0.x.x\n    github.com/jonwraymond/toolobserve v0.x.x\n    github.com/jonwraymond/toolcache v0.x.x\n)\n\n// After\nrequire (\n    github.com/jonwraymond/toolfoundation v0.1.0\n    github.com/jonwraymond/tooldiscovery v0.1.0\n    github.com/jonwraymond/toolexec v0.1.0\n    github.com/jonwraymond/toolcompose v0.1.0\n    github.com/jonwraymond/toolops v0.1.0\n    github.com/jonwraymond/toolprotocol v0.1.0\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/#task-2-update-import-statements","title":"Task 2: Update Import Statements","text":"<pre><code># Find all files with old imports\ngrep -r \"github.com/jonwraymond/tool\" --include=\"*.go\" | grep -v \"toolfoundation\\|tooldiscovery\\|toolexec\\|toolcompose\\|toolops\\|toolprotocol\"\n\n# Update imports using sed\nfind . -name \"*.go\" -exec sed -i '' \\\n  -e 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' \\\n  -e 's|github.com/jonwraymond/tooladapter|github.com/jonwraymond/toolfoundation/adapter|g' \\\n  -e 's|github.com/jonwraymond/toolindex|github.com/jonwraymond/tooldiscovery/index|g' \\\n  -e 's|github.com/jonwraymond/toolsearch|github.com/jonwraymond/tooldiscovery/search|g' \\\n  -e 's|github.com/jonwraymond/toolrun|github.com/jonwraymond/toolexec/run|g' \\\n  -e 's|github.com/jonwraymond/toolruntime|github.com/jonwraymond/toolexec/runtime|g' \\\n  -e 's|github.com/jonwraymond/toolcode|github.com/jonwraymond/toolexec/code|g' \\\n  -e 's|github.com/jonwraymond/metatools-mcp/internal/backend|github.com/jonwraymond/toolexec/backend|g' \\\n  -e 's|github.com/jonwraymond/toolset|github.com/jonwraymond/toolcompose/set|g' \\\n  -e 's|github.com/jonwraymond/toolobserve|github.com/jonwraymond/toolops/observe|g' \\\n  -e 's|github.com/jonwraymond/toolcache|github.com/jonwraymond/toolops/cache|g' \\\n  {} \\;\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/#task-3-remove-internal-packages","title":"Task 3: Remove Internal Packages","text":"<p>Extract code that was internalized into consolidated repos:</p> <pre><code># Remove internal packages now in consolidated repos\nrm -rf internal/backend/  # Now in toolexec/backend\nrm -rf internal/auth/     # Now in toolops/auth\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/#task-4-update-internal-references","title":"Task 4: Update Internal References","text":"<p>Update remaining internal code to use new packages:</p> <pre><code>// Before\nimport \"metatools-mcp/internal/auth\"\n\n// After\nimport \"github.com/jonwraymond/toolops/auth\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/#task-5-build-and-test","title":"Task 5: Build and Test","text":"<pre><code>go mod tidy\ngo build ./...\ngo test ./...\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/#task-6-commit","title":"Task 6: Commit","text":"<pre><code>git add -A\ngit commit -m \"feat: migrate to consolidated repositories\n\nUpdate all imports to use consolidated ApertureStack repos:\n\nFoundation:\n- toolmodel \u2192 toolfoundation/model\n- tooladapter \u2192 toolfoundation/adapter\n\nDiscovery:\n- toolindex \u2192 tooldiscovery/index\n- toolsearch \u2192 tooldiscovery/search\n\nExecution:\n- toolrun \u2192 toolexec/run\n- toolruntime \u2192 toolexec/runtime\n- toolcode \u2192 toolexec/code\n\nComposition:\n- toolset \u2192 toolcompose/set\n\nOperations:\n- toolobserve \u2192 toolops/observe\n- toolcache \u2192 toolops/cache\n\n## Implementation Summary\n\n- All code imports updated to consolidated packages under `github.com/jonwraymond`.\n- Docs/diagrams updated to reference consolidated layers and build tags.\n- go.mod cleaned to depend on tooldiscovery/toolexec/toolfoundation.\n- internal/auth \u2192 toolops/auth\n\nBREAKING CHANGE: All import paths have changed.\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All old imports replaced</li> <li>[x] go mod tidy succeeds</li> <li>[x] go build succeeds</li> <li>[x] All tests pass</li> <li>[ ] MCP server runs correctly</li> <li>[ ] Tool execution works</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-180-update-metatools-mcp/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-181: Update ai-tools-stack</li> <li>PRD-182: Documentation Site</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-181-update-ai-tools-stack/","title":"PRD-181: Update ai-tools-stack","text":"<p>Phase: 8 - Integration Priority: High Effort: 4 hours Dependencies: PRD-180 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-181-update-ai-tools-stack/#objective","title":"Objective","text":"<p>Update ai-tools-stack coordination repository with new consolidated structure.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-181-update-ai-tools-stack/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-181-update-ai-tools-stack/#task-1-update-versionsmd","title":"Task 1: Update VERSIONS.md","text":"<p>Replace standalone repos with consolidated repos:</p> <pre><code># ApertureStack Version Matrix\n\n## Consolidated Repositories (v0.1.0)\n\n| Repository | Version | Packages |\n|------------|---------|----------|\n| toolfoundation | v0.1.0 | model, adapter, version |\n| tooldiscovery | v0.1.0 | index, search, semantic, docs |\n| toolexec | v0.1.0 | run, runtime, code, backend |\n| toolcompose | v0.1.0 | set, skill |\n| toolops | v0.1.0 | observe, cache, resilience, health, auth |\n| toolprotocol | v0.1.0 | transport, wire, discover, content, task, stream, session, elicit, resource, prompt |\n| metatools-mcp | v0.2.0 | (uses all above) |\n\n## Compatibility Matrix\n\n| metatools-mcp | toolfoundation | tooldiscovery | toolexec | toolcompose | toolops | toolprotocol |\n|---------------|----------------|---------------|----------|-------------|---------|--------------|\n| v0.2.0 | v0.1.0 | v0.1.0 | v0.1.0 | v0.1.0 | v0.1.0 | v0.1.0 |\n\n## Archived Repositories\n\nThe following repositories have been consolidated and archived:\n\n- toolmodel \u2192 toolfoundation/model\n- tooladapter \u2192 toolfoundation/adapter\n- toolindex \u2192 tooldiscovery/index\n- toolsearch \u2192 tooldiscovery/search\n- toolsemantic \u2192 tooldiscovery/semantic\n- tooldocs \u2192 tooldiscovery/docs\n- toolrun \u2192 toolexec/run\n- toolruntime \u2192 toolexec/runtime\n- toolcode \u2192 toolexec/code\n- toolset \u2192 toolcompose/set\n- toolskill \u2192 toolcompose/skill\n- toolobserve \u2192 toolops/observe\n- toolcache \u2192 toolops/cache\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-181-update-ai-tools-stack/#task-2-update-gomod","title":"Task 2: Update go.mod","text":"<pre><code>module github.com/jonwraymond/ai-tools-stack\n\ngo 1.24\n\nrequire (\n    github.com/jonwraymond/toolfoundation v0.1.0\n    github.com/jonwraymond/tooldiscovery v0.1.0\n    github.com/jonwraymond/toolexec v0.1.0\n    github.com/jonwraymond/toolcompose v0.1.0\n    github.com/jonwraymond/toolops v0.1.0\n    github.com/jonwraymond/toolprotocol v0.1.0\n    github.com/jonwraymond/metatools-mcp v0.5.0\n)\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-181-update-ai-tools-stack/#task-3-update-readmemd","title":"Task 3: Update README.md","text":"<pre><code># ApertureStack\n\nAI Tool Ecosystem for building, discovering, and executing AI agent tools.\n\n## Repositories\n\n| Repository | Description |\n|------------|-------------|\n| [toolfoundation](https://github.com/jonwraymond/toolfoundation) | Core schemas, adapters, versioning |\n| [tooldiscovery](https://github.com/jonwraymond/tooldiscovery) | Registry, search, semantic, docs |\n| [toolexec](https://github.com/jonwraymond/toolexec) | Execution, runtime, code |\n| [toolcompose](https://github.com/jonwraymond/toolcompose) | Toolsets, skills |\n| [toolops](https://github.com/jonwraymond/toolops) | Observability, caching, auth |\n| [toolprotocol](https://github.com/jonwraymond/toolprotocol) | MCP, A2A, ACP protocols |\n| [metatools-mcp](https://github.com/jonwraymond/metatools-mcp) | MCP server |\n\n## Quick Start\n\n\\`\\`\\`bash\ngo get github.com/jonwraymond/metatools-mcp@latest\n\\`\\`\\`\n\n## Documentation\n\nSee the GitHub Pages docs site for ai-tools-stack\n\n## Implementation Summary\n\n- mkdocs nav + multirepo imports updated to consolidated repos.\n- docs workflow + changelog/version scripts updated to consolidated repos.\n- VERSIONS matrix aligned with consolidated repo tags.\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-181-update-ai-tools-stack/#task-4-update-scripts","title":"Task 4: Update Scripts","text":"<p>Update any automation scripts to use new repo names.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-181-update-ai-tools-stack/#task-5-commit","title":"Task 5: Commit","text":"<pre><code>git add -A\ngit commit -m \"feat: update for consolidated repositories\n\n- Update VERSIONS.md with new repo structure\n- Update go.mod dependencies\n- Update README with new repos\n- Archive old repo references\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-181-update-ai-tools-stack/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-182: Documentation Site</li> <li>PRD-190: Archive Old Repos</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-182-documentation-site/","title":"PRD-182: Documentation Site","text":"<p>Phase: 8 - Integration Priority: Medium Effort: 6 hours Dependencies: PRD-181 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-182-documentation-site/#objective","title":"Objective","text":"<p>Update MkDocs documentation site with consolidated repository structure.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-182-documentation-site/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-182-documentation-site/#task-1-update-mkdocsyml","title":"Task 1: Update mkdocs.yml","text":"<pre><code>site_name: ApertureStack\nsite_url: https://jonwraymond.github.io/ai-tools-stack/\n\nnav:\n  - Home: index.md\n  - Getting Started:\n    - Installation: getting-started/install.md\n    - Quick Start: getting-started/quickstart.md\n  - Foundation:\n    - Overview: foundation/index.md\n    - Model: foundation/model.md\n    - Adapter: foundation/adapter.md\n    - Version: foundation/version.md\n  - Discovery:\n    - Overview: discovery/index.md\n    - Index: discovery/index-pkg.md\n    - Search: discovery/search.md\n    - Semantic: discovery/semantic.md\n    - Docs: discovery/docs.md\n  - Execution:\n    - Overview: execution/index.md\n    - Run: execution/run.md\n    - Runtime: execution/runtime.md\n    - Code: execution/code.md\n    - Backend: execution/backend.md\n  - Composition:\n    - Overview: composition/index.md\n    - Set: composition/set.md\n    - Skill: composition/skill.md\n  - Operations:\n    - Overview: operations/index.md\n    - Observe: operations/observe.md\n    - Cache: operations/cache.md\n    - Auth: operations/auth.md\n    - Resilience: operations/resilience.md\n    - Health: operations/health.md\n  - Protocol:\n    - Overview: protocol/index.md\n    - Transport: protocol/transport.md\n    - Wire: protocol/wire.md\n    - MCP: protocol/mcp.md\n    - A2A: protocol/a2a.md\n  - API Reference:\n    - metatools-mcp: api/metatools-mcp.md\n\ntheme:\n  name: material\n  features:\n    - navigation.tabs\n    - navigation.sections\n    - search.suggest\n\nplugins:\n  - search\n  - multirepo:\n      repos:\n        - name: toolfoundation\n          import: github.com/jonwraymond/toolfoundation/docs\n        - name: tooldiscovery\n          import: github.com/jonwraymond/tooldiscovery/docs\n        - name: toolexec\n          import: github.com/jonwraymond/toolexec/docs\n        - name: toolcompose\n          import: github.com/jonwraymond/toolcompose/docs\n        - name: toolops\n          import: github.com/jonwraymond/toolops/docs\n        - name: toolprotocol\n          import: github.com/jonwraymond/toolprotocol/docs\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-182-documentation-site/#task-2-update-landing-page","title":"Task 2: Update Landing Page","text":"<pre><code># ApertureStack\n\nBuild, discover, and execute AI agent tools with a unified ecosystem.\n\n## Architecture\n\n```mermaid\ngraph TB\n    subgraph \"Application Layer\"\n        metatools-mcp[\"metatools-mcp\"]\n    end\n\n    subgraph \"Protocol Layer\"\n        toolprotocol[\"toolprotocol\"]\n    end\n\n    subgraph \"Operations Layer\"\n        toolops[\"toolops\"]\n    end\n\n    subgraph \"Composition Layer\"\n        toolcompose[\"toolcompose\"]\n    end\n\n    subgraph \"Execution Layer\"\n        toolexec[\"toolexec\"]\n    end\n\n    subgraph \"Discovery Layer\"\n        tooldiscovery[\"tooldiscovery\"]\n    end\n\n    subgraph \"Foundation Layer\"\n        toolfoundation[\"toolfoundation\"]\n    end\n\n    metatools-mcp --&gt; toolprotocol\n    metatools-mcp --&gt; toolops\n    metatools-mcp --&gt; toolcompose\n    toolprotocol --&gt; toolfoundation\n    toolops --&gt; toolfoundation\n    toolcompose --&gt; toolexec\n    toolcompose --&gt; tooldiscovery\n    toolexec --&gt; toolfoundation\n    tooldiscovery --&gt; toolfoundation\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-182-documentation-site/#repositories","title":"Repositories","text":"Layer Repository Packages Foundation toolfoundation model, adapter, version Discovery tooldiscovery index, search, semantic, docs Execution toolexec run, runtime, code, backend Composition toolcompose set, skill Operations toolops observe, cache, auth, resilience, health Protocol toolprotocol transport, wire, discover, content, task, stream, session, elicit, resource, prompt"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-182-documentation-site/#quick-start","title":"Quick Start","text":"<p><pre><code># Install metatools-mcp\ngo install github.com/jonwraymond/metatools-mcp/cmd/metatools@latest\n\n# Run MCP server\nmetatools serve\n\n## Implementation Summary\n\n- mkdocs nav and multirepo imports aligned with consolidated repos.\n- D2 diagrams re-rendered and embedded into component docs.\n- GitHub Pages publish flow uses mike for `latest`/`stable` versions.\n</code></pre> <pre><code>### Task 3: Build and Deploy\n\n```bash\n# Build docs\nmkdocs build\n\n# Deploy to GitHub Pages\nmkdocs gh-deploy\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-182-documentation-site/#task-4-commit","title":"Task 4: Commit","text":"<pre><code>git add -A\ngit commit -m \"docs: update for consolidated repositories\n\n- Restructure navigation for 6 consolidated repos\n- Update architecture diagrams\n- Add multirepo imports\n- Update landing page\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-182-documentation-site/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-190: Archive Old Repos</li> <li>Gate G6: Integration complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-190-archive-old-repos/","title":"PRD-190: Archive Old Repos","text":"<p>Phase: 9 - Cleanup Priority: High Effort: 2 hours Dependencies: PRD-180 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-190-archive-old-repos/#objective","title":"Objective","text":"<p>Archive all 13 standalone repositories that have been consolidated.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-190-archive-old-repos/#repositories-to-archive","title":"Repositories to Archive","text":"Repository Migrated To toolmodel toolfoundation/model tooladapter toolfoundation/adapter toolindex tooldiscovery/index toolsearch tooldiscovery/search toolsemantic tooldiscovery/semantic tooldocs tooldiscovery/tooldoc toolrun toolexec/run toolruntime toolexec/runtime toolcode toolexec/code toolset toolcompose/set toolskill toolcompose/skill toolobserve toolops/observe toolcache toolops/cache"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-190-archive-old-repos/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-190-archive-old-repos/#task-1-add-deprecation-notices","title":"Task 1: Add Deprecation Notices","text":"<p>For each repo, update README.md:</p> <pre><code># \u26a0\ufe0f DEPRECATED\n\nThis repository has been archived. The code has been migrated to:\n\n**[toolfoundation](https://github.com/jonwraymond/toolfoundation)** (model package)\n\n## Migration\n\nUpdate your imports:\n\n```go\n// Before\nimport \"github.com/jonwraymond/toolmodel\"\n\n// After\nimport \"github.com/jonwraymond/toolfoundation/model\"\n</code></pre> <p>See the stack migration guide for details: https://jonwraymond.github.io/ai-tools-stack/operations/migration-guide/ <pre><code>### Task 2: Create Migration Guides\n\n**File: MIGRATION.md** (per repo)\n\n```markdown\n# Migration Guide\n\n## Import Changes\n\n| Old | New |\n|-----|-----|\n| `github.com/jonwraymond/toolmodel` | `github.com/jonwraymond/toolfoundation/model` |\n\n## Breaking Changes\n\n- Package name changed from `toolmodel` to `model`\n- All functionality preserved\n\n## Steps\n\n1. Update go.mod:\n   ```bash\ngo get github.com/jonwraymond/toolfoundation@latest\n   ```\n\n2. Update imports:\n   ```bash\nsed -i 's|github.com/jonwraymond/toolmodel|github.com/jonwraymond/toolfoundation/model|g' *.go\n   ```\n\n3. Remove old dependency:\n   ```bash\n   go mod tidy\n   ```\n</code></pre></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-190-archive-old-repos/#task-3-archive-repositories","title":"Task 3: Archive Repositories","text":"<pre><code>REPOS=(\n  toolmodel\n  tooladapter\n  toolindex\n  toolsearch\n  toolsemantic\n  tooldocs\n  toolrun\n  toolruntime\n  toolcode\n  toolset\n  toolskill\n  toolobserve\n  toolcache\n)\n\nfor repo in \"${REPOS[@]}\"; do\n  echo \"Archiving jonwraymond/$repo...\"\n\n  # Update README with deprecation notice\n  # (done manually per repo with appropriate redirect)\n\n  # Archive the repository\n  gh repo archive \"jonwraymond/$repo\" --yes\n\n  echo \"\u2713 $repo archived\"\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-190-archive-old-repos/#task-4-verify-archives","title":"Task 4: Verify Archives","text":"<pre><code># List archived repos\ngh repo list jonwraymond --archived --limit 20\n\n# Verify each is read-only\nfor repo in toolmodel tooladapter toolindex toolsearch; do\n  gh repo view \"jonwraymond/$repo\" --json isArchived -q '.isArchived'\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-190-archive-old-repos/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] All 13 repos have deprecation notices</li> <li>[x] All 13 repos have MIGRATION.md</li> <li>[x] All 13 repos are archived</li> <li>[x] Archives are read-only</li> <li>[x] Redirects work (README links to new location)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-190-archive-old-repos/#rollback-plan","title":"Rollback Plan","text":"<pre><code># Unarchive a repo if needed\ngh repo unarchive jonwraymond/toolmodel --yes\n\n## Verification (2026-02-01)\n\n- All 13 repos archived under `jonwraymond`.\n- README contains deprecation notice; MIGRATION.md present in each repo.\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-190-archive-old-repos/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-191: Update Submodules</li> <li>PRD-192: Validation</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/","title":"PRD-191: Update Submodules","text":"<p>Phase: 9 - Cleanup Priority: High Effort: 2 hours Dependencies: PRD-190 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#objective","title":"Objective","text":"<p>Update ApertureStack root to use new consolidated submodules.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#task-1-remove-old-submodules","title":"Task 1: Remove Old Submodules","text":"<pre><code>cd /Users/jraymond/Documents/Projects/ApertureStack\n\n# Remove old submodules\nOLD_REPOS=(\n  toolmodel\n  tooladapter\n  toolindex\n  toolsearch\n  toolsemantic\n  tooldocs\n  toolrun\n  toolruntime\n  toolcode\n  toolset\n  toolskill\n  toolobserve\n  toolcache\n)\n\nfor repo in \"${OLD_REPOS[@]}\"; do\n  git submodule deinit -f \"$repo\" 2&gt;/dev/null || true\n  git rm -f \"$repo\" 2&gt;/dev/null || true\n  rm -rf \".git/modules/$repo\" 2&gt;/dev/null || true\ndone\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#task-2-add-new-submodules","title":"Task 2: Add New Submodules","text":"<pre><code>cd /Users/jraymond/Documents/Projects/ApertureStack\n\n# Add consolidated submodules\ngit submodule add git@github.com:jonwraymond/toolfoundation.git toolfoundation\ngit submodule add git@github.com:jonwraymond/tooldiscovery.git tooldiscovery\ngit submodule add git@github.com:jonwraymond/toolexec.git toolexec\ngit submodule add git@github.com:jonwraymond/toolcompose.git toolcompose\ngit submodule add git@github.com:jonwraymond/toolops.git toolops\ngit submodule add git@github.com:jonwraymond/toolprotocol.git toolprotocol\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#task-3-update-gitmodules","title":"Task 3: Update .gitmodules","text":"<p>Verify <code>.gitmodules</code> looks like:</p> <pre><code>[submodule \"toolfoundation\"]\n    path = toolfoundation\n    url = git@github.com:jonwraymond/toolfoundation.git\n\n[submodule \"tooldiscovery\"]\n    path = tooldiscovery\n    url = git@github.com:jonwraymond/tooldiscovery.git\n\n[submodule \"toolexec\"]\n    path = toolexec\n    url = git@github.com:jonwraymond/toolexec.git\n\n[submodule \"toolcompose\"]\n    path = toolcompose\n    url = git@github.com:jonwraymond/toolcompose.git\n\n[submodule \"toolops\"]\n    path = toolops\n    url = git@github.com:jonwraymond/toolops.git\n\n[submodule \"toolprotocol\"]\n    path = toolprotocol\n    url = git@github.com:jonwraymond/toolprotocol.git\n\n[submodule \"metatools-mcp\"]\n    path = metatools-mcp\n    url = git@github.com:jonwraymond/metatools-mcp.git\n\n[submodule \"ai-tools-stack\"]\n    path = ai-tools-stack\n    url = git@github.com:jonwraymond/ai-tools-stack.git\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#task-4-commit-changes","title":"Task 4: Commit Changes","text":"<pre><code>git add .gitmodules\ngit add toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol\n\ngit commit -m \"feat: update submodules to consolidated repos\n\nRemove old standalone submodules:\n- toolmodel, tooladapter\n- toolindex, toolsearch, toolsemantic, tooldocs\n- toolrun, toolruntime, toolcode\n- toolset, toolskill\n- toolobserve, toolcache\n\nAdd consolidated submodules:\n- toolfoundation (model, adapter, version)\n- tooldiscovery (index, search, semantic, docs)\n- toolexec (run, runtime, code, backend)\n- toolcompose (set, skill)\n- toolops (observe, cache, resilience, health, auth)\n- toolprotocol (transport, wire, discover, content, task, stream, session, elicit, resource, prompt)\n\nCo-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;\"\n\ngit push origin main\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#task-5-initialize-submodules","title":"Task 5: Initialize Submodules","text":"<pre><code># On fresh clone\ngit submodule update --init --recursive\n\n# Verify\ngit submodule status\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#expected-structure","title":"Expected Structure","text":"<pre><code>ApertureStack/\n\u251c\u2500\u2500 toolfoundation/      # NEW\n\u251c\u2500\u2500 tooldiscovery/       # NEW\n\u251c\u2500\u2500 toolexec/            # NEW\n\u251c\u2500\u2500 toolcompose/         # NEW\n\u251c\u2500\u2500 toolops/             # NEW\n\u251c\u2500\u2500 toolprotocol/        # NEW\n\u251c\u2500\u2500 metatools-mcp/       # Existing (updated)\n\u251c\u2500\u2500 ai-tools-stack/      # Existing (updated)\n\u2514\u2500\u2500 .gitmodules\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[x] Old submodules removed</li> <li>[x] New submodules added</li> <li>[x] .gitmodules updated</li> <li>[x] Committed and pushed</li> <li>[x] Fresh clone works</li> <li>[x] <code>git submodule update --init</code> works</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#implementation-summary","title":"Implementation Summary","text":"<ul> <li>Root <code>.gitmodules</code> now points to consolidated repos under <code>jonwraymond</code>.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-191-update-submodules/#next-steps","title":"Next Steps","text":"<ul> <li>PRD-192: Validation</li> <li>Gate G7: Full validation complete</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/","title":"PRD-192: Validation","text":"<p>Phase: 9 - Cleanup Priority: Critical Effort: 4 hours Dependencies: PRD-191 Status: Done (2026-02-01)</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#objective","title":"Objective","text":"<p>Perform comprehensive validation that the consolidation is complete and working.</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#tasks","title":"Tasks","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#task-1-repository-validation","title":"Task 1: Repository Validation","text":"<pre><code>#!/bin/bash\nset -e\n\necho \"=== Repository Validation ===\"\n\nREPOS=(\n  toolfoundation\n  tooldiscovery\n  toolexec\n  toolcompose\n  toolops\n  toolprotocol\n)\n\nfor repo in \"${REPOS[@]}\"; do\n  echo \"\"\n  echo \"Checking $repo...\"\n\n  # Verify repo exists\n  gh repo view \"jonwraymond/$repo\" &gt; /dev/null\n\n  # Clone and test\n  cd /tmp\n  rm -rf \"$repo\"\n  git clone \"git@github.com:jonwraymond/$repo.git\"\n  cd \"$repo\"\n\n  # Build\n  echo \"  Building...\"\n  go build ./...\n\n  # Test\n  echo \"  Testing...\"\n  GOWORK=off go test ./...\n\n  # Check CI status\n  echo \"  CI Status:\"\n  gh run list --limit 1\n\n  echo \"  \u2713 $repo OK\"\ndone\n\necho \"\"\necho \"=== All repositories validated ===\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#task-2-integration-validation","title":"Task 2: Integration Validation","text":"<pre><code>#!/bin/bash\nset -e\n\necho \"=== Integration Validation ===\"\n\ncd /tmp\nrm -rf metatools-mcp-test\ngit clone git@github.com:jonwraymond/metatools-mcp.git metatools-mcp-test\ncd metatools-mcp-test\n\necho \"Building metatools-mcp...\"\ngo build ./cmd/metatools\n\necho \"Running tests...\"\nGOWORK=off go test ./...\n\necho \"Starting server...\"\n./metatools serve &amp;\nPID=$!\nsleep 3\n\necho \"Testing tool list...\"\n# Test MCP tools/list\ncurl -s -X POST http://localhost:8080/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\"}' | jq .\n\necho \"Stopping server...\"\nkill $PID\n\necho \"\u2713 Integration validation passed\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#task-3-submodule-validation","title":"Task 3: Submodule Validation","text":"<pre><code>#!/bin/bash\nset -e\n\necho \"=== Submodule Validation ===\"\n\ncd /tmp\nrm -rf ApertureStack-test\ngit clone --recursive git@github.com:jonwraymond/ApertureStack.git ApertureStack-test\ncd ApertureStack-test\n\necho \"Checking submodules...\"\ngit submodule status\n\necho \"Building all submodules...\"\nfor dir in toolfoundation tooldiscovery toolexec toolcompose toolops toolprotocol; do\n  echo \"  Building $dir...\"\n  cd \"$dir\"\n  GOWORK=off go build ./...\n  cd ..\ndone\n\necho \"\u2713 Submodule validation passed\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#task-4-documentation-validation","title":"Task 4: Documentation Validation","text":"<pre><code>#!/bin/bash\nset -e\n\necho \"=== Documentation Validation ===\"\n\ncd /tmp\nrm -rf ai-tools-stack-test\ngit clone git@github.com:jonwraymond/ai-tools-stack.git ai-tools-stack-test\ncd ai-tools-stack-test\n\necho \"Checking VERSIONS.md...\"\ngrep -q \"toolfoundation\" VERSIONS.md &amp;&amp; echo \"  \u2713 toolfoundation listed\"\ngrep -q \"tooldiscovery\" VERSIONS.md &amp;&amp; echo \"  \u2713 tooldiscovery listed\"\ngrep -q \"toolexec\" VERSIONS.md &amp;&amp; echo \"  \u2713 toolexec listed\"\ngrep -q \"toolcompose\" VERSIONS.md &amp;&amp; echo \"  \u2713 toolcompose listed\"\ngrep -q \"toolops\" VERSIONS.md &amp;&amp; echo \"  \u2713 toolops listed\"\ngrep -q \"toolprotocol\" VERSIONS.md &amp;&amp; echo \"  \u2713 toolprotocol listed\"\n\necho \"Building docs...\"\nmkdocs build\n\necho \"\u2713 Documentation validation passed\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#task-5-archive-validation","title":"Task 5: Archive Validation","text":"<pre><code>#!/bin/bash\nset -e\n\necho \"=== Archive Validation ===\"\n\nARCHIVED=(\n  toolmodel\n  tooladapter\n  toolindex\n  toolsearch\n  toolsemantic\n  tooldocs\n  toolrun\n  toolruntime\n  toolcode\n  toolset\n  toolskill\n  toolobserve\n  toolcache\n)\n\nfor repo in \"${ARCHIVED[@]}\"; do\n  ARCHIVED_STATUS=$(gh repo view \"jonwraymond/$repo\" --json isArchived -q '.isArchived')\n  if [ \"$ARCHIVED_STATUS\" = \"true\" ]; then\n    echo \"  \u2713 $repo is archived\"\n  else\n    echo \"  \u2717 $repo is NOT archived\"\n    exit 1\n  fi\ndone\n\necho \"\u2713 Archive validation passed\"\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#task-6-final-checklist","title":"Task 6: Final Checklist","text":"<p>Create validation report:</p> <pre><code># Consolidation Validation Report\n\nDate: [YYYY-MM-DD]\n\n## Repository Status\n\n| Repository | Build | Tests | CI | Status |\n|------------|-------|-------|-----|--------|\n| toolfoundation | \u2713 | \u2713 | \u2713 | OK |\n| tooldiscovery | \u2713 | \u2713 | \u2713 | OK |\n| toolexec | \u2713 | \u2713 | \u2713 | OK |\n| toolcompose | \u2713 | \u2713 | \u2713 | OK |\n| toolops | \u2713 | \u2713 | \u2713 | OK |\n| toolprotocol | \u2713 | \u2713 | \u2713 | OK |\n| metatools-mcp | \u2713 | \u2713 | \u2713 | OK |\n\n## Integration Status\n\n| Test | Status |\n|------|--------|\n| metatools-mcp build | \u2713 |\n| MCP server starts | \u2713 |\n| tools/list works | \u2713 |\n| Tool execution works | \u2713 |\n\n## Archive Status\n\nAll 13 standalone repos archived: \u2713\n\n## Submodule Status\n\nAll 6 consolidated repos as submodules: \u2713\n\n## Documentation Status\n\n- VERSIONS.md updated: \u2713\n- README updated: \u2713\n- MkDocs builds: \u2713\n\n## Conclusion\n\nConsolidation complete and validated.\n\n## Verification (2026-02-01)\n\n- Consolidated repos (`toolfoundation`, `tooldiscovery`, `toolexec`, `toolcompose`, `toolops`, `toolprotocol`) pass `go test ./...` locally with `GOWORK=off`.\n- `metatools-mcp` builds and tests clean; `./metatools version` runs.\n- Old repos archived under `jonwraymond` with README deprecation notice + MIGRATION.md present.\n- Submodules updated to consolidated repos; `git submodule status` clean.\n- Docs build not run locally (mkdocs not installed); rely on CI after push.\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#verification-checklist","title":"Verification Checklist","text":"<ul> <li>[ ] All 6 consolidated repos build</li> <li>[ ] All 6 consolidated repos pass tests</li> <li>[ ] All 6 consolidated repos have passing CI</li> <li>[ ] metatools-mcp builds with new imports</li> <li>[ ] metatools-mcp tests pass</li> <li>[ ] MCP server runs correctly</li> <li>[ ] All 13 old repos archived</li> <li>[ ] Submodules work correctly</li> <li>[ ] Documentation updated</li> <li>[ ] Validation report created</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#acceptance-criteria","title":"Acceptance Criteria","text":"<ol> <li>All smoke tests pass</li> <li>No broken imports</li> <li>CI green on all repos</li> <li>Documentation accessible</li> <li>Old repos archived and read-only</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#gate-g7-complete","title":"Gate G7 Complete","text":"<p>Upon successful validation: - ApertureStack consolidation is complete - 15 repos \u2192 8 repos (6 consolidated + metatools-mcp + ai-tools-stack) - 29 packages organized into 6 consolidated repositories - Full backward compatibility removed per requirements</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-192-validation/#post-completion","title":"Post-Completion","text":"<ul> <li>Monitor for any issues from external users</li> <li>Update any external documentation/links</li> <li>Consider GitHub redirects for archived repos</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/","title":"PRD Order of Operations","text":"<p>Date: 2026-01-30 Purpose: Exact execution order for all consolidation PRDs</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#critical-path","title":"Critical Path","text":"<pre><code>PRD-100 \u2192 PRD-110 \u2192 PRD-120 \u2192 PRD-130 \u2192 PRD-150 \u2192 PRD-152 \u2192 PRD-180 \u2192 PRD-190\n   \u2193         \u2193         \u2193         \u2193         \u2193\nPRD-101   PRD-111   PRD-121   PRD-131   PRD-151\nPRD-102   PRD-112   PRD-122   PRD-132           \u2192 PRD-181 \u2192 PRD-191\n          PRD-113           PRD-133                       \u2192 PRD-192\n                              \u2193\n                           PRD-140 \u2192 PRD-143 \u2192 PRD-144 \u2192 PRD-149\n                           PRD-141\n                           PRD-142\n                              \u2193\n                           PRD-160 \u2192 PRD-162 \u2192 PRD-165 \u2192 PRD-169\n                           PRD-161\n                           PRD-163\n                           PRD-164\n                              \u2193\n                           PRD-170 \u2192 PRD-171 \u2192 ... \u2192 PRD-179\n                              \u2193\n                           PRD-182\n</code></pre>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#execution-order-sequential","title":"Execution Order (Sequential)","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-1-planning-infrastructure","title":"Week 1: Planning &amp; Infrastructure","text":"Order PRD Title Est. Hours Depends On 1 PRD-100 Master Plan 4h \u2014 2 PRD-101 Architecture Diagrams 4h PRD-100 3 PRD-102 Schema Definitions 4h PRD-100 4 PRD-110 Repository Creation 8h PRD-100 5 PRD-111 CI/CD Templates 4h PRD-110 6 PRD-112 GitHub Org Config 2h PRD-110 7 PRD-113 Release Automation 2h PRD-111"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-2-foundation-layer","title":"Week 2: Foundation Layer","text":"Order PRD Title Est. Hours Depends On 8 PRD-120 Migrate toolmodel 4h PRD-110 9 PRD-121 Migrate tooladapter 4h PRD-120 10 PRD-122 Create toolversion 8h PRD-120"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-2b-foundation-hardening-docs-contracts","title":"Week 2b: Foundation Hardening (Docs + Contracts)","text":"Order PRD Title Est. Hours Depends On 10.1 PRD-123 Docs + README alignment 3h PRD-122 10.2 PRD-124 Schema validation policy docs 2h PRD-120 10.3 PRD-125 Adapter feature matrix docs 2h PRD-121 10.4 PRD-126 Version package usage docs 2h PRD-122 10.5 PRD-127 Contract verification 1h PRD-120, PRD-121 10.6 PRD-128 Release + propagation 1h PRD-122 10.7 PRD-129 Gate G2 validation 1h PRD-120, PRD-121, PRD-122"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-3-discovery-layer","title":"Week 3: Discovery Layer","text":"Order PRD Title Est. Hours Depends On 11 PRD-130 Migrate toolindex 4h PRD-120 12 PRD-131 Migrate toolsearch 4h PRD-130 13 PRD-132 Migrate toolsemantic 6h PRD-131 14 PRD-133 Migrate tooldocs 4h PRD-120"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-3b-discovery-hardening-docs-validation","title":"Week 3b: Discovery Hardening (Docs + Validation)","text":"Order PRD Title Est. Hours Depends On 14.1 PRD-134 Docs + README alignment 2h PRD-130\u2013133 14.2 PRD-135 Search strategy policy docs 2h PRD-131 14.3 PRD-136 Semantic contracts docs 2h PRD-132 14.4 PRD-137 Progressive docs details 2h PRD-133 14.5 PRD-138 Release + propagation 1h PRD-130\u2013133 14.6 PRD-139 Discovery validation 1h PRD-130\u2013138"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-4-execution-layer","title":"Week 4: Execution Layer","text":"Order PRD Title Est. Hours Depends On 15 PRD-140 Migrate toolrun 4h PRD-120 16 PRD-141 Migrate toolruntime 4h PRD-120 17 PRD-142 Migrate toolcode 4h PRD-140 18 PRD-143 Extract toolbackend 6h PRD-120"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-4b-execution-hardening-docs-validation","title":"Week 4b: Execution Hardening (Docs + Validation)","text":"Order PRD Title Est. Hours Depends On 18.1 PRD-144 toolexec docs alignment 2h PRD-140\u2013143 18.2 PRD-145 Runtime security profile docs 2h PRD-141 18.3 PRD-146 Backend matrix docs 2h PRD-141, PRD-143 18.4 PRD-147 Toolcode/runtime contract docs 2h PRD-141, PRD-142 18.5 PRD-148 Release + propagation 1h PRD-140\u2013147 18.6 PRD-149 toolexec validation 1h PRD-140\u2013148"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-5-composition-operations-layers","title":"Week 5: Composition + Operations Layers","text":"Order PRD Title Est. Hours Depends On 19 PRD-150 Migrate toolset 4h PRD-121, PRD-130 20 PRD-151 Complete toolskill 8h PRD-150, PRD-140 21 PRD-160 Migrate toolobserve 4h PRD-120 22 PRD-161 Migrate toolcache 4h PRD-120"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-5b-composition-hardening-docs-validation","title":"Week 5b: Composition Hardening (Docs + Validation)","text":"Order PRD Title Est. Hours Depends On 20.1 PRD-152 toolcompose docs alignment 2h PRD-150\u2013151 20.2 PRD-153 set filter/policy docs 2h PRD-150 20.3 PRD-154 skill contract docs 2h PRD-151 20.4 PRD-155 user journey + examples 2h PRD-150\u2013151 20.5 PRD-156 docs site integration 1h PRD-152\u2013155 20.6 PRD-157 release + propagation 1h PRD-150\u2013156 20.7 PRD-158 toolcompose validation 1h PRD-150\u2013157 20.8 PRD-159 docs publish readiness 1h PRD-156"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-6-operations-layer-continued","title":"Week 6: Operations Layer (continued)","text":"Order PRD Title Est. Hours Depends On 23 PRD-162 Extract toolauth 8h PRD-120 24 PRD-163 Create toolresilience 8h PRD-120 25 PRD-164 Create toolhealth 6h PRD-120"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-6b-operations-hardening-docs-validation","title":"Week 6b: Operations Hardening (Docs + Validation)","text":"Order PRD Title Est. Hours Depends On 25.1 PRD-165 toolops docs alignment 2h PRD-160\u2013164 25.2 PRD-166 observe contracts docs 2h PRD-160 25.3 PRD-167 cache policy docs 2h PRD-161 25.4 PRD-168 auth/health/resilience docs 2h PRD-162\u2013164 25.5 PRD-169 release + validation 2h PRD-160\u2013168"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-7-8-protocol-layer","title":"Week 7-8: Protocol Layer","text":"Order PRD Title Est. Hours Depends On 26 PRD-170 Create tooltransport 8h PRD-120 27 PRD-171 Create toolwire 12h PRD-170 28 PRD-172 Create tooldiscover 8h PRD-171 29 PRD-173 Create toolcontent 8h PRD-120 30 PRD-174 Create tooltask 10h PRD-140, PRD-173 31 PRD-175 Create toolstream 8h PRD-170 32 PRD-176 Create toolsession 6h PRD-120 33 PRD-177 Create toolelicit 6h PRD-173 34 PRD-178 Create toolresource 10h PRD-130 35 PRD-179 Create toolprompt 8h PRD-173"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#week-9-integration-cleanup","title":"Week 9: Integration &amp; Cleanup","text":"Order PRD Title Est. Hours Depends On 36 PRD-180 Update metatools-mcp 12h All Phase 2-7 37 PRD-181 Update ai-tools-stack 4h PRD-180 38 PRD-182 Documentation Site 6h PRD-181 39 PRD-190 Archive Old Repos 2h PRD-180 40 PRD-191 Update Submodules 2h PRD-190 41 PRD-192 Validation 4h PRD-191"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#parallel-execution-opportunities","title":"Parallel Execution Opportunities","text":"<p>These PRDs can run in parallel:</p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#parallel-group-1-after-prd-110","title":"Parallel Group 1 (After PRD-110)","text":"<ul> <li>PRD-111, PRD-112 (can start together)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#parallel-group-2-after-prd-120","title":"Parallel Group 2 (After PRD-120)","text":"<ul> <li>PRD-121, PRD-122</li> <li>PRD-130, PRD-133</li> <li>PRD-140, PRD-141, PRD-143</li> <li>PRD-144\u2013149</li> <li>PRD-160, PRD-161, PRD-162</li> <li>PRD-152\u2013159</li> <li>PRD-165\u2013169</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#parallel-group-3-during-phase-7","title":"Parallel Group 3 (During Phase 7)","text":"<ul> <li>PRD-170 and PRD-173 (independent)</li> <li>PRD-175, PRD-176, PRD-177 (independent)</li> <li>PRD-178, PRD-179 (independent)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#checkpoint-gates","title":"Checkpoint Gates","text":"Gate After PRD Validation G1 PRD-113 All repos created, CI working G2 PRD-122 Foundation layer complete, tests pass G3 PRD-143 Discovery + Execution layers complete G4 PRD-164 Composition + Operations layers complete G5 PRD-179 Protocol layer complete G6 PRD-182 Integration complete G7 PRD-192 Full validation, cleanup complete"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#prd-file-naming-convention","title":"PRD File Naming Convention","text":"<p>All PRDs stored in: <code>docs/plans/</code></p> <p>Format: <code>PRD-{number}-{short-name}.md</code></p> <p>Examples: - <code>PRD-100-master-plan.md</code> - <code>PRD-110-repo-creation.md</code> - <code>PRD-120-migrate-toolmodel.md</code> - <code>PRD-170-create-tooltransport.md</code></p>"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#quick-reference-what-each-prd-delivers","title":"Quick Reference: What Each PRD Delivers","text":""},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#infrastructure-prds-100s","title":"Infrastructure PRDs (100s)","text":"PRD Deliverable 100 Master plan document 101 D2 diagrams, architecture.d2 102 schemas/*.json files 110 6 empty repos with structure 111 .github/workflows/*.yml templates 112 GitHub org secrets configured 113 release-please-config.json for each"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#migration-prds-120-160s","title":"Migration PRDs (120-160s)","text":"PRD Deliverable 120-122 toolfoundation/ with 3 packages 130-133 tooldiscovery/ with 4 packages 140-143 toolexec/ with 4 packages 150-151 toolcompose/ with 2 packages 160-164 toolops/ with 5 packages"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#new-development-prds-170s","title":"New Development PRDs (170s)","text":"PRD Deliverable 170-179 toolprotocol/ with 10 packages"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#integration-prds-180s","title":"Integration PRDs (180s)","text":"PRD Deliverable 180 metatools-mcp using new imports 181 Updated VERSIONS.md, go.mod 182 Updated MkDocs site"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#cleanup-prds-190s","title":"Cleanup PRDs (190s)","text":"PRD Deliverable 190 13 repos archived 191 New .gitmodules 192 All smoke tests passing"},{"location":"library-docs-from-repos/metatools-mcp/plans/archive/PRD-ORDER-OF-OPERATIONS/#total-effort-summary","title":"Total Effort Summary","text":"Phase PRDs Hours Days (8h) 0 100-102 12h 1.5 1 110-113 16h 2 2 120-122 16h 2 3 130-133 18h 2.25 4 140-143 18h 2.25 5 150-151 12h 1.5 6 160-164 30h 3.75 7 170-179 84h 10.5 8 180-182 22h 2.75 9 190-192 8h 1 Total 41 PRDs 236h 29.5 days <p>With parallelization, estimated calendar time: 6-8 weeks</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/","title":"Architecture Review: Consolidated Stack","text":"<p>Status: Revised (2026-02-02) Date: 2026-02-02</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#executive-summary","title":"Executive Summary","text":"<p>The consolidated stack is structurally sound and aligns with the goals of protocol-agnostic tooling, progressive discovery, and sandboxed execution. The largest risks are runtime backend completeness and protocol adapter coverage. Auth consolidation is complete and now lives in <code>toolops/auth</code>.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#what-is-solid","title":"What Is Solid","text":"<ul> <li>Layer separation is clean: <code>toolfoundation</code> \u2192 <code>tooldiscovery</code> \u2192 <code>toolexec</code> \u2192 <code>toolcompose</code> \u2192 <code>toolops</code> \u2192 <code>toolprotocol</code> \u2192 <code>metatools-mcp</code>.</li> <li>Canonical model embeds MCP SDK for spec fidelity.</li> <li>Progressive discovery has a clear pipeline and interfaces.</li> <li>Execution/runtimes are isolated behind stable contracts.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#gaps-to-close-priority-order","title":"Gaps to Close (Priority Order)","text":"<ol> <li>Protocol adapters beyond MCP/OpenAI/Anthropic (A2A + Google Gemini).</li> <li>Runtime parity for Kubernetes, gVisor, Kata, Firecracker, and remote backends.</li> <li>Auth consolidation: complete (single source in <code>toolops/auth</code>).</li> <li>Spec alignment: MCP 2025-11-25 feature coverage and testing.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#decisions-reaffirmed","title":"Decisions (Reaffirmed)","text":"<ul> <li>Keep <code>CanonicalTool</code> as the hub-and-spoke adapter format.</li> <li>Keep protocol primitives in <code>toolprotocol</code>; do not fork per protocol.</li> <li>Treat <code>metatools-mcp</code> as a reference server, not the source of truth.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ARCHITECTURE-REVIEW/#references","title":"References","text":"<ul> <li><code>ai-tools-stack/docs/roadmap.md</code></li> <li><code>ai-tools-stack/docs/architecture/stack-map.md</code></li> <li><code>ai-tools-stack/docs/architecture/protocol-crosswalk.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/ROADMAP/","title":"Metatools Roadmap (Superseded)","text":"<p>Status: Superseded Last Updated: 2026-02-02</p> <p>The consolidated roadmap for the entire stack now lives in:</p> <ul> <li><code>ai-tools-stack/docs/roadmap.md</code></li> </ul> <p>This proposal is retained for historical context only.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/","title":"Architecture Evaluation (Rewritten)","text":"<p>Status: Draft (Rewritten) Date: 2026-02-02</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#purpose","title":"Purpose","text":"<p>Evaluate the consolidated stack against interoperability, correctness, and operator experience goals.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#evaluation-criteria","title":"Evaluation Criteria","text":"<ul> <li>Protocol fidelity: MCP 2025-11-25 compliance and cross-protocol mapping.</li> <li>Execution safety: runtime isolation, strict validation, and consistent error handling.</li> <li>Operability: tracing, metrics, and clear config surfaces.</li> <li>Extensibility: clean adapter points and minimal coupling between layers.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#findings","title":"Findings","text":"<ul> <li>Strengths: canonical tool model, progressive discovery pipeline, layered packages, deterministic wire contracts.</li> <li>Risks: incomplete runtime backends; adapter coverage limited; auth duplicated across repos.</li> <li>Opportunities: add A2A bindings using <code>toolprotocol</code>, and unify adapter validation to report feature loss.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#recommendations","title":"Recommendations","text":"<ol> <li>Formalize adapter coverage (MCP/A2A/OpenAI/Anthropic/Gemini).</li> <li>Establish runtime backend readiness tiers (prod, beta, stub).</li> <li>Consolidate auth into <code>toolops/auth</code> and wire it via middleware.</li> </ol>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/architecture-evaluation/#references","title":"References","text":"<ul> <li><code>ai-tools-stack/docs/roadmap.md</code></li> <li><code>ai-tools-stack/docs/architecture/protocol-crosswalk.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/","title":"Pluggable Authentication &amp; Authorization Middleware","text":"<p>Status: Draft (Rewritten) Date: 2026-02-02</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#overview","title":"Overview","text":"<p>Provide a pluggable, policy-driven auth layer for tool discovery and execution. The core primitives live in <code>toolops/auth</code>, and <code>metatools-mcp</code> wires them as middleware.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#goals","title":"Goals","text":"<ul> <li>Single auth source of truth: <code>toolops/auth</code>.</li> <li>Request-scoped identity context for all tool operations.</li> <li>Clear separation of authentication (who) and authorization (can do what).</li> <li>Configuration-driven selection of authenticators/authorizers.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#non-goals","title":"Non-Goals","text":"<ul> <li>Full IAM system.</li> <li>Persisted policy storage (can be added later).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#architecture","title":"Architecture","text":"<ul> <li>Authenticator validates credentials and produces an identity.</li> <li>Authorizer evaluates permissions for tool operations.</li> <li>Auth middleware extracts request metadata, authenticates, authorizes, and injects identity into context.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#interfaces-from-toolopsauth","title":"Interfaces (from <code>toolops/auth</code>)","text":"<ul> <li><code>Authenticator</code>, <code>Authorizer</code>, <code>Identity</code>, <code>AuthRequest</code>, <code>AuthResult</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#integration-points","title":"Integration Points","text":"<ul> <li><code>metatools-mcp/internal/middleware</code> for enforcement.</li> <li><code>metatools-mcp/internal/transport</code> for request metadata (headers, method, resource).</li> <li><code>toolexec/run</code> for optional tool-level scope checks.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#config-surface","title":"Config Surface","text":"<ul> <li>Enable/disable authenticators (JWT, API key, OAuth2 introspection).</li> <li>Authorizer selection (RBAC, static policy).</li> <li>Default decision (deny by default, allow by default).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/auth-middleware/#references","title":"References","text":"<ul> <li><code>toolops/auth</code></li> <li><code>metatools-mcp/docs/plans/2026-01-30-prd-017-auth-middleware.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/","title":"Component Library Analysis (Consolidated Stack)","text":"<p>Status: Draft (Rewritten) Date: 2026-02-02</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#summary","title":"Summary","text":"<p>The consolidated stack is organized by capability layers. Each repo provides a focused set of packages with stable interfaces. This doc summarizes the layer map and points to the canonical stack map.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#layer-map-consolidated","title":"Layer Map (Consolidated)","text":"<ul> <li>Foundation: <code>toolfoundation</code> (canonical model + adapters)</li> <li>Discovery: <code>tooldiscovery</code> (registry + search + docs)</li> <li>Execution: <code>toolexec</code> (run + runtime + backend)</li> <li>Composition: <code>toolcompose</code> (tool sets + skills)</li> <li>Operations: <code>toolops</code> (auth + cache + observe + health + resilience)</li> <li>Protocol: <code>toolprotocol</code> (transport + wire + content + task + stream + session + prompt + resource + elicit)</li> <li>Surface: <code>metatools-mcp</code> (reference MCP server)</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/component-library-analysis/#references","title":"References","text":"<ul> <li><code>ai-tools-stack/docs/architecture/stack-map.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/","title":"Implementation Phases (Consolidated Stack)","text":"<p>Status: Draft (Rewritten) Date: 2026-02-02</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#overview","title":"Overview","text":"<p>Implementation is now tracked by the canonical roadmap. This document summarizes phase intent and defers to the roadmap for ordering and priorities.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#phases-high-level","title":"Phases (High-Level)","text":"<ul> <li>Now: protocol adapters + runtime parity + doc cleanup.</li> <li>Next: multi-tenancy + protocol bindings + observability wiring.</li> <li>Later: Proxmox/LXC backend, advanced routing policy.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/implementation-phases/#canonical-roadmap","title":"Canonical Roadmap","text":"<ul> <li><code>ai-tools-stack/docs/roadmap.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/","title":"MCP Spec Alignment Proposal (2025-11-25)","text":"<p>Status: Draft (Rewritten) Date: 2026-02-02</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#goal","title":"Goal","text":"<p>Ensure <code>metatools-mcp</code> is fully aligned with MCP spec 2025-11-25, including features, error semantics, and transport behavior.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#required-capabilities","title":"Required Capabilities","text":"<ul> <li>Core features: resources, prompts, tools.</li> <li>Discovery: <code>search_tools</code>, <code>describe_tool</code> with stable pagination.</li> <li>Notifications: tool list change events.</li> <li>Execution: cancellation + progress.</li> <li>Client features: sampling, roots, elicitation (where supported).</li> <li>Transports: stdio and streamable HTTP/SSE compliance.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#implementation-notes","title":"Implementation Notes","text":"<ul> <li>Validate the MCP version constant in <code>toolfoundation/model</code> against 2025-11-25.</li> <li>Ensure transport behavior matches the spec (headers, session IDs, event streams).</li> <li>Add conformance tests where possible.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/mcp-spec-alignment/#references","title":"References","text":"<ul> <li>MCP spec: https://modelcontextprotocol.io/specification/2025-11-25</li> <li><code>ai-tools-stack/docs/architecture/protocol-crosswalk.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/","title":"Multi-Tenancy Extension","text":"<p>Status: Draft (Rewritten) Date: 2026-02-02</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#overview","title":"Overview","text":"<p>Introduce tenant-aware boundaries across discovery, execution, and policy enforcement.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#goals","title":"Goals","text":"<ul> <li>Tenant-scoped tool registries and search.</li> <li>Tenant-aware execution isolation.</li> <li>Clear authz model for cross-tenant access.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#design","title":"Design","text":"<ul> <li>Tenant identity sourced from <code>toolops/auth</code> identity context.</li> <li>Tenant registry: namespace tool IDs by tenant and enforce visibility rules.</li> <li>Runtime isolation: map tenant to runtime backend or resource pool.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#dependencies","title":"Dependencies","text":"<ul> <li><code>toolops/auth</code> for identity + scopes.</li> <li><code>tooldiscovery/index</code> for scoped search.</li> <li><code>toolexec/runtime</code> for backend isolation.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/multi-tenancy/#references","title":"References","text":"<ul> <li><code>ai-tools-stack/docs/roadmap.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/","title":"Persistence Boundary Architecture","text":"<p>Status: Draft (Rewritten) Date: 2026-02-02</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#principle","title":"Principle","text":"<p>Separate in-memory orchestration from durable state to keep the stack portable and testable.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#boundary-rules","title":"Boundary Rules","text":"<ul> <li>Core packages should accept storage interfaces, not concrete DBs.</li> <li>Durable state lives behind optional interfaces in <code>toolprotocol</code> or per-layer packages.</li> <li>The reference server (<code>metatools-mcp</code>) may include concrete persistence adapters, but should not force them into core libs.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#candidates-for-persistence","title":"Candidates for Persistence","text":"<ul> <li>Tool registry snapshots</li> <li>Execution history and audit logs</li> <li>Cached tool results</li> <li>Long-running task state</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/persistence-boundary/#references","title":"References","text":"<ul> <li><code>toolprotocol</code> (interfaces)</li> <li><code>toolops/cache</code>, <code>toolops/observe</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/","title":"Pluggable Architecture Proposal (Consolidated Stack)","text":"<p>Status: Draft (Rewritten) Date: 2026-02-02</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#summary","title":"Summary","text":"<p>The stack is intentionally pluggable at every layer: tool schemas, discovery, execution, composition, operations, and protocol bindings.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#extension-points","title":"Extension Points","text":"<ul> <li>Schemas &amp; adapters: <code>toolfoundation/adapter</code></li> <li>Discovery: <code>tooldiscovery/index</code>, <code>search</code>, <code>semantic</code>, <code>tooldoc</code></li> <li>Execution: <code>toolexec/backend</code>, <code>toolexec/runtime</code></li> <li>Composition: <code>toolcompose/set</code>, <code>toolcompose/skill</code></li> <li>Ops: <code>toolops/auth</code>, <code>cache</code>, <code>observe</code>, <code>health</code>, <code>resilience</code></li> <li>Protocol: <code>toolprotocol/transport</code>, <code>wire</code>, <code>stream</code>, <code>task</code>, <code>resource</code>, <code>prompt</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#guardrails","title":"Guardrails","text":"<ul> <li>Keep adapters side-effect free.</li> <li>Preserve schema fidelity; emit feature-loss warnings on conversion.</li> <li>Keep runtime execution isolated behind explicit backends.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/pluggable-architecture/#references","title":"References","text":"<ul> <li><code>ai-tools-stack/docs/architecture/stack-map.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/","title":"Protocol-Agnostic Tools","text":"<p>Status: Draft (Rewritten) Date: 2026-02-02</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#summary","title":"Summary","text":"<p>Normalize tool definitions across MCP, A2A, OpenAI, Anthropic, and Google by using <code>CanonicalTool</code> as the adapter hub.</p>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#goals","title":"Goals","text":"<ul> <li>Preserve round-trip fidelity via <code>SourceMeta</code>.</li> <li>Emit feature-loss warnings for narrower schemas.</li> <li>Provide adapters for MCP, OpenAI, Anthropic, A2A, and Gemini.</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#core-types","title":"Core Types","text":"<ul> <li><code>toolfoundation/adapter.CanonicalTool</code></li> <li><code>toolfoundation/adapter.Adapter</code></li> <li><code>toolfoundation/adapter.JSONSchema</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#next-work","title":"Next Work","text":"<ul> <li>Add A2A adapter (AgentCard + skills mapping).</li> <li>Add Gemini adapter (OpenAPI subset schemas).</li> </ul>"},{"location":"library-docs-from-repos/metatools-mcp/proposals/protocol-agnostic-tools/#references","title":"References","text":"<ul> <li><code>ai-tools-stack/docs/architecture/protocol-crosswalk.md</code></li> </ul>"},{"location":"library-docs-from-repos/metatools-a2a/","title":"metatools-a2a","text":"<p><code>metatools-a2a</code> is the A2A reference server for the ApertureStack tool stack. It exposes tools as A2A skills, supports JSON-RPC + REST endpoints, and streams task updates over SSE.</p>"},{"location":"library-docs-from-repos/metatools-a2a/#highlights","title":"Highlights","text":"<ul> <li>A2A JSON-RPC (<code>agent/invoke</code>, <code>agent/status</code>)</li> <li>Agent card generation from canonical provider metadata</li> <li>REST discovery endpoints for skills and tasks</li> <li>SSE task updates for long-running executions</li> </ul>"},{"location":"library-docs-from-repos/metatools-a2a/#key-packages","title":"Key Packages","text":"<ul> <li><code>internal/agent</code> \u2014 maps ApertureStack discovery/execution into A2A semantics</li> <li><code>internal/server</code> \u2014 HTTP server and routing</li> <li><code>toolprotocol/a2a</code> \u2014 protocol binding shared across servers</li> </ul>"},{"location":"library-docs-from-repos/metatools-a2a/architecture/","title":"Architecture","text":"<p><code>metatools-a2a</code> layers an A2A protocol surface on top of the ApertureStack discovery + execution stack.</p> <pre><code>Client (A2A) \u2192 toolprotocol/a2a \u2192 metatools-a2a/agent \u2192 tooldiscovery + toolexec\n</code></pre>"},{"location":"library-docs-from-repos/metatools-a2a/architecture/#execution-flow","title":"Execution Flow","text":"<ol> <li>JSON-RPC request arrives (<code>agent/invoke</code>)</li> <li>Task created and streamed via SSE</li> <li>Tool executed via <code>toolexec/run</code></li> <li>Task completed with result payload</li> </ol>"},{"location":"library-docs-from-repos/metatools-a2a/architecture/#discovery-flow","title":"Discovery Flow","text":"<ol> <li><code>skills</code> list is derived from <code>tooldiscovery</code> summaries</li> <li>Agent card is generated from canonical provider metadata</li> </ol>"},{"location":"library-docs-from-repos/metatools-a2a/usage/","title":"Usage","text":""},{"location":"library-docs-from-repos/metatools-a2a/usage/#run-the-server","title":"Run the Server","text":"<pre><code>export METATOOLS_A2A_HOST=0.0.0.0\nexport METATOOLS_A2A_PORT=8091\nexport METATOOLS_A2A_BASE_PATH=/a2a\nexport METATOOLS_A2A_TOOLS_FILE=./tools.yaml\n\ngo run ./cmd/metatools-a2a\n</code></pre>"},{"location":"library-docs-from-repos/metatools-a2a/usage/#agent-card","title":"Agent Card","text":"<pre><code>curl http://localhost:8091/a2a/agent-card\n</code></pre>"},{"location":"library-docs-from-repos/metatools-a2a/usage/#invoke-a-skill-json-rpc","title":"Invoke a Skill (JSON-RPC)","text":"<pre><code>curl -X POST http://localhost:8091/a2a \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -d '{\n    \"jsonrpc\": \"2.0\",\n    \"id\": \"task-1\",\n    \"method\": \"agent/invoke\",\n    \"params\": {\n      \"skillId\": \"example:echo:1.0.0\",\n      \"arguments\": {\"message\": \"hello\"}\n    }\n  }'\n</code></pre>"},{"location":"library-docs-from-repos/metatools-a2a/usage/#task-events-sse","title":"Task Events (SSE)","text":"<pre><code>curl http://localhost:8091/a2a/tasks/task-1/events\n</code></pre>"}]}